{
    "id": "ezx63ah25wuvasurag6fj3vj45hrmn6s",
    "title": "Interest-Based RDF Update Propagation",
    "info": {
        "author": [
            "Fabrizio Orlandi, Department of Enterprise Information Systems (EIS), University of Bonn"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_orlandi_rdf_update/",
    "segmentation": [
        [
            "OK, hello everyone, I am fabrics your landing from the University of Bonn an I'm going to present this work that I've done together with other colleagues.",
            "Camilla, especially Camilla Andresa, PhD student in our group who unfortunately couldn't be here to present the paper because of visa visa issues so.",
            "Most of the credits go to him because he did a really great work.",
            "Together with him there were also Cidre Faisal, and certain hour and Simon Sherry.",
            "The work today I'm going to present is about interest based RDF update propagation."
        ],
        [
            "So the main motivation for this work is.",
            "About accessing sparticle endpoints, there are problems.",
            "As you know, accessing Parkland points on the web, there are many datasets, many link data datasets, and SPARQL endpoints an you want to use applications that they can easily access these endpoints, but."
        ],
        [
            "There are many challenges, so there are challenges of availability for this endpoint or low performance or high traffic or even some restrictions for the queries and the number of results that you might get."
        ],
        [
            "So when these endpoints are not available, possible solution would be that you set up a local replica of this data set.",
            "Anne."
        ],
        [
            "This solution, however has some other problems.",
            "First of all, setting up a local replica might require either to download data set, dump an entire data set, dump and download it locally and store it, and then you need to update it every time there is a change on this data set, you need to re download an reinstall it.",
            "Or you can have a continuous synchronization approach.",
            "But you need to propagate all the changes which are coming from the source.",
            "The original source you need to propagate all the changes to your local replica Ann.",
            "You need to do that also for triples where you are not really interested in on what you're not really interested in so."
        ],
        [
            "First of all, just a quick definition.",
            "Here we consider this work that we can access changesets from the sources.",
            "So from this Parkland points.",
            "So we quickly define changesets as basically sets of triples added and removed triples.",
            "Um?"
        ],
        [
            "So with the traditional approach for synchronization, you would collect these changesets from the source that they are published.",
            "For example, DPD alive is publishing changeset, many change that every hour also link Geo data used to do that and many other datasets.",
            "So a traditional approach would be you just take all the remove triples.",
            "All the other triples and then you propagate them to your local copy.",
            "Um?"
        ],
        [
            "Our approach aims at taking tackling the problem of propagating all the changes, so we aim at creating a subset, a local replica of this data set, but create basically just download a slice of this data set so just a subset of the original source, store it locally and then keeping it up to date.",
            "By using an interest.",
            "So basically an application or users, they can express their own interest on a data set an the updates that we will propagate to.",
            "Your local copy will be only related to your interest.",
            "So these interest expressions would be basically Sparkle basic graph patterns.",
            "An they are evaluated on the changeset, so once we get the changeset from the source, then we evaluate the interest of an application or or the user.",
            "We do matching and then we decide if we need to basically propagate the interests.",
            "Right, the triples, sorry.",
            "Um?"
        ],
        [
            "So just briefly about the architecture of our framework, the interest based propagation framework.",
            "As you can see here, on the left we have the source here.",
            "This is the source of remote data set.",
            "Ann, we assume the remote endpoint is publishing changesets regularly, so we could collect, added and deleted triples here.",
            "From the local from the remote source.",
            "An once we do that, an application or a user can register the interest.",
            "So the part of the data set that's interested in register the interest up here into the framework.",
            "And then basically we do interest evaluation matching the interest of an application or a user against the changeset.",
            "Anne.",
            "This filtering basically candidate generation.",
            "We will see later a bit more in detail.",
            "Um?",
            "It's not so simple as it looks, as you need to consider also.",
            "Partial matches to your interests.",
            "So two years Parker Query, so that's why we have here a data set which is potentially interesting data set, so it's containing potentially interesting triples which might be propagated to your local copy here to the right.",
            "At a later stage.",
            "Um?"
        ],
        [
            "But first of all, let's see I said an interest expression.",
            "So an application or a user can express an interest on a particular data set.",
            "An basically this is just a sparkle query.",
            "It's a construct query.",
            "As you can see here, it's a composition of basic graph patterns, an optional graph patterns plus the your eyes of the source and the replica about the target.",
            "So this would be the interest."
        ],
        [
            "And the interest needs to be matched against the change sets.",
            "That we retrieved from the source.",
            "The remote data set.",
            "So the interest evaluation process is basically divided into 2 steps.",
            "We have interest candidate generation, an interest candidate assertion.",
            "So the first step basically performs a matching between the interest expression so that the sparkle query which is representing your interest.",
            "And the change sets which are coming from the remote data set the remote endpoint.",
            "This generates a set of candidate triples.",
            "As you can see here.",
            "Um, this set of candidate triples then needs to be matched again against the interest and the target data set.",
            "Because we need to check what we already have on our local copy on our local replica.",
            "In this case here, it's called the target."
        ],
        [
            "This evaluation, to put it very simply, I don't have time to go into detail, but you have a complete formalization into the paper, so I invite you to have a look at the paper.",
            "This would generate a set of interesting, removed and added triples.",
            "Which are being propagated to your local copy and also a set of potentially interesting removed another triples which we need to keep in memory and check at the later stages for future updates if we need to propagate them or not to your local copy."
        ],
        [
            "So if you remember, a typical approach would be for a typical data set near or tool to basically propagate all the removed, another triples which are in the change sets at the source, propagate them locally to your replica."
        ],
        [
            "We don't want to do that, so that's why we express an interest.",
            "The interest.",
            "It's a sparkle query.",
            "Once we have this."
        ],
        [
            "Particle query this basically generates a set of.",
            "Candidate triples a set of interesting, removed and added triples which will be propagated.",
            "Basically it's a subset of the change that we receive from the source, and we can directly propagate it to the local replica.",
            "So the interesting triples here are fully matching the interest that we have seen before fully matching the graph patterns in the query which is representing the interests.",
            "But"
        ],
        [
            "We also need to take care of potentially interesting triples.",
            "Which are partially matching the interest.",
            "The sparkle query that you have your interest and are later stage.",
            "They might be basically promoted as interesting triples, and so they need to be propagated to the local replica."
        ],
        [
            "Um, we implemented this in a framework or I wrap it's open source so you can at the website.",
            "Here you can download it and it's on GitHub and it was implemented in Java, an Gina Ann.",
            "We use this implementation for the experiments that I'm going to explain."
        ],
        [
            "Anne followed the experiments.",
            "Basically we consider DB PEDIA 2014 as a source data set.",
            "As I said, DB Pedia is constantly publishing changesets.",
            "So we took more than 12,000 changeset in October 2014 around 15 days in October.",
            "Um?",
            "So these were the change set that we collected from the original source and then we created two different basically use cases.",
            "One is the football use case, an one is the location locations use case.",
            "So for each of the use cases we have one data set.",
            "So we created a football data set locally.",
            "It's a slice of the pedia.",
            "Anne, it's it was including more than 200,000 triples.",
            "Anne Anne this is Lisa of DB Pedia was stored locally and updated using the interest that you can see on the right here.",
            "So this interest on the right here.",
            "This particle query basically represents the interest we composed about football players.",
            "And the same for the location use cases.",
            "The only thing the only difference was that we didn't download a slice of DB pedia.",
            "But we downloaded locally the complete DB pedia data set and then we updated this copy only with the interesting triples which we were filtering.",
            "Basically using the irap framework."
        ],
        [
            "So these are the results of the evaluation on the football data set.",
            "So on the first use case we have as you can see, the total removed and total added triples, so the first 2 columns.",
            "Here it's on a logarithmic scale, so this is the number of the triples that we had in our data set locally.",
            "So the total remove triple in total added triples.",
            "They are basically what we collected from the changesets which were coming from the source.",
            "The remote source an as a comparison you can see the other two columns so interesting removed interesting added triples an.",
            "These are basically only the interesting triples that we wanted to propagate to our local copy."
        ],
        [
            "And we also hear the the information about the potentially interesting data set.",
            "So the triples which we are not propagated directly but which we kept into our potentially interesting data set.",
            "Ann as a result.",
            "Basically we found out that only zero point 3% of the total triples coming from the change set.",
            "They were actually interesting for this use case."
        ],
        [
            "Here we show for again for the football use case.",
            "We show the overall time span of around 60 hours.",
            "We showed the number of triples.",
            "Basically the growth of our local replica overtime.",
            "So with a simple naive.",
            "Mirroring approach the blue line here.",
            "Basically you can see that the data set is growing because it's collecting every possible change set from the source, while if you use the irap framework there is just a very slight increase in the number of the triples."
        ],
        [
            "The same results also for the location an use case."
        ],
        [
            "So for locations we can observe that only 4% of the triples removed.",
            "Triples were interesting and only one point 8% of the other triples were interesting."
        ],
        [
            "And similar behavior as well for the growth of the local replica."
        ],
        [
            "So as a conclusion, we have presented a novel approach for interest based at the update propagation an we have full formalizations in the paper.",
            "So I invite you to have a look at the paper for more details.",
            "I couldn't go very deeply into that.",
            "Um?",
            "The evaluation clearly shows that we can highly reduce and cut down the size of the data updates, so the updates that you would propagate to your local copy.",
            "An an as a possible use case.",
            "If you think about mobile devices or devices which have a very limited computational power or storage, this approach comes in very handy because you basically don't need to copy the whole data set again and again or perform your sparkle query on a full data set, but only on a small replica."
        ],
        [
            "So thank you very much for your attention.",
            "If you have any questions.",
            "Hi, thanks for the talk again.",
            "Um, do you support filters as well?",
            "In the construct statement?",
            "And no, not at the moment, so we only have basic graph patterns, optional graph patterns.",
            "And no filters, it's in future work to consider filters here.",
            "Um?",
            "What was the reason for?",
            "Allowing only one single query to express the interest.",
            "So basically this was that's a very good point, so a possible extension of this work would be to allow several different interest queries to be registered in the Irap framework so that we can.",
            "Basically, distribute several different updates, actually an extension of this that we are considering is to have this implemented in a kind of pub sub system where the irobe framework would act as a publisher of the of the updates.",
            "An interesting applications, they can register their interest as subscribers to the framework and receive the updates dynamically.",
            "So and at the same time and I wrap framework can be also a consumer or a subscriber of another data set.",
            "So this.",
            "This would be the possible extension."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, hello everyone, I am fabrics your landing from the University of Bonn an I'm going to present this work that I've done together with other colleagues.",
                    "label": 0
                },
                {
                    "sent": "Camilla, especially Camilla Andresa, PhD student in our group who unfortunately couldn't be here to present the paper because of visa visa issues so.",
                    "label": 0
                },
                {
                    "sent": "Most of the credits go to him because he did a really great work.",
                    "label": 0
                },
                {
                    "sent": "Together with him there were also Cidre Faisal, and certain hour and Simon Sherry.",
                    "label": 0
                },
                {
                    "sent": "The work today I'm going to present is about interest based RDF update propagation.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main motivation for this work is.",
                    "label": 0
                },
                {
                    "sent": "About accessing sparticle endpoints, there are problems.",
                    "label": 0
                },
                {
                    "sent": "As you know, accessing Parkland points on the web, there are many datasets, many link data datasets, and SPARQL endpoints an you want to use applications that they can easily access these endpoints, but.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are many challenges, so there are challenges of availability for this endpoint or low performance or high traffic or even some restrictions for the queries and the number of results that you might get.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when these endpoints are not available, possible solution would be that you set up a local replica of this data set.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This solution, however has some other problems.",
                    "label": 0
                },
                {
                    "sent": "First of all, setting up a local replica might require either to download data set, dump an entire data set, dump and download it locally and store it, and then you need to update it every time there is a change on this data set, you need to re download an reinstall it.",
                    "label": 0
                },
                {
                    "sent": "Or you can have a continuous synchronization approach.",
                    "label": 0
                },
                {
                    "sent": "But you need to propagate all the changes which are coming from the source.",
                    "label": 0
                },
                {
                    "sent": "The original source you need to propagate all the changes to your local replica Ann.",
                    "label": 0
                },
                {
                    "sent": "You need to do that also for triples where you are not really interested in on what you're not really interested in so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, just a quick definition.",
                    "label": 0
                },
                {
                    "sent": "Here we consider this work that we can access changesets from the sources.",
                    "label": 0
                },
                {
                    "sent": "So from this Parkland points.",
                    "label": 0
                },
                {
                    "sent": "So we quickly define changesets as basically sets of triples added and removed triples.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with the traditional approach for synchronization, you would collect these changesets from the source that they are published.",
                    "label": 0
                },
                {
                    "sent": "For example, DPD alive is publishing changeset, many change that every hour also link Geo data used to do that and many other datasets.",
                    "label": 0
                },
                {
                    "sent": "So a traditional approach would be you just take all the remove triples.",
                    "label": 0
                },
                {
                    "sent": "All the other triples and then you propagate them to your local copy.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach aims at taking tackling the problem of propagating all the changes, so we aim at creating a subset, a local replica of this data set, but create basically just download a slice of this data set so just a subset of the original source, store it locally and then keeping it up to date.",
                    "label": 1
                },
                {
                    "sent": "By using an interest.",
                    "label": 0
                },
                {
                    "sent": "So basically an application or users, they can express their own interest on a data set an the updates that we will propagate to.",
                    "label": 0
                },
                {
                    "sent": "Your local copy will be only related to your interest.",
                    "label": 0
                },
                {
                    "sent": "So these interest expressions would be basically Sparkle basic graph patterns.",
                    "label": 1
                },
                {
                    "sent": "An they are evaluated on the changeset, so once we get the changeset from the source, then we evaluate the interest of an application or or the user.",
                    "label": 0
                },
                {
                    "sent": "We do matching and then we decide if we need to basically propagate the interests.",
                    "label": 0
                },
                {
                    "sent": "Right, the triples, sorry.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just briefly about the architecture of our framework, the interest based propagation framework.",
                    "label": 0
                },
                {
                    "sent": "As you can see here, on the left we have the source here.",
                    "label": 0
                },
                {
                    "sent": "This is the source of remote data set.",
                    "label": 0
                },
                {
                    "sent": "Ann, we assume the remote endpoint is publishing changesets regularly, so we could collect, added and deleted triples here.",
                    "label": 0
                },
                {
                    "sent": "From the local from the remote source.",
                    "label": 0
                },
                {
                    "sent": "An once we do that, an application or a user can register the interest.",
                    "label": 0
                },
                {
                    "sent": "So the part of the data set that's interested in register the interest up here into the framework.",
                    "label": 0
                },
                {
                    "sent": "And then basically we do interest evaluation matching the interest of an application or a user against the changeset.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This filtering basically candidate generation.",
                    "label": 1
                },
                {
                    "sent": "We will see later a bit more in detail.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It's not so simple as it looks, as you need to consider also.",
                    "label": 0
                },
                {
                    "sent": "Partial matches to your interests.",
                    "label": 0
                },
                {
                    "sent": "So two years Parker Query, so that's why we have here a data set which is potentially interesting data set, so it's containing potentially interesting triples which might be propagated to your local copy here to the right.",
                    "label": 1
                },
                {
                    "sent": "At a later stage.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But first of all, let's see I said an interest expression.",
                    "label": 1
                },
                {
                    "sent": "So an application or a user can express an interest on a particular data set.",
                    "label": 0
                },
                {
                    "sent": "An basically this is just a sparkle query.",
                    "label": 0
                },
                {
                    "sent": "It's a construct query.",
                    "label": 0
                },
                {
                    "sent": "As you can see here, it's a composition of basic graph patterns, an optional graph patterns plus the your eyes of the source and the replica about the target.",
                    "label": 1
                },
                {
                    "sent": "So this would be the interest.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the interest needs to be matched against the change sets.",
                    "label": 0
                },
                {
                    "sent": "That we retrieved from the source.",
                    "label": 0
                },
                {
                    "sent": "The remote data set.",
                    "label": 0
                },
                {
                    "sent": "So the interest evaluation process is basically divided into 2 steps.",
                    "label": 1
                },
                {
                    "sent": "We have interest candidate generation, an interest candidate assertion.",
                    "label": 1
                },
                {
                    "sent": "So the first step basically performs a matching between the interest expression so that the sparkle query which is representing your interest.",
                    "label": 0
                },
                {
                    "sent": "And the change sets which are coming from the remote data set the remote endpoint.",
                    "label": 0
                },
                {
                    "sent": "This generates a set of candidate triples.",
                    "label": 1
                },
                {
                    "sent": "As you can see here.",
                    "label": 0
                },
                {
                    "sent": "Um, this set of candidate triples then needs to be matched again against the interest and the target data set.",
                    "label": 0
                },
                {
                    "sent": "Because we need to check what we already have on our local copy on our local replica.",
                    "label": 0
                },
                {
                    "sent": "In this case here, it's called the target.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This evaluation, to put it very simply, I don't have time to go into detail, but you have a complete formalization into the paper, so I invite you to have a look at the paper.",
                    "label": 0
                },
                {
                    "sent": "This would generate a set of interesting, removed and added triples.",
                    "label": 1
                },
                {
                    "sent": "Which are being propagated to your local copy and also a set of potentially interesting removed another triples which we need to keep in memory and check at the later stages for future updates if we need to propagate them or not to your local copy.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you remember, a typical approach would be for a typical data set near or tool to basically propagate all the removed, another triples which are in the change sets at the source, propagate them locally to your replica.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't want to do that, so that's why we express an interest.",
                    "label": 0
                },
                {
                    "sent": "The interest.",
                    "label": 0
                },
                {
                    "sent": "It's a sparkle query.",
                    "label": 0
                },
                {
                    "sent": "Once we have this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particle query this basically generates a set of.",
                    "label": 0
                },
                {
                    "sent": "Candidate triples a set of interesting, removed and added triples which will be propagated.",
                    "label": 0
                },
                {
                    "sent": "Basically it's a subset of the change that we receive from the source, and we can directly propagate it to the local replica.",
                    "label": 0
                },
                {
                    "sent": "So the interesting triples here are fully matching the interest that we have seen before fully matching the graph patterns in the query which is representing the interests.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also need to take care of potentially interesting triples.",
                    "label": 0
                },
                {
                    "sent": "Which are partially matching the interest.",
                    "label": 0
                },
                {
                    "sent": "The sparkle query that you have your interest and are later stage.",
                    "label": 0
                },
                {
                    "sent": "They might be basically promoted as interesting triples, and so they need to be propagated to the local replica.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, we implemented this in a framework or I wrap it's open source so you can at the website.",
                    "label": 0
                },
                {
                    "sent": "Here you can download it and it's on GitHub and it was implemented in Java, an Gina Ann.",
                    "label": 0
                },
                {
                    "sent": "We use this implementation for the experiments that I'm going to explain.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne followed the experiments.",
                    "label": 0
                },
                {
                    "sent": "Basically we consider DB PEDIA 2014 as a source data set.",
                    "label": 1
                },
                {
                    "sent": "As I said, DB Pedia is constantly publishing changesets.",
                    "label": 0
                },
                {
                    "sent": "So we took more than 12,000 changeset in October 2014 around 15 days in October.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So these were the change set that we collected from the original source and then we created two different basically use cases.",
                    "label": 0
                },
                {
                    "sent": "One is the football use case, an one is the location locations use case.",
                    "label": 0
                },
                {
                    "sent": "So for each of the use cases we have one data set.",
                    "label": 0
                },
                {
                    "sent": "So we created a football data set locally.",
                    "label": 1
                },
                {
                    "sent": "It's a slice of the pedia.",
                    "label": 0
                },
                {
                    "sent": "Anne, it's it was including more than 200,000 triples.",
                    "label": 0
                },
                {
                    "sent": "Anne Anne this is Lisa of DB Pedia was stored locally and updated using the interest that you can see on the right here.",
                    "label": 0
                },
                {
                    "sent": "So this interest on the right here.",
                    "label": 0
                },
                {
                    "sent": "This particle query basically represents the interest we composed about football players.",
                    "label": 0
                },
                {
                    "sent": "And the same for the location use cases.",
                    "label": 0
                },
                {
                    "sent": "The only thing the only difference was that we didn't download a slice of DB pedia.",
                    "label": 0
                },
                {
                    "sent": "But we downloaded locally the complete DB pedia data set and then we updated this copy only with the interesting triples which we were filtering.",
                    "label": 0
                },
                {
                    "sent": "Basically using the irap framework.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the results of the evaluation on the football data set.",
                    "label": 0
                },
                {
                    "sent": "So on the first use case we have as you can see, the total removed and total added triples, so the first 2 columns.",
                    "label": 0
                },
                {
                    "sent": "Here it's on a logarithmic scale, so this is the number of the triples that we had in our data set locally.",
                    "label": 0
                },
                {
                    "sent": "So the total remove triple in total added triples.",
                    "label": 0
                },
                {
                    "sent": "They are basically what we collected from the changesets which were coming from the source.",
                    "label": 0
                },
                {
                    "sent": "The remote source an as a comparison you can see the other two columns so interesting removed interesting added triples an.",
                    "label": 0
                },
                {
                    "sent": "These are basically only the interesting triples that we wanted to propagate to our local copy.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we also hear the the information about the potentially interesting data set.",
                    "label": 0
                },
                {
                    "sent": "So the triples which we are not propagated directly but which we kept into our potentially interesting data set.",
                    "label": 0
                },
                {
                    "sent": "Ann as a result.",
                    "label": 0
                },
                {
                    "sent": "Basically we found out that only zero point 3% of the total triples coming from the change set.",
                    "label": 1
                },
                {
                    "sent": "They were actually interesting for this use case.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we show for again for the football use case.",
                    "label": 0
                },
                {
                    "sent": "We show the overall time span of around 60 hours.",
                    "label": 0
                },
                {
                    "sent": "We showed the number of triples.",
                    "label": 0
                },
                {
                    "sent": "Basically the growth of our local replica overtime.",
                    "label": 0
                },
                {
                    "sent": "So with a simple naive.",
                    "label": 0
                },
                {
                    "sent": "Mirroring approach the blue line here.",
                    "label": 0
                },
                {
                    "sent": "Basically you can see that the data set is growing because it's collecting every possible change set from the source, while if you use the irap framework there is just a very slight increase in the number of the triples.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same results also for the location an use case.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for locations we can observe that only 4% of the triples removed.",
                    "label": 0
                },
                {
                    "sent": "Triples were interesting and only one point 8% of the other triples were interesting.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And similar behavior as well for the growth of the local replica.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as a conclusion, we have presented a novel approach for interest based at the update propagation an we have full formalizations in the paper.",
                    "label": 1
                },
                {
                    "sent": "So I invite you to have a look at the paper for more details.",
                    "label": 0
                },
                {
                    "sent": "I couldn't go very deeply into that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The evaluation clearly shows that we can highly reduce and cut down the size of the data updates, so the updates that you would propagate to your local copy.",
                    "label": 1
                },
                {
                    "sent": "An an as a possible use case.",
                    "label": 0
                },
                {
                    "sent": "If you think about mobile devices or devices which have a very limited computational power or storage, this approach comes in very handy because you basically don't need to copy the whole data set again and again or perform your sparkle query on a full data set, but only on a small replica.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So thank you very much for your attention.",
                    "label": 1
                },
                {
                    "sent": "If you have any questions.",
                    "label": 0
                },
                {
                    "sent": "Hi, thanks for the talk again.",
                    "label": 0
                },
                {
                    "sent": "Um, do you support filters as well?",
                    "label": 0
                },
                {
                    "sent": "In the construct statement?",
                    "label": 0
                },
                {
                    "sent": "And no, not at the moment, so we only have basic graph patterns, optional graph patterns.",
                    "label": 0
                },
                {
                    "sent": "And no filters, it's in future work to consider filters here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What was the reason for?",
                    "label": 0
                },
                {
                    "sent": "Allowing only one single query to express the interest.",
                    "label": 0
                },
                {
                    "sent": "So basically this was that's a very good point, so a possible extension of this work would be to allow several different interest queries to be registered in the Irap framework so that we can.",
                    "label": 0
                },
                {
                    "sent": "Basically, distribute several different updates, actually an extension of this that we are considering is to have this implemented in a kind of pub sub system where the irobe framework would act as a publisher of the of the updates.",
                    "label": 0
                },
                {
                    "sent": "An interesting applications, they can register their interest as subscribers to the framework and receive the updates dynamically.",
                    "label": 0
                },
                {
                    "sent": "So and at the same time and I wrap framework can be also a consumer or a subscriber of another data set.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "This would be the possible extension.",
                    "label": 0
                }
            ]
        }
    }
}