{
    "id": "dfilwcyelrae4yodga257pyalzu4yikb",
    "title": "Minimax Policies for Combinatorial Prediction Games",
    "info": {
        "author": [
            "S\u00e9bastien Bubeck, Department of Operations Research and Financial Engineering, Princeton University"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Mathematics->Combinatorics"
        ]
    },
    "url": "http://videolectures.net/colt2011_bubeck_games/",
    "segmentation": [
        [
            "OK so I will talk about combinatorial prediction games and I will start by defining what I mean by combinatorial."
        ],
        [
            "OK, so let me start with an example.",
            "So many of you have already seen pictures like that, so it's going to be an example for the past planning program.",
            "So this is a map of Barcelona.",
            "This is a place where I live and this is where is the University.",
            "So every morning when I wake up, I have a decision problem.",
            "I need to choose a path to go from my apartment to the University.",
            "OK, so it's it's a sequential game where the action set is the set of all paths from point A to point B. OK, so this set is huge, it's it's a really big set but but there is some very interesting structure in this set.",
            "So for instance if I take.",
            "This path OK and now I take the same path but I turn left on this street OK and then I go to be.",
            "Then the two pass.",
            "They share a lot of information, right?",
            "So I know that the time it takes for me to go from here to here is going to be the same on the two path.",
            "OK, so I want to exploit that structure.",
            "Alright, so."
        ],
        [
            "Now let me formalize this a little bit more.",
            "So we have a game between the player and an adversary, and we have a graph which is given OK, so I want to go from this node to this one."
        ],
        [
            "So as a player at every every day I choose a path.",
            "OK, so for instance this one and simultaneously."
        ],
        [
            "Do we have an adversary with choosing the delays on the graph OK, the delays on this?"
        ],
        [
            "So it chooses all the delays, so let's assume that we have a graph with D edges, so it chooses Adele, A L1, which represents the time it takes for me to go from this node to this one OK, and L4, which is from this node to this one, etc up to LD, which is the time it takes to go from this note to this one.",
            "Alright, so now how long does it take for me when I."
        ],
        [
            "Exact path, well it takes the sum L 2 + 7 etc plus LD.",
            "That's the time it took for me to with this pass, OK?",
            "Now I want to learn, so I receive a feedback OK and we will make.",
            "We will assume three different types."
        ],
        [
            "Feedback so the first one, the strongest one, is what is called the fuel information feedback.",
            "So we assume that we observe at the end of the day the delays on all the edges in the graph.",
            "OK, so in my example it means that I'm very serious about my problem and I don't know why I listen to the radio.",
            "I watched the TV and I recalled the delays on every street in Barcelona.",
            "OK, so that's it's a very strong assump."
        ],
        [
            "Done right?",
            "And also kind of feedback is what is called or what we call the semi bandits feedback.",
            "So it's we only record the time on every street that I went through.",
            "OK so I record L2L7 etc up to LD.",
            "Alright, so that's a weaker signal, but but it's still something."
        ],
        [
            "Now the weakest signal is in the simplest signal in my example, so we assume that we only record the total time that it took to go from my place to the University.",
            "So we only record L, 2 + 7, etc plus LD.",
            "So this is so bandit is much weaker than semi Bandit and you would guess that semi Bandit is much, much weaker than sure information will show that it's not.",
            "The picture is not as clear as that."
        ],
        [
            "OK, so now a little bit of notation, so we have a graph.",
            "That we represent as a subset of the hypercube, so why so if I have so we have the edges?",
            "OK, so a point in the hypercube in dimension D, you can view it as a set of edges, right?",
            "So if I have point U in 01 to the D, if there is a one at coordinate I, it means that edge I is in my set.",
            "OK.",
            "So now pass from this node to this one.",
            "It's a subset of all set of edges.",
            "OK, so I can represent that equivalently as a subset of the hypercube.",
            "OK so I have a subset of the hyperscript S. Note that subset of hypercube are much more general than paths in a graph.",
            "OK, can mobilize other things, but for for the talk I will restrict a path.",
            "So the adversary is choosing a loss Lt.",
            "In ardian.",
            "We will assume that the loss is non negative.",
            "OK, so the delay is a non negative number.",
            "Then as as I said at every time step T the player chooses a path V sub T in South.",
            "So it chooses a path and the loss that he suffers is the dot product.",
            "So I think I think that's clear right?",
            "So it's clear that it's a dot product because if if I cross street I so edge I then it means that Vt at coordinates.",
            "Why is 1?",
            "So I get the ice coordinate of the last Lt. OK, so and then it's just the sun.",
            "And then as usual, I'm interested in the regret which is defined as follows, so it's.",
            "So we play the game for anytime step and I compare the cumulative loss of my strategy to the best I could have obtained if I knew in hindsight, what was the best path.",
            "OK, and I would everyday choose the best path.",
            "OK, so that's the usual definition of regret, and then I have an expectation because we will see we choose the path randomly.",
            "OK, so we have an expectation with respect to the strategy of the player.",
            "So far that's.",
            "Most of you know no."
        ],
        [
            "What this is?"
        ],
        [
            "And now I want to prove regret bounds, but I need to put some assumptions on the loss.",
            "OK, just assuming that it's in Rd, it's not enough, because then the loss could blow up at certain rounds and we would not control that and we would miss a big part of the loss at those, right?"
        ],
        [
            "So we need some assumption of an Lt.",
            "I think the most natural one is the L Infinity assumption, which says that simply the loss on the streets is normalized so.",
            "In an Infinity norm, the vector Lt is smaller than one OK. Now.",
            "Another assumption has got a lot of attention, namely the what we call the L2 assumption.",
            "So it says that the DOT product LTV for any path V is smaller than one.",
            "So it means that the the total time it takes for me to go from the starting point to the end point is smaller than one.",
            "OK, so in particular it means that it's independent of the size of the graph, right?",
            "So it's not clear if that's such a good assumption an.",
            "That the first thing and the second thing is that you intuitively you would say that you can move from L2 to L Infinity and vice versa, right?",
            "That it's just a matter of normalization.",
            "And I will show you that it's really not the case that.",
            "There exist algorithm which are minimax optimal for L2 adversaries and which are fundamentally not minimax optimal for L Infinity adversaries.",
            "You cannot just change the parameter and into work."
        ],
        [
            "OK, so before showing you this result I would like just to remind you the key idea of this type of games.",
            "So the key idea is simply to take the action at random.",
            "OK, so we have a probability distribution PT or the set of paths and we take Viti at random from PT.",
            "Why is it such a good idea?",
            "Because then we can build an unbiased estimate.",
            "LTT of the true loss, Lt.",
            "Even if we don't observe it, of course in the full information game we observe it, so we don't need to estimate.",
            "We just set Lt. To be healthy.",
            "In the semi bandit game, it's also very easy because so we observe for fixed Street I either we don't observe it and then we estimate that it's zero, or if we observe it then we will normalize by the probability of observing this street OK, so that's like in the standard bandit case.",
            "Now in the bandit game, it's a little bit more complicated, so this estimator was suggested by Danny's and Caddy.",
            "It's it's very easy to see that it's unbiased.",
            "I don't want to enter into the detail, but just you need to know that you can build an unbiased estimate even when you just observe the cumulative loss."
        ],
        [
            "OK. Now I will move to showing you why L2 and L Infinity are not the same.",
            "So we consider what we call the expanded exponentially weighted average forecaster.",
            "So it's so why expanded?",
            "So this formula you know, maybe as edge or exponential forecaster or whatever.",
            "There are many names here.",
            "It's expanded because we have this law system, so it it's almost like playing edge on the set of paths, except that we have a.",
            "More clever estimate.",
            "A clever estimate of the loss.",
            "OK, so it's not exactly edge on the set of paths, it's something a little bit different, but it doesn't matter that much for these slides because I will restrict my attention to the fuel information, full information case, and then it's exactly playing edge on the set of path.",
            "Then in the 2008 paper down, yes and CKD showed that in social information game against L2 adversaries, you can if you tune it, ITA in a good way.",
            "Then the regret is smaller than square root of DN.",
            "So let me just say that in this talk we will be mostly interested by the dependency on D because the dependency on now it's it's known.",
            "It's very well known that it's crowd of any in all these games.",
            "OK, so now what is left to do is to catch the right dependency on the dimension.",
            "OK, so they prove square root of DN and this is the optimal right?",
            "So they prove also allowed bond with another two adversary which is correct again.",
            "Then just by noting that if you are L Infinity, if you have L Infinity bound L Infinity bound on your adversaries and you also have a L2 bound on your adversary with an additional factor D. So there is a scaling factor of D so.",
            "This bound directly implies that against her Infinity adversary, you get D to three off script event.",
            "But now this is suboptimal and that was a core classy and so couldn't 1 moose and Kevin, and they proved that in fact you can get discrete event with a fundamentally different algorithm that I will present later.",
            "So the question the open problem in that paper was is it intersects that you get data this real or can you improve the analysis?",
            "So what we prove is that no matter what is eaten.",
            "You can find a graph or a subset S of the hypercube and some L Infinity adversary so that the regret will be at least D to this real square root of N. So it's you cannot tune edge to be optimal against an Infinity adversaries in the in the linear case OK."
        ],
        [
            "So you need to do something different.",
            "So what can you do?",
            "Well you need.",
            "We do something very different, so let me just briefly remind you which is allusion to function so you have a convex set D in Rd OK, and you take a function F which goes from from D2 R and we just assume that basically it's strictly convex and the gradient tends to Infinity on the boundary of the OK.",
            "So you have D strictly convex an on the boundaries of gradient turns to Infinity.",
            "That's long.",
            "OK, so it's not.",
            "It's not much."
        ],
        [
            "Two illusion function you can associate the Bregman divergent DF, which basically for any two points U&V in Indy it represents the mistakes that you make when you do a first order Taylor approximation of F of you at the point be OK, it's just the error that you make, so it's very much related to the structure of the Asian of F."
        ],
        [
            "Alright.",
            "And now I will present you the algorithm.",
            "So we have that is a simplex over S. OK, so that's the set of probability distribution overpass cake lives in some big dimensional space.",
            "Now we also have inaudi.",
            "We have S so that the vertices of this pull it up and we take the convex Hull Office that this green region.",
            "Then we take a super set of the convex surface, which is the.",
            "So D will be a parameter of our algorithm and we take a function F. Jean Sunday.",
            "OK, so that's the algorithm which we called Club.",
            "By the way, is parameterized by F and."
        ],
        [
            "And then we will do the following.",
            "So we are at some point PT in the simplex over S OK and I will tell you how to move from PT to PT plus one using the last estimate at time T."
        ],
        [
            "So first you move from PT2 from the simplex to the convex are by simply taking WT which is the expectation of PT.",
            "OK so when you choose the pass at random, the expectation of that path is in the convex Hull.",
            "So PT you have some."
        ],
        [
            "WT.",
            "Then you do a mirror gradient decent step using the function F. OK, so you solve you find W prime T + 1 which solve the gradient of at.",
            "This new point must be equal to the gradient of FWT minus the last estimate.",
            "So that's where we use the last estimate.",
            "To do this, mirror gradient."
        ],
        [
            "Decent step.",
            "Then we project back using the Bregman Divergent, so OK, so we project back W Prime T + 1 in the convex Hull Office."
        ],
        [
            "And now we project again back on the simplex using simply we just find the probability distribution such that in expectation its expectation is TT plus one, so it's not unique.",
            "It's certainly not computationally efficient in many cases, but we are really interested in the optimal regret.",
            "OK, so we not in computational complexity, at least not for now.",
            "So let me say that this kind of algorithm has a very long history.",
            "OK, so I won't review all the other people worked with very similar algorithm.",
            "For instance, many of you might be familiar with the same algorithm where F is strongly convex, for instance.",
            "So here it's more general.",
            "Here F is lesion.",
            "And even in that more general framework, you can still prove."
        ],
        [
            "Generally, regret bound which looks like this.",
            "So you have one term which measure the size of S, the diameter of S viewed under the Bregman divergent associated to F, and then you have another time, which is a quadratic term, so it's a quadratic form applied to the last estimate, and the quadratic form is the inverse of the action.",
            "OK, so for those of, you know that kind of bounds.",
            "I think it looks familiar.",
            "Alright, so."
        ],
        [
            "Which is really nice.",
            "Which club is that?",
            "Basically generalizes.",
            "Everything so.",
            "So if you take D to be the positive, autant OK an F to be the entropy function, we scaled by one over ISA, then for that kind of graph.",
            "So what does it mean?",
            "That kind of graphic means that you cannot infer anything from one part to another, so it's just a multi unbanded or standard expert prediction problem.",
            "So in that case if you take club with those parameters and in the full information you get edge or exponential weighted average forecasts or whatever the name you prefer in the semi bandit and Bandit framework is the same here.",
            "And you get X3.",
            "Now for general graph.",
            "Club with those parameters we call it Linux by the way.",
            "Insufficient information case.",
            "It corresponds to component edge that were presented at court last year in the semi bandit case.",
            "It corresponds to the MW algorithm which was presented, I think at NIPS.",
            "And in the bandit case, it's a new algorithm which which was not published before."
        ],
        [
            "OK, so another interesting choices.",
            "Again, D to be the positive autumn and now F is is like that.",
            "OK so it's a sum of integral of some potential upside invest.",
            "So why do we take such a complicated lesion function?",
            "Because then it generalizes the algorithms that we published with joint two years ago, which is minimax optimal in the simple multi unbanded case.",
            "So general case, if you take side to be exponential exponential potential, then you get Linux and if you take side to be polynomial then you get a completely new algorithm which we call link Poly which has very nice property and I will talk a little bit about."
        ],
        [
            "Another case is when you take D to be exactly the convex office.",
            "OK, so not not a super set of S, but the convex olivette then it's exactly follows a regularised leader with regularizer F an.",
            "As you probably know, one very interesting choices to take F to be a self concordant barrier function.",
            "OK, then you basically get the best results that we know for the bandit case.",
            "But still not optimal as I will show you so now."
        ],
        [
            "When we go, we get to the the main result of our paper.",
            "So let me define what we mean by being minimax regret.",
            "So you take the regrets?",
            "OK, now you take the supremum overall adversaries.",
            "So either L, Infinity or L2.",
            "You take the worst possible subset of the hypercube, so you want to guarantee that that is satisfied for any graph.",
            "OK, you don't want a guarantee that depends on the structure of the graph, and now you take the best strategy with respect to that criteria.",
            "OK, so that's what we called the minimax regret for combinatorial prediction games.",
            "Then we have this result so.",
            "The shooting full information and semi bandit games.",
            "Against L Infinity adversaries, we know exactly what is the minimax regret is discrete, often up to a constant OK?",
            "In the L2 case, we know it also up to a log factor, so it's crowd of DN in the lower bound and stripped of DN log D in the upper bound.",
            "So to get this Superman we needed limpley.",
            "OK, so we need that the new algorithm, otherwise we couldn't get it.",
            "So what?",
            "What is really nice is that it's a little bit hidden in the way I see it is that it's true for full information and semi bandit, so you remember at the beginning of the talk I was saying that.",
            "It's the semi bandit signal is much weaker than the full information, and it turns out that when you look at the minimax regret, it's not that much weaker.",
            "It's just a matter of a constant.",
            "So it's quite surprising.",
            "Now in the bandit game for an Infiniti adversaries, we have data three outskirts of N&E to the five helps code event for the upper bound, so there is a gap of D and against L2 we have disco defending the lower bound and it to the three of scrotal, and so this table.",
            "So we have a gap.",
            "Scope of this table.",
            "So we can recover all these results with our analysis, but most of them already appeared before.",
            "OK so.",
            "Most of them like, not all, are bound, not this upper bound, but.",
            "But many of them appeared.",
            "So now what is really interesting is to fill in that gap.",
            "OK, so the gap in their infinite case and the square root of the gap in the L2 case.",
            "So what I personally think is that for the L2 case, so it is known for their two case that for some subset South you can match the lower bound by using the paper of Gabor and Niccolo of called last year.",
            "I think, where they do some kind of specific exploration S, but unfortunately what they do does not work in general.",
            "In general, you can get an exponential bound, which is exponentially D. OK, and we don't know how to generalize to any set S, so I think if you have a way to do that then you will probably close the gap for the L2 adversary and then for the L Infinity adversary.",
            "With that, that's my guess.",
            "I guess you improve Bias quote of D and then to get the others quote of D you need to find a new lesion function F which will be.",
            "I think completely different from what we know.",
            "So what we know currently is either the Asian is diagonal so that we do with info or the action is non diagonal and then it's a cell phone content barrier function.",
            "But somehow the self concordant barrier function seems too general to under.",
            "Any said S, but that's that's basically where where we stopped at the open question, and that's it.",
            "Thank you.",
            "Questions, so I was curious what do the as the least valuable lessons you have an do?",
            "They have a very, you know, awful particular property that you could try to adapt to?",
            "Not at all.",
            "It's not.",
            "It's not bad, bad settings, so it's basically so worst case is K sets, so you have two cases where K is a prodigy.",
            "OK, so when you have to choose.",
            "And you said, as you.",
            "So you have bandit problem where you have D arms OK and you have to choose at every time step D. Half of those arms.",
            "And what you observe is the sun.",
            "That's basically the most difficult case, so it's really nothing, nothing fancy.",
            "Nothing is hidden.",
            "I think nothing is hidden here.",
            "Question.",
            "What can you say about the computational complexity of the methods in this case?",
            "So not much so.",
            "In general, I think in general you can't say anything for particular sets, as you can say something so that was done actually in in the Cold Paper last year by one moussan: and keeping and so for some set S you can come up with good way to project with this Bregman divergences.",
            "But in general we don't know and it might be that.",
            "If you ask for computationally efficient strategy, might very well be that the table will look completely different, but that's a very difficult question.",
            "Going back to the to the motivating example with routing so mean in, so you assume that you choose all path at once.",
            "I mean all the path at once, whereas you know in a semi bandit feedback you could imagine you know choosing the first stage, observing the feedback and then choosing the next and so forth.",
            "I was wondering, you know?",
            "What do you think of this version?",
            "OK, so I've seen I think it's a different version, so I think it requires.",
            "Probably, maybe not a very different analysis, but at least it doesn't follows from what we did, but it's an interesting problem.",
            "Last question from Jake.",
            "So I have two questions I can ask both.",
            "Still it's OK. OK, so the first one is you had about that was in terms of the Hessian of the.",
            "Yeah, so in terms of the Hessian, you take the Lt, transpose the F squared.",
            "Yeah that, so that doesn't hold in general, right?",
            "That fact doesn't hold in general, no.",
            "So you see that the."
        ],
        [
            "Term, thankfully not exactly smaller than that.",
            "OK so.",
            "Here's something easy then, so so it's like it holds for a point which is near WT maybe, but not at exactly exactly exactly.",
            "And that's where that's where the the hard stuff is.",
            "In the bandit case, because that's where you need the exploration.",
            "That's exactly why.",
            "See if that was true, then everything will be solved.",
            "OK, so the next question is I just decided before, so what's the gap?"
        ],
        [
            "Now I did notice in the red and green, yellow, red and green on that slide you OK or bread and blue.",
            "Sorry alright, so so red is at Infinity adversaries, so you assume that the Infinity norm of the loss is bounded by one.",
            "OK and blue is L2, so you assume that what you assumed in your paper Lt transpose V, is smaller than one.",
            "That's the blue set, the blue OK that the L2.",
            "So there's still a gap.",
            "We still don't know between absolutely so.",
            "So in code Classilla Gabba Nicole at the paperwork for.",
            "Some said S. They could close the gap, but it doesn't work in general.",
            "And what do you think is the I think for?",
            "You know it's it's a lower bound.",
            "OK, so let's think Sebastian and."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I will talk about combinatorial prediction games and I will start by defining what I mean by combinatorial.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me start with an example.",
                    "label": 0
                },
                {
                    "sent": "So many of you have already seen pictures like that, so it's going to be an example for the past planning program.",
                    "label": 0
                },
                {
                    "sent": "So this is a map of Barcelona.",
                    "label": 0
                },
                {
                    "sent": "This is a place where I live and this is where is the University.",
                    "label": 0
                },
                {
                    "sent": "So every morning when I wake up, I have a decision problem.",
                    "label": 0
                },
                {
                    "sent": "I need to choose a path to go from my apartment to the University.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's it's a sequential game where the action set is the set of all paths from point A to point B. OK, so this set is huge, it's it's a really big set but but there is some very interesting structure in this set.",
                    "label": 0
                },
                {
                    "sent": "So for instance if I take.",
                    "label": 0
                },
                {
                    "sent": "This path OK and now I take the same path but I turn left on this street OK and then I go to be.",
                    "label": 0
                },
                {
                    "sent": "Then the two pass.",
                    "label": 0
                },
                {
                    "sent": "They share a lot of information, right?",
                    "label": 0
                },
                {
                    "sent": "So I know that the time it takes for me to go from here to here is going to be the same on the two path.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to exploit that structure.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let me formalize this a little bit more.",
                    "label": 0
                },
                {
                    "sent": "So we have a game between the player and an adversary, and we have a graph which is given OK, so I want to go from this node to this one.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as a player at every every day I choose a path.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance this one and simultaneously.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do we have an adversary with choosing the delays on the graph OK, the delays on this?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it chooses all the delays, so let's assume that we have a graph with D edges, so it chooses Adele, A L1, which represents the time it takes for me to go from this node to this one OK, and L4, which is from this node to this one, etc up to LD, which is the time it takes to go from this note to this one.",
                    "label": 0
                },
                {
                    "sent": "Alright, so now how long does it take for me when I.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exact path, well it takes the sum L 2 + 7 etc plus LD.",
                    "label": 0
                },
                {
                    "sent": "That's the time it took for me to with this pass, OK?",
                    "label": 0
                },
                {
                    "sent": "Now I want to learn, so I receive a feedback OK and we will make.",
                    "label": 0
                },
                {
                    "sent": "We will assume three different types.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feedback so the first one, the strongest one, is what is called the fuel information feedback.",
                    "label": 0
                },
                {
                    "sent": "So we assume that we observe at the end of the day the delays on all the edges in the graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so in my example it means that I'm very serious about my problem and I don't know why I listen to the radio.",
                    "label": 0
                },
                {
                    "sent": "I watched the TV and I recalled the delays on every street in Barcelona.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's it's a very strong assump.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Done right?",
                    "label": 0
                },
                {
                    "sent": "And also kind of feedback is what is called or what we call the semi bandits feedback.",
                    "label": 0
                },
                {
                    "sent": "So it's we only record the time on every street that I went through.",
                    "label": 0
                },
                {
                    "sent": "OK so I record L2L7 etc up to LD.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's a weaker signal, but but it's still something.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the weakest signal is in the simplest signal in my example, so we assume that we only record the total time that it took to go from my place to the University.",
                    "label": 0
                },
                {
                    "sent": "So we only record L, 2 + 7, etc plus LD.",
                    "label": 0
                },
                {
                    "sent": "So this is so bandit is much weaker than semi Bandit and you would guess that semi Bandit is much, much weaker than sure information will show that it's not.",
                    "label": 0
                },
                {
                    "sent": "The picture is not as clear as that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now a little bit of notation, so we have a graph.",
                    "label": 0
                },
                {
                    "sent": "That we represent as a subset of the hypercube, so why so if I have so we have the edges?",
                    "label": 0
                },
                {
                    "sent": "OK, so a point in the hypercube in dimension D, you can view it as a set of edges, right?",
                    "label": 0
                },
                {
                    "sent": "So if I have point U in 01 to the D, if there is a one at coordinate I, it means that edge I is in my set.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now pass from this node to this one.",
                    "label": 0
                },
                {
                    "sent": "It's a subset of all set of edges.",
                    "label": 0
                },
                {
                    "sent": "OK, so I can represent that equivalently as a subset of the hypercube.",
                    "label": 0
                },
                {
                    "sent": "OK so I have a subset of the hyperscript S. Note that subset of hypercube are much more general than paths in a graph.",
                    "label": 0
                },
                {
                    "sent": "OK, can mobilize other things, but for for the talk I will restrict a path.",
                    "label": 0
                },
                {
                    "sent": "So the adversary is choosing a loss Lt.",
                    "label": 0
                },
                {
                    "sent": "In ardian.",
                    "label": 0
                },
                {
                    "sent": "We will assume that the loss is non negative.",
                    "label": 0
                },
                {
                    "sent": "OK, so the delay is a non negative number.",
                    "label": 0
                },
                {
                    "sent": "Then as as I said at every time step T the player chooses a path V sub T in South.",
                    "label": 0
                },
                {
                    "sent": "So it chooses a path and the loss that he suffers is the dot product.",
                    "label": 0
                },
                {
                    "sent": "So I think I think that's clear right?",
                    "label": 0
                },
                {
                    "sent": "So it's clear that it's a dot product because if if I cross street I so edge I then it means that Vt at coordinates.",
                    "label": 0
                },
                {
                    "sent": "Why is 1?",
                    "label": 0
                },
                {
                    "sent": "So I get the ice coordinate of the last Lt. OK, so and then it's just the sun.",
                    "label": 0
                },
                {
                    "sent": "And then as usual, I'm interested in the regret which is defined as follows, so it's.",
                    "label": 0
                },
                {
                    "sent": "So we play the game for anytime step and I compare the cumulative loss of my strategy to the best I could have obtained if I knew in hindsight, what was the best path.",
                    "label": 0
                },
                {
                    "sent": "OK, and I would everyday choose the best path.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the usual definition of regret, and then I have an expectation because we will see we choose the path randomly.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have an expectation with respect to the strategy of the player.",
                    "label": 0
                },
                {
                    "sent": "So far that's.",
                    "label": 0
                },
                {
                    "sent": "Most of you know no.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What this is?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now I want to prove regret bounds, but I need to put some assumptions on the loss.",
                    "label": 0
                },
                {
                    "sent": "OK, just assuming that it's in Rd, it's not enough, because then the loss could blow up at certain rounds and we would not control that and we would miss a big part of the loss at those, right?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we need some assumption of an Lt.",
                    "label": 0
                },
                {
                    "sent": "I think the most natural one is the L Infinity assumption, which says that simply the loss on the streets is normalized so.",
                    "label": 0
                },
                {
                    "sent": "In an Infinity norm, the vector Lt is smaller than one OK. Now.",
                    "label": 0
                },
                {
                    "sent": "Another assumption has got a lot of attention, namely the what we call the L2 assumption.",
                    "label": 1
                },
                {
                    "sent": "So it says that the DOT product LTV for any path V is smaller than one.",
                    "label": 0
                },
                {
                    "sent": "So it means that the the total time it takes for me to go from the starting point to the end point is smaller than one.",
                    "label": 0
                },
                {
                    "sent": "OK, so in particular it means that it's independent of the size of the graph, right?",
                    "label": 0
                },
                {
                    "sent": "So it's not clear if that's such a good assumption an.",
                    "label": 0
                },
                {
                    "sent": "That the first thing and the second thing is that you intuitively you would say that you can move from L2 to L Infinity and vice versa, right?",
                    "label": 0
                },
                {
                    "sent": "That it's just a matter of normalization.",
                    "label": 0
                },
                {
                    "sent": "And I will show you that it's really not the case that.",
                    "label": 0
                },
                {
                    "sent": "There exist algorithm which are minimax optimal for L2 adversaries and which are fundamentally not minimax optimal for L Infinity adversaries.",
                    "label": 0
                },
                {
                    "sent": "You cannot just change the parameter and into work.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so before showing you this result I would like just to remind you the key idea of this type of games.",
                    "label": 0
                },
                {
                    "sent": "So the key idea is simply to take the action at random.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a probability distribution PT or the set of paths and we take Viti at random from PT.",
                    "label": 0
                },
                {
                    "sent": "Why is it such a good idea?",
                    "label": 0
                },
                {
                    "sent": "Because then we can build an unbiased estimate.",
                    "label": 1
                },
                {
                    "sent": "LTT of the true loss, Lt.",
                    "label": 1
                },
                {
                    "sent": "Even if we don't observe it, of course in the full information game we observe it, so we don't need to estimate.",
                    "label": 1
                },
                {
                    "sent": "We just set Lt. To be healthy.",
                    "label": 0
                },
                {
                    "sent": "In the semi bandit game, it's also very easy because so we observe for fixed Street I either we don't observe it and then we estimate that it's zero, or if we observe it then we will normalize by the probability of observing this street OK, so that's like in the standard bandit case.",
                    "label": 1
                },
                {
                    "sent": "Now in the bandit game, it's a little bit more complicated, so this estimator was suggested by Danny's and Caddy.",
                    "label": 0
                },
                {
                    "sent": "It's it's very easy to see that it's unbiased.",
                    "label": 0
                },
                {
                    "sent": "I don't want to enter into the detail, but just you need to know that you can build an unbiased estimate even when you just observe the cumulative loss.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Now I will move to showing you why L2 and L Infinity are not the same.",
                    "label": 0
                },
                {
                    "sent": "So we consider what we call the expanded exponentially weighted average forecaster.",
                    "label": 1
                },
                {
                    "sent": "So it's so why expanded?",
                    "label": 0
                },
                {
                    "sent": "So this formula you know, maybe as edge or exponential forecaster or whatever.",
                    "label": 0
                },
                {
                    "sent": "There are many names here.",
                    "label": 1
                },
                {
                    "sent": "It's expanded because we have this law system, so it it's almost like playing edge on the set of paths, except that we have a.",
                    "label": 0
                },
                {
                    "sent": "More clever estimate.",
                    "label": 0
                },
                {
                    "sent": "A clever estimate of the loss.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's not exactly edge on the set of paths, it's something a little bit different, but it doesn't matter that much for these slides because I will restrict my attention to the fuel information, full information case, and then it's exactly playing edge on the set of path.",
                    "label": 0
                },
                {
                    "sent": "Then in the 2008 paper down, yes and CKD showed that in social information game against L2 adversaries, you can if you tune it, ITA in a good way.",
                    "label": 1
                },
                {
                    "sent": "Then the regret is smaller than square root of DN.",
                    "label": 0
                },
                {
                    "sent": "So let me just say that in this talk we will be mostly interested by the dependency on D because the dependency on now it's it's known.",
                    "label": 0
                },
                {
                    "sent": "It's very well known that it's crowd of any in all these games.",
                    "label": 1
                },
                {
                    "sent": "OK, so now what is left to do is to catch the right dependency on the dimension.",
                    "label": 0
                },
                {
                    "sent": "OK, so they prove square root of DN and this is the optimal right?",
                    "label": 0
                },
                {
                    "sent": "So they prove also allowed bond with another two adversary which is correct again.",
                    "label": 0
                },
                {
                    "sent": "Then just by noting that if you are L Infinity, if you have L Infinity bound L Infinity bound on your adversaries and you also have a L2 bound on your adversary with an additional factor D. So there is a scaling factor of D so.",
                    "label": 0
                },
                {
                    "sent": "This bound directly implies that against her Infinity adversary, you get D to three off script event.",
                    "label": 0
                },
                {
                    "sent": "But now this is suboptimal and that was a core classy and so couldn't 1 moose and Kevin, and they proved that in fact you can get discrete event with a fundamentally different algorithm that I will present later.",
                    "label": 0
                },
                {
                    "sent": "So the question the open problem in that paper was is it intersects that you get data this real or can you improve the analysis?",
                    "label": 0
                },
                {
                    "sent": "So what we prove is that no matter what is eaten.",
                    "label": 0
                },
                {
                    "sent": "You can find a graph or a subset S of the hypercube and some L Infinity adversary so that the regret will be at least D to this real square root of N. So it's you cannot tune edge to be optimal against an Infinity adversaries in the in the linear case OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you need to do something different.",
                    "label": 0
                },
                {
                    "sent": "So what can you do?",
                    "label": 0
                },
                {
                    "sent": "Well you need.",
                    "label": 0
                },
                {
                    "sent": "We do something very different, so let me just briefly remind you which is allusion to function so you have a convex set D in Rd OK, and you take a function F which goes from from D2 R and we just assume that basically it's strictly convex and the gradient tends to Infinity on the boundary of the OK.",
                    "label": 1
                },
                {
                    "sent": "So you have D strictly convex an on the boundaries of gradient turns to Infinity.",
                    "label": 0
                },
                {
                    "sent": "That's long.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not much.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two illusion function you can associate the Bregman divergent DF, which basically for any two points U&V in Indy it represents the mistakes that you make when you do a first order Taylor approximation of F of you at the point be OK, it's just the error that you make, so it's very much related to the structure of the Asian of F.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "And now I will present you the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we have that is a simplex over S. OK, so that's the set of probability distribution overpass cake lives in some big dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Now we also have inaudi.",
                    "label": 0
                },
                {
                    "sent": "We have S so that the vertices of this pull it up and we take the convex Hull Office that this green region.",
                    "label": 0
                },
                {
                    "sent": "Then we take a super set of the convex surface, which is the.",
                    "label": 0
                },
                {
                    "sent": "So D will be a parameter of our algorithm and we take a function F. Jean Sunday.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the algorithm which we called Club.",
                    "label": 0
                },
                {
                    "sent": "By the way, is parameterized by F and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we will do the following.",
                    "label": 0
                },
                {
                    "sent": "So we are at some point PT in the simplex over S OK and I will tell you how to move from PT to PT plus one using the last estimate at time T.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first you move from PT2 from the simplex to the convex are by simply taking WT which is the expectation of PT.",
                    "label": 0
                },
                {
                    "sent": "OK so when you choose the pass at random, the expectation of that path is in the convex Hull.",
                    "label": 0
                },
                {
                    "sent": "So PT you have some.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "WT.",
                    "label": 0
                },
                {
                    "sent": "Then you do a mirror gradient decent step using the function F. OK, so you solve you find W prime T + 1 which solve the gradient of at.",
                    "label": 0
                },
                {
                    "sent": "This new point must be equal to the gradient of FWT minus the last estimate.",
                    "label": 0
                },
                {
                    "sent": "So that's where we use the last estimate.",
                    "label": 0
                },
                {
                    "sent": "To do this, mirror gradient.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decent step.",
                    "label": 0
                },
                {
                    "sent": "Then we project back using the Bregman Divergent, so OK, so we project back W Prime T + 1 in the convex Hull Office.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now we project again back on the simplex using simply we just find the probability distribution such that in expectation its expectation is TT plus one, so it's not unique.",
                    "label": 0
                },
                {
                    "sent": "It's certainly not computationally efficient in many cases, but we are really interested in the optimal regret.",
                    "label": 0
                },
                {
                    "sent": "OK, so we not in computational complexity, at least not for now.",
                    "label": 0
                },
                {
                    "sent": "So let me say that this kind of algorithm has a very long history.",
                    "label": 0
                },
                {
                    "sent": "OK, so I won't review all the other people worked with very similar algorithm.",
                    "label": 0
                },
                {
                    "sent": "For instance, many of you might be familiar with the same algorithm where F is strongly convex, for instance.",
                    "label": 0
                },
                {
                    "sent": "So here it's more general.",
                    "label": 0
                },
                {
                    "sent": "Here F is lesion.",
                    "label": 0
                },
                {
                    "sent": "And even in that more general framework, you can still prove.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Generally, regret bound which looks like this.",
                    "label": 1
                },
                {
                    "sent": "So you have one term which measure the size of S, the diameter of S viewed under the Bregman divergent associated to F, and then you have another time, which is a quadratic term, so it's a quadratic form applied to the last estimate, and the quadratic form is the inverse of the action.",
                    "label": 0
                },
                {
                    "sent": "OK, so for those of, you know that kind of bounds.",
                    "label": 0
                },
                {
                    "sent": "I think it looks familiar.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is really nice.",
                    "label": 0
                },
                {
                    "sent": "Which club is that?",
                    "label": 0
                },
                {
                    "sent": "Basically generalizes.",
                    "label": 0
                },
                {
                    "sent": "Everything so.",
                    "label": 0
                },
                {
                    "sent": "So if you take D to be the positive, autant OK an F to be the entropy function, we scaled by one over ISA, then for that kind of graph.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "That kind of graphic means that you cannot infer anything from one part to another, so it's just a multi unbanded or standard expert prediction problem.",
                    "label": 0
                },
                {
                    "sent": "So in that case if you take club with those parameters and in the full information you get edge or exponential weighted average forecasts or whatever the name you prefer in the semi bandit and Bandit framework is the same here.",
                    "label": 0
                },
                {
                    "sent": "And you get X3.",
                    "label": 0
                },
                {
                    "sent": "Now for general graph.",
                    "label": 0
                },
                {
                    "sent": "Club with those parameters we call it Linux by the way.",
                    "label": 0
                },
                {
                    "sent": "Insufficient information case.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to component edge that were presented at court last year in the semi bandit case.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to the MW algorithm which was presented, I think at NIPS.",
                    "label": 0
                },
                {
                    "sent": "And in the bandit case, it's a new algorithm which which was not published before.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so another interesting choices.",
                    "label": 0
                },
                {
                    "sent": "Again, D to be the positive autumn and now F is is like that.",
                    "label": 0
                },
                {
                    "sent": "OK so it's a sum of integral of some potential upside invest.",
                    "label": 0
                },
                {
                    "sent": "So why do we take such a complicated lesion function?",
                    "label": 0
                },
                {
                    "sent": "Because then it generalizes the algorithms that we published with joint two years ago, which is minimax optimal in the simple multi unbanded case.",
                    "label": 0
                },
                {
                    "sent": "So general case, if you take side to be exponential exponential potential, then you get Linux and if you take side to be polynomial then you get a completely new algorithm which we call link Poly which has very nice property and I will talk a little bit about.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another case is when you take D to be exactly the convex office.",
                    "label": 0
                },
                {
                    "sent": "OK, so not not a super set of S, but the convex olivette then it's exactly follows a regularised leader with regularizer F an.",
                    "label": 0
                },
                {
                    "sent": "As you probably know, one very interesting choices to take F to be a self concordant barrier function.",
                    "label": 0
                },
                {
                    "sent": "OK, then you basically get the best results that we know for the bandit case.",
                    "label": 0
                },
                {
                    "sent": "But still not optimal as I will show you so now.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When we go, we get to the the main result of our paper.",
                    "label": 0
                },
                {
                    "sent": "So let me define what we mean by being minimax regret.",
                    "label": 0
                },
                {
                    "sent": "So you take the regrets?",
                    "label": 0
                },
                {
                    "sent": "OK, now you take the supremum overall adversaries.",
                    "label": 0
                },
                {
                    "sent": "So either L, Infinity or L2.",
                    "label": 0
                },
                {
                    "sent": "You take the worst possible subset of the hypercube, so you want to guarantee that that is satisfied for any graph.",
                    "label": 0
                },
                {
                    "sent": "OK, you don't want a guarantee that depends on the structure of the graph, and now you take the best strategy with respect to that criteria.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's what we called the minimax regret for combinatorial prediction games.",
                    "label": 1
                },
                {
                    "sent": "Then we have this result so.",
                    "label": 1
                },
                {
                    "sent": "The shooting full information and semi bandit games.",
                    "label": 0
                },
                {
                    "sent": "Against L Infinity adversaries, we know exactly what is the minimax regret is discrete, often up to a constant OK?",
                    "label": 0
                },
                {
                    "sent": "In the L2 case, we know it also up to a log factor, so it's crowd of DN in the lower bound and stripped of DN log D in the upper bound.",
                    "label": 0
                },
                {
                    "sent": "So to get this Superman we needed limpley.",
                    "label": 0
                },
                {
                    "sent": "OK, so we need that the new algorithm, otherwise we couldn't get it.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "What is really nice is that it's a little bit hidden in the way I see it is that it's true for full information and semi bandit, so you remember at the beginning of the talk I was saying that.",
                    "label": 0
                },
                {
                    "sent": "It's the semi bandit signal is much weaker than the full information, and it turns out that when you look at the minimax regret, it's not that much weaker.",
                    "label": 0
                },
                {
                    "sent": "It's just a matter of a constant.",
                    "label": 0
                },
                {
                    "sent": "So it's quite surprising.",
                    "label": 1
                },
                {
                    "sent": "Now in the bandit game for an Infiniti adversaries, we have data three outskirts of N&E to the five helps code event for the upper bound, so there is a gap of D and against L2 we have disco defending the lower bound and it to the three of scrotal, and so this table.",
                    "label": 0
                },
                {
                    "sent": "So we have a gap.",
                    "label": 0
                },
                {
                    "sent": "Scope of this table.",
                    "label": 0
                },
                {
                    "sent": "So we can recover all these results with our analysis, but most of them already appeared before.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Most of them like, not all, are bound, not this upper bound, but.",
                    "label": 0
                },
                {
                    "sent": "But many of them appeared.",
                    "label": 0
                },
                {
                    "sent": "So now what is really interesting is to fill in that gap.",
                    "label": 0
                },
                {
                    "sent": "OK, so the gap in their infinite case and the square root of the gap in the L2 case.",
                    "label": 0
                },
                {
                    "sent": "So what I personally think is that for the L2 case, so it is known for their two case that for some subset South you can match the lower bound by using the paper of Gabor and Niccolo of called last year.",
                    "label": 0
                },
                {
                    "sent": "I think, where they do some kind of specific exploration S, but unfortunately what they do does not work in general.",
                    "label": 0
                },
                {
                    "sent": "In general, you can get an exponential bound, which is exponentially D. OK, and we don't know how to generalize to any set S, so I think if you have a way to do that then you will probably close the gap for the L2 adversary and then for the L Infinity adversary.",
                    "label": 0
                },
                {
                    "sent": "With that, that's my guess.",
                    "label": 0
                },
                {
                    "sent": "I guess you improve Bias quote of D and then to get the others quote of D you need to find a new lesion function F which will be.",
                    "label": 0
                },
                {
                    "sent": "I think completely different from what we know.",
                    "label": 0
                },
                {
                    "sent": "So what we know currently is either the Asian is diagonal so that we do with info or the action is non diagonal and then it's a cell phone content barrier function.",
                    "label": 0
                },
                {
                    "sent": "But somehow the self concordant barrier function seems too general to under.",
                    "label": 0
                },
                {
                    "sent": "Any said S, but that's that's basically where where we stopped at the open question, and that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Questions, so I was curious what do the as the least valuable lessons you have an do?",
                    "label": 0
                },
                {
                    "sent": "They have a very, you know, awful particular property that you could try to adapt to?",
                    "label": 0
                },
                {
                    "sent": "Not at all.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "It's not bad, bad settings, so it's basically so worst case is K sets, so you have two cases where K is a prodigy.",
                    "label": 0
                },
                {
                    "sent": "OK, so when you have to choose.",
                    "label": 0
                },
                {
                    "sent": "And you said, as you.",
                    "label": 0
                },
                {
                    "sent": "So you have bandit problem where you have D arms OK and you have to choose at every time step D. Half of those arms.",
                    "label": 0
                },
                {
                    "sent": "And what you observe is the sun.",
                    "label": 0
                },
                {
                    "sent": "That's basically the most difficult case, so it's really nothing, nothing fancy.",
                    "label": 0
                },
                {
                    "sent": "Nothing is hidden.",
                    "label": 0
                },
                {
                    "sent": "I think nothing is hidden here.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "What can you say about the computational complexity of the methods in this case?",
                    "label": 0
                },
                {
                    "sent": "So not much so.",
                    "label": 0
                },
                {
                    "sent": "In general, I think in general you can't say anything for particular sets, as you can say something so that was done actually in in the Cold Paper last year by one moussan: and keeping and so for some set S you can come up with good way to project with this Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "But in general we don't know and it might be that.",
                    "label": 0
                },
                {
                    "sent": "If you ask for computationally efficient strategy, might very well be that the table will look completely different, but that's a very difficult question.",
                    "label": 0
                },
                {
                    "sent": "Going back to the to the motivating example with routing so mean in, so you assume that you choose all path at once.",
                    "label": 0
                },
                {
                    "sent": "I mean all the path at once, whereas you know in a semi bandit feedback you could imagine you know choosing the first stage, observing the feedback and then choosing the next and so forth.",
                    "label": 0
                },
                {
                    "sent": "I was wondering, you know?",
                    "label": 0
                },
                {
                    "sent": "What do you think of this version?",
                    "label": 0
                },
                {
                    "sent": "OK, so I've seen I think it's a different version, so I think it requires.",
                    "label": 0
                },
                {
                    "sent": "Probably, maybe not a very different analysis, but at least it doesn't follows from what we did, but it's an interesting problem.",
                    "label": 0
                },
                {
                    "sent": "Last question from Jake.",
                    "label": 0
                },
                {
                    "sent": "So I have two questions I can ask both.",
                    "label": 0
                },
                {
                    "sent": "Still it's OK. OK, so the first one is you had about that was in terms of the Hessian of the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in terms of the Hessian, you take the Lt, transpose the F squared.",
                    "label": 0
                },
                {
                    "sent": "Yeah that, so that doesn't hold in general, right?",
                    "label": 0
                },
                {
                    "sent": "That fact doesn't hold in general, no.",
                    "label": 0
                },
                {
                    "sent": "So you see that the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Term, thankfully not exactly smaller than that.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Here's something easy then, so so it's like it holds for a point which is near WT maybe, but not at exactly exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "And that's where that's where the the hard stuff is.",
                    "label": 0
                },
                {
                    "sent": "In the bandit case, because that's where you need the exploration.",
                    "label": 0
                },
                {
                    "sent": "That's exactly why.",
                    "label": 0
                },
                {
                    "sent": "See if that was true, then everything will be solved.",
                    "label": 0
                },
                {
                    "sent": "OK, so the next question is I just decided before, so what's the gap?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I did notice in the red and green, yellow, red and green on that slide you OK or bread and blue.",
                    "label": 0
                },
                {
                    "sent": "Sorry alright, so so red is at Infinity adversaries, so you assume that the Infinity norm of the loss is bounded by one.",
                    "label": 0
                },
                {
                    "sent": "OK and blue is L2, so you assume that what you assumed in your paper Lt transpose V, is smaller than one.",
                    "label": 0
                },
                {
                    "sent": "That's the blue set, the blue OK that the L2.",
                    "label": 0
                },
                {
                    "sent": "So there's still a gap.",
                    "label": 0
                },
                {
                    "sent": "We still don't know between absolutely so.",
                    "label": 0
                },
                {
                    "sent": "So in code Classilla Gabba Nicole at the paperwork for.",
                    "label": 0
                },
                {
                    "sent": "Some said S. They could close the gap, but it doesn't work in general.",
                    "label": 0
                },
                {
                    "sent": "And what do you think is the I think for?",
                    "label": 0
                },
                {
                    "sent": "You know it's it's a lower bound.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's think Sebastian and.",
                    "label": 0
                }
            ]
        }
    }
}