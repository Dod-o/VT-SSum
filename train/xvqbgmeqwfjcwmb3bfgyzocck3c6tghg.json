{
    "id": "xvqbgmeqwfjcwmb3bfgyzocck3c6tghg",
    "title": "Limited-memory quasi-Newton and Hessianfree Newton methods for non-smooth optimization",
    "info": {
        "author": [
            "Mark Schmidt, Department of Computer Science, University of British Columbia"
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Optimization Methods"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_schmidt_lmq/",
    "segmentation": [
        [
            "OK, thanks Sebastian, for the introduction and thanks for invited inviting me here.",
            "I'm really honored to be among the very very prestigious list of invited speakers that he's had before.",
            "I was kind of surprised when I got the invite.",
            "And also thanks for waking up in the morning.",
            "I know that jokes don't go over very well in the morning, so I'm going to give you some words of wisdom.",
            "Chosen randomly.",
            "So let's go with a different one.",
            "So this is sponsored by the Mongolie Grill.",
            "It says you will do well to expand your horizons.",
            "So I picked a bunch of keywords.",
            "I'm going to talk about limited memory, quasi Newton methods and has seen free Newton methods for nonsmooth optimization.",
            "Tried to throw a lot in the title so that people would be inspired to wake up in the morning and possibly expand your horizons."
        ],
        [
            "So I'm going to start with just the problems that I've worked on, so Sebastian mentioned that I've done a bunch of stuff in graphical model structure and that sort of motivated my interest in sparse optimization, so I'm just going over some applications 1st, and then we'll get into some of the basics of these methods for smooth optimization, and then I'll talk about some non smooth extensions and I guess I should mention my talk is going to be a little bit biased towards the methods that I'm more familiar with, so I will mention some of the other methods.",
            "At the end."
        ],
        [
            "So the basic problem that when I started working with Kevin Murphy is we were looking at this graphical model structure learning so we can imagine we have some set of variables X1 text 9 here, and the problem that we initially looked on was these are different parts of the heart and we wanted to know, sort of if one part of one part of the heart is not moving properly, which other parts are not likely to moving properly.",
            "Also an so it's a discrete data set.",
            "They are rated by doctors on a scale of 1 to 5 and we actually want to find.",
            "But the structure is, and there's of course many, many other applications of graphical models."
        ],
        [
            "So we have these vertices and we also have these edges and we can think of each edge at least in the binary case, is having some scalar parameter and you can think of this as sort of how correlated they are.",
            "It's actually the log potential in the model, so but higher value means the variables are very correlated than a negative value means they're sort of anti correlated or negatively coral."
        ],
        [
            "I did, but we can also think of having other edges, but that aren't actually explicitly in the graph and that's in our parameterisation.",
            "That's equivalent to actually having an edge there that just has a parameter of 0, and that's where the L1 regularization."
        ],
        [
            "Comes in So what we can actually think of doing is trying to actually learn the parameters and structure at the same time by putting all the edges there and then using L1 regularization to encourage the edges to be set to 0.",
            "And that's equivalent to removing the edge from the model, so it's a very nice way to formulate this discrete structure learning problem in a continuous way."
        ],
        [
            "So that leads us to an optimization problem with this form.",
            "So F of X is going to be a smooth, twice differentiable function, and then we've got this nonsmooth L1 regularization."
        ],
        [
            "Arm.",
            "And.",
            "Thinking about solving this problem when we first worked on it many years ago, you basically run into three complicating factors.",
            "So the first is that the number of variables is very large, so it's going to be at least quadratic in the number of original variables you have.",
            "So if you want to fit this to 10s of thousands of variables, the number of variables grows quite quickly.",
            "Value in the objective function is also very expensive, so it's not really the sort of number of training examples that doesn't really influence it because it only depends on sufficient statistics so you can handle trillions of training examples no problem, you just go through it once and computer accounts, But the problem is computing the partition function that normalizes the distribution, so I'm going to assume you're either going to like send that off to the cluster and work really, really hard to commute that exactly, or you're going to send it off to the cluster and work very, very hard to make a very good approximation to it.",
            "But the approximation is still going to be smooth and satisfy the same properties that the original one would.",
            "The third complicating factor is its non smooth because of the presence of the L1."
        ],
        [
            "Term.",
            "So if the objective was smooth and we just had the first 2 problems, we might think of doing Hessian free Newton methods or limited memory quasi Newton methods.",
            "And the second part of my talk is going to sort of go over a few of those for the smooth case."
        ],
        [
            "Now we can apply those to this problem, but the regularizer there, the nonsmooth part, is actually separable, and that's the property that we're going to be able to use in the third part of my talk will look at some methods to extend those to the case of a separable regular."
        ],
        [
            "Riser.",
            "But that's not the end of the story, so L1 regularization was done by a bunch of other people.",
            "And for my problem, each of the variables actually had multiple levels.",
            "So here you can think of a graphical model where each node now has three states.",
            "So instead of just one parameter there, we now have a three by three table.",
            "So."
        ],
        [
            "Each edge is going to have more than one parameter, so now removing the edge is equivalent to setting all elements of that table to 0 or any other constant value.",
            "So that's one case where you have groups of parameters on the edges."
        ],
        [
            "Another interesting cases when you have sort of types of nodes.",
            "So here we've got XY and Z nodes."
        ],
        [
            "And you might think of edges between nodes of the same type."
        ],
        [
            "But you might also want to group edges between nodes of different types, so these might be different biological pathways and you might want to assume that some of them don't actually communicate with each other."
        ],
        [
            "And so you might learn a model like this where maybe only those sort of green edges matter, but you want block sparsity in the other types of edges."
        ],
        [
            "And then the one that we looked at was actually conditional random field.",
            "So here we actually have covariates in the model.",
            "We have features and then on each edge you actually have a tensor.",
            "And so to actually remove the edge from the model you have to set all elements of that tensor to 0."
        ],
        [
            "So in those cases, you might think of this group L1 regularization penalty.",
            "So basically we've generalized the L1 norm to penalize some P norm of disjoint groups.",
            "Obviously if the if the groups are just individual variables that you get the L1 penalty is."
        ],
        [
            "Special case typically we're going to use the L2 norm.",
            "The L Infinity norm, or in the case of matrix groups, the nuclear norm."
        ],
        [
            "So if you use the L2 norm and encourages group sparsity, you actually get that effect."
        ],
        [
            "If you get the L Infinity norm, it also encourages parameter tying within these potentials, so you're going to set a bunch of things to the same value, or at least the same magnitude.",
            "Another"
        ],
        [
            "And you can think of doing is viewing those as matrix.",
            "You can use the nuclear norm, and now we're actually encouraging this to have a low rank representation, so you get the actual log potentials by computing this outer product and then we rank one or rank two or rank three.",
            "So in models where you have maybe hundreds of states on each node, this makes a lot of sense because it's a much more efficient representation if you can approximate it by a low rank matrix."
        ],
        [
            "The problem is when you go to that, the nonsmooth term is not even separable, so it's group separable, but a lot of the tricks that work for separable functions are not going to work in that case."
        ],
        [
            "But the nonsmooth term still satisfies the property that I'm going to call being simple, and I'll define that later."
        ],
        [
            "And so the 4th part of the talk is going to look at methods for simple regularizers.",
            "Now the final graphical model application, which is very recent work is rather than just considering pairwise models where we just look at pairs of variables."
        ],
        [
            "Actually going to look at the space of hierarchical log linear models and you can use this.",
            "This idea of structured sparsity to enforce the solution of your optimization algorithms.",
            "Actually, hierarchical model and that way you can learn 3 way, four way, five way, seven way factors between the variables.",
            "And that's important for things like you know, finding out which variables are correlated with cancer because we know that usually when you develop a cancer it's not because of a problem in one gene it's a problem in two or three genes.",
            "It's multiple things after breakdown, so pairwise dependencies can't really.",
            "Capture that."
        ],
        [
            "So we can.",
            "This is our AI stats paper this year so we can solve the optimization problem that looks like that, and it's basically the same as group L1 regularization.",
            "But we now allow the groups to overlay."
        ],
        [
            "Up but now the nonsmooth term is not even going to be."
        ],
        [
            "And so it is the sum of simple functions.",
            "So at the very end of the talk, I'll just very briefly mention how we can extend the methods that I talk about that case."
        ],
        [
            "OK, so maybe let's try some more words of inspiration.",
            "Your personality is that is fueled by the fascination you feel for life.",
            "Sponsored by the Mongolian Grill."
        ],
        [
            "OK, so we're going to think about the case of a twice differentiable function F of."
        ],
        [
            "Thanks.",
            "And I'm the focus of my talk is going to be on Newton like methods.",
            "So at each iteration K we formed this function QK of X Anna stepsize Alpha.",
            "It's almost the Taylor expansion except for we've got this.",
            "We've truncated the higher order terms and we've got this step size on the quadratic part and HK is going to be some positive definite approximation of the Hessian.",
            "So the matrix of 2nd partial derivatives."
        ],
        [
            "And we're going to set our next iteration to the minimizer of this approximation so you can show that the minimizer is given by this update, where DK is the solution to that linear system."
        ],
        [
            "And under smoothness assumptions, as long as Alpha is small enough, this is going to lead to an improvement in your objective."
        ],
        [
            "Function.",
            "So this is the part of the talk where if you got them on the way and you put on your 3D glasses.",
            "If not, you're just going to visualize that these are the level curves of some function.",
            "So as we get more red, we're closer to the minimum of the function, so the minimum will be here and then the function sort of goes up in a bowl as we go out."
        ],
        [
            "So we have some iteration XK and the."
        ],
        [
            "The gradient method would just take a step on the line orthogonal to the level curve."
        ],
        [
            "And in Newton's method, we're going to be something more clever.",
            "We're going to make this Q function, which is some approximation, so I've drawn the level curves of the Q function."
        ],
        [
            "And then we're going to move to the minimizer of that Q function, and that's going to be our next."
        ],
        [
            "Ocean.",
            "So to choose the stepsize Alpha, there's a bunch of variety of ways to do it, but right now I'm just going to concentrate on something called the Army oh condition, which is proposed by army oh in the 60s and it just says we just want to make a little bit more improvement than having dissent based on what the current gradient is.",
            "The reason I'm focusing on this condition is generalizes a little bit more nicely to the non smooth case than other."
        ],
        [
            "Now some people see a line search and they get a little scared because it looks a bit complicated.",
            "But if you use Hermite interpolation to both initialize Alpha and to choose your sequence of decreasing values and you have a little bit of control on the spectrum of your Hessian approximation, usually going to accept the initial Alpha, or you might have to backtrack only once or maybe twice so it's called align search, but it's not really very precise and usually don't have to evaluate many step sizes."
        ],
        [
            "So if you make suitable assumptions on smoothness an strong convexity, the method gets."
        ],
        [
            "Quadratic convergence rate.",
            "So you have a dependency on the error that looks something like that, and you can find I'm hiding a little bit of details, but you can find that in Boyd and Vandenberghe or other standard references."
        ],
        [
            "Another interesting result is the dentist more a characterization of superlinear convergence, and it says that if you have any algorithm of this four man, you're in the, you're going to a strict local minimizer.",
            "It has a super linear convergence rate if and only if you're testing approximation eventually behaves like the Newton direction.",
            "Now this is sort of.",
            "This is saying in some sense One Direction of this is saying something weaker, 'cause if this has quadratic convergence, well, super linear convergence is not as strong condition.",
            "But this is if and only if.",
            "So if you walk around nips, you see a lot of posters where people say they have efficient algorithms, and that's fine.",
            "We don't really have a precise definition of that, but if you think about the reverse implication, this is saying that if your algorithm can be written in this form and it doesn't start behaving like Newton's method as you approach the minimizer that you can't.",
            "Actually, you're not actually converging super linearly.",
            "So it's sort of like Newton is the only game in town when you're looking at iterations like this."
        ],
        [
            "Yes.",
            "But of course the disadvantages of Newtons method are well known.",
            "Often you can't compute the Hessian or you can't even store and end by end matrix.",
            "So for our problems we have a huge number of variables we want to avoid that."
        ],
        [
            "But there's a lot of limited memory methods available, so I put a list here of things you might consider in different methods work better on different problems, But for my problems I found that these last two methods sort of worked the best, and those are the Hessian Free Newton methods in the limited memory quasi Newton methods.",
            "So my talks mainly going to focus on these two, although I will mention those two quite a few times and then the first 2 there's smarter people than me in the room who can talk about them."
        ],
        [
            "OK, so has seen free Newton methods we want to implement this step, which is basically the main cost is often solving that linear system."
        ],
        [
            "So Henry Newton methods.",
            "The idea is very simple.",
            "Instead of applying a direct solver to this system, we're going to use an iterative solver, and usually we use."
        ],
        [
            "You get gradient.",
            "That's sort of the standard choice, but later in the talk I'll talk about how you can actually have other choices to do that."
        ],
        [
            "The nice thing about conjugate gradient and other things I'll talk about, is that they're only going to need testing vector products to compute the system so they don't.",
            "They don't need the Hessian explicitly, you just need to be able to do multiplication by."
        ],
        [
            "Fashion and we can usually do that multiplication without actually explicitly computing."
        ],
        [
            "And so sometimes this is because you're hashing has some structure.",
            "So if you do anything in the exponential family is going to have a structure like that.",
            "So you just multiply by A and then D and then a transpose.",
            "So often you can do that efficiently."
        ],
        [
            "Or you can think about doing a numerical approximation using finite differences."
        ],
        [
            "Or you can be a little bit clever if you have some weak assumptions about F and then you can actually compute the Hessian vector product without any cancellation error by using a very small complex mu, and that's by this formula.",
            "So basically you compute your gradient with a complex input so you have your current editor it, and you do a very, very small complex perturbation, so mu is usually 1 E to the minus 150 or something in this so very small.",
            "The real part gives you the gradient and the imaginary part gives you.",
            "The Hessian vector product and then since mu is either the minus 150 mu squared is going to be very small, so it's a very very precise thing."
        ],
        [
            "Now when you're not near the minimizer, there's no real need to solve that very accurately.",
            "So the question.",
            "So you might need to get a residual and the question is what properties do that residual have to have to get?"
        ],
        [
            "Convergence rate and this nice paper by Demo Eisenstadt and style from almost 30 years ago, and I guess Styles PhD thesis."
        ],
        [
            "Even earlier gives you sort of exactly the conditions you need to satisfy, or at least these are sufficient conditions.",
            "So if you want linear convergence, you just need the normal residual to be slightly less than the gradient.",
            "If you want super linear convergence, that needs to go to zero, and for quadratic convergence you need to be less than the gradient norm of the gradient squared."
        ],
        [
            "So for example, if you want super linear convergence, typically you would just set a decay to that simple formula and that works quite well in practice."
        ],
        [
            "So just a few notes on this, so you can often drastically reduce the number of conjugate gradients by preconditioning."
        ],
        [
            "You could also modify the conjugate gradient to still give you a descent direction even when you're testing isn't positive DEF."
        ],
        [
            "At.",
            "And a really nice thing about this is you can also sometimes use it to detect the direction of negative curvature, so this is the direction along which if you go there you're actually decreasing faster as you move along it.",
            "And the idea is if you can find a direction like that, that's the direction that you should definitely go along 'cause the function is going to start decreasing very quickly, and usually you do some sort of fancy line search.",
            "If you can find a direction like that."
        ],
        [
            "So to start with, no saddle and right is a good place, but this is covered in a lot of textbooks on nonlinear optim."
        ],
        [
            "Station.",
            "So now I'm going to want to quasi Newton methods, but first I'll just sort of very simply hide."
        ],
        [
            "The difference between them so has seen free Newton methods as I just talked about approximately inverse."
        ],
        [
            "Fashion and quasi Newton methods are going to invert an approximate Hessian, and that's the main difference."
        ],
        [
            "So qualitative methods always work with these parameters SK and YK.",
            "The difference in Paramus."
        ],
        [
            "In gradients, and we're going to choose some initial approximation H. 0, so usually it's a scaled version of the identity matrix, and then after we take our iteration, we're going to update our approximation so it sort of acts like the Hessian would on the previous iteration."
        ],
        [
            "Now that isn't really a unique formula.",
            "Using a matrix to interpolate two vectors, so one of the most popular ways to choose a new unique matrix is with the."
        ],
        [
            "FGS method Now if you're not strongly convex you can do some tricks like update, skipping or dapping, or you can use a more sophisticated line search just to make sure."
        ],
        [
            "It stays positive definite.",
            "And the BF's method does satisfy those.",
            "Dennis that Dennis Morey conditions.",
            "So it has super linear convergence rate."
        ],
        [
            "But it still uses a dense approximation."
        ],
        [
            "So instead of storing that the limited memory BF's actually just stores those vectors S&Y."
        ],
        [
            "And then there's a recursive update from 30 years ago that shows how you can apply that S&Y updates to H zero in linear time."
        ],
        [
            "And I know some people think have said that they don't use this algorithm, 'cause it's very complicated.",
            "So I just wrote this up the other day in Matlab from the paper from 1980.",
            "So it's two for loop.",
            "So if you can implement like belief propagation, you can implement LBF.",
            "So I don't think that's a good excuse.",
            "'cause lots of people use but."
        ],
        [
            "Propagation.",
            "So one important point is that the choice that initial scaling matrix is actually really crucial, so the performance of LBF's."
        ],
        [
            "The market is crashing.",
            "OK so one of the most common choices is this.",
            "This step here, which I'm suggested calling Alpha BB.",
            "So basically this is we're solving that quasi Newton interpolation condition with the diagonal Hessian at least square sense, and that has a nice formula."
        ],
        [
            "Now I showed the demo Eisenstadt style and the convergence theory for Hessian Free Newton methods is very nice.",
            "It's not as nice for LBF, so we don't have a super linear convergence, but often it actually works a lot better than many other methods available, at least on."
        ],
        [
            "Some problems.",
            "Now we can also consider an absolutely degenerate approximate quasi Newton method where we just take that scaling.",
            "That seems to work quite well.",
            "That was proposed."
        ],
        [
            "In the 70s, but it's become very popular lately under the name of the bars Lion Borwin method."
        ],
        [
            "And typically, you're going to choose if that step size does.",
            "You're going to choose the Alpha to satisfy this thing called the non monotonic armillo condition and the idea there is that we've replaced F of XK with the Max over a bunch of previous iterations, so that's still going to give us convergence, but it's going to try and accept that Alpha BB step more often, 'cause it usually gives good perform."
        ],
        [
            "Prince and it's a really simple method and it's just a minor modification of steepest descent, but it's become really popular lately, 'cause it works really well empirically.",
            "There was a paper in the Pacific Journal optimization I think last month that showed that under certain conditions that if that Alpha BB step converges to a constant, you'll actually satisfy the dentist.",
            "Morey conditions and have superlinear convergence, but I don't know how if that convergence tuacahn."
        ],
        [
            "It actually happens in real life, so, but it does work very well.",
            "So before I move on to nonsmooth, I just want to say that you can actually combine these two ideas of Ellefson Hessian Free Newton."
        ],
        [
            "Kids, so one of the ways is, well, you want if you want a precondition.",
            "The conjugate gradient methods, you want something that acts like the inverse Hessian, and that's sort of exactly what the LB FS is trying to do.",
            "So one thing you can do is you can use your LBF's as a preconditioner in your Hessian.",
            "Free Newton methods and that you can usually drastically reduce the number of iterations uni."
        ],
        [
            "It.",
            "And then another thing later on, by the same authors is well.",
            "We said that LFC vary depending on this choice of age 0 and you can actually use conjugate gradient iterations to try and make that approximate the inverse Hessian.",
            "So basically the same idea, but we've flipped the role of the Hessian Free Newton and Quasi Newton."
        ],
        [
            "OK, so a bit more words of inspiration.",
            "You deserve to have a good time after a hard day's work, alright?",
            "Skybreak right?"
        ],
        [
            "OK, so we're going to go back to the nonsmooth problem, this L1 regularization problem.",
            "So I'm just going to think of generic case where L of X is sort of a well behaved, twice differentiable function, strongly convex if you want, But the algorithms will still work if it's not an, then we have the L one term."
        ],
        [
            "Now, the nonsmooth regularizer is going to break the quasi Newton Hessian Free Newton methods, so you can't really apply it directly, because."
        ],
        [
            "It's not differentiable everywhere, but the regularizer is."
        ],
        [
            "Separable, so we're going to look at two ways to take advantage of that, so one is a really classic method called 2 metric projection that we're going to play on a different But equivalent problem, and then we're going to try and take the ideas, learn there, imply that back to our."
        ],
        [
            "No problem, so we can write rewrite this objective in this form.",
            "So basically we've doubled the number of variables we've divided each variable into a variable X plus and X minus that are constrained to be non negative.",
            "So our original objective is here, and then we replace the L1 norm by this term, and if that's feasible, then this is going to be upper bound on the L1 norm and then at at minimizer the bound is going to be tight."
        ],
        [
            "So they have the same solutions.",
            "And once you do that transformation, you can think about applying methods for bound constrained optimization of smooth fun."
        ],
        [
            "Oceans.",
            "So a classic algorithm that goes back to the 60s is the gradient projection, and so basically for non negative constraints you take your gradient step and then you just apply this plus function which means if a variable is negative you set it to zero and then you can use the army oh condition and you get convergence."
        ],
        [
            "And stuff, so let's we're just going to."
        ],
        [
            "Quick cartoon of that.",
            "So we have our function.",
            "These are the axes."
        ],
        [
            "And we have a feasible set.",
            "We're saying we only want to look at parameter vectors that are non negative."
        ],
        [
            "So we have our iteration XK."
        ],
        [
            "We take our gradient step."
        ],
        [
            "And then we find the closest point in the set that satisfies the constraints, which in this case just corresponds to setting negative variables."
        ],
        [
            "Zero, and then we're going to search along that direction."
        ],
        [
            "So we might want to try and speed speed this up with a Newton like step so you can naively I guess, think of just plugging the Newton step into that plus function."
        ],
        [
            "And this is called A2 metric projection algorithm.",
            "For slightly subtle reasons, and that's 'cause you can view the Newton step as steepest descent into non Euclidean norm.",
            "And then you compute the projection under the Euclidean norm.",
            "So the norms actually don't match."
        ],
        [
            "Because those norms don't match.",
            "This method actually doesn't work, so it may not be possible to actually improve on the objective function with this method."
        ],
        [
            "And so I designed this very carefully to give a counterexample.",
            "So."
        ],
        [
            "We put down our Q function in Newtons."
        ],
        [
            "Should we move to the minimizer of the Q function?"
        ],
        [
            "And then we compute the project."
        ],
        [
            "Action and that gives us this step.",
            "So the direction we want to go is this way that the minimizer is somewhere here, but the projected Newton step is actually telling us to move in the exact opposite direction that we want to."
        ],
        [
            "So.",
            "But you can actually guarantee descent if you just put a few further restrictions on what you're passing approximation looks."
        ],
        [
            "Like so.",
            "One thing is you can make your head spin approximation a diagonal matrix and that's quite popular."
        ],
        [
            "Or you can use that Barzilai Borwein step and your non monotonic armillo condition.",
            "So this was proposed 10 years ago and Figueiredo Ale and one of the authors of the organizers of the workshop proposed this for L1 minimization a few years."
        ],
        [
            "Go.",
            "But do we really need HK to be diagonal?",
            "That seems like a pretty strong."
        ],
        [
            "Asian.",
            "So the work by Gaffney and Bertsekas, and I've cited this paper, but there's a few more says that you actually have to make the Hessian partially diagonal, and if you make it partially diagonal with respect to an appropriate set of variables that sufficient to guarantee descent.",
            "So basically we find the variables that are either close that are both close to 0 and that have a positive derivative, so these are the variables that want to become negative and we're going to make the Hessian diagonal with respect."
        ],
        [
            "Are those variables?",
            "So we have part of our hashing is diagonal with respect to these variables that are close to 0.",
            "Want to become zero?",
            "Then here we can actually do whatever we want.",
            "We can put some positive definite matrix there."
        ],
        [
            "And so we're going to use that.",
            "Make that H bar approximate the sub Hessian."
        ],
        [
            "So we can write the joint step in this form.",
            "So for these variables that want to become zero, we're going to do a diagonally scaled projected step and then for the variables the other variables we can actually do that to metric projection step."
        ],
        [
            "Now it's very easy to think about doing a Hessian free Newton method.",
            "We just apply conjugate gradient to solve this system now, and that might be very very efficient because when you're not near minimizer and you don't know the sparsity pattern, well, we don't need to solve it very accurately to get a convergence rate.",
            "But when you are, do the minimizer, and if it's sparse, that's going to be a very small linear system, so this might be fast all the way."
        ],
        [
            "True.",
            "And you can also think about doing LBF's methods where you just replace H bar with LBF.",
            "So I know a lot of you have used my code for this and that's basically what it does."
        ],
        [
            "Or the that's what the one on the web does.",
            "So I really kind of like this because as soon as you find the correct set of nonzero variables, you're basically applying Newton's method on those variables.",
            "So it's quite a nice extension to the."
        ],
        [
            "Remove bound constraints.",
            "But the question is, should we really have converted to a bound constraint problem in the 1st place?",
            "Because that doubles the number of variables, but it also more subtly, it might make the problem harder.",
            "So if you can imagine your original L of X is a strongly convex function, when you go to this twice, twice the number of variables thing that will not be strongly convex.",
            "That always has an indefinite has."
        ],
        [
            "And so the question is, can we apply the tricks that I just showed for bound constrained optimization?",
            "Sort of directly to L1 regularization problems?"
        ],
        [
            "And we're going to do that using non smooth generalization of steepest descent."
        ],
        [
            "That was our motivating problem.",
            "And if F of X is convex, even though it's not differentiable everywhere, you always have subgradients and."
        ],
        [
            "Optional derivatives.",
            "So I'm going to use Edk to note the minimum norm subgradient.",
            "So this is the element of the subdifferential that has minimum Norman.",
            "I'll show exactly what that is for this problem in a second."
        ],
        [
            "But the reason we're interested in that is the direction that minimizes the directional derivative is just going to be the negative of that."
        ],
        [
            "Value.",
            "So this you can think of this is steepest descent for nonsmooth convex."
        ],
        [
            "Optimization problem, so for our problem because that regularizer is separable, you can just solve that in closed form and has a very nice solution so.",
            "If you're non 0, so it's differentiable, it's just basically the derivative, you just take the sign as the derivative.",
            "If you're 0 and your derivative is small, it might say just stay at zero.",
            "That's the minimum norm subgradient.",
            "But if your zero in the derivative is bigger than Lambda, then it says you should go away from zero and it gives you exact."
        ],
        [
            "The direction so you can think of this as the steepest descent direction for L1 regularization problems, and I've motivated from the perspective of convexity.",
            "But you can start talking about things like generalized gradient."
        ],
        [
            "And drive the same thing so you can think about doing a non smooth steepest descent step.",
            "So we just replace the gradient by the minimum norm."
        ],
        [
            "Subgradient and then you can think of doing the army oh condition to get a sufficient decrease.",
            "And there's some minor issues there that I will briefly mention later.",
            "So some of you might already know why that might not be a good idea, but for now we're just going to say well can we do a Newton version of that step so where we just replace the gradient with the minimum subgradient in the Newton equation?"
        ],
        [
            "But there's actually 2 pretty big problems with that step, so one is we actually want sparse solutions, and this really doesn't have any way to set things to exactly 0, and also similar to the bound constraint case.",
            "This is not going to guarantee descent, even if our hashing approx."
        ],
        [
            "Nation is positive definite, so for the first problem I'm going to use a trick that a lot of other people use, which is called orthant projection, and the idea is when you're going to take your step and if something changes sign, you just set it to exactly 0, so that's effective at sparsifying the solution, but there's also a more subtle advantage to it, and it's going to restrict your quadratic approximation to a sort of a region where your power series."
        ],
        [
            "Makes sense, so here's my character of what the L1 function might look like, so we're given orthant.",
            "This is going to be a smooth function, but when we switch over or or, things were going to discontinuity there."
        ],
        [
            "So we have some iteration."
        ],
        [
            "And then we picked the orthant that contains the iteration."
        ],
        [
            "Then we put down our Q function, so within the orthant, the Q function actually makes sense, but once you go to another orthant, the Q function is just kind of ridiculous.",
            "It doesn't make any sense, because you know Taylor's theorem doesn't work past the."
        ],
        [
            "Non differentiable point.",
            "So you can think of moving to the minimizer of that quadratic approximation."
        ],
        [
            "But then we're going to compute the project."
        ],
        [
            "Onto the earth and we're going to search along this piecewise linear projection path, so you notice if the step size is big enough, it actually sets this thing to exactly 0, but it also means that we sort of stay in this region where are quadratic approximation actually makes sense."
        ],
        [
            "So that was the first issue.",
            "The second issue is how do we get?"
        ],
        [
            "Cheetah sent well as before.",
            "We can use the diagonal scaling and that will be."
        ],
        [
            "Fine or we can use the bars Libor in step and again those actually give you big improvements over sort of."
        ],
        [
            "Simple methods.",
            "But inspired by that, Gaffney and Bootsy kiss paper, we can also think about making our hassian partially diagonal with respect to some appropriate set of variables.",
            "And here I'm there is more clever things you can read about if you want to look at my thesis, but I'm just going to think of the most basic case where we say if you're close to zero, you have to be diagonal with respect to those."
        ],
        [
            "Variables, so this is going to lead to something that I'm going to call it 2 metrics subgradient projection.",
            "So the variables that are close to zero, we take our diagonally scaled steepest descent projected onto the orthant.",
            "For the other variables, we're going to project the Newton step, and I've actually written gradient here because these are the variables that are away from zero, so we're actually differentiable with respect to them, and a Newton step actually makes sense."
        ],
        [
            "So as before you can derive Hessian free Newton methods or LBF."
        ],
        [
            "Yes, versions, not unlike the too much projection for bound constrained optimization.",
            "The choice of decay actually has a pretty big influence on the problem.",
            "So one possibility you can do here is that bars Libor one step."
        ],
        [
            "So the method has a bunch of sort of.",
            "It has a lot of the properties you would want of an L1 minimization one, but the one I'm going to emphasize is that once you identify the set of nonzero variables, it's basically like you're applying Newton's method to those variables, so you don't have to.",
            "Actually, you don't have to think about like switching between two methods once you've identified the sparsity pattern here, as soon as you have the sparsity pattern, you're going to be doing Newtons method."
        ],
        [
            "Now, if you want to solve really, really big problems that are really sparse, there's two other issues that you need to think about, and I'm not really going to talk about them, so one is usually you get better performance if you start with a large value of Lambda and you successively decrease it to the value you want.",
            "We don't really have great results on how to actually choose those Lambda, although there is some work and the other is sub optimization where you can sort of temporarily ignore variables that you don't think you're going to move away from zero, so you can either do that temporarily or.",
            "A talk later in the day will talk about doing that."
        ],
        [
            "Permanently.",
            "You can extend that basic algorithm to a much more general class of problems, so we have a smooth function, possibly with bound constraints on the variable, and justice separable regularizer that's differentiable almost everywhere, and two metric projection algorithms also exist for other types of constraints.",
            "So I know this mirror descent algorithm is very popular for optimization over the simplex, but Gaffney and Burzik is also have a two metric projection that's quite competitive for that problem too."
        ],
        [
            "Now, of course, this isn't completely original method.",
            "There's lots of other good ideas for L1 regularization methods in the literature, so these are some of the most closely related ones.",
            "Well, I've sort of argued that you get a descent for sure with this step.",
            "There are some theoretical problems with this type of method, so it's not.",
            "We don't actually have a fully rigorous proof that this type of method is globally convergent, so some of you might have saw me come up to your poster and kind of annoy you.",
            "Like does this algorithm actually converge because we don't know that these type of subgradient methods converge.",
            "One thing you can do is you can use a decreasing sequence of step sizes to force convergence, but that sort of kills your convergence rate.",
            "The other thing is.",
            "Assuming that issue can be addressed or we can modify the algorithm to address that, there's also showing that in a finite number of iterations that it actually identifies the optimal sparsity pattern."
        ],
        [
            "OK, so.",
            "You have good luck in your personal affairs.",
            "Very nice.",
            "OK, so now we're going to go to a problem that's maybe not as excessively study as the L."
        ],
        [
            "One problem which is the group L1 problem.",
            "So I'm just going to focus on the case of the two norm of the group, so we can think of this as doing L1 regularization of the lengths of the vectors.",
            "So when the length of the vector goes to zero, it's equivalent to setting that to the zero vector.",
            "And here we're going to."
        ],
        [
            "Zoom disjoint groups so the regularizer is not separable, so we can't apply the algorithm.",
            "I've just talked about."
        ],
        [
            "But the regularizer is still simple in."
        ],
        [
            "Since I'll define quickly and I'm going to talk about two methods that actually take advantage of this, so we're going to talk about inexact projected Newton methods on an equivalent problem, and then like before going to think about using those tricks from the converting it to constrain problem to solve it directly."
        ],
        [
            "So there's sort of two standard ways to convert this to a constraint problem, so one is we introduce these extra variables T. They're going to be upper bounds on the norm, so these are second order cone constraints, and then you just minimize a linear function.",
            "So that's going to be an upper bound on the function when it's feasible, and the other way is to just do optimization over this weighted group L."
        ],
        [
            "Two norm ball and in both cases the constraints are simple and by that I mean you can compute the projection in linear time.",
            "So for this one the constraints are just a Cartesian product of norm cones and you can look up the exercise in the textbook or the bottom one.",
            "We showed a few years ago that you can compute that in linear time with a randomized algorithm."
        ],
        [
            "So the basic projected gradient step is we take our gradient step.",
            "This guy and then we're going to find the closest point.",
            "The projection that satisfies the constraints, and I'll quickly."
        ],
        [
            "Show a cartoon of that, so we have a function we have our feasible set and some iterate."
        ],
        [
            "And and like before, we take the green, which is the gradient step that we find the closest point in the step, and that gets sort of gives us the direction to search along."
        ],
        [
            "So to speed convergence, you might think you can plug in the Newton step, but I guess I've running theme."
        ],
        [
            "This top is that doesn't work."
        ],
        [
            "So in projected Newton methods, which goes back to this very, very nice paper by Levitin Polyak, I've only read the English translation, but it's it's very well written.",
            "You could you could.",
            "You can read this like tomorrow and it would still seem like it's like an up-to-date optimization paper.",
            "the English translation only read.",
            "So basically, instead of doing this Newton step and projecting under the Euclidean norm, we project under a norm that's going to be defined by our Hessian approximation.",
            "So this quadratic norm."
        ],
        [
            "And that's actually going to give us descent, so we can rewrite this problem as minimizing RQ function that we had before subject to the constraint that we stay in the convex set."
        ],
        [
            "The problem is in general this projection is going to be expensive, so even if you can compute the Euclidean projection efficiently, you probably won't be able to compute this projection.",
            "There are some cases, like if you make H diagonal, you might be able to solve that for some problems in the group L1 you can solve."
        ],
        [
            "But the thing with this talk is using non diagonal Hessian approximations.",
            "So we're going to consider something called an inexact project."
        ],
        [
            "Newton method.",
            "This is going to be sort of a constrained analogue of Hessian free Newton methods, so instead of solving that minimizing Q function, sort of exactly, we're going to think about using an iteratee."
        ],
        [
            "Solver to do that, and you know, there's there's many possible choices, but I'm going to think about using the SPG iterations.",
            "So basically we take a projected gradient step on the Q function and project that under the Euclidean norm, and we're going to use that to minimize the quadratic."
        ],
        [
            "Proximation and this is quite nice, because these SPG iterations, they only require projection under the Euclidean norm.",
            "You don't have to project under that Hessian norm, and they only need testing vector products to evaluate the objective function and gradient.",
            "So as we discussed before, for our problem, we can efficiently compute Euclidean projections.",
            "We can also efficiently compute Hessian vector products, or at least for not any more expensive."
        ],
        [
            "In the gradient calculation, so a quick cartoon of that so."
        ],
        [
            "Same picture we lay down our queue function as we did."
        ],
        [
            "For now, you can think of maybe starting with the projected gradient step, but then you're."
        ],
        [
            "Going to iterate."
        ],
        [
            "And you're going to try and find the minimizer over the convex set of your queue function.",
            "That also gives you a direction along which you can search."
        ],
        [
            "So a natural question you might ask is we saw the demo Eisenstadt style result on sort of that you don't actually have to solve the problem accurately.",
            "I'm not going to give a full care."
        ],
        [
            "Risation because I don't think that work has been done yet that I'm aware of, but it's very easy to show the following property that if you set if you initialize your constraint solver with your previous iteration, then as long as you run that SPG iteration for at least one line search, then you can guarantee that you improve on the objective function for Alpha small.",
            "Or you can just set out for the one and then set decay to that, and that's going to give you a feasible descent direction.",
            "So it's going to satisfy the constraints and give you this."
        ],
        [
            "Now the paper that Sebastian mentioned at the beginning we did last year, so we basically did the same thing, but we did an LBF's approximation within that.",
            "So you can think."
        ],
        [
            "As a hybrid method, so in this case the approximate Hessian vector product just involves running that LB FS24 loop things so we can do that in linear time.",
            "And the thing I really like about this, at least for my problems, is that the SPG iterations they're going to use the Euclidean projection.",
            "That's fine, 'cause our constraints are simple.",
            "We can compute that quickly, but those SPG iterations don't need to touch the objective function, so we're not actually doing the Hessian vector product.",
            "We don't need to do inference in our graphical model, so that's very very nice, at least for my problems.",
            "And I think that for other problems this is also quite nice.",
            "I think it's very nice if you have a costly objective function and simple constraints.",
            "That's sort of different, like the standard optimization paradigm.",
            "'cause if you think about like quadratic programming, the objective is sort of cheap, but the projection is going to be very, very expensive, so this is like the opposite scenario."
        ],
        [
            "So.",
            "To do that, we converted to a constraint problem as we did before, and so like we did before, just in my last few minutes here, we're going to talk about can we apply those ideas directly to solve the nonsmooth?"
        ],
        [
            "And we can do that using proximal operators.",
            "So remember the projection is just minimizing this subject to satisfying the constraints.",
            "Now we're not going to have constraints, but we're going to put our regularizer directly into that projection, like function, and you get projection as a special case where our of X is the indicator function on the convex."
        ],
        [
            "Set.",
            "I said the group L1 regularizer is simple and that we can solve this proximal operator in linear time so the proximal operator ends up being separable with respect to the groups.",
            "So we get this problem with respect to each group and you get this solution which is a generalization of the soft thresholding operator and this signal function is.",
            "You can view our old paper, but it's a generalization of the complex modulus to grow."
        ],
        [
            "Apps.",
            "So the basic proximal gradient step is a lot like the approximal or projected gradient step basically looks like that."
        ],
        [
            "And then you can plug in your Newton step.",
            "But as you might guess, that actually doesn't work."
        ],
        [
            "So what you can actually do is you can match the norms and that gives you descent.",
            "So we match our HK norm in the Newton step to the norm.",
            "We compute the proximal operator under so that you can think of this as like a generalized type of."
        ],
        [
            "Proximal step and now you can show that the proximal step under that norm is equivalent to minimizing RQ function plus our regularizer times the stepsize Alpha."
        ],
        [
            "And as before, the problem is that problem is usually going to be expensive, even if your regularizer is."
        ],
        [
            "Simple so you can think about doing a diagonal scaling or bars Libor winsteps and that was those two papers last year."
        ],
        [
            "Or you can think about doing a non diagonal scaling by salt, minimize solving this minimization problem with an iterative solver.",
            "So in my thesis we looked at using this iterative solver to solve this problem and it has a few nice properties so it only needs Euclidean proximal operators and Hessian vector products.",
            "You're guaranteed descent as long as you run it for at least one iteration.",
            "And if you use an LBF's approximation, that's going to be something that's quite nice for optimizing costly objectives that have simple regularizers."
        ],
        [
            "So I've considered on the two norm.",
            "You can extend these ideas to the case of the L Infinity norm or the nuclear norm.",
            "I talked with the start so L Infinity norm.",
            "It's basically you have to solve a sorting problem or a median finding a problem for the nuclear norm.",
            "You just need to find the largest singular values to compute the projection or the proximal operator.",
            "Now the convergence theory for these inexact methods is not fully developed, and we don't quite know how accurately we need to solve that problem to guarantee sort of nice properties.",
            "But that is an area of that I'm hoping to fix in the next month."
        ],
        [
            "With the help of some people in the audience here.",
            "OK, so before I wrap up, I just want to mention a few other topics."
        ],
        [
            "So in the very beginning I mentioned this overlapping Group One problem that arises from the structured sparsity approach."
        ],
        [
            "So now the regularizer is not even simple because our groups overlap."
        ],
        [
            "But it is the sum of simple regularizers, so if we take the same step as before."
        ],
        [
            "To constraint problem you're going to do something called Dijkstra's algorithm to compute the projection.",
            "Dexter is kind of nice because we know it actually has a geometric convergence rate, at least for some sets.",
            "Now for this set, it doesn't have it, but if you do the Infinity norm of the group then you get that geometric convergence rate."
        ],
        [
            "And more recently, there was this paper by Bashian combat combats that generalize Dexter's algorithm to compute proximal operators of the sum of simple functions.",
            "So that you can directly apply within that quasi Newton Approximal method."
        ],
        [
            "Now in the past year, there's been a lot of people interested in this structured sparsity, so we've seen a bunch of methods for specifically that case, and I just wanted to mention them because some of them are actually quite good."
        ],
        [
            "Now, in the case where your regularizer is not even simple or where you may have an even more complicated nonsmooth type of thing, there's a few options available for Nonsmooth Newton like methods.",
            "So one is, you can try incorporate the subdifferential sort of directly into your Q function.",
            "You can also think of smoothing and then a really promising recent approaches.",
            "These augmented Lagrangian dual augmented Lagrangian, and I think those can really take advantage of the structure of the problem in.",
            "Many cases."
        ],
        [
            "So I just want to briefly mention that, so I've sort of assume you have a deterministic approximation, But you can think about doing a Monte Carlo objective function, or you might be using mini batches when you think about conditional random fields.",
            "So there is some work on stochastic variance, so there's this paper looks at convergence proofs for LBF's and there was an ICM wallpaper on Hessian free Newton methods and then some work that a master student in our lab Kevin Swersky, did on something called an optimal bars Libor and for the stochastic case, but.",
            "Never got written up, but a problem with these is they don't actually share the fast convergence rates you get with the deterministic variants of the algorithm."
        ],
        [
            "So before I conclude, I just want to thank my coauthors, my.",
            "So first and foremost is a what Vandenberg who we did.",
            "The exact projected Newton stuff with and he's now a postdoc at Stanford with Emmanuel Candes, my PhD supervisor Kevin Murphy, and my current supervisor, Michael Friedlander, Glen Fung, and Romer, who gave me the heart application.",
            "I talked about the beginning and Surete and Dongmin, who we wrote up some of the stuff in this talk for the book that's coming out next year that Sebastian will prob."
        ],
        [
            "I plug later today so this is sort of the take home message, so if this is the one slide, if you just want the high level view of that, Oxo has seen freedom methods and limited memory briefs or two of the workhorses of 1 constraint."
        ],
        [
            "Optimization to metric subgradient projection methods.",
            "Let us apply these methods to problems where we have bound constraints or non differentiable but separable regularizers."
        ],
        [
            "And then in exact projected and proxamol new methods are an appealing approach.",
            "When you have a very costly objective function, but you have simple constraints and or a simple non differential regularizer.",
            "So I'll conclude by saying that this talk roughly followed chapters one to three of my thesis.",
            "So if you want to.",
            "Find out what the ending is.",
            "You can grab that off my web page.",
            "We have sufficient time for questions questions.",
            "Thanks for very nice talk, I'm just wondering about the limitations of the fault implies managers.",
            "And offsetting those generally applied to L1, but presumably they are applicable to anything where the discontinuity's in the derivatives are actually at the axis, right?",
            "And so I just wanted, is that true?",
            "Well, you have to be a little bit careful.",
            "OK, so I did mention that you can generalize so you can actually apply them if your regularizer is separable and differentiable almost everywhere.",
            "So you can have many, many discontinuities, and they can be whatever you want, but they need to be on like a set of measure 0.",
            "You can't have like a non differentiable region or something, so you can apply them in that problem.",
            "But of course if there's a whole bunch of non differential abilities than the Earth is going to slow you down as you sort of try and plow through these things so.",
            "But you can apply this things like this CAD penalty and a bunch of other things.",
            "Do the city opens then get as we look at this more complicated regularise.",
            "Well, the orphans are obviously.",
            "I mean so.",
            "So maybe Orthon is not the right view.",
            "So because we're really only thinking about 1 dimensional here, so it's really only as complicated as complicated as you have one discontinuity is along one along individual coordinates, so it doesn't get much more complicated all.",
            "And if you, I don't think we've put the chapter we wrote for the book up, but we actually do show the formula for the general case.",
            "In the book chapter.",
            "In general disease, a result in improvement for your original motivation for hardware.",
            "Did they actually clear house out in the result?",
            "Map of clinical informations.",
            "Well, this is just a different way to solve the optimization problem, so you get the same result, you just get it in like an hour instead of like a week.",
            "So clinical interpretation is not influenced except for the whole attempt.",
            "Depends if you're paying for computational costs or not.",
            "Questions we have time.",
            "Possible method?",
            "I was even able to implement it, but lines of code.",
            "In your case, it seems that you have a lot of.",
            "Parameters in the.",
            "Exact problems in the middle.",
            "So how easy is it to do it again?",
            "You will fuck one week without.",
            "Obviously it's not that hard, so the inner iteration is still the proximal method, so the inner iteration is going to be exactly the same except for your just.",
            "You can take your existing code and you plug it into another code that feeds it, an objective function that tells you what you're asking.",
            "Approximation is so if you can implement the proximal method in a few hours and then you copy those two for loops I showed earlier, then that's basically it.",
            "Actually no wait, so for for the exact method you can actually use those two for loops you have to use a paper by berdale on how to represent the quasi 'cause you need multiplication by the Hessian and not the inverse Hessian.",
            "But it's just a low rank representation of the matrix.",
            "Or you can just download the code off my web page.",
            "So in fact we had this off one question along those lines.",
            "Link back to the old days of L2 regularization.",
            "I just downloaded the LGS color brilliantly.",
            "Is there similar code as well?",
            "But I am sort of applying for a Markov random field type problem.",
            "Detail.",
            "So I have a MATLAB implementation of.",
            "Most of these methods on my webpage and the ones that aren't will be up in the next.",
            "When I have time.",
            "And so basically for that it's kind of like the LBF's code you feed it function that gives it that returns the function value in the gradient.",
            "So that can be whatever you want and then you give it the values of the L1, the value of the L1 norm on each variable and then it just runs.",
            "So you need one extra input to run these methods in a code.",
            "But it is Matlab where I've just sort of mixed the LB FS.",
            "Those two for loops to make it a little bit faster.",
            "And yeah, actually if you go to my web page, I have like a list of like 20 different demos of showing how to apply it to like Gaussian graphical models and logistic regression and conditional random fields and compressed sensing and all that other stuff.",
            "So it's very very.",
            "I've tried to make it very much plug and play.",
            "Let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thanks Sebastian, for the introduction and thanks for invited inviting me here.",
                    "label": 0
                },
                {
                    "sent": "I'm really honored to be among the very very prestigious list of invited speakers that he's had before.",
                    "label": 0
                },
                {
                    "sent": "I was kind of surprised when I got the invite.",
                    "label": 0
                },
                {
                    "sent": "And also thanks for waking up in the morning.",
                    "label": 0
                },
                {
                    "sent": "I know that jokes don't go over very well in the morning, so I'm going to give you some words of wisdom.",
                    "label": 0
                },
                {
                    "sent": "Chosen randomly.",
                    "label": 0
                },
                {
                    "sent": "So let's go with a different one.",
                    "label": 0
                },
                {
                    "sent": "So this is sponsored by the Mongolie Grill.",
                    "label": 0
                },
                {
                    "sent": "It says you will do well to expand your horizons.",
                    "label": 0
                },
                {
                    "sent": "So I picked a bunch of keywords.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about limited memory, quasi Newton methods and has seen free Newton methods for nonsmooth optimization.",
                    "label": 1
                },
                {
                    "sent": "Tried to throw a lot in the title so that people would be inspired to wake up in the morning and possibly expand your horizons.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to start with just the problems that I've worked on, so Sebastian mentioned that I've done a bunch of stuff in graphical model structure and that sort of motivated my interest in sparse optimization, so I'm just going over some applications 1st, and then we'll get into some of the basics of these methods for smooth optimization, and then I'll talk about some non smooth extensions and I guess I should mention my talk is going to be a little bit biased towards the methods that I'm more familiar with, so I will mention some of the other methods.",
                    "label": 0
                },
                {
                    "sent": "At the end.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the basic problem that when I started working with Kevin Murphy is we were looking at this graphical model structure learning so we can imagine we have some set of variables X1 text 9 here, and the problem that we initially looked on was these are different parts of the heart and we wanted to know, sort of if one part of one part of the heart is not moving properly, which other parts are not likely to moving properly.",
                    "label": 1
                },
                {
                    "sent": "Also an so it's a discrete data set.",
                    "label": 0
                },
                {
                    "sent": "They are rated by doctors on a scale of 1 to 5 and we actually want to find.",
                    "label": 0
                },
                {
                    "sent": "But the structure is, and there's of course many, many other applications of graphical models.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have these vertices and we also have these edges and we can think of each edge at least in the binary case, is having some scalar parameter and you can think of this as sort of how correlated they are.",
                    "label": 0
                },
                {
                    "sent": "It's actually the log potential in the model, so but higher value means the variables are very correlated than a negative value means they're sort of anti correlated or negatively coral.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I did, but we can also think of having other edges, but that aren't actually explicitly in the graph and that's in our parameterisation.",
                    "label": 0
                },
                {
                    "sent": "That's equivalent to actually having an edge there that just has a parameter of 0, and that's where the L1 regularization.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comes in So what we can actually think of doing is trying to actually learn the parameters and structure at the same time by putting all the edges there and then using L1 regularization to encourage the edges to be set to 0.",
                    "label": 0
                },
                {
                    "sent": "And that's equivalent to removing the edge from the model, so it's a very nice way to formulate this discrete structure learning problem in a continuous way.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that leads us to an optimization problem with this form.",
                    "label": 0
                },
                {
                    "sent": "So F of X is going to be a smooth, twice differentiable function, and then we've got this nonsmooth L1 regularization.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Arm.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Thinking about solving this problem when we first worked on it many years ago, you basically run into three complicating factors.",
                    "label": 0
                },
                {
                    "sent": "So the first is that the number of variables is very large, so it's going to be at least quadratic in the number of original variables you have.",
                    "label": 0
                },
                {
                    "sent": "So if you want to fit this to 10s of thousands of variables, the number of variables grows quite quickly.",
                    "label": 0
                },
                {
                    "sent": "Value in the objective function is also very expensive, so it's not really the sort of number of training examples that doesn't really influence it because it only depends on sufficient statistics so you can handle trillions of training examples no problem, you just go through it once and computer accounts, But the problem is computing the partition function that normalizes the distribution, so I'm going to assume you're either going to like send that off to the cluster and work really, really hard to commute that exactly, or you're going to send it off to the cluster and work very, very hard to make a very good approximation to it.",
                    "label": 0
                },
                {
                    "sent": "But the approximation is still going to be smooth and satisfy the same properties that the original one would.",
                    "label": 0
                },
                {
                    "sent": "The third complicating factor is its non smooth because of the presence of the L1.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Term.",
                    "label": 0
                },
                {
                    "sent": "So if the objective was smooth and we just had the first 2 problems, we might think of doing Hessian free Newton methods or limited memory quasi Newton methods.",
                    "label": 0
                },
                {
                    "sent": "And the second part of my talk is going to sort of go over a few of those for the smooth case.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we can apply those to this problem, but the regularizer there, the nonsmooth part, is actually separable, and that's the property that we're going to be able to use in the third part of my talk will look at some methods to extend those to the case of a separable regular.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Riser.",
                    "label": 0
                },
                {
                    "sent": "But that's not the end of the story, so L1 regularization was done by a bunch of other people.",
                    "label": 0
                },
                {
                    "sent": "And for my problem, each of the variables actually had multiple levels.",
                    "label": 0
                },
                {
                    "sent": "So here you can think of a graphical model where each node now has three states.",
                    "label": 0
                },
                {
                    "sent": "So instead of just one parameter there, we now have a three by three table.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each edge is going to have more than one parameter, so now removing the edge is equivalent to setting all elements of that table to 0 or any other constant value.",
                    "label": 0
                },
                {
                    "sent": "So that's one case where you have groups of parameters on the edges.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another interesting cases when you have sort of types of nodes.",
                    "label": 0
                },
                {
                    "sent": "So here we've got XY and Z nodes.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you might think of edges between nodes of the same type.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you might also want to group edges between nodes of different types, so these might be different biological pathways and you might want to assume that some of them don't actually communicate with each other.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you might learn a model like this where maybe only those sort of green edges matter, but you want block sparsity in the other types of edges.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the one that we looked at was actually conditional random field.",
                    "label": 0
                },
                {
                    "sent": "So here we actually have covariates in the model.",
                    "label": 0
                },
                {
                    "sent": "We have features and then on each edge you actually have a tensor.",
                    "label": 0
                },
                {
                    "sent": "And so to actually remove the edge from the model you have to set all elements of that tensor to 0.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in those cases, you might think of this group L1 regularization penalty.",
                    "label": 0
                },
                {
                    "sent": "So basically we've generalized the L1 norm to penalize some P norm of disjoint groups.",
                    "label": 0
                },
                {
                    "sent": "Obviously if the if the groups are just individual variables that you get the L1 penalty is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Special case typically we're going to use the L2 norm.",
                    "label": 0
                },
                {
                    "sent": "The L Infinity norm, or in the case of matrix groups, the nuclear norm.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you use the L2 norm and encourages group sparsity, you actually get that effect.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you get the L Infinity norm, it also encourages parameter tying within these potentials, so you're going to set a bunch of things to the same value, or at least the same magnitude.",
                    "label": 0
                },
                {
                    "sent": "Another",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can think of doing is viewing those as matrix.",
                    "label": 0
                },
                {
                    "sent": "You can use the nuclear norm, and now we're actually encouraging this to have a low rank representation, so you get the actual log potentials by computing this outer product and then we rank one or rank two or rank three.",
                    "label": 0
                },
                {
                    "sent": "So in models where you have maybe hundreds of states on each node, this makes a lot of sense because it's a much more efficient representation if you can approximate it by a low rank matrix.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is when you go to that, the nonsmooth term is not even separable, so it's group separable, but a lot of the tricks that work for separable functions are not going to work in that case.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the nonsmooth term still satisfies the property that I'm going to call being simple, and I'll define that later.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the 4th part of the talk is going to look at methods for simple regularizers.",
                    "label": 0
                },
                {
                    "sent": "Now the final graphical model application, which is very recent work is rather than just considering pairwise models where we just look at pairs of variables.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually going to look at the space of hierarchical log linear models and you can use this.",
                    "label": 0
                },
                {
                    "sent": "This idea of structured sparsity to enforce the solution of your optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "Actually, hierarchical model and that way you can learn 3 way, four way, five way, seven way factors between the variables.",
                    "label": 0
                },
                {
                    "sent": "And that's important for things like you know, finding out which variables are correlated with cancer because we know that usually when you develop a cancer it's not because of a problem in one gene it's a problem in two or three genes.",
                    "label": 0
                },
                {
                    "sent": "It's multiple things after breakdown, so pairwise dependencies can't really.",
                    "label": 0
                },
                {
                    "sent": "Capture that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can.",
                    "label": 0
                },
                {
                    "sent": "This is our AI stats paper this year so we can solve the optimization problem that looks like that, and it's basically the same as group L1 regularization.",
                    "label": 0
                },
                {
                    "sent": "But we now allow the groups to overlay.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up but now the nonsmooth term is not even going to be.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so it is the sum of simple functions.",
                    "label": 0
                },
                {
                    "sent": "So at the very end of the talk, I'll just very briefly mention how we can extend the methods that I talk about that case.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so maybe let's try some more words of inspiration.",
                    "label": 0
                },
                {
                    "sent": "Your personality is that is fueled by the fascination you feel for life.",
                    "label": 0
                },
                {
                    "sent": "Sponsored by the Mongolian Grill.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we're going to think about the case of a twice differentiable function F of.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "And I'm the focus of my talk is going to be on Newton like methods.",
                    "label": 0
                },
                {
                    "sent": "So at each iteration K we formed this function QK of X Anna stepsize Alpha.",
                    "label": 0
                },
                {
                    "sent": "It's almost the Taylor expansion except for we've got this.",
                    "label": 0
                },
                {
                    "sent": "We've truncated the higher order terms and we've got this step size on the quadratic part and HK is going to be some positive definite approximation of the Hessian.",
                    "label": 1
                },
                {
                    "sent": "So the matrix of 2nd partial derivatives.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we're going to set our next iteration to the minimizer of this approximation so you can show that the minimizer is given by this update, where DK is the solution to that linear system.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And under smoothness assumptions, as long as Alpha is small enough, this is going to lead to an improvement in your objective.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "So this is the part of the talk where if you got them on the way and you put on your 3D glasses.",
                    "label": 0
                },
                {
                    "sent": "If not, you're just going to visualize that these are the level curves of some function.",
                    "label": 0
                },
                {
                    "sent": "So as we get more red, we're closer to the minimum of the function, so the minimum will be here and then the function sort of goes up in a bowl as we go out.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have some iteration XK and the.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The gradient method would just take a step on the line orthogonal to the level curve.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in Newton's method, we're going to be something more clever.",
                    "label": 0
                },
                {
                    "sent": "We're going to make this Q function, which is some approximation, so I've drawn the level curves of the Q function.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we're going to move to the minimizer of that Q function, and that's going to be our next.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ocean.",
                    "label": 0
                },
                {
                    "sent": "So to choose the stepsize Alpha, there's a bunch of variety of ways to do it, but right now I'm just going to concentrate on something called the Army oh condition, which is proposed by army oh in the 60s and it just says we just want to make a little bit more improvement than having dissent based on what the current gradient is.",
                    "label": 0
                },
                {
                    "sent": "The reason I'm focusing on this condition is generalizes a little bit more nicely to the non smooth case than other.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now some people see a line search and they get a little scared because it looks a bit complicated.",
                    "label": 0
                },
                {
                    "sent": "But if you use Hermite interpolation to both initialize Alpha and to choose your sequence of decreasing values and you have a little bit of control on the spectrum of your Hessian approximation, usually going to accept the initial Alpha, or you might have to backtrack only once or maybe twice so it's called align search, but it's not really very precise and usually don't have to evaluate many step sizes.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you make suitable assumptions on smoothness an strong convexity, the method gets.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quadratic convergence rate.",
                    "label": 0
                },
                {
                    "sent": "So you have a dependency on the error that looks something like that, and you can find I'm hiding a little bit of details, but you can find that in Boyd and Vandenberghe or other standard references.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another interesting result is the dentist more a characterization of superlinear convergence, and it says that if you have any algorithm of this four man, you're in the, you're going to a strict local minimizer.",
                    "label": 1
                },
                {
                    "sent": "It has a super linear convergence rate if and only if you're testing approximation eventually behaves like the Newton direction.",
                    "label": 1
                },
                {
                    "sent": "Now this is sort of.",
                    "label": 0
                },
                {
                    "sent": "This is saying in some sense One Direction of this is saying something weaker, 'cause if this has quadratic convergence, well, super linear convergence is not as strong condition.",
                    "label": 0
                },
                {
                    "sent": "But this is if and only if.",
                    "label": 0
                },
                {
                    "sent": "So if you walk around nips, you see a lot of posters where people say they have efficient algorithms, and that's fine.",
                    "label": 0
                },
                {
                    "sent": "We don't really have a precise definition of that, but if you think about the reverse implication, this is saying that if your algorithm can be written in this form and it doesn't start behaving like Newton's method as you approach the minimizer that you can't.",
                    "label": 0
                },
                {
                    "sent": "Actually, you're not actually converging super linearly.",
                    "label": 0
                },
                {
                    "sent": "So it's sort of like Newton is the only game in town when you're looking at iterations like this.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "But of course the disadvantages of Newtons method are well known.",
                    "label": 0
                },
                {
                    "sent": "Often you can't compute the Hessian or you can't even store and end by end matrix.",
                    "label": 1
                },
                {
                    "sent": "So for our problems we have a huge number of variables we want to avoid that.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there's a lot of limited memory methods available, so I put a list here of things you might consider in different methods work better on different problems, But for my problems I found that these last two methods sort of worked the best, and those are the Hessian Free Newton methods in the limited memory quasi Newton methods.",
                    "label": 0
                },
                {
                    "sent": "So my talks mainly going to focus on these two, although I will mention those two quite a few times and then the first 2 there's smarter people than me in the room who can talk about them.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so has seen free Newton methods we want to implement this step, which is basically the main cost is often solving that linear system.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Henry Newton methods.",
                    "label": 0
                },
                {
                    "sent": "The idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "Instead of applying a direct solver to this system, we're going to use an iterative solver, and usually we use.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You get gradient.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the standard choice, but later in the talk I'll talk about how you can actually have other choices to do that.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The nice thing about conjugate gradient and other things I'll talk about, is that they're only going to need testing vector products to compute the system so they don't.",
                    "label": 0
                },
                {
                    "sent": "They don't need the Hessian explicitly, you just need to be able to do multiplication by.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fashion and we can usually do that multiplication without actually explicitly computing.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so sometimes this is because you're hashing has some structure.",
                    "label": 0
                },
                {
                    "sent": "So if you do anything in the exponential family is going to have a structure like that.",
                    "label": 0
                },
                {
                    "sent": "So you just multiply by A and then D and then a transpose.",
                    "label": 0
                },
                {
                    "sent": "So often you can do that efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or you can think about doing a numerical approximation using finite differences.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or you can be a little bit clever if you have some weak assumptions about F and then you can actually compute the Hessian vector product without any cancellation error by using a very small complex mu, and that's by this formula.",
                    "label": 1
                },
                {
                    "sent": "So basically you compute your gradient with a complex input so you have your current editor it, and you do a very, very small complex perturbation, so mu is usually 1 E to the minus 150 or something in this so very small.",
                    "label": 0
                },
                {
                    "sent": "The real part gives you the gradient and the imaginary part gives you.",
                    "label": 0
                },
                {
                    "sent": "The Hessian vector product and then since mu is either the minus 150 mu squared is going to be very small, so it's a very very precise thing.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now when you're not near the minimizer, there's no real need to solve that very accurately.",
                    "label": 0
                },
                {
                    "sent": "So the question.",
                    "label": 0
                },
                {
                    "sent": "So you might need to get a residual and the question is what properties do that residual have to have to get?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convergence rate and this nice paper by Demo Eisenstadt and style from almost 30 years ago, and I guess Styles PhD thesis.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Even earlier gives you sort of exactly the conditions you need to satisfy, or at least these are sufficient conditions.",
                    "label": 0
                },
                {
                    "sent": "So if you want linear convergence, you just need the normal residual to be slightly less than the gradient.",
                    "label": 0
                },
                {
                    "sent": "If you want super linear convergence, that needs to go to zero, and for quadratic convergence you need to be less than the gradient norm of the gradient squared.",
                    "label": 1
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, if you want super linear convergence, typically you would just set a decay to that simple formula and that works quite well in practice.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just a few notes on this, so you can often drastically reduce the number of conjugate gradients by preconditioning.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You could also modify the conjugate gradient to still give you a descent direction even when you're testing isn't positive DEF.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "And a really nice thing about this is you can also sometimes use it to detect the direction of negative curvature, so this is the direction along which if you go there you're actually decreasing faster as you move along it.",
                    "label": 1
                },
                {
                    "sent": "And the idea is if you can find a direction like that, that's the direction that you should definitely go along 'cause the function is going to start decreasing very quickly, and usually you do some sort of fancy line search.",
                    "label": 1
                },
                {
                    "sent": "If you can find a direction like that.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to start with, no saddle and right is a good place, but this is covered in a lot of textbooks on nonlinear optim.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to want to quasi Newton methods, but first I'll just sort of very simply hide.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The difference between them so has seen free Newton methods as I just talked about approximately inverse.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fashion and quasi Newton methods are going to invert an approximate Hessian, and that's the main difference.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So qualitative methods always work with these parameters SK and YK.",
                    "label": 0
                },
                {
                    "sent": "The difference in Paramus.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In gradients, and we're going to choose some initial approximation H. 0, so usually it's a scaled version of the identity matrix, and then after we take our iteration, we're going to update our approximation so it sort of acts like the Hessian would on the previous iteration.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now that isn't really a unique formula.",
                    "label": 0
                },
                {
                    "sent": "Using a matrix to interpolate two vectors, so one of the most popular ways to choose a new unique matrix is with the.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "FGS method Now if you're not strongly convex you can do some tricks like update, skipping or dapping, or you can use a more sophisticated line search just to make sure.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It stays positive definite.",
                    "label": 0
                },
                {
                    "sent": "And the BF's method does satisfy those.",
                    "label": 0
                },
                {
                    "sent": "Dennis that Dennis Morey conditions.",
                    "label": 0
                },
                {
                    "sent": "So it has super linear convergence rate.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it still uses a dense approximation.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So instead of storing that the limited memory BF's actually just stores those vectors S&Y.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then there's a recursive update from 30 years ago that shows how you can apply that S&Y updates to H zero in linear time.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I know some people think have said that they don't use this algorithm, 'cause it's very complicated.",
                    "label": 0
                },
                {
                    "sent": "So I just wrote this up the other day in Matlab from the paper from 1980.",
                    "label": 0
                },
                {
                    "sent": "So it's two for loop.",
                    "label": 0
                },
                {
                    "sent": "So if you can implement like belief propagation, you can implement LBF.",
                    "label": 0
                },
                {
                    "sent": "So I don't think that's a good excuse.",
                    "label": 0
                },
                {
                    "sent": "'cause lots of people use but.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Propagation.",
                    "label": 0
                },
                {
                    "sent": "So one important point is that the choice that initial scaling matrix is actually really crucial, so the performance of LBF's.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The market is crashing.",
                    "label": 0
                },
                {
                    "sent": "OK so one of the most common choices is this.",
                    "label": 0
                },
                {
                    "sent": "This step here, which I'm suggested calling Alpha BB.",
                    "label": 0
                },
                {
                    "sent": "So basically this is we're solving that quasi Newton interpolation condition with the diagonal Hessian at least square sense, and that has a nice formula.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I showed the demo Eisenstadt style and the convergence theory for Hessian Free Newton methods is very nice.",
                    "label": 0
                },
                {
                    "sent": "It's not as nice for LBF, so we don't have a super linear convergence, but often it actually works a lot better than many other methods available, at least on.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some problems.",
                    "label": 0
                },
                {
                    "sent": "Now we can also consider an absolutely degenerate approximate quasi Newton method where we just take that scaling.",
                    "label": 0
                },
                {
                    "sent": "That seems to work quite well.",
                    "label": 0
                },
                {
                    "sent": "That was proposed.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the 70s, but it's become very popular lately under the name of the bars Lion Borwin method.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And typically, you're going to choose if that step size does.",
                    "label": 0
                },
                {
                    "sent": "You're going to choose the Alpha to satisfy this thing called the non monotonic armillo condition and the idea there is that we've replaced F of XK with the Max over a bunch of previous iterations, so that's still going to give us convergence, but it's going to try and accept that Alpha BB step more often, 'cause it usually gives good perform.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prince and it's a really simple method and it's just a minor modification of steepest descent, but it's become really popular lately, 'cause it works really well empirically.",
                    "label": 0
                },
                {
                    "sent": "There was a paper in the Pacific Journal optimization I think last month that showed that under certain conditions that if that Alpha BB step converges to a constant, you'll actually satisfy the dentist.",
                    "label": 0
                },
                {
                    "sent": "Morey conditions and have superlinear convergence, but I don't know how if that convergence tuacahn.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It actually happens in real life, so, but it does work very well.",
                    "label": 0
                },
                {
                    "sent": "So before I move on to nonsmooth, I just want to say that you can actually combine these two ideas of Ellefson Hessian Free Newton.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kids, so one of the ways is, well, you want if you want a precondition.",
                    "label": 0
                },
                {
                    "sent": "The conjugate gradient methods, you want something that acts like the inverse Hessian, and that's sort of exactly what the LB FS is trying to do.",
                    "label": 0
                },
                {
                    "sent": "So one thing you can do is you can use your LBF's as a preconditioner in your Hessian.",
                    "label": 0
                },
                {
                    "sent": "Free Newton methods and that you can usually drastically reduce the number of iterations uni.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "And then another thing later on, by the same authors is well.",
                    "label": 0
                },
                {
                    "sent": "We said that LFC vary depending on this choice of age 0 and you can actually use conjugate gradient iterations to try and make that approximate the inverse Hessian.",
                    "label": 1
                },
                {
                    "sent": "So basically the same idea, but we've flipped the role of the Hessian Free Newton and Quasi Newton.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so a bit more words of inspiration.",
                    "label": 0
                },
                {
                    "sent": "You deserve to have a good time after a hard day's work, alright?",
                    "label": 0
                },
                {
                    "sent": "Skybreak right?",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we're going to go back to the nonsmooth problem, this L1 regularization problem.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to think of generic case where L of X is sort of a well behaved, twice differentiable function, strongly convex if you want, But the algorithms will still work if it's not an, then we have the L one term.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, the nonsmooth regularizer is going to break the quasi Newton Hessian Free Newton methods, so you can't really apply it directly, because.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not differentiable everywhere, but the regularizer is.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Separable, so we're going to look at two ways to take advantage of that, so one is a really classic method called 2 metric projection that we're going to play on a different But equivalent problem, and then we're going to try and take the ideas, learn there, imply that back to our.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No problem, so we can write rewrite this objective in this form.",
                    "label": 0
                },
                {
                    "sent": "So basically we've doubled the number of variables we've divided each variable into a variable X plus and X minus that are constrained to be non negative.",
                    "label": 0
                },
                {
                    "sent": "So our original objective is here, and then we replace the L1 norm by this term, and if that's feasible, then this is going to be upper bound on the L1 norm and then at at minimizer the bound is going to be tight.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So they have the same solutions.",
                    "label": 0
                },
                {
                    "sent": "And once you do that transformation, you can think about applying methods for bound constrained optimization of smooth fun.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oceans.",
                    "label": 0
                },
                {
                    "sent": "So a classic algorithm that goes back to the 60s is the gradient projection, and so basically for non negative constraints you take your gradient step and then you just apply this plus function which means if a variable is negative you set it to zero and then you can use the army oh condition and you get convergence.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And stuff, so let's we're just going to.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quick cartoon of that.",
                    "label": 0
                },
                {
                    "sent": "So we have our function.",
                    "label": 0
                },
                {
                    "sent": "These are the axes.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have a feasible set.",
                    "label": 0
                },
                {
                    "sent": "We're saying we only want to look at parameter vectors that are non negative.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have our iteration XK.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We take our gradient step.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we find the closest point in the set that satisfies the constraints, which in this case just corresponds to setting negative variables.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zero, and then we're going to search along that direction.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we might want to try and speed speed this up with a Newton like step so you can naively I guess, think of just plugging the Newton step into that plus function.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is called A2 metric projection algorithm.",
                    "label": 0
                },
                {
                    "sent": "For slightly subtle reasons, and that's 'cause you can view the Newton step as steepest descent into non Euclidean norm.",
                    "label": 0
                },
                {
                    "sent": "And then you compute the projection under the Euclidean norm.",
                    "label": 0
                },
                {
                    "sent": "So the norms actually don't match.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because those norms don't match.",
                    "label": 0
                },
                {
                    "sent": "This method actually doesn't work, so it may not be possible to actually improve on the objective function with this method.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I designed this very carefully to give a counterexample.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We put down our Q function in Newtons.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should we move to the minimizer of the Q function?",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we compute the project.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action and that gives us this step.",
                    "label": 0
                },
                {
                    "sent": "So the direction we want to go is this way that the minimizer is somewhere here, but the projected Newton step is actually telling us to move in the exact opposite direction that we want to.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But you can actually guarantee descent if you just put a few further restrictions on what you're passing approximation looks.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like so.",
                    "label": 0
                },
                {
                    "sent": "One thing is you can make your head spin approximation a diagonal matrix and that's quite popular.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or you can use that Barzilai Borwein step and your non monotonic armillo condition.",
                    "label": 0
                },
                {
                    "sent": "So this was proposed 10 years ago and Figueiredo Ale and one of the authors of the organizers of the workshop proposed this for L1 minimization a few years.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go.",
                    "label": 0
                },
                {
                    "sent": "But do we really need HK to be diagonal?",
                    "label": 1
                },
                {
                    "sent": "That seems like a pretty strong.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asian.",
                    "label": 0
                },
                {
                    "sent": "So the work by Gaffney and Bertsekas, and I've cited this paper, but there's a few more says that you actually have to make the Hessian partially diagonal, and if you make it partially diagonal with respect to an appropriate set of variables that sufficient to guarantee descent.",
                    "label": 1
                },
                {
                    "sent": "So basically we find the variables that are either close that are both close to 0 and that have a positive derivative, so these are the variables that want to become negative and we're going to make the Hessian diagonal with respect.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are those variables?",
                    "label": 0
                },
                {
                    "sent": "So we have part of our hashing is diagonal with respect to these variables that are close to 0.",
                    "label": 1
                },
                {
                    "sent": "Want to become zero?",
                    "label": 1
                },
                {
                    "sent": "Then here we can actually do whatever we want.",
                    "label": 0
                },
                {
                    "sent": "We can put some positive definite matrix there.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we're going to use that.",
                    "label": 0
                },
                {
                    "sent": "Make that H bar approximate the sub Hessian.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can write the joint step in this form.",
                    "label": 0
                },
                {
                    "sent": "So for these variables that want to become zero, we're going to do a diagonally scaled projected step and then for the variables the other variables we can actually do that to metric projection step.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it's very easy to think about doing a Hessian free Newton method.",
                    "label": 0
                },
                {
                    "sent": "We just apply conjugate gradient to solve this system now, and that might be very very efficient because when you're not near minimizer and you don't know the sparsity pattern, well, we don't need to solve it very accurately to get a convergence rate.",
                    "label": 1
                },
                {
                    "sent": "But when you are, do the minimizer, and if it's sparse, that's going to be a very small linear system, so this might be fast all the way.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "True.",
                    "label": 0
                },
                {
                    "sent": "And you can also think about doing LBF's methods where you just replace H bar with LBF.",
                    "label": 0
                },
                {
                    "sent": "So I know a lot of you have used my code for this and that's basically what it does.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or the that's what the one on the web does.",
                    "label": 1
                },
                {
                    "sent": "So I really kind of like this because as soon as you find the correct set of nonzero variables, you're basically applying Newton's method on those variables.",
                    "label": 1
                },
                {
                    "sent": "So it's quite a nice extension to the.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Remove bound constraints.",
                    "label": 0
                },
                {
                    "sent": "But the question is, should we really have converted to a bound constraint problem in the 1st place?",
                    "label": 1
                },
                {
                    "sent": "Because that doubles the number of variables, but it also more subtly, it might make the problem harder.",
                    "label": 0
                },
                {
                    "sent": "So if you can imagine your original L of X is a strongly convex function, when you go to this twice, twice the number of variables thing that will not be strongly convex.",
                    "label": 0
                },
                {
                    "sent": "That always has an indefinite has.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the question is, can we apply the tricks that I just showed for bound constrained optimization?",
                    "label": 0
                },
                {
                    "sent": "Sort of directly to L1 regularization problems?",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we're going to do that using non smooth generalization of steepest descent.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That was our motivating problem.",
                    "label": 0
                },
                {
                    "sent": "And if F of X is convex, even though it's not differentiable everywhere, you always have subgradients and.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optional derivatives.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to use Edk to note the minimum norm subgradient.",
                    "label": 0
                },
                {
                    "sent": "So this is the element of the subdifferential that has minimum Norman.",
                    "label": 0
                },
                {
                    "sent": "I'll show exactly what that is for this problem in a second.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the reason we're interested in that is the direction that minimizes the directional derivative is just going to be the negative of that.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Value.",
                    "label": 0
                },
                {
                    "sent": "So this you can think of this is steepest descent for nonsmooth convex.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optimization problem, so for our problem because that regularizer is separable, you can just solve that in closed form and has a very nice solution so.",
                    "label": 1
                },
                {
                    "sent": "If you're non 0, so it's differentiable, it's just basically the derivative, you just take the sign as the derivative.",
                    "label": 0
                },
                {
                    "sent": "If you're 0 and your derivative is small, it might say just stay at zero.",
                    "label": 0
                },
                {
                    "sent": "That's the minimum norm subgradient.",
                    "label": 0
                },
                {
                    "sent": "But if your zero in the derivative is bigger than Lambda, then it says you should go away from zero and it gives you exact.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The direction so you can think of this as the steepest descent direction for L1 regularization problems, and I've motivated from the perspective of convexity.",
                    "label": 0
                },
                {
                    "sent": "But you can start talking about things like generalized gradient.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And drive the same thing so you can think about doing a non smooth steepest descent step.",
                    "label": 0
                },
                {
                    "sent": "So we just replace the gradient by the minimum norm.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subgradient and then you can think of doing the army oh condition to get a sufficient decrease.",
                    "label": 0
                },
                {
                    "sent": "And there's some minor issues there that I will briefly mention later.",
                    "label": 0
                },
                {
                    "sent": "So some of you might already know why that might not be a good idea, but for now we're just going to say well can we do a Newton version of that step so where we just replace the gradient with the minimum subgradient in the Newton equation?",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there's actually 2 pretty big problems with that step, so one is we actually want sparse solutions, and this really doesn't have any way to set things to exactly 0, and also similar to the bound constraint case.",
                    "label": 0
                },
                {
                    "sent": "This is not going to guarantee descent, even if our hashing approx.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation is positive definite, so for the first problem I'm going to use a trick that a lot of other people use, which is called orthant projection, and the idea is when you're going to take your step and if something changes sign, you just set it to exactly 0, so that's effective at sparsifying the solution, but there's also a more subtle advantage to it, and it's going to restrict your quadratic approximation to a sort of a region where your power series.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Makes sense, so here's my character of what the L1 function might look like, so we're given orthant.",
                    "label": 0
                },
                {
                    "sent": "This is going to be a smooth function, but when we switch over or or, things were going to discontinuity there.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have some iteration.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we picked the orthant that contains the iteration.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we put down our Q function, so within the orthant, the Q function actually makes sense, but once you go to another orthant, the Q function is just kind of ridiculous.",
                    "label": 0
                },
                {
                    "sent": "It doesn't make any sense, because you know Taylor's theorem doesn't work past the.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Non differentiable point.",
                    "label": 0
                },
                {
                    "sent": "So you can think of moving to the minimizer of that quadratic approximation.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then we're going to compute the project.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Onto the earth and we're going to search along this piecewise linear projection path, so you notice if the step size is big enough, it actually sets this thing to exactly 0, but it also means that we sort of stay in this region where are quadratic approximation actually makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was the first issue.",
                    "label": 0
                },
                {
                    "sent": "The second issue is how do we get?",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cheetah sent well as before.",
                    "label": 0
                },
                {
                    "sent": "We can use the diagonal scaling and that will be.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fine or we can use the bars Libor in step and again those actually give you big improvements over sort of.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simple methods.",
                    "label": 0
                },
                {
                    "sent": "But inspired by that, Gaffney and Bootsy kiss paper, we can also think about making our hassian partially diagonal with respect to some appropriate set of variables.",
                    "label": 0
                },
                {
                    "sent": "And here I'm there is more clever things you can read about if you want to look at my thesis, but I'm just going to think of the most basic case where we say if you're close to zero, you have to be diagonal with respect to those.",
                    "label": 1
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variables, so this is going to lead to something that I'm going to call it 2 metrics subgradient projection.",
                    "label": 0
                },
                {
                    "sent": "So the variables that are close to zero, we take our diagonally scaled steepest descent projected onto the orthant.",
                    "label": 0
                },
                {
                    "sent": "For the other variables, we're going to project the Newton step, and I've actually written gradient here because these are the variables that are away from zero, so we're actually differentiable with respect to them, and a Newton step actually makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as before you can derive Hessian free Newton methods or LBF.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, versions, not unlike the too much projection for bound constrained optimization.",
                    "label": 0
                },
                {
                    "sent": "The choice of decay actually has a pretty big influence on the problem.",
                    "label": 0
                },
                {
                    "sent": "So one possibility you can do here is that bars Libor one step.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the method has a bunch of sort of.",
                    "label": 1
                },
                {
                    "sent": "It has a lot of the properties you would want of an L1 minimization one, but the one I'm going to emphasize is that once you identify the set of nonzero variables, it's basically like you're applying Newton's method to those variables, so you don't have to.",
                    "label": 1
                },
                {
                    "sent": "Actually, you don't have to think about like switching between two methods once you've identified the sparsity pattern here, as soon as you have the sparsity pattern, you're going to be doing Newtons method.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, if you want to solve really, really big problems that are really sparse, there's two other issues that you need to think about, and I'm not really going to talk about them, so one is usually you get better performance if you start with a large value of Lambda and you successively decrease it to the value you want.",
                    "label": 1
                },
                {
                    "sent": "We don't really have great results on how to actually choose those Lambda, although there is some work and the other is sub optimization where you can sort of temporarily ignore variables that you don't think you're going to move away from zero, so you can either do that temporarily or.",
                    "label": 0
                },
                {
                    "sent": "A talk later in the day will talk about doing that.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Permanently.",
                    "label": 0
                },
                {
                    "sent": "You can extend that basic algorithm to a much more general class of problems, so we have a smooth function, possibly with bound constraints on the variable, and justice separable regularizer that's differentiable almost everywhere, and two metric projection algorithms also exist for other types of constraints.",
                    "label": 1
                },
                {
                    "sent": "So I know this mirror descent algorithm is very popular for optimization over the simplex, but Gaffney and Burzik is also have a two metric projection that's quite competitive for that problem too.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, of course, this isn't completely original method.",
                    "label": 0
                },
                {
                    "sent": "There's lots of other good ideas for L1 regularization methods in the literature, so these are some of the most closely related ones.",
                    "label": 0
                },
                {
                    "sent": "Well, I've sort of argued that you get a descent for sure with this step.",
                    "label": 0
                },
                {
                    "sent": "There are some theoretical problems with this type of method, so it's not.",
                    "label": 0
                },
                {
                    "sent": "We don't actually have a fully rigorous proof that this type of method is globally convergent, so some of you might have saw me come up to your poster and kind of annoy you.",
                    "label": 0
                },
                {
                    "sent": "Like does this algorithm actually converge because we don't know that these type of subgradient methods converge.",
                    "label": 0
                },
                {
                    "sent": "One thing you can do is you can use a decreasing sequence of step sizes to force convergence, but that sort of kills your convergence rate.",
                    "label": 0
                },
                {
                    "sent": "The other thing is.",
                    "label": 0
                },
                {
                    "sent": "Assuming that issue can be addressed or we can modify the algorithm to address that, there's also showing that in a finite number of iterations that it actually identifies the optimal sparsity pattern.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "You have good luck in your personal affairs.",
                    "label": 0
                },
                {
                    "sent": "Very nice.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're going to go to a problem that's maybe not as excessively study as the L.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One problem which is the group L1 problem.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to focus on the case of the two norm of the group, so we can think of this as doing L1 regularization of the lengths of the vectors.",
                    "label": 0
                },
                {
                    "sent": "So when the length of the vector goes to zero, it's equivalent to setting that to the zero vector.",
                    "label": 0
                },
                {
                    "sent": "And here we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zoom disjoint groups so the regularizer is not separable, so we can't apply the algorithm.",
                    "label": 0
                },
                {
                    "sent": "I've just talked about.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the regularizer is still simple in.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since I'll define quickly and I'm going to talk about two methods that actually take advantage of this, so we're going to talk about inexact projected Newton methods on an equivalent problem, and then like before going to think about using those tricks from the converting it to constrain problem to solve it directly.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's sort of two standard ways to convert this to a constraint problem, so one is we introduce these extra variables T. They're going to be upper bounds on the norm, so these are second order cone constraints, and then you just minimize a linear function.",
                    "label": 0
                },
                {
                    "sent": "So that's going to be an upper bound on the function when it's feasible, and the other way is to just do optimization over this weighted group L.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two norm ball and in both cases the constraints are simple and by that I mean you can compute the projection in linear time.",
                    "label": 1
                },
                {
                    "sent": "So for this one the constraints are just a Cartesian product of norm cones and you can look up the exercise in the textbook or the bottom one.",
                    "label": 0
                },
                {
                    "sent": "We showed a few years ago that you can compute that in linear time with a randomized algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the basic projected gradient step is we take our gradient step.",
                    "label": 1
                },
                {
                    "sent": "This guy and then we're going to find the closest point.",
                    "label": 0
                },
                {
                    "sent": "The projection that satisfies the constraints, and I'll quickly.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show a cartoon of that, so we have a function we have our feasible set and some iterate.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And and like before, we take the green, which is the gradient step that we find the closest point in the step, and that gets sort of gives us the direction to search along.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to speed convergence, you might think you can plug in the Newton step, but I guess I've running theme.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This top is that doesn't work.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in projected Newton methods, which goes back to this very, very nice paper by Levitin Polyak, I've only read the English translation, but it's it's very well written.",
                    "label": 0
                },
                {
                    "sent": "You could you could.",
                    "label": 0
                },
                {
                    "sent": "You can read this like tomorrow and it would still seem like it's like an up-to-date optimization paper.",
                    "label": 0
                },
                {
                    "sent": "the English translation only read.",
                    "label": 0
                },
                {
                    "sent": "So basically, instead of doing this Newton step and projecting under the Euclidean norm, we project under a norm that's going to be defined by our Hessian approximation.",
                    "label": 0
                },
                {
                    "sent": "So this quadratic norm.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's actually going to give us descent, so we can rewrite this problem as minimizing RQ function that we had before subject to the constraint that we stay in the convex set.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is in general this projection is going to be expensive, so even if you can compute the Euclidean projection efficiently, you probably won't be able to compute this projection.",
                    "label": 0
                },
                {
                    "sent": "There are some cases, like if you make H diagonal, you might be able to solve that for some problems in the group L1 you can solve.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the thing with this talk is using non diagonal Hessian approximations.",
                    "label": 0
                },
                {
                    "sent": "So we're going to consider something called an inexact project.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Newton method.",
                    "label": 0
                },
                {
                    "sent": "This is going to be sort of a constrained analogue of Hessian free Newton methods, so instead of solving that minimizing Q function, sort of exactly, we're going to think about using an iteratee.",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solver to do that, and you know, there's there's many possible choices, but I'm going to think about using the SPG iterations.",
                    "label": 0
                },
                {
                    "sent": "So basically we take a projected gradient step on the Q function and project that under the Euclidean norm, and we're going to use that to minimize the quadratic.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proximation and this is quite nice, because these SPG iterations, they only require projection under the Euclidean norm.",
                    "label": 0
                },
                {
                    "sent": "You don't have to project under that Hessian norm, and they only need testing vector products to evaluate the objective function and gradient.",
                    "label": 0
                },
                {
                    "sent": "So as we discussed before, for our problem, we can efficiently compute Euclidean projections.",
                    "label": 0
                },
                {
                    "sent": "We can also efficiently compute Hessian vector products, or at least for not any more expensive.",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the gradient calculation, so a quick cartoon of that so.",
                    "label": 0
                }
            ]
        },
        "clip_169": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same picture we lay down our queue function as we did.",
                    "label": 0
                }
            ]
        },
        "clip_170": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For now, you can think of maybe starting with the projected gradient step, but then you're.",
                    "label": 0
                }
            ]
        },
        "clip_171": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to iterate.",
                    "label": 0
                }
            ]
        },
        "clip_172": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you're going to try and find the minimizer over the convex set of your queue function.",
                    "label": 0
                },
                {
                    "sent": "That also gives you a direction along which you can search.",
                    "label": 0
                }
            ]
        },
        "clip_173": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a natural question you might ask is we saw the demo Eisenstadt style result on sort of that you don't actually have to solve the problem accurately.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to give a full care.",
                    "label": 0
                }
            ]
        },
        "clip_174": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Risation because I don't think that work has been done yet that I'm aware of, but it's very easy to show the following property that if you set if you initialize your constraint solver with your previous iteration, then as long as you run that SPG iteration for at least one line search, then you can guarantee that you improve on the objective function for Alpha small.",
                    "label": 0
                },
                {
                    "sent": "Or you can just set out for the one and then set decay to that, and that's going to give you a feasible descent direction.",
                    "label": 0
                },
                {
                    "sent": "So it's going to satisfy the constraints and give you this.",
                    "label": 0
                }
            ]
        },
        "clip_175": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the paper that Sebastian mentioned at the beginning we did last year, so we basically did the same thing, but we did an LBF's approximation within that.",
                    "label": 0
                },
                {
                    "sent": "So you can think.",
                    "label": 0
                }
            ]
        },
        "clip_176": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a hybrid method, so in this case the approximate Hessian vector product just involves running that LB FS24 loop things so we can do that in linear time.",
                    "label": 0
                },
                {
                    "sent": "And the thing I really like about this, at least for my problems, is that the SPG iterations they're going to use the Euclidean projection.",
                    "label": 0
                },
                {
                    "sent": "That's fine, 'cause our constraints are simple.",
                    "label": 0
                },
                {
                    "sent": "We can compute that quickly, but those SPG iterations don't need to touch the objective function, so we're not actually doing the Hessian vector product.",
                    "label": 0
                },
                {
                    "sent": "We don't need to do inference in our graphical model, so that's very very nice, at least for my problems.",
                    "label": 0
                },
                {
                    "sent": "And I think that for other problems this is also quite nice.",
                    "label": 0
                },
                {
                    "sent": "I think it's very nice if you have a costly objective function and simple constraints.",
                    "label": 0
                },
                {
                    "sent": "That's sort of different, like the standard optimization paradigm.",
                    "label": 0
                },
                {
                    "sent": "'cause if you think about like quadratic programming, the objective is sort of cheap, but the projection is going to be very, very expensive, so this is like the opposite scenario.",
                    "label": 0
                }
            ]
        },
        "clip_177": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To do that, we converted to a constraint problem as we did before, and so like we did before, just in my last few minutes here, we're going to talk about can we apply those ideas directly to solve the nonsmooth?",
                    "label": 0
                }
            ]
        },
        "clip_178": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can do that using proximal operators.",
                    "label": 0
                },
                {
                    "sent": "So remember the projection is just minimizing this subject to satisfying the constraints.",
                    "label": 0
                },
                {
                    "sent": "Now we're not going to have constraints, but we're going to put our regularizer directly into that projection, like function, and you get projection as a special case where our of X is the indicator function on the convex.",
                    "label": 0
                }
            ]
        },
        "clip_179": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "I said the group L1 regularizer is simple and that we can solve this proximal operator in linear time so the proximal operator ends up being separable with respect to the groups.",
                    "label": 1
                },
                {
                    "sent": "So we get this problem with respect to each group and you get this solution which is a generalization of the soft thresholding operator and this signal function is.",
                    "label": 0
                },
                {
                    "sent": "You can view our old paper, but it's a generalization of the complex modulus to grow.",
                    "label": 0
                }
            ]
        },
        "clip_180": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apps.",
                    "label": 0
                },
                {
                    "sent": "So the basic proximal gradient step is a lot like the approximal or projected gradient step basically looks like that.",
                    "label": 0
                }
            ]
        },
        "clip_181": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can plug in your Newton step.",
                    "label": 0
                },
                {
                    "sent": "But as you might guess, that actually doesn't work.",
                    "label": 0
                }
            ]
        },
        "clip_182": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what you can actually do is you can match the norms and that gives you descent.",
                    "label": 0
                },
                {
                    "sent": "So we match our HK norm in the Newton step to the norm.",
                    "label": 0
                },
                {
                    "sent": "We compute the proximal operator under so that you can think of this as like a generalized type of.",
                    "label": 0
                }
            ]
        },
        "clip_183": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proximal step and now you can show that the proximal step under that norm is equivalent to minimizing RQ function plus our regularizer times the stepsize Alpha.",
                    "label": 0
                }
            ]
        },
        "clip_184": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as before, the problem is that problem is usually going to be expensive, even if your regularizer is.",
                    "label": 0
                }
            ]
        },
        "clip_185": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple so you can think about doing a diagonal scaling or bars Libor winsteps and that was those two papers last year.",
                    "label": 0
                }
            ]
        },
        "clip_186": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or you can think about doing a non diagonal scaling by salt, minimize solving this minimization problem with an iterative solver.",
                    "label": 1
                },
                {
                    "sent": "So in my thesis we looked at using this iterative solver to solve this problem and it has a few nice properties so it only needs Euclidean proximal operators and Hessian vector products.",
                    "label": 1
                },
                {
                    "sent": "You're guaranteed descent as long as you run it for at least one iteration.",
                    "label": 0
                },
                {
                    "sent": "And if you use an LBF's approximation, that's going to be something that's quite nice for optimizing costly objectives that have simple regularizers.",
                    "label": 1
                }
            ]
        },
        "clip_187": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I've considered on the two norm.",
                    "label": 0
                },
                {
                    "sent": "You can extend these ideas to the case of the L Infinity norm or the nuclear norm.",
                    "label": 1
                },
                {
                    "sent": "I talked with the start so L Infinity norm.",
                    "label": 0
                },
                {
                    "sent": "It's basically you have to solve a sorting problem or a median finding a problem for the nuclear norm.",
                    "label": 0
                },
                {
                    "sent": "You just need to find the largest singular values to compute the projection or the proximal operator.",
                    "label": 0
                },
                {
                    "sent": "Now the convergence theory for these inexact methods is not fully developed, and we don't quite know how accurately we need to solve that problem to guarantee sort of nice properties.",
                    "label": 1
                },
                {
                    "sent": "But that is an area of that I'm hoping to fix in the next month.",
                    "label": 0
                }
            ]
        },
        "clip_188": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the help of some people in the audience here.",
                    "label": 0
                },
                {
                    "sent": "OK, so before I wrap up, I just want to mention a few other topics.",
                    "label": 0
                }
            ]
        },
        "clip_189": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the very beginning I mentioned this overlapping Group One problem that arises from the structured sparsity approach.",
                    "label": 0
                }
            ]
        },
        "clip_190": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the regularizer is not even simple because our groups overlap.",
                    "label": 0
                }
            ]
        },
        "clip_191": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it is the sum of simple regularizers, so if we take the same step as before.",
                    "label": 0
                }
            ]
        },
        "clip_192": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To constraint problem you're going to do something called Dijkstra's algorithm to compute the projection.",
                    "label": 1
                },
                {
                    "sent": "Dexter is kind of nice because we know it actually has a geometric convergence rate, at least for some sets.",
                    "label": 0
                },
                {
                    "sent": "Now for this set, it doesn't have it, but if you do the Infinity norm of the group then you get that geometric convergence rate.",
                    "label": 0
                }
            ]
        },
        "clip_193": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And more recently, there was this paper by Bashian combat combats that generalize Dexter's algorithm to compute proximal operators of the sum of simple functions.",
                    "label": 0
                },
                {
                    "sent": "So that you can directly apply within that quasi Newton Approximal method.",
                    "label": 0
                }
            ]
        },
        "clip_194": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in the past year, there's been a lot of people interested in this structured sparsity, so we've seen a bunch of methods for specifically that case, and I just wanted to mention them because some of them are actually quite good.",
                    "label": 0
                }
            ]
        },
        "clip_195": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, in the case where your regularizer is not even simple or where you may have an even more complicated nonsmooth type of thing, there's a few options available for Nonsmooth Newton like methods.",
                    "label": 0
                },
                {
                    "sent": "So one is, you can try incorporate the subdifferential sort of directly into your Q function.",
                    "label": 0
                },
                {
                    "sent": "You can also think of smoothing and then a really promising recent approaches.",
                    "label": 0
                },
                {
                    "sent": "These augmented Lagrangian dual augmented Lagrangian, and I think those can really take advantage of the structure of the problem in.",
                    "label": 1
                },
                {
                    "sent": "Many cases.",
                    "label": 0
                }
            ]
        },
        "clip_196": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I just want to briefly mention that, so I've sort of assume you have a deterministic approximation, But you can think about doing a Monte Carlo objective function, or you might be using mini batches when you think about conditional random fields.",
                    "label": 1
                },
                {
                    "sent": "So there is some work on stochastic variance, so there's this paper looks at convergence proofs for LBF's and there was an ICM wallpaper on Hessian free Newton methods and then some work that a master student in our lab Kevin Swersky, did on something called an optimal bars Libor and for the stochastic case, but.",
                    "label": 0
                },
                {
                    "sent": "Never got written up, but a problem with these is they don't actually share the fast convergence rates you get with the deterministic variants of the algorithm.",
                    "label": 1
                }
            ]
        },
        "clip_197": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before I conclude, I just want to thank my coauthors, my.",
                    "label": 0
                },
                {
                    "sent": "So first and foremost is a what Vandenberg who we did.",
                    "label": 0
                },
                {
                    "sent": "The exact projected Newton stuff with and he's now a postdoc at Stanford with Emmanuel Candes, my PhD supervisor Kevin Murphy, and my current supervisor, Michael Friedlander, Glen Fung, and Romer, who gave me the heart application.",
                    "label": 0
                },
                {
                    "sent": "I talked about the beginning and Surete and Dongmin, who we wrote up some of the stuff in this talk for the book that's coming out next year that Sebastian will prob.",
                    "label": 0
                }
            ]
        },
        "clip_198": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I plug later today so this is sort of the take home message, so if this is the one slide, if you just want the high level view of that, Oxo has seen freedom methods and limited memory briefs or two of the workhorses of 1 constraint.",
                    "label": 0
                }
            ]
        },
        "clip_199": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optimization to metric subgradient projection methods.",
                    "label": 0
                },
                {
                    "sent": "Let us apply these methods to problems where we have bound constraints or non differentiable but separable regularizers.",
                    "label": 0
                }
            ]
        },
        "clip_200": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then in exact projected and proxamol new methods are an appealing approach.",
                    "label": 1
                },
                {
                    "sent": "When you have a very costly objective function, but you have simple constraints and or a simple non differential regularizer.",
                    "label": 0
                },
                {
                    "sent": "So I'll conclude by saying that this talk roughly followed chapters one to three of my thesis.",
                    "label": 0
                },
                {
                    "sent": "So if you want to.",
                    "label": 0
                },
                {
                    "sent": "Find out what the ending is.",
                    "label": 0
                },
                {
                    "sent": "You can grab that off my web page.",
                    "label": 0
                },
                {
                    "sent": "We have sufficient time for questions questions.",
                    "label": 0
                },
                {
                    "sent": "Thanks for very nice talk, I'm just wondering about the limitations of the fault implies managers.",
                    "label": 0
                },
                {
                    "sent": "And offsetting those generally applied to L1, but presumably they are applicable to anything where the discontinuity's in the derivatives are actually at the axis, right?",
                    "label": 0
                },
                {
                    "sent": "And so I just wanted, is that true?",
                    "label": 0
                },
                {
                    "sent": "Well, you have to be a little bit careful.",
                    "label": 0
                },
                {
                    "sent": "OK, so I did mention that you can generalize so you can actually apply them if your regularizer is separable and differentiable almost everywhere.",
                    "label": 0
                },
                {
                    "sent": "So you can have many, many discontinuities, and they can be whatever you want, but they need to be on like a set of measure 0.",
                    "label": 0
                },
                {
                    "sent": "You can't have like a non differentiable region or something, so you can apply them in that problem.",
                    "label": 0
                },
                {
                    "sent": "But of course if there's a whole bunch of non differential abilities than the Earth is going to slow you down as you sort of try and plow through these things so.",
                    "label": 0
                },
                {
                    "sent": "But you can apply this things like this CAD penalty and a bunch of other things.",
                    "label": 0
                },
                {
                    "sent": "Do the city opens then get as we look at this more complicated regularise.",
                    "label": 0
                },
                {
                    "sent": "Well, the orphans are obviously.",
                    "label": 0
                },
                {
                    "sent": "I mean so.",
                    "label": 0
                },
                {
                    "sent": "So maybe Orthon is not the right view.",
                    "label": 0
                },
                {
                    "sent": "So because we're really only thinking about 1 dimensional here, so it's really only as complicated as complicated as you have one discontinuity is along one along individual coordinates, so it doesn't get much more complicated all.",
                    "label": 0
                },
                {
                    "sent": "And if you, I don't think we've put the chapter we wrote for the book up, but we actually do show the formula for the general case.",
                    "label": 0
                },
                {
                    "sent": "In the book chapter.",
                    "label": 0
                },
                {
                    "sent": "In general disease, a result in improvement for your original motivation for hardware.",
                    "label": 0
                },
                {
                    "sent": "Did they actually clear house out in the result?",
                    "label": 0
                },
                {
                    "sent": "Map of clinical informations.",
                    "label": 0
                },
                {
                    "sent": "Well, this is just a different way to solve the optimization problem, so you get the same result, you just get it in like an hour instead of like a week.",
                    "label": 0
                },
                {
                    "sent": "So clinical interpretation is not influenced except for the whole attempt.",
                    "label": 0
                },
                {
                    "sent": "Depends if you're paying for computational costs or not.",
                    "label": 0
                },
                {
                    "sent": "Questions we have time.",
                    "label": 0
                },
                {
                    "sent": "Possible method?",
                    "label": 0
                },
                {
                    "sent": "I was even able to implement it, but lines of code.",
                    "label": 0
                },
                {
                    "sent": "In your case, it seems that you have a lot of.",
                    "label": 0
                },
                {
                    "sent": "Parameters in the.",
                    "label": 0
                },
                {
                    "sent": "Exact problems in the middle.",
                    "label": 0
                },
                {
                    "sent": "So how easy is it to do it again?",
                    "label": 0
                },
                {
                    "sent": "You will fuck one week without.",
                    "label": 0
                },
                {
                    "sent": "Obviously it's not that hard, so the inner iteration is still the proximal method, so the inner iteration is going to be exactly the same except for your just.",
                    "label": 0
                },
                {
                    "sent": "You can take your existing code and you plug it into another code that feeds it, an objective function that tells you what you're asking.",
                    "label": 0
                },
                {
                    "sent": "Approximation is so if you can implement the proximal method in a few hours and then you copy those two for loops I showed earlier, then that's basically it.",
                    "label": 0
                },
                {
                    "sent": "Actually no wait, so for for the exact method you can actually use those two for loops you have to use a paper by berdale on how to represent the quasi 'cause you need multiplication by the Hessian and not the inverse Hessian.",
                    "label": 0
                },
                {
                    "sent": "But it's just a low rank representation of the matrix.",
                    "label": 0
                },
                {
                    "sent": "Or you can just download the code off my web page.",
                    "label": 0
                },
                {
                    "sent": "So in fact we had this off one question along those lines.",
                    "label": 0
                },
                {
                    "sent": "Link back to the old days of L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "I just downloaded the LGS color brilliantly.",
                    "label": 0
                },
                {
                    "sent": "Is there similar code as well?",
                    "label": 0
                },
                {
                    "sent": "But I am sort of applying for a Markov random field type problem.",
                    "label": 0
                },
                {
                    "sent": "Detail.",
                    "label": 0
                },
                {
                    "sent": "So I have a MATLAB implementation of.",
                    "label": 0
                },
                {
                    "sent": "Most of these methods on my webpage and the ones that aren't will be up in the next.",
                    "label": 0
                },
                {
                    "sent": "When I have time.",
                    "label": 0
                },
                {
                    "sent": "And so basically for that it's kind of like the LBF's code you feed it function that gives it that returns the function value in the gradient.",
                    "label": 1
                },
                {
                    "sent": "So that can be whatever you want and then you give it the values of the L1, the value of the L1 norm on each variable and then it just runs.",
                    "label": 0
                },
                {
                    "sent": "So you need one extra input to run these methods in a code.",
                    "label": 0
                },
                {
                    "sent": "But it is Matlab where I've just sort of mixed the LB FS.",
                    "label": 0
                },
                {
                    "sent": "Those two for loops to make it a little bit faster.",
                    "label": 0
                },
                {
                    "sent": "And yeah, actually if you go to my web page, I have like a list of like 20 different demos of showing how to apply it to like Gaussian graphical models and logistic regression and conditional random fields and compressed sensing and all that other stuff.",
                    "label": 0
                },
                {
                    "sent": "So it's very very.",
                    "label": 0
                },
                {
                    "sent": "I've tried to make it very much plug and play.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}