{
    "id": "5ks5qazbc6p4w3awvnprd3bl4d2uutes",
    "title": "Query Execution Optimization for Clients of Triple Pattern Fragments",
    "info": {
        "author": [
            "Joachim Van Herwegen, Ghent University"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_van_herwegen_pattern_fragments/",
    "segmentation": [
        [
            "Hello good afternoon everyone.",
            "So set my name is your him.",
            "I'm a PhD researcher at Timelines Uganda University.",
            "I'm going to talk about the query execution optimization for clients of triple button fragments."
        ],
        [
            "At first the weather.",
            "The most default ways to access Link data these days mean most famous ones.",
            "Obviously Sparkle endpoints are running spark endpoints.",
            "You also can have data dumps where the server just provides a data set which internal Dan.",
            "Execute your queries locally and then you have some simple interfaces which are somewhere in between.",
            "What we really would like to have is an interface that solves all problems.",
            "These separate attempts want to solve like they want to have full sparkle support, high scalability, fast response time, and so on.",
            "But due to technical reasons, this is quite unlikely that a system like this will ever exist.",
            "So each of these solutions has their own advantages and disadvantages.",
            "Which is why we have chosen to try to improve one of these interfaces, and in this case we try to improve one of these simple interfaces which is double button fragments, which I will explain later."
        ],
        [
            "So in my presentation I will first go over the multiple ways to access link data and what exactly are the differences are advantages and disadvantages of the more common methods and compare them to triple pattern fragments?",
            "I wouldn't see what the problem is with troubled by the friends.",
            "I tried to solve.",
            "And then the techniques are used to solve this or improving the jointery and optimizing the local joints.",
            "And finally I will bring this all together with the conclusion and evaluations."
        ],
        [
            "So accessing linked data."
        ],
        [
            "So the most the two extremes are sparkle protocol and data dumps.",
            "Sparkle Protocol is perfect for clients, almost like you have life.",
            "Data can execute all the spark queries you want and all the load is on the server.",
            "So the client actually doesn't have to do anything.",
            "But obviously for people who host Sparkle servers, this is bad because all the load is on your server, so you might have lost uptime because of the load you have to.",
            "Rent an expensive server to do all this, so obviously this is a disadvantage.",
            "And then on the other hand, you have data dumps, which is really easy for the server host since you just put the file there, provide you a right to users an well they download it and do whatever they want with it."
        ],
        [
            "So these are two methods to access link data, but there are a lot of other methods and last year a new concept called Link data Fragments was introduced, which is a generic way to describe.",
            "How you can access this linked data?",
            "So link data fragments.",
            "How does it work?",
            "Describes three parts of your interface, so you have the data, which is what you get back when you try to access this fragment.",
            "Then you have the metadata which gives you additional information about the information.",
            "You just go back and then you have the control switch allow you to access all the fragments and example."
        ],
        [
            "This is the sparkle endpoints sparkle endpoints.",
            "While the data is really simple data, you get art bindings that are the result of the query you wanted to execute.",
            "And because sparkle endpoints are again so good for the user, you don't actually need meta data or control since you get a complete answer.",
            "Answers exactly what you wanted.",
            "On the other hand, you have trip."
        ],
        [
            "Button fragments travel pattern fragments tries to reduce some of the load on the server and move it to the client.",
            "How does it do this?",
            "You can access a triple pattern fragmente by providing a triple pattern, hence the name and what you get back is a list of triples that corresponds to the to the pattern you requested and pages also to again reduce load on servers.",
            "And then you get extra metadata, because since it's in pages, you don't get all the data back.",
            "You get an estimate of how many pages there will be in total, how many elements are on each page, and you also have some control.",
            "Since you only get the page you get close to the next page first page and the root fragment of your server.",
            "Here's a."
        ],
        [
            "Visual example of triple button fragments.",
            "So what So what do you have?",
            "You have your ID, which uniquely describes this exact fragmente.",
            "It contains this subject, predicate, and object you try to ask what your query, which you can see again there.",
            "So the query we used here is only with the predicates which contains the birthplace.",
            "Below that you have your results.",
            "And also Additionally, you have metadata and controls like these are triples one 200 to the first 100 triples account estimates and who may have a page and control the next page.",
            "So, but this is just a visualization can also simply request and in three version of this data that you get all this information back and triple format so it can be handled by an three parsers."
        ],
        [
            "So.",
            "This is double the fragments.",
            "This is what we will focus on in this presentation.",
            "The problem is.",
            "Since you can only request Drupal patterns, it count execute sparkle queries.",
            "So to actually execute Sparkle query you need to do more work client site.",
            "You need to find out which are the triple patterns I need to request to actually find all the results for my sparkle query and this is where it sometimes goes wrong with triple bottom frag."
        ],
        [
            "So this is a small sparkle query.",
            "We just try to find all the architects.",
            "That left that they were born in one of the European capitals.",
            "So how does the initial algorithm work?",
            "It was originally proposed with trouble by the fragments, but simply takes the smallest pattern of all patterns in the query.",
            "And download all pages that are for this.",
            "So in this case the smallest one is all the capitals of Europe.",
            "It has 60 triples.",
            "Default page size is 100.",
            "So you need only one call to actually get all these triples.",
            "The next step is done to see which is the next small spot, and I can see there's only one path, and that's actually bound to the same variable variable set here, so there's only one choice which is birthplace.",
            "In total because they're capitals, you get about 400 pages of inhabitants of this Earth.",
            "Well, people are born in these capitals, so we need 400 calls too.",
            "Execute the second button and then finally.",
            "We want to bind to return patterns, which is checking if this is an architect.",
            "But a previous step we had 400 pages, foreign players equal 40,000 results.",
            "So we have 40,000 people.",
            "And each of these get bound to the top pattern to check if it's an architect.",
            "So since we bind every separate of this, 40,000 values need to do 40,000 calls to actually check as this person architect now.",
            "OK, so next one architect know and so on.",
            "So the highest load of this query is in this last step.",
            "More."
        ],
        [
            "Optimal solution would be if we simply downloads the list of all the architects there are 1200, so it's 12 pages.",
            "And then we have a list of architects and a list of people that were born in the EU capitals.",
            "And then we simply merge this list locally.",
            "This doesn't require any HTTP calls to server, since it's all done locally, so we go from more than 40,000 HP calls to four hundreds.",
            "So."
        ],
        [
            "Now, of course the question is, how do you actually achieve this more optimal result?",
            "We need to detect in some way that in this case it's better to download the architect separately instead of binding them.",
            "The first part for this is we try to improve so the joint real gets used to solve this query."
        ],
        [
            "So the goal is to minimize the number of HTTP calls for each of these patterns to get all the results we need to solve this query, and we do this by assigning roles to each of these patterns.",
            "Every pattern either gets assigned to download role, which means we just did this pattern as it appears in the Sparkle query an during all the pages for it.",
            "Or the other option is we have this query.",
            "We bind one of the variables with values we got from other parts.",
            "Other patterns in the query and then download all the corresponding pages there.",
            "So the greedy algorithm originally started to only one donut pattern and then just get binding to the next once we try to see if maybe it's better to sometimes download multiple of the patterns."
        ],
        [
            "So how do you estimate this?",
            "Well, we need to have at least one download button if all the patterns or buying patterns, they would all be waiting for bind values, but we would never have a point value since they will be waiting.",
            "So we have at least one donut pattern.",
            "We start with the smallest pattern also and just say this is dona pattern and all the other patterns we look at the results we have for pattern you have so far and look sort of estimates.",
            "Will it be more efficient to be download pattern?",
            "Or a buying pattern.",
            "The exact way of how this gets actually calculated, as in the paper.",
            "So with."
        ],
        [
            "Then you end up with.",
            "This sort of joint Reso first note is a donut node, so we do it all here for this query.",
            "All Spanish cities.",
            "And this provides new values for the city variable.",
            "Then we have two other nodes which we bound to the city variable and design provides again new values for their other variables, and so this goes on.",
            "So this is calculated purely on estimations we have.",
            "Look by looking at the estimates of each of the patterns are looking.",
            "If they're small patterns, we probably just want to donate them.",
            "If they're really large, you want to bind values and also looking at their parents.",
            "So during iterations."
        ],
        [
            "We reiterate this algorithm every iteration.",
            "We download one page, we don't need page and look at.",
            "We store these new values to download it, and then we have new bindings for variables in the next iteration with another page.",
            "And we wanted to know the pages in such a way.",
            "That we reach our results as soon as possible.",
            "This is streaming algorithms, so we don't simply provide execute it.",
            "And here are all the results we at streaming and every time it finds the result it outputs a tenant.",
            "Keeps going on.",
            "So the first iteration we need to start with the download pattern.",
            "Since we don't have find values with."
        ],
        [
            "After that we try to make sure that each of these patterns gets sometimes execute.",
            "If it has some new bind files to make sure that no pattern gets ignored an again this is based mostly on estimations of which you can find complete calculations in the paper."
        ],
        [
            "No, of course these initial rules.",
            "They could be wrong there, simply based on the current estimates we had in the beginning.",
            "Maybe we made a wrong caster.",
            "This specific query requires other solutions, so every iteration we check all these rolls over patterns and we see.",
            "Did we make the right choice, and if not, is it still efficient enough to change?",
            "So for every pattern, every iteration we estimate how many HTTP calls will we still need to get the remaining triples of this pattern.",
            "For download choose a donut roll.",
            "It's really easy, you just go into number of pages that correspond with this pattern.",
            "Mind benders are bit harder because we don't know how many bind values they will.",
            "There will be in the remainder for this pattern and even if we have a bias value we don't know in advance how many pages will get.",
            "So again, we estimate this.",
            "We look at how many bindings we have found so far.",
            "And we look at how many pages we have found for each binding and then based on what percentage of values we have so far.",
            "We estimate out this will probably still needs another so many HTTP calls and if this is less.",
            "If this is more than the amount we would need to simply donate all the triples for this path and we switched the role.",
            "Which I mean, again, this can happen at runtime during every iteration.",
            "So if we see out we're doing it wrong, will simply switch and continue on with the new rules."
        ],
        [
            "So.",
            "This provides us with a bunch of triples.",
            "Every pattern in the query will download its own triples and store them somewhere locally then, but we don't want triples.",
            "We want a solution to a sparkle query, so to do that we have to do local joints.",
            "We have to join all these triples we found.",
            "Together locally to solve the sparkle query."
        ],
        [
            "But since we don't know it, only one page per iteration or data doesn't change that much per iteration, like at a certain iteration will have this block of triple patterns after button.",
            "Next iteration, we will donate one page, which is 100 triple patterns.",
            "So if you already downloaded 1000, this is only a change of 10% another data set so far.",
            "Meaning that's the checks we did previously to see.",
            "Do we have results?",
            "Most of these binding checks won't change a lot since most data stays the same, so we want to reduce most of this joint knowledge.",
            "We had every iteration."
        ],
        [
            "So how does this happen?",
            "At a certain iteration, we have or set of bindings we have calculated previously, and we have triples that we don't know so far and we combine these together to get a new bindings.",
            "The next iteration we will have some more bindings, so more triples to finally reach again some more bindings.",
            "And to join this box together we need to well, do these four combinations that you can see here with the arrows.",
            "We need to combine the old bindings with the New triples commanding old bindings with the old triples, the and so on, but combining the old buildings with all triples is actually not necessary since we did that the previous step, so we can drop this block completely.",
            "So what we actually want to do is."
        ],
        [
            "Want to make sure that this.",
            "Block that we drop is actually the largest possible block, because that means we will use as much data as possible.",
            "And we do this by looking at all of our patterns we have so far.",
            "And we look at the largest subset over patterns that hasn't changed in this iteration, so there are no new bindings for their variables.",
            "There are no new triples that donors for them, they just simply stay the same.",
            "And if they stay the same, we know well there won't be a change if we join these together.",
            "And afterwards we just add patterns.",
            "At the triple soft and of the patterns we have so far as such, again with estimations to make sure that every new pattern we add two or patterns in the join is a minimal amount of work.",
            "We have to do.",
            "Because I mean if we suddenly, it usually means that the pattern of it should download the new triples will be somewhere at the end, since that's often the biggest change in patterns we had."
        ],
        [
            "So we have these multiple methods now.",
            "We can combine this all together to have a new client side algorithm to solve sparkle queries."
        ],
        [
            "So the main goal was to prevent local Optima.",
            "The original greedy algorithm got stuck in local Optima because it's.",
            "It was really greedy algorithm, it just looked oh I'm here at this point.",
            "What is the next step?",
            "Which could.",
            "Which looks the best for me at this point or algorithm tries to look a bit more globally over the data and tries to see.",
            "OK, this step might be best now, but maybe at later point it won't be so good.",
            "So this is also why we have a more tree like joint structure instead of a joint path which is again with the greedy algorithm did.",
            "It forces us to do more joints locally.",
            "But we try to minimize the amount of reuse that happens so that actually everything just gets joined once."
        ],
        [
            "So obviously we tested this.",
            "We ran the client and the server on the same machine.",
            "This laptop actually.",
            "And we added a delay of 100 milliseconds to the server because I mean the focus of this algorithm is to reduce the number of HTTP calls.",
            "So the higher the delay when you access the server, actually the balance algorithms and we want to simulate an environment where there is some.",
            "Bing time delay when you access server.",
            "So in this case 100 milliseconds."
        ],
        [
            "And these are results.",
            "So the Y axis.",
            "So we used to.",
            "What if benchmark and we clustered.",
            "We clustered queries used by amounts of triple patterns in the query, so that's the Y axis.",
            "So the first line is all queries with one triple patterns and so on.",
            "And the first growth is the medium amount of HTTP calls that are necessary to actually solve these queries.",
            "With the green one being the new one I propose here.",
            "And it's quite obvious that we actually do have less HTTP calls.",
            "The second graph is the amount of time that was necessary to execute these queries, and you can see that's actually there.",
            "I mean, there are still improvements, but it's not that extreme because the algorithm does a lot more local work.",
            "But again, this is 100 milliseconds Leon Server.",
            "So if you added 200 milliseconds delay on the server because maybe there's bad Internet traffic, the server has some problems.",
            "And answering then this time delays at this time difference would get bigger and bigger every time, so focuses on situations where there is bad Internet."
        ],
        [
            "I mean, even if there's good Internet, but then the results will be less impressive.",
            "So to conclude, we try to reduce number of HTTP calls better downside of having more client side processing.",
            "So it's ideal when you have a slow, slow or bad connection or server that responds slowly to your calls.",
            "But obviously this is not a perfect solution yet since.",
            "On the one hand, it's based a lot of estimations.",
            "An estimations can always be improved or can be wrong.",
            "And there are still some features that could be added to even more improve it, like we don't know per iteration one page because for example, introduce parallelism to donut multiple patterns per iteration at the same time.",
            "And also there's a focus on Bee GPS, which is because we base to work on triple pattern fragments, which also focuses on the GPS.",
            "Uh.",
            "And again, yes, there's more work per HTTP call."
        ],
        [
            "Thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "So set my name is your him.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD researcher at Timelines Uganda University.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about the query execution optimization for clients of triple button fragments.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At first the weather.",
                    "label": 0
                },
                {
                    "sent": "The most default ways to access Link data these days mean most famous ones.",
                    "label": 0
                },
                {
                    "sent": "Obviously Sparkle endpoints are running spark endpoints.",
                    "label": 0
                },
                {
                    "sent": "You also can have data dumps where the server just provides a data set which internal Dan.",
                    "label": 0
                },
                {
                    "sent": "Execute your queries locally and then you have some simple interfaces which are somewhere in between.",
                    "label": 0
                },
                {
                    "sent": "What we really would like to have is an interface that solves all problems.",
                    "label": 0
                },
                {
                    "sent": "These separate attempts want to solve like they want to have full sparkle support, high scalability, fast response time, and so on.",
                    "label": 0
                },
                {
                    "sent": "But due to technical reasons, this is quite unlikely that a system like this will ever exist.",
                    "label": 0
                },
                {
                    "sent": "So each of these solutions has their own advantages and disadvantages.",
                    "label": 0
                },
                {
                    "sent": "Which is why we have chosen to try to improve one of these interfaces, and in this case we try to improve one of these simple interfaces which is double button fragments, which I will explain later.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in my presentation I will first go over the multiple ways to access link data and what exactly are the differences are advantages and disadvantages of the more common methods and compare them to triple pattern fragments?",
                    "label": 0
                },
                {
                    "sent": "I wouldn't see what the problem is with troubled by the friends.",
                    "label": 0
                },
                {
                    "sent": "I tried to solve.",
                    "label": 0
                },
                {
                    "sent": "And then the techniques are used to solve this or improving the jointery and optimizing the local joints.",
                    "label": 0
                },
                {
                    "sent": "And finally I will bring this all together with the conclusion and evaluations.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So accessing linked data.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the most the two extremes are sparkle protocol and data dumps.",
                    "label": 0
                },
                {
                    "sent": "Sparkle Protocol is perfect for clients, almost like you have life.",
                    "label": 0
                },
                {
                    "sent": "Data can execute all the spark queries you want and all the load is on the server.",
                    "label": 0
                },
                {
                    "sent": "So the client actually doesn't have to do anything.",
                    "label": 0
                },
                {
                    "sent": "But obviously for people who host Sparkle servers, this is bad because all the load is on your server, so you might have lost uptime because of the load you have to.",
                    "label": 0
                },
                {
                    "sent": "Rent an expensive server to do all this, so obviously this is a disadvantage.",
                    "label": 0
                },
                {
                    "sent": "And then on the other hand, you have data dumps, which is really easy for the server host since you just put the file there, provide you a right to users an well they download it and do whatever they want with it.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are two methods to access link data, but there are a lot of other methods and last year a new concept called Link data Fragments was introduced, which is a generic way to describe.",
                    "label": 1
                },
                {
                    "sent": "How you can access this linked data?",
                    "label": 0
                },
                {
                    "sent": "So link data fragments.",
                    "label": 0
                },
                {
                    "sent": "How does it work?",
                    "label": 0
                },
                {
                    "sent": "Describes three parts of your interface, so you have the data, which is what you get back when you try to access this fragment.",
                    "label": 0
                },
                {
                    "sent": "Then you have the metadata which gives you additional information about the information.",
                    "label": 0
                },
                {
                    "sent": "You just go back and then you have the control switch allow you to access all the fragments and example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the sparkle endpoints sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "While the data is really simple data, you get art bindings that are the result of the query you wanted to execute.",
                    "label": 0
                },
                {
                    "sent": "And because sparkle endpoints are again so good for the user, you don't actually need meta data or control since you get a complete answer.",
                    "label": 0
                },
                {
                    "sent": "Answers exactly what you wanted.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you have trip.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Button fragments travel pattern fragments tries to reduce some of the load on the server and move it to the client.",
                    "label": 0
                },
                {
                    "sent": "How does it do this?",
                    "label": 0
                },
                {
                    "sent": "You can access a triple pattern fragmente by providing a triple pattern, hence the name and what you get back is a list of triples that corresponds to the to the pattern you requested and pages also to again reduce load on servers.",
                    "label": 1
                },
                {
                    "sent": "And then you get extra metadata, because since it's in pages, you don't get all the data back.",
                    "label": 0
                },
                {
                    "sent": "You get an estimate of how many pages there will be in total, how many elements are on each page, and you also have some control.",
                    "label": 0
                },
                {
                    "sent": "Since you only get the page you get close to the next page first page and the root fragment of your server.",
                    "label": 1
                },
                {
                    "sent": "Here's a.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Visual example of triple button fragments.",
                    "label": 0
                },
                {
                    "sent": "So what So what do you have?",
                    "label": 0
                },
                {
                    "sent": "You have your ID, which uniquely describes this exact fragmente.",
                    "label": 0
                },
                {
                    "sent": "It contains this subject, predicate, and object you try to ask what your query, which you can see again there.",
                    "label": 0
                },
                {
                    "sent": "So the query we used here is only with the predicates which contains the birthplace.",
                    "label": 0
                },
                {
                    "sent": "Below that you have your results.",
                    "label": 0
                },
                {
                    "sent": "And also Additionally, you have metadata and controls like these are triples one 200 to the first 100 triples account estimates and who may have a page and control the next page.",
                    "label": 0
                },
                {
                    "sent": "So, but this is just a visualization can also simply request and in three version of this data that you get all this information back and triple format so it can be handled by an three parsers.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is double the fragments.",
                    "label": 0
                },
                {
                    "sent": "This is what we will focus on in this presentation.",
                    "label": 0
                },
                {
                    "sent": "The problem is.",
                    "label": 0
                },
                {
                    "sent": "Since you can only request Drupal patterns, it count execute sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "So to actually execute Sparkle query you need to do more work client site.",
                    "label": 0
                },
                {
                    "sent": "You need to find out which are the triple patterns I need to request to actually find all the results for my sparkle query and this is where it sometimes goes wrong with triple bottom frag.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a small sparkle query.",
                    "label": 0
                },
                {
                    "sent": "We just try to find all the architects.",
                    "label": 0
                },
                {
                    "sent": "That left that they were born in one of the European capitals.",
                    "label": 0
                },
                {
                    "sent": "So how does the initial algorithm work?",
                    "label": 0
                },
                {
                    "sent": "It was originally proposed with trouble by the fragments, but simply takes the smallest pattern of all patterns in the query.",
                    "label": 1
                },
                {
                    "sent": "And download all pages that are for this.",
                    "label": 0
                },
                {
                    "sent": "So in this case the smallest one is all the capitals of Europe.",
                    "label": 0
                },
                {
                    "sent": "It has 60 triples.",
                    "label": 0
                },
                {
                    "sent": "Default page size is 100.",
                    "label": 0
                },
                {
                    "sent": "So you need only one call to actually get all these triples.",
                    "label": 0
                },
                {
                    "sent": "The next step is done to see which is the next small spot, and I can see there's only one path, and that's actually bound to the same variable variable set here, so there's only one choice which is birthplace.",
                    "label": 0
                },
                {
                    "sent": "In total because they're capitals, you get about 400 pages of inhabitants of this Earth.",
                    "label": 0
                },
                {
                    "sent": "Well, people are born in these capitals, so we need 400 calls too.",
                    "label": 0
                },
                {
                    "sent": "Execute the second button and then finally.",
                    "label": 0
                },
                {
                    "sent": "We want to bind to return patterns, which is checking if this is an architect.",
                    "label": 0
                },
                {
                    "sent": "But a previous step we had 400 pages, foreign players equal 40,000 results.",
                    "label": 0
                },
                {
                    "sent": "So we have 40,000 people.",
                    "label": 0
                },
                {
                    "sent": "And each of these get bound to the top pattern to check if it's an architect.",
                    "label": 0
                },
                {
                    "sent": "So since we bind every separate of this, 40,000 values need to do 40,000 calls to actually check as this person architect now.",
                    "label": 0
                },
                {
                    "sent": "OK, so next one architect know and so on.",
                    "label": 0
                },
                {
                    "sent": "So the highest load of this query is in this last step.",
                    "label": 0
                },
                {
                    "sent": "More.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optimal solution would be if we simply downloads the list of all the architects there are 1200, so it's 12 pages.",
                    "label": 0
                },
                {
                    "sent": "And then we have a list of architects and a list of people that were born in the EU capitals.",
                    "label": 0
                },
                {
                    "sent": "And then we simply merge this list locally.",
                    "label": 0
                },
                {
                    "sent": "This doesn't require any HTTP calls to server, since it's all done locally, so we go from more than 40,000 HP calls to four hundreds.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, of course the question is, how do you actually achieve this more optimal result?",
                    "label": 0
                },
                {
                    "sent": "We need to detect in some way that in this case it's better to download the architect separately instead of binding them.",
                    "label": 0
                },
                {
                    "sent": "The first part for this is we try to improve so the joint real gets used to solve this query.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal is to minimize the number of HTTP calls for each of these patterns to get all the results we need to solve this query, and we do this by assigning roles to each of these patterns.",
                    "label": 1
                },
                {
                    "sent": "Every pattern either gets assigned to download role, which means we just did this pattern as it appears in the Sparkle query an during all the pages for it.",
                    "label": 0
                },
                {
                    "sent": "Or the other option is we have this query.",
                    "label": 0
                },
                {
                    "sent": "We bind one of the variables with values we got from other parts.",
                    "label": 0
                },
                {
                    "sent": "Other patterns in the query and then download all the corresponding pages there.",
                    "label": 0
                },
                {
                    "sent": "So the greedy algorithm originally started to only one donut pattern and then just get binding to the next once we try to see if maybe it's better to sometimes download multiple of the patterns.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do you estimate this?",
                    "label": 0
                },
                {
                    "sent": "Well, we need to have at least one download button if all the patterns or buying patterns, they would all be waiting for bind values, but we would never have a point value since they will be waiting.",
                    "label": 0
                },
                {
                    "sent": "So we have at least one donut pattern.",
                    "label": 0
                },
                {
                    "sent": "We start with the smallest pattern also and just say this is dona pattern and all the other patterns we look at the results we have for pattern you have so far and look sort of estimates.",
                    "label": 0
                },
                {
                    "sent": "Will it be more efficient to be download pattern?",
                    "label": 0
                },
                {
                    "sent": "Or a buying pattern.",
                    "label": 0
                },
                {
                    "sent": "The exact way of how this gets actually calculated, as in the paper.",
                    "label": 0
                },
                {
                    "sent": "So with.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you end up with.",
                    "label": 0
                },
                {
                    "sent": "This sort of joint Reso first note is a donut node, so we do it all here for this query.",
                    "label": 0
                },
                {
                    "sent": "All Spanish cities.",
                    "label": 0
                },
                {
                    "sent": "And this provides new values for the city variable.",
                    "label": 0
                },
                {
                    "sent": "Then we have two other nodes which we bound to the city variable and design provides again new values for their other variables, and so this goes on.",
                    "label": 0
                },
                {
                    "sent": "So this is calculated purely on estimations we have.",
                    "label": 0
                },
                {
                    "sent": "Look by looking at the estimates of each of the patterns are looking.",
                    "label": 0
                },
                {
                    "sent": "If they're small patterns, we probably just want to donate them.",
                    "label": 0
                },
                {
                    "sent": "If they're really large, you want to bind values and also looking at their parents.",
                    "label": 0
                },
                {
                    "sent": "So during iterations.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We reiterate this algorithm every iteration.",
                    "label": 0
                },
                {
                    "sent": "We download one page, we don't need page and look at.",
                    "label": 0
                },
                {
                    "sent": "We store these new values to download it, and then we have new bindings for variables in the next iteration with another page.",
                    "label": 0
                },
                {
                    "sent": "And we wanted to know the pages in such a way.",
                    "label": 0
                },
                {
                    "sent": "That we reach our results as soon as possible.",
                    "label": 0
                },
                {
                    "sent": "This is streaming algorithms, so we don't simply provide execute it.",
                    "label": 0
                },
                {
                    "sent": "And here are all the results we at streaming and every time it finds the result it outputs a tenant.",
                    "label": 0
                },
                {
                    "sent": "Keeps going on.",
                    "label": 0
                },
                {
                    "sent": "So the first iteration we need to start with the download pattern.",
                    "label": 1
                },
                {
                    "sent": "Since we don't have find values with.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After that we try to make sure that each of these patterns gets sometimes execute.",
                    "label": 0
                },
                {
                    "sent": "If it has some new bind files to make sure that no pattern gets ignored an again this is based mostly on estimations of which you can find complete calculations in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, of course these initial rules.",
                    "label": 0
                },
                {
                    "sent": "They could be wrong there, simply based on the current estimates we had in the beginning.",
                    "label": 0
                },
                {
                    "sent": "Maybe we made a wrong caster.",
                    "label": 0
                },
                {
                    "sent": "This specific query requires other solutions, so every iteration we check all these rolls over patterns and we see.",
                    "label": 0
                },
                {
                    "sent": "Did we make the right choice, and if not, is it still efficient enough to change?",
                    "label": 0
                },
                {
                    "sent": "So for every pattern, every iteration we estimate how many HTTP calls will we still need to get the remaining triples of this pattern.",
                    "label": 0
                },
                {
                    "sent": "For download choose a donut roll.",
                    "label": 0
                },
                {
                    "sent": "It's really easy, you just go into number of pages that correspond with this pattern.",
                    "label": 0
                },
                {
                    "sent": "Mind benders are bit harder because we don't know how many bind values they will.",
                    "label": 0
                },
                {
                    "sent": "There will be in the remainder for this pattern and even if we have a bias value we don't know in advance how many pages will get.",
                    "label": 0
                },
                {
                    "sent": "So again, we estimate this.",
                    "label": 0
                },
                {
                    "sent": "We look at how many bindings we have found so far.",
                    "label": 1
                },
                {
                    "sent": "And we look at how many pages we have found for each binding and then based on what percentage of values we have so far.",
                    "label": 1
                },
                {
                    "sent": "We estimate out this will probably still needs another so many HTTP calls and if this is less.",
                    "label": 0
                },
                {
                    "sent": "If this is more than the amount we would need to simply donate all the triples for this path and we switched the role.",
                    "label": 0
                },
                {
                    "sent": "Which I mean, again, this can happen at runtime during every iteration.",
                    "label": 0
                },
                {
                    "sent": "So if we see out we're doing it wrong, will simply switch and continue on with the new rules.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This provides us with a bunch of triples.",
                    "label": 0
                },
                {
                    "sent": "Every pattern in the query will download its own triples and store them somewhere locally then, but we don't want triples.",
                    "label": 0
                },
                {
                    "sent": "We want a solution to a sparkle query, so to do that we have to do local joints.",
                    "label": 0
                },
                {
                    "sent": "We have to join all these triples we found.",
                    "label": 0
                },
                {
                    "sent": "Together locally to solve the sparkle query.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But since we don't know it, only one page per iteration or data doesn't change that much per iteration, like at a certain iteration will have this block of triple patterns after button.",
                    "label": 0
                },
                {
                    "sent": "Next iteration, we will donate one page, which is 100 triple patterns.",
                    "label": 0
                },
                {
                    "sent": "So if you already downloaded 1000, this is only a change of 10% another data set so far.",
                    "label": 0
                },
                {
                    "sent": "Meaning that's the checks we did previously to see.",
                    "label": 0
                },
                {
                    "sent": "Do we have results?",
                    "label": 0
                },
                {
                    "sent": "Most of these binding checks won't change a lot since most data stays the same, so we want to reduce most of this joint knowledge.",
                    "label": 0
                },
                {
                    "sent": "We had every iteration.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how does this happen?",
                    "label": 0
                },
                {
                    "sent": "At a certain iteration, we have or set of bindings we have calculated previously, and we have triples that we don't know so far and we combine these together to get a new bindings.",
                    "label": 0
                },
                {
                    "sent": "The next iteration we will have some more bindings, so more triples to finally reach again some more bindings.",
                    "label": 0
                },
                {
                    "sent": "And to join this box together we need to well, do these four combinations that you can see here with the arrows.",
                    "label": 0
                },
                {
                    "sent": "We need to combine the old bindings with the New triples commanding old bindings with the old triples, the and so on, but combining the old buildings with all triples is actually not necessary since we did that the previous step, so we can drop this block completely.",
                    "label": 0
                },
                {
                    "sent": "So what we actually want to do is.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Want to make sure that this.",
                    "label": 0
                },
                {
                    "sent": "Block that we drop is actually the largest possible block, because that means we will use as much data as possible.",
                    "label": 0
                },
                {
                    "sent": "And we do this by looking at all of our patterns we have so far.",
                    "label": 0
                },
                {
                    "sent": "And we look at the largest subset over patterns that hasn't changed in this iteration, so there are no new bindings for their variables.",
                    "label": 1
                },
                {
                    "sent": "There are no new triples that donors for them, they just simply stay the same.",
                    "label": 0
                },
                {
                    "sent": "And if they stay the same, we know well there won't be a change if we join these together.",
                    "label": 0
                },
                {
                    "sent": "And afterwards we just add patterns.",
                    "label": 0
                },
                {
                    "sent": "At the triple soft and of the patterns we have so far as such, again with estimations to make sure that every new pattern we add two or patterns in the join is a minimal amount of work.",
                    "label": 0
                },
                {
                    "sent": "We have to do.",
                    "label": 0
                },
                {
                    "sent": "Because I mean if we suddenly, it usually means that the pattern of it should download the new triples will be somewhere at the end, since that's often the biggest change in patterns we had.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have these multiple methods now.",
                    "label": 0
                },
                {
                    "sent": "We can combine this all together to have a new client side algorithm to solve sparkle queries.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main goal was to prevent local Optima.",
                    "label": 1
                },
                {
                    "sent": "The original greedy algorithm got stuck in local Optima because it's.",
                    "label": 0
                },
                {
                    "sent": "It was really greedy algorithm, it just looked oh I'm here at this point.",
                    "label": 0
                },
                {
                    "sent": "What is the next step?",
                    "label": 0
                },
                {
                    "sent": "Which could.",
                    "label": 0
                },
                {
                    "sent": "Which looks the best for me at this point or algorithm tries to look a bit more globally over the data and tries to see.",
                    "label": 0
                },
                {
                    "sent": "OK, this step might be best now, but maybe at later point it won't be so good.",
                    "label": 0
                },
                {
                    "sent": "So this is also why we have a more tree like joint structure instead of a joint path which is again with the greedy algorithm did.",
                    "label": 0
                },
                {
                    "sent": "It forces us to do more joints locally.",
                    "label": 0
                },
                {
                    "sent": "But we try to minimize the amount of reuse that happens so that actually everything just gets joined once.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So obviously we tested this.",
                    "label": 0
                },
                {
                    "sent": "We ran the client and the server on the same machine.",
                    "label": 1
                },
                {
                    "sent": "This laptop actually.",
                    "label": 1
                },
                {
                    "sent": "And we added a delay of 100 milliseconds to the server because I mean the focus of this algorithm is to reduce the number of HTTP calls.",
                    "label": 1
                },
                {
                    "sent": "So the higher the delay when you access the server, actually the balance algorithms and we want to simulate an environment where there is some.",
                    "label": 0
                },
                {
                    "sent": "Bing time delay when you access server.",
                    "label": 0
                },
                {
                    "sent": "So in this case 100 milliseconds.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these are results.",
                    "label": 0
                },
                {
                    "sent": "So the Y axis.",
                    "label": 0
                },
                {
                    "sent": "So we used to.",
                    "label": 0
                },
                {
                    "sent": "What if benchmark and we clustered.",
                    "label": 0
                },
                {
                    "sent": "We clustered queries used by amounts of triple patterns in the query, so that's the Y axis.",
                    "label": 0
                },
                {
                    "sent": "So the first line is all queries with one triple patterns and so on.",
                    "label": 0
                },
                {
                    "sent": "And the first growth is the medium amount of HTTP calls that are necessary to actually solve these queries.",
                    "label": 0
                },
                {
                    "sent": "With the green one being the new one I propose here.",
                    "label": 0
                },
                {
                    "sent": "And it's quite obvious that we actually do have less HTTP calls.",
                    "label": 1
                },
                {
                    "sent": "The second graph is the amount of time that was necessary to execute these queries, and you can see that's actually there.",
                    "label": 0
                },
                {
                    "sent": "I mean, there are still improvements, but it's not that extreme because the algorithm does a lot more local work.",
                    "label": 0
                },
                {
                    "sent": "But again, this is 100 milliseconds Leon Server.",
                    "label": 0
                },
                {
                    "sent": "So if you added 200 milliseconds delay on the server because maybe there's bad Internet traffic, the server has some problems.",
                    "label": 0
                },
                {
                    "sent": "And answering then this time delays at this time difference would get bigger and bigger every time, so focuses on situations where there is bad Internet.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean, even if there's good Internet, but then the results will be less impressive.",
                    "label": 0
                },
                {
                    "sent": "So to conclude, we try to reduce number of HTTP calls better downside of having more client side processing.",
                    "label": 0
                },
                {
                    "sent": "So it's ideal when you have a slow, slow or bad connection or server that responds slowly to your calls.",
                    "label": 0
                },
                {
                    "sent": "But obviously this is not a perfect solution yet since.",
                    "label": 0
                },
                {
                    "sent": "On the one hand, it's based a lot of estimations.",
                    "label": 0
                },
                {
                    "sent": "An estimations can always be improved or can be wrong.",
                    "label": 0
                },
                {
                    "sent": "And there are still some features that could be added to even more improve it, like we don't know per iteration one page because for example, introduce parallelism to donut multiple patterns per iteration at the same time.",
                    "label": 0
                },
                {
                    "sent": "And also there's a focus on Bee GPS, which is because we base to work on triple pattern fragments, which also focuses on the GPS.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "And again, yes, there's more work per HTTP call.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}