{
    "id": "5ela7h5xixwgkw3etyjhhjyoclbw32yf",
    "title": "Augment-and-Conquer Negative Binomial Processes",
    "info": {
        "author": [
            "Mingyuan Zhou, Department of Electrical and Computer Engineering, Duke University"
        ],
        "published": "Jan. 14, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/machine_zhou_negative/",
    "segmentation": [
        [
            "So good afternoon everyone.",
            "So mixture modeling is a key research area in statistics and machine learning.",
            "So here we come with our new perspective about doing mixed modeling.",
            "Basically with your mixture Modeling's account modeling problems.",
            "What does that mean?",
            "For example, given example of topic modeling, essentially you're modeling mixture.",
            "Group towards mixture model with words.",
            "So we're trying to model account matrices, right?",
            "If we consider the number of words you send it to a topic in a given document, what's that is account and in the end you're trying to model atopic by document count matrices.",
            "And here we use the negative binomial distribution and negative binomial process to model discount matrices.",
            "So why we use the negative binomial distribution and so we know for contributions most prominent person distribution as we know it's quite restrictive cause.",
            "It has the IT has the equal dispersion assumption that means the horizon is the same with the same rate parameter but negative binomial distribution.",
            "Here I'm going to tell your story why it's so special, why it's very useful.",
            "So if you know the Chinese restaurant process, it tells your story.",
            "Give me a fixed number of customers you're going to use the challenge restaurant to put this customer on their tables.",
            "So the number of customer is fixed, but the number of table is random.",
            "Now tell you you can also treat the number of customer as a random variable.",
            "So give me negative binomial number random give me negative binomial random number customer.",
            "I'm going to put them into tables, follow Chinese restaurant process and then you get 2 random variable right randomizer number, customer number table, random number table.",
            "There are two random variables and I'm going to say actually they are exactly the same but doing another way I'm going to first draw person number of tables and then on each of these table I'm going to independent draw log rhythmic distributed.",
            "Random number of customers.",
            "We can see, no matter first, draw the customer and then put on tables or first draw the table and then put the customer on the tables that join the distribution of the customer count and table count are exactly the same.",
            "Yes, the negative binomial distribution able to linger to lots of different distribution.",
            "Here what we showed up on distribution log.",
            "The log arhythmic distribution, the changes on the table distribution.",
            "Also the negative binomial distribution is a gamma also mixed with distribution and the person you can link it to the multinomial distribution so you can see the big picture why the mixture modeling count modeling lots of different distribution can be united under the same framework."
        ],
        [
            "And also because the negative binomial distribution has two parameters right?",
            "It has the distribution parameter, it has the probability parameter.",
            "So we can easily construct hierarchical structures.",
            "We can either use the gamma process.",
            "Put on the as the user gallop.",
            "Assess as the rate parameter as the dispersion parameter of the negative binomial process to construct, negative binomial hierarchical construction.",
            "We can also use the beta process to put on the probability parameter to construct the beta negative binomial process, so there are lots of different construction you can construct based on this framework.",
            "The most important, most interesting thing is that you can enter these frameworks, unify lots of different algorithms, including including laser duration, location, long acting, matrix factorization, hierarchical DP, LDA folks, topic modeling, modeling based on negative binomial process, lost lots of different algorithms."
        ],
        [
            "Of course, this algorithm has very distinct statistical properties, but if you only care about out of sample prediction prediction, then the perspective we provide here you really have to model both the overdispersion level and the rise to mean ratio of the count distribution, which are respected governor by the dispersion parameter and the probability parameter of the negative binomial distribution.",
            "So thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "So mixture modeling is a key research area in statistics and machine learning.",
                    "label": 0
                },
                {
                    "sent": "So here we come with our new perspective about doing mixed modeling.",
                    "label": 0
                },
                {
                    "sent": "Basically with your mixture Modeling's account modeling problems.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "For example, given example of topic modeling, essentially you're modeling mixture.",
                    "label": 1
                },
                {
                    "sent": "Group towards mixture model with words.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to model account matrices, right?",
                    "label": 0
                },
                {
                    "sent": "If we consider the number of words you send it to a topic in a given document, what's that is account and in the end you're trying to model atopic by document count matrices.",
                    "label": 0
                },
                {
                    "sent": "And here we use the negative binomial distribution and negative binomial process to model discount matrices.",
                    "label": 1
                },
                {
                    "sent": "So why we use the negative binomial distribution and so we know for contributions most prominent person distribution as we know it's quite restrictive cause.",
                    "label": 0
                },
                {
                    "sent": "It has the IT has the equal dispersion assumption that means the horizon is the same with the same rate parameter but negative binomial distribution.",
                    "label": 1
                },
                {
                    "sent": "Here I'm going to tell your story why it's so special, why it's very useful.",
                    "label": 0
                },
                {
                    "sent": "So if you know the Chinese restaurant process, it tells your story.",
                    "label": 0
                },
                {
                    "sent": "Give me a fixed number of customers you're going to use the challenge restaurant to put this customer on their tables.",
                    "label": 0
                },
                {
                    "sent": "So the number of customer is fixed, but the number of table is random.",
                    "label": 0
                },
                {
                    "sent": "Now tell you you can also treat the number of customer as a random variable.",
                    "label": 0
                },
                {
                    "sent": "So give me negative binomial number random give me negative binomial random number customer.",
                    "label": 0
                },
                {
                    "sent": "I'm going to put them into tables, follow Chinese restaurant process and then you get 2 random variable right randomizer number, customer number table, random number table.",
                    "label": 0
                },
                {
                    "sent": "There are two random variables and I'm going to say actually they are exactly the same but doing another way I'm going to first draw person number of tables and then on each of these table I'm going to independent draw log rhythmic distributed.",
                    "label": 0
                },
                {
                    "sent": "Random number of customers.",
                    "label": 0
                },
                {
                    "sent": "We can see, no matter first, draw the customer and then put on tables or first draw the table and then put the customer on the tables that join the distribution of the customer count and table count are exactly the same.",
                    "label": 1
                },
                {
                    "sent": "Yes, the negative binomial distribution able to linger to lots of different distribution.",
                    "label": 0
                },
                {
                    "sent": "Here what we showed up on distribution log.",
                    "label": 0
                },
                {
                    "sent": "The log arhythmic distribution, the changes on the table distribution.",
                    "label": 0
                },
                {
                    "sent": "Also the negative binomial distribution is a gamma also mixed with distribution and the person you can link it to the multinomial distribution so you can see the big picture why the mixture modeling count modeling lots of different distribution can be united under the same framework.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also because the negative binomial distribution has two parameters right?",
                    "label": 1
                },
                {
                    "sent": "It has the distribution parameter, it has the probability parameter.",
                    "label": 0
                },
                {
                    "sent": "So we can easily construct hierarchical structures.",
                    "label": 0
                },
                {
                    "sent": "We can either use the gamma process.",
                    "label": 0
                },
                {
                    "sent": "Put on the as the user gallop.",
                    "label": 0
                },
                {
                    "sent": "Assess as the rate parameter as the dispersion parameter of the negative binomial process to construct, negative binomial hierarchical construction.",
                    "label": 1
                },
                {
                    "sent": "We can also use the beta process to put on the probability parameter to construct the beta negative binomial process, so there are lots of different construction you can construct based on this framework.",
                    "label": 1
                },
                {
                    "sent": "The most important, most interesting thing is that you can enter these frameworks, unify lots of different algorithms, including including laser duration, location, long acting, matrix factorization, hierarchical DP, LDA folks, topic modeling, modeling based on negative binomial process, lost lots of different algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, this algorithm has very distinct statistical properties, but if you only care about out of sample prediction prediction, then the perspective we provide here you really have to model both the overdispersion level and the rise to mean ratio of the count distribution, which are respected governor by the dispersion parameter and the probability parameter of the negative binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        }
    }
}