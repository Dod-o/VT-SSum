{
    "id": "oeielwggfdm5j4m7f5kas2xy6gy3dtga",
    "title": "LC-QuAD 2.0: A large dataset for complex question answering over Wikidata and DBpedia",
    "info": {
        "author": [
            "Mohnish Dubey, Department of Computer Science, Bonn-Rhine-Sieg University of Applied Sciences"
        ],
        "published": "Nov. 27, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_dubey_large_dataset/",
    "segmentation": [
        [
            "Hello, my name is Manish Dubey.",
            "I'm a PhD student at University of Bonn and I will be presenting our work on LC code 2.0.",
            "So."
        ],
        [
            "Why do we need a data set?",
            "We need it.",
            "We need a data set becausw it helps to benchmark and also helps to improve the state of the art on in any field.",
            "So that is why a key QA data set would always help to improve Cage QA and help benchmark it further.",
            "So this helps you to set up goals."
        ],
        [
            "So this is the outline.",
            "Go through it.",
            "I'll first give some motivation.",
            "Then we look at the impact of the previous else code.",
            "What are the new crazy models that we're looking into the objectives of the data set, then the process and outcome and some future directions?"
        ],
        [
            "So question answering.",
            "Basically, what is a question?",
            "A question.",
            "Is something a sentence is basically tries to extract some information in Cage Q at this."
        ],
        [
            "Information actually means the information stored in the Knowledge Graph itself."
        ],
        [
            "So what is the mode?"
        ],
        [
            "Vision for this data set.",
            "This data set is based on the success of LC code 1.0 which which we release in SWC 2017 and also the impact of verification of cages on Casey Key Way or the potential impact that it could have."
        ],
        [
            "So this is how the basic LC caught framework looks like.",
            "Basically you revert back the process of question answering.",
            "So basically you first have answer you try to formulate a sparkle around it and then you try to get some template based translation to it.",
            "And then you finally get English question and as you have a English question corresponding to Sparkle query."
        ],
        [
            "So this is the exact same slide that we used in 2017 presentation.",
            "That's the lights last slide, so it has complex question.",
            "It has sparkle queries, variation of it.",
            "It just provides you gold standards, extensible and it's awesome."
        ],
        [
            "And this is the impact of LC code.",
            "We can see that we now have, like good baselines on complex questions.",
            "We can see that have been few question answering components developed using more or less mainly else code.",
            "You can see there are assembled systems.",
            "There are also benchmarking's which have been developed around else code Becausw because now we have like more questions.",
            "I would say more complex questions.",
            "So now this is the second motivation which is about the cagey models, so a classical in a classical cagey model, a triple would look like this, where you have a subject predicate an the edges connecting.",
            "Yeah."
        ],
        [
            "Subject and object the predicate.",
            "But in one of the ways that."
        ],
        [
            "Define model.",
            "This is just one of the ways there could be many other ways.",
            "I'm just for the explanatory of this slides.",
            "I'm using choosing this specific model.",
            "So.",
            "So let's say Robert Downey Junior is our entity, so he's connected to SSID, which is a statement ID.",
            "And then if you see in the previous slide it has Susan Downey his wife.",
            "Then it becomes the object and then if you again look in the previous slide spouse that becomes another node here which is connected through egeanin predicate.",
            "So now what this gives is opportunity to us to have store more information about this specific fact, something like.",
            "Location you can save location information related to this specific fact.",
            "You can have something like a start date and yeah."
        ],
        [
            "This is how it is helpful, so you can basically have more information about a particular effect.",
            "This is if you can have a question answering system using these facts, you can have more expressive questions.",
            "You can have questions with a lot more variety and user can ask for more detailed informations."
        ],
        [
            "So we have already covered motivation and and the other three points.",
            "Now we look into the objectives of the data set."
        ],
        [
            "So the four objectives that we have set are the first of all the datasets should be based on the refight Casey model.",
            "So if you know Wiki data is already using this kind of model, the new DB pedia versions would in future would also be using it.",
            "They already have released their dump.",
            "But yeah, the public endpoint is still using the classical cagey model.",
            "Maybe in future they will also change it, but the models the dump is already available we have.",
            "Did our experiments locali on it.",
            "So we're looking to have a data set using Riffic AG model.",
            "We also look to increase the complexity variety in their question, not just in number of triples, but also in other other dimensions.",
            "Also, if you're using the qualifier information in there, if I'd knowledge graphs, this also gain gives us more opportunity to increase variety in the complexity of the questions.",
            "The third objective is to scale up the whole question generation process.",
            "In the previous version, we will manually the three authors of the paper over manually doing most of the work left of translating question, but we want to now since you want to upscale the data set, we have to think about this and also the 4th objective is to have paraphrase questions.",
            "Because recently we have seen studies where an LP any kind of problems if if you just change few words here and there in a in a data set the performance.",
            "Has been drastically decreased.",
            "So does this.",
            "If you already have a paraphrase in the question on some datasets itself, there are more chances that the system will be robust towards paraphrasing."
        ],
        [
            "So I'll see."
        ],
        [
            "Lots of you want not else quite 2.0."
        ],
        [
            "So now we go to the data creation."
        ],
        [
            "So this is how the workflow looks like.",
            "I go step by step.",
            "So we first choose some vital entities from Wikipedia.",
            "There is a Wikipedia page where you can wear which enlists the entity based on based on their wikiHow.",
            "Wikipedia works basically crowdsourcing efforts so you can go something like Wikipedia vital level 5 or so.",
            "On Level 5, they aim to have 50,000 articles in various varieties, so one can always already check from there, so some of the seed entities were taken from there.",
            "And then we choose."
        ],
        [
            "Some sparkle templates by by looking in in the model in the cagey model, an also in the in the way the previous datasets were generated.",
            "So basically you would look like you would look into considering ask queries, ranking queries, Boolean queries, so those kind of things you will be considering.",
            "And then we choose predicate list based on specific.",
            "Based on specific sparkle type, because not not every sparkle type would be making a good question with a particular predicate, so you have to whitelist the predicate list, but you have to also whitelist, maybe according to maybe.",
            "Maybe according to your sparkle query type also so some predicate query will not make sense in other."
        ],
        [
            "Another sparkle so once you once you know the sparkle, you know that relations then you can generate a sub graph and then you can do a template fitting on the on the basic sparkle template that you initially made and then you will finally get a final sparkle query.",
            "Of course, we were generating a lot of them and then choosing on based on subura sticks that we want only these kind of sparkles.",
            "And just to make sure that not every sparkle query is about Barack Obama or not, every sparkle query is about a certain relation.",
            "So so we were trying to make those checks."
        ],
        [
            "Balance, so once this is particle queries generated then we try to make something called an equity which we introduced in a previous version of the paper which basically is rule based translation of a sparkle query to English question.",
            "I would say these questions looks very similar because they're just template based.",
            "A human can understand those questions, but yet though they might not be very grammatically coherent or correct.",
            "So what we conducted an AMT experiment that these questions were given to the AMT workers.",
            "Basically crowdsourcing workers and we will ask them to verbalize those questions into correct English.",
            "So basically an in cutie now becomes a question template and verbalize questions becomes the verbalise questions.",
            "So this is how we get the first version of the question.",
            "And then we again give that Verbalised question again to empty for another paraphrasing experience, and where they again paraphrase the same question again in a different way, so and then."
        ],
        [
            "At the last we conducted the third round of AMT experiment, where these these two pairs of questions were given an an annotator was was asked to check whether these are correct in terms of grammar or in terms of semantics or not.",
            "So."
        ],
        [
            "So, so let's say this is.",
            "This is our sparkle.",
            "If this is a sparkle where Robert Downey junior spouse Anne Susan Downey are given and you are asking for the location and.",
            "Start date of their marriage.",
            "So this is how your template questions would look like.",
            "So what start time and place of marriage of Robert Downey?",
            "Junior's is spouse of Susan Downey.",
            "So the verbalised question would be when did Robert Downey Junior get married to Susan Downey an at work place?",
            "And then the paraphrase question would be where, when and where did Robert RDJ normal?",
            "We have, since it's paraphrasing.",
            "It can write Robert Downey, Junior, as RDJ also got married to Susan.",
            "Also, in this very specific example, I have chosen one of the varieties that we have introduced in the data set, which is a dual intention variety.",
            "I'll come to that in later slides."
        ],
        [
            "So this is the current state of the datasets that we have.",
            "If you see we have a lot of data sets, but if you see in the variation of their complex questions only call 9.",
            "I would say has a high variation or in any of the any of the other called challenges.",
            "Here you will find high variation becausw people actually just make a less number of questions so they actually put a lot more effort while making questions.",
            "And as you see, a lot more variety and that is why in one of the previous presentations.",
            "Also the performance in called it was less.",
            "And then you have a large number of questions on simple questions and factory questions.",
            "For example, for web questions, do it is, it is supposed to have complex questions, but I think 90% of the questions in web questions are still simple questions.",
            "And then we had LC code which was released in 2017 ANAN."
        ],
        [
            "They also got 2.0.",
            "We have 30,000 questions which have high variation in.",
            "In their question, Variety is the Sparkle variety.",
            "It also has paraphrases, and you can query those those article queries to wiki data an in the 2018 version of DVD also.",
            "So it is one of the."
        ],
        [
            "Data set which you can directly use on 2."
        ],
        [
            "These cops already.",
            "Yeah, so now we look into the outcomes of this process.",
            "Basically we see did we achieve our objectives or not that we set initially?",
            "So else code 2.0 is based on pre fight models.",
            "So yeah it is based sparkle query following refight cages questions can ask the information about qualifiers.",
            "The question could have information about the qualifier and you were asking about something else.",
            "So for example you could have a question where you are asking to whom did Robert Downey junior married in 2015?",
            "Now not.",
            "That information is in the question you are asking for an object now.",
            "So yeah, this is one kind of variety.",
            "We also introduce literals inside the questions because qualifier information had literals.",
            "Sometimes like dates as I mentioned in this specific example.",
            "Yeah, so high rating question type.",
            "So you have classical complex question which are like multi effects question where you're basically having two triples.",
            "And then you have."
        ],
        [
            "Questions with dual intentions, which was suggested by Dennis.",
            "Which was basically asking about two intention and one question.",
            "Something like when and where or who is the father and brother of Robert Downey Junior.",
            "Something like this.",
            "So we had these new."
        ],
        [
            "Category of questions.",
            "You can have questions with temporal aspects.",
            "This is all held by the refried Knowledge Graph because in rification, when you have qualifiers, the qualifiers have a lot of spatial and temporal information, so you can have questions with them.",
            "Then we have Boolean count and ranking and some of the types actually involve two of them.",
            "So you could have an ASK query where you have to do a count query also.",
            "And then we also introduced something called string operation queries where the questions would be something like give me all Rock Band which starts with R or give me all rock Band which has.",
            "New York, in their name.",
            "Something like this.",
            "So yeah, this is the question, right?"
        ],
        [
            "Type, that's a distribution, so it's fairly distributed.",
            "If you see that the 23 multi fact it's becausw, this multi effect itself has several varieties in it, so.",
            "Yeah."
        ],
        [
            "And then upscaling the process.",
            "So basically transforming this process of question generation to an empty task.",
            "So we were able to make that this into an empty experience where a template question was given an we were able to successfully verbalize the question.",
            "Does it help us to upscale the data?"
        ],
        [
            "Yeah.",
            "Able to paraphrase the question, yes, so just becausw from from question one, so it's more clear here."
        ],
        [
            "Yeah, so if you see here since since the data set.",
            "Yeah, so the template question.",
            "And the verbalize question, if you compare it to the template question and the and the paraphrase question, the semantic distance between them keeps on increasing.",
            "And then there's also the Levenshtein distance keeps on increasing.",
            "So you can say that now the questions are bit more far away from from their actual template that they were because it has been verified twice."
        ],
        [
            "Yeah, so I would say that we would say that all the four objectives are met."
        ],
        [
            "Also then we go for discussion."
        ],
        [
            "So this data set still doesn't have an union or an option query.",
            "There are no out of scope question at the moment because generating them are difficult.",
            "One limitation we came over from last year that last to last, I mean the last version that all our Sparkle query which were like ask queries were all true.",
            "In the last version, but in this version, not all of them are true because we use some sort of semantic similarity of entities and made some logical.",
            "Statements there, so some of the sparkle queries are also false.",
            "We also made sure that it's false in a way that doesn't sound stupid.",
            "Something like is is Narendra Modi the Prime Minister of of USA?",
            "Because this obviously looks false bus but something like is Hillary Clinton, president of United States.",
            "So something like this?",
            "Yeah."
        ],
        [
            "And in future direction.",
            "So basically I think the whole cagey community needs to look in this direction if they want to focus.",
            "Lets him more on Wiki data kind of data model, so they need to look in riffic Aries and then creating baseline on on this kind of data set and then other future direction would be I have also seen the paper this year on this is about automatic question generation and specifically automatic question generation ONS.",
            "Complex question."
        ],
        [
            "For acknowledgement, I would acknowledge front over an BMF before.",
            "For providing the findings."
        ],
        [
            "I would also acknowledge Mikhail for giving useful feedbacks on knowledge graphs."
        ],
        [
            "The references."
        ],
        [
            "Yeah yeah, feel free to ask me questions now."
        ],
        [
            "Thank you for your talk.",
            "I wonder how many sparkle templates do you use and will you share your sparkle templates as well?",
            "Would you publish them?",
            "The sparkle query themselves are published so."
        ],
        [
            "Oops.",
            "Yeah, so if you can go on this website.",
            "Also it's in the slides.",
            "I will also make the slides on Twitter so you can see there.",
            "You already have sparkle queries in the data set.",
            "Also, we also mentioned that there are 20 two different templates.",
            "Also, I think in the data set it is marked that this is there is a ranking a specific ID given to a template, so you can reverse back.",
            "Yeah, that's possible.",
            "Because I thought it would make sense to hide those templates because it reduces the search.",
            "Yeah, so then yeah.",
            "So specifically, I think there is this data set name SSQ which doesn't give you the sparkle then.",
            "Basically you cannot do a question to sparkle thing right?",
            "Because if you do not give us benchmarking Sparkle query then then it doesn't make sense like it makes sense in some way.",
            "But then the whole point of translating question two Sparkle goes away.",
            "Is there another question here?",
            "Yeah, just have one doubt.",
            "If you clear it would be great like I'm thinking what would be the application of a system that will use your data set for evaluation.",
            "When you have this kind of complex questions which have two questions at the same time like when and where X&Y were married like.",
            "What what will be the application to use this kind of questions?",
            "Like instead of asking 2 separate questions, you just ask one single question, right?",
            "That's the application I would select, it just depends on like not all questions had to intentions.",
            "It's just one of the varieties in the whole 22 variety of questions that we have.",
            "It's not that the whole data set is like that, it's just one of the varieties and we can also discuss it offline, yeah?",
            "I can also cover up your point of I or you, or you can repeat if nobody is asking.",
            "OK, so thank you very much.",
            "OK, I'll click your post."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, my name is Manish Dubey.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at University of Bonn and I will be presenting our work on LC code 2.0.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why do we need a data set?",
                    "label": 0
                },
                {
                    "sent": "We need it.",
                    "label": 0
                },
                {
                    "sent": "We need a data set becausw it helps to benchmark and also helps to improve the state of the art on in any field.",
                    "label": 0
                },
                {
                    "sent": "So that is why a key QA data set would always help to improve Cage QA and help benchmark it further.",
                    "label": 0
                },
                {
                    "sent": "So this helps you to set up goals.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the outline.",
                    "label": 0
                },
                {
                    "sent": "Go through it.",
                    "label": 0
                },
                {
                    "sent": "I'll first give some motivation.",
                    "label": 0
                },
                {
                    "sent": "Then we look at the impact of the previous else code.",
                    "label": 0
                },
                {
                    "sent": "What are the new crazy models that we're looking into the objectives of the data set, then the process and outcome and some future directions?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So question answering.",
                    "label": 0
                },
                {
                    "sent": "Basically, what is a question?",
                    "label": 0
                },
                {
                    "sent": "A question.",
                    "label": 0
                },
                {
                    "sent": "Is something a sentence is basically tries to extract some information in Cage Q at this.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Information actually means the information stored in the Knowledge Graph itself.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is the mode?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vision for this data set.",
                    "label": 0
                },
                {
                    "sent": "This data set is based on the success of LC code 1.0 which which we release in SWC 2017 and also the impact of verification of cages on Casey Key Way or the potential impact that it could have.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is how the basic LC caught framework looks like.",
                    "label": 0
                },
                {
                    "sent": "Basically you revert back the process of question answering.",
                    "label": 0
                },
                {
                    "sent": "So basically you first have answer you try to formulate a sparkle around it and then you try to get some template based translation to it.",
                    "label": 0
                },
                {
                    "sent": "And then you finally get English question and as you have a English question corresponding to Sparkle query.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the exact same slide that we used in 2017 presentation.",
                    "label": 0
                },
                {
                    "sent": "That's the lights last slide, so it has complex question.",
                    "label": 0
                },
                {
                    "sent": "It has sparkle queries, variation of it.",
                    "label": 0
                },
                {
                    "sent": "It just provides you gold standards, extensible and it's awesome.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the impact of LC code.",
                    "label": 0
                },
                {
                    "sent": "We can see that we now have, like good baselines on complex questions.",
                    "label": 0
                },
                {
                    "sent": "We can see that have been few question answering components developed using more or less mainly else code.",
                    "label": 0
                },
                {
                    "sent": "You can see there are assembled systems.",
                    "label": 0
                },
                {
                    "sent": "There are also benchmarking's which have been developed around else code Becausw because now we have like more questions.",
                    "label": 0
                },
                {
                    "sent": "I would say more complex questions.",
                    "label": 0
                },
                {
                    "sent": "So now this is the second motivation which is about the cagey models, so a classical in a classical cagey model, a triple would look like this, where you have a subject predicate an the edges connecting.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Subject and object the predicate.",
                    "label": 0
                },
                {
                    "sent": "But in one of the ways that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Define model.",
                    "label": 0
                },
                {
                    "sent": "This is just one of the ways there could be many other ways.",
                    "label": 0
                },
                {
                    "sent": "I'm just for the explanatory of this slides.",
                    "label": 0
                },
                {
                    "sent": "I'm using choosing this specific model.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let's say Robert Downey Junior is our entity, so he's connected to SSID, which is a statement ID.",
                    "label": 0
                },
                {
                    "sent": "And then if you see in the previous slide it has Susan Downey his wife.",
                    "label": 0
                },
                {
                    "sent": "Then it becomes the object and then if you again look in the previous slide spouse that becomes another node here which is connected through egeanin predicate.",
                    "label": 0
                },
                {
                    "sent": "So now what this gives is opportunity to us to have store more information about this specific fact, something like.",
                    "label": 0
                },
                {
                    "sent": "Location you can save location information related to this specific fact.",
                    "label": 0
                },
                {
                    "sent": "You can have something like a start date and yeah.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is how it is helpful, so you can basically have more information about a particular effect.",
                    "label": 0
                },
                {
                    "sent": "This is if you can have a question answering system using these facts, you can have more expressive questions.",
                    "label": 0
                },
                {
                    "sent": "You can have questions with a lot more variety and user can ask for more detailed informations.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have already covered motivation and and the other three points.",
                    "label": 0
                },
                {
                    "sent": "Now we look into the objectives of the data set.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the four objectives that we have set are the first of all the datasets should be based on the refight Casey model.",
                    "label": 0
                },
                {
                    "sent": "So if you know Wiki data is already using this kind of model, the new DB pedia versions would in future would also be using it.",
                    "label": 0
                },
                {
                    "sent": "They already have released their dump.",
                    "label": 0
                },
                {
                    "sent": "But yeah, the public endpoint is still using the classical cagey model.",
                    "label": 0
                },
                {
                    "sent": "Maybe in future they will also change it, but the models the dump is already available we have.",
                    "label": 0
                },
                {
                    "sent": "Did our experiments locali on it.",
                    "label": 0
                },
                {
                    "sent": "So we're looking to have a data set using Riffic AG model.",
                    "label": 1
                },
                {
                    "sent": "We also look to increase the complexity variety in their question, not just in number of triples, but also in other other dimensions.",
                    "label": 1
                },
                {
                    "sent": "Also, if you're using the qualifier information in there, if I'd knowledge graphs, this also gain gives us more opportunity to increase variety in the complexity of the questions.",
                    "label": 0
                },
                {
                    "sent": "The third objective is to scale up the whole question generation process.",
                    "label": 0
                },
                {
                    "sent": "In the previous version, we will manually the three authors of the paper over manually doing most of the work left of translating question, but we want to now since you want to upscale the data set, we have to think about this and also the 4th objective is to have paraphrase questions.",
                    "label": 0
                },
                {
                    "sent": "Because recently we have seen studies where an LP any kind of problems if if you just change few words here and there in a in a data set the performance.",
                    "label": 0
                },
                {
                    "sent": "Has been drastically decreased.",
                    "label": 0
                },
                {
                    "sent": "So does this.",
                    "label": 0
                },
                {
                    "sent": "If you already have a paraphrase in the question on some datasets itself, there are more chances that the system will be robust towards paraphrasing.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll see.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lots of you want not else quite 2.0.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we go to the data creation.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is how the workflow looks like.",
                    "label": 0
                },
                {
                    "sent": "I go step by step.",
                    "label": 0
                },
                {
                    "sent": "So we first choose some vital entities from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "There is a Wikipedia page where you can wear which enlists the entity based on based on their wikiHow.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia works basically crowdsourcing efforts so you can go something like Wikipedia vital level 5 or so.",
                    "label": 0
                },
                {
                    "sent": "On Level 5, they aim to have 50,000 articles in various varieties, so one can always already check from there, so some of the seed entities were taken from there.",
                    "label": 0
                },
                {
                    "sent": "And then we choose.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some sparkle templates by by looking in in the model in the cagey model, an also in the in the way the previous datasets were generated.",
                    "label": 0
                },
                {
                    "sent": "So basically you would look like you would look into considering ask queries, ranking queries, Boolean queries, so those kind of things you will be considering.",
                    "label": 0
                },
                {
                    "sent": "And then we choose predicate list based on specific.",
                    "label": 0
                },
                {
                    "sent": "Based on specific sparkle type, because not not every sparkle type would be making a good question with a particular predicate, so you have to whitelist the predicate list, but you have to also whitelist, maybe according to maybe.",
                    "label": 0
                },
                {
                    "sent": "Maybe according to your sparkle query type also so some predicate query will not make sense in other.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another sparkle so once you once you know the sparkle, you know that relations then you can generate a sub graph and then you can do a template fitting on the on the basic sparkle template that you initially made and then you will finally get a final sparkle query.",
                    "label": 0
                },
                {
                    "sent": "Of course, we were generating a lot of them and then choosing on based on subura sticks that we want only these kind of sparkles.",
                    "label": 0
                },
                {
                    "sent": "And just to make sure that not every sparkle query is about Barack Obama or not, every sparkle query is about a certain relation.",
                    "label": 0
                },
                {
                    "sent": "So so we were trying to make those checks.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Balance, so once this is particle queries generated then we try to make something called an equity which we introduced in a previous version of the paper which basically is rule based translation of a sparkle query to English question.",
                    "label": 0
                },
                {
                    "sent": "I would say these questions looks very similar because they're just template based.",
                    "label": 0
                },
                {
                    "sent": "A human can understand those questions, but yet though they might not be very grammatically coherent or correct.",
                    "label": 0
                },
                {
                    "sent": "So what we conducted an AMT experiment that these questions were given to the AMT workers.",
                    "label": 0
                },
                {
                    "sent": "Basically crowdsourcing workers and we will ask them to verbalize those questions into correct English.",
                    "label": 0
                },
                {
                    "sent": "So basically an in cutie now becomes a question template and verbalize questions becomes the verbalise questions.",
                    "label": 0
                },
                {
                    "sent": "So this is how we get the first version of the question.",
                    "label": 0
                },
                {
                    "sent": "And then we again give that Verbalised question again to empty for another paraphrasing experience, and where they again paraphrase the same question again in a different way, so and then.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the last we conducted the third round of AMT experiment, where these these two pairs of questions were given an an annotator was was asked to check whether these are correct in terms of grammar or in terms of semantics or not.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so let's say this is.",
                    "label": 0
                },
                {
                    "sent": "This is our sparkle.",
                    "label": 0
                },
                {
                    "sent": "If this is a sparkle where Robert Downey junior spouse Anne Susan Downey are given and you are asking for the location and.",
                    "label": 0
                },
                {
                    "sent": "Start date of their marriage.",
                    "label": 0
                },
                {
                    "sent": "So this is how your template questions would look like.",
                    "label": 0
                },
                {
                    "sent": "So what start time and place of marriage of Robert Downey?",
                    "label": 0
                },
                {
                    "sent": "Junior's is spouse of Susan Downey.",
                    "label": 0
                },
                {
                    "sent": "So the verbalised question would be when did Robert Downey Junior get married to Susan Downey an at work place?",
                    "label": 0
                },
                {
                    "sent": "And then the paraphrase question would be where, when and where did Robert RDJ normal?",
                    "label": 0
                },
                {
                    "sent": "We have, since it's paraphrasing.",
                    "label": 0
                },
                {
                    "sent": "It can write Robert Downey, Junior, as RDJ also got married to Susan.",
                    "label": 0
                },
                {
                    "sent": "Also, in this very specific example, I have chosen one of the varieties that we have introduced in the data set, which is a dual intention variety.",
                    "label": 0
                },
                {
                    "sent": "I'll come to that in later slides.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the current state of the datasets that we have.",
                    "label": 0
                },
                {
                    "sent": "If you see we have a lot of data sets, but if you see in the variation of their complex questions only call 9.",
                    "label": 0
                },
                {
                    "sent": "I would say has a high variation or in any of the any of the other called challenges.",
                    "label": 0
                },
                {
                    "sent": "Here you will find high variation becausw people actually just make a less number of questions so they actually put a lot more effort while making questions.",
                    "label": 0
                },
                {
                    "sent": "And as you see, a lot more variety and that is why in one of the previous presentations.",
                    "label": 0
                },
                {
                    "sent": "Also the performance in called it was less.",
                    "label": 0
                },
                {
                    "sent": "And then you have a large number of questions on simple questions and factory questions.",
                    "label": 0
                },
                {
                    "sent": "For example, for web questions, do it is, it is supposed to have complex questions, but I think 90% of the questions in web questions are still simple questions.",
                    "label": 0
                },
                {
                    "sent": "And then we had LC code which was released in 2017 ANAN.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They also got 2.0.",
                    "label": 0
                },
                {
                    "sent": "We have 30,000 questions which have high variation in.",
                    "label": 0
                },
                {
                    "sent": "In their question, Variety is the Sparkle variety.",
                    "label": 0
                },
                {
                    "sent": "It also has paraphrases, and you can query those those article queries to wiki data an in the 2018 version of DVD also.",
                    "label": 0
                },
                {
                    "sent": "So it is one of the.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data set which you can directly use on 2.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These cops already.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so now we look into the outcomes of this process.",
                    "label": 0
                },
                {
                    "sent": "Basically we see did we achieve our objectives or not that we set initially?",
                    "label": 0
                },
                {
                    "sent": "So else code 2.0 is based on pre fight models.",
                    "label": 0
                },
                {
                    "sent": "So yeah it is based sparkle query following refight cages questions can ask the information about qualifiers.",
                    "label": 0
                },
                {
                    "sent": "The question could have information about the qualifier and you were asking about something else.",
                    "label": 0
                },
                {
                    "sent": "So for example you could have a question where you are asking to whom did Robert Downey junior married in 2015?",
                    "label": 0
                },
                {
                    "sent": "Now not.",
                    "label": 0
                },
                {
                    "sent": "That information is in the question you are asking for an object now.",
                    "label": 0
                },
                {
                    "sent": "So yeah, this is one kind of variety.",
                    "label": 0
                },
                {
                    "sent": "We also introduce literals inside the questions because qualifier information had literals.",
                    "label": 0
                },
                {
                    "sent": "Sometimes like dates as I mentioned in this specific example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so high rating question type.",
                    "label": 0
                },
                {
                    "sent": "So you have classical complex question which are like multi effects question where you're basically having two triples.",
                    "label": 0
                },
                {
                    "sent": "And then you have.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Questions with dual intentions, which was suggested by Dennis.",
                    "label": 1
                },
                {
                    "sent": "Which was basically asking about two intention and one question.",
                    "label": 0
                },
                {
                    "sent": "Something like when and where or who is the father and brother of Robert Downey Junior.",
                    "label": 0
                },
                {
                    "sent": "Something like this.",
                    "label": 0
                },
                {
                    "sent": "So we had these new.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Category of questions.",
                    "label": 0
                },
                {
                    "sent": "You can have questions with temporal aspects.",
                    "label": 1
                },
                {
                    "sent": "This is all held by the refried Knowledge Graph because in rification, when you have qualifiers, the qualifiers have a lot of spatial and temporal information, so you can have questions with them.",
                    "label": 0
                },
                {
                    "sent": "Then we have Boolean count and ranking and some of the types actually involve two of them.",
                    "label": 0
                },
                {
                    "sent": "So you could have an ASK query where you have to do a count query also.",
                    "label": 0
                },
                {
                    "sent": "And then we also introduced something called string operation queries where the questions would be something like give me all Rock Band which starts with R or give me all rock Band which has.",
                    "label": 0
                },
                {
                    "sent": "New York, in their name.",
                    "label": 0
                },
                {
                    "sent": "Something like this.",
                    "label": 0
                },
                {
                    "sent": "So yeah, this is the question, right?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Type, that's a distribution, so it's fairly distributed.",
                    "label": 0
                },
                {
                    "sent": "If you see that the 23 multi fact it's becausw, this multi effect itself has several varieties in it, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then upscaling the process.",
                    "label": 0
                },
                {
                    "sent": "So basically transforming this process of question generation to an empty task.",
                    "label": 0
                },
                {
                    "sent": "So we were able to make that this into an empty experience where a template question was given an we were able to successfully verbalize the question.",
                    "label": 0
                },
                {
                    "sent": "Does it help us to upscale the data?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Able to paraphrase the question, yes, so just becausw from from question one, so it's more clear here.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so if you see here since since the data set.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the template question.",
                    "label": 0
                },
                {
                    "sent": "And the verbalize question, if you compare it to the template question and the and the paraphrase question, the semantic distance between them keeps on increasing.",
                    "label": 0
                },
                {
                    "sent": "And then there's also the Levenshtein distance keeps on increasing.",
                    "label": 0
                },
                {
                    "sent": "So you can say that now the questions are bit more far away from from their actual template that they were because it has been verified twice.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so I would say that we would say that all the four objectives are met.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also then we go for discussion.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this data set still doesn't have an union or an option query.",
                    "label": 0
                },
                {
                    "sent": "There are no out of scope question at the moment because generating them are difficult.",
                    "label": 0
                },
                {
                    "sent": "One limitation we came over from last year that last to last, I mean the last version that all our Sparkle query which were like ask queries were all true.",
                    "label": 0
                },
                {
                    "sent": "In the last version, but in this version, not all of them are true because we use some sort of semantic similarity of entities and made some logical.",
                    "label": 0
                },
                {
                    "sent": "Statements there, so some of the sparkle queries are also false.",
                    "label": 0
                },
                {
                    "sent": "We also made sure that it's false in a way that doesn't sound stupid.",
                    "label": 0
                },
                {
                    "sent": "Something like is is Narendra Modi the Prime Minister of of USA?",
                    "label": 0
                },
                {
                    "sent": "Because this obviously looks false bus but something like is Hillary Clinton, president of United States.",
                    "label": 0
                },
                {
                    "sent": "So something like this?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in future direction.",
                    "label": 0
                },
                {
                    "sent": "So basically I think the whole cagey community needs to look in this direction if they want to focus.",
                    "label": 0
                },
                {
                    "sent": "Lets him more on Wiki data kind of data model, so they need to look in riffic Aries and then creating baseline on on this kind of data set and then other future direction would be I have also seen the paper this year on this is about automatic question generation and specifically automatic question generation ONS.",
                    "label": 0
                },
                {
                    "sent": "Complex question.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For acknowledgement, I would acknowledge front over an BMF before.",
                    "label": 0
                },
                {
                    "sent": "For providing the findings.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would also acknowledge Mikhail for giving useful feedbacks on knowledge graphs.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The references.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah yeah, feel free to ask me questions now.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for your talk.",
                    "label": 0
                },
                {
                    "sent": "I wonder how many sparkle templates do you use and will you share your sparkle templates as well?",
                    "label": 0
                },
                {
                    "sent": "Would you publish them?",
                    "label": 0
                },
                {
                    "sent": "The sparkle query themselves are published so.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oops.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if you can go on this website.",
                    "label": 0
                },
                {
                    "sent": "Also it's in the slides.",
                    "label": 0
                },
                {
                    "sent": "I will also make the slides on Twitter so you can see there.",
                    "label": 0
                },
                {
                    "sent": "You already have sparkle queries in the data set.",
                    "label": 0
                },
                {
                    "sent": "Also, we also mentioned that there are 20 two different templates.",
                    "label": 0
                },
                {
                    "sent": "Also, I think in the data set it is marked that this is there is a ranking a specific ID given to a template, so you can reverse back.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's possible.",
                    "label": 0
                },
                {
                    "sent": "Because I thought it would make sense to hide those templates because it reduces the search.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so then yeah.",
                    "label": 0
                },
                {
                    "sent": "So specifically, I think there is this data set name SSQ which doesn't give you the sparkle then.",
                    "label": 0
                },
                {
                    "sent": "Basically you cannot do a question to sparkle thing right?",
                    "label": 0
                },
                {
                    "sent": "Because if you do not give us benchmarking Sparkle query then then it doesn't make sense like it makes sense in some way.",
                    "label": 0
                },
                {
                    "sent": "But then the whole point of translating question two Sparkle goes away.",
                    "label": 0
                },
                {
                    "sent": "Is there another question here?",
                    "label": 0
                },
                {
                    "sent": "Yeah, just have one doubt.",
                    "label": 0
                },
                {
                    "sent": "If you clear it would be great like I'm thinking what would be the application of a system that will use your data set for evaluation.",
                    "label": 0
                },
                {
                    "sent": "When you have this kind of complex questions which have two questions at the same time like when and where X&Y were married like.",
                    "label": 0
                },
                {
                    "sent": "What what will be the application to use this kind of questions?",
                    "label": 0
                },
                {
                    "sent": "Like instead of asking 2 separate questions, you just ask one single question, right?",
                    "label": 0
                },
                {
                    "sent": "That's the application I would select, it just depends on like not all questions had to intentions.",
                    "label": 0
                },
                {
                    "sent": "It's just one of the varieties in the whole 22 variety of questions that we have.",
                    "label": 0
                },
                {
                    "sent": "It's not that the whole data set is like that, it's just one of the varieties and we can also discuss it offline, yeah?",
                    "label": 0
                },
                {
                    "sent": "I can also cover up your point of I or you, or you can repeat if nobody is asking.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you very much.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll click your post.",
                    "label": 0
                }
            ]
        }
    }
}