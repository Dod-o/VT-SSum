{
    "id": "jqx27iabwswnj47rgqhpoesthse4r5o7",
    "title": "Effective computation of maximal sound approximations of Description Logic ontologies",
    "info": {
        "author": [
            "Valerio Santarelli, Department of Computer and System Sciences Antonio Ruberti, Sapienza University of Rome"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_santarelli_ontologies/",
    "segmentation": [
        [
            "So I'm literally and I'm here to present a joint work with Marco Concelhos Amara Ricardo Rosado.",
            "Meaning of abuse of A at the Spencer University.",
            "And the title once again is effective.",
            "Computation of maximum sound approximations of description, logic, ontologies.",
            "OK, so quick."
        ],
        [
            "Duction generally ontologies can be used for many things, among them you can use them as a description of a domain of interest and when using them for this purpose you would like to have to use a very expressive language such As for example Al 2.",
            "But on the other hand, if you use ontologies for reasoning, as we saw in the previous presentation, this use of these expressive languages can be a problem.",
            "For example, in ontology based data access.",
            "The computational cost of reasoning over languages such as L2 is prohibitive, so a good compromise here is the use of the use of approximation.",
            "So the idea is to take an ontology expressed in a language and somehow reformulate it into an ontology expressed in a less expressive language.",
            "With the goal to preserve as much as possible of the semantics of the of the array."
        ],
        [
            "Don't argue so, in a certain sense, through approximation, we can perform reasoning over ontologies that were originally expressed in expressive languages."
        ],
        [
            "So here we focused on mythology approximation for the purpose of ontology based data access.",
            "And in this talk I'm going to give our definition of approximation of description logic ontologies.",
            "I'm going to show how some techniques we have developed for approximating out to ontologies into our two QL, which as we saw earlier, is also is the data oriented profile of L2.",
            "I'm going to show some experimental valuation of these techniques.",
            "And I'm going to conclude with some future work which we are beginning to to undertake."
        ],
        [
            "So some very, very quick preliminaries.",
            "This is actually."
        ],
        [
            "Alcohol I'm not going to get into the details since I'm sure many of you already know what we're talking about.",
            "The one thing that I want to point out is that is a property about to call.",
            "Actually is what we called the closed language, meaning that each set of out to quell axioms actually forms a proper outlook.",
            "Well, ontology and this isn't always the case in description logics.",
            "For example, DL 8 is not a close language, so we're going to see in the slides later on how this nice property of LTC is going to come in handy for us."
        ],
        [
            "OK, so our definition of approximation first of."
        ],
        [
            "So this work actually follows in the footsteps of the work by Jeff on an Edward Thomas and here we're dealing with semantic approximation.",
            "So when dealing with semantic approximation, you generally want two things you want.",
            "You want soundness, meaning you want the approximation to produce only axioms that are entailed by the original dollars.",
            "So you don't want anything new.",
            "And you want to preserve as much as possible of the entailments of the original ontology.",
            "Obviously all of those entailments that can be expressed in the target language, so."
        ],
        [
            "Since in the following set I'm going to show you our definition, it's based on sets of models of the original Ontology Annex approximation.",
            "So these two desiderata can be expressed in terms of soundness.",
            "So we want the sets of models of the approximation to be a super set of the ones of the original apology and in terms of minimal change.",
            "So we want to keep minimal distance in terms of sets of models between the original ontology and the approximation which we are compute."
        ],
        [
            "So here is our definition of our notion of approximation of an ontology in a target language.",
            "So we say that given a certain signature, a source ontology in a source language and target language, we see that an ontology is the global semantic approximation of the original ontology in the target language.",
            "If these two conditions hold, so essentially the soundness condition, which is what I mentioned in the previous slide, and the minimal change condition which imposes that there is no other ontology in this case, so prime.",
            "Who's sets of models include the ones of the original target, but are strictly included in the ones of the target ontology.",
            "So once again, we don't want there to be another ontology that is closer to the original apology than the one we produced with the approximation.",
            "So quick observation we denote with global APX to the set of all the global semantic approximations in the target language of the source ontology, and we're going to use this notation."
        ],
        [
            "Later on.",
            "OK, so two properties here.",
            "First of all, when does the global approximation exist?",
            "So we have that if if the given a target language and signature of the ontology if the set of non equivalent axioms that can be generated over this signature in the target language is finished, then for any source language and any source ontology there is at least one ontology which it which is it's global semantic approximation."
        ],
        [
            "We also have that for.",
            "For closed languages, for example outlook, we also which we saw earlier.",
            "If we are approximating in these in the target language which is closed language, then for any two ontologies that belong to the set of approximations of a source ontology, we have that these two ontology are in fact logically equivalent, and we're going to see later on how these two properties help us in computing the approximation."
        ],
        [
            "So now we know we have given a definition of global semantic approximation, but doesn't.",
            "This doesn't really help us out in figuring out how to how to compute it.",
            "So in order to move to a more constructive definition, we give a new definition based on the notion of entailment set an entailment that was introduced by by Jeff Pan and Edward Thomas in 2007, and essentially entailment, set of in ontology with respect to language.",
            "Is the set of all the axioms that can be expressed in that language, and that are entailed by the ontology itself so.",
            "We have this theorem which allows us to reformulate the soundness in the minimal change condition which we saw in the previous definition, and essentially it tells us that the soundness condition is verified if and only if the entailment set of the ontology that we produced through the approximation in the target language is included in the entailment set of the original ontology in that target language, and that the minimal change condition is satisfied.",
            "If there is no other ontology.",
            "In this case over Prime Prime, which is whose entailment set.",
            "Is strictly includes the one we compute through the approximation, so OT and is itself included in the entailment set of the original anthology."
        ],
        [
            "So now we have we we we know that to compute the global semantic approximation we can use the.",
            "We can use the entailment set, which we know how to compute."
        ],
        [
            "So.",
            "This is great, but actually computing the entailment set is quite hard in general for very large or very complex ontologies expressed in very expressive language is this isn't always possible, with the reasons that are currently at our disposal.",
            "So why is this?",
            "Is this because in order to compute the entailment set, you have to reason over the whole ontology at once.",
            "So our idea was instead of trying to reason over the whole ontology, let's just reason over portions of it at a time and then put together what we get from each of these single single steps.",
            "And so we came up with this notion of K approximation, where this parameter K is.",
            "Essentially, it gives us the number of axioms which we reason over at a time, and so we were able to compute the approximation by computing the global semantic approximation of each week and say sub ontology formed by K axioms.",
            "Of the original ontology in isolation.",
            "And then we put them all together and we obtain our approximation.",
            "We obtained the K approximation."
        ],
        [
            "So this is the definition of K approximation.",
            "As you can see, it's very very similar to the one we saw earlier for global semantic approximation.",
            "The only difference is that instead of comparing the set of models of of the target ontology to the ones of the original ontology, we're comparing them to the.",
            "The intersection of the models of the global semantic approximations of each of these smaller ontologies formed by K axioms.",
            "So the soundness and minimal change condition remained the same.",
            "The only difference is is this.",
            "So instead of using the models of the original apology, we use the models of the intersection of the models of the global semantic approximations of each sub ontology."
        ],
        [
            "OK, so we have studied two significant cases for ontology approximation for K approximation.",
            "Sorry, so the one in which K assumes its largest possible value, which is the number of axioms in the original ontology and the one in which assumes its smallest possible value, which is obviously One South 4K which equals to the number of actions in the original ontology.",
            "We have.",
            "The key approximation is exactly identical to the global semantic approximation, so you reason over the ontology.",
            "At once and you get your approximation.",
            "On the other hand, if you choose K = 1, then essentially your reasoning over one axiom of the original apology at a time, and we call this local semantic approximation.",
            "So two edges of this K, parametric approximation, GSA and LSA."
        ],
        [
            "Obviously, global semantic approximation is going to give you a better approximation than the local semantic one, but as we as I said earlier, it's not always possible for very large ontologies.",
            "So for example, here we have the end original ontology.",
            "We say we have that A is included in B or C and that be is included in dianbai reasoning over both these these axioms, the ontology obtained through GSA, is able to preserve that AIDS included.",
            "Indeed, while the ontology obtained through LSA is going to lose this this entailment because it can only reason over one ontology."
        ],
        [
            "OK, so how does this?"
        ],
        [
            "Translate to approximating into outlook.",
            "Well, very quickly it.",
            "We have this theorem that tells us that thanks to the characteristics of L2 QL and to the properties which we saw earlier in order to compute the K approximation of an ontology of an L2 ontology into outlook, well, what you have to do is you have to compute the entailment set of each of the single sub ontologies obtained obtained by considering only K axioms at a time.",
            "And So what I was saying this holds for the two for the two properties which we saw.",
            "Earlier, which apply in the case about two QL."
        ],
        [
            "And just a quick observation, if we choose for K, then the number of accidents in the original ontology we actually have that the K approximation in L2 QL is unique, so there's only one, and it's exactly the same as its Entailments ET al.",
            "Two Q."
        ],
        [
            "So obviously the algorithm is very simple to compute the K proximation outlook.",
            "Will you just take the original teologi you divide it into a number of sub ontologies formed by K axioms.",
            "You compute the entailment set of each of these sub ontologies and you put them all together and you have your K approximation."
        ],
        [
            "OK, so we."
        ],
        [
            "And quite a number of experiments to see.",
            "Two things.",
            "First of all, how the GSA compares with the LSA and then to see how they both GSA an LSA compared to baseline approximation approach, which we implemented as a syntactic sound approximation, which basically takes the axioms of the original ontology, reformulates them in normalizes.",
            "I'm sorry, in accordance to L2 QL and then just disregards the axioms that are not compliant with the with LTE, so our experiments ran with that.",
            "I'm out of eight hours for each single approximation.",
            "We collected 41 ontologies from the Biorepository to test our techniques.",
            "And first of all, as we expected, the local semantic approximation is always computable, and it's always very fast, while the global semantic approximation was computable for 26 out of $41.00 an in blue.",
            "Here you can see the overall average results in terms of the number of entailments that are, so the percentage of entailments that are preserved.",
            "So in the first column we see that the global semantic approximation was able to preserve 80% of original of the entailments of the original ontologies.",
            "On average, the local semantic approximation is able to preserve.",
            "87% of the entailments of the global semantic approximations and the our baseline syntactic approximation was able to preserve, respectively, 72 and 90% of the entailments of the GSA in the LSA, and obviously, the GSA is much, much lower than than the local semantic approximation, which doesn't necessarily have to be a problem.",
            "'cause typically you can approximate just once in awhile.",
            "It doesn't necessarily have to be a runtime process, so these are the results for the 26 ontologies for which we were able to compute the GSA.",
            "For those 15 which we wish we weren't, so we only have the LSA we have that on average, so these are quite a large and complex ontologies.",
            "On average the LSA is able to maintain 72% of the axioms of the original theology and it computes on.",
            "In general, on average in less than a minute, about 51 seconds."
        ],
        [
            "OK, So what we want to take home from these experiments, essentially that both the global approach and the local approach can be useful.",
            "So the global approach gives us maximum sound approximation.",
            "For the majority of the ontologies which reset which we tested in reasonable time, so roughly about 2025 minutes on average.",
            "Of course there are exceptions, and in those exceptions we can rely on the local semantic approximation, which is able to preserve even for these very large or very complex otologists, quite a good portion of the entailments, as we saw 72% so and Lastly, both the local and the global stack up very well against the syntactic approach.",
            "The global is able to maintain.",
            "Almost 30% more of the entailments and the local 10% more, which may not seem like much, but actually for very large ontologies this can mean thousands and thousands of entailments that are preserved in the approximation and with very little overhead time.",
            "'cause as we saw the local semantic approximation is very very fast."
        ],
        [
            "On average.",
            "OK."
        ],
        [
            "So what are we working on now?",
            "We're developing techniques for effective approximation with values of K that are in between the local and the global, and to do this we are studying the integration of ontology model extraction techniques.",
            "We are also investigating cases in which it's useless to go beyond the local semantic approach because you're not going to imply anything else by reasoning over more than one axiom anytime.",
            "And Lastly, we're generalizing.",
            "We're generalizing our approach to an OBD scenario.",
            "Essentially we take the ontology and the ontology mappings in the target.",
            "Language and we use them to approximate the source ontology.",
            "So we're working with complete obiee specification and OK."
        ],
        [
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm literally and I'm here to present a joint work with Marco Concelhos Amara Ricardo Rosado.",
                    "label": 0
                },
                {
                    "sent": "Meaning of abuse of A at the Spencer University.",
                    "label": 0
                },
                {
                    "sent": "And the title once again is effective.",
                    "label": 0
                },
                {
                    "sent": "Computation of maximum sound approximations of description, logic, ontologies.",
                    "label": 1
                },
                {
                    "sent": "OK, so quick.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Duction generally ontologies can be used for many things, among them you can use them as a description of a domain of interest and when using them for this purpose you would like to have to use a very expressive language such As for example Al 2.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, if you use ontologies for reasoning, as we saw in the previous presentation, this use of these expressive languages can be a problem.",
                    "label": 1
                },
                {
                    "sent": "For example, in ontology based data access.",
                    "label": 0
                },
                {
                    "sent": "The computational cost of reasoning over languages such as L2 is prohibitive, so a good compromise here is the use of the use of approximation.",
                    "label": 1
                },
                {
                    "sent": "So the idea is to take an ontology expressed in a language and somehow reformulate it into an ontology expressed in a less expressive language.",
                    "label": 1
                },
                {
                    "sent": "With the goal to preserve as much as possible of the semantics of the of the array.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't argue so, in a certain sense, through approximation, we can perform reasoning over ontologies that were originally expressed in expressive languages.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we focused on mythology approximation for the purpose of ontology based data access.",
                    "label": 0
                },
                {
                    "sent": "And in this talk I'm going to give our definition of approximation of description logic ontologies.",
                    "label": 1
                },
                {
                    "sent": "I'm going to show how some techniques we have developed for approximating out to ontologies into our two QL, which as we saw earlier, is also is the data oriented profile of L2.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show some experimental valuation of these techniques.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to conclude with some future work which we are beginning to to undertake.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some very, very quick preliminaries.",
                    "label": 0
                },
                {
                    "sent": "This is actually.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alcohol I'm not going to get into the details since I'm sure many of you already know what we're talking about.",
                    "label": 0
                },
                {
                    "sent": "The one thing that I want to point out is that is a property about to call.",
                    "label": 1
                },
                {
                    "sent": "Actually is what we called the closed language, meaning that each set of out to quell axioms actually forms a proper outlook.",
                    "label": 1
                },
                {
                    "sent": "Well, ontology and this isn't always the case in description logics.",
                    "label": 0
                },
                {
                    "sent": "For example, DL 8 is not a close language, so we're going to see in the slides later on how this nice property of LTC is going to come in handy for us.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so our definition of approximation first of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this work actually follows in the footsteps of the work by Jeff on an Edward Thomas and here we're dealing with semantic approximation.",
                    "label": 0
                },
                {
                    "sent": "So when dealing with semantic approximation, you generally want two things you want.",
                    "label": 1
                },
                {
                    "sent": "You want soundness, meaning you want the approximation to produce only axioms that are entailed by the original dollars.",
                    "label": 0
                },
                {
                    "sent": "So you don't want anything new.",
                    "label": 0
                },
                {
                    "sent": "And you want to preserve as much as possible of the entailments of the original ontology.",
                    "label": 1
                },
                {
                    "sent": "Obviously all of those entailments that can be expressed in the target language, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Since in the following set I'm going to show you our definition, it's based on sets of models of the original Ontology Annex approximation.",
                    "label": 1
                },
                {
                    "sent": "So these two desiderata can be expressed in terms of soundness.",
                    "label": 0
                },
                {
                    "sent": "So we want the sets of models of the approximation to be a super set of the ones of the original apology and in terms of minimal change.",
                    "label": 1
                },
                {
                    "sent": "So we want to keep minimal distance in terms of sets of models between the original ontology and the approximation which we are compute.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is our definition of our notion of approximation of an ontology in a target language.",
                    "label": 1
                },
                {
                    "sent": "So we say that given a certain signature, a source ontology in a source language and target language, we see that an ontology is the global semantic approximation of the original ontology in the target language.",
                    "label": 0
                },
                {
                    "sent": "If these two conditions hold, so essentially the soundness condition, which is what I mentioned in the previous slide, and the minimal change condition which imposes that there is no other ontology in this case, so prime.",
                    "label": 0
                },
                {
                    "sent": "Who's sets of models include the ones of the original target, but are strictly included in the ones of the target ontology.",
                    "label": 0
                },
                {
                    "sent": "So once again, we don't want there to be another ontology that is closer to the original apology than the one we produced with the approximation.",
                    "label": 0
                },
                {
                    "sent": "So quick observation we denote with global APX to the set of all the global semantic approximations in the target language of the source ontology, and we're going to use this notation.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later on.",
                    "label": 0
                },
                {
                    "sent": "OK, so two properties here.",
                    "label": 0
                },
                {
                    "sent": "First of all, when does the global approximation exist?",
                    "label": 0
                },
                {
                    "sent": "So we have that if if the given a target language and signature of the ontology if the set of non equivalent axioms that can be generated over this signature in the target language is finished, then for any source language and any source ontology there is at least one ontology which it which is it's global semantic approximation.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also have that for.",
                    "label": 0
                },
                {
                    "sent": "For closed languages, for example outlook, we also which we saw earlier.",
                    "label": 0
                },
                {
                    "sent": "If we are approximating in these in the target language which is closed language, then for any two ontologies that belong to the set of approximations of a source ontology, we have that these two ontology are in fact logically equivalent, and we're going to see later on how these two properties help us in computing the approximation.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we know we have given a definition of global semantic approximation, but doesn't.",
                    "label": 0
                },
                {
                    "sent": "This doesn't really help us out in figuring out how to how to compute it.",
                    "label": 0
                },
                {
                    "sent": "So in order to move to a more constructive definition, we give a new definition based on the notion of entailment set an entailment that was introduced by by Jeff Pan and Edward Thomas in 2007, and essentially entailment, set of in ontology with respect to language.",
                    "label": 1
                },
                {
                    "sent": "Is the set of all the axioms that can be expressed in that language, and that are entailed by the ontology itself so.",
                    "label": 1
                },
                {
                    "sent": "We have this theorem which allows us to reformulate the soundness in the minimal change condition which we saw in the previous definition, and essentially it tells us that the soundness condition is verified if and only if the entailment set of the ontology that we produced through the approximation in the target language is included in the entailment set of the original ontology in that target language, and that the minimal change condition is satisfied.",
                    "label": 0
                },
                {
                    "sent": "If there is no other ontology.",
                    "label": 0
                },
                {
                    "sent": "In this case over Prime Prime, which is whose entailment set.",
                    "label": 0
                },
                {
                    "sent": "Is strictly includes the one we compute through the approximation, so OT and is itself included in the entailment set of the original anthology.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have we we we know that to compute the global semantic approximation we can use the.",
                    "label": 0
                },
                {
                    "sent": "We can use the entailment set, which we know how to compute.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is great, but actually computing the entailment set is quite hard in general for very large or very complex ontologies expressed in very expressive language is this isn't always possible, with the reasons that are currently at our disposal.",
                    "label": 0
                },
                {
                    "sent": "So why is this?",
                    "label": 0
                },
                {
                    "sent": "Is this because in order to compute the entailment set, you have to reason over the whole ontology at once.",
                    "label": 1
                },
                {
                    "sent": "So our idea was instead of trying to reason over the whole ontology, let's just reason over portions of it at a time and then put together what we get from each of these single single steps.",
                    "label": 1
                },
                {
                    "sent": "And so we came up with this notion of K approximation, where this parameter K is.",
                    "label": 0
                },
                {
                    "sent": "Essentially, it gives us the number of axioms which we reason over at a time, and so we were able to compute the approximation by computing the global semantic approximation of each week and say sub ontology formed by K axioms.",
                    "label": 1
                },
                {
                    "sent": "Of the original ontology in isolation.",
                    "label": 0
                },
                {
                    "sent": "And then we put them all together and we obtain our approximation.",
                    "label": 0
                },
                {
                    "sent": "We obtained the K approximation.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the definition of K approximation.",
                    "label": 0
                },
                {
                    "sent": "As you can see, it's very very similar to the one we saw earlier for global semantic approximation.",
                    "label": 0
                },
                {
                    "sent": "The only difference is that instead of comparing the set of models of of the target ontology to the ones of the original ontology, we're comparing them to the.",
                    "label": 0
                },
                {
                    "sent": "The intersection of the models of the global semantic approximations of each of these smaller ontologies formed by K axioms.",
                    "label": 0
                },
                {
                    "sent": "So the soundness and minimal change condition remained the same.",
                    "label": 0
                },
                {
                    "sent": "The only difference is is this.",
                    "label": 0
                },
                {
                    "sent": "So instead of using the models of the original apology, we use the models of the intersection of the models of the global semantic approximations of each sub ontology.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we have studied two significant cases for ontology approximation for K approximation.",
                    "label": 1
                },
                {
                    "sent": "Sorry, so the one in which K assumes its largest possible value, which is the number of axioms in the original ontology and the one in which assumes its smallest possible value, which is obviously One South 4K which equals to the number of actions in the original ontology.",
                    "label": 0
                },
                {
                    "sent": "We have.",
                    "label": 0
                },
                {
                    "sent": "The key approximation is exactly identical to the global semantic approximation, so you reason over the ontology.",
                    "label": 0
                },
                {
                    "sent": "At once and you get your approximation.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, if you choose K = 1, then essentially your reasoning over one axiom of the original apology at a time, and we call this local semantic approximation.",
                    "label": 0
                },
                {
                    "sent": "So two edges of this K, parametric approximation, GSA and LSA.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obviously, global semantic approximation is going to give you a better approximation than the local semantic one, but as we as I said earlier, it's not always possible for very large ontologies.",
                    "label": 0
                },
                {
                    "sent": "So for example, here we have the end original ontology.",
                    "label": 0
                },
                {
                    "sent": "We say we have that A is included in B or C and that be is included in dianbai reasoning over both these these axioms, the ontology obtained through GSA, is able to preserve that AIDS included.",
                    "label": 0
                },
                {
                    "sent": "Indeed, while the ontology obtained through LSA is going to lose this this entailment because it can only reason over one ontology.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how does this?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Translate to approximating into outlook.",
                    "label": 0
                },
                {
                    "sent": "Well, very quickly it.",
                    "label": 0
                },
                {
                    "sent": "We have this theorem that tells us that thanks to the characteristics of L2 QL and to the properties which we saw earlier in order to compute the K approximation of an ontology of an L2 ontology into outlook, well, what you have to do is you have to compute the entailment set of each of the single sub ontologies obtained obtained by considering only K axioms at a time.",
                    "label": 0
                },
                {
                    "sent": "And So what I was saying this holds for the two for the two properties which we saw.",
                    "label": 0
                },
                {
                    "sent": "Earlier, which apply in the case about two QL.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just a quick observation, if we choose for K, then the number of accidents in the original ontology we actually have that the K approximation in L2 QL is unique, so there's only one, and it's exactly the same as its Entailments ET al.",
                    "label": 0
                },
                {
                    "sent": "Two Q.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So obviously the algorithm is very simple to compute the K proximation outlook.",
                    "label": 0
                },
                {
                    "sent": "Will you just take the original teologi you divide it into a number of sub ontologies formed by K axioms.",
                    "label": 0
                },
                {
                    "sent": "You compute the entailment set of each of these sub ontologies and you put them all together and you have your K approximation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And quite a number of experiments to see.",
                    "label": 0
                },
                {
                    "sent": "Two things.",
                    "label": 0
                },
                {
                    "sent": "First of all, how the GSA compares with the LSA and then to see how they both GSA an LSA compared to baseline approximation approach, which we implemented as a syntactic sound approximation, which basically takes the axioms of the original ontology, reformulates them in normalizes.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, in accordance to L2 QL and then just disregards the axioms that are not compliant with the with LTE, so our experiments ran with that.",
                    "label": 0
                },
                {
                    "sent": "I'm out of eight hours for each single approximation.",
                    "label": 0
                },
                {
                    "sent": "We collected 41 ontologies from the Biorepository to test our techniques.",
                    "label": 0
                },
                {
                    "sent": "And first of all, as we expected, the local semantic approximation is always computable, and it's always very fast, while the global semantic approximation was computable for 26 out of $41.00 an in blue.",
                    "label": 0
                },
                {
                    "sent": "Here you can see the overall average results in terms of the number of entailments that are, so the percentage of entailments that are preserved.",
                    "label": 0
                },
                {
                    "sent": "So in the first column we see that the global semantic approximation was able to preserve 80% of original of the entailments of the original ontologies.",
                    "label": 0
                },
                {
                    "sent": "On average, the local semantic approximation is able to preserve.",
                    "label": 0
                },
                {
                    "sent": "87% of the entailments of the global semantic approximations and the our baseline syntactic approximation was able to preserve, respectively, 72 and 90% of the entailments of the GSA in the LSA, and obviously, the GSA is much, much lower than than the local semantic approximation, which doesn't necessarily have to be a problem.",
                    "label": 0
                },
                {
                    "sent": "'cause typically you can approximate just once in awhile.",
                    "label": 0
                },
                {
                    "sent": "It doesn't necessarily have to be a runtime process, so these are the results for the 26 ontologies for which we were able to compute the GSA.",
                    "label": 0
                },
                {
                    "sent": "For those 15 which we wish we weren't, so we only have the LSA we have that on average, so these are quite a large and complex ontologies.",
                    "label": 0
                },
                {
                    "sent": "On average the LSA is able to maintain 72% of the axioms of the original theology and it computes on.",
                    "label": 0
                },
                {
                    "sent": "In general, on average in less than a minute, about 51 seconds.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what we want to take home from these experiments, essentially that both the global approach and the local approach can be useful.",
                    "label": 0
                },
                {
                    "sent": "So the global approach gives us maximum sound approximation.",
                    "label": 0
                },
                {
                    "sent": "For the majority of the ontologies which reset which we tested in reasonable time, so roughly about 2025 minutes on average.",
                    "label": 1
                },
                {
                    "sent": "Of course there are exceptions, and in those exceptions we can rely on the local semantic approximation, which is able to preserve even for these very large or very complex otologists, quite a good portion of the entailments, as we saw 72% so and Lastly, both the local and the global stack up very well against the syntactic approach.",
                    "label": 0
                },
                {
                    "sent": "The global is able to maintain.",
                    "label": 0
                },
                {
                    "sent": "Almost 30% more of the entailments and the local 10% more, which may not seem like much, but actually for very large ontologies this can mean thousands and thousands of entailments that are preserved in the approximation and with very little overhead time.",
                    "label": 1
                },
                {
                    "sent": "'cause as we saw the local semantic approximation is very very fast.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On average.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are we working on now?",
                    "label": 0
                },
                {
                    "sent": "We're developing techniques for effective approximation with values of K that are in between the local and the global, and to do this we are studying the integration of ontology model extraction techniques.",
                    "label": 0
                },
                {
                    "sent": "We are also investigating cases in which it's useless to go beyond the local semantic approach because you're not going to imply anything else by reasoning over more than one axiom anytime.",
                    "label": 0
                },
                {
                    "sent": "And Lastly, we're generalizing.",
                    "label": 0
                },
                {
                    "sent": "We're generalizing our approach to an OBD scenario.",
                    "label": 1
                },
                {
                    "sent": "Essentially we take the ontology and the ontology mappings in the target.",
                    "label": 1
                },
                {
                    "sent": "Language and we use them to approximate the source ontology.",
                    "label": 0
                },
                {
                    "sent": "So we're working with complete obiee specification and OK.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}