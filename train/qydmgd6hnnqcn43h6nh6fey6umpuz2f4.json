{
    "id": "qydmgd6hnnqcn43h6nh6fey6umpuz2f4",
    "title": "Learning to Distinguish Valid Textual Entailments",
    "info": {
        "author": [
            "Marie-Catherine de Marneffe, Stanford University"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "April 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Human Language Technology",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/pcw06_marneffe_ldvte/",
    "segmentation": [
        [
            "America trend among listen I'm going to prison.",
            "Stanford entry in this year competition.",
            "So there have been three approaches to RT so."
        ],
        [
            "Far World overlap models, logical approach is an in between graph matching approaches and the system of Stanford is focusing of this on this type of approach.",
            "So as you already know."
        ],
        [
            "So in the graph matching approach, we try to represent sentences as type dependency trees and then we find a Locust alignment between the two graphs.",
            "So here if we have a stack stroke install, just released their lives in today's ambush and in the hypothesis several troops were killed in their hand in the ambush, we hope that will align Ambusher, ambush the troops with soldier, the verb last laugh, with killed, an starting with several or several with working.",
            "And here you can see that the grammatical structure of both the text and the hypothesis are required.",
            "Similar when when we try to align with.",
            "Also we take account of the world themselves and also the structure of the trees.",
            "But if you want to get right a lot of examples we need to allow so sloppy matching in respect of the structure of the sentences.",
            "So if you look at this example, today's best estimate of giant panda numbers in the wild is about 1100 individuals living in up to 32 separate population, mostly in China.",
            "So it's I'm lost, blah blah blah.",
            "And the hypothesis is there are about 1100 pandas in the wild in China."
        ],
        [
            "You see that you need to have sloppy matching in the structure of the sentence.",
            "However, as Vasily pointed out, there is a problem with three matching.",
            "If you look at this example deley both anyone stock and Clinton Salton, one stop, and the hypothesis is deley sold and one stop, what will happen in the graph matching system will align deley with deley, both with sold, maybe an one with Enron and stock with stock and."
        ],
        [
            "We do that will say that the hypothesis is entailed, which is not the case.",
            "So we want to give a high cost to both and salt, which are antonyms to not have this this problem.",
            "But remember that we are embedded in a search for a low cost alignment.",
            "So what will happen if we have a high cost between board and sword?",
            "And we have sloppy matching.",
            "The lucky alignment that will get is dealing with delays sold with salt and one with anyone and stock with stock here.",
            "And again will say that this isn't tape.",
            "So what we try to do?"
        ],
        [
            "This to solve this problem is first to align and then to evaluate the alignment we get.",
            "So will and deliver deley both with salt and one with anyone.",
            "Stop with stock and then say oops, here we have antonyms in both positive context.",
            "So this is not leading to an entailment between the hypothesis and the text.",
            "So think we."
        ],
        [
            "To fix in this system is first the confounding of alignment, an entailment which I just show.",
            "Also, the assumption of monotonicity in the graph matching system we assume upon monotonicity.",
            "However, if we have the text, Sue Solum is arrive in London and the hypothesis Sue Solomon to Rob this is true, but then if you look at the other one below, the largest missile base in Asia is there jumping missile testing wrong in Taiwan with the following hypothesis, the largest missile base in the is the jumping missile.",
            "Testing wrong in Taiwan.",
            "Then this is not entered.",
            "However, a graph matching system will say that this is true.",
            "And just the third problem is the assumption of locality, which is done in graph matching system."
        ],
        [
            "However, if the alignment is good or not depends on local factors.",
            "So if you look at example one.",
            "Some students came to school by car.",
            "Did any students come to school?",
            "This is true.",
            "In the second one, no students came to school by car.",
            "Did any student come to school, which is exactly the same question or hypothesis.",
            "We don't know whether it's true or not.",
            "So here to see if it's OK to delete by car in the question.",
            "We it depends on the subject quantifier in the text.",
            "And so I know the nonlocal.",
            "Feature is for example, in the first sentences it is not the case that bin Laden was seen in Tora Bora with the following question was bin Laden seen in terebra?",
            "What will happen in a graph matching system will align bin Laden with bin Laden seen with seeing trouble with Tora Bora.",
            "We said that this is entailed.",
            "However we do not take account of the non factive context.",
            "It is not the case that.",
            "So what we propose is a priest."
        ],
        [
            "Each architecture in our system first will annotate semantic graphs or transforming both the hypothesis and the text into semantic graphs.",
            "Then align the two graphs, and in the third step to decide whether the hypothesis graph is entailed by the next graph.",
            "So step one is the linguistic."
        ],
        [
            "Dictation, so we do name entity recognition.",
            "We also try to do some canonicalization of quantity, date and money expression.",
            "So we normalize dates and we are also able, in a certain way to deal with relational expressions of amount.",
            "So in the following example example, Kecerovce team conducted 60,643 face to face interviews with adults in 14 countries and the hypothesis is Kessler steam interviewed more than 60,000 others in 14 countries.",
            "We had both to say that more than 60,000 is entailed by 60,643.",
            "We also do some any Aaron collocation collapsing so George Bush will be identified as just one token carried out also.",
            "So the collocation comes from come from work net.",
            "We do, of course, for structure and type dependency parsing with Stanford parser and from Stanford parser.",
            "We also get the dependencies.",
            "We do coreference resolution and we have TF IDF scores for the words in the sentences.",
            "In the second step, then."
        ],
        [
            "Allowing the hypothesis graph an into the text graph using all the information which is available from the first step, and then lexical resources which give us similarity between pairs of world.",
            "We are using word net inform app which is doing Latin semantic analysis.",
            "Some string overlaps and gazetteer.",
            "So for example we have a handmade list of acronyms, acronyms and their expansion.",
            "We have also list.",
            "Between the name of people and the country.",
            "So for example French, France, Belgium, Belgian bedroom, etc.",
            "We also use distribute itional similarity scores.",
            "And so the third step."
        ],
        [
            "Is really the moment where we decide whether the text, the hypothesis or is entailed by the text or not.",
            "So we compute Special Edge feature like the one I show for antonym.",
            "We also look from negation.",
            "We do quantification and numeric mismatch and also we have some more linguistic features that I will describe further.",
            "And we use machine learning techniques to assign a weight for the semantic features in our system.",
            "We are using logistic regression, so actually we have two ways to set the way one is using the machine learning technique and the other one is just using a handset weight that we just said by linguistic intuition.",
            "So here this this is an exam."
        ],
        [
            "To show you how the system is working.",
            "So let's say that we have as tax Mitsubishi Motor Corporation new vehicle sales in the USV 46 person in June.",
            "And the hypothesis is which we see sales rose 46 person, you have the dependency graph for the hypothesis, then the alignment between the hypothesis and the text will be the following one.",
            "Rose will align with Fell Mitsubishi, still with sales.",
            "Soaring Mitsubishi with Mitsubishi Motors Corporation which is a name entity.",
            "Recognized posting with person 4656.",
            "This give us an alignment score which is quite good.",
            "And then we extract some features so we discover that we have a long antonym Rosenfeld, both in positive contexts, which is a negative feature will also extract some structural features, and we look here at the grammatical structure of the sentence, and here they are almost the same, so that's OK. Numeric quantity matches Quantity 46 Match 46.",
            "We discovered that we have a date missing in the hypothesis from the text in June has been deleted in the hypothesis, which is not OK, and the alignment score is good, which is a positive features and from those features with the weight we have assigned to them, we get an infant score and if this score is below a threshold, then we say that the hypothesis is not entailed.",
            "By the text.",
            "And here it was correct."
        ],
        [
            "So what are the more linguistic features that we have?",
            "So we have some structural mismatch feature or match features.",
            "So in this example I'm in Egypt, attacked the threat to bring the issue of Iran's nuclear activity to the UN Security Council.",
            "And the hypothesis is a managed attack.",
            "the UN Security Council will discover that the the object in the text and in the hypothesis have nothing to do with one another, and this is not OK.",
            "So we check the main predicate of the hypothesis with the match in the text to assess compatibility using grammatical relations.",
            "Another kind of features we have is modality feature, so."
        ],
        [
            "Text here is the script C has a range of 500 kilometers.",
            "And the hypothesis is as good.",
            "She can fly 500 kilometers.",
            "What we do is to map both the text and the hypothesis into six Canonical modalities possible.",
            "Not possible actual not actually necessary, not necessary.",
            "Using some linguistic words present in the sentences.",
            "So for example can perhaps might will be mapped to possible.",
            "And then we have so a pair of.",
            "Modalities and we have rules to map this modality pair into a judgment feature.",
            "So here, for example, the text is actually the hypothesis is possible and we say, OK, that's a positive feature front element.",
            "We also have features dealing with restrictive agents."
        ],
        [
            "So if the text is in all Zurich, boat 422 million dollar worlds of all from Iraq, according to the Volcker Committee, an hypothesis is Zurich Bolt oil from Iraq during the embargo.",
            "The addition of during the embargo here doesn't lead to an entailment.",
            "In the following example.",
            "Zurich didn't buy.",
            "Any oil from Iraq, according to the Worker Committee hypothesis zero he didn't buy oil from Iraq during the embargo this time.",
            "This is true the addition of during the embargo.",
            "It's OK with the entertainment and so we can check whether adding or dropping restrictive aging is licensed relative to abroad and don't work and then context."
        ],
        [
            "Another kind of features is factive, an implicative features.",
            "Scientists have discovered that drinking tea protects against heart disease by improving the function of the artery walls, and the hypothesis is T protects from some disease, which is true.",
            "So what do we do?",
            "We evaluate governing verbs for implicatively class, so we have a handmade list of verbs put in some category, like say, Taylor Swift.",
            "Try, you don't really know if what follows is true or not.",
            "We have fact known and acknowledged in your so if you said, I acknowledge that blah blah blah blah is probably probably true, but you don't really know.",
            "Managed to this is true force failed to forget to so this refers to what Sander was explaining with the park people.",
            "And here we also need to check for negative context to which we do.",
            "So for example, if you say.",
            "Chris failed to attend a meeting at the meeting.",
            "You know that this is not true.",
            "But if you say Chris didn't fail to attend the meeting, then it's true that Chris attending the meeting.",
            "So."
        ],
        [
            "Our results are the following, so we don't really beat the baseline.",
            "So here we have the.",
            "The reason for the 82 deaths set with the handset weight and the learned weights.",
            "Accuracy and average precision and here are the results for the test set with handset weights and learned weights.",
            "And then post hoc ablation studies on 32.",
            "Beth said data showed on the features that we use showed that using the structure features are very important.",
            "Using the modality feature help a little bit, but then using the antonymy adjunct and factivity feature done really help, but that was done only on RT2.",
            "Def set data.",
            "And so for the for running the system on the test set, we use as training data 31 def set one only the first part of 31.",
            "And of course all the test.",
            "Set the development set of 32."
        ],
        [
            "So the program region speaks is identification of some structural mismatches.",
            "So, for example, ingredients lawyer or Lex Lasry told blah blah blah and then the hypothesis is angry and is a lawyer.",
            "We should be able to identify that this is not true.",
            "We also hope to be able to handle computation.",
            "This is good news for garlic translator as the EU will have to turn out official documents in this language in addition to the 20 other official EU languages.",
            "And the hypothesis is there are 21 official EU languages we should be able to.",
            "To see that this language plus 20 and Tails 21.",
            "Another thing we can fix in the alignment step, what I just saw is error."
        ],
        [
            "In the.",
            "Third step in the.",
            "And Penguin step.",
            "And here in the second step, when we align we should be able to do a better job in aligning number with respect to the sentence of the structure of the sentence.",
            "The sentence structure.",
            "Sorry, some 420 people have been hanged in Singapore sings 19191.",
            "That gives the country of 4.4 million people the highest execution rate in the world relative to population and the hypothesis.",
            "Is 44 million people were executed in Singapore right now?",
            "We are aligning for that 4 million with 44 million and then of course we don't discover that there is a mismatch in the number.",
            "And if here we had a less sloppy matching will be able to see that there is a mismatch between 4.4 and 420.",
            "Madame March and enjoy."
        ],
        [
            "Problems that right now we are not able to fix.",
            "As somebody pointed out earlier, none team and is really easier to find a non payment.",
            "So I think we are good at finding knockout features but it's really hard to be certain that we've considered everything.",
            "Also, the fact of dealing with dropping and adding modifiers versus the acquired and don't want on telling context is really hard because actually we need to know which are restrictive or not of disco items, so more it was subsequently killed in Angola as an example.",
            "And then everybody agrees.",
            "We really need multi work, lexical semantics or world knowledge.",
            "We are good at synonym, Hyponyms and antonyms.",
            "But we are not able to solve multi world equivalences and we have a lot of those in the data.",
            "David Mccool took the money and decided to start Music Lane in 2002.",
            "Hypothesis, David Mccool is the founder of Mozilla Lane.",
            "We should be able to know that to be the founder.",
            "Off is to decide to start something I didn't put here.",
            "All the.",
            "Doors kind of multiworld lexical knowledge that is required for a few data, but there are a lot of examples of this sort, so I hope that in the future, as maybe everybody is collaborating, will be able to build some huge lexical semantics resources.",
            "I think.",
            "Sandra, deregulation settings can be separated out between both syntactic features that positives and negatives.",
            "Interesting how she started to do this is our system.",
            "Set up.",
            "It will be raining at the base.",
            "Yeah will be.",
            "Yeah we are able to do it, but I didn't do it now, but it's it's easy to implement and to do, yeah.",
            "That would be interesting to see, but once one thing was which was interesting, is that almost.",
            "All the time.",
            "Derm Hunt said it, wait that we had correspond roughly to the to the long one.",
            "Other questions.",
            "How many differences?",
            "Just cause.",
            "Components.",
            "Do you mean the propagation of errors between them entities and then the bars and?",
            "Why did you sleep in that moment?",
            "What is Roman Catholic Church program?",
            "Or is it kind of got us?",
            "Classification.",
            "But for example, one thing we identified after the challenge is for the fact if features the classification we have is.",
            "Maybe in some sense.",
            "Maybe it's too fine, and in another sense, maybe it's not finding enough because we have like a lot of examples.",
            "We could just like a report he said that.",
            "And then here the fact that it's true or false depending on the authority who said that fact and so.",
            "But then again you need some work knowledge too.",
            "To identify those classes, but maybe if we had another class for those specific reports, verbs.",
            "We had run a a better wait for those for those verbs, for example, so factivity actually we had.",
            "If we don't use activity features, we have a better score in this data, but which was not the case on LT1 data for example.",
            "So I think it really varies and depends on the data, but it's certain that there there is propagation of errors and in the system, but it's hard to identify and we have to do a very very constrained error analysis to identify exactly which.",
            "Items sports have problems.",
            "No, we did.",
            "We did that by hand.",
            "We use a little bit of the the idea of the idea come from from parks as some dimension it, but then we have like a hand build list of verbs, an informed modalities to like the linguistic words.",
            "It's just hundreds.",
            "So we missed a lot maybe."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "America trend among listen I'm going to prison.",
                    "label": 0
                },
                {
                    "sent": "Stanford entry in this year competition.",
                    "label": 0
                },
                {
                    "sent": "So there have been three approaches to RT so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Far World overlap models, logical approach is an in between graph matching approaches and the system of Stanford is focusing of this on this type of approach.",
                    "label": 0
                },
                {
                    "sent": "So as you already know.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the graph matching approach, we try to represent sentences as type dependency trees and then we find a Locust alignment between the two graphs.",
                    "label": 1
                },
                {
                    "sent": "So here if we have a stack stroke install, just released their lives in today's ambush and in the hypothesis several troops were killed in their hand in the ambush, we hope that will align Ambusher, ambush the troops with soldier, the verb last laugh, with killed, an starting with several or several with working.",
                    "label": 1
                },
                {
                    "sent": "And here you can see that the grammatical structure of both the text and the hypothesis are required.",
                    "label": 0
                },
                {
                    "sent": "Similar when when we try to align with.",
                    "label": 0
                },
                {
                    "sent": "Also we take account of the world themselves and also the structure of the trees.",
                    "label": 0
                },
                {
                    "sent": "But if you want to get right a lot of examples we need to allow so sloppy matching in respect of the structure of the sentences.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this example, today's best estimate of giant panda numbers in the wild is about 1100 individuals living in up to 32 separate population, mostly in China.",
                    "label": 0
                },
                {
                    "sent": "So it's I'm lost, blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "And the hypothesis is there are about 1100 pandas in the wild in China.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see that you need to have sloppy matching in the structure of the sentence.",
                    "label": 0
                },
                {
                    "sent": "However, as Vasily pointed out, there is a problem with three matching.",
                    "label": 0
                },
                {
                    "sent": "If you look at this example deley both anyone stock and Clinton Salton, one stop, and the hypothesis is deley sold and one stop, what will happen in the graph matching system will align deley with deley, both with sold, maybe an one with Enron and stock with stock and.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do that will say that the hypothesis is entailed, which is not the case.",
                    "label": 0
                },
                {
                    "sent": "So we want to give a high cost to both and salt, which are antonyms to not have this this problem.",
                    "label": 0
                },
                {
                    "sent": "But remember that we are embedded in a search for a low cost alignment.",
                    "label": 0
                },
                {
                    "sent": "So what will happen if we have a high cost between board and sword?",
                    "label": 0
                },
                {
                    "sent": "And we have sloppy matching.",
                    "label": 0
                },
                {
                    "sent": "The lucky alignment that will get is dealing with delays sold with salt and one with anyone and stock with stock here.",
                    "label": 0
                },
                {
                    "sent": "And again will say that this isn't tape.",
                    "label": 0
                },
                {
                    "sent": "So what we try to do?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This to solve this problem is first to align and then to evaluate the alignment we get.",
                    "label": 0
                },
                {
                    "sent": "So will and deliver deley both with salt and one with anyone.",
                    "label": 0
                },
                {
                    "sent": "Stop with stock and then say oops, here we have antonyms in both positive context.",
                    "label": 1
                },
                {
                    "sent": "So this is not leading to an entailment between the hypothesis and the text.",
                    "label": 0
                },
                {
                    "sent": "So think we.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To fix in this system is first the confounding of alignment, an entailment which I just show.",
                    "label": 0
                },
                {
                    "sent": "Also, the assumption of monotonicity in the graph matching system we assume upon monotonicity.",
                    "label": 0
                },
                {
                    "sent": "However, if we have the text, Sue Solum is arrive in London and the hypothesis Sue Solomon to Rob this is true, but then if you look at the other one below, the largest missile base in Asia is there jumping missile testing wrong in Taiwan with the following hypothesis, the largest missile base in the is the jumping missile.",
                    "label": 1
                },
                {
                    "sent": "Testing wrong in Taiwan.",
                    "label": 0
                },
                {
                    "sent": "Then this is not entered.",
                    "label": 0
                },
                {
                    "sent": "However, a graph matching system will say that this is true.",
                    "label": 0
                },
                {
                    "sent": "And just the third problem is the assumption of locality, which is done in graph matching system.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, if the alignment is good or not depends on local factors.",
                    "label": 0
                },
                {
                    "sent": "So if you look at example one.",
                    "label": 0
                },
                {
                    "sent": "Some students came to school by car.",
                    "label": 0
                },
                {
                    "sent": "Did any students come to school?",
                    "label": 0
                },
                {
                    "sent": "This is true.",
                    "label": 0
                },
                {
                    "sent": "In the second one, no students came to school by car.",
                    "label": 0
                },
                {
                    "sent": "Did any student come to school, which is exactly the same question or hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We don't know whether it's true or not.",
                    "label": 0
                },
                {
                    "sent": "So here to see if it's OK to delete by car in the question.",
                    "label": 0
                },
                {
                    "sent": "We it depends on the subject quantifier in the text.",
                    "label": 0
                },
                {
                    "sent": "And so I know the nonlocal.",
                    "label": 0
                },
                {
                    "sent": "Feature is for example, in the first sentences it is not the case that bin Laden was seen in Tora Bora with the following question was bin Laden seen in terebra?",
                    "label": 1
                },
                {
                    "sent": "What will happen in a graph matching system will align bin Laden with bin Laden seen with seeing trouble with Tora Bora.",
                    "label": 0
                },
                {
                    "sent": "We said that this is entailed.",
                    "label": 0
                },
                {
                    "sent": "However we do not take account of the non factive context.",
                    "label": 0
                },
                {
                    "sent": "It is not the case that.",
                    "label": 0
                },
                {
                    "sent": "So what we propose is a priest.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each architecture in our system first will annotate semantic graphs or transforming both the hypothesis and the text into semantic graphs.",
                    "label": 1
                },
                {
                    "sent": "Then align the two graphs, and in the third step to decide whether the hypothesis graph is entailed by the next graph.",
                    "label": 0
                },
                {
                    "sent": "So step one is the linguistic.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dictation, so we do name entity recognition.",
                    "label": 0
                },
                {
                    "sent": "We also try to do some canonicalization of quantity, date and money expression.",
                    "label": 1
                },
                {
                    "sent": "So we normalize dates and we are also able, in a certain way to deal with relational expressions of amount.",
                    "label": 1
                },
                {
                    "sent": "So in the following example example, Kecerovce team conducted 60,643 face to face interviews with adults in 14 countries and the hypothesis is Kessler steam interviewed more than 60,000 others in 14 countries.",
                    "label": 1
                },
                {
                    "sent": "We had both to say that more than 60,000 is entailed by 60,643.",
                    "label": 0
                },
                {
                    "sent": "We also do some any Aaron collocation collapsing so George Bush will be identified as just one token carried out also.",
                    "label": 0
                },
                {
                    "sent": "So the collocation comes from come from work net.",
                    "label": 0
                },
                {
                    "sent": "We do, of course, for structure and type dependency parsing with Stanford parser and from Stanford parser.",
                    "label": 0
                },
                {
                    "sent": "We also get the dependencies.",
                    "label": 0
                },
                {
                    "sent": "We do coreference resolution and we have TF IDF scores for the words in the sentences.",
                    "label": 0
                },
                {
                    "sent": "In the second step, then.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Allowing the hypothesis graph an into the text graph using all the information which is available from the first step, and then lexical resources which give us similarity between pairs of world.",
                    "label": 1
                },
                {
                    "sent": "We are using word net inform app which is doing Latin semantic analysis.",
                    "label": 0
                },
                {
                    "sent": "Some string overlaps and gazetteer.",
                    "label": 0
                },
                {
                    "sent": "So for example we have a handmade list of acronyms, acronyms and their expansion.",
                    "label": 0
                },
                {
                    "sent": "We have also list.",
                    "label": 0
                },
                {
                    "sent": "Between the name of people and the country.",
                    "label": 0
                },
                {
                    "sent": "So for example French, France, Belgium, Belgian bedroom, etc.",
                    "label": 1
                },
                {
                    "sent": "We also use distribute itional similarity scores.",
                    "label": 0
                },
                {
                    "sent": "And so the third step.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is really the moment where we decide whether the text, the hypothesis or is entailed by the text or not.",
                    "label": 0
                },
                {
                    "sent": "So we compute Special Edge feature like the one I show for antonym.",
                    "label": 0
                },
                {
                    "sent": "We also look from negation.",
                    "label": 0
                },
                {
                    "sent": "We do quantification and numeric mismatch and also we have some more linguistic features that I will describe further.",
                    "label": 0
                },
                {
                    "sent": "And we use machine learning techniques to assign a weight for the semantic features in our system.",
                    "label": 1
                },
                {
                    "sent": "We are using logistic regression, so actually we have two ways to set the way one is using the machine learning technique and the other one is just using a handset weight that we just said by linguistic intuition.",
                    "label": 1
                },
                {
                    "sent": "So here this this is an exam.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To show you how the system is working.",
                    "label": 0
                },
                {
                    "sent": "So let's say that we have as tax Mitsubishi Motor Corporation new vehicle sales in the USV 46 person in June.",
                    "label": 1
                },
                {
                    "sent": "And the hypothesis is which we see sales rose 46 person, you have the dependency graph for the hypothesis, then the alignment between the hypothesis and the text will be the following one.",
                    "label": 0
                },
                {
                    "sent": "Rose will align with Fell Mitsubishi, still with sales.",
                    "label": 0
                },
                {
                    "sent": "Soaring Mitsubishi with Mitsubishi Motors Corporation which is a name entity.",
                    "label": 0
                },
                {
                    "sent": "Recognized posting with person 4656.",
                    "label": 0
                },
                {
                    "sent": "This give us an alignment score which is quite good.",
                    "label": 0
                },
                {
                    "sent": "And then we extract some features so we discover that we have a long antonym Rosenfeld, both in positive contexts, which is a negative feature will also extract some structural features, and we look here at the grammatical structure of the sentence, and here they are almost the same, so that's OK. Numeric quantity matches Quantity 46 Match 46.",
                    "label": 0
                },
                {
                    "sent": "We discovered that we have a date missing in the hypothesis from the text in June has been deleted in the hypothesis, which is not OK, and the alignment score is good, which is a positive features and from those features with the weight we have assigned to them, we get an infant score and if this score is below a threshold, then we say that the hypothesis is not entailed.",
                    "label": 0
                },
                {
                    "sent": "By the text.",
                    "label": 0
                },
                {
                    "sent": "And here it was correct.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the more linguistic features that we have?",
                    "label": 0
                },
                {
                    "sent": "So we have some structural mismatch feature or match features.",
                    "label": 0
                },
                {
                    "sent": "So in this example I'm in Egypt, attacked the threat to bring the issue of Iran's nuclear activity to the UN Security Council.",
                    "label": 1
                },
                {
                    "sent": "And the hypothesis is a managed attack.",
                    "label": 0
                },
                {
                    "sent": "the UN Security Council will discover that the the object in the text and in the hypothesis have nothing to do with one another, and this is not OK.",
                    "label": 1
                },
                {
                    "sent": "So we check the main predicate of the hypothesis with the match in the text to assess compatibility using grammatical relations.",
                    "label": 0
                },
                {
                    "sent": "Another kind of features we have is modality feature, so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Text here is the script C has a range of 500 kilometers.",
                    "label": 1
                },
                {
                    "sent": "And the hypothesis is as good.",
                    "label": 1
                },
                {
                    "sent": "She can fly 500 kilometers.",
                    "label": 0
                },
                {
                    "sent": "What we do is to map both the text and the hypothesis into six Canonical modalities possible.",
                    "label": 0
                },
                {
                    "sent": "Not possible actual not actually necessary, not necessary.",
                    "label": 1
                },
                {
                    "sent": "Using some linguistic words present in the sentences.",
                    "label": 0
                },
                {
                    "sent": "So for example can perhaps might will be mapped to possible.",
                    "label": 1
                },
                {
                    "sent": "And then we have so a pair of.",
                    "label": 0
                },
                {
                    "sent": "Modalities and we have rules to map this modality pair into a judgment feature.",
                    "label": 0
                },
                {
                    "sent": "So here, for example, the text is actually the hypothesis is possible and we say, OK, that's a positive feature front element.",
                    "label": 0
                },
                {
                    "sent": "We also have features dealing with restrictive agents.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if the text is in all Zurich, boat 422 million dollar worlds of all from Iraq, according to the Volcker Committee, an hypothesis is Zurich Bolt oil from Iraq during the embargo.",
                    "label": 1
                },
                {
                    "sent": "The addition of during the embargo here doesn't lead to an entailment.",
                    "label": 0
                },
                {
                    "sent": "In the following example.",
                    "label": 0
                },
                {
                    "sent": "Zurich didn't buy.",
                    "label": 0
                },
                {
                    "sent": "Any oil from Iraq, according to the Worker Committee hypothesis zero he didn't buy oil from Iraq during the embargo this time.",
                    "label": 1
                },
                {
                    "sent": "This is true the addition of during the embargo.",
                    "label": 0
                },
                {
                    "sent": "It's OK with the entertainment and so we can check whether adding or dropping restrictive aging is licensed relative to abroad and don't work and then context.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another kind of features is factive, an implicative features.",
                    "label": 0
                },
                {
                    "sent": "Scientists have discovered that drinking tea protects against heart disease by improving the function of the artery walls, and the hypothesis is T protects from some disease, which is true.",
                    "label": 1
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We evaluate governing verbs for implicatively class, so we have a handmade list of verbs put in some category, like say, Taylor Swift.",
                    "label": 0
                },
                {
                    "sent": "Try, you don't really know if what follows is true or not.",
                    "label": 0
                },
                {
                    "sent": "We have fact known and acknowledged in your so if you said, I acknowledge that blah blah blah blah is probably probably true, but you don't really know.",
                    "label": 0
                },
                {
                    "sent": "Managed to this is true force failed to forget to so this refers to what Sander was explaining with the park people.",
                    "label": 1
                },
                {
                    "sent": "And here we also need to check for negative context to which we do.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you say.",
                    "label": 0
                },
                {
                    "sent": "Chris failed to attend a meeting at the meeting.",
                    "label": 0
                },
                {
                    "sent": "You know that this is not true.",
                    "label": 0
                },
                {
                    "sent": "But if you say Chris didn't fail to attend the meeting, then it's true that Chris attending the meeting.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our results are the following, so we don't really beat the baseline.",
                    "label": 0
                },
                {
                    "sent": "So here we have the.",
                    "label": 0
                },
                {
                    "sent": "The reason for the 82 deaths set with the handset weight and the learned weights.",
                    "label": 0
                },
                {
                    "sent": "Accuracy and average precision and here are the results for the test set with handset weights and learned weights.",
                    "label": 0
                },
                {
                    "sent": "And then post hoc ablation studies on 32.",
                    "label": 0
                },
                {
                    "sent": "Beth said data showed on the features that we use showed that using the structure features are very important.",
                    "label": 0
                },
                {
                    "sent": "Using the modality feature help a little bit, but then using the antonymy adjunct and factivity feature done really help, but that was done only on RT2.",
                    "label": 0
                },
                {
                    "sent": "Def set data.",
                    "label": 0
                },
                {
                    "sent": "And so for the for running the system on the test set, we use as training data 31 def set one only the first part of 31.",
                    "label": 0
                },
                {
                    "sent": "And of course all the test.",
                    "label": 0
                },
                {
                    "sent": "Set the development set of 32.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the program region speaks is identification of some structural mismatches.",
                    "label": 0
                },
                {
                    "sent": "So, for example, ingredients lawyer or Lex Lasry told blah blah blah and then the hypothesis is angry and is a lawyer.",
                    "label": 0
                },
                {
                    "sent": "We should be able to identify that this is not true.",
                    "label": 0
                },
                {
                    "sent": "We also hope to be able to handle computation.",
                    "label": 0
                },
                {
                    "sent": "This is good news for garlic translator as the EU will have to turn out official documents in this language in addition to the 20 other official EU languages.",
                    "label": 0
                },
                {
                    "sent": "And the hypothesis is there are 21 official EU languages we should be able to.",
                    "label": 0
                },
                {
                    "sent": "To see that this language plus 20 and Tails 21.",
                    "label": 0
                },
                {
                    "sent": "Another thing we can fix in the alignment step, what I just saw is error.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the.",
                    "label": 0
                },
                {
                    "sent": "Third step in the.",
                    "label": 0
                },
                {
                    "sent": "And Penguin step.",
                    "label": 0
                },
                {
                    "sent": "And here in the second step, when we align we should be able to do a better job in aligning number with respect to the sentence of the structure of the sentence.",
                    "label": 0
                },
                {
                    "sent": "The sentence structure.",
                    "label": 0
                },
                {
                    "sent": "Sorry, some 420 people have been hanged in Singapore sings 19191.",
                    "label": 1
                },
                {
                    "sent": "That gives the country of 4.4 million people the highest execution rate in the world relative to population and the hypothesis.",
                    "label": 1
                },
                {
                    "sent": "Is 44 million people were executed in Singapore right now?",
                    "label": 0
                },
                {
                    "sent": "We are aligning for that 4 million with 44 million and then of course we don't discover that there is a mismatch in the number.",
                    "label": 0
                },
                {
                    "sent": "And if here we had a less sloppy matching will be able to see that there is a mismatch between 4.4 and 420.",
                    "label": 0
                },
                {
                    "sent": "Madame March and enjoy.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problems that right now we are not able to fix.",
                    "label": 0
                },
                {
                    "sent": "As somebody pointed out earlier, none team and is really easier to find a non payment.",
                    "label": 0
                },
                {
                    "sent": "So I think we are good at finding knockout features but it's really hard to be certain that we've considered everything.",
                    "label": 1
                },
                {
                    "sent": "Also, the fact of dealing with dropping and adding modifiers versus the acquired and don't want on telling context is really hard because actually we need to know which are restrictive or not of disco items, so more it was subsequently killed in Angola as an example.",
                    "label": 0
                },
                {
                    "sent": "And then everybody agrees.",
                    "label": 0
                },
                {
                    "sent": "We really need multi work, lexical semantics or world knowledge.",
                    "label": 0
                },
                {
                    "sent": "We are good at synonym, Hyponyms and antonyms.",
                    "label": 0
                },
                {
                    "sent": "But we are not able to solve multi world equivalences and we have a lot of those in the data.",
                    "label": 1
                },
                {
                    "sent": "David Mccool took the money and decided to start Music Lane in 2002.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis, David Mccool is the founder of Mozilla Lane.",
                    "label": 0
                },
                {
                    "sent": "We should be able to know that to be the founder.",
                    "label": 0
                },
                {
                    "sent": "Off is to decide to start something I didn't put here.",
                    "label": 0
                },
                {
                    "sent": "All the.",
                    "label": 0
                },
                {
                    "sent": "Doors kind of multiworld lexical knowledge that is required for a few data, but there are a lot of examples of this sort, so I hope that in the future, as maybe everybody is collaborating, will be able to build some huge lexical semantics resources.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "Sandra, deregulation settings can be separated out between both syntactic features that positives and negatives.",
                    "label": 0
                },
                {
                    "sent": "Interesting how she started to do this is our system.",
                    "label": 0
                },
                {
                    "sent": "Set up.",
                    "label": 0
                },
                {
                    "sent": "It will be raining at the base.",
                    "label": 0
                },
                {
                    "sent": "Yeah will be.",
                    "label": 0
                },
                {
                    "sent": "Yeah we are able to do it, but I didn't do it now, but it's it's easy to implement and to do, yeah.",
                    "label": 0
                },
                {
                    "sent": "That would be interesting to see, but once one thing was which was interesting, is that almost.",
                    "label": 0
                },
                {
                    "sent": "All the time.",
                    "label": 0
                },
                {
                    "sent": "Derm Hunt said it, wait that we had correspond roughly to the to the long one.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "How many differences?",
                    "label": 0
                },
                {
                    "sent": "Just cause.",
                    "label": 0
                },
                {
                    "sent": "Components.",
                    "label": 0
                },
                {
                    "sent": "Do you mean the propagation of errors between them entities and then the bars and?",
                    "label": 0
                },
                {
                    "sent": "Why did you sleep in that moment?",
                    "label": 0
                },
                {
                    "sent": "What is Roman Catholic Church program?",
                    "label": 0
                },
                {
                    "sent": "Or is it kind of got us?",
                    "label": 0
                },
                {
                    "sent": "Classification.",
                    "label": 0
                },
                {
                    "sent": "But for example, one thing we identified after the challenge is for the fact if features the classification we have is.",
                    "label": 0
                },
                {
                    "sent": "Maybe in some sense.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's too fine, and in another sense, maybe it's not finding enough because we have like a lot of examples.",
                    "label": 0
                },
                {
                    "sent": "We could just like a report he said that.",
                    "label": 0
                },
                {
                    "sent": "And then here the fact that it's true or false depending on the authority who said that fact and so.",
                    "label": 0
                },
                {
                    "sent": "But then again you need some work knowledge too.",
                    "label": 0
                },
                {
                    "sent": "To identify those classes, but maybe if we had another class for those specific reports, verbs.",
                    "label": 0
                },
                {
                    "sent": "We had run a a better wait for those for those verbs, for example, so factivity actually we had.",
                    "label": 0
                },
                {
                    "sent": "If we don't use activity features, we have a better score in this data, but which was not the case on LT1 data for example.",
                    "label": 0
                },
                {
                    "sent": "So I think it really varies and depends on the data, but it's certain that there there is propagation of errors and in the system, but it's hard to identify and we have to do a very very constrained error analysis to identify exactly which.",
                    "label": 0
                },
                {
                    "sent": "Items sports have problems.",
                    "label": 0
                },
                {
                    "sent": "No, we did.",
                    "label": 0
                },
                {
                    "sent": "We did that by hand.",
                    "label": 0
                },
                {
                    "sent": "We use a little bit of the the idea of the idea come from from parks as some dimension it, but then we have like a hand build list of verbs, an informed modalities to like the linguistic words.",
                    "label": 0
                },
                {
                    "sent": "It's just hundreds.",
                    "label": 0
                },
                {
                    "sent": "So we missed a lot maybe.",
                    "label": 0
                }
            ]
        }
    }
}