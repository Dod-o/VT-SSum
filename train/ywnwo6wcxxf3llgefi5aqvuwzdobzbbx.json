{
    "id": "ywnwo6wcxxf3llgefi5aqvuwzdobzbbx",
    "title": "Hierarchical Multilabel Classification Trees for Gene Function Prediction",
    "info": {
        "author": [
            "Leander Schietgat, Department of Computer Science, KU Leuven"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Classification"
        ]
    },
    "url": "http://videolectures.net/pmsb06_schietgat_hmctg/",
    "segmentation": [
        [
            "So this is going to work by myself.",
            "Kendrick Locaton young straight from the University of Durban and also meant that there from the University of Aberystwyth in Wales was involved as well as social diversity from the other state from instituting."
        ],
        [
            "People ya know?",
            "So in this talk 1st, I'll discuss the application, so function prediction, then I'll give our machine learning few minutes.",
            "So I'll discuss the concept of hierarchical multi label classification and then I'll explain how we use decision trees to to perform agency and then I'll show you some experimental results and in the end."
        ],
        [
            "Do some regions.",
            "So I don't think I have to explain a lot about this.",
            "The task of gene function prediction.",
            "So basically what is the task we have given data set of descriptions of jeans and the functions that they have and what we want to do is to learn a model that predicts for new unseen jeans what functions they made before.",
            "So as you might know now already teams can have multiple functions at once, and these teams are organized in a hierarchy.",
            "So for example, Gene can have three classes plus 1 + 2 and close 2, two.",
            "And well, this is a small example of such a hierarchy in which we see that's close to two is a subclass of Class 2."
        ],
        [
            "So basically in machine learning, the task of classification so involves to predict for unseen instances the class to which they belong.",
            "An well we want to have a model that predicts this that is learned on previously labeled training examples.",
            "So this classification tasks can be performed by a number of different techniques.",
            "So you have support vector machines.",
            "You can use Bayesian networks, but there was.",
            "There were also more simpler approaches like.",
            "Decision trees."
        ],
        [
            "So.",
            "This is the concept of hierarchical multi label classification.",
            "So in the normal classification you predict only one single class.",
            "So if an instance belongs to that class or not.",
            "So we define the task of hierarchical multi label classification just as an extension of that.",
            "So an instance can have multiple classes at once and these classes are organized in a hierarchy.",
            "So this perfectly aligns with the applications ask of gene function prediction.",
            "Well, there is one thing you should know well.",
            "We also have to take into account some hierarchy constraint and this means."
        ],
        [
            "If we go back to the previous example if Clause 2, two is predicted, then also all the superclass has to be have to be predicted too.",
            "So that's why I see two is also a class."
        ],
        [
            "That is predicted.",
            "Well, basically you have two different approaches to perform the agency task and obviously an obvious approach would be to learn a separate model for each class, and So what happens is that for each separate class.",
            "Well, let's say you have 10 different classes.",
            "So for each class you learn a model and, well, you just predict whether the gene belongs to that class or not, and you do that end times.",
            "An advantage of this approach is that you can use a lot of existing machine learning algorithms who know how to do that, but there are several disadvantages.",
            "First of all, we have to build any of these models, so that's not very efficient seconds well.",
            "Binary classifiers, single classifiers have known problems with scoot class distribution so that they work very well.",
            "If there isn't a balanced amount of positive and negative examples, but well in our problem setting where you have.",
            "A lot of classes, well, it is very likely that some classes occur very infrequently so well.",
            "Those binary models have problems with this and finally also went well.",
            "When you want to combine predictions of all the different models, well, the hierarchy constraints which I discussed is not automatically imposed, so can be that some subclauses predicted, but not super close."
        ],
        [
            "So this second approach, and well, this is the one we propose here is to learn a single model that predicts all the classes at once, so you have only one model, and, well, it predicts all the classes in one vector, for example.",
            "So the advantage of this approach is, well, it's faster to learn, you have to build only one model.",
            "It's easier to interpret because well, then you have to end different models for each class.",
            "Will you have to look at all these different features?",
            "Well, we can also take the higher heat constraint into account in the learning process, so we can impose it that way.",
            "And well, if we have also a single model, the features the relevant feature had are selected are relevant for all close together instead of.",
            "If we build in separate models, well, then we see features that may be or may be relevant to one class, but well, it's good to have a global picture sometimes.",
            "An at disadvantage of this approach might be that well, since the task of predicting end clauses ones might be more difficult than just predicting one plus, well, the model could have a worse predictive performance if you compare it to the fur."
        ],
        [
            "Approach.",
            "Here's some related work on HC.",
            "Well, as roses already said, but it quickly and some others presented a paper of or published paper in the Journal of Bioinformatics in the beginning of this year and well, there they propose an instantiation of the first approach, which I discussed.",
            "So they learn each class separately with support vector machines, and then they use in Naive Bayes approach to combine with addictions afterwards.",
            "So.",
            "That's how they solve one of the previous disadvantages."
        ],
        [
            "That I discussed well with naive bias approach, they solve problem of the hierarchical constraints well."
        ],
        [
            "We can impose it.",
            "Anne.",
            "In 2000, three men that care presented in her doctoral thesis to an extension of the C 4.5 Decision tree learning algorithm, so, and that's an instantiation of the second approach.",
            "So she also builds one model that predicts all classes together.",
            "An well a lot of work and agency was.",
            "Also focused on the cost of fixed desiccation, so you will do so.",
            "Presented the paper at Acnl last year that gave an overview of different techniques and well I didn't go deeper into that because we want to focus on gene function prediction.",
            "Well Ann you could situate the approach of the previous presentation also somewhere at the.",
            "Bottom Left and set up the table."
        ],
        [
            "So why do we use decision trees for our approach?",
            "Well, I'll first give a brief overview of other decision tree actually is.",
            "So we start from the database during an example.",
            "So you have information about the number of genes we have, the attributes they have, let's say, well, I'm giving an example now with just a binary tree that predicts if he belongs to a certain class.",
            "Well, let's say we want to predict.",
            "Here Iphigene belongs to the molecular function component working ontology for example.",
            "So what happens?",
            "At the three.",
            "Look for test stats.",
            "Try to separate the positive and the negative examples as good as possible.",
            "So let's say there is some test done or not.",
            "Nitrogen depletion?",
            "Well, some of them were in the top node.",
            "You start from all training examples, so all the examples that.",
            "Yeah, where the fulfill these tests are true to the to the left and it could be in the other branch that you have to perform another test.",
            "Well in the end you have a tree that contains tests and every leaf there are some training examples.",
            "So what do you do then to predict the claws?",
            "Well, for a binary decision problem is very easy.",
            "You just predict the majority class.",
            "So in the first if you have 3 positive examples and two negative, so we predict positive and.",
            "Well, the second is just the pure leaf.",
            "It's contains all possible all positive examples.",
            "So we also predict positive and in the Third leaf we have four negative examples against one.",
            "So we predict negative.",
            "So what are the exact advantages of decision trees?",
            "So they're very false to build their false to use their have reasonable predictions, and they're also very easy to interpret, so that's why we chose decision trees for for this."
        ],
        [
            "So.",
            "So of course we have to extend the normal concept of decision trees somewhat to be able to perform the task of hierarchical multi label classification.",
            "So we use the class system and well, that's positional decision tree learning that was implemented by young, stray and well it uses some IPS of normal decisions we learners as C 4.5 and also cards and well it's also based on the concept of predicting plus spring trees that was already proposed by Hendrik Local in 1998.",
            "And basically what we have to change is.",
            "The heuristic that we used to choose a test.",
            "Now it's actually generalization of the desktop is running cards there.",
            "It looks for a test that tries to maximize the reduction in variance.",
            "So here we try to do the same, but we have to take into account all classes."
        ],
        [
            "So.",
            "As we want to do a comparison also between the first approach I discussed in the second.",
            "Well, it's very easy because we can use the class system to perform agency.",
            "So we have a tree that predicts in the Leafs several classes at once and we want to compare this approach to the binary classification approach where we built a separate tree for each class.",
            "So you have entries that's.",
            "Decide on one particular class."
        ],
        [
            "And so for the experiments we used the same data set, says Ross already discussed in his favor.",
            "So there are all datasets about genes of the genome of East, so that is one of the model organisms in biology.",
            "So when we also use the medicine get hierarchy, so which contains 250 classes and this is a small example of it.",
            "Well, you have already seen it.",
            "Yes, I should not discuss the datasets anymore because well, Rose gave already very elaborate this."
        ],
        [
            "And this is, well, this is now an example run of how our algorithm works exactly.",
            "So let's say, well we have euro training sets with a number of different teams with their descriptions, so their attributes and also the functions they have.",
            "So in the top node of the tree we start from all the instances.",
            "Then we look for a test.",
            "Has tried to separate.",
            "The class is as good as possible, so let's say there is again a test on nitrogen, nitrogen depletion and in the.",
            "Left branch well.",
            "Two classes are are are in that leaf and on the right branch you have an additional test that separates the examples as good as possible.",
            "So.",
            "Now the problem is, in the end, what classes do we want to predict?",
            "Well, as I said in the binary setting, it's very easy.",
            "You just pick the majority class.",
            "But as we have multiple classes here, well that's not very easy.",
            "So how how?",
            "Which classes will predict in the ends?",
            "An additional problem we have is well.",
            "Different classes might have different frequencies.",
            "It could be that some class has a prior of 80% while some other class occurs very infrequently.",
            "So while we thought about this and.",
            "Anne.",
            "We wanted to introduce a threshold so.",
            "We don't want to pick a particular threshold like most decision tree algorithms do at the end.",
            "This sale we predict.",
            "Applause is 50%, for example, of the training examples in a leaf has left us.",
            "Well, we decided to use a threshold that we arrive from zero percent to 100% and.",
            "With that facials, we don't have to use a particular.",
            "Thresholds to to get a prediction.",
            "We just have different classifiers and then we can let the biologists decide which classifier they really want.",
            "But I'll show that on the precision recall curves that would make by letting that threshold barrier.",
            "So in this example, what predictions do we make?",
            "So let's say we have a prediction threshold of 0%, but that just means that you predict all classes that are in the least.",
            "So in the first week, for example, we have clauses 4043 and 4016.",
            "So when we let threshold rise to 50%, So what happens?",
            "Hello.",
            "That means that 50% of the training examples in the leaf have to have to have the clause.",
            "So for example, in the third key you see that only plus one and five.",
            "Well, I guess I may never hear her.",
            "Yes, of course.",
            "Only one of the two examples, but if already one of the two examples here half the class, so all clauses are predicted like you, the only difference is here I may leave here where there are three examples and there you see that plus 43 is already not predicted anymore because only one of the three training examples have plus 43.",
            "So in when we choose a threshold of 100%, this basically means that, well, every training example in the leaf have to have to have that.",
            "But in the threshold of 100%, only one and five are predicted."
        ],
        [
            "So what we first wanted to do is to validate, validate our approach, so we compared it with the current state of the art and agency decisions we learn.",
            "So it makes the algorithm of crosslinking.",
            "Sorry from Amanda clearing Grosky an so.",
            "Well.",
            "And this is this is the fee that we also had was, well.",
            "How do we want to evaluate mental model on 250 classes at once?",
            "So it's very difficult so.",
            "In the first place, we wanted to make use of precision and recall, so that's 'cause accuracy isn't a very good measure.",
            "When we have different laws frequencies.",
            "So what we did is we took the concepts of precision and recall, have extended them to the after the setting for 250 for multiple classes.",
            "So for 250 classes so precision is here that defined then as a proportion of instance class predictions that are correct.",
            "And the recall is in the proportion of the truth.",
            "The actual instance clause cases that are predicted.",
            "So well, you you see some example person you see well?",
            "Since the algorithm of man declare has a certain threshold so.",
            "Only one red Stars is shown, so that's the prediction by bilateral and the blue you see the curve of the class algorithm.",
            "So which has a point for every different thresholds.",
            "So you see that the Perfice consistently above the points for the start of C of the extension of C 4.5.",
            "So we can conclude that our new approach is certainly working well, so we're not doing version then."
        ],
        [
            "The current state of the art.",
            "So here's an example of a rule we had with the system, so it's very easy when you have a decision tree to extract the roof from.",
            "If you just go to relief and you look what this has to do to get the belief, and then you write this test out and you get a rule.",
            "So this is an example room rule for the cash one data set, which is one of the microarray datasets Anne was for for the clause 43.",
            "So here you see a precision recall curve for search for only that clause in particular.",
            "And you also see well.",
            "We chose the point that had the highest decision because we know that biologists prefer a very high precision while we call is less important.",
            "So this rule scores the precision of 97% of equal of 50%."
        ],
        [
            "So what we wanted to do next is to make a comparison of the 1st and the 2nd approach which I discussed earlier, so we wanted to look at size of the tree, how they differed and also at random times and predictive performance.",
            "So for the size of the trees what we saw was that for a single agency, three that predicts all classes at once.",
            "Well, it contains on average 24 nodes by a single single classification tree.",
            "At 30 three nodes, so and when you know that you have 250 of these trees, well, you see that it's definitely well.",
            "And there's a big complexity reduction when used in Agency 3's second, when we compare runtimes well.",
            "A single S3 SC trees is faster to build than a single agency tree well because in single classification tree has to focus only on one plus an.",
            "But as you know, 250 of these models have to be built, so we concluded that agency is on average 37 times faster than then doing the single classification methods and then combining the predictions.",
            "So when you look at."
        ],
        [
            "Predicted performance so.",
            "These products also some curves, so the blue curve is the.",
            "Agency approach while the red curve is the single classification approach and this is a very amazing result.",
            "'cause we see that the curve of HC is consistently lying both well if there's a higher AUC.",
            "So in area under the curve then the curve single classification.",
            "And this is a very good result because, well.",
            "The trees are smaller and.",
            "Yes, we have a better predictor."
        ],
        [
            "Performance.",
            "So we wanted to look for a reason for this results so.",
            "The first thing we concluded from this as well, the clauses in the hierarchy are not independent, so we saw that when you billed separately for each class separately, that, well, some of them have more or less the same structure.",
            "So when you merge all these trees into one, it's normal that you have some complexity, complexity reduction, and SEC.",
            "Because we take into account the higher the constraint we can.",
            "Let's information carry over from 1 + 2 to another class and this increases the signal to noise ratio.",
            "Well, it provides a better guidance when learning the tree, and it also avoids overfitting, so we did some miracle tests when we compare the training error with the test error and we saw that single classification approaches overfitting alot more than that."
        ],
        [
            "Can see approach.",
            "So what can we conclude now?",
            "First of all, decision trees in agency trees in particular are a very useful tool to do team function prediction.",
            "Their false to learn they have high interpretability, and Moreover when you compare agency decision tree learning to regular tree learning, you see that agency to be learning is even faster it and it yields three that are smaller in size.",
            "There are easier to interpret because you have one single model.",
            "And well, they have an equal or even better predictive performance."
        ],
        [
            "So what we want to do next is, well, maybe to do a comparison with other agency learning algorithms.",
            "So we're very interested in how this approach relates to two kernel methods which are discussed here a lot.",
            "So if they have.",
            "Better results so well we could do a comparison with some algorithms that you would use to present it, or the algorithm that, particularly in some others presented.",
            "An what we also wanted to do is to well to use different hierarchy.",
            "So we use now a version of the midst Benefits classification scheme scheme that is already a little bit outdated, so we wanted to use the Gene Ontology scheme so you know, mythology is a worldwide project where information about functions of genes is colored.",
            "So in one place so that all the knowledge and hold the roads.",
            "Can be combined so.",
            "This genealogy hierarchy contains thousands of classes in spread over 19 level, so it's also good to see how the algorithm scales to do that, proportions and well, we have also a small problem by engine ontology.",
            "You have different kind of relations, so we try to build the hierarchy through the installation.",
            "So if a gene A hasn't is a relation between B, that means just that team A.",
            "Our function A is a subclass of a function be so, but there is also the parts of relationship and well, even biologists are not giving agreement about how to interpret this.",
            "If function A is part of function E, does that mean that?",
            "This function, a hash function be or is function agents involved in in function being well, if anyone could have experience with, But this could be very glad to have some insights in this."
        ],
        [
            "Alright, thank you for your attention.",
            "Question.",
            "Quite.",
            "Hello.",
            "Full service hierarchy confirms only in prediction phase or also in politics, and if so, how did you check it?",
            "Well, in fact what we do is when you go back to the slides.",
            "Well, I have notes very elaborate on that, but so we assign a vector for each instance, so which contains just terrorism once.",
            "For each class and then, well, we define two to measure the reduction in variance.",
            "We define the distance between all those factors and we define the distance in such a way.",
            "That we.",
            "Can't compare it.",
            "Well, we say that predictions on higher levels are.",
            "Well, if you have make mistakes and in predictions at lower levels, it's not that bad and making a mistake higher up in the hierarchy, so an and also.",
            "But we see that if.",
            "Have a certain instance has a multiple functions which contain a lot of 14 and, well, you have for example here 43 and 4016.",
            "Maybe there is some noise in it, but.",
            "Since.",
            "The function 4016 has also we know that this happened that it has function 42, so it's you don't see it here, but as a across here for both classes, we can measure the distance between it and so we make use of more information to to define the distance measures.",
            "So that is not done by my other algorithms.",
            "I hope I was clear about it.",
            "So I didn't really understand about this decision tree is you can make this decision tree deeper and deeper, right?",
            "You make outlook knows they are compressed by the training.",
            "Something perfectly, but you overheat.",
            "Yes, well he has to determine the time to quit.",
            "Well, there's something pretty ring.",
            "It consists of statistical tests in at one side, so it it's checks if the reduction in vereins is really significant.",
            "So if it is significant device if it is not significant, it doesn't, and there's an additional stopping criterion with which says well.",
            "It sends that it says what we want to have in a leaf.",
            "At least 5 examples.",
            "That's not the case here, because this is a very simplified example.",
            "But well, when you have at least 5 examples in a leaf, it's more difficult to over fix.",
            "But, well, you can adjust those parameters.",
            "OK.",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is going to work by myself.",
                    "label": 0
                },
                {
                    "sent": "Kendrick Locaton young straight from the University of Durban and also meant that there from the University of Aberystwyth in Wales was involved as well as social diversity from the other state from instituting.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People ya know?",
                    "label": 0
                },
                {
                    "sent": "So in this talk 1st, I'll discuss the application, so function prediction, then I'll give our machine learning few minutes.",
                    "label": 1
                },
                {
                    "sent": "So I'll discuss the concept of hierarchical multi label classification and then I'll explain how we use decision trees to to perform agency and then I'll show you some experimental results and in the end.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do some regions.",
                    "label": 0
                },
                {
                    "sent": "So I don't think I have to explain a lot about this.",
                    "label": 0
                },
                {
                    "sent": "The task of gene function prediction.",
                    "label": 1
                },
                {
                    "sent": "So basically what is the task we have given data set of descriptions of jeans and the functions that they have and what we want to do is to learn a model that predicts for new unseen jeans what functions they made before.",
                    "label": 1
                },
                {
                    "sent": "So as you might know now already teams can have multiple functions at once, and these teams are organized in a hierarchy.",
                    "label": 0
                },
                {
                    "sent": "So for example, Gene can have three classes plus 1 + 2 and close 2, two.",
                    "label": 0
                },
                {
                    "sent": "And well, this is a small example of such a hierarchy in which we see that's close to two is a subclass of Class 2.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basically in machine learning, the task of classification so involves to predict for unseen instances the class to which they belong.",
                    "label": 1
                },
                {
                    "sent": "An well we want to have a model that predicts this that is learned on previously labeled training examples.",
                    "label": 0
                },
                {
                    "sent": "So this classification tasks can be performed by a number of different techniques.",
                    "label": 1
                },
                {
                    "sent": "So you have support vector machines.",
                    "label": 0
                },
                {
                    "sent": "You can use Bayesian networks, but there was.",
                    "label": 0
                },
                {
                    "sent": "There were also more simpler approaches like.",
                    "label": 0
                },
                {
                    "sent": "Decision trees.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is the concept of hierarchical multi label classification.",
                    "label": 0
                },
                {
                    "sent": "So in the normal classification you predict only one single class.",
                    "label": 1
                },
                {
                    "sent": "So if an instance belongs to that class or not.",
                    "label": 0
                },
                {
                    "sent": "So we define the task of hierarchical multi label classification just as an extension of that.",
                    "label": 0
                },
                {
                    "sent": "So an instance can have multiple classes at once and these classes are organized in a hierarchy.",
                    "label": 1
                },
                {
                    "sent": "So this perfectly aligns with the applications ask of gene function prediction.",
                    "label": 0
                },
                {
                    "sent": "Well, there is one thing you should know well.",
                    "label": 0
                },
                {
                    "sent": "We also have to take into account some hierarchy constraint and this means.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we go back to the previous example if Clause 2, two is predicted, then also all the superclass has to be have to be predicted too.",
                    "label": 0
                },
                {
                    "sent": "So that's why I see two is also a class.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That is predicted.",
                    "label": 0
                },
                {
                    "sent": "Well, basically you have two different approaches to perform the agency task and obviously an obvious approach would be to learn a separate model for each class, and So what happens is that for each separate class.",
                    "label": 1
                },
                {
                    "sent": "Well, let's say you have 10 different classes.",
                    "label": 0
                },
                {
                    "sent": "So for each class you learn a model and, well, you just predict whether the gene belongs to that class or not, and you do that end times.",
                    "label": 0
                },
                {
                    "sent": "An advantage of this approach is that you can use a lot of existing machine learning algorithms who know how to do that, but there are several disadvantages.",
                    "label": 1
                },
                {
                    "sent": "First of all, we have to build any of these models, so that's not very efficient seconds well.",
                    "label": 0
                },
                {
                    "sent": "Binary classifiers, single classifiers have known problems with scoot class distribution so that they work very well.",
                    "label": 0
                },
                {
                    "sent": "If there isn't a balanced amount of positive and negative examples, but well in our problem setting where you have.",
                    "label": 0
                },
                {
                    "sent": "A lot of classes, well, it is very likely that some classes occur very infrequently so well.",
                    "label": 0
                },
                {
                    "sent": "Those binary models have problems with this and finally also went well.",
                    "label": 0
                },
                {
                    "sent": "When you want to combine predictions of all the different models, well, the hierarchy constraints which I discussed is not automatically imposed, so can be that some subclauses predicted, but not super close.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this second approach, and well, this is the one we propose here is to learn a single model that predicts all the classes at once, so you have only one model, and, well, it predicts all the classes in one vector, for example.",
                    "label": 1
                },
                {
                    "sent": "So the advantage of this approach is, well, it's faster to learn, you have to build only one model.",
                    "label": 1
                },
                {
                    "sent": "It's easier to interpret because well, then you have to end different models for each class.",
                    "label": 0
                },
                {
                    "sent": "Will you have to look at all these different features?",
                    "label": 0
                },
                {
                    "sent": "Well, we can also take the higher heat constraint into account in the learning process, so we can impose it that way.",
                    "label": 0
                },
                {
                    "sent": "And well, if we have also a single model, the features the relevant feature had are selected are relevant for all close together instead of.",
                    "label": 0
                },
                {
                    "sent": "If we build in separate models, well, then we see features that may be or may be relevant to one class, but well, it's good to have a global picture sometimes.",
                    "label": 0
                },
                {
                    "sent": "An at disadvantage of this approach might be that well, since the task of predicting end clauses ones might be more difficult than just predicting one plus, well, the model could have a worse predictive performance if you compare it to the fur.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Approach.",
                    "label": 0
                },
                {
                    "sent": "Here's some related work on HC.",
                    "label": 1
                },
                {
                    "sent": "Well, as roses already said, but it quickly and some others presented a paper of or published paper in the Journal of Bioinformatics in the beginning of this year and well, there they propose an instantiation of the first approach, which I discussed.",
                    "label": 1
                },
                {
                    "sent": "So they learn each class separately with support vector machines, and then they use in Naive Bayes approach to combine with addictions afterwards.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's how they solve one of the previous disadvantages.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That I discussed well with naive bias approach, they solve problem of the hierarchical constraints well.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can impose it.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "In 2000, three men that care presented in her doctoral thesis to an extension of the C 4.5 Decision tree learning algorithm, so, and that's an instantiation of the second approach.",
                    "label": 1
                },
                {
                    "sent": "So she also builds one model that predicts all classes together.",
                    "label": 1
                },
                {
                    "sent": "An well a lot of work and agency was.",
                    "label": 1
                },
                {
                    "sent": "Also focused on the cost of fixed desiccation, so you will do so.",
                    "label": 0
                },
                {
                    "sent": "Presented the paper at Acnl last year that gave an overview of different techniques and well I didn't go deeper into that because we want to focus on gene function prediction.",
                    "label": 0
                },
                {
                    "sent": "Well Ann you could situate the approach of the previous presentation also somewhere at the.",
                    "label": 0
                },
                {
                    "sent": "Bottom Left and set up the table.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why do we use decision trees for our approach?",
                    "label": 0
                },
                {
                    "sent": "Well, I'll first give a brief overview of other decision tree actually is.",
                    "label": 0
                },
                {
                    "sent": "So we start from the database during an example.",
                    "label": 0
                },
                {
                    "sent": "So you have information about the number of genes we have, the attributes they have, let's say, well, I'm giving an example now with just a binary tree that predicts if he belongs to a certain class.",
                    "label": 0
                },
                {
                    "sent": "Well, let's say we want to predict.",
                    "label": 0
                },
                {
                    "sent": "Here Iphigene belongs to the molecular function component working ontology for example.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                },
                {
                    "sent": "At the three.",
                    "label": 0
                },
                {
                    "sent": "Look for test stats.",
                    "label": 0
                },
                {
                    "sent": "Try to separate the positive and the negative examples as good as possible.",
                    "label": 0
                },
                {
                    "sent": "So let's say there is some test done or not.",
                    "label": 0
                },
                {
                    "sent": "Nitrogen depletion?",
                    "label": 0
                },
                {
                    "sent": "Well, some of them were in the top node.",
                    "label": 0
                },
                {
                    "sent": "You start from all training examples, so all the examples that.",
                    "label": 1
                },
                {
                    "sent": "Yeah, where the fulfill these tests are true to the to the left and it could be in the other branch that you have to perform another test.",
                    "label": 0
                },
                {
                    "sent": "Well in the end you have a tree that contains tests and every leaf there are some training examples.",
                    "label": 0
                },
                {
                    "sent": "So what do you do then to predict the claws?",
                    "label": 0
                },
                {
                    "sent": "Well, for a binary decision problem is very easy.",
                    "label": 0
                },
                {
                    "sent": "You just predict the majority class.",
                    "label": 0
                },
                {
                    "sent": "So in the first if you have 3 positive examples and two negative, so we predict positive and.",
                    "label": 0
                },
                {
                    "sent": "Well, the second is just the pure leaf.",
                    "label": 0
                },
                {
                    "sent": "It's contains all possible all positive examples.",
                    "label": 0
                },
                {
                    "sent": "So we also predict positive and in the Third leaf we have four negative examples against one.",
                    "label": 0
                },
                {
                    "sent": "So we predict negative.",
                    "label": 0
                },
                {
                    "sent": "So what are the exact advantages of decision trees?",
                    "label": 0
                },
                {
                    "sent": "So they're very false to build their false to use their have reasonable predictions, and they're also very easy to interpret, so that's why we chose decision trees for for this.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So of course we have to extend the normal concept of decision trees somewhat to be able to perform the task of hierarchical multi label classification.",
                    "label": 0
                },
                {
                    "sent": "So we use the class system and well, that's positional decision tree learning that was implemented by young, stray and well it uses some IPS of normal decisions we learners as C 4.5 and also cards and well it's also based on the concept of predicting plus spring trees that was already proposed by Hendrik Local in 1998.",
                    "label": 0
                },
                {
                    "sent": "And basically what we have to change is.",
                    "label": 0
                },
                {
                    "sent": "The heuristic that we used to choose a test.",
                    "label": 0
                },
                {
                    "sent": "Now it's actually generalization of the desktop is running cards there.",
                    "label": 0
                },
                {
                    "sent": "It looks for a test that tries to maximize the reduction in variance.",
                    "label": 0
                },
                {
                    "sent": "So here we try to do the same, but we have to take into account all classes.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As we want to do a comparison also between the first approach I discussed in the second.",
                    "label": 0
                },
                {
                    "sent": "Well, it's very easy because we can use the class system to perform agency.",
                    "label": 0
                },
                {
                    "sent": "So we have a tree that predicts in the Leafs several classes at once and we want to compare this approach to the binary classification approach where we built a separate tree for each class.",
                    "label": 0
                },
                {
                    "sent": "So you have entries that's.",
                    "label": 0
                },
                {
                    "sent": "Decide on one particular class.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so for the experiments we used the same data set, says Ross already discussed in his favor.",
                    "label": 0
                },
                {
                    "sent": "So there are all datasets about genes of the genome of East, so that is one of the model organisms in biology.",
                    "label": 0
                },
                {
                    "sent": "So when we also use the medicine get hierarchy, so which contains 250 classes and this is a small example of it.",
                    "label": 0
                },
                {
                    "sent": "Well, you have already seen it.",
                    "label": 0
                },
                {
                    "sent": "Yes, I should not discuss the datasets anymore because well, Rose gave already very elaborate this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is, well, this is now an example run of how our algorithm works exactly.",
                    "label": 0
                },
                {
                    "sent": "So let's say, well we have euro training sets with a number of different teams with their descriptions, so their attributes and also the functions they have.",
                    "label": 0
                },
                {
                    "sent": "So in the top node of the tree we start from all the instances.",
                    "label": 0
                },
                {
                    "sent": "Then we look for a test.",
                    "label": 0
                },
                {
                    "sent": "Has tried to separate.",
                    "label": 0
                },
                {
                    "sent": "The class is as good as possible, so let's say there is again a test on nitrogen, nitrogen depletion and in the.",
                    "label": 0
                },
                {
                    "sent": "Left branch well.",
                    "label": 0
                },
                {
                    "sent": "Two classes are are are in that leaf and on the right branch you have an additional test that separates the examples as good as possible.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is, in the end, what classes do we want to predict?",
                    "label": 0
                },
                {
                    "sent": "Well, as I said in the binary setting, it's very easy.",
                    "label": 0
                },
                {
                    "sent": "You just pick the majority class.",
                    "label": 0
                },
                {
                    "sent": "But as we have multiple classes here, well that's not very easy.",
                    "label": 0
                },
                {
                    "sent": "So how how?",
                    "label": 0
                },
                {
                    "sent": "Which classes will predict in the ends?",
                    "label": 0
                },
                {
                    "sent": "An additional problem we have is well.",
                    "label": 0
                },
                {
                    "sent": "Different classes might have different frequencies.",
                    "label": 0
                },
                {
                    "sent": "It could be that some class has a prior of 80% while some other class occurs very infrequently.",
                    "label": 0
                },
                {
                    "sent": "So while we thought about this and.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "We wanted to introduce a threshold so.",
                    "label": 0
                },
                {
                    "sent": "We don't want to pick a particular threshold like most decision tree algorithms do at the end.",
                    "label": 0
                },
                {
                    "sent": "This sale we predict.",
                    "label": 0
                },
                {
                    "sent": "Applause is 50%, for example, of the training examples in a leaf has left us.",
                    "label": 0
                },
                {
                    "sent": "Well, we decided to use a threshold that we arrive from zero percent to 100% and.",
                    "label": 0
                },
                {
                    "sent": "With that facials, we don't have to use a particular.",
                    "label": 0
                },
                {
                    "sent": "Thresholds to to get a prediction.",
                    "label": 0
                },
                {
                    "sent": "We just have different classifiers and then we can let the biologists decide which classifier they really want.",
                    "label": 0
                },
                {
                    "sent": "But I'll show that on the precision recall curves that would make by letting that threshold barrier.",
                    "label": 0
                },
                {
                    "sent": "So in this example, what predictions do we make?",
                    "label": 0
                },
                {
                    "sent": "So let's say we have a prediction threshold of 0%, but that just means that you predict all classes that are in the least.",
                    "label": 0
                },
                {
                    "sent": "So in the first week, for example, we have clauses 4043 and 4016.",
                    "label": 0
                },
                {
                    "sent": "So when we let threshold rise to 50%, So what happens?",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "That means that 50% of the training examples in the leaf have to have to have the clause.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the third key you see that only plus one and five.",
                    "label": 0
                },
                {
                    "sent": "Well, I guess I may never hear her.",
                    "label": 0
                },
                {
                    "sent": "Yes, of course.",
                    "label": 0
                },
                {
                    "sent": "Only one of the two examples, but if already one of the two examples here half the class, so all clauses are predicted like you, the only difference is here I may leave here where there are three examples and there you see that plus 43 is already not predicted anymore because only one of the three training examples have plus 43.",
                    "label": 0
                },
                {
                    "sent": "So in when we choose a threshold of 100%, this basically means that, well, every training example in the leaf have to have to have that.",
                    "label": 0
                },
                {
                    "sent": "But in the threshold of 100%, only one and five are predicted.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we first wanted to do is to validate, validate our approach, so we compared it with the current state of the art and agency decisions we learn.",
                    "label": 0
                },
                {
                    "sent": "So it makes the algorithm of crosslinking.",
                    "label": 0
                },
                {
                    "sent": "Sorry from Amanda clearing Grosky an so.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "And this is this is the fee that we also had was, well.",
                    "label": 0
                },
                {
                    "sent": "How do we want to evaluate mental model on 250 classes at once?",
                    "label": 0
                },
                {
                    "sent": "So it's very difficult so.",
                    "label": 0
                },
                {
                    "sent": "In the first place, we wanted to make use of precision and recall, so that's 'cause accuracy isn't a very good measure.",
                    "label": 0
                },
                {
                    "sent": "When we have different laws frequencies.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we took the concepts of precision and recall, have extended them to the after the setting for 250 for multiple classes.",
                    "label": 0
                },
                {
                    "sent": "So for 250 classes so precision is here that defined then as a proportion of instance class predictions that are correct.",
                    "label": 1
                },
                {
                    "sent": "And the recall is in the proportion of the truth.",
                    "label": 1
                },
                {
                    "sent": "The actual instance clause cases that are predicted.",
                    "label": 0
                },
                {
                    "sent": "So well, you you see some example person you see well?",
                    "label": 0
                },
                {
                    "sent": "Since the algorithm of man declare has a certain threshold so.",
                    "label": 0
                },
                {
                    "sent": "Only one red Stars is shown, so that's the prediction by bilateral and the blue you see the curve of the class algorithm.",
                    "label": 0
                },
                {
                    "sent": "So which has a point for every different thresholds.",
                    "label": 0
                },
                {
                    "sent": "So you see that the Perfice consistently above the points for the start of C of the extension of C 4.5.",
                    "label": 0
                },
                {
                    "sent": "So we can conclude that our new approach is certainly working well, so we're not doing version then.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The current state of the art.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of a rule we had with the system, so it's very easy when you have a decision tree to extract the roof from.",
                    "label": 0
                },
                {
                    "sent": "If you just go to relief and you look what this has to do to get the belief, and then you write this test out and you get a rule.",
                    "label": 0
                },
                {
                    "sent": "So this is an example room rule for the cash one data set, which is one of the microarray datasets Anne was for for the clause 43.",
                    "label": 0
                },
                {
                    "sent": "So here you see a precision recall curve for search for only that clause in particular.",
                    "label": 0
                },
                {
                    "sent": "And you also see well.",
                    "label": 0
                },
                {
                    "sent": "We chose the point that had the highest decision because we know that biologists prefer a very high precision while we call is less important.",
                    "label": 0
                },
                {
                    "sent": "So this rule scores the precision of 97% of equal of 50%.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we wanted to do next is to make a comparison of the 1st and the 2nd approach which I discussed earlier, so we wanted to look at size of the tree, how they differed and also at random times and predictive performance.",
                    "label": 0
                },
                {
                    "sent": "So for the size of the trees what we saw was that for a single agency, three that predicts all classes at once.",
                    "label": 0
                },
                {
                    "sent": "Well, it contains on average 24 nodes by a single single classification tree.",
                    "label": 1
                },
                {
                    "sent": "At 30 three nodes, so and when you know that you have 250 of these trees, well, you see that it's definitely well.",
                    "label": 0
                },
                {
                    "sent": "And there's a big complexity reduction when used in Agency 3's second, when we compare runtimes well.",
                    "label": 0
                },
                {
                    "sent": "A single S3 SC trees is faster to build than a single agency tree well because in single classification tree has to focus only on one plus an.",
                    "label": 0
                },
                {
                    "sent": "But as you know, 250 of these models have to be built, so we concluded that agency is on average 37 times faster than then doing the single classification methods and then combining the predictions.",
                    "label": 1
                },
                {
                    "sent": "So when you look at.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Predicted performance so.",
                    "label": 0
                },
                {
                    "sent": "These products also some curves, so the blue curve is the.",
                    "label": 0
                },
                {
                    "sent": "Agency approach while the red curve is the single classification approach and this is a very amazing result.",
                    "label": 0
                },
                {
                    "sent": "'cause we see that the curve of HC is consistently lying both well if there's a higher AUC.",
                    "label": 0
                },
                {
                    "sent": "So in area under the curve then the curve single classification.",
                    "label": 1
                },
                {
                    "sent": "And this is a very good result because, well.",
                    "label": 0
                },
                {
                    "sent": "The trees are smaller and.",
                    "label": 0
                },
                {
                    "sent": "Yes, we have a better predictor.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Performance.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to look for a reason for this results so.",
                    "label": 0
                },
                {
                    "sent": "The first thing we concluded from this as well, the clauses in the hierarchy are not independent, so we saw that when you billed separately for each class separately, that, well, some of them have more or less the same structure.",
                    "label": 0
                },
                {
                    "sent": "So when you merge all these trees into one, it's normal that you have some complexity, complexity reduction, and SEC.",
                    "label": 1
                },
                {
                    "sent": "Because we take into account the higher the constraint we can.",
                    "label": 0
                },
                {
                    "sent": "Let's information carry over from 1 + 2 to another class and this increases the signal to noise ratio.",
                    "label": 1
                },
                {
                    "sent": "Well, it provides a better guidance when learning the tree, and it also avoids overfitting, so we did some miracle tests when we compare the training error with the test error and we saw that single classification approaches overfitting alot more than that.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can see approach.",
                    "label": 0
                },
                {
                    "sent": "So what can we conclude now?",
                    "label": 0
                },
                {
                    "sent": "First of all, decision trees in agency trees in particular are a very useful tool to do team function prediction.",
                    "label": 1
                },
                {
                    "sent": "Their false to learn they have high interpretability, and Moreover when you compare agency decision tree learning to regular tree learning, you see that agency to be learning is even faster it and it yields three that are smaller in size.",
                    "label": 1
                },
                {
                    "sent": "There are easier to interpret because you have one single model.",
                    "label": 0
                },
                {
                    "sent": "And well, they have an equal or even better predictive performance.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we want to do next is, well, maybe to do a comparison with other agency learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "So we're very interested in how this approach relates to two kernel methods which are discussed here a lot.",
                    "label": 0
                },
                {
                    "sent": "So if they have.",
                    "label": 0
                },
                {
                    "sent": "Better results so well we could do a comparison with some algorithms that you would use to present it, or the algorithm that, particularly in some others presented.",
                    "label": 0
                },
                {
                    "sent": "An what we also wanted to do is to well to use different hierarchy.",
                    "label": 0
                },
                {
                    "sent": "So we use now a version of the midst Benefits classification scheme scheme that is already a little bit outdated, so we wanted to use the Gene Ontology scheme so you know, mythology is a worldwide project where information about functions of genes is colored.",
                    "label": 0
                },
                {
                    "sent": "So in one place so that all the knowledge and hold the roads.",
                    "label": 0
                },
                {
                    "sent": "Can be combined so.",
                    "label": 0
                },
                {
                    "sent": "This genealogy hierarchy contains thousands of classes in spread over 19 level, so it's also good to see how the algorithm scales to do that, proportions and well, we have also a small problem by engine ontology.",
                    "label": 1
                },
                {
                    "sent": "You have different kind of relations, so we try to build the hierarchy through the installation.",
                    "label": 0
                },
                {
                    "sent": "So if a gene A hasn't is a relation between B, that means just that team A.",
                    "label": 1
                },
                {
                    "sent": "Our function A is a subclass of a function be so, but there is also the parts of relationship and well, even biologists are not giving agreement about how to interpret this.",
                    "label": 1
                },
                {
                    "sent": "If function A is part of function E, does that mean that?",
                    "label": 0
                },
                {
                    "sent": "This function, a hash function be or is function agents involved in in function being well, if anyone could have experience with, But this could be very glad to have some insights in this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Quite.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "Full service hierarchy confirms only in prediction phase or also in politics, and if so, how did you check it?",
                    "label": 0
                },
                {
                    "sent": "Well, in fact what we do is when you go back to the slides.",
                    "label": 0
                },
                {
                    "sent": "Well, I have notes very elaborate on that, but so we assign a vector for each instance, so which contains just terrorism once.",
                    "label": 0
                },
                {
                    "sent": "For each class and then, well, we define two to measure the reduction in variance.",
                    "label": 0
                },
                {
                    "sent": "We define the distance between all those factors and we define the distance in such a way.",
                    "label": 0
                },
                {
                    "sent": "That we.",
                    "label": 0
                },
                {
                    "sent": "Can't compare it.",
                    "label": 0
                },
                {
                    "sent": "Well, we say that predictions on higher levels are.",
                    "label": 0
                },
                {
                    "sent": "Well, if you have make mistakes and in predictions at lower levels, it's not that bad and making a mistake higher up in the hierarchy, so an and also.",
                    "label": 0
                },
                {
                    "sent": "But we see that if.",
                    "label": 0
                },
                {
                    "sent": "Have a certain instance has a multiple functions which contain a lot of 14 and, well, you have for example here 43 and 4016.",
                    "label": 0
                },
                {
                    "sent": "Maybe there is some noise in it, but.",
                    "label": 0
                },
                {
                    "sent": "Since.",
                    "label": 0
                },
                {
                    "sent": "The function 4016 has also we know that this happened that it has function 42, so it's you don't see it here, but as a across here for both classes, we can measure the distance between it and so we make use of more information to to define the distance measures.",
                    "label": 0
                },
                {
                    "sent": "So that is not done by my other algorithms.",
                    "label": 0
                },
                {
                    "sent": "I hope I was clear about it.",
                    "label": 0
                },
                {
                    "sent": "So I didn't really understand about this decision tree is you can make this decision tree deeper and deeper, right?",
                    "label": 0
                },
                {
                    "sent": "You make outlook knows they are compressed by the training.",
                    "label": 0
                },
                {
                    "sent": "Something perfectly, but you overheat.",
                    "label": 0
                },
                {
                    "sent": "Yes, well he has to determine the time to quit.",
                    "label": 0
                },
                {
                    "sent": "Well, there's something pretty ring.",
                    "label": 0
                },
                {
                    "sent": "It consists of statistical tests in at one side, so it it's checks if the reduction in vereins is really significant.",
                    "label": 0
                },
                {
                    "sent": "So if it is significant device if it is not significant, it doesn't, and there's an additional stopping criterion with which says well.",
                    "label": 0
                },
                {
                    "sent": "It sends that it says what we want to have in a leaf.",
                    "label": 0
                },
                {
                    "sent": "At least 5 examples.",
                    "label": 0
                },
                {
                    "sent": "That's not the case here, because this is a very simplified example.",
                    "label": 0
                },
                {
                    "sent": "But well, when you have at least 5 examples in a leaf, it's more difficult to over fix.",
                    "label": 0
                },
                {
                    "sent": "But, well, you can adjust those parameters.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}