{
    "id": "kjwicame6wk5usvqa57fdkll5swg4bgo",
    "title": "Online Learning: Beyond Regret",
    "info": {
        "author": [
            "Karthik Sridharan, Department of Computer Science, Cornell University"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Computational Learning Theory"
        ]
    },
    "url": "http://videolectures.net/colt2011_sridharan_online/",
    "segmentation": [
        [
            "The story in the Statistical learning world is nice, but we have nature that basically selects a distribution is not given to the learner.",
            "The learner basically has to learn are basically has to learn based on the samples that he gets and here basically the tools that we have to analyze this learning problem.",
            "We have a we have a huge bag of tools with a lot of complexity measures like Rademacher Complexity, VC dimension and so on.",
            "And the online learning world things are slightly different, at least most of the work has been more algorithmic and little case by case.",
            "So only recently we've been.",
            "We've started having kind of a toolbox for generic toolbox for online learning, so little shown introduced this little Son Dimension, and David and Shy and Shy basically showed that for agnostic learning you can essentially this access as an analog for VC dimension and you know previous NIPS paper we showed that you actually can get analogs for things like Rademacher complexity, covering numbers, and most of this.",
            "So basically we can fill up the online learning tool box with most of the tools that we.",
            "With analogs of the tools that we had in the statistical learning world.",
            "But of course not all.",
            "Not all online learning problems are regret based problems or regret minimization problems.",
            "So today we're going to look at is online learning going beyond the beyond regret minimization type problems, and the basic idea is I'm going to give you a framework.",
            "So to put your online learning problem in and machinery so you can try and get bound.",
            "So the idea is you take your favorite online learning problem.",
            "Put it in the framework, crank the crank the wheel and you start getting both.",
            "Hopefully I can do that."
        ],
        [
            "OK, so let's review the online learning game.",
            "So it's a two player game between a player and an adversary.",
            "It's a multi round game where at each round the learner picks an action FT from his action set script.",
            "If the adversary freaks and action XD from this action set Script X and this happens simultaneously and player basically suffers loss LFT, XD.",
            "So what's the notion of performance?",
            "The usual notion of performance we are familiar with is the notion of external regret.",
            "So here.",
            "We basically look at what's the average loss that the player suffered for the tearooms and we see how good was this compared to the best that he could have done.",
            "If you had picked the single best action at hindsight.",
            "So what we want to do is we want to extend this."
        ],
        [
            "Moments measure out here.",
            "So the first thing we do is why average?",
            "I mean why do we look at cumulative costs?",
            "Just the average cost?",
            "So instead we are going to use a function B that takes in the T losses and Maps it to the reals.",
            "And once we do this immediately, we see that the last no longer actually even needs to be real valued.",
            "So throughout this talk, I'm going to assume that the loss is H valued, where H is a subset of some backspace.",
            "And be basically Maps these T losses that we received to the reals.",
            "This Ibiza form of cumulative loss costs.",
            "OK, the next thing that we do is instead of comparing with the best with the best action at hindsight, we're going to do a transformation.",
            "So every time that we see L of F1, X one, we're going to transform it to LP, one of F1, X1, where Phi is a transformation chosen from PCP.",
            "So fee is basically a sequence of transformations which transforms each of these pay offs to these ones, and we want to comparing ourselves against the best transformation one can immediately see that.",
            "External regret itself can be returned back in this format if they were just the average and if this transformation is basically only changes F1 to single F. And of course, what's the goal here?",
            "The goal here still is there is to basically make sure that the number of rounds become larger and larger.",
            "We can push the performance measure to 0.",
            "OK, so why?",
            "Why do we consider this form of performance measure?",
            "So the reason we consider this.",
            "We took this form of performance measure is that it's specific enough that we can actually get a machinery to get bounds and to get tools to analyze these games.",
            "On the other hand, on the other hand, it's also general enough that we could put a lot of a lot of online learning games into into this framework and analyze them."
        ],
        [
            "So as examples, the first one is an extended notion of external regret called the fee.",
            "Regret it similar to the normal regret, except that here it's a transformation of your actions.",
            "The next example is what Jake described just a moment ago.",
            "The Blackwells approachability game, where we compare ourselves to the where we basically look at the distance to a convex set S. Another example is learning with global costs proposed by Amanda.",
            "Tell lots of other.",
            "There are lots of other applications like calibration, adaptive regret and tracking, best experts and so on.",
            "And Sasha will talk more about calibration."
        ],
        [
            "In the next talk.",
            "OK, so what's the key concept in analyzing and analyzing the complexity of these of these online games?",
            "So the key concept is the notion of the value of the game, so the value of the game is basically we are asking the question what's the best thing that learner can do against any adversary?",
            "So essentially it's the regret of the optimal or the performance measure.",
            "I'm going to just call it regret of the optimal learner against the optimal adversary.",
            "So the regret and we're going to allow randomized algorithms.",
            "So essentially we can write down the value as the first player go.",
            "I mean, the player or the learner goes first.",
            "He picks a distribution over his set of actions F and the adversary goes next.",
            "He does basically the best thing that he can do, choose the best action that he can do.",
            "And of course we have to.",
            "The learner draws the action from his distribution and the game basically are the definition of value, basically.",
            "Goes on similar fashion with alternating incense soaps.",
            "OK, so why is this quantity?",
            "Why is this concept important?",
            "The concept of value is important because of two things.",
            "First, we can show that there exists a randomized online algorithms whose expected regret is always bounded by the value of the game.",
            "And on the other hand, no algorithm can hope to achieve a regret better than the value of the game.",
            "So essentially the value of the game is a exact characterization of the hardness of this online learning problem.",
            "And before I proceed with the, I have a few comments, so the first one is pure.",
            "Of course, we're doing everything in expectation over the randomization of the algorithm, but high probability results are possible and you should have a look at the paper for more of those.",
            "The next is the number of rounds that we play 40 is fixed in advance, and for particular games like Calibration and Blackwell approachability and fear.",
            "Regret we can actually get rid of this.",
            "So the player the two players need not know Ty in advance, so you can still get almost sure convergence and the third is.",
            "The downside is that since we are trying to get bounds on this, it's going to be all the results are going to be nonconstructive.",
            "So there is, uh, once we get around this, it basically means that there exists an algorithm and online learning algorithm that can do as well as this, but we won't be pointing out to the algorithm.",
            "OK, so now let's actually try and."
        ],
        [
            "Get the machinery running so we start with the value of the game and with a little bit of with a little bit of work what we can do is we can show that the value of the game is bounded by three quantities, so the first quantity is a quantity that basically is a martingale convergence term.",
            "So let me show what this is with an example or illustrate what this is with an example.",
            "So for example, if you take the regret minimization case where B is just the average.",
            "And script age is essentially the reals, then this term is Supreme over joint distribution of expectation of this guy.",
            "What is this?",
            "This is basically average of LFT, XT minus its conditional expectation.",
            "So this basically 0 right because it's average of expectation of average of points minus the conditional expectation in general.",
            "Of course it's not going to be this easy, but in general we get a model convergence term and we can use simple tools from probability theory and concentration inequalities to basically bound this term.",
            "The second term is something that we'd like to call the best response term, so I'll try to roughly give you an idea of what the best response term consists of, so here is not exactly regret.",
            "You should probably see the paper for an exact equation for this, but you have something like a regret, regret, and but then notice that here the orders of the order of the players have switched, so you have the adversary going first and the player going next.",
            "And essentially what this is saying is that if we switch the roles of the players.",
            "Then how well can we solve the game?",
            "And it turns out that for most of the most of the games that we consider, or most of the games that are usually considered, this term can be easily bounded either either directly bounded by zero or bounded by some easy term.",
            "And the reason this is easy is because one is the best response term because every time the player gets to see what the adversary is doing and he chooses the best response according to that.",
            "And of course, so we have a martingale convergence terminal term which should be easy enough to bound.",
            "So where does the complexity of the problem come in?",
            "So this is essentially the third term.",
            "It's the problem, complexity term and OK.",
            "So where is the problem?",
            "Is the complexity of the problem coming in?",
            "Is it from the set script for the set Script X?",
            "It turns out that it's none of these is actually the transformation said fee of tea.",
            "So essentially the martingale convergence term.",
            "Sorry, the problem complexity term is a form of uniform martingale convergence term.",
            "It's uniform over the set of transformations fee.",
            "And of course, for external regret, fee was directly corresponded to the set F, so then for external regret case, it's just.",
            "The complexity is characterized by the complexity of the class script F, but in general is characterized by the class fee.",
            "OK, so this beast here is a little hard to hard to get direct bounds on, so we're going to use the trick of symmetrization that's used in, for instance, forgetting classical Rademacher complexity.",
            "We're going to do that, but in a sequential manner to actually get be."
        ],
        [
            "Quickly complexity, which is like Sarah marker complexity on steroids.",
            "So this basically looks like Rademacher complexity, but instead of supremum over sequences, we have a Supreme over trees.",
            "And again we have expectation with respect to random signs instead of going through this messy equation, let me show it to you as an example.",
            "So let's say you have an F under next tree, but I'm only going to do with the next tree, so you have an extra here.",
            "So what's the extreme?",
            "It's length.",
            "It's a tree with the deputy.",
            "And the pluses and minuses essentially show the path and what sitting in each of the nodes is something from the set script text.",
            "And as an example, if we take epsilon to be plus 1 -- 1 -- 1, what part does it correspond to?",
            "It corresponds to basically left and.",
            "Basically, this guy left and right and right.",
            "And So what does this inner term here correspond to?",
            "So, given a fee and an F, the senior term corresponds to putting X one X3 and X and so on F1F3F6.",
            "And the signs here that we multiply with them is essentially the signs of the plus and minus.",
            "Notice that if this B was ascentia was an average, then this quantity here.",
            "This piece here is the sequential order complexity.",
            "OK, so why is this useful?",
            "This is useful because the sequential Rademacher complexity bounds the problem complexity."
        ],
        [
            "So it bounds the third term.",
            "You can show that if B is subadditive, then the third term is bounded by two times the sequential order complexity.",
            "So let's look at an example of how we can use this or where."
        ],
        [
            "You can use this, so let's so we're going to use the setting where where B of Z1 through ZT we consider the specific setting where B of Z1 through ZT is a function of the average.",
            "So it's G of average of the zipties.",
            "So here's the teaser vectors, and we also assume that G is 1 Lipschitz with respect to some smooth norm, this one.",
            "OK, so in this case if supposing the class of transformations were finite, then what's the rate that you would expect?",
            "Any guesses?",
            "Yeah, log cardinality so low cardinality by T because it's divided by T and that's sorry.",
            "I forgot to give you examples examples of G or linear and the Euclidean norm, Hilbert space and Hilbert norm and so on.",
            "So that's exactly what you get.",
            "You essentially get the complexity.",
            "Sequential complexity is bounded by square root log cardinality divided by T, and of course we need that the loss is bounded.",
            "I mean the one in the usual case you need the losses bonded.",
            "Here we need bounded under their arm.",
            "OK, so this answers for finite cardinality cardinality transformations.",
            "What about when feasibility is has infinite cardinality?",
            "Then what does the trick that we use?",
            "So the usual trick that we use is go to covering numbers well, but how do we do covering numbers for this?",
            "This kind of more complex scenario, so here it turns out that the symmetrization that we did in the Rademacher complexity, the epsilons, the plus minus one remember them.",
            "So they basically give you a tree."
        ],
        [
            "And so the covering number turns out to be kind of related to trees, binary trees.",
            "So instead of going through the formal definition, let me give you pictorial kind of explanation.",
            "So let's say that you are given an F and X3 and fee consists of these three functions Phi Phi Prime and Phi double prime, and it evaluates to these things.",
            "So it's a 2 dimensional example.",
            "So what's a cover for this?",
            "A cover for this is a set of scripts, value trees.",
            "So for example, these two.",
            "Why is this a cover?",
            "Because pick any fee.",
            "For instance, let's say we pick this one.",
            "And let's say we pick this path.",
            "So for this for this particular tree and this path, we see that there exists a tree here, such that on that path.",
            "It's the same value here.",
            "Of course, we just need their Alpha close.",
            "For covering number at scale Alpha and basically the covering number is the smallest set that covers.",
            "And the nice part about the why we need discovering number is now the covering number.",
            "Kind of replaces the cardinality.",
            "We can do a little better than that, and instead of so we can actually give a Dudley integral type bound.",
            "Don't worry about the constants and stuff, it's just a Dudley integral bound with the log, it's analog."
        ],
        [
            "After the deadly integrable.",
            "OK, so let's move onto examples.",
            "So the first example that we look at is the fear regret minimization example.",
            "So here it has a form.",
            "The regret has a form very similar to external regret, except that your fee comes from a set of transformations.",
            "Here, each feed Maps from script descriptive.",
            "So for instance, if capital fee was the set of all set of all constant transformation, this is the same as external regret.",
            "Of course, we can allow different transformations out here.",
            "So what we can show in this case is that the value of the game is bounded by two times the sequential complexity.",
            "So once we do this and notice that here B is linear, so we can use our result for instance for finite fee.",
            "So for instance swap regret where you consider all functions you can get a square root cardinality log cardinality divided by T internal regret you can get square root log cardinality by T. You can also go to infinite classes so you can go to an online convex optimization type scenario where your script F is some unit ball in a Hilbert space and your transformations are linear transformations with some bounded operator norm.",
            "And in this case you can get square root.",
            "Over T you can look at metric entropy case and kind of improves on previous result by certain legacy but."
        ],
        [
            "Beyond this, what we're what we can really do is we can kind of go beyond metric entropy type type bounds, and we can go into sequential covering number.",
            "The one that I introduced and so you can look at larger sets fee and get bounds for them.",
            "And you can also the other thing that you can do is you can go to bounds for settings beyond online convex optimization for losses which are not convex, you can still do that and another kind of related topic to the feeder.",
            "Regret notion is the notion of correlated equilibrium.",
            "So we can show faster convergence rate to free correlated equilibrium for certain."
        ],
        [
            "OK, the next example is the one that Jake nicely described for me before.",
            "Thanks, Jay.",
            "So the Blackwell approachability problem we want to approach this set S so we want this average pay offs to reach this set S and the nice thing here is that we first we can go go to General Banach spaces and it's kind of free of cost.",
            "And this example is kind of really nice because it shows that all that you need for this example, all you need to do to get results is take the problem, put it in the framework that I gave you, and the triplex inequality already gives you the results.",
            "So the result that we can show is that for anyone short, approachable game, so one shot.",
            "Approachability, I think it was what Jake called as.",
            "Responce satisfiability, thanks Ann.",
            "For such game you can basically show that the value is upper bounded by the rate at which Martindale different sequences in this backspace converge.",
            "So here the teaser Martindale, different sequences which take values in the absolute contact seller Script H. Now of course one can ask how tight are these rates and what we can in fact show is that for any symmetric convex at H you can come up with a one shot approachable game such that the value of the game is also lower bonded to within constant of the martini.",
            "Convergence and so essentially what we do is we can establish titrates for things like the Euclidean approach ability in the Euclidean space approach ability in D dimensional L1 space, and in D dimensional Infinity space.",
            "But more than that, what we can do is go to examples like Hilbert Nauman, matrix norm and of course we have a tight characterization of the rates for these problems."
        ],
        [
            "So there are of course other applications calibration with special deal with global cost learning tracking best expert and of course here we not only recover results, we can also get go to infinite function classes slowly varying transformation where what you compare with just varies a little bit each step.",
            "Adaptive regret introduced by Hazen and Shodry.",
            "Here again we can go to settings beyond online convex optimization setting and OK, so that's for the applications."
        ],
        [
            "Now I'd like to give some kind of future direction or some questions that might be interesting.",
            "So the first one, of course, is whatever I presented was was nonconstructive, and now we have a tool that kind of characterizes the hardness or the problem complexity.",
            "So can we use this sequential complexity and formal generic algorithm that's based on the sequential complexity?",
            "The next question.",
            "OK, so before I move on to the next question, basically what we did today is kind of extend on this line.",
            "We have the adversarial external regret, but then we kind of got a framework that captures things here.",
            "A common framework for all of them.",
            "But now there is another direction that we can explore.",
            "The other direction is what if the adversary is not is not worst case?",
            "Or is not?",
            "Yeah, it's not completely adversarial, but has some constraints or stochastic, for instance, so we can what we'd like to do is really explore this 2 dimensional space.",
            "So we do.",
            "I like to point out that we do have like some results, so we have only on this particular line.",
            "So we have some results for external regret with stochastic or constraint adversary you can look at the archive version.",
            "And the most kind of interesting thing for me question that would be really nice to get some hold on is what if we consider games with partial information?",
            "So this is the third dimension.",
            "So right now we're looking at a game that games where we have complete information where we know what the other player player has played as soon as round is over.",
            "But what if we only get partial feedback?",
            "Can we get a generic kind of generic toolbox that kind of that can handle anything in this 3 dimensional space?"
        ],
        [
            "So thanks and question.",
            "This XXX inequality is strong enough to prove logarithmic regret bounds.",
            "Uh.",
            "Logitech regret bounds no no, I mean so.",
            "The triplex inequality itself.",
            "The triplex inequality is the first step.",
            "The sequential complexity is a question, so I guess, so we have the sequential complexity, which covers the worst case to get the log rhythmic regret bounds.",
            "I mean, our conjecture is there should be some form of local sequential complexity type thing, but we haven't been able to get that even for the external regret case.",
            "So can you actually show lock lock with Nick regret just with the minimax formulation?",
            "So can you just before you go into the triplex, can you just massage that Minimax formulation to get to show love with?",
            "So that's kind of what we tried.",
            "Oh, for quadratic we can get, but but not.",
            "I mean in general, like for strongly contingent, general, strongly convex.",
            "We weren't able to get, so if you just consider external regret, then all of this is.",
            "I mean then you don't need the triplex inequality, there's just one term which is the problem complexity term that occurs, which is what was done in the newspaper.",
            "It's the, it's the sequential order complexity, and so if you want to get the faster rate then you need.",
            "I don't know.",
            "I think I need you need like some form of local sequential regimen complexity.",
            "But yeah, right now.",
            "I mean we have a formulation for the quadratic loss, but we are not able to recover general fast fields.",
            "That will give you an explicit algorithm, even if it's inefficient, But let's say an Oracle that will.",
            "So that's the thing.",
            "I mean, the 1 min Max or something like that.",
            "Yeah, so I mean, I guess I didn't actually go through like the proof essence.",
            "So one of the key step in the proof is that we use one nine months min Max in equal or a version of that.",
            "So once the once a player roles are swapped then what happens is that you get so we get a strategy in the dual.",
            "But then, in the general case, we don't know how to convert that to a strategy in the primal.",
            "So of course, so far the external regret.",
            "So the result by David Sheehan shy.",
            "Basically they take the little stone dimension, which is I mean like mutant.",
            "From this point it's like a dual quantity, but you take that and then you actually get an algorithm in the primal and you can extend that to for instance for real real valued supervised learning problems.",
            "But beyond that we still don't know.",
            "So you have a characterization examples of those covering numbers or the other numbers.",
            "But can you express it as some more combinatorial explicit property of the of the family?",
            "Or for certain cases, yes.",
            "So for the fear regret case we can, we can get an unlock of fat shattering dimension, which works for the feeder grid.",
            "The thing is so for, so I actually kind of didn't differentiate between transformations that vary at each time step versus ones that remain fixed.",
            "If they remain so in some sense.",
            "So when we tried the combinatorial properties, if they vary at each time step, then there is no way to kind of get a handle on them.",
            "But if they are fixed at each time step, then at least for certain cases we were able to workout combinatorial properties.",
            "So even for the non case there is a combinatorial property, but we suspect it's not tight, it's just that it's kind of a loose.",
            "Up alone, but yeah, for the figure it we do have and for the field grade you can show that certain cases it is actually died.",
            "Last question.",
            "So in the IID case, rather marker complexity captures uniform convergence, right?",
            "So, but you are working in a general setting and we know that listing the ID case that learnability is not equivalent to uniform convergence.",
            "So how our same example will show that uniform convergence?",
            "So there are cases where the sequential Rademacher complexity is cannot be bounded by.",
            "I mean it cannot be bounded by within like it can only be bounded by order one.",
            "But then you can still, it's still learnable.",
            "It's still the same case, but the one kind of saving grace in in online learning setting is that.",
            "So, for instance, the example that we considered was was online convex optimization problem, right?",
            "So you take the online convex optimization problem.",
            "The complexity of the sequential marker complexity of that is not mean.",
            "We can't get a useful bound, but then you take that and then.",
            "So there are you can.",
            "You can basically see that the value of the online convex optimization game is same as the value of the linear game.",
            "And then you go to the linear Adam marker of the linear and that's bound.",
            "You can bound that.",
            "So basically through some reductions you can still get back all the results of online convex optimization, but not directly.",
            "So and in the appendix of the at least the full full version of this paper we have like we have like a few, at least like there's a llama which basically says.",
            "When can you do a reduction from one game to another?",
            "More generality than just online convex optimization to linear?",
            "OK thanks, let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The story in the Statistical learning world is nice, but we have nature that basically selects a distribution is not given to the learner.",
                    "label": 0
                },
                {
                    "sent": "The learner basically has to learn are basically has to learn based on the samples that he gets and here basically the tools that we have to analyze this learning problem.",
                    "label": 0
                },
                {
                    "sent": "We have a we have a huge bag of tools with a lot of complexity measures like Rademacher Complexity, VC dimension and so on.",
                    "label": 0
                },
                {
                    "sent": "And the online learning world things are slightly different, at least most of the work has been more algorithmic and little case by case.",
                    "label": 0
                },
                {
                    "sent": "So only recently we've been.",
                    "label": 0
                },
                {
                    "sent": "We've started having kind of a toolbox for generic toolbox for online learning, so little shown introduced this little Son Dimension, and David and Shy and Shy basically showed that for agnostic learning you can essentially this access as an analog for VC dimension and you know previous NIPS paper we showed that you actually can get analogs for things like Rademacher complexity, covering numbers, and most of this.",
                    "label": 0
                },
                {
                    "sent": "So basically we can fill up the online learning tool box with most of the tools that we.",
                    "label": 0
                },
                {
                    "sent": "With analogs of the tools that we had in the statistical learning world.",
                    "label": 0
                },
                {
                    "sent": "But of course not all.",
                    "label": 0
                },
                {
                    "sent": "Not all online learning problems are regret based problems or regret minimization problems.",
                    "label": 0
                },
                {
                    "sent": "So today we're going to look at is online learning going beyond the beyond regret minimization type problems, and the basic idea is I'm going to give you a framework.",
                    "label": 0
                },
                {
                    "sent": "So to put your online learning problem in and machinery so you can try and get bound.",
                    "label": 0
                },
                {
                    "sent": "So the idea is you take your favorite online learning problem.",
                    "label": 0
                },
                {
                    "sent": "Put it in the framework, crank the crank the wheel and you start getting both.",
                    "label": 0
                },
                {
                    "sent": "Hopefully I can do that.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's review the online learning game.",
                    "label": 1
                },
                {
                    "sent": "So it's a two player game between a player and an adversary.",
                    "label": 0
                },
                {
                    "sent": "It's a multi round game where at each round the learner picks an action FT from his action set script.",
                    "label": 0
                },
                {
                    "sent": "If the adversary freaks and action XD from this action set Script X and this happens simultaneously and player basically suffers loss LFT, XD.",
                    "label": 0
                },
                {
                    "sent": "So what's the notion of performance?",
                    "label": 1
                },
                {
                    "sent": "The usual notion of performance we are familiar with is the notion of external regret.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "We basically look at what's the average loss that the player suffered for the tearooms and we see how good was this compared to the best that he could have done.",
                    "label": 0
                },
                {
                    "sent": "If you had picked the single best action at hindsight.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is we want to extend this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moments measure out here.",
                    "label": 0
                },
                {
                    "sent": "So the first thing we do is why average?",
                    "label": 0
                },
                {
                    "sent": "I mean why do we look at cumulative costs?",
                    "label": 0
                },
                {
                    "sent": "Just the average cost?",
                    "label": 0
                },
                {
                    "sent": "So instead we are going to use a function B that takes in the T losses and Maps it to the reals.",
                    "label": 0
                },
                {
                    "sent": "And once we do this immediately, we see that the last no longer actually even needs to be real valued.",
                    "label": 0
                },
                {
                    "sent": "So throughout this talk, I'm going to assume that the loss is H valued, where H is a subset of some backspace.",
                    "label": 1
                },
                {
                    "sent": "And be basically Maps these T losses that we received to the reals.",
                    "label": 1
                },
                {
                    "sent": "This Ibiza form of cumulative loss costs.",
                    "label": 0
                },
                {
                    "sent": "OK, the next thing that we do is instead of comparing with the best with the best action at hindsight, we're going to do a transformation.",
                    "label": 0
                },
                {
                    "sent": "So every time that we see L of F1, X one, we're going to transform it to LP, one of F1, X1, where Phi is a transformation chosen from PCP.",
                    "label": 0
                },
                {
                    "sent": "So fee is basically a sequence of transformations which transforms each of these pay offs to these ones, and we want to comparing ourselves against the best transformation one can immediately see that.",
                    "label": 0
                },
                {
                    "sent": "External regret itself can be returned back in this format if they were just the average and if this transformation is basically only changes F1 to single F. And of course, what's the goal here?",
                    "label": 1
                },
                {
                    "sent": "The goal here still is there is to basically make sure that the number of rounds become larger and larger.",
                    "label": 0
                },
                {
                    "sent": "We can push the performance measure to 0.",
                    "label": 0
                },
                {
                    "sent": "OK, so why?",
                    "label": 0
                },
                {
                    "sent": "Why do we consider this form of performance measure?",
                    "label": 1
                },
                {
                    "sent": "So the reason we consider this.",
                    "label": 0
                },
                {
                    "sent": "We took this form of performance measure is that it's specific enough that we can actually get a machinery to get bounds and to get tools to analyze these games.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, on the other hand, it's also general enough that we could put a lot of a lot of online learning games into into this framework and analyze them.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as examples, the first one is an extended notion of external regret called the fee.",
                    "label": 0
                },
                {
                    "sent": "Regret it similar to the normal regret, except that here it's a transformation of your actions.",
                    "label": 0
                },
                {
                    "sent": "The next example is what Jake described just a moment ago.",
                    "label": 0
                },
                {
                    "sent": "The Blackwells approachability game, where we compare ourselves to the where we basically look at the distance to a convex set S. Another example is learning with global costs proposed by Amanda.",
                    "label": 1
                },
                {
                    "sent": "Tell lots of other.",
                    "label": 1
                },
                {
                    "sent": "There are lots of other applications like calibration, adaptive regret and tracking, best experts and so on.",
                    "label": 0
                },
                {
                    "sent": "And Sasha will talk more about calibration.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the next talk.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the key concept in analyzing and analyzing the complexity of these of these online games?",
                    "label": 0
                },
                {
                    "sent": "So the key concept is the notion of the value of the game, so the value of the game is basically we are asking the question what's the best thing that learner can do against any adversary?",
                    "label": 0
                },
                {
                    "sent": "So essentially it's the regret of the optimal or the performance measure.",
                    "label": 0
                },
                {
                    "sent": "I'm going to just call it regret of the optimal learner against the optimal adversary.",
                    "label": 1
                },
                {
                    "sent": "So the regret and we're going to allow randomized algorithms.",
                    "label": 0
                },
                {
                    "sent": "So essentially we can write down the value as the first player go.",
                    "label": 0
                },
                {
                    "sent": "I mean, the player or the learner goes first.",
                    "label": 0
                },
                {
                    "sent": "He picks a distribution over his set of actions F and the adversary goes next.",
                    "label": 0
                },
                {
                    "sent": "He does basically the best thing that he can do, choose the best action that he can do.",
                    "label": 0
                },
                {
                    "sent": "And of course we have to.",
                    "label": 0
                },
                {
                    "sent": "The learner draws the action from his distribution and the game basically are the definition of value, basically.",
                    "label": 0
                },
                {
                    "sent": "Goes on similar fashion with alternating incense soaps.",
                    "label": 0
                },
                {
                    "sent": "OK, so why is this quantity?",
                    "label": 0
                },
                {
                    "sent": "Why is this concept important?",
                    "label": 0
                },
                {
                    "sent": "The concept of value is important because of two things.",
                    "label": 1
                },
                {
                    "sent": "First, we can show that there exists a randomized online algorithms whose expected regret is always bounded by the value of the game.",
                    "label": 1
                },
                {
                    "sent": "And on the other hand, no algorithm can hope to achieve a regret better than the value of the game.",
                    "label": 0
                },
                {
                    "sent": "So essentially the value of the game is a exact characterization of the hardness of this online learning problem.",
                    "label": 0
                },
                {
                    "sent": "And before I proceed with the, I have a few comments, so the first one is pure.",
                    "label": 0
                },
                {
                    "sent": "Of course, we're doing everything in expectation over the randomization of the algorithm, but high probability results are possible and you should have a look at the paper for more of those.",
                    "label": 0
                },
                {
                    "sent": "The next is the number of rounds that we play 40 is fixed in advance, and for particular games like Calibration and Blackwell approachability and fear.",
                    "label": 0
                },
                {
                    "sent": "Regret we can actually get rid of this.",
                    "label": 0
                },
                {
                    "sent": "So the player the two players need not know Ty in advance, so you can still get almost sure convergence and the third is.",
                    "label": 0
                },
                {
                    "sent": "The downside is that since we are trying to get bounds on this, it's going to be all the results are going to be nonconstructive.",
                    "label": 0
                },
                {
                    "sent": "So there is, uh, once we get around this, it basically means that there exists an algorithm and online learning algorithm that can do as well as this, but we won't be pointing out to the algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so now let's actually try and.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get the machinery running so we start with the value of the game and with a little bit of with a little bit of work what we can do is we can show that the value of the game is bounded by three quantities, so the first quantity is a quantity that basically is a martingale convergence term.",
                    "label": 0
                },
                {
                    "sent": "So let me show what this is with an example or illustrate what this is with an example.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you take the regret minimization case where B is just the average.",
                    "label": 0
                },
                {
                    "sent": "And script age is essentially the reals, then this term is Supreme over joint distribution of expectation of this guy.",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "This is basically average of LFT, XT minus its conditional expectation.",
                    "label": 0
                },
                {
                    "sent": "So this basically 0 right because it's average of expectation of average of points minus the conditional expectation in general.",
                    "label": 0
                },
                {
                    "sent": "Of course it's not going to be this easy, but in general we get a model convergence term and we can use simple tools from probability theory and concentration inequalities to basically bound this term.",
                    "label": 0
                },
                {
                    "sent": "The second term is something that we'd like to call the best response term, so I'll try to roughly give you an idea of what the best response term consists of, so here is not exactly regret.",
                    "label": 0
                },
                {
                    "sent": "You should probably see the paper for an exact equation for this, but you have something like a regret, regret, and but then notice that here the orders of the order of the players have switched, so you have the adversary going first and the player going next.",
                    "label": 0
                },
                {
                    "sent": "And essentially what this is saying is that if we switch the roles of the players.",
                    "label": 0
                },
                {
                    "sent": "Then how well can we solve the game?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that for most of the most of the games that we consider, or most of the games that are usually considered, this term can be easily bounded either either directly bounded by zero or bounded by some easy term.",
                    "label": 0
                },
                {
                    "sent": "And the reason this is easy is because one is the best response term because every time the player gets to see what the adversary is doing and he chooses the best response according to that.",
                    "label": 0
                },
                {
                    "sent": "And of course, so we have a martingale convergence terminal term which should be easy enough to bound.",
                    "label": 0
                },
                {
                    "sent": "So where does the complexity of the problem come in?",
                    "label": 0
                },
                {
                    "sent": "So this is essentially the third term.",
                    "label": 0
                },
                {
                    "sent": "It's the problem, complexity term and OK.",
                    "label": 0
                },
                {
                    "sent": "So where is the problem?",
                    "label": 0
                },
                {
                    "sent": "Is the complexity of the problem coming in?",
                    "label": 0
                },
                {
                    "sent": "Is it from the set script for the set Script X?",
                    "label": 0
                },
                {
                    "sent": "It turns out that it's none of these is actually the transformation said fee of tea.",
                    "label": 0
                },
                {
                    "sent": "So essentially the martingale convergence term.",
                    "label": 1
                },
                {
                    "sent": "Sorry, the problem complexity term is a form of uniform martingale convergence term.",
                    "label": 1
                },
                {
                    "sent": "It's uniform over the set of transformations fee.",
                    "label": 0
                },
                {
                    "sent": "And of course, for external regret, fee was directly corresponded to the set F, so then for external regret case, it's just.",
                    "label": 0
                },
                {
                    "sent": "The complexity is characterized by the complexity of the class script F, but in general is characterized by the class fee.",
                    "label": 0
                },
                {
                    "sent": "OK, so this beast here is a little hard to hard to get direct bounds on, so we're going to use the trick of symmetrization that's used in, for instance, forgetting classical Rademacher complexity.",
                    "label": 0
                },
                {
                    "sent": "We're going to do that, but in a sequential manner to actually get be.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quickly complexity, which is like Sarah marker complexity on steroids.",
                    "label": 1
                },
                {
                    "sent": "So this basically looks like Rademacher complexity, but instead of supremum over sequences, we have a Supreme over trees.",
                    "label": 0
                },
                {
                    "sent": "And again we have expectation with respect to random signs instead of going through this messy equation, let me show it to you as an example.",
                    "label": 0
                },
                {
                    "sent": "So let's say you have an F under next tree, but I'm only going to do with the next tree, so you have an extra here.",
                    "label": 0
                },
                {
                    "sent": "So what's the extreme?",
                    "label": 0
                },
                {
                    "sent": "It's length.",
                    "label": 0
                },
                {
                    "sent": "It's a tree with the deputy.",
                    "label": 0
                },
                {
                    "sent": "And the pluses and minuses essentially show the path and what sitting in each of the nodes is something from the set script text.",
                    "label": 1
                },
                {
                    "sent": "And as an example, if we take epsilon to be plus 1 -- 1 -- 1, what part does it correspond to?",
                    "label": 0
                },
                {
                    "sent": "It corresponds to basically left and.",
                    "label": 0
                },
                {
                    "sent": "Basically, this guy left and right and right.",
                    "label": 0
                },
                {
                    "sent": "And So what does this inner term here correspond to?",
                    "label": 0
                },
                {
                    "sent": "So, given a fee and an F, the senior term corresponds to putting X one X3 and X and so on F1F3F6.",
                    "label": 0
                },
                {
                    "sent": "And the signs here that we multiply with them is essentially the signs of the plus and minus.",
                    "label": 0
                },
                {
                    "sent": "Notice that if this B was ascentia was an average, then this quantity here.",
                    "label": 0
                },
                {
                    "sent": "This piece here is the sequential order complexity.",
                    "label": 1
                },
                {
                    "sent": "OK, so why is this useful?",
                    "label": 0
                },
                {
                    "sent": "This is useful because the sequential Rademacher complexity bounds the problem complexity.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it bounds the third term.",
                    "label": 0
                },
                {
                    "sent": "You can show that if B is subadditive, then the third term is bounded by two times the sequential order complexity.",
                    "label": 1
                },
                {
                    "sent": "So let's look at an example of how we can use this or where.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can use this, so let's so we're going to use the setting where where B of Z1 through ZT we consider the specific setting where B of Z1 through ZT is a function of the average.",
                    "label": 0
                },
                {
                    "sent": "So it's G of average of the zipties.",
                    "label": 0
                },
                {
                    "sent": "So here's the teaser vectors, and we also assume that G is 1 Lipschitz with respect to some smooth norm, this one.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case if supposing the class of transformations were finite, then what's the rate that you would expect?",
                    "label": 0
                },
                {
                    "sent": "Any guesses?",
                    "label": 0
                },
                {
                    "sent": "Yeah, log cardinality so low cardinality by T because it's divided by T and that's sorry.",
                    "label": 0
                },
                {
                    "sent": "I forgot to give you examples examples of G or linear and the Euclidean norm, Hilbert space and Hilbert norm and so on.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly what you get.",
                    "label": 0
                },
                {
                    "sent": "You essentially get the complexity.",
                    "label": 0
                },
                {
                    "sent": "Sequential complexity is bounded by square root log cardinality divided by T, and of course we need that the loss is bounded.",
                    "label": 0
                },
                {
                    "sent": "I mean the one in the usual case you need the losses bonded.",
                    "label": 0
                },
                {
                    "sent": "Here we need bounded under their arm.",
                    "label": 0
                },
                {
                    "sent": "OK, so this answers for finite cardinality cardinality transformations.",
                    "label": 0
                },
                {
                    "sent": "What about when feasibility is has infinite cardinality?",
                    "label": 0
                },
                {
                    "sent": "Then what does the trick that we use?",
                    "label": 0
                },
                {
                    "sent": "So the usual trick that we use is go to covering numbers well, but how do we do covering numbers for this?",
                    "label": 0
                },
                {
                    "sent": "This kind of more complex scenario, so here it turns out that the symmetrization that we did in the Rademacher complexity, the epsilons, the plus minus one remember them.",
                    "label": 0
                },
                {
                    "sent": "So they basically give you a tree.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the covering number turns out to be kind of related to trees, binary trees.",
                    "label": 0
                },
                {
                    "sent": "So instead of going through the formal definition, let me give you pictorial kind of explanation.",
                    "label": 0
                },
                {
                    "sent": "So let's say that you are given an F and X3 and fee consists of these three functions Phi Phi Prime and Phi double prime, and it evaluates to these things.",
                    "label": 0
                },
                {
                    "sent": "So it's a 2 dimensional example.",
                    "label": 0
                },
                {
                    "sent": "So what's a cover for this?",
                    "label": 0
                },
                {
                    "sent": "A cover for this is a set of scripts, value trees.",
                    "label": 0
                },
                {
                    "sent": "So for example, these two.",
                    "label": 0
                },
                {
                    "sent": "Why is this a cover?",
                    "label": 0
                },
                {
                    "sent": "Because pick any fee.",
                    "label": 0
                },
                {
                    "sent": "For instance, let's say we pick this one.",
                    "label": 0
                },
                {
                    "sent": "And let's say we pick this path.",
                    "label": 0
                },
                {
                    "sent": "So for this for this particular tree and this path, we see that there exists a tree here, such that on that path.",
                    "label": 0
                },
                {
                    "sent": "It's the same value here.",
                    "label": 0
                },
                {
                    "sent": "Of course, we just need their Alpha close.",
                    "label": 0
                },
                {
                    "sent": "For covering number at scale Alpha and basically the covering number is the smallest set that covers.",
                    "label": 0
                },
                {
                    "sent": "And the nice part about the why we need discovering number is now the covering number.",
                    "label": 0
                },
                {
                    "sent": "Kind of replaces the cardinality.",
                    "label": 0
                },
                {
                    "sent": "We can do a little better than that, and instead of so we can actually give a Dudley integral type bound.",
                    "label": 0
                },
                {
                    "sent": "Don't worry about the constants and stuff, it's just a Dudley integral bound with the log, it's analog.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After the deadly integrable.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's move onto examples.",
                    "label": 0
                },
                {
                    "sent": "So the first example that we look at is the fear regret minimization example.",
                    "label": 0
                },
                {
                    "sent": "So here it has a form.",
                    "label": 0
                },
                {
                    "sent": "The regret has a form very similar to external regret, except that your fee comes from a set of transformations.",
                    "label": 0
                },
                {
                    "sent": "Here, each feed Maps from script descriptive.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if capital fee was the set of all set of all constant transformation, this is the same as external regret.",
                    "label": 0
                },
                {
                    "sent": "Of course, we can allow different transformations out here.",
                    "label": 0
                },
                {
                    "sent": "So what we can show in this case is that the value of the game is bounded by two times the sequential complexity.",
                    "label": 0
                },
                {
                    "sent": "So once we do this and notice that here B is linear, so we can use our result for instance for finite fee.",
                    "label": 0
                },
                {
                    "sent": "So for instance swap regret where you consider all functions you can get a square root cardinality log cardinality divided by T internal regret you can get square root log cardinality by T. You can also go to infinite classes so you can go to an online convex optimization type scenario where your script F is some unit ball in a Hilbert space and your transformations are linear transformations with some bounded operator norm.",
                    "label": 0
                },
                {
                    "sent": "And in this case you can get square root.",
                    "label": 0
                },
                {
                    "sent": "Over T you can look at metric entropy case and kind of improves on previous result by certain legacy but.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Beyond this, what we're what we can really do is we can kind of go beyond metric entropy type type bounds, and we can go into sequential covering number.",
                    "label": 0
                },
                {
                    "sent": "The one that I introduced and so you can look at larger sets fee and get bounds for them.",
                    "label": 0
                },
                {
                    "sent": "And you can also the other thing that you can do is you can go to bounds for settings beyond online convex optimization for losses which are not convex, you can still do that and another kind of related topic to the feeder.",
                    "label": 0
                },
                {
                    "sent": "Regret notion is the notion of correlated equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So we can show faster convergence rate to free correlated equilibrium for certain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the next example is the one that Jake nicely described for me before.",
                    "label": 0
                },
                {
                    "sent": "Thanks, Jay.",
                    "label": 0
                },
                {
                    "sent": "So the Blackwell approachability problem we want to approach this set S so we want this average pay offs to reach this set S and the nice thing here is that we first we can go go to General Banach spaces and it's kind of free of cost.",
                    "label": 1
                },
                {
                    "sent": "And this example is kind of really nice because it shows that all that you need for this example, all you need to do to get results is take the problem, put it in the framework that I gave you, and the triplex inequality already gives you the results.",
                    "label": 0
                },
                {
                    "sent": "So the result that we can show is that for anyone short, approachable game, so one shot.",
                    "label": 0
                },
                {
                    "sent": "Approachability, I think it was what Jake called as.",
                    "label": 0
                },
                {
                    "sent": "Responce satisfiability, thanks Ann.",
                    "label": 0
                },
                {
                    "sent": "For such game you can basically show that the value is upper bounded by the rate at which Martindale different sequences in this backspace converge.",
                    "label": 0
                },
                {
                    "sent": "So here the teaser Martindale, different sequences which take values in the absolute contact seller Script H. Now of course one can ask how tight are these rates and what we can in fact show is that for any symmetric convex at H you can come up with a one shot approachable game such that the value of the game is also lower bonded to within constant of the martini.",
                    "label": 1
                },
                {
                    "sent": "Convergence and so essentially what we do is we can establish titrates for things like the Euclidean approach ability in the Euclidean space approach ability in D dimensional L1 space, and in D dimensional Infinity space.",
                    "label": 1
                },
                {
                    "sent": "But more than that, what we can do is go to examples like Hilbert Nauman, matrix norm and of course we have a tight characterization of the rates for these problems.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are of course other applications calibration with special deal with global cost learning tracking best expert and of course here we not only recover results, we can also get go to infinite function classes slowly varying transformation where what you compare with just varies a little bit each step.",
                    "label": 1
                },
                {
                    "sent": "Adaptive regret introduced by Hazen and Shodry.",
                    "label": 0
                },
                {
                    "sent": "Here again we can go to settings beyond online convex optimization setting and OK, so that's for the applications.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'd like to give some kind of future direction or some questions that might be interesting.",
                    "label": 0
                },
                {
                    "sent": "So the first one, of course, is whatever I presented was was nonconstructive, and now we have a tool that kind of characterizes the hardness or the problem complexity.",
                    "label": 0
                },
                {
                    "sent": "So can we use this sequential complexity and formal generic algorithm that's based on the sequential complexity?",
                    "label": 1
                },
                {
                    "sent": "The next question.",
                    "label": 0
                },
                {
                    "sent": "OK, so before I move on to the next question, basically what we did today is kind of extend on this line.",
                    "label": 1
                },
                {
                    "sent": "We have the adversarial external regret, but then we kind of got a framework that captures things here.",
                    "label": 0
                },
                {
                    "sent": "A common framework for all of them.",
                    "label": 0
                },
                {
                    "sent": "But now there is another direction that we can explore.",
                    "label": 0
                },
                {
                    "sent": "The other direction is what if the adversary is not is not worst case?",
                    "label": 0
                },
                {
                    "sent": "Or is not?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's not completely adversarial, but has some constraints or stochastic, for instance, so we can what we'd like to do is really explore this 2 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So we do.",
                    "label": 0
                },
                {
                    "sent": "I like to point out that we do have like some results, so we have only on this particular line.",
                    "label": 0
                },
                {
                    "sent": "So we have some results for external regret with stochastic or constraint adversary you can look at the archive version.",
                    "label": 0
                },
                {
                    "sent": "And the most kind of interesting thing for me question that would be really nice to get some hold on is what if we consider games with partial information?",
                    "label": 0
                },
                {
                    "sent": "So this is the third dimension.",
                    "label": 0
                },
                {
                    "sent": "So right now we're looking at a game that games where we have complete information where we know what the other player player has played as soon as round is over.",
                    "label": 0
                },
                {
                    "sent": "But what if we only get partial feedback?",
                    "label": 0
                },
                {
                    "sent": "Can we get a generic kind of generic toolbox that kind of that can handle anything in this 3 dimensional space?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thanks and question.",
                    "label": 0
                },
                {
                    "sent": "This XXX inequality is strong enough to prove logarithmic regret bounds.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Logitech regret bounds no no, I mean so.",
                    "label": 0
                },
                {
                    "sent": "The triplex inequality itself.",
                    "label": 0
                },
                {
                    "sent": "The triplex inequality is the first step.",
                    "label": 0
                },
                {
                    "sent": "The sequential complexity is a question, so I guess, so we have the sequential complexity, which covers the worst case to get the log rhythmic regret bounds.",
                    "label": 0
                },
                {
                    "sent": "I mean, our conjecture is there should be some form of local sequential complexity type thing, but we haven't been able to get that even for the external regret case.",
                    "label": 0
                },
                {
                    "sent": "So can you actually show lock lock with Nick regret just with the minimax formulation?",
                    "label": 0
                },
                {
                    "sent": "So can you just before you go into the triplex, can you just massage that Minimax formulation to get to show love with?",
                    "label": 0
                },
                {
                    "sent": "So that's kind of what we tried.",
                    "label": 0
                },
                {
                    "sent": "Oh, for quadratic we can get, but but not.",
                    "label": 0
                },
                {
                    "sent": "I mean in general, like for strongly contingent, general, strongly convex.",
                    "label": 0
                },
                {
                    "sent": "We weren't able to get, so if you just consider external regret, then all of this is.",
                    "label": 0
                },
                {
                    "sent": "I mean then you don't need the triplex inequality, there's just one term which is the problem complexity term that occurs, which is what was done in the newspaper.",
                    "label": 0
                },
                {
                    "sent": "It's the, it's the sequential order complexity, and so if you want to get the faster rate then you need.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I think I need you need like some form of local sequential regimen complexity.",
                    "label": 0
                },
                {
                    "sent": "But yeah, right now.",
                    "label": 0
                },
                {
                    "sent": "I mean we have a formulation for the quadratic loss, but we are not able to recover general fast fields.",
                    "label": 0
                },
                {
                    "sent": "That will give you an explicit algorithm, even if it's inefficient, But let's say an Oracle that will.",
                    "label": 0
                },
                {
                    "sent": "So that's the thing.",
                    "label": 0
                },
                {
                    "sent": "I mean, the 1 min Max or something like that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I mean, I guess I didn't actually go through like the proof essence.",
                    "label": 0
                },
                {
                    "sent": "So one of the key step in the proof is that we use one nine months min Max in equal or a version of that.",
                    "label": 0
                },
                {
                    "sent": "So once the once a player roles are swapped then what happens is that you get so we get a strategy in the dual.",
                    "label": 0
                },
                {
                    "sent": "But then, in the general case, we don't know how to convert that to a strategy in the primal.",
                    "label": 0
                },
                {
                    "sent": "So of course, so far the external regret.",
                    "label": 0
                },
                {
                    "sent": "So the result by David Sheehan shy.",
                    "label": 0
                },
                {
                    "sent": "Basically they take the little stone dimension, which is I mean like mutant.",
                    "label": 0
                },
                {
                    "sent": "From this point it's like a dual quantity, but you take that and then you actually get an algorithm in the primal and you can extend that to for instance for real real valued supervised learning problems.",
                    "label": 0
                },
                {
                    "sent": "But beyond that we still don't know.",
                    "label": 0
                },
                {
                    "sent": "So you have a characterization examples of those covering numbers or the other numbers.",
                    "label": 0
                },
                {
                    "sent": "But can you express it as some more combinatorial explicit property of the of the family?",
                    "label": 0
                },
                {
                    "sent": "Or for certain cases, yes.",
                    "label": 0
                },
                {
                    "sent": "So for the fear regret case we can, we can get an unlock of fat shattering dimension, which works for the feeder grid.",
                    "label": 0
                },
                {
                    "sent": "The thing is so for, so I actually kind of didn't differentiate between transformations that vary at each time step versus ones that remain fixed.",
                    "label": 0
                },
                {
                    "sent": "If they remain so in some sense.",
                    "label": 0
                },
                {
                    "sent": "So when we tried the combinatorial properties, if they vary at each time step, then there is no way to kind of get a handle on them.",
                    "label": 0
                },
                {
                    "sent": "But if they are fixed at each time step, then at least for certain cases we were able to workout combinatorial properties.",
                    "label": 0
                },
                {
                    "sent": "So even for the non case there is a combinatorial property, but we suspect it's not tight, it's just that it's kind of a loose.",
                    "label": 0
                },
                {
                    "sent": "Up alone, but yeah, for the figure it we do have and for the field grade you can show that certain cases it is actually died.",
                    "label": 0
                },
                {
                    "sent": "Last question.",
                    "label": 0
                },
                {
                    "sent": "So in the IID case, rather marker complexity captures uniform convergence, right?",
                    "label": 0
                },
                {
                    "sent": "So, but you are working in a general setting and we know that listing the ID case that learnability is not equivalent to uniform convergence.",
                    "label": 0
                },
                {
                    "sent": "So how our same example will show that uniform convergence?",
                    "label": 0
                },
                {
                    "sent": "So there are cases where the sequential Rademacher complexity is cannot be bounded by.",
                    "label": 0
                },
                {
                    "sent": "I mean it cannot be bounded by within like it can only be bounded by order one.",
                    "label": 0
                },
                {
                    "sent": "But then you can still, it's still learnable.",
                    "label": 0
                },
                {
                    "sent": "It's still the same case, but the one kind of saving grace in in online learning setting is that.",
                    "label": 0
                },
                {
                    "sent": "So, for instance, the example that we considered was was online convex optimization problem, right?",
                    "label": 0
                },
                {
                    "sent": "So you take the online convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "The complexity of the sequential marker complexity of that is not mean.",
                    "label": 0
                },
                {
                    "sent": "We can't get a useful bound, but then you take that and then.",
                    "label": 0
                },
                {
                    "sent": "So there are you can.",
                    "label": 0
                },
                {
                    "sent": "You can basically see that the value of the online convex optimization game is same as the value of the linear game.",
                    "label": 0
                },
                {
                    "sent": "And then you go to the linear Adam marker of the linear and that's bound.",
                    "label": 0
                },
                {
                    "sent": "You can bound that.",
                    "label": 0
                },
                {
                    "sent": "So basically through some reductions you can still get back all the results of online convex optimization, but not directly.",
                    "label": 0
                },
                {
                    "sent": "So and in the appendix of the at least the full full version of this paper we have like we have like a few, at least like there's a llama which basically says.",
                    "label": 0
                },
                {
                    "sent": "When can you do a reduction from one game to another?",
                    "label": 0
                },
                {
                    "sent": "More generality than just online convex optimization to linear?",
                    "label": 0
                },
                {
                    "sent": "OK thanks, let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}