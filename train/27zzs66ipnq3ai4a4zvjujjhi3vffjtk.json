{
    "id": "27zzs66ipnq3ai4a4zvjujjhi3vffjtk",
    "title": "Poster Spotlights",
    "info": {
        "author": [
            "Chang Huang, Computer Science Department, University of Southern California",
            "Shai Bagon, Faculty of Mathematics and Computer Science, Weizmann Institute of Science",
            "Zdenek Kalal, Centre of Vision, Speech and Signal Processing, University of Surrey",
            "Jose M. Alvarez Lopez, Computer Vision Center, Autonomous University of Barcelona",
            "Sid Ying-Ze Bao, Department of Electrical Engineering and Computer Science, University of Michigan",
            "Bogdan Alexe, Department of Information Technology and Electrical Engineering, ETH Zurich",
            "Tai-Peng Tian, Computer Science Department, Boston University",
            "Ramakrishna Kakarala, Nanyang Technological University",
            "Carolina Galleguillos, Department of Computer Science and Engineering, UC San Diego",
            "Paul Schnitzspan, Department of Computer Science, Darmstadt University of Technology",
            "Myung Jin Choi, MIT Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, MIT",
            "Javier Marin Tur, Computer Vision Center, Autonomous University of Barcelona",
            "Li-Jia Li, Department of Computer Science, Stanford University"
        ],
        "published": "July 9, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_spotlights1a/",
    "segmentation": [
        [
            "Hello, I'm shy.",
            "Begun this is work with Barbara stop Schema graph, Balloon and Macaulay Ronnie detecting and sketching the common."
        ],
        [
            "Given very few input images, say three or four that share something in common, we would like to detect this common part and sketch it.",
            "Now it may not be easy to see what is common to all these images, but if you look carefully, you'll see that all contained a heart like shape in them, and indeed this is the output.",
            "Our algorithm produces a sketch of the heart.",
            "This is done despite the large variability in appearance of the heart in the images and lots of background clutter, and there are no other images to learn from.",
            "This is all the information we have, just these 4 images.",
            "So how do we go about doing that?",
            "First we detect the common part in the images.",
            "This is done by searching for the least trivial and sample of self similarity descriptors common to all the images.",
            "Having found such mutual and samples of descriptors, we proceed to invert them into a binary sketch.",
            "The main novelty of our work lies in this second step of inverting the descriptor to produce the optimal sketch or sketching algorithm is able to handle a huge variability in appearance.",
            "For example, take a look at these five phase images.",
            "They look very different.",
            "They do not share the same edges or colors or textured, yet this is the output our algorithm produces.",
            "This is done with a well defined objective function, an optimization process.",
            "Let's look at one more example.",
            "Look at these four images with lots of clutter.",
            "This is the sketch our algorithm produces, and we have many more examples, both qualitative and quantitative.",
            "Thank you."
        ],
        [
            "Title of."
        ],
        [
            "Title of this paper is.",
            "OK.",
            "The title of this paper is High performance, collaborative learning of jointer ranking or granular features.",
            "My name's channel from University of Southern California, the coauthors Professor, Amnon, Patio, sliding window, these sliding window projects being widely used in object detection for simplicity and generality.",
            "It requires classification method of high up, high accuracy, and fast speed.",
            "Due to the large number of sliding windows in a testing image as shown in the laptop figure.",
            "The duroc features include patterns by concatenating, concatenating binary, comparing results of pairwise granulars.",
            "They are flexible in definition and very efficient in computation.",
            "The main difficulty is extremely large feature space.",
            "We propose a collaborative collaborative learning algorithm that adopted simulated annealing and incremental feature selection to search the feature space in stochastic and deterministic ways.",
            "Furthermore, to handle the troublesome integration.",
            "Problems a very crowded situations.",
            "We developed an improved apart based detection method is that infers positions of multiple objects by their part.",
            "Detection response is the experiment in several challenge data set show that our pose our proposed approach achieves good fairly good detection accuracy and very fast detention speed capable of processing 1,000,000 sub windows per second.",
            "OK, time's up."
        ],
        [
            "Hi, my name is Danny Carla Lant I'm from University of Surrey and I'm very happy that I can present you algorithm which we call P and learning.",
            "It's a semi supervised learning algorithm.",
            "Basically our goal is to take a single example of an object and a video where the objects appear from time to time and we want to learn a classifier in a semi supervised manner.",
            "Being learning defines two types of constraints.",
            "One is positive constraint which is defining positive examples from the video and 2nd is negative constraints which is defining negative examples.",
            "These two constraints are running in parallel during learning and they are enforcing our learning process.",
            "The novelty of our framework is that these constraints are interlinked in a negative feedback manner.",
            "So if one of them makes error their second one is compensating for that and this makes our.",
            "Learning stable, we're played.",
            "We applied the learning to the tracking of sequences like this.",
            "We call it long-term tracking.",
            "So if you would like to see how the PN learning works, please come to our poster and we are running also demo session and you will see the running of the system in real time.",
            "Thank you very much."
        ],
        [
            "Hello, my name is Jose Alvarez from the Computer Vision Center in Barcelona.",
            "The main topic of our research is Rd detection.",
            "Rd"
        ],
        [
            "Section consisting detecting the free Rd through face ahead a moving vehicle.",
            "This is quite challenging since we we must deal with the continuously changing background.",
            "Different lighting and acquisition conditions and the presence of different and unknown objects.",
            "The main idea of wallpaper exploiting.",
            "Prior knowledge regarding the location of the road in the scene.",
            "For instance, if we know where the original Horizon line is, we may assume that the road is somewhere below.",
            "Or if we know where the vanishing point is, we may assume that the road is pointing pointing towards it.",
            "Or a finally.",
            "We know the 3D layer is seen layout.",
            "We may assume that the road is somewhere within the ground surface is.",
            "All this information is combined in a simple budgeting framework to provide the final result.",
            "From the experiments we can conclude that this approach clearly outperformed.",
            "Current state of the Art Rd detection algorithms.",
            "Thank you."
        ],
        [
            "Good morning, we are setting the ball means and civil service from the University of Michigan.",
            "Our title is taller, coherent object detection and."
        ],
        [
            "In layout understanding, by using only a single uncalibrated image, we want to identify our loves objects in the scene an estimated the things layout.",
            "By layout we mean camera poles and focal length, 3D supporting plans and 3D object locations.",
            "We assume object detectors are available and they are capable of detecting objects such as these bottles and mugs.",
            "Notice the detections are not perfect, so there may be false alarms and miss positives.",
            "We propose a coherent generative probabilistic model that uses the detections to estimate the most likely layout.",
            "In turn, our model uses the layout to improve the improve the object detections to make the inference tractable.",
            "Reinforced geometric constraints as penalty terms in the learning process.",
            "We also leverage layout priors to help the inference.",
            "Here are two examples or algorithm works and their generic camera configuration on both indoor and order things is with single or multiple supporting plans.",
            "Here again, the estimated supporting plan is shown as a Golden grid.",
            "And they improve.",
            "The detections are in green and thank you.",
            "Please come to a post for more details."
        ],
        [
            "Hi, my name is Bob and Alex and this is joint work with Thomas Jefferson, Vittorio Ferrari."
        ],
        [
            "We present a generic objects measure, quantifying how likely it is for an image window to contain an object of any class.",
            "Objects are standalone things with well defined boundary and center such, such as ships and cars.",
            "This is opposite to amorphous background stuff like grass or Rd.",
            "Our measure should score high as the windows covering tightly and object should score lower windows, partially covering the object and scored lowest.",
            "The windows containing only stuff.",
            "Given an input image, we scored all Windows by using cues measuring characteristic characteristic of objects in general and then.",
            "And the object is the objects of a window is the posterior probability that it contains an object of any class.",
            "Now we can sample from the distribution of objects any desired number of Windows given the sample windows.",
            "Now this this can be used as the location prior for a number of application, for example as a focus of attention mechanism for weekly supervised learning of optic glasses.",
            "This will be proven in a paper in EC 2010, but.",
            "Today we'll show you how to use Objectness to greatly reduce the number of Windows evaluated by class specific object detectors.",
            "But by how much it exactly counter poster and find out.",
            "Thank you."
        ],
        [
            "Good morning everyone.",
            "My name is typing Tien and this is joint work with Stans Claire off and we are from Boston University."
        ],
        [
            "So we have developed the exact algorithm for inference over loopy graph that runs very fast in practice.",
            "So how fast does it run?",
            "We will use the human parsing problem as example.",
            "So on the left is we recover the spatial layout of the human body parts using a tree structured model.",
            "So this is done using belief propagation and it's 612 seconds on the right.",
            "OK, let me go back to the left image.",
            "You could see there are some problems with localising the links correctly.",
            "So on the right we correct that corrected that with loopy graph an using our algorithm, we only require 119 seconds, so 7 seconds more.",
            "So in contrast, approximation algorithms actually takes many more hours.",
            "So do come by our poster and I'll tell you more about the details.",
            "Thank you."
        ],
        [
            "Good morning Bronco Corolla from NTU in Singapore.",
            "My paper is about rotation invariants and phase.",
            "So."
        ],
        [
            "Sorry about the detail which is difficult to see.",
            "The motivation for our paper is really to look at spherical harmonics which have been used to represent objects in geophysics in medical imaging and also in computer vision and computer vision.",
            "Spherical harmonics have been used for rotation matching.",
            "That is determining when two shapes of the same except one is a rotation of the other.",
            "For that purpose, with spherical harmonics, magnitudes have been used and not phase an people have known for a while.",
            "This is not a good thing, and the upper left the two shapes are actually not rotations of each other, but they have the same magnitudes.",
            "They can be distinguished if we use phase, and that's the purpose of our paper.",
            "We introduce something called by Spectrum, which is actually well known in signal processing.",
            "But not in computer vision.",
            "When we show that the Bispectrum can perform phase sensitive rotation matching.",
            "So we applied by spectrum to a number of different cases.",
            "The figure in the top right is showing one thing we can accomplish with the bispectrum that we cannot accomplish with magnitudes alone and that is distinguishing rotations from reflections.",
            "So we show the bispectrum can tell the right hand from the left, which you cannot do just from magnitudes.",
            "We apply the bispectrum to some standard datasets such as the Princeton shape data set, Thank you."
        ],
        [
            "Hi, I'm Karina years and this is joint work with Brian McPhee."
        ],
        [
            "So trilogy anger language.",
            "We introduce a novel model for multi class object localization that incorporates different levels of contextual interactions such as pixel region, an object level.",
            "Our method uses a multiple kernel learning algorithm that integrates appearance features with pixel and region interaction data, resulting in a unified similarity metric which is optimized for nearest neighbor classification.",
            "Tomorrow at object level interactions, we use a conditional random field which reduces the final label prediction, and consequently we are able to study the relative relative contribution of these contextual interactions and also through different data an object classes and also we are able to outperform current state of the art contextual object recognition frameworks come to see our poster.",
            "Thank you."
        ],
        [
            "So we almost through it, so my name is Paul Japan and I present joint work.",
            "Steven Rothenberg.",
            "Sheila entitled Automatic discovery of meaningful object parts with."
        ],
        [
            "This year, if so, the goal of our paper is to to take objects and challenging scenes with the scenes cover wide range of difficulties among them partial occlusion, articulation and viewpoint.",
            "Variation of object instances so motivated by these challenges, we propose the latency ref model is based on a flexible assembly of object parts.",
            "In the top figure you can see from bottom up that we develop the graphical model with hidden notes where the hidden nodes can take on object parts and from top down we learn object classifier that scores likely part constellations.",
            "And we learn the model with expectation maximization, and we learn that from bounding box labels alone, meaning that we do not need prior knowledge about the object parts.",
            "And Additionally we developed structure learning method based on the hidden nodes of the graphical model which can also be seen as structure learning object parts.",
            "And quantitatively will obtain competitive results on the Pascal detection challenge.",
            "An qualitative results are depicted below.",
            "We can see for the.",
            "For instance, for the motorbike example that we can handle partial occlusion before the host example, we can handle articulation and for the sheep and for the bicycle example, we can handle viewpoint variation.",
            "So at the posted there more of these colorful and nice figures and come to the poster and we control to you, thank you."
        ],
        [
            "Hi, I'm Jin Choi from MIT and this is joint work with Joseph Lim, Antonio Torralba and Alan Whiskey."
        ],
        [
            "So we present a context model incorporating object dependencies, global image features, and local detector outputs into a single probabilistic framework to exploit contextual information.",
            "It is important to have many different categories present simultaneously, image which is not the case for many standard data datasets like Pascal 07.",
            "So we introduce a new datasets 09 with more than 200 of the categories, and each image contains an average 5 to 7 different categories with a wide range of difficulties.",
            "So it is suitable to train and evaluate context models an with so many categories of full pairwise dependence model could be computationally intractable and may overbid.",
            "So instead we use a tree structure to capture the object dependencies in the personal news way.",
            "Here we show a tree relating 107 objects learned from so nine, and that re organize objects Inter natural hierarchy.",
            "For example.",
            "Here in this sub tree can see objects that commonly appear in the kitchen.",
            "When we apply a context model for object localization, we see big improvements over the baseline in many categories, and the improvement in presence prediction is even more significant.",
            "We also apply our model for scene understanding problems such as querying images by object categories or detecting objects out of context."
        ],
        [
            "Good morning, my name is Javier Marin and I come from the Computer Vision Center in Barcelona.",
            "The world we present here is focus on."
        ],
        [
            "In pedestrian classifiers?",
            "Detecting pedestrians using computer vision techniques is a major challenge for many.",
            "For many applications like surveillance or driver assistance systems, discriminatively learning approaches.",
            "Based on to the appearance, I promise him, but they need good examples and counterexamples, since collecting samples from real world is time consuming, manual leveling, and it's difficult for engineer.",
            "The separate samples an alternative consists in collecting them from realistic.",
            "Configurable virtual scenarios.",
            "Then directing question is.",
            "Can a pedestrian learned in a virtual world be successfully applied in a real world?",
            "There is also far suggestio.",
            "Thank you very much for any question.",
            "Come to my post please.",
            "Hello everyone, my name is Lee Jolly and I'm going to present our work about building and using a semantic visual image hierarchy and this is joint work with Chong Wang.",
            "You one link and professor they reply and Professor Philly and our algorithm can automatically construct hierarchy from a large collection of real world images and related texts and here specifically we use 404 thousand.",
            "Flickr photos and 538 unique user tags and the contract constructed hierarchy has a general to specific structure.",
            "As you can see at the top, the images are grouped into photo and photos are further split into Football Garden and holiday and at the bottom of the hierarchy you can see more specific Pacific groups like soccer players.",
            "And the soccer fields, and we evaluate our hierarchy by using the Amazon Mechanic Turk service.",
            "And it turns out that our algorithm, our hierarchy, is more understandable than those built along on images or all texts and the constructed hierarchy can be further used for tasks like classification, annotation, an hierarchical annotation, and our algorithm.",
            "Outperforms the state of the art algorithms to know more about our paper, please come to our poster tonight.",
            "Thank you.",
            "And it's all over for the morning.",
            "We should thank the speakers for being on time, particularly the poster speakers."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, I'm shy.",
                    "label": 0
                },
                {
                    "sent": "Begun this is work with Barbara stop Schema graph, Balloon and Macaulay Ronnie detecting and sketching the common.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Given very few input images, say three or four that share something in common, we would like to detect this common part and sketch it.",
                    "label": 0
                },
                {
                    "sent": "Now it may not be easy to see what is common to all these images, but if you look carefully, you'll see that all contained a heart like shape in them, and indeed this is the output.",
                    "label": 0
                },
                {
                    "sent": "Our algorithm produces a sketch of the heart.",
                    "label": 0
                },
                {
                    "sent": "This is done despite the large variability in appearance of the heart in the images and lots of background clutter, and there are no other images to learn from.",
                    "label": 0
                },
                {
                    "sent": "This is all the information we have, just these 4 images.",
                    "label": 0
                },
                {
                    "sent": "So how do we go about doing that?",
                    "label": 0
                },
                {
                    "sent": "First we detect the common part in the images.",
                    "label": 1
                },
                {
                    "sent": "This is done by searching for the least trivial and sample of self similarity descriptors common to all the images.",
                    "label": 0
                },
                {
                    "sent": "Having found such mutual and samples of descriptors, we proceed to invert them into a binary sketch.",
                    "label": 0
                },
                {
                    "sent": "The main novelty of our work lies in this second step of inverting the descriptor to produce the optimal sketch or sketching algorithm is able to handle a huge variability in appearance.",
                    "label": 0
                },
                {
                    "sent": "For example, take a look at these five phase images.",
                    "label": 0
                },
                {
                    "sent": "They look very different.",
                    "label": 0
                },
                {
                    "sent": "They do not share the same edges or colors or textured, yet this is the output our algorithm produces.",
                    "label": 0
                },
                {
                    "sent": "This is done with a well defined objective function, an optimization process.",
                    "label": 0
                },
                {
                    "sent": "Let's look at one more example.",
                    "label": 0
                },
                {
                    "sent": "Look at these four images with lots of clutter.",
                    "label": 0
                },
                {
                    "sent": "This is the sketch our algorithm produces, and we have many more examples, both qualitative and quantitative.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Title of.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Title of this paper is.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The title of this paper is High performance, collaborative learning of jointer ranking or granular features.",
                    "label": 1
                },
                {
                    "sent": "My name's channel from University of Southern California, the coauthors Professor, Amnon, Patio, sliding window, these sliding window projects being widely used in object detection for simplicity and generality.",
                    "label": 0
                },
                {
                    "sent": "It requires classification method of high up, high accuracy, and fast speed.",
                    "label": 0
                },
                {
                    "sent": "Due to the large number of sliding windows in a testing image as shown in the laptop figure.",
                    "label": 0
                },
                {
                    "sent": "The duroc features include patterns by concatenating, concatenating binary, comparing results of pairwise granulars.",
                    "label": 0
                },
                {
                    "sent": "They are flexible in definition and very efficient in computation.",
                    "label": 0
                },
                {
                    "sent": "The main difficulty is extremely large feature space.",
                    "label": 0
                },
                {
                    "sent": "We propose a collaborative collaborative learning algorithm that adopted simulated annealing and incremental feature selection to search the feature space in stochastic and deterministic ways.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, to handle the troublesome integration.",
                    "label": 0
                },
                {
                    "sent": "Problems a very crowded situations.",
                    "label": 0
                },
                {
                    "sent": "We developed an improved apart based detection method is that infers positions of multiple objects by their part.",
                    "label": 0
                },
                {
                    "sent": "Detection response is the experiment in several challenge data set show that our pose our proposed approach achieves good fairly good detection accuracy and very fast detention speed capable of processing 1,000,000 sub windows per second.",
                    "label": 0
                },
                {
                    "sent": "OK, time's up.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Danny Carla Lant I'm from University of Surrey and I'm very happy that I can present you algorithm which we call P and learning.",
                    "label": 0
                },
                {
                    "sent": "It's a semi supervised learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Basically our goal is to take a single example of an object and a video where the objects appear from time to time and we want to learn a classifier in a semi supervised manner.",
                    "label": 1
                },
                {
                    "sent": "Being learning defines two types of constraints.",
                    "label": 0
                },
                {
                    "sent": "One is positive constraint which is defining positive examples from the video and 2nd is negative constraints which is defining negative examples.",
                    "label": 0
                },
                {
                    "sent": "These two constraints are running in parallel during learning and they are enforcing our learning process.",
                    "label": 0
                },
                {
                    "sent": "The novelty of our framework is that these constraints are interlinked in a negative feedback manner.",
                    "label": 0
                },
                {
                    "sent": "So if one of them makes error their second one is compensating for that and this makes our.",
                    "label": 0
                },
                {
                    "sent": "Learning stable, we're played.",
                    "label": 0
                },
                {
                    "sent": "We applied the learning to the tracking of sequences like this.",
                    "label": 0
                },
                {
                    "sent": "We call it long-term tracking.",
                    "label": 1
                },
                {
                    "sent": "So if you would like to see how the PN learning works, please come to our poster and we are running also demo session and you will see the running of the system in real time.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, my name is Jose Alvarez from the Computer Vision Center in Barcelona.",
                    "label": 0
                },
                {
                    "sent": "The main topic of our research is Rd detection.",
                    "label": 0
                },
                {
                    "sent": "Rd",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Section consisting detecting the free Rd through face ahead a moving vehicle.",
                    "label": 1
                },
                {
                    "sent": "This is quite challenging since we we must deal with the continuously changing background.",
                    "label": 0
                },
                {
                    "sent": "Different lighting and acquisition conditions and the presence of different and unknown objects.",
                    "label": 0
                },
                {
                    "sent": "The main idea of wallpaper exploiting.",
                    "label": 0
                },
                {
                    "sent": "Prior knowledge regarding the location of the road in the scene.",
                    "label": 0
                },
                {
                    "sent": "For instance, if we know where the original Horizon line is, we may assume that the road is somewhere below.",
                    "label": 1
                },
                {
                    "sent": "Or if we know where the vanishing point is, we may assume that the road is pointing pointing towards it.",
                    "label": 0
                },
                {
                    "sent": "Or a finally.",
                    "label": 1
                },
                {
                    "sent": "We know the 3D layer is seen layout.",
                    "label": 0
                },
                {
                    "sent": "We may assume that the road is somewhere within the ground surface is.",
                    "label": 0
                },
                {
                    "sent": "All this information is combined in a simple budgeting framework to provide the final result.",
                    "label": 0
                },
                {
                    "sent": "From the experiments we can conclude that this approach clearly outperformed.",
                    "label": 0
                },
                {
                    "sent": "Current state of the Art Rd detection algorithms.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, we are setting the ball means and civil service from the University of Michigan.",
                    "label": 0
                },
                {
                    "sent": "Our title is taller, coherent object detection and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In layout understanding, by using only a single uncalibrated image, we want to identify our loves objects in the scene an estimated the things layout.",
                    "label": 0
                },
                {
                    "sent": "By layout we mean camera poles and focal length, 3D supporting plans and 3D object locations.",
                    "label": 1
                },
                {
                    "sent": "We assume object detectors are available and they are capable of detecting objects such as these bottles and mugs.",
                    "label": 0
                },
                {
                    "sent": "Notice the detections are not perfect, so there may be false alarms and miss positives.",
                    "label": 0
                },
                {
                    "sent": "We propose a coherent generative probabilistic model that uses the detections to estimate the most likely layout.",
                    "label": 0
                },
                {
                    "sent": "In turn, our model uses the layout to improve the improve the object detections to make the inference tractable.",
                    "label": 0
                },
                {
                    "sent": "Reinforced geometric constraints as penalty terms in the learning process.",
                    "label": 0
                },
                {
                    "sent": "We also leverage layout priors to help the inference.",
                    "label": 0
                },
                {
                    "sent": "Here are two examples or algorithm works and their generic camera configuration on both indoor and order things is with single or multiple supporting plans.",
                    "label": 0
                },
                {
                    "sent": "Here again, the estimated supporting plan is shown as a Golden grid.",
                    "label": 0
                },
                {
                    "sent": "And they improve.",
                    "label": 0
                },
                {
                    "sent": "The detections are in green and thank you.",
                    "label": 0
                },
                {
                    "sent": "Please come to a post for more details.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Bob and Alex and this is joint work with Thomas Jefferson, Vittorio Ferrari.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We present a generic objects measure, quantifying how likely it is for an image window to contain an object of any class.",
                    "label": 0
                },
                {
                    "sent": "Objects are standalone things with well defined boundary and center such, such as ships and cars.",
                    "label": 0
                },
                {
                    "sent": "This is opposite to amorphous background stuff like grass or Rd.",
                    "label": 0
                },
                {
                    "sent": "Our measure should score high as the windows covering tightly and object should score lower windows, partially covering the object and scored lowest.",
                    "label": 0
                },
                {
                    "sent": "The windows containing only stuff.",
                    "label": 1
                },
                {
                    "sent": "Given an input image, we scored all Windows by using cues measuring characteristic characteristic of objects in general and then.",
                    "label": 1
                },
                {
                    "sent": "And the object is the objects of a window is the posterior probability that it contains an object of any class.",
                    "label": 1
                },
                {
                    "sent": "Now we can sample from the distribution of objects any desired number of Windows given the sample windows.",
                    "label": 0
                },
                {
                    "sent": "Now this this can be used as the location prior for a number of application, for example as a focus of attention mechanism for weekly supervised learning of optic glasses.",
                    "label": 1
                },
                {
                    "sent": "This will be proven in a paper in EC 2010, but.",
                    "label": 0
                },
                {
                    "sent": "Today we'll show you how to use Objectness to greatly reduce the number of Windows evaluated by class specific object detectors.",
                    "label": 0
                },
                {
                    "sent": "But by how much it exactly counter poster and find out.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is typing Tien and this is joint work with Stans Claire off and we are from Boston University.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have developed the exact algorithm for inference over loopy graph that runs very fast in practice.",
                    "label": 0
                },
                {
                    "sent": "So how fast does it run?",
                    "label": 0
                },
                {
                    "sent": "We will use the human parsing problem as example.",
                    "label": 0
                },
                {
                    "sent": "So on the left is we recover the spatial layout of the human body parts using a tree structured model.",
                    "label": 0
                },
                {
                    "sent": "So this is done using belief propagation and it's 612 seconds on the right.",
                    "label": 0
                },
                {
                    "sent": "OK, let me go back to the left image.",
                    "label": 0
                },
                {
                    "sent": "You could see there are some problems with localising the links correctly.",
                    "label": 0
                },
                {
                    "sent": "So on the right we correct that corrected that with loopy graph an using our algorithm, we only require 119 seconds, so 7 seconds more.",
                    "label": 1
                },
                {
                    "sent": "So in contrast, approximation algorithms actually takes many more hours.",
                    "label": 0
                },
                {
                    "sent": "So do come by our poster and I'll tell you more about the details.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning Bronco Corolla from NTU in Singapore.",
                    "label": 0
                },
                {
                    "sent": "My paper is about rotation invariants and phase.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry about the detail which is difficult to see.",
                    "label": 0
                },
                {
                    "sent": "The motivation for our paper is really to look at spherical harmonics which have been used to represent objects in geophysics in medical imaging and also in computer vision and computer vision.",
                    "label": 0
                },
                {
                    "sent": "Spherical harmonics have been used for rotation matching.",
                    "label": 0
                },
                {
                    "sent": "That is determining when two shapes of the same except one is a rotation of the other.",
                    "label": 0
                },
                {
                    "sent": "For that purpose, with spherical harmonics, magnitudes have been used and not phase an people have known for a while.",
                    "label": 1
                },
                {
                    "sent": "This is not a good thing, and the upper left the two shapes are actually not rotations of each other, but they have the same magnitudes.",
                    "label": 0
                },
                {
                    "sent": "They can be distinguished if we use phase, and that's the purpose of our paper.",
                    "label": 0
                },
                {
                    "sent": "We introduce something called by Spectrum, which is actually well known in signal processing.",
                    "label": 0
                },
                {
                    "sent": "But not in computer vision.",
                    "label": 0
                },
                {
                    "sent": "When we show that the Bispectrum can perform phase sensitive rotation matching.",
                    "label": 0
                },
                {
                    "sent": "So we applied by spectrum to a number of different cases.",
                    "label": 0
                },
                {
                    "sent": "The figure in the top right is showing one thing we can accomplish with the bispectrum that we cannot accomplish with magnitudes alone and that is distinguishing rotations from reflections.",
                    "label": 0
                },
                {
                    "sent": "So we show the bispectrum can tell the right hand from the left, which you cannot do just from magnitudes.",
                    "label": 0
                },
                {
                    "sent": "We apply the bispectrum to some standard datasets such as the Princeton shape data set, Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Karina years and this is joint work with Brian McPhee.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So trilogy anger language.",
                    "label": 0
                },
                {
                    "sent": "We introduce a novel model for multi class object localization that incorporates different levels of contextual interactions such as pixel region, an object level.",
                    "label": 1
                },
                {
                    "sent": "Our method uses a multiple kernel learning algorithm that integrates appearance features with pixel and region interaction data, resulting in a unified similarity metric which is optimized for nearest neighbor classification.",
                    "label": 1
                },
                {
                    "sent": "Tomorrow at object level interactions, we use a conditional random field which reduces the final label prediction, and consequently we are able to study the relative relative contribution of these contextual interactions and also through different data an object classes and also we are able to outperform current state of the art contextual object recognition frameworks come to see our poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we almost through it, so my name is Paul Japan and I present joint work.",
                    "label": 0
                },
                {
                    "sent": "Steven Rothenberg.",
                    "label": 0
                },
                {
                    "sent": "Sheila entitled Automatic discovery of meaningful object parts with.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This year, if so, the goal of our paper is to to take objects and challenging scenes with the scenes cover wide range of difficulties among them partial occlusion, articulation and viewpoint.",
                    "label": 1
                },
                {
                    "sent": "Variation of object instances so motivated by these challenges, we propose the latency ref model is based on a flexible assembly of object parts.",
                    "label": 0
                },
                {
                    "sent": "In the top figure you can see from bottom up that we develop the graphical model with hidden notes where the hidden nodes can take on object parts and from top down we learn object classifier that scores likely part constellations.",
                    "label": 0
                },
                {
                    "sent": "And we learn the model with expectation maximization, and we learn that from bounding box labels alone, meaning that we do not need prior knowledge about the object parts.",
                    "label": 0
                },
                {
                    "sent": "And Additionally we developed structure learning method based on the hidden nodes of the graphical model which can also be seen as structure learning object parts.",
                    "label": 1
                },
                {
                    "sent": "And quantitatively will obtain competitive results on the Pascal detection challenge.",
                    "label": 1
                },
                {
                    "sent": "An qualitative results are depicted below.",
                    "label": 0
                },
                {
                    "sent": "We can see for the.",
                    "label": 0
                },
                {
                    "sent": "For instance, for the motorbike example that we can handle partial occlusion before the host example, we can handle articulation and for the sheep and for the bicycle example, we can handle viewpoint variation.",
                    "label": 0
                },
                {
                    "sent": "So at the posted there more of these colorful and nice figures and come to the poster and we control to you, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Jin Choi from MIT and this is joint work with Joseph Lim, Antonio Torralba and Alan Whiskey.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we present a context model incorporating object dependencies, global image features, and local detector outputs into a single probabilistic framework to exploit contextual information.",
                    "label": 1
                },
                {
                    "sent": "It is important to have many different categories present simultaneously, image which is not the case for many standard data datasets like Pascal 07.",
                    "label": 0
                },
                {
                    "sent": "So we introduce a new datasets 09 with more than 200 of the categories, and each image contains an average 5 to 7 different categories with a wide range of difficulties.",
                    "label": 0
                },
                {
                    "sent": "So it is suitable to train and evaluate context models an with so many categories of full pairwise dependence model could be computationally intractable and may overbid.",
                    "label": 0
                },
                {
                    "sent": "So instead we use a tree structure to capture the object dependencies in the personal news way.",
                    "label": 0
                },
                {
                    "sent": "Here we show a tree relating 107 objects learned from so nine, and that re organize objects Inter natural hierarchy.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Here in this sub tree can see objects that commonly appear in the kitchen.",
                    "label": 0
                },
                {
                    "sent": "When we apply a context model for object localization, we see big improvements over the baseline in many categories, and the improvement in presence prediction is even more significant.",
                    "label": 0
                },
                {
                    "sent": "We also apply our model for scene understanding problems such as querying images by object categories or detecting objects out of context.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, my name is Javier Marin and I come from the Computer Vision Center in Barcelona.",
                    "label": 0
                },
                {
                    "sent": "The world we present here is focus on.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In pedestrian classifiers?",
                    "label": 0
                },
                {
                    "sent": "Detecting pedestrians using computer vision techniques is a major challenge for many.",
                    "label": 0
                },
                {
                    "sent": "For many applications like surveillance or driver assistance systems, discriminatively learning approaches.",
                    "label": 0
                },
                {
                    "sent": "Based on to the appearance, I promise him, but they need good examples and counterexamples, since collecting samples from real world is time consuming, manual leveling, and it's difficult for engineer.",
                    "label": 0
                },
                {
                    "sent": "The separate samples an alternative consists in collecting them from realistic.",
                    "label": 0
                },
                {
                    "sent": "Configurable virtual scenarios.",
                    "label": 0
                },
                {
                    "sent": "Then directing question is.",
                    "label": 0
                },
                {
                    "sent": "Can a pedestrian learned in a virtual world be successfully applied in a real world?",
                    "label": 1
                },
                {
                    "sent": "There is also far suggestio.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for any question.",
                    "label": 0
                },
                {
                    "sent": "Come to my post please.",
                    "label": 0
                },
                {
                    "sent": "Hello everyone, my name is Lee Jolly and I'm going to present our work about building and using a semantic visual image hierarchy and this is joint work with Chong Wang.",
                    "label": 0
                },
                {
                    "sent": "You one link and professor they reply and Professor Philly and our algorithm can automatically construct hierarchy from a large collection of real world images and related texts and here specifically we use 404 thousand.",
                    "label": 0
                },
                {
                    "sent": "Flickr photos and 538 unique user tags and the contract constructed hierarchy has a general to specific structure.",
                    "label": 0
                },
                {
                    "sent": "As you can see at the top, the images are grouped into photo and photos are further split into Football Garden and holiday and at the bottom of the hierarchy you can see more specific Pacific groups like soccer players.",
                    "label": 0
                },
                {
                    "sent": "And the soccer fields, and we evaluate our hierarchy by using the Amazon Mechanic Turk service.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that our algorithm, our hierarchy, is more understandable than those built along on images or all texts and the constructed hierarchy can be further used for tasks like classification, annotation, an hierarchical annotation, and our algorithm.",
                    "label": 0
                },
                {
                    "sent": "Outperforms the state of the art algorithms to know more about our paper, please come to our poster tonight.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "And it's all over for the morning.",
                    "label": 0
                },
                {
                    "sent": "We should thank the speakers for being on time, particularly the poster speakers.",
                    "label": 0
                }
            ]
        }
    }
}