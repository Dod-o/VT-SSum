{
    "id": "fbqyx6ax2ukfik57zhdarzafwtvdvkss",
    "title": "Approximate Inference",
    "info": {
        "author": [
            "Tom Minka, Microsoft Research"
        ],
        "published": "Nov. 2, 2009",
        "recorded": "August 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss09uk_minka_ai/",
    "segmentation": [
        [
            "OK, so I'm Tom Minka and I'm going to talk to you today about approximate inference.",
            "At this point, you're probably very excited about graphical models and Bayesian inference, and you want to run home and implement some models.",
            "The problem is that you'll quickly find is that.",
            "Many times exact answers are infeasible, or if you try to use sampling, it's going to be very slow.",
            "So what you'd like to do is do something which is both fast and Bayesian, and that's what I'm going to talk about today.",
            "So for example, if you want to do real time processing of an online data set, or if you have a huge database you want to process that."
        ],
        [
            "These methods are welcome in, so I'm going to be focusing on Bayesian inference in this talk, so let me just give a quick overview of why I think Bayesian inference is so important and so useful.",
            "I think if you want a formal definition, basically what does it mean to be Bayesian, it just means that you consistently use probability theory for reasoning about anything that you don't know.",
            "So if you have a latent variable, if you have missing data, if you have parameters, you'll always represent that uncertainty with probability distributions and and.",
            "I mean, that's useful in a sense, because now all of your algorithms are consistent.",
            "Every algorithm can handle these unknowns in exactly the same way, and you can make very general procedures for reasoning about all kinds of different models.",
            "But there's actually another advantage, which is what Chris talked about this morning, which is modularity.",
            "So by using Bayesian inference, you simply get this very nice decoupling of different things, so you can decouple, for example, your model from your decision making process.",
            "So what I'd like to do is, I like to think of Bayesian inference is sort of a flow diagram where you have data at one end.",
            "Alright, and you have your model.",
            "And you put these two together.",
            "And you get a posterior distribution.",
            "Right now, if you want to make decisions as Chris showed this morning.",
            "All you need is the posterior distribution.",
            "You don't need to go back to your data, so if your loss matrix changes, you can just go to your posterior and ask what should my new decision be or if you are priors in different classes change.",
            "You can again just make your decision based on the posterior already had you don't go back to your data so it's modular.",
            "In that sense it summarizes everything you need to know about the data, and if you get more data, for example in an online streaming context.",
            "You just take your posterior you incorporate, use it as a prior for the new data you have.",
            "You get a new posterior and again you don't look at your old data again, so it's a very very efficient way of processing data.",
            "If you think about it now, lot of people associated Bayesian inference is being slow, but actually I think it is being very a very fast way of processing data because of this."
        ],
        [
            "Pretty.",
            "So here this slide basically summarizes what I just said, so the posterior distribution is your friend that summarizes everything that you have learned from the data, right?",
            "So instead of thinking of data, we should think about distributions, right?",
            "An essentially described your training data allows you to make predictions, and as you do online learning, But the problem is, how can we efficiently represent in compute with these posterior distributions?",
            "Because often they're very complicated, and so that's what I'm going to talk about today.",
            "How we can actually make this into a practical approach?"
        ],
        [
            "Azure now the tool that I'm going to use today is a very, very important innovation actually, which is factor graphs and which is a type of graphical model which is actually, I think, the best way of thinking about approximate inference algorithms in terms of factor graph.",
            "So let me just give you a quick summary of what it was.",
            "I know that zoom in or give a talk on this, but let me just give my own take on what a factor graph is.",
            "So a factor graph basically can be applied to any function, it isn't, it isn't something specific to probability theory combined in any function.",
            "All it does is it just shows you a way of factoring this function into a product of terms, and obviously this is not unique.",
            "You can take a given function in factored in many different ways.",
            "So if I take a polynomial for example, I can factor in various different ways and a factor graph just shows you one particular way of factoring the function.",
            "So here I give an example of a function F of XYZ.",
            "This is not a distribution, is just a function.",
            "It happens to factor in this way X + y Y plus Z, XYZ and given that factorization.",
            "I can now use a factor graph to represent that factorization.",
            "So what is the factor graph for this function?",
            "Well, first of all I have my variables XY and Z.",
            "And for each term in my factorization, I just make a box and I connect it to each of the variables that it uses.",
            "So the first term is a box that uses X&Y.",
            "The second term is a box that uses Y&Z.",
            "And the third term is.",
            "The box uses actions E, so that's the factor graph for this.",
            "Factoring of this function.",
            "OK, now why is this so useful?",
            "Because posterior distributions often have this form right, so you often have some sort of parameter.",
            "X which has some prior distribution and you're going to observe a bunch of data.",
            "Right, why I give an axe?",
            "And this will be your joint distribution of Y&X.",
            "Right?",
            "And so, so this sort of factored product and actually arise, and that's why that's why factor graph."
        ],
        [
            "So useful.",
            "We just show an example of a factor graph that arises in probability theory or machine learning.",
            "Let's suppose we just have a Gaussian observations of some unknown mean.",
            "So we have this variable M which is unknown, and we've made observations of that.",
            "And let's suppose we make ID observations of that.",
            "So now you all know how to write this down algebraically, right?",
            "So you'd write that the posterior distribution of M given a bunch of X is.",
            "It is going to be proportional to first of all the prior on M. And the product of the likelihoods of all of the axes.",
            "Right, hopefully that's second nature to you guys now.",
            "But what is the factor graph for this problem?",
            "Alright, well I've given you the posterior distribution.",
            "I've shown you how it factors so it should be quite straightforward to give me the factor graph.",
            "Can anyone give me the factor graph for this problem?",
            "So your facts have M and all the axes.",
            "And you have one factor for each X, and what does it do?",
            "Connect them to each one OK. Are we done?",
            "Yes, one single factor for the prior on M. There we go.",
            "OK, let me give you another brain teaser.",
            "Suppose we have a Markov chain.",
            "Alright, so what's the formula for a Markov chain so I have a bunch of axis.",
            "And we have a distribution for the first one.",
            "And then we'll have a distribution for each X conditional on the previous X.",
            "Right, so that's the that's the joint distribution for a Markov chain.",
            "If you pile familiar with.",
            "But now, what is the factor graph for this Markov chain?",
            "Square.",
            "A chain of squares and circles OK.",
            "Yes.",
            "And there's the prior yes.",
            "So we have X1X 2X3.",
            "OK, and this so this box here.",
            "Just to be clear, is the prior on X1.",
            "This box here is the conditional distribution of X2 given X one and this box is X3 given X2.",
            "OK."
        ],
        [
            "Great, so now you all know how to write down factor graphs.",
            "You're halfway there.",
            "So.",
            "Yeah, so just to review.",
            "One, so there's two sort of big problems.",
            "One is what graph should use for your particular data set.",
            "I'm not going to sit at all.",
            "I'm assuming that you figured out how to model your data already.",
            "Then there's a second question is, given the grafana data, what is the mean of X?",
            "For example, what are the?",
            "What's the posterior distribution?",
            "And there's a very different albums you can choose from, and the algorithm going to be looking at.",
            "They are what are called message passing type algorithms, in particular expected."
        ],
        [
            "Propagation variational bayes.",
            "OK, so I'm going to illustrate these algorithms with a specific concrete problem which is seemingly very difficult problem.",
            "If you look at it from exactly inference, but actually quite easy if you look at it from."
        ],
        [
            "Proximate inference POV.",
            "OK, so this problem is one that I've used a lot in pit my papers, which is called the clutter problem.",
            "So in this problem you have this unknown X scalar variable which has Gaussian prior and you have a bunch of observations of this X, But the observations are corrupted with some probability, so half the time the observations are just Gaussian observations whose mean is X, just as I wrote before, but half the time the observations are just plain noise, they have nothing to do with us at all, it's just why is distributed from zero 10 normal distribution.",
            "So what is so?",
            "This is sort of like a problem where you have background noise.",
            "Some of your points are actually meaningful.",
            "The foreground points that the ones that actually tell you about what you're trying to estimate, and there's a whole bunch of data that just says nothing about what you're trying to estimate.",
            "Just random stuff that was thrown in.",
            "But you don't know which points are which, OK, so.",
            "What is the?",
            "And now we're going to observe the a bunch of these wise and we want to try to estimate X. OK, so at this point you guys can probably tell me what the factor graph is for this problem, right?",
            "Factor graph of this problem.",
            "So we have a bunch of wise.",
            "We have X.",
            "And we will have.",
            "Are likelihoods connected to X another primix?",
            "OK, now what is the what is the form of the exact?",
            "Posterior on X for this problem.",
            "So we give you N data points.",
            "Right?",
            "What form does this have?",
            "Well, as we know it's going to be.",
            "P vaccine supportive iyi given X. OK now PX is a Gaussian P of why I given axis is some weighted sum of two Gaussians.",
            "OK. Now, what's that?",
            "What's that going to turn into?",
            "Well, let's see.",
            "So if I have.",
            "If I have say.",
            "Two data points.",
            "And I'm going to get Gaussian times a product of two terms times another product of two terms.",
            "If I expand that out, I'm going to four terms.",
            "In my son, all the Gaussians are going to apply to give Gaussians.",
            "So essentially I have a mixture of four Gaussians in my posterior distribution.",
            "Is that clear to everyone?",
            "So let's see if I have two points.",
            "I get 4 Gaussians.",
            "Doesn't sound too bad overweight if I have endpoints.",
            "How many Gaussians do I have in my posterior distribution?",
            "Two to the N likes OK.",
            "So that doesn't seem very tractable.",
            "So if I give you 100 points, you're already we already out of luck for doing exact inference here.",
            "So yes, you can enumerate all those Gaussians, and you can compute that giant mixture, but it's going to be.",
            "It's going to take a long time.",
            "But is this problem?"
        ],
        [
            "That heart that is the question so.",
            "This is what I get if I actually take yes.",
            "What's that you're looking for?",
            "The posterior on X.",
            "So you have all this noisy data, so half of it is good, half of it is not.",
            "You want to estimate the posterior region X.",
            "Is that the question?",
            "How many people?",
            "Why do we need 4?",
            "Oh, OK, So what I was writing there was was how complex does the posterior distribution for axis get?",
            "How complex is this function here get?",
            "If I have two data points.",
            "And basically this case here.",
            "And basically, if I just substitute in those formulas at the top into that, what I find is that I have a some weighted sum of four terms.",
            "Right, each of which is Gaussian.",
            "So that's how the complexity of this grows.",
            "But here's the thing.",
            "If you actually take a data set of 100 points, and you actually compute this posterior plotted, this is what you get.",
            "That's the posterior for X.",
            "So yes, that is it is a mixture of two to 100 Gaussians, but it ends up having a very simple shape effectively, even though the algebraic formulas very complex, the actual shape is quite simple and this happens a lot in Bayesian inference problems, mainly because you have a sort of central limit theorem effects.",
            "The more data more data you have affecting a certain parameter, essentially makes the distribution look posterior lobe Gaussian, even though each individual likely it could be very non Gaussian.",
            "So this gives us some hope that probably we could do some sort of approximation and get a good representation of this posterior.",
            "Very simple, compact representation of this posterior and compute with that rather than going with this due to the 100 mixture of."
        ],
        [
            "Audience.",
            "So, So what I'm going to talk about is how can we?",
            "How can we compute and represent that posterior distribution compactly?",
            "OK, so at this point there's sort of a fork in the road of what type of approximate inference technique you want to use.",
            "Now you've just seen whole bunch of lectures on sampling, and sampling is certainly one way that you could approach this problem.",
            "I would say that sampling is particularly good for cases where the posterior distribution has a very complicated shape and it's not something you could easily summarize with some sort of analytic form.",
            "So for example, if you have.",
            "Shape on the left which has lots of modes in it.",
            "Then using for example a particle filter or a bunch of samples to represent that distribution is would be a good idea.",
            "On the other hand, if you have a nice smooth posterior distribution like the one I just showed you, you can actually get something much cheaper and much simpler, which is just to approximate it with some parametric families such as the Gaussian.",
            "And.",
            "Essentially, you have a tradeoff here.",
            "So the nice thing about sampling is that.",
            "Is that it allows you to wait?",
            "Right here.",
            "OK, is that if you use enough samples, you know you're going to get a good representation of the posterior even if you don't know what it really looks like, as long as you have samples, you'll get something that captures most of the posterior.",
            "As long as you could sample, that is.",
            "The thing about deterministic approximations is that you don't really know in advance how accurate is going to be unless you actually examine your posterior distribution to see that it does match the formula fitting to see how Gaussian it is.",
            "I just did.",
            "If you don't do that, you won't really know how accurate your results are, so that's sort of this unpredictability to it.",
            "Hand."
        ],
        [
            "It is very fast.",
            "Now, within deterministic approximations, there's still a whole bunch of things you could do, so one of the original methods that people use was called in the plus method.",
            "And what happens there is you essentially find the mode of your posterior distribution.",
            "You find the derivatives at that mode, and you choose a Gaussian which has the same mode in the same derivatives as your posterior.",
            "So essentially you're choosing Gaussian, which matches your posterior at one point very well.",
            "And this has been used for various problems.",
            "Sometimes it is very effective, so I've applied it for example to do Bayesian PCA where it works very well for that problem.",
            "Another method you could use is called variational bounds, so in this case we'd be finding a Gaussian that doesn't just match at one point, but is a sort of good lower bound to my posterior distribution.",
            "And one of the reasons that people like using lower bounds is, for example, you get certain guarantees about your approximation.",
            "You get nice convergence properties of the algorithm and so on.",
            "I'm."
        ],
        [
            "But today I'm not going to either of those going to 3rd approach.",
            "We just called moment matching and I'll talk about variational bounds tomorrow.",
            "But today I'm going to focus on this one, and the reason I like this one is because for certain problems where your posterior distribution does match your assumptions very well, you can get very good accuracy with this method.",
            "And I'm going to be talking about a method called expectation propagation, which is basically a method for finding Gaussian approximations to posteriors.",
            "Which was the essentially a combination.",
            "It rose is a combination of two previous algorithms.",
            "One is called assume density filtering which came out of the common filtering literature and loopy belief propagation, which came out of the machine learning literature and essentially it's it subsumes both of them.",
            "So essentially, they're both special cases of the algorithm."
        ],
        [
            "Too bad today.",
            "OK so today will be focused on moment matching.",
            "Tomorrow we'll talk about variational bounds."
        ],
        [
            "OK, so first of all, let's come back to our problem.",
            "Is there any hope of finding a Gaussian that fits our posterior well what I'm showing here is I'm showing again that same exact posterior distribution on X and I'm showing the best Gaussian fit and by best Gaussian I just mean the one that has the same moment as the same meaning variance as that posterior distribution, and we see that it's a reasonably good fit, though it's not a perfect fit and that's because our posterior wasn't exactly Gaussian, it was it had heavier tails in a Gaussian and as a result we're not going to be perfect, but it does a reasonable job.",
            "So essentially our target is going to find that purple curve as fast as possible.",
            "And the and the error between the purple curve and the green curve will never be on the recovery using a Gaussian."
        ],
        [
            "Fox nation.",
            "OK, So what is the basic strategy?",
            "So recall that we had this factor graph for X.",
            "Which had a bunch of factors.",
            "We had some wise.",
            "And the reason that the posterior distribution for X was not Gaussian was because some of the factors in this model were not Gaussian, right?",
            "They were some of two Gaussians.",
            "Well, what if we were so lucky as all the factors in R model were Gaussian?",
            "Well then we would end up with the Gaussian posterior X, and that's what we want.",
            "So one way of getting that Gaussian approximate Gaussian posterior on X is to take each of the factors in R model an approximate each one of them with a Gaussian.",
            "And if we approximate each one of these factors one by one with Gaussians will ensure that our approximate posterior will be costing.",
            "So we just multiply them together and we get our approximate posterior.",
            "So it's essentially what I'm going to do.",
            "So it works in a very different way than.",
            "For example, the process method.",
            "So on the plus method you form the whole posterior.",
            "You find this mode and so on.",
            "Here I'm going to do it in a very distributed way.",
            "I'm going to take each factor one at a time and approximate it, and then eventually put them all together.",
            "OK, so mathematically I'm going to take that some weighted sum of Gaussians.",
            "Then I'm going to approximate it with Gaussian and Gaussian will have some free powders which I'm going to call me and VI and those are the numbers that I need to find in my algorithm.",
            "OK, now at first this might sound a bit fishy, So what I'm going to do is I'm going to take something which is the sum of two Gaussians in approximately 1 Gaussian.",
            "And how can that possibly give me a good approximation?",
            "If you think about it, if you think about what a mixture of Gaussians might look like, right?",
            "And I'm going to try and approximate it.",
            "With.",
            "One Gaussian that sounds like how could you possibly do good doing that?",
            "Here's the reasoning that.",
            "When we multiply all of these likelihood terms together.",
            "The posterior distribution will be very very compact.",
            "In other words, the variance of the posterior.",
            "We quite small compared to any single likelihood term.",
            "In other words, if I were to overlay the posterior on top of one of these likelihoods, I would find that the posterior would be, for example, like.",
            "This could be some very narrow thing because I'm multiplying together many many likelihood terms to get my posterior, so it will be very narrow.",
            "And as a result, I don't really need to represent all of the details in each individual likelihood function.",
            "All I really need to get a good approximation is just to represent this one bit.",
            "Of the likelihood function very well, and if I can represent that one bit very well, then after having multiplied them altogether, I'll get a good approximation to my overall posterior.",
            "And that's essentially why this method works and I can give you an."
        ],
        [
            "Other example of that."
        ],
        [
            "So here I'm showing just the effect.",
            "This effect you get when multiplying a bunch of like this together.",
            "So in the blue curve I have a mixture of Gaussians which I'm calling the exact likely.",
            "So this is sort of an idealized problem.",
            "It's not the exact letter problem anymore.",
            "But suppose we have some likely term, which is this blue curve, and it's a mixture of Gaussians.",
            "And we want to approximate it by another Gaussian and suppose we picked the green curve as our approximation.",
            "Now.",
            "In our model we also have priors.",
            "We have various other terms that are going to be multiplied in and I'm throwing all those together and calling that Q, not I of X which is the 2nd row.",
            "Now if we take our exact likelihood, we multiply it by all those of the terms.",
            "We get a posterior distribution, which is this P of X which I've written in blue.",
            "That would be our exact posterior for this abstract problem.",
            "Now if we take our approximate term which is this green curve and we multiply it again by Q, not I, I'll get another posterior which I've written in green there, right?",
            "So this green at the bottom is the posterior I would get if I had used this green replacement of the top OK."
        ],
        [
            "And we see the problem here is that this green curve isn't a very good green curve because we know we're going to multiply by that Q, not I.",
            "Why are we buying even bothering to represent the stuff on the left, right?",
            "Why don't we just put a Gaussian to represent FI on the right side, which is where it counts, right?",
            "So let's suppose we do that.",
            "Suppose for example, we chose our green approximation to simply be the Gaussian on the right.",
            "Alright, as our approximation, instead of trying to smile representing both.",
            "So if we just pick the Gaussian on the right and now we multiply by the Q, not I, we in fact find that our approximation approximate cost here is very very close to the exact posterior because the Gaussian left didn't really matter anyway.",
            "When you multiply by other other terms in the model.",
            "And this is the basic intuition for why this moment matching technique works is because we're going to take our non Gaussian likelihoods and approximate them by Gaussians.",
            "But in exactly the spot where we need to approximate them, and that's why we're going to get results.",
            "OK, hopefully that's clear to everyone, yes.",
            "Ah, that I will show you, but the idea is to look at the other terms so you look at the other factors that are in your model and they will give you a hint as to where the posterior is going to be.",
            "And once you have an idea of where the posterior is going to be, you now know how you should approximate this particular likely term.",
            "So essentially what will happen is the factors will talk to each other.",
            "These factors will say OK, another posterior somewhere over here he says OK.",
            "In that case I'll use this approximation.",
            "He sends it back over them and then they change their approximation and so on.",
            "And that's where the whole message passing structure comes from.",
            "Yes.",
            "One of the factors has got one big mode, like if all of the factors are bimodal, it you get in trouble.",
            "Well, no, because they showed if you multiply, if you multiply enough bimodal factors together, you still get a single mode.",
            "So here Q not I represents like every other factor.",
            "This in the model.",
            "So I'm assuming that all of them just add up to give a Gaussian, but you're right that if you if there aren't enough data points, you won't get your posterior won't be very Gaussian, and in which case this approximation won't be very good.",
            "So essentially relies on you having a lot of significant amount of data.",
            "Yes.",
            "Repeat the question OK.",
            "The pictures to be non overlapping across the different.",
            "So if they have a significant overlap then you will still get a bimodal.",
            "What happens is when you actually sample data from the model I just gave you the oh I'm supposed to repeat the question.",
            "OK, right?",
            "Right, so the question was, let's see, the question was what if all the mixture components lineup somehow?",
            "Won't you then still get it by model posterior?",
            "And that's correct.",
            "You would get that.",
            "But if you actually sampling data from this model, you wouldn't get reported and line up in some magical way to give you a bimodal.",
            "And I already showed that when I showed the exact posterior that it wasn't by model, so that shows you that you don't get that strange lining up effect.",
            "If you only do two points, then you would get you would get a lining up affecting you would you would literally see that the four Gaussians that were in that posterior.",
            "OK, should I move on?",
            "Yes.",
            "Define instead of fitting into a single Gaussian fitting into the mixture of emotion and even include the performance of this method.",
            "It would improve the performance and people have tried it.",
            "The main problem with that is that it takes a long time.",
            "It takes significantly longer than you would think to fit two rather than one.",
            "It isn't just twice as much.",
            "It's like 10 or 100 times slower to fit two.",
            "That's the problem so.",
            "But The thing is, if you could find a way of fitting two Gaussians which was only twice as expensive as fitting one, then you'd be in business, right?",
            "So then you'd have best paper right there if you could find that, but no one is known as found such a method yet.",
            "Ham other questions."
        ],
        [
            "OK, so here's what I'm going to do.",
            "I'm going to show you how you can find that approximation, the good, the good green approximation features the likelihood terms.",
            "OK, so I'm just going to 1st show it in a sort of abstract.",
            "In an abstract sense.",
            "OK, so recall that.",
            "Add this likelihood term, which is a function of X. OK, and I was just calling this FI affects the fact they're connected to X. OK, and we want to approximate that.",
            "With.",
            "Some Gaussian which I'm going to call FI tilled of X.",
            "Which is going to be our approximation.",
            "And if I have, X can have essentially any functional form, we're not going to restrict at all.",
            "However FI till it has to be a Gaussian Onyx.",
            "Now what we're going to use to make this approximation is we're going to use knowledge of the other factors that are in the model.",
            "An on the previous slide I called those.",
            "Q Not I have X so basically will have this will have this this Gaussian which is which I'm calling the context.",
            "Is that is that hard to read?",
            "Anne.",
            "So we'll have so cute.",
            "I have X summarizes all of the other factors that are in the model.",
            "OK, and that is a Gaussian.",
            "So let me just write down all the constraints we have.",
            "So FYI, is anything.",
            "Cunot I.",
            "Is definitely going to be aghasyan.",
            "And I'll tell you how we ensure that later.",
            "NFI tilt is going to be awesome.",
            "OK. How should we find if I tailed well?",
            "So if we take basically the property we want is that if I take the context which is this QIX.",
            "And I multiply it by both that that output of that multiplication should be similar for the two.",
            "Which is which is what I was arguing on the previous slide.",
            "It isn't that we want justify till to match F. We want the product with the other factors to match the product because that's what the process here is after all.",
            "So essentially we want.",
            "F of X.",
            "Times cue not.",
            "I have X to be somehow similar to FI till devex.",
            "And Q not I have X.",
            "Now at this point we could choose various measures of similarity, but since I'm doing moment matching, let's use that.",
            "So we'll try and find one that same moments now to sort of reduce on the amount of notation I use, I'm going to introduce an operator here which is called deep rajappa rater.",
            "And.",
            "What project does it takes in any distribution and it gives you back a Gaussian which is the same moment that as that distribution.",
            "Well.",
            "So these will have.",
            "The same moments, and obviously if I give a Gaussian the project going to the same Gaussian back.",
            "OK.",
            "So question.",
            "Oh sorry, I meant the mean invariants.",
            "Yeah.",
            "OK, yeah, Gaussian can only match the meaning variance.",
            "Nothing more than that, so that's all I'm going to go for.",
            "But if you had, if you had used, for example, a mixture of two Gaussians, you could have gone for more moments if you wanted to question.",
            "Yeah.",
            "Yes.",
            "And then do this process for every factor, right?",
            "That's right.",
            "Let's table because we're doing important.",
            "Also doing the same.",
            "Proximation to the other factor so.",
            "Have you hugging your soon to form a queue when?",
            "Do not lie when you're doing it for the other part of Q about their constituents.",
            "Yes, yes yes.",
            "So the question isn't Q not I of X different for every factor as I go through all the factors and answer is yes that's why I called it cannot I?",
            "So it depends on I it's basically going to be, it's my overall approximate posterior with this fact.",
            "One approximate factor removed from it.",
            "So essentially the notation I use.",
            "I use Q of X for the approximate posterior.",
            "I'm trying to find for the Gaussian.",
            "I'm trying to find and use Q not I for that with one factor removed from it.",
            "And so yes, as you visit each factor, FI is going to be different in Q not I will be different because it'll have something different missing from it.",
            "Yes.",
            "That's right.",
            "Yeah, you don't get no others affected buildings left you OK.",
            "So Q not I is going to be the approximate version of all of those factors.",
            "That's what's going to happen.",
            "That's right, so basically we have a chicken and egg problem.",
            "We have to approximate the factors in order to find approximations of the factors and the way we're going to solve that is by solving by just setting it up as a fixed point system.",
            "So we're going to initialize the approximations and just iterate until convergence.",
            "OK, so.",
            "Anymore questions.",
            "Alright, so as I said, I want to find a distribution with the same moment and So what I'm going to do is I'm going to write the following.",
            "Going to see that the project FIX.",
            "Times Q9IX is equal to.",
            "FI till the XQIX.",
            "So it's not making a precise statement saying that the Gaussian on the right has the same meaning variance as the distribution on the left.",
            "And the free.",
            "The free variable here is just FITLQ not I you can't change that's going to be given to you and you have to find FI told.",
            "And so, in order to do that, all you have to do is solve this equation.",
            "So how do we solve this equation?",
            "Well, that's pretty easy.",
            "If I tilt of X.",
            "Must then be equal to prauge.",
            "Of if I ask you, not IX.",
            "Divided by not I ask.",
            "And does this have member that has to be a Gaussian?",
            "Is it a Gaussian?",
            "Well, it is because project is Mia Gaussian.",
            "And if I take the ratio of that with another Gaussian, I have something which is also Gaussian because of the exponential family property.",
            "So if I tilt axes indeed of the right form, and this is actually is the optimal fitil X for matching moments.",
            "This is the unique file which gives you the same moments.",
            "Everyone follow that.",
            "OK, so essentially that's the key equation.",
            "I mean, that's the."
        ],
        [
            "This equation you need now, you just wrap that up into an iterative scheme.",
            "Here I'm just trying to.",
            "I'm going to to avoid doing anymore anymore algebra with Gaussians, I'm just going to tell you that if I multiply 2 Gaussians, there's a simple formula which gives you a new Gaussian.",
            "You can easily compute the mean and variance of the new Galaxy, and if I take it, the product of two and Gaussian densities, and similarly if I have the ratio of two Gaussian densities as I had in the last slide, there is a simple formula which will give you the median variance of the new Gaussian density.",
            "OK, so you can type that into your favorite object oriented package and then you can just call that times and divide of Gaussians and use that as your use it as your division and multiplication operator from now on.",
            "So I won't have to talk about Gaussians anymore, I'll just say divide these Gaussians or multiply these Gaussians.",
            "OK.",
            "Question.",
            "That's right, so I'm allowing my Gaussians to have negative variances in this case.",
            "So essentially my factors don't have to be normalized Gaussian, so I'm just going to make the normalizer.",
            "It's just a scale factor anyway.",
            "On the whole posterior, so I'm just going to use a normalized Gaussians as my approximations, multiply them altogether to get my Gaussian posterior, normalize at the end, in which case it will be.",
            "It will be proper so.",
            "Guarantee that you are.",
            "So here's the thing.",
            "So when I computed FI tilled I got it from the prauge of something.",
            "OK, and so I know that when I multiply back do not INF.",
            "I tilled, it's going to be an actual proper Gaussian.",
            "Is there another no."
        ],
        [
            "OK, so I want to give you some intuition of how these approximations look.",
            "How that formula behaves that product divided by Q not I formula.",
            "So what I'm going to do is I'm going to show you the actual factor in this in the actual clutter problem and how it gets approximated as I changed the context.",
            "OK, so.",
            "This blue curve is what the actual likelihood looks like.",
            "So if I fix iy in this case, I think why I was two or something like that and I'm plotting.",
            "What is it likely for X?",
            "And essentially, so intuitively, what the likelihood for accessing is that.",
            "You should be near the observation, but it's OK if you're very far from the observation, because the observation could have been the background noise, right?",
            "So you get this likelihood, which is a Gaussian, but then has this flat thing.",
            "So zero is here, so this is so the likelihood is raised above 0.",
            "It never never eliminates any particular value of X, it just says that values near this are better than others, but otherwise you can be far away if you like.",
            "OK, so now we want to approximate that blue curve with a Gaussian distribution.",
            "So let's start with the example on the right actually, so my context, which is the Q not I function is this green curve.",
            "So let's suppose that we know that all of the other likelihood terms in the problem give me this very, very narrow Gaussian right on that spot, and I know that whatever approximation I'm going to make this blue likelihood I'm going to multiply it by that green curve, right?",
            "So, in that case, I know that I really only need to be accurate, right on the right on that spot, right?",
            "In that one particular place in the likelihood.",
            "And in fact, if we use that formula, given the previous slide, we get this red Gaussian as our solution, which does exactly what you expect.",
            "It matches the likely right at that spot, yeah?",
            "So yeah, so the question is why did it move what I'm doing here is I'm showing the same.",
            "I'm going to show the same blue curve on all these slides from going to move the green curve around and that's all that I'm going to change.",
            "Is the green curve and I'm just showing the resulting red curve, so the red curve is deterministic function of the green curve and the blue curve.",
            "I'm just showing.",
            "What is the?",
            "What is the approximation you get out for different combinations of factor and context?",
            "Basically, the property that you want to have happened is that is that the context tells you where you need to be accurate, and so the red curve should always be good in the neighborhood of the context.",
            "So just showing you intuitively that it has the behavior we want.",
            "So on the right hand case it matches the curve exactly where we want to match and what it does.",
            "Other than that, I'm sure it's about approximation away from the context, but doesn't really matter 'cause we're going to multiply by the context anyway.",
            "OK. Now here's an interesting case.",
            "So if the context is right here.",
            "Then we have to approximate this convex curving up part of the likelihood function and the only way to do that is to use a Gaussian with a negative variance and this is what a Gaussian with a negative variance looks like.",
            "If you ever wonder.",
            "And as you can see, these are very useful actually for modeling certain likelihood.",
            "So if you ever have a likelihood with a with a concave up part, you want to use a Gaussian with negative variance to model it.",
            "And that's what happens here.",
            "So we get we get a very nice approximation of that likelihood.",
            "In this in this region."
        ],
        [
            "OK, so if we make the context wider so before it was very very narrow, so we just had the Model 1 little tiny part of the likely.",
            "If the context is a bit wider, meaning we don't have as much data around, then what you find is that it's sort of it's sort of takes a more more averaged approximation, so it isn't sort of locally specific anymore.",
            "So in this case.",
            "We still get a negative variance, but it sort of tries to be good in a bigger area and similarly on the right.",
            "And if we make the context."
        ],
        [
            "Very very wide.",
            "Then we end up with just sort of a one global overall Gaussian approximation, which is what you would have expected from the beginning, right?",
            "So if I didn't but in tell you anything about what I was going to play with the best you can do is just to make one big moment matched approximation.",
            "Question.",
            "So we could we make a good, very good approximation and where exactly we made a good approximation 'cause on the previous examples some context give good approximations in some areas.",
            "Other areas, right?",
            "Well the.",
            "OK, so the question is how can we understand the error that we're making in the approximations so you could locally measure the error that you've made.",
            "So after you've done after you've made found the red curve, you could just measure the error to the blue curve.",
            "And you could.",
            "You could measure.",
            "That way you can add up those approximations, and some people have done that as a way of estimating the error of a VP.",
            "I'm not certainly one thing to do.",
            "But I think what really happens is you run EP is that you start out with all of your approximations being very flat and very broad, and so you end up in this case.",
            "So everyone just make sort of a broad averaged approximation, but then as the as the algorithm iterates you get more and more information flowing in from all these other factors and you end up getting narrow or an error or context and you get more and more specific approximations.",
            "Question.",
            "This negative Goshen store isn't just computationally free, it's just the computational tracking.",
            "I mean, well, OK, there's a public interpretation.",
            "They probably interpretation is that if this blue curve was your prior and this sorry if the green curve was your prior on X and the blue curve was your likelihood.",
            "Then your posterior distribution would have a bigger variance than your prior did.",
            "And that's essentially what this red curve is saying.",
            "So saying you need to.",
            "You actually need to reduce the variance of your prior in the posterior.",
            "So you can interpret this approximation these Gaussian approximations as being especially what would be the equivalent Gaussian observation as the likelihood, as you're likely right, would be would be the equivalent Gaussian up thing that I could observe and what this is saying is that the closest equivalent in a Gaussian observation would be one with negative variance, meaning one that actually makes you more uncertain after you observed it, rather than one that makes you more certain.",
            "And that certainly does happen in some cases.",
            "Yes.",
            "I mean, if you if you iterate this.",
            "Are you able to guarantee that all the all the approximated terms have positive variance?",
            "No, no isn't it more reasonable that than to exclude that measurement from the system so that your answer typically doesn't think that measurement already doesn't give any information, but increasing your uncertainity more?",
            "OK.",
            "So the question is, should we just?",
            "Should we run the algorithm to conversions and then throw out all of the messages that had negative variances?",
            "And the answer is, I would say no, because you want your posterior.",
            "Correct amount of uncertainty in it, and if one of your data points says that you should increase the amount of uncertainty, then you should do that you don't.",
            "You should just ignore it because that's what it says to do.",
            "In particular this approximation.",
            "The reason that it has negative variances because you're likely does have that shape in that region, and so just by just by throwing out this.",
            "Likely because there's a shape you don't like that doesn't seem right, right?",
            "That's not that's not the Bayesian correct thing to do.",
            "You should multiply all the liquids no matter what shape they have, even if they're unfriendly."
        ],
        [
            "So there we go.",
            "So now all we need to do is we need to put this formula together into an iterative scheme.",
            "So I've given you this formula where I take the project and I divide and now we're just going to make a message passing scheme out of it.",
            "So we're going to start with a case where there's only two factors in the model, so I just have a variable X. I'm trying to estimate and it's just going to factors F1 and F2.",
            "And I want to Gaussian approximations of the posterior on X.",
            "So what I'm going to do is I'm going to approximate each of these factors by Gaussian terms and after I found these two edges, multiply them together and that's my Gaussian posterior on X.",
            "And the way I'm going to find each of these approximations is I'm going to 1st initialize with some approximations and then I'll take one factor of the context for the other factor, because I know that after I approximate factor one, I'm going to multiply it by factor 2, and similarly for you, I'm going to take that approximated multiplied by factor one.",
            "So therefore when I approximate each factor, I'll take the other factor into consideration, and So what we end up getting is this formula here, which says that if I want to approximate factor 1, first of all I take the approximation that I already made for Factor 2.",
            "Which I know that I'm going to multiply by in the end.",
            "I multiply it by the exact factor one.",
            "I do a project divide right?",
            "So this is saying that I'm going to choose F1 tilt.",
            "So that when I multiplied by FT which I already have in hand.",
            "But that's going to have the same moments as if I had taken F1 and multiplied by F tilt.",
            "Right, so if I finalize on my FT tilled, this is definitely the right F1 tail to choose, right?",
            "But now I can do it from the direction if I finalized on my choice of F1, tilt the best F2 tilt is obviously the one given by this formula, 'cause that's the one that will have the same moments.",
            "And now we just go back and forth basically.",
            "Until they would have won F1.",
            "So, so I'm assuming that F1 and F2 are non Gaussian factors.",
            "So if I multiply them together I get a non Gaussian distribution which I don't want.",
            "OK, so in order to force X to have a Gaussian posterior, I'm going to approximate each of the factors connected with customers.",
            "Question.",
            "Sure.",
            "Yeah.",
            "That's right, yeah.",
            "That's right.",
            "Yeah, and the and the green is the cue, not I.",
            "So does this procedure make sense?",
            "Right?",
            "Now here's the thing.",
            "What I've done is I've I've ensured that F1 till times F2 tailed is the project F 1 * F Two Hill and on the bottom I've ensured that F1, tilt times F2 tilt.",
            "Is the project F2 tilt F1 tilt?",
            "OK.",
            "So if I run this to convergence, what I'll know is that these two things are equal.",
            "OK, but that doesn't mean that I've necessarily found the prauge.",
            "Of what I really wanted, which was F1F2.",
            "So that's what I really wanted, which is the arguments of the actual posterior.",
            "So this is not necessarily the same as this.",
            "And the reason for that is because I had to.",
            "I had to use a context which was Gaussian.",
            "I couldn't use the exact F2 as my context for fitting F1, because that would be intractable.",
            "I mean, it doesn't scale if you do that, so I had to add user Gaussian context when approximating F1.",
            "Hence there's the approximation.",
            "That's why I can't get the exact moments, so there's sort of sort of two approximations going on.",
            "One is that.",
            "I'm approximating the posterior with Gaussians.",
            "That's one approximation, and Secondly I'm not getting the Gaussian.",
            "That is exactly the same moments as the real cost here, but it will be very close, as you'll see."
        ],
        [
            "OK. Hopefully you can now see how this would generalize the three factors.",
            "So suppose I have X connected to three factors, all non Gaussian, and I want to make them all Gaussian.",
            "So how should I update for example F1?",
            "What should F1 till B?",
            "In my updating scheme.",
            "Anyone like to venture a guess?",
            "Yes.",
            "F2 tilt.",
            "And F3 tilt.",
            "Yes.",
            "Exactly, and why can I do that?",
            "The reason is that F2 till then at three till they both Gaussian.",
            "So the product of Gaussian.",
            "So again have a Gaussian context.",
            "So I can I can put together all of my approximate factors into a single Gaussian and just use that as my context so I don't have to know how many factors access connected to what.",
            "I'm approximately one I can just take all of them, multiply them altogether, Singleton, and just pretend as if I'm connected.",
            "Only one other factor essentially.",
            "And if I want to update F2 tilt, well just by symmetry.",
            "I just take the exact F2, multiply it by F1 and F3 is approximation.",
            "And divide by F1 of three.",
            "OK, so does everyone get the general pattern at this point?",
            "So essentially I have a bunch of coupled equations and and Interestingly enough what ends up working to solve this coupled equations is simply to iterate them to a fixed point.",
            "It often works, it doesn't.",
            "This actually doesn't probably reach a fixed point, but it often reaches a fixed point very fast, and if you actually look at these equations in detail and compare them to, say, loopy belief propagation, it turns out it's doing essentially the same as loopy belief propagation, so it has the same sort of issues as the same sort of speed, but also lack of convergence proof as loopy belief propagation.",
            "OK."
        ],
        [
            "Alright, so.",
            "So what?",
            "So what's the big picture?",
            "So coming back to the big picture here, one way you can interpret one message passing is is essentially, it's a distributed optimization.",
            "I'm trying to.",
            "I'm trying to solve for the best approximation zephy tilts and I'm doing it in this very distributed way, where where, where I choose MFA till to send them to send them over to a factor.",
            "That factor decides how it should approximate itself and then sends its approximation to the other ones and so on.",
            "Is that a question?",
            "Yeah, OK. Variables that mean you are doing something you're looking for, some pizza port in a 2 dimensional space.",
            "Yeah, so each of these approximations has two free variables, which are the mean and variance of that approximate factor.",
            "So in fact there's going to be 6 variables of this optimization problem.",
            "Essentially an I'll iterate to a fixed point of all six of those numbers.",
            "Is that is that?",
            "It's not complicated because all I have to do is initialize these approximations to some save values.",
            "So for example, uniform is what I usually use, so you just set all of these F tilts to uniform distributions and just iterate these equations in orders.",
            "You have three equations, you just run those updates in order over and over and over again, and then that's how you reach your fixed point.",
            "OK. OK, so so right.",
            "So back to the message passing interpretation.",
            "How can we interpret this message passing so?",
            "We have our exact distribution P. Which is a product of factors on X and we want to find an approximate distribution Q.",
            "Which is a product of approximate factors on X.",
            "And we're now trying to solve an optimization problem trying to find the best FI tools that we can.",
            "And we're going to solve this in a distributed way.",
            "So basically we're going to choose values for all the FIS.",
            "And essentially, we're going to send the FIS.",
            "We've already got to approximate the ones to re approximate the ones we have.",
            "And essentially, you can think of what message passing is is just a way of choosing the parameters of Q to FTB.",
            "That's essentially what it is.",
            "Now when running any sort of message passing algorithm, there's essentially two types.",
            "Two choices you need to make.",
            "One is what type of distribution do you want to have at the end.",
            "So in this case I chose a Gaussian distribution because that seem relevant for estimating X.",
            "You could choose another approximating family as well, so in particular expectation propagation will work for any distributions which are closed under multiplication, because that's really the only property I needed that I could divide and multiply distributions and stay within the same family, so anything that's closed under multiplication is fine, so that includes beta distributions.",
            "Gamma distributions, the visualizing so on essentially any of the standard members of exponential family, would work.",
            "Um?",
            "The next choice you have to make is what sort of cost function do you want to minimize, and next time I'll go into more detail of what sort of what different cost functions you could use today.",
            "I'm only going to talk about one cost function, which is the moment matching cost function.",
            "But it should be clear that I could.",
            "I could replace my moment matching procedure with anything else and I get a similar message passing type procedure, right?",
            "OK.",
            "Right, so here this is just repeating that stuff again.",
            "Um?",
            "And I will skip this bit."
        ],
        [
            "And this bit.",
            "Alright, so.",
            "What happens if we actually take the procedure I just gave you, which is called expectation propagation, and we run that run all those fixed point equations to convergence on the actual clutter problem with 20 actual data points.",
            "So again, blue is that exact posterior.",
            "I showed you before.",
            "Purple is the best possible Gaussian, which is the one that is exact same moments as the blue curve, and then green is the one that you actually find by this iterative scheme by EP.",
            "And we'll see that we see that it doesn't exactly have the same moments as the purple curve because of the because of those that second approximation that we made.",
            "But it's a pretty good fit.",
            "And if we compare it to other algorithms that are available for fitting Gaussians, will see that it's actually quite good at this problem."
        ],
        [
            "So in particular I ran variational bounds.",
            "I ran the plus method on the exact same problem, and next time I'll explain how you how you would run these two on this problem, But essentially these are the two Gaussians you get.",
            "You probably can't see the plus one very well, so that's this.",
            "Very light blue Gaussian here and the very strong balance is there red Gaussian."
        ],
        [
            "And here, here's the comparison of the moments that you get out of those three methods.",
            "So exact posterior mean was 1.64 in this problem, EP is actually quite close again.",
            "1.64 Plus in VB.",
            "Posterior means slightly off, so the Gaussian is a bit shifted, but even more importantly, the variance is much better approximated by EP.",
            "And in particular, the variational bound approach as a much smaller variance than the real posterior.",
            "That's right, yeah.",
            "So all three approx.",
            "All three methods give you a Gaussian approximation.",
            "That's just three different ways of doing it question.",
            "Does the fix?",
            "It it would in a multimodal problem.",
            "But it doesn't in this case, because this is a very clearly unimodal problem and this is 1 strong mode of the posterior.",
            "So you're always going to converse with that.",
            "But just just as in loopy belief propagation, if you have a multimodal posterior, you will be sensitive to initial conditions.",
            "Yeah.",
            "Factors to be normalized?",
            "Or can you deal?",
            "How do you deal with her?",
            "Then you have a missing normalization constant.",
            "OK, so the question was do you have to normalize all the factors and the answer is no.",
            "So in fact I wasn't assuming normalization in any of this.",
            "I was only assuming that FI times Q not.",
            "I was normalizable, I never had to assume that FI was normalizable, nor did I have to assume that F~ was normalizable.",
            "That's right.",
            "Yeah.",
            "So if you look at all of my equations, I never have to never compute the moments of just FYI or FYI, tilled by itself.",
            "I always compute products of things.",
            "Which by construction will be will be normalized."
        ],
        [
            "OK.",
            "So of course I'm going to show you probably works well, right?",
            "Here's a more detailed comparison where I'm showing the computation time versus the error of different approximation methods for the clutter problem here, what I've done is I've drawn 20 points from the model and here I drew on the right hand side.",
            "I drew 200 points from the model.",
            "And the real mean was too.",
            "So.",
            "The way you read these curves is each iteration of EP gives you an estimate, so I can always stop EP after, say one iteration or two iterations and get an estimate, and so the Blue EP curve there is showing what you get it after every after every iteration.",
            "And similarly we get a curve out of the process method in variational Bayes, because again you can stop them early and get an answer.",
            "I'm also showing the results from important sampling and Gibbs sampling again, where after every sample you look at what is the quality of the answer.",
            "And so on.",
            "The left curve I'm showing how well you estimate the posterior mean, as you saw before, the peak is a much better result, and Interestingly enough it also gets it very fast, so it gets it incomparable amount of time as computing Laplace method or variational bounds.",
            "So on the third iteration it gets, it gets closer to the posterior mean, but then corrects itself and moves back away from the posterior mean.",
            "Right, so that that can certainly happen, right?",
            "It's just just an iterative fixed point algorithm.",
            "Similarly, gives sometimes gets closer to the posterior mean and moves away, right?",
            "Because you're taking samples and averaging them.",
            "So I haven't.",
            "I haven't averaged the results over many problems, which is so usually you see averages over many many problems and so you see these nice smooth curves.",
            "Here I'm showing it for one particular instance.",
            "You see all the noise that's inherent in it.",
            "Again, yeah, so right.",
            "That's just the dynamics of the of the procedure.",
            "It goes towards towards the correct answer and then maybe overshoots it right.",
            "And so you get this.",
            "You'll get this dip behavior.",
            "OK, so yeah, So what I'm comparing to here is the exact posterior mean, not not the target value that the algorithm is trying to get right, which is which will be different in each of the algorithms cases.",
            "Right, so interesting thing to notice on this plot is that as I go from 20 points, 200 points, the deterministic methods Laplacian EP suddenly get very good.",
            "I mean, they're actually accuracy gets very high like the right, so the vertical scale is the same.",
            "So these methods have suddenly become super accurate, so EP is not in the minus six, whereas the sampling methods are essentially the same error as he did in a 20 point case.",
            "And the reason for that is that when you have more data, the posture becomes more and more Gaussian, so your assumption makes.",
            "More and more sense, and so all of these deterministic methods get better, and that's sort of a nice property of all the deterministic inference methods which the sampling methods don't have.",
            "So if you think about it, the sampling methods generally don't benefit from the fact that your posterior is is especially Gaussian.",
            "Benefit from there being one mode rather than two, but if you have one mode which is becoming more and more Gaussian, your sampling method isn't going to suddenly become better.",
            "Yes.",
            "The hidden variable parameter yes pending here is one dimension.",
            "That's right, yeah, so can you give us an intuition for how things would work in higher dimensions?",
            "Well, that Gaussian property would be the same even in even higher dimensions.",
            "So I mean empirically.",
            "Like you know, sampling methods versus deterministic algorithms in high dimensions.",
            "Do you have a?",
            "The sense for whether qualitatively forget very different results than this, Oh well, the first of all, these results are not really based on the dimension of the problem, so you get results like this even if you make.",
            "Even if you make the clutter problem high dimensional.",
            "So I have a version of the clutter problem, which is where you have a K dimensional Gaussian which is observed with noise and so on.",
            "And you can run all these algorithms on it and you basically exact same curves out when you're on the K dimensional version.",
            "Really, the difference in performance comes down to the shape of the posterior.",
            "That's really what it comes down to.",
            "So if you have a multivariate Gaussian posterior, then the deterministic albums are going to work very well compared to sampling ones.",
            "That's that's really what it comes down to.",
            "Question.",
            "I'm wondering it feels like there's sort of a kind of deep connection with PM here, right where you sort of instead of keeping the maximum likelihood, you're just keeping the whole distribution right.",
            "Yes, and in fact the variational bounds have even more of that flavor.",
            "But yes, it definitely is that flavor.",
            "Propagation, why did I name it expectation propagation?",
            "Well, because it extends belief propagation.",
            "That was essentially the reason, so belief propagation passes the entire distribution as a message rise.",
            "Expectation propagation will only pass moments of the distribution.",
            "Certain expectations of the distribution that allows you to have very compact messages.",
            "Yep, theoretical guarantee about performance or the accuracy of this network.",
            "There is hardly any.",
            "I mean there's some for belief propagation, which would be a special case, but fully general case of all expectation propagation algorithms, there's hardly any results on.",
            "So what I did was I took the exact mean of the posterior distribution.",
            "So the mean of the green curve at the blue curve, and then I used the mean of the Gaussian that came out, and I measured the absolute difference and the same for the.",
            "Yeah, it's the mean in both cases.",
            "Question.",
            "So even if you would use a Gaussian approximation or just area, yeah I could have zero errors in this.",
            "Correct, yeah, that's right.",
            "So yeah, OK, so OK, right?",
            "So this so you're saying this metric is somehow cheating because it's measuring something that a Gaussian could capture.",
            "Yes, agreed.",
            "Error coming from because you said there's two type of approximation.",
            "One is because of using Dustin and the other one is because you don't actually do moment matching.",
            "Yeah, exactly that's right.",
            "So here, if you're measuring the error due to local, that's correct, yeah.",
            "I mean, well, there are cases where the posterior mean is actually the answers of the problem.",
            "So for example, if I wanted to predict for a test point, where would it appear?",
            "What is the expected location of a new point then the posterior mean of X would be the answer to that question.",
            "OK."
        ],
        [
            "So so earlier this morning in Chris is talk, someone asked about censoring, so I thought, why don't we censoring right?",
            "Is that person here by any chance, yes.",
            "So so we can write down a censoring problem which is very similar to the collector problem.",
            "So here I've written down a simple centering problem where I have an ex that I want to meet from Y.",
            "Now.",
            "X Again has this Gaussian prior and I have a bunch of wise.",
            "We turn just Gaussian observations whose mean is X, but some of the wiser censored and the censoring process that I picked is 1 where you just know that the magnitude of why is bigger than some threshold, so you know that why is magnitude 10 or more, for example, that would be a censoring process, so my my whatever device I'm using can't measure beyond some threshold and it just says oh bigger than threshold, that's it.",
            "Now for that sort of censoring problem, we can solve that using EP as well.",
            "What's the first thing we do when you want to solve the problem right on the factor graph, right so?",
            "The factor graph for this problem will be.",
            "Mother Bunch of wise and suppose we have a special censored Y.",
            "Which alright as.",
            "Why for greater than T?",
            "So this special censored observation.",
            "OK, so these factors will be ordinary Gaussian factors connected to X. OK, and for the censored observation, I'll have this special factor whose formula I've written here.",
            "So this factor says this is just the probability of observing AY which is between minus Infinity, right here.",
            "Probability of observing awai whose magnitude is bigger than T. Alright, so if you're gonna get 0 -- T and T. Then it's the probability of getting an observation.",
            "Here, right, so I'm just integrating the likelihood.",
            "The Gaussian likelihood over that region.",
            "So.",
            "Now what would be the exact posterior for X in this problem?",
            "Well, if I have a bunch of these censored observations will get a similar thing, is what happened before.",
            "I'll have a bunch of these, so each of these censored observations gives me this sum.",
            "An if I multiply together, I'll have to the end of these terms showing up each of the terms in this sum.",
            "By the way, is very simple, because this term, for example, is just a cumulative Gaussian function, and so will this term be.",
            "The problem is that you have two of them.",
            "Two of these cumulative Gaussians.",
            "So if we want to estimate approximate the posterior for X.",
            "In this problem we can run expectation propagation and essentially what will happen is.",
            "When we visit each of these Gaussian factors will find that their approximation is themselves because they're already Gaussian, and so when you run through that formula will just find you should just use yourself as the approximation.",
            "And the only thing then we need to wear something interesting happens.",
            "Is on these censored observations, where we're just going to get?",
            "The following problem we're going to have this censored observation we're going to have this context term.",
            "Q Not I have X, which in this case will be easier, just be the product of all the other Gaussian terms that will be my context for just one sensor observation.",
            "And then all I need all I need to do is do the project that.",
            "Divide that by Q, not IMX.",
            "And that will be my.",
            "Approximation for that censored factor.",
            "And this the moments of this product.",
            "Are can be worked out.",
            "So basically you'll have discussing CDF times another Gaussian and just work on those moments and I'll show later.",
            "A nice trick for working out moments of this type which arise quite a lot in EP.",
            "OK, so hopefully that that shows how you might use this censoring in this in this framework.",
            "OK."
        ],
        [
            "So let's move on to some other problems and I'll illustrate how you can apply even to those problems as well.",
            "Right, so here's the problem."
        ],
        [
            "Rises a lot in machine learning.",
            "You want to sort of tracking problem right?",
            "So you have you have an object which is moving around.",
            "I observe the object at certain spots at certain times.",
            "An my measurement is noisy, so the object is moving around that has some true location which is given by X and a certain instance in time.",
            "I observe a noisy estimate of its position, so observe Y one which is a noisy version of X1Y2 is a noisy version of X2 and so on."
        ],
        [
            "So what is the factor graph for that sort of problem?",
            "Well, we have suppose that the object is just undergoing some simple Markov chains, or random walk is a very common assumption.",
            "So we'll have, for example, this equation for the dynamics, which turns into that familiar linear chain factor graph.",
            "And our observation model is just that we add Gaussian noise to X.",
            "So we have these factors hanging off.",
            "And the estimation problem is that we want to estimate where was the objects we want to estimate X given the wise.",
            "OK, so.",
            "What I'm going to do?",
            "Yeah, so first of all.",
            "Now you might recognize this as a familiar problem, so you might say this is a common filtering problem.",
            "Annual without your signal processing book and start reading the common filtering equations, but I would suggest don't do that because the algorithm is going to give you is much more general, so you can apply it not only to linear Gaussian problems, but nonlinear problems as well, and I will show you how to how you can run a nonlinear problem, so put away your signal processing book for awhile and just think in terms of graphical models.",
            "So we just have a graphical model we're going to buy general purpose graphical modeling."
        ],
        [
            "Makes this problem OK, so.",
            "What I'm going to do is to compute the posterior distribution of the axis.",
            "I'm going to make a very particular assumption.",
            "Which is that I want a posterior distribution on axis which is factorized.",
            "So I want to get.",
            "I don't want to have a joint distribution all the access, but that's going to be way too complicated if I have 100 times.",
            "I'm going to a joint solution over 100 things and that's that's unwieldy.",
            "So instead I'm just going to try and get the marginal distribution of each of the axis.",
            "So what I'm going to do is, I'm going to look for.",
            "A distribution Q of X1 which is Gaussian on X1QX2 which is Gaussian.",
            "The next two and so on and the way I can ensure that is I need to approximate my factors in a particular way.",
            "All I need to do to ensure that as I is the only factors that are really bugging me.",
            "So the factors that are connected.",
            "Why aren't really a problem 'cause there's a Gaussian and there only one variable anyway?",
            "The real problem are those transition factors.",
            "The transition vectors are connecting two axes together and I don't want that because if I when I multiply those together I'll get a couple of distribution.",
            "So what I'm going to do is I'm going to.",
            "I'm going to approximate each of those pairwise transition factors with two separate Singleton factors.",
            "OK, so.",
            "Oh, so the transition factor is this one right?",
            "So this is P of X2 given X1.",
            "So it's these factors which cause coupling in my problem.",
            "And I don't want that.",
            "So what I'm going to do is I'm going to take each one of those factors, so this used to be.",
            "P of X2.",
            "Given X one what I'm going to do is I'm going to replace that with two Gaussians going to replace it with a Gaussian X one and a Gaussian on X2.",
            "That would be my approximation.",
            "And I will call that.",
            "The.",
            "Backward distribution for X1 and the other one will be called the forward distribution for X2.",
            "So.",
            "Just to write it a different way, I'm going to take.",
            "This transition factor and I'm going to approximate it as the product of two Gaussians.",
            "1X1 and 1X2.",
            "And I'm going to do that for all of the transition factors and it should be clear that after I've done that, I now have just a separate Gaussian distribution on all of my variables, right?",
            "Because this distribution here.",
            "Was already quite friendly.",
            "That was just pure Y one given X1.",
            "Which was already Gaussian in this case.",
            "And all I want to do is multiply that with with the backward distribution.",
            "That would be my distribution.",
            "Explain, OK question.",
            "Caution.",
            "So could I approximated by apparel biodistribution?",
            "Depends on both X1 and X2.",
            "I certainly could, but then I'd get a posterior which is a joint function of both X1 and X2.",
            "So but I said from the outset I don't want that.",
            "I want just marginal distributions on each of the variables.",
            "Absolutely yes.",
            "So if you want a better approximation, you can use bigger, bigger neighborhoods essentially, so you can say that I want to use the first to distribute.",
            "I want the first 2 variables to be in one of my approximate posteriors, the 2nd two variables will be in another one, and so on.",
            "We can certainly do that, and in fact, what you would do in that case is you would just simply not break the transition between one and two apart, but you would only break the transition between two and three apart, for example, and that would give you.",
            "What you wanted, I would give you a joint on one and two and three and four.",
            "So it's really just the choice of.",
            "I mean, once you've decided what you want your approximation to look like, how much structure you want to be in it?",
            "You, then it's pretty mechanical to decide.",
            "OK which factors we need to approximate in, how essentially and maybe you don't need approximate.",
            "Maybe some of them don't need to be approximated at all.",
            "OK."
        ],
        [
            "So.",
            "We now need to split these pairwise factors.",
            "As I said.",
            "It's going to have this form.",
            "And this form.",
            "And how can I find a good pair of Gaussians to approximate that?",
            "That single joint Gaussian.",
            "I'm.",
            "Let's see what should I do?",
            "Anyone have any ideas?",
            "Project project.",
            "Well, let's see.",
            "Suppose I chose.",
            "Suppose I did this.",
            "That's one option I guess.",
            "It's sort of records to generalize.",
            "We mean by projection, but there's an issue here, which is that I haven't taken into account any context.",
            "Right, so as I said before, the best way to approximate a factor isn't clear until you know what's going to be multiplied by.",
            "So in fact this is a trick question.",
            "You shouldn't should not try to approx."
        ],
        [
            "The factor is this way.",
            "Instead you should try to approximate it this way.",
            "So here.",
            "How far?",
            "Transition distribution, and now I'm going to take into account the approximations that I already made for the other transition factors, so I already have a Gaussian sitting here on X2 and I'll have another Gaussian sitting here on X3.",
            "In addition to these.",
            "These distributions here, which are abbreviated as Q upwards.",
            "OK, so everything I've written with the Q is a Gaussian.",
            "And what I've written with the IS is, well, it's a Gaussian, but not a not a Singleton Gaussian.",
            "And what I want to approximate with, well, the context is obviously going to be the same.",
            "Alright, so all of that is the same.",
            "We're not going to change any of that.",
            "I'm just going to change what's in the center.",
            "I'm going to replace that.",
            "With my 2.",
            "Univariate gaussians?",
            "OK.",
            "Arrows.",
            "You mean this?",
            "That's so this is the.",
            "This is the message that came from the data point.",
            "It's what's the factor that's connected to that data point, which I'm not drawing because it's not important, essentially.",
            "Are you confused confusion?",
            "Um?",
            "So.",
            "Before I said that you can take all the factors in the model, assume that they've all been approximated except for the one that you're looking at now, right?",
            "And that's essentially what I've done, so I've assumed that I've already split apart all of the other transition factors, and if any of the if any of these, like load factors need to be approximated, I've done those as well.",
            "OK, so every every other factor in the model has been turned into a Gaussian, and the only thing I need to do left is to break this one factor part into Gaussians.",
            "And so the the idea now is, how can I incorporate all the information that I've learned from my context to make to do this optimally?",
            "Right now?",
            "What does optimally mean?",
            "So we should come back to that question?",
            "What is it that we want to have happen?",
            "Well, we want X twos moments to be the same in the top and the bottom, and you want X3 is mostly the same time because that's our moment matching objective.",
            "That's what we've chosen that we've chosen as our things to do today.",
            "So.",
            "Let's just write out that constraint.",
            "So what we want is we want.",
            "This distribution.",
            "OK, So what I've written here on the upper right is the distribution of X2 for the top graph.",
            "Right where I have marginalized out X3, so that's the exact distribution of X2 on the top graph.",
            "And I want to approximate that.",
            "With.",
            "Pops the distribution I get in the bottom graph.",
            "Well distribution.",
            "The bottom graph is actually quite simple because I don't need to really integrate RX3, I can just ignore the fact all the factors that are not connected to.",
            "So that's what I get on the bottom graph, and I want these two distributions to be similar and the notion of similar I want is having the same moments, so this should not give you the answer.",
            "So if I want these two to have the same moments, how should I choose?",
            "This message here.",
            "So this is the only message I'm choosing in this part right?",
            "All the other ones are fixed.",
            "Any ideas how should I choose this message?",
            "So I should choose.",
            "So this will be equal to something.",
            "Exactly, so we just take the projection of this big mess on the top.",
            "OK Q.",
            "Thanks too.",
            "Integral whole bunch of stuff.",
            "OK divided by.",
            "This stuff.",
            "Is that clear?",
            "What does that do with common filtering?",
            "Well, here's here's the interesting part.",
            "So the distribution that's in this project.",
            "Is actually a Gaussian distribution in this particular case, because that transition distribution is a Gaussian.",
            "Right, so when I multiply all those Gaussians together, integrate X3 I Gaussian X2, multiplied by some more Gaussian X2, the whole thing is Gaussian.",
            "Is that clear?",
            "So what's in the project?",
            "Gaussian already?",
            "Before I did the garage, which means that the projects and no, it doesn't actually do anything, so I can remove the project and when I remove the project now, the denominator cancels with what was in the numerator.",
            "So in fact what I get out in this Gaussian case?",
            "Because it's a Gaussian case, is that?",
            "It's just this integral.",
            "OK, this should have been nice.",
            "There we go OK so now people have studied common filters or Hmm's know about forward backward equations will recognize this as the standard backward equation that you get in a Markov chain, right?",
            "Because this is the backward message for X3.",
            "This is the data term for X3.",
            "Integrate that through the transition density and that's the message that you the backward message that you send to X2.",
            "So in fact we didn't have to know this was a common filter model.",
            "We didn't know that that Gaussianity was special.",
            "We can just apply the same old EP equations and you get it out automatically.",
            "OK, so this this would be what you normally call the backward message.",
            "In a forward backward algorithm.",
            "And the forward message is very similar.",
            "You can go through the derivation of the forward message, which is this one.",
            "So so if we try and solve for this one using the same procedure, what you'll find is it is the standard way you computer forward message in Markov model.",
            "OK."
        ],
        [
            "So now how can we put this all together to get an actual to get an actual algorithm?",
            "How would we actually do inference on this problem so?",
            "So what is our approximation approximation?",
            "Is that for each of these transition factors, we're going to break it into two separate factors.",
            "So."
        ],
        [
            "So we have an iterative scheme where we just initialize all of these approximations.",
            "So we just initialize all these forward and backward messages essentially.",
            "And we'll start by updating this one in the context of the other approximations that we've made.",
            "So these have already been."
        ],
        [
            "It'll update that one.",
            "And then, once that's been approximated, which then go to the second one, we say, OK, I've already got forward and backward messages here."
        ],
        [
            "Now I will approximate this one.",
            "And so on.",
            "Now you see, this ones are these horizon approximated by approximately this one and then repeat.",
            "So you go in a round Robin fashion.",
            "And essentially if you order these updates just right, you'll get the same updates that you would do in a common filter.",
            "So you would get get forward messages in backward messages.",
            "Now, however, I said that EP was in iterative scheme that you iterate to get fixed point.",
            "So does that mean that we're going to get more often than a common filter one?",
            "So common filter would only go forward once in backward once, and it would be done.",
            "There will be no further iterations, but in an EP scheme.",
            "We would keep iterating well what ends up happening is as soon as you've done one iteration, you already have done the common filter, and if you iterate again, the answer won't change.",
            "When you're running, so it will be, it will reach a fixed point after the very first forward backward pass, so you don't necessarily lose anything by using YP for this problem, instead of common filtering and what yeah?",
            "That's right, yeah.",
            "So you have to be a bit smart about how you do the scheduling.",
            "So in particular you don't necessarily have to compute both forward and backward message every time you visit one of these pairs.",
            "'cause if you know that you're doing the forward version the forward pass, you only need the forward message and when you're going backward rolling into backward message so you can skip some of the computation that you would have done.",
            "I mean that on the grass it looks or like.",
            "Speaking.",
            "Oh, absolutely yeah.",
            "I mean the same is true of loopy belief propagation as well, so anything you've heard about loopy belief propagation would apply just as much to expectation propagation.",
            "OK, so as I said, if you do, if you do common filtering, if you apply this this EP procedure to a common filtering problem, you essentially get the common filter algorithm where finishes in one iteration, so that seems you didn't gain much.",
            "But the nice thing is that now we can apply this to nonlinear problems, where now we will have to iterate.",
            "It won't be done after just one forward backward pass.",
            "You have to do multiple forward backward passes and you'll keep refining each of those Gaussian posteriors to get that done."
        ],
        [
            "You get a good estimate, so I'll show you an example of that.",
            "So I can now apply the algorithm I just gave you to all sorts of nonlinear problems, and So what I'm going to do is I'm going to apply to the problem of Passan tracking, which is where we have a state, a real valued state.",
            "But what we observe is not just the Gaussian noise applied to that state, but we're going to observe an integer and that integers distribution is given by a person distribution whose rate is the exponential of X. OK, so this is the type of model you would use if you were trying to do some sort of time series modeling of counts.",
            "So if you had if you had counts of for example, you know the number of cells on a plate and you had some sort of time you had a time series of those counts and you want to model what is the underlying intensity of cells on that plate, for example.",
            "So any anything that's account that you've observed overtime, so we observe, for example, sales data for a store, and you want to model how?",
            "What is the true underlying distribution of those sales?",
            "You might use a model like this."
        ],
        [
            "OK, so here I'm just giving some simple distributions.",
            "So suppose the prior on the first state is just a Gaussian.",
            "The transition densities again just the Gaussian transition.",
            "But now the fancy thing is that the observation density is not a Gaussian distribution.",
            "So this person where the rate is the exponential of X and you get that you get that form."
        ],
        [
            "Loud.",
            "OK, so again, what's the first thing we do for any problem we write down the factor graph the factor graph.",
            "This problem looks exactly like the common filter problem, right?",
            "So we again have these transition densities between the axes and we again have these observation densities between the wise and the X is yes.",
            "More like smoother.",
            "Yeah, it's trying to find the posterior on each axis given all of the data.",
            "So yeah, it's a smoother.",
            "OK, so right, so the factor graph has the same form.",
            "The difference now is that these observation densities now are not Gaussian, which means that if we want to get Gaussian queues.",
            "On each of the axes, we're going to approximate those factors as well.",
            "So in addition to, in addition to breaking apart the transition densities, we're going to have to now make Gaussian approximations on the observation factors OK."
        ],
        [
            "And you guys should now be pros at this.",
            "You should now know exactly what to do.",
            "If I give you this problem.",
            "So let's suppose we have a backward message for X1.",
            "Right?",
            "And I have my likelihood.",
            "Which is in this case of course on distribution on Y1.",
            "With intensity E to the X1.",
            "And I want to approximate that.",
            "Buy a Gaussian in X1 which will have some.",
            "Mean and variance parameters.",
            "How do I find?",
            "That gaussian.",
            "Use projection, yes.",
            "We love projection.",
            "So no one's answering 'cause it's so easy, right?",
            "It's so obvious what you would do.",
            "So what we want to do is we want.",
            "To take the factor, we're going to approximate, multiply it by our context.",
            "And then divide by the context.",
            "And that ensures that when I multiply these two together and get a posterior distribution of the same moments as that posterior distribution, OK?",
            "And so, so you just have to workout.",
            "What are the moments of apasan times a Gaussian with exponential rate, and I'm sure you guys can work that out.",
            "I'll leave."
        ],
        [
            "As a homework problem.",
            "How?",
            "And here are the results you get so so essentially, let me just briefly describe what the algorithm is like, so we have this forward backward thing on the top as we did before.",
            "But now we're going to have to approximate each of the likely terms.",
            "So as you're doing forward and backward, you're also going to be re approximating each of these likely terms, and each one is going to be approximated using the current messages that that that state is receiving.",
            "So with that seat is currently receiving a forward and backward message, and based on those current forward and backward messages are going to approximate that likely term.",
            "So the whole thing will need multiple passes, you converge.",
            "And So what I'm plotting here are the state estimates after each iteration, so here, so I have my time series at 100 time steps in it, so there's 100 different states we're tracking.",
            "And I'm plotting the posterior mean of each of the states.",
            "So the mean of the Gaussian that I'm estimating for the state.",
            "And I'm just showing what it's like after each iteration.",
            "So in the first EP iteration I just blanked out all of the approximations that they were all uniform and I just ran one forward backward and this is what you get from that one forward backward and you find that the estimates are all shifted and the reason for that is because you haven't yet fully incorporated all of the information from all parts of the data set.",
            "So there's sort of this sort of lag effect.",
            "But now when you run additional iterations of EP, you find that it stabilizes and EP iteration tenant essentially is converged to this blue.",
            "Estimate so if you remember that data set that I showed you have integer counts sort of low in the middle and high at the ends, right?",
            "So it makes sense that your estimate would be low in the middle and high at the ends for the underlying state."
        ],
        [
            "Mean.",
            "OK.",
            "Here I'm showing the the exact posterior for the last state.",
            "So for State 100 of the chain, given the data set and comparing that to the EP approximation, so the exact one is in black.",
            "So after iteration one EP gets this blue approximation blue Gaussian an after iteration three, we get a very very close green Gaussian.",
            "Now the exact one is not Gaussian, but it sure looks Gaussian, right?",
            "So it's again one of these problems where even though the exact distribution is actually quite complicated, if you were to write it out, it's an integral of a whole bunch of Gaussian states times plus on likelihoods.",
            "So it's very messy analytically.",
            "But when you actually plot it, it's actually very nice distribution."
        ],
        [
            "OK, so.",
            "Here I'm comparing different methods for this problem.",
            "Um?",
            "So on the top I'm showing the the posterior means that were estimated, so the same as the plot before, I'm just adding additional algorithms to it.",
            "So the extra algorithms that I'm adding this time I'm adding particle smoothing, which is a well known algorithm for handling nonlinear time series problems.",
            "And I'm also considering a Gibbs sampler, which I'm calling MCMC here, which is something you could also use for a time series problem, although would be very slow, and by the way the particle filter and the.",
            "And the MCMC sampler were run for a very long time and they were run.",
            "They used like 100 times more computer time than the EPL going to.",
            "So even though yes, you could run them longer and longer and longer and get better and better results.",
            "I ran them for what seemed like a feasible amount of time, and these are the results I'm getting.",
            "As you can see, the particle smoother actually doesn't do particularly good job if you look at the top plot here, you'll see that there's this again, this lag effect with the particle smoother, so it doesn't something particular.",
            "Good job of smoothing.",
            "But otherwise the mean is pretty close by the way.",
            "You might be wondering why the why you don't see a blue curve creepy?",
            "That's because it's right on top of the exact curve on this planet.",
            "On the bottom plot you can just barely make out that there's a distinction between the blue and the black curve.",
            "As for that for the posterior variance.",
            "Now interesting thing that I've noticed here, which I've noticed in many problems, is that for the.",
            "For the particle smoother, which is the red curve.",
            "It's very good at filtering, so particle filters are particularly good filtering, so they give you a nice estimate right at the end of time.",
            "But when it comes back to smoothing backwards, they're actually not very good at all, and so we find is that the estimate of the state posterior gets very very bad as you go back in time.",
            "Yes question.",
            "That's right, yeah.",
            "So what I'm showing is I'm essentially showing what MBTI would give if you stopped it early.",
            "So if you ran it for a finite number of iterations and look at, the result would be, and in this case what I'm doing is I'm sampling the states of this Markov chain, which are highly correlated with each other and I'm using Gibbs, so it's not a particularly smart way of sampling states in a Markov chain, so Gibbs sampling means I have to sample one at a time condition on its two neighbors, so it makes it very, very slowly.",
            "And in particular, it mixes so slowly that I always underestimate the variance of each state.",
            "At this point, so systematically low in terms of my estimate of the variance.",
            "Um?",
            "Now there people have worked on some fancier ways of sampling Markov chains, but actually it's quite a hard problem to sample to sample a Markov chain with Monte Carlo efficiently.",
            "So if you were to type in, for example this model into bugs and ask bugs, what would be the state estimate you would use exactly this algorithm?"
        ],
        [
            "OK.",
            "So here is a comparison of time accuracy.",
            "So there's two different curves.",
            "Just because I use two different ways of doing the integral over the person.",
            "So if you could give us an times in Gaussian, and I did two different ways of doing that, one which is sort of fast and cheap, which is what we want, another one which is more accurate.",
            "So what this shows is that you know if the integrals that occur within EP are expensive, you may want to even make those approximate to make the to make the algorithm faster.",
            "So this is sort of the fast but less accurate way of doing that integral in here.",
            "So faster way of doing that integral.",
            "And here I'm comparing the results from MTN particle filtering which are way off even with lots more time.",
            "So I gave them huge amount more time orders of magnitude more time and they still were way off.",
            "And again, the reason for that is not because of the dimensionality of the problem or anything like that is because it's because it's a friendly problem.",
            "For EP, I mean the posterior is very very Gaussian, so you expect to get good results.",
            "OK.",
            "So I think I should end the talk there, right?",
            "So it's 5:30 and next time I will talk about other approximate inference albums.",
            "I'll talk about variational, Bayes and so on.",
            "I'm so I'll see you then."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm Tom Minka and I'm going to talk to you today about approximate inference.",
                    "label": 1
                },
                {
                    "sent": "At this point, you're probably very excited about graphical models and Bayesian inference, and you want to run home and implement some models.",
                    "label": 0
                },
                {
                    "sent": "The problem is that you'll quickly find is that.",
                    "label": 0
                },
                {
                    "sent": "Many times exact answers are infeasible, or if you try to use sampling, it's going to be very slow.",
                    "label": 0
                },
                {
                    "sent": "So what you'd like to do is do something which is both fast and Bayesian, and that's what I'm going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to do real time processing of an online data set, or if you have a huge database you want to process that.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These methods are welcome in, so I'm going to be focusing on Bayesian inference in this talk, so let me just give a quick overview of why I think Bayesian inference is so important and so useful.",
                    "label": 0
                },
                {
                    "sent": "I think if you want a formal definition, basically what does it mean to be Bayesian, it just means that you consistently use probability theory for reasoning about anything that you don't know.",
                    "label": 1
                },
                {
                    "sent": "So if you have a latent variable, if you have missing data, if you have parameters, you'll always represent that uncertainty with probability distributions and and.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's useful in a sense, because now all of your algorithms are consistent.",
                    "label": 0
                },
                {
                    "sent": "Every algorithm can handle these unknowns in exactly the same way, and you can make very general procedures for reasoning about all kinds of different models.",
                    "label": 0
                },
                {
                    "sent": "But there's actually another advantage, which is what Chris talked about this morning, which is modularity.",
                    "label": 0
                },
                {
                    "sent": "So by using Bayesian inference, you simply get this very nice decoupling of different things, so you can decouple, for example, your model from your decision making process.",
                    "label": 0
                },
                {
                    "sent": "So what I'd like to do is, I like to think of Bayesian inference is sort of a flow diagram where you have data at one end.",
                    "label": 0
                },
                {
                    "sent": "Alright, and you have your model.",
                    "label": 0
                },
                {
                    "sent": "And you put these two together.",
                    "label": 0
                },
                {
                    "sent": "And you get a posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Right now, if you want to make decisions as Chris showed this morning.",
                    "label": 0
                },
                {
                    "sent": "All you need is the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "You don't need to go back to your data, so if your loss matrix changes, you can just go to your posterior and ask what should my new decision be or if you are priors in different classes change.",
                    "label": 0
                },
                {
                    "sent": "You can again just make your decision based on the posterior already had you don't go back to your data so it's modular.",
                    "label": 0
                },
                {
                    "sent": "In that sense it summarizes everything you need to know about the data, and if you get more data, for example in an online streaming context.",
                    "label": 0
                },
                {
                    "sent": "You just take your posterior you incorporate, use it as a prior for the new data you have.",
                    "label": 0
                },
                {
                    "sent": "You get a new posterior and again you don't look at your old data again, so it's a very very efficient way of processing data.",
                    "label": 0
                },
                {
                    "sent": "If you think about it now, lot of people associated Bayesian inference is being slow, but actually I think it is being very a very fast way of processing data because of this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty.",
                    "label": 0
                },
                {
                    "sent": "So here this slide basically summarizes what I just said, so the posterior distribution is your friend that summarizes everything that you have learned from the data, right?",
                    "label": 1
                },
                {
                    "sent": "So instead of thinking of data, we should think about distributions, right?",
                    "label": 0
                },
                {
                    "sent": "An essentially described your training data allows you to make predictions, and as you do online learning, But the problem is, how can we efficiently represent in compute with these posterior distributions?",
                    "label": 1
                },
                {
                    "sent": "Because often they're very complicated, and so that's what I'm going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "How we can actually make this into a practical approach?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Azure now the tool that I'm going to use today is a very, very important innovation actually, which is factor graphs and which is a type of graphical model which is actually, I think, the best way of thinking about approximate inference algorithms in terms of factor graph.",
                    "label": 0
                },
                {
                    "sent": "So let me just give you a quick summary of what it was.",
                    "label": 0
                },
                {
                    "sent": "I know that zoom in or give a talk on this, but let me just give my own take on what a factor graph is.",
                    "label": 0
                },
                {
                    "sent": "So a factor graph basically can be applied to any function, it isn't, it isn't something specific to probability theory combined in any function.",
                    "label": 0
                },
                {
                    "sent": "All it does is it just shows you a way of factoring this function into a product of terms, and obviously this is not unique.",
                    "label": 1
                },
                {
                    "sent": "You can take a given function in factored in many different ways.",
                    "label": 0
                },
                {
                    "sent": "So if I take a polynomial for example, I can factor in various different ways and a factor graph just shows you one particular way of factoring the function.",
                    "label": 0
                },
                {
                    "sent": "So here I give an example of a function F of XYZ.",
                    "label": 1
                },
                {
                    "sent": "This is not a distribution, is just a function.",
                    "label": 0
                },
                {
                    "sent": "It happens to factor in this way X + y Y plus Z, XYZ and given that factorization.",
                    "label": 0
                },
                {
                    "sent": "I can now use a factor graph to represent that factorization.",
                    "label": 0
                },
                {
                    "sent": "So what is the factor graph for this function?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all I have my variables XY and Z.",
                    "label": 0
                },
                {
                    "sent": "And for each term in my factorization, I just make a box and I connect it to each of the variables that it uses.",
                    "label": 0
                },
                {
                    "sent": "So the first term is a box that uses X&Y.",
                    "label": 0
                },
                {
                    "sent": "The second term is a box that uses Y&Z.",
                    "label": 0
                },
                {
                    "sent": "And the third term is.",
                    "label": 0
                },
                {
                    "sent": "The box uses actions E, so that's the factor graph for this.",
                    "label": 0
                },
                {
                    "sent": "Factoring of this function.",
                    "label": 0
                },
                {
                    "sent": "OK, now why is this so useful?",
                    "label": 0
                },
                {
                    "sent": "Because posterior distributions often have this form right, so you often have some sort of parameter.",
                    "label": 0
                },
                {
                    "sent": "X which has some prior distribution and you're going to observe a bunch of data.",
                    "label": 0
                },
                {
                    "sent": "Right, why I give an axe?",
                    "label": 0
                },
                {
                    "sent": "And this will be your joint distribution of Y&X.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And so, so this sort of factored product and actually arise, and that's why that's why factor graph.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So useful.",
                    "label": 0
                },
                {
                    "sent": "We just show an example of a factor graph that arises in probability theory or machine learning.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose we just have a Gaussian observations of some unknown mean.",
                    "label": 0
                },
                {
                    "sent": "So we have this variable M which is unknown, and we've made observations of that.",
                    "label": 0
                },
                {
                    "sent": "And let's suppose we make ID observations of that.",
                    "label": 0
                },
                {
                    "sent": "So now you all know how to write this down algebraically, right?",
                    "label": 0
                },
                {
                    "sent": "So you'd write that the posterior distribution of M given a bunch of X is.",
                    "label": 0
                },
                {
                    "sent": "It is going to be proportional to first of all the prior on M. And the product of the likelihoods of all of the axes.",
                    "label": 0
                },
                {
                    "sent": "Right, hopefully that's second nature to you guys now.",
                    "label": 0
                },
                {
                    "sent": "But what is the factor graph for this problem?",
                    "label": 1
                },
                {
                    "sent": "Alright, well I've given you the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "I've shown you how it factors so it should be quite straightforward to give me the factor graph.",
                    "label": 0
                },
                {
                    "sent": "Can anyone give me the factor graph for this problem?",
                    "label": 0
                },
                {
                    "sent": "So your facts have M and all the axes.",
                    "label": 0
                },
                {
                    "sent": "And you have one factor for each X, and what does it do?",
                    "label": 0
                },
                {
                    "sent": "Connect them to each one OK. Are we done?",
                    "label": 0
                },
                {
                    "sent": "Yes, one single factor for the prior on M. There we go.",
                    "label": 0
                },
                {
                    "sent": "OK, let me give you another brain teaser.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "Alright, so what's the formula for a Markov chain so I have a bunch of axis.",
                    "label": 0
                },
                {
                    "sent": "And we have a distribution for the first one.",
                    "label": 0
                },
                {
                    "sent": "And then we'll have a distribution for each X conditional on the previous X.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's the that's the joint distribution for a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "If you pile familiar with.",
                    "label": 0
                },
                {
                    "sent": "But now, what is the factor graph for this Markov chain?",
                    "label": 0
                },
                {
                    "sent": "Square.",
                    "label": 0
                },
                {
                    "sent": "A chain of squares and circles OK.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "And there's the prior yes.",
                    "label": 0
                },
                {
                    "sent": "So we have X1X 2X3.",
                    "label": 0
                },
                {
                    "sent": "OK, and this so this box here.",
                    "label": 0
                },
                {
                    "sent": "Just to be clear, is the prior on X1.",
                    "label": 0
                },
                {
                    "sent": "This box here is the conditional distribution of X2 given X one and this box is X3 given X2.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Great, so now you all know how to write down factor graphs.",
                    "label": 0
                },
                {
                    "sent": "You're halfway there.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so just to review.",
                    "label": 0
                },
                {
                    "sent": "One, so there's two sort of big problems.",
                    "label": 0
                },
                {
                    "sent": "One is what graph should use for your particular data set.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to sit at all.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming that you figured out how to model your data already.",
                    "label": 1
                },
                {
                    "sent": "Then there's a second question is, given the grafana data, what is the mean of X?",
                    "label": 1
                },
                {
                    "sent": "For example, what are the?",
                    "label": 0
                },
                {
                    "sent": "What's the posterior distribution?",
                    "label": 0
                },
                {
                    "sent": "And there's a very different albums you can choose from, and the algorithm going to be looking at.",
                    "label": 0
                },
                {
                    "sent": "They are what are called message passing type algorithms, in particular expected.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Propagation variational bayes.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to illustrate these algorithms with a specific concrete problem which is seemingly very difficult problem.",
                    "label": 0
                },
                {
                    "sent": "If you look at it from exactly inference, but actually quite easy if you look at it from.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proximate inference POV.",
                    "label": 0
                },
                {
                    "sent": "OK, so this problem is one that I've used a lot in pit my papers, which is called the clutter problem.",
                    "label": 0
                },
                {
                    "sent": "So in this problem you have this unknown X scalar variable which has Gaussian prior and you have a bunch of observations of this X, But the observations are corrupted with some probability, so half the time the observations are just Gaussian observations whose mean is X, just as I wrote before, but half the time the observations are just plain noise, they have nothing to do with us at all, it's just why is distributed from zero 10 normal distribution.",
                    "label": 0
                },
                {
                    "sent": "So what is so?",
                    "label": 0
                },
                {
                    "sent": "This is sort of like a problem where you have background noise.",
                    "label": 0
                },
                {
                    "sent": "Some of your points are actually meaningful.",
                    "label": 0
                },
                {
                    "sent": "The foreground points that the ones that actually tell you about what you're trying to estimate, and there's a whole bunch of data that just says nothing about what you're trying to estimate.",
                    "label": 0
                },
                {
                    "sent": "Just random stuff that was thrown in.",
                    "label": 0
                },
                {
                    "sent": "But you don't know which points are which, OK, so.",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "And now we're going to observe the a bunch of these wise and we want to try to estimate X. OK, so at this point you guys can probably tell me what the factor graph is for this problem, right?",
                    "label": 1
                },
                {
                    "sent": "Factor graph of this problem.",
                    "label": 0
                },
                {
                    "sent": "So we have a bunch of wise.",
                    "label": 0
                },
                {
                    "sent": "We have X.",
                    "label": 0
                },
                {
                    "sent": "And we will have.",
                    "label": 0
                },
                {
                    "sent": "Are likelihoods connected to X another primix?",
                    "label": 0
                },
                {
                    "sent": "OK, now what is the what is the form of the exact?",
                    "label": 0
                },
                {
                    "sent": "Posterior on X for this problem.",
                    "label": 0
                },
                {
                    "sent": "So we give you N data points.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "What form does this have?",
                    "label": 0
                },
                {
                    "sent": "Well, as we know it's going to be.",
                    "label": 0
                },
                {
                    "sent": "P vaccine supportive iyi given X. OK now PX is a Gaussian P of why I given axis is some weighted sum of two Gaussians.",
                    "label": 0
                },
                {
                    "sent": "OK. Now, what's that?",
                    "label": 0
                },
                {
                    "sent": "What's that going to turn into?",
                    "label": 0
                },
                {
                    "sent": "Well, let's see.",
                    "label": 0
                },
                {
                    "sent": "So if I have.",
                    "label": 0
                },
                {
                    "sent": "If I have say.",
                    "label": 0
                },
                {
                    "sent": "Two data points.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to get Gaussian times a product of two terms times another product of two terms.",
                    "label": 0
                },
                {
                    "sent": "If I expand that out, I'm going to four terms.",
                    "label": 0
                },
                {
                    "sent": "In my son, all the Gaussians are going to apply to give Gaussians.",
                    "label": 0
                },
                {
                    "sent": "So essentially I have a mixture of four Gaussians in my posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Is that clear to everyone?",
                    "label": 0
                },
                {
                    "sent": "So let's see if I have two points.",
                    "label": 0
                },
                {
                    "sent": "I get 4 Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Doesn't sound too bad overweight if I have endpoints.",
                    "label": 0
                },
                {
                    "sent": "How many Gaussians do I have in my posterior distribution?",
                    "label": 0
                },
                {
                    "sent": "Two to the N likes OK.",
                    "label": 0
                },
                {
                    "sent": "So that doesn't seem very tractable.",
                    "label": 0
                },
                {
                    "sent": "So if I give you 100 points, you're already we already out of luck for doing exact inference here.",
                    "label": 0
                },
                {
                    "sent": "So yes, you can enumerate all those Gaussians, and you can compute that giant mixture, but it's going to be.",
                    "label": 0
                },
                {
                    "sent": "It's going to take a long time.",
                    "label": 0
                },
                {
                    "sent": "But is this problem?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That heart that is the question so.",
                    "label": 0
                },
                {
                    "sent": "This is what I get if I actually take yes.",
                    "label": 0
                },
                {
                    "sent": "What's that you're looking for?",
                    "label": 0
                },
                {
                    "sent": "The posterior on X.",
                    "label": 0
                },
                {
                    "sent": "So you have all this noisy data, so half of it is good, half of it is not.",
                    "label": 0
                },
                {
                    "sent": "You want to estimate the posterior region X.",
                    "label": 0
                },
                {
                    "sent": "Is that the question?",
                    "label": 0
                },
                {
                    "sent": "How many people?",
                    "label": 0
                },
                {
                    "sent": "Why do we need 4?",
                    "label": 0
                },
                {
                    "sent": "Oh, OK, So what I was writing there was was how complex does the posterior distribution for axis get?",
                    "label": 0
                },
                {
                    "sent": "How complex is this function here get?",
                    "label": 0
                },
                {
                    "sent": "If I have two data points.",
                    "label": 0
                },
                {
                    "sent": "And basically this case here.",
                    "label": 0
                },
                {
                    "sent": "And basically, if I just substitute in those formulas at the top into that, what I find is that I have a some weighted sum of four terms.",
                    "label": 0
                },
                {
                    "sent": "Right, each of which is Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So that's how the complexity of this grows.",
                    "label": 0
                },
                {
                    "sent": "But here's the thing.",
                    "label": 0
                },
                {
                    "sent": "If you actually take a data set of 100 points, and you actually compute this posterior plotted, this is what you get.",
                    "label": 0
                },
                {
                    "sent": "That's the posterior for X.",
                    "label": 0
                },
                {
                    "sent": "So yes, that is it is a mixture of two to 100 Gaussians, but it ends up having a very simple shape effectively, even though the algebraic formulas very complex, the actual shape is quite simple and this happens a lot in Bayesian inference problems, mainly because you have a sort of central limit theorem effects.",
                    "label": 0
                },
                {
                    "sent": "The more data more data you have affecting a certain parameter, essentially makes the distribution look posterior lobe Gaussian, even though each individual likely it could be very non Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So this gives us some hope that probably we could do some sort of approximation and get a good representation of this posterior.",
                    "label": 0
                },
                {
                    "sent": "Very simple, compact representation of this posterior and compute with that rather than going with this due to the 100 mixture of.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Audience.",
                    "label": 0
                },
                {
                    "sent": "So, So what I'm going to talk about is how can we?",
                    "label": 0
                },
                {
                    "sent": "How can we compute and represent that posterior distribution compactly?",
                    "label": 0
                },
                {
                    "sent": "OK, so at this point there's sort of a fork in the road of what type of approximate inference technique you want to use.",
                    "label": 0
                },
                {
                    "sent": "Now you've just seen whole bunch of lectures on sampling, and sampling is certainly one way that you could approach this problem.",
                    "label": 0
                },
                {
                    "sent": "I would say that sampling is particularly good for cases where the posterior distribution has a very complicated shape and it's not something you could easily summarize with some sort of analytic form.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have.",
                    "label": 0
                },
                {
                    "sent": "Shape on the left which has lots of modes in it.",
                    "label": 0
                },
                {
                    "sent": "Then using for example a particle filter or a bunch of samples to represent that distribution is would be a good idea.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if you have a nice smooth posterior distribution like the one I just showed you, you can actually get something much cheaper and much simpler, which is just to approximate it with some parametric families such as the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you have a tradeoff here.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing about sampling is that.",
                    "label": 0
                },
                {
                    "sent": "Is that it allows you to wait?",
                    "label": 0
                },
                {
                    "sent": "Right here.",
                    "label": 0
                },
                {
                    "sent": "OK, is that if you use enough samples, you know you're going to get a good representation of the posterior even if you don't know what it really looks like, as long as you have samples, you'll get something that captures most of the posterior.",
                    "label": 0
                },
                {
                    "sent": "As long as you could sample, that is.",
                    "label": 0
                },
                {
                    "sent": "The thing about deterministic approximations is that you don't really know in advance how accurate is going to be unless you actually examine your posterior distribution to see that it does match the formula fitting to see how Gaussian it is.",
                    "label": 0
                },
                {
                    "sent": "I just did.",
                    "label": 0
                },
                {
                    "sent": "If you don't do that, you won't really know how accurate your results are, so that's sort of this unpredictability to it.",
                    "label": 0
                },
                {
                    "sent": "Hand.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is very fast.",
                    "label": 0
                },
                {
                    "sent": "Now, within deterministic approximations, there's still a whole bunch of things you could do, so one of the original methods that people use was called in the plus method.",
                    "label": 0
                },
                {
                    "sent": "And what happens there is you essentially find the mode of your posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "You find the derivatives at that mode, and you choose a Gaussian which has the same mode in the same derivatives as your posterior.",
                    "label": 0
                },
                {
                    "sent": "So essentially you're choosing Gaussian, which matches your posterior at one point very well.",
                    "label": 0
                },
                {
                    "sent": "And this has been used for various problems.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it is very effective, so I've applied it for example to do Bayesian PCA where it works very well for that problem.",
                    "label": 0
                },
                {
                    "sent": "Another method you could use is called variational bounds, so in this case we'd be finding a Gaussian that doesn't just match at one point, but is a sort of good lower bound to my posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And one of the reasons that people like using lower bounds is, for example, you get certain guarantees about your approximation.",
                    "label": 0
                },
                {
                    "sent": "You get nice convergence properties of the algorithm and so on.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But today I'm not going to either of those going to 3rd approach.",
                    "label": 0
                },
                {
                    "sent": "We just called moment matching and I'll talk about variational bounds tomorrow.",
                    "label": 1
                },
                {
                    "sent": "But today I'm going to focus on this one, and the reason I like this one is because for certain problems where your posterior distribution does match your assumptions very well, you can get very good accuracy with this method.",
                    "label": 1
                },
                {
                    "sent": "And I'm going to be talking about a method called expectation propagation, which is basically a method for finding Gaussian approximations to posteriors.",
                    "label": 0
                },
                {
                    "sent": "Which was the essentially a combination.",
                    "label": 0
                },
                {
                    "sent": "It rose is a combination of two previous algorithms.",
                    "label": 0
                },
                {
                    "sent": "One is called assume density filtering which came out of the common filtering literature and loopy belief propagation, which came out of the machine learning literature and essentially it's it subsumes both of them.",
                    "label": 1
                },
                {
                    "sent": "So essentially, they're both special cases of the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Too bad today.",
                    "label": 0
                },
                {
                    "sent": "OK so today will be focused on moment matching.",
                    "label": 1
                },
                {
                    "sent": "Tomorrow we'll talk about variational bounds.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so first of all, let's come back to our problem.",
                    "label": 0
                },
                {
                    "sent": "Is there any hope of finding a Gaussian that fits our posterior well what I'm showing here is I'm showing again that same exact posterior distribution on X and I'm showing the best Gaussian fit and by best Gaussian I just mean the one that has the same moment as the same meaning variance as that posterior distribution, and we see that it's a reasonably good fit, though it's not a perfect fit and that's because our posterior wasn't exactly Gaussian, it was it had heavier tails in a Gaussian and as a result we're not going to be perfect, but it does a reasonable job.",
                    "label": 0
                },
                {
                    "sent": "So essentially our target is going to find that purple curve as fast as possible.",
                    "label": 0
                },
                {
                    "sent": "And the and the error between the purple curve and the green curve will never be on the recovery using a Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fox nation.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the basic strategy?",
                    "label": 0
                },
                {
                    "sent": "So recall that we had this factor graph for X.",
                    "label": 0
                },
                {
                    "sent": "Which had a bunch of factors.",
                    "label": 0
                },
                {
                    "sent": "We had some wise.",
                    "label": 0
                },
                {
                    "sent": "And the reason that the posterior distribution for X was not Gaussian was because some of the factors in this model were not Gaussian, right?",
                    "label": 0
                },
                {
                    "sent": "They were some of two Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Well, what if we were so lucky as all the factors in R model were Gaussian?",
                    "label": 0
                },
                {
                    "sent": "Well then we would end up with the Gaussian posterior X, and that's what we want.",
                    "label": 0
                },
                {
                    "sent": "So one way of getting that Gaussian approximate Gaussian posterior on X is to take each of the factors in R model an approximate each one of them with a Gaussian.",
                    "label": 1
                },
                {
                    "sent": "And if we approximate each one of these factors one by one with Gaussians will ensure that our approximate posterior will be costing.",
                    "label": 0
                },
                {
                    "sent": "So we just multiply them together and we get our approximate posterior.",
                    "label": 0
                },
                {
                    "sent": "So it's essentially what I'm going to do.",
                    "label": 0
                },
                {
                    "sent": "So it works in a very different way than.",
                    "label": 0
                },
                {
                    "sent": "For example, the process method.",
                    "label": 0
                },
                {
                    "sent": "So on the plus method you form the whole posterior.",
                    "label": 0
                },
                {
                    "sent": "You find this mode and so on.",
                    "label": 0
                },
                {
                    "sent": "Here I'm going to do it in a very distributed way.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take each factor one at a time and approximate it, and then eventually put them all together.",
                    "label": 0
                },
                {
                    "sent": "OK, so mathematically I'm going to take that some weighted sum of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to approximate it with Gaussian and Gaussian will have some free powders which I'm going to call me and VI and those are the numbers that I need to find in my algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, now at first this might sound a bit fishy, So what I'm going to do is I'm going to take something which is the sum of two Gaussians in approximately 1 Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And how can that possibly give me a good approximation?",
                    "label": 0
                },
                {
                    "sent": "If you think about it, if you think about what a mixture of Gaussians might look like, right?",
                    "label": 0
                },
                {
                    "sent": "And I'm going to try and approximate it.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "One Gaussian that sounds like how could you possibly do good doing that?",
                    "label": 0
                },
                {
                    "sent": "Here's the reasoning that.",
                    "label": 0
                },
                {
                    "sent": "When we multiply all of these likelihood terms together.",
                    "label": 0
                },
                {
                    "sent": "The posterior distribution will be very very compact.",
                    "label": 0
                },
                {
                    "sent": "In other words, the variance of the posterior.",
                    "label": 0
                },
                {
                    "sent": "We quite small compared to any single likelihood term.",
                    "label": 0
                },
                {
                    "sent": "In other words, if I were to overlay the posterior on top of one of these likelihoods, I would find that the posterior would be, for example, like.",
                    "label": 0
                },
                {
                    "sent": "This could be some very narrow thing because I'm multiplying together many many likelihood terms to get my posterior, so it will be very narrow.",
                    "label": 0
                },
                {
                    "sent": "And as a result, I don't really need to represent all of the details in each individual likelihood function.",
                    "label": 0
                },
                {
                    "sent": "All I really need to get a good approximation is just to represent this one bit.",
                    "label": 0
                },
                {
                    "sent": "Of the likelihood function very well, and if I can represent that one bit very well, then after having multiplied them altogether, I'll get a good approximation to my overall posterior.",
                    "label": 0
                },
                {
                    "sent": "And that's essentially why this method works and I can give you an.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other example of that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I'm showing just the effect.",
                    "label": 0
                },
                {
                    "sent": "This effect you get when multiplying a bunch of like this together.",
                    "label": 0
                },
                {
                    "sent": "So in the blue curve I have a mixture of Gaussians which I'm calling the exact likely.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of an idealized problem.",
                    "label": 0
                },
                {
                    "sent": "It's not the exact letter problem anymore.",
                    "label": 0
                },
                {
                    "sent": "But suppose we have some likely term, which is this blue curve, and it's a mixture of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "And we want to approximate it by another Gaussian and suppose we picked the green curve as our approximation.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "In our model we also have priors.",
                    "label": 0
                },
                {
                    "sent": "We have various other terms that are going to be multiplied in and I'm throwing all those together and calling that Q, not I of X which is the 2nd row.",
                    "label": 0
                },
                {
                    "sent": "Now if we take our exact likelihood, we multiply it by all those of the terms.",
                    "label": 0
                },
                {
                    "sent": "We get a posterior distribution, which is this P of X which I've written in blue.",
                    "label": 0
                },
                {
                    "sent": "That would be our exact posterior for this abstract problem.",
                    "label": 0
                },
                {
                    "sent": "Now if we take our approximate term which is this green curve and we multiply it again by Q, not I, I'll get another posterior which I've written in green there, right?",
                    "label": 0
                },
                {
                    "sent": "So this green at the bottom is the posterior I would get if I had used this green replacement of the top OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we see the problem here is that this green curve isn't a very good green curve because we know we're going to multiply by that Q, not I.",
                    "label": 0
                },
                {
                    "sent": "Why are we buying even bothering to represent the stuff on the left, right?",
                    "label": 0
                },
                {
                    "sent": "Why don't we just put a Gaussian to represent FI on the right side, which is where it counts, right?",
                    "label": 0
                },
                {
                    "sent": "So let's suppose we do that.",
                    "label": 0
                },
                {
                    "sent": "Suppose for example, we chose our green approximation to simply be the Gaussian on the right.",
                    "label": 0
                },
                {
                    "sent": "Alright, as our approximation, instead of trying to smile representing both.",
                    "label": 0
                },
                {
                    "sent": "So if we just pick the Gaussian on the right and now we multiply by the Q, not I, we in fact find that our approximation approximate cost here is very very close to the exact posterior because the Gaussian left didn't really matter anyway.",
                    "label": 0
                },
                {
                    "sent": "When you multiply by other other terms in the model.",
                    "label": 0
                },
                {
                    "sent": "And this is the basic intuition for why this moment matching technique works is because we're going to take our non Gaussian likelihoods and approximate them by Gaussians.",
                    "label": 0
                },
                {
                    "sent": "But in exactly the spot where we need to approximate them, and that's why we're going to get results.",
                    "label": 0
                },
                {
                    "sent": "OK, hopefully that's clear to everyone, yes.",
                    "label": 0
                },
                {
                    "sent": "Ah, that I will show you, but the idea is to look at the other terms so you look at the other factors that are in your model and they will give you a hint as to where the posterior is going to be.",
                    "label": 0
                },
                {
                    "sent": "And once you have an idea of where the posterior is going to be, you now know how you should approximate this particular likely term.",
                    "label": 0
                },
                {
                    "sent": "So essentially what will happen is the factors will talk to each other.",
                    "label": 0
                },
                {
                    "sent": "These factors will say OK, another posterior somewhere over here he says OK.",
                    "label": 0
                },
                {
                    "sent": "In that case I'll use this approximation.",
                    "label": 0
                },
                {
                    "sent": "He sends it back over them and then they change their approximation and so on.",
                    "label": 0
                },
                {
                    "sent": "And that's where the whole message passing structure comes from.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "One of the factors has got one big mode, like if all of the factors are bimodal, it you get in trouble.",
                    "label": 0
                },
                {
                    "sent": "Well, no, because they showed if you multiply, if you multiply enough bimodal factors together, you still get a single mode.",
                    "label": 0
                },
                {
                    "sent": "So here Q not I represents like every other factor.",
                    "label": 0
                },
                {
                    "sent": "This in the model.",
                    "label": 0
                },
                {
                    "sent": "So I'm assuming that all of them just add up to give a Gaussian, but you're right that if you if there aren't enough data points, you won't get your posterior won't be very Gaussian, and in which case this approximation won't be very good.",
                    "label": 0
                },
                {
                    "sent": "So essentially relies on you having a lot of significant amount of data.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Repeat the question OK.",
                    "label": 0
                },
                {
                    "sent": "The pictures to be non overlapping across the different.",
                    "label": 0
                },
                {
                    "sent": "So if they have a significant overlap then you will still get a bimodal.",
                    "label": 0
                },
                {
                    "sent": "What happens is when you actually sample data from the model I just gave you the oh I'm supposed to repeat the question.",
                    "label": 0
                },
                {
                    "sent": "OK, right?",
                    "label": 0
                },
                {
                    "sent": "Right, so the question was, let's see, the question was what if all the mixture components lineup somehow?",
                    "label": 0
                },
                {
                    "sent": "Won't you then still get it by model posterior?",
                    "label": 0
                },
                {
                    "sent": "And that's correct.",
                    "label": 0
                },
                {
                    "sent": "You would get that.",
                    "label": 0
                },
                {
                    "sent": "But if you actually sampling data from this model, you wouldn't get reported and line up in some magical way to give you a bimodal.",
                    "label": 0
                },
                {
                    "sent": "And I already showed that when I showed the exact posterior that it wasn't by model, so that shows you that you don't get that strange lining up effect.",
                    "label": 0
                },
                {
                    "sent": "If you only do two points, then you would get you would get a lining up affecting you would you would literally see that the four Gaussians that were in that posterior.",
                    "label": 0
                },
                {
                    "sent": "OK, should I move on?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Define instead of fitting into a single Gaussian fitting into the mixture of emotion and even include the performance of this method.",
                    "label": 0
                },
                {
                    "sent": "It would improve the performance and people have tried it.",
                    "label": 0
                },
                {
                    "sent": "The main problem with that is that it takes a long time.",
                    "label": 0
                },
                {
                    "sent": "It takes significantly longer than you would think to fit two rather than one.",
                    "label": 0
                },
                {
                    "sent": "It isn't just twice as much.",
                    "label": 0
                },
                {
                    "sent": "It's like 10 or 100 times slower to fit two.",
                    "label": 0
                },
                {
                    "sent": "That's the problem so.",
                    "label": 0
                },
                {
                    "sent": "But The thing is, if you could find a way of fitting two Gaussians which was only twice as expensive as fitting one, then you'd be in business, right?",
                    "label": 0
                },
                {
                    "sent": "So then you'd have best paper right there if you could find that, but no one is known as found such a method yet.",
                    "label": 0
                },
                {
                    "sent": "Ham other questions.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's what I'm going to do.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you how you can find that approximation, the good, the good green approximation features the likelihood terms.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm just going to 1st show it in a sort of abstract.",
                    "label": 0
                },
                {
                    "sent": "In an abstract sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so recall that.",
                    "label": 0
                },
                {
                    "sent": "Add this likelihood term, which is a function of X. OK, and I was just calling this FI affects the fact they're connected to X. OK, and we want to approximate that.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "Some Gaussian which I'm going to call FI tilled of X.",
                    "label": 0
                },
                {
                    "sent": "Which is going to be our approximation.",
                    "label": 0
                },
                {
                    "sent": "And if I have, X can have essentially any functional form, we're not going to restrict at all.",
                    "label": 0
                },
                {
                    "sent": "However FI till it has to be a Gaussian Onyx.",
                    "label": 0
                },
                {
                    "sent": "Now what we're going to use to make this approximation is we're going to use knowledge of the other factors that are in the model.",
                    "label": 0
                },
                {
                    "sent": "An on the previous slide I called those.",
                    "label": 0
                },
                {
                    "sent": "Q Not I have X so basically will have this will have this this Gaussian which is which I'm calling the context.",
                    "label": 0
                },
                {
                    "sent": "Is that is that hard to read?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So we'll have so cute.",
                    "label": 0
                },
                {
                    "sent": "I have X summarizes all of the other factors that are in the model.",
                    "label": 0
                },
                {
                    "sent": "OK, and that is a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So let me just write down all the constraints we have.",
                    "label": 0
                },
                {
                    "sent": "So FYI, is anything.",
                    "label": 0
                },
                {
                    "sent": "Cunot I.",
                    "label": 0
                },
                {
                    "sent": "Is definitely going to be aghasyan.",
                    "label": 0
                },
                {
                    "sent": "And I'll tell you how we ensure that later.",
                    "label": 0
                },
                {
                    "sent": "NFI tilt is going to be awesome.",
                    "label": 0
                },
                {
                    "sent": "OK. How should we find if I tailed well?",
                    "label": 0
                },
                {
                    "sent": "So if we take basically the property we want is that if I take the context which is this QIX.",
                    "label": 0
                },
                {
                    "sent": "And I multiply it by both that that output of that multiplication should be similar for the two.",
                    "label": 0
                },
                {
                    "sent": "Which is which is what I was arguing on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "It isn't that we want justify till to match F. We want the product with the other factors to match the product because that's what the process here is after all.",
                    "label": 0
                },
                {
                    "sent": "So essentially we want.",
                    "label": 0
                },
                {
                    "sent": "F of X.",
                    "label": 0
                },
                {
                    "sent": "Times cue not.",
                    "label": 0
                },
                {
                    "sent": "I have X to be somehow similar to FI till devex.",
                    "label": 0
                },
                {
                    "sent": "And Q not I have X.",
                    "label": 0
                },
                {
                    "sent": "Now at this point we could choose various measures of similarity, but since I'm doing moment matching, let's use that.",
                    "label": 0
                },
                {
                    "sent": "So we'll try and find one that same moments now to sort of reduce on the amount of notation I use, I'm going to introduce an operator here which is called deep rajappa rater.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What project does it takes in any distribution and it gives you back a Gaussian which is the same moment that as that distribution.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So these will have.",
                    "label": 0
                },
                {
                    "sent": "The same moments, and obviously if I give a Gaussian the project going to the same Gaussian back.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So question.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, I meant the mean invariants.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, Gaussian can only match the meaning variance.",
                    "label": 0
                },
                {
                    "sent": "Nothing more than that, so that's all I'm going to go for.",
                    "label": 0
                },
                {
                    "sent": "But if you had, if you had used, for example, a mixture of two Gaussians, you could have gone for more moments if you wanted to question.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "And then do this process for every factor, right?",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Let's table because we're doing important.",
                    "label": 0
                },
                {
                    "sent": "Also doing the same.",
                    "label": 0
                },
                {
                    "sent": "Proximation to the other factor so.",
                    "label": 0
                },
                {
                    "sent": "Have you hugging your soon to form a queue when?",
                    "label": 0
                },
                {
                    "sent": "Do not lie when you're doing it for the other part of Q about their constituents.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes yes.",
                    "label": 0
                },
                {
                    "sent": "So the question isn't Q not I of X different for every factor as I go through all the factors and answer is yes that's why I called it cannot I?",
                    "label": 0
                },
                {
                    "sent": "So it depends on I it's basically going to be, it's my overall approximate posterior with this fact.",
                    "label": 0
                },
                {
                    "sent": "One approximate factor removed from it.",
                    "label": 0
                },
                {
                    "sent": "So essentially the notation I use.",
                    "label": 0
                },
                {
                    "sent": "I use Q of X for the approximate posterior.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to find for the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to find and use Q not I for that with one factor removed from it.",
                    "label": 0
                },
                {
                    "sent": "And so yes, as you visit each factor, FI is going to be different in Q not I will be different because it'll have something different missing from it.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you don't get no others affected buildings left you OK.",
                    "label": 0
                },
                {
                    "sent": "So Q not I is going to be the approximate version of all of those factors.",
                    "label": 0
                },
                {
                    "sent": "That's what's going to happen.",
                    "label": 0
                },
                {
                    "sent": "That's right, so basically we have a chicken and egg problem.",
                    "label": 0
                },
                {
                    "sent": "We have to approximate the factors in order to find approximations of the factors and the way we're going to solve that is by solving by just setting it up as a fixed point system.",
                    "label": 0
                },
                {
                    "sent": "So we're going to initialize the approximations and just iterate until convergence.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "Alright, so as I said, I want to find a distribution with the same moment and So what I'm going to do is I'm going to write the following.",
                    "label": 0
                },
                {
                    "sent": "Going to see that the project FIX.",
                    "label": 0
                },
                {
                    "sent": "Times Q9IX is equal to.",
                    "label": 0
                },
                {
                    "sent": "FI till the XQIX.",
                    "label": 0
                },
                {
                    "sent": "So it's not making a precise statement saying that the Gaussian on the right has the same meaning variance as the distribution on the left.",
                    "label": 0
                },
                {
                    "sent": "And the free.",
                    "label": 0
                },
                {
                    "sent": "The free variable here is just FITLQ not I you can't change that's going to be given to you and you have to find FI told.",
                    "label": 0
                },
                {
                    "sent": "And so, in order to do that, all you have to do is solve this equation.",
                    "label": 0
                },
                {
                    "sent": "So how do we solve this equation?",
                    "label": 0
                },
                {
                    "sent": "Well, that's pretty easy.",
                    "label": 0
                },
                {
                    "sent": "If I tilt of X.",
                    "label": 0
                },
                {
                    "sent": "Must then be equal to prauge.",
                    "label": 0
                },
                {
                    "sent": "Of if I ask you, not IX.",
                    "label": 0
                },
                {
                    "sent": "Divided by not I ask.",
                    "label": 0
                },
                {
                    "sent": "And does this have member that has to be a Gaussian?",
                    "label": 0
                },
                {
                    "sent": "Is it a Gaussian?",
                    "label": 0
                },
                {
                    "sent": "Well, it is because project is Mia Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And if I take the ratio of that with another Gaussian, I have something which is also Gaussian because of the exponential family property.",
                    "label": 0
                },
                {
                    "sent": "So if I tilt axes indeed of the right form, and this is actually is the optimal fitil X for matching moments.",
                    "label": 0
                },
                {
                    "sent": "This is the unique file which gives you the same moments.",
                    "label": 0
                },
                {
                    "sent": "Everyone follow that.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially that's the key equation.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This equation you need now, you just wrap that up into an iterative scheme.",
                    "label": 0
                },
                {
                    "sent": "Here I'm just trying to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to to avoid doing anymore anymore algebra with Gaussians, I'm just going to tell you that if I multiply 2 Gaussians, there's a simple formula which gives you a new Gaussian.",
                    "label": 0
                },
                {
                    "sent": "You can easily compute the mean and variance of the new Galaxy, and if I take it, the product of two and Gaussian densities, and similarly if I have the ratio of two Gaussian densities as I had in the last slide, there is a simple formula which will give you the median variance of the new Gaussian density.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can type that into your favorite object oriented package and then you can just call that times and divide of Gaussians and use that as your use it as your division and multiplication operator from now on.",
                    "label": 0
                },
                {
                    "sent": "So I won't have to talk about Gaussians anymore, I'll just say divide these Gaussians or multiply these Gaussians.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "That's right, so I'm allowing my Gaussians to have negative variances in this case.",
                    "label": 0
                },
                {
                    "sent": "So essentially my factors don't have to be normalized Gaussian, so I'm just going to make the normalizer.",
                    "label": 0
                },
                {
                    "sent": "It's just a scale factor anyway.",
                    "label": 0
                },
                {
                    "sent": "On the whole posterior, so I'm just going to use a normalized Gaussians as my approximations, multiply them altogether to get my Gaussian posterior, normalize at the end, in which case it will be.",
                    "label": 0
                },
                {
                    "sent": "It will be proper so.",
                    "label": 0
                },
                {
                    "sent": "Guarantee that you are.",
                    "label": 0
                },
                {
                    "sent": "So here's the thing.",
                    "label": 0
                },
                {
                    "sent": "So when I computed FI tilled I got it from the prauge of something.",
                    "label": 0
                },
                {
                    "sent": "OK, and so I know that when I multiply back do not INF.",
                    "label": 0
                },
                {
                    "sent": "I tilled, it's going to be an actual proper Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Is there another no.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I want to give you some intuition of how these approximations look.",
                    "label": 0
                },
                {
                    "sent": "How that formula behaves that product divided by Q not I formula.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do is I'm going to show you the actual factor in this in the actual clutter problem and how it gets approximated as I changed the context.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This blue curve is what the actual likelihood looks like.",
                    "label": 0
                },
                {
                    "sent": "So if I fix iy in this case, I think why I was two or something like that and I'm plotting.",
                    "label": 0
                },
                {
                    "sent": "What is it likely for X?",
                    "label": 0
                },
                {
                    "sent": "And essentially, so intuitively, what the likelihood for accessing is that.",
                    "label": 0
                },
                {
                    "sent": "You should be near the observation, but it's OK if you're very far from the observation, because the observation could have been the background noise, right?",
                    "label": 0
                },
                {
                    "sent": "So you get this likelihood, which is a Gaussian, but then has this flat thing.",
                    "label": 0
                },
                {
                    "sent": "So zero is here, so this is so the likelihood is raised above 0.",
                    "label": 0
                },
                {
                    "sent": "It never never eliminates any particular value of X, it just says that values near this are better than others, but otherwise you can be far away if you like.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we want to approximate that blue curve with a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So let's start with the example on the right actually, so my context, which is the Q not I function is this green curve.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose that we know that all of the other likelihood terms in the problem give me this very, very narrow Gaussian right on that spot, and I know that whatever approximation I'm going to make this blue likelihood I'm going to multiply it by that green curve, right?",
                    "label": 0
                },
                {
                    "sent": "So, in that case, I know that I really only need to be accurate, right on the right on that spot, right?",
                    "label": 0
                },
                {
                    "sent": "In that one particular place in the likelihood.",
                    "label": 0
                },
                {
                    "sent": "And in fact, if we use that formula, given the previous slide, we get this red Gaussian as our solution, which does exactly what you expect.",
                    "label": 0
                },
                {
                    "sent": "It matches the likely right at that spot, yeah?",
                    "label": 0
                },
                {
                    "sent": "So yeah, so the question is why did it move what I'm doing here is I'm showing the same.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show the same blue curve on all these slides from going to move the green curve around and that's all that I'm going to change.",
                    "label": 0
                },
                {
                    "sent": "Is the green curve and I'm just showing the resulting red curve, so the red curve is deterministic function of the green curve and the blue curve.",
                    "label": 0
                },
                {
                    "sent": "I'm just showing.",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "What is the approximation you get out for different combinations of factor and context?",
                    "label": 0
                },
                {
                    "sent": "Basically, the property that you want to have happened is that is that the context tells you where you need to be accurate, and so the red curve should always be good in the neighborhood of the context.",
                    "label": 0
                },
                {
                    "sent": "So just showing you intuitively that it has the behavior we want.",
                    "label": 0
                },
                {
                    "sent": "So on the right hand case it matches the curve exactly where we want to match and what it does.",
                    "label": 0
                },
                {
                    "sent": "Other than that, I'm sure it's about approximation away from the context, but doesn't really matter 'cause we're going to multiply by the context anyway.",
                    "label": 0
                },
                {
                    "sent": "OK. Now here's an interesting case.",
                    "label": 0
                },
                {
                    "sent": "So if the context is right here.",
                    "label": 0
                },
                {
                    "sent": "Then we have to approximate this convex curving up part of the likelihood function and the only way to do that is to use a Gaussian with a negative variance and this is what a Gaussian with a negative variance looks like.",
                    "label": 0
                },
                {
                    "sent": "If you ever wonder.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, these are very useful actually for modeling certain likelihood.",
                    "label": 0
                },
                {
                    "sent": "So if you ever have a likelihood with a with a concave up part, you want to use a Gaussian with negative variance to model it.",
                    "label": 0
                },
                {
                    "sent": "And that's what happens here.",
                    "label": 0
                },
                {
                    "sent": "So we get we get a very nice approximation of that likelihood.",
                    "label": 0
                },
                {
                    "sent": "In this in this region.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if we make the context wider so before it was very very narrow, so we just had the Model 1 little tiny part of the likely.",
                    "label": 0
                },
                {
                    "sent": "If the context is a bit wider, meaning we don't have as much data around, then what you find is that it's sort of it's sort of takes a more more averaged approximation, so it isn't sort of locally specific anymore.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "We still get a negative variance, but it sort of tries to be good in a bigger area and similarly on the right.",
                    "label": 0
                },
                {
                    "sent": "And if we make the context.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very very wide.",
                    "label": 0
                },
                {
                    "sent": "Then we end up with just sort of a one global overall Gaussian approximation, which is what you would have expected from the beginning, right?",
                    "label": 0
                },
                {
                    "sent": "So if I didn't but in tell you anything about what I was going to play with the best you can do is just to make one big moment matched approximation.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So we could we make a good, very good approximation and where exactly we made a good approximation 'cause on the previous examples some context give good approximations in some areas.",
                    "label": 0
                },
                {
                    "sent": "Other areas, right?",
                    "label": 0
                },
                {
                    "sent": "Well the.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is how can we understand the error that we're making in the approximations so you could locally measure the error that you've made.",
                    "label": 0
                },
                {
                    "sent": "So after you've done after you've made found the red curve, you could just measure the error to the blue curve.",
                    "label": 0
                },
                {
                    "sent": "And you could.",
                    "label": 0
                },
                {
                    "sent": "You could measure.",
                    "label": 0
                },
                {
                    "sent": "That way you can add up those approximations, and some people have done that as a way of estimating the error of a VP.",
                    "label": 0
                },
                {
                    "sent": "I'm not certainly one thing to do.",
                    "label": 0
                },
                {
                    "sent": "But I think what really happens is you run EP is that you start out with all of your approximations being very flat and very broad, and so you end up in this case.",
                    "label": 0
                },
                {
                    "sent": "So everyone just make sort of a broad averaged approximation, but then as the as the algorithm iterates you get more and more information flowing in from all these other factors and you end up getting narrow or an error or context and you get more and more specific approximations.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "This negative Goshen store isn't just computationally free, it's just the computational tracking.",
                    "label": 0
                },
                {
                    "sent": "I mean, well, OK, there's a public interpretation.",
                    "label": 0
                },
                {
                    "sent": "They probably interpretation is that if this blue curve was your prior and this sorry if the green curve was your prior on X and the blue curve was your likelihood.",
                    "label": 0
                },
                {
                    "sent": "Then your posterior distribution would have a bigger variance than your prior did.",
                    "label": 0
                },
                {
                    "sent": "And that's essentially what this red curve is saying.",
                    "label": 0
                },
                {
                    "sent": "So saying you need to.",
                    "label": 0
                },
                {
                    "sent": "You actually need to reduce the variance of your prior in the posterior.",
                    "label": 0
                },
                {
                    "sent": "So you can interpret this approximation these Gaussian approximations as being especially what would be the equivalent Gaussian observation as the likelihood, as you're likely right, would be would be the equivalent Gaussian up thing that I could observe and what this is saying is that the closest equivalent in a Gaussian observation would be one with negative variance, meaning one that actually makes you more uncertain after you observed it, rather than one that makes you more certain.",
                    "label": 0
                },
                {
                    "sent": "And that certainly does happen in some cases.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you if you iterate this.",
                    "label": 0
                },
                {
                    "sent": "Are you able to guarantee that all the all the approximated terms have positive variance?",
                    "label": 0
                },
                {
                    "sent": "No, no isn't it more reasonable that than to exclude that measurement from the system so that your answer typically doesn't think that measurement already doesn't give any information, but increasing your uncertainity more?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the question is, should we just?",
                    "label": 0
                },
                {
                    "sent": "Should we run the algorithm to conversions and then throw out all of the messages that had negative variances?",
                    "label": 0
                },
                {
                    "sent": "And the answer is, I would say no, because you want your posterior.",
                    "label": 0
                },
                {
                    "sent": "Correct amount of uncertainty in it, and if one of your data points says that you should increase the amount of uncertainty, then you should do that you don't.",
                    "label": 0
                },
                {
                    "sent": "You should just ignore it because that's what it says to do.",
                    "label": 0
                },
                {
                    "sent": "In particular this approximation.",
                    "label": 0
                },
                {
                    "sent": "The reason that it has negative variances because you're likely does have that shape in that region, and so just by just by throwing out this.",
                    "label": 0
                },
                {
                    "sent": "Likely because there's a shape you don't like that doesn't seem right, right?",
                    "label": 0
                },
                {
                    "sent": "That's not that's not the Bayesian correct thing to do.",
                    "label": 0
                },
                {
                    "sent": "You should multiply all the liquids no matter what shape they have, even if they're unfriendly.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there we go.",
                    "label": 0
                },
                {
                    "sent": "So now all we need to do is we need to put this formula together into an iterative scheme.",
                    "label": 0
                },
                {
                    "sent": "So I've given you this formula where I take the project and I divide and now we're just going to make a message passing scheme out of it.",
                    "label": 1
                },
                {
                    "sent": "So we're going to start with a case where there's only two factors in the model, so I just have a variable X. I'm trying to estimate and it's just going to factors F1 and F2.",
                    "label": 0
                },
                {
                    "sent": "And I want to Gaussian approximations of the posterior on X.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do is I'm going to approximate each of these factors by Gaussian terms and after I found these two edges, multiply them together and that's my Gaussian posterior on X.",
                    "label": 0
                },
                {
                    "sent": "And the way I'm going to find each of these approximations is I'm going to 1st initialize with some approximations and then I'll take one factor of the context for the other factor, because I know that after I approximate factor one, I'm going to multiply it by factor 2, and similarly for you, I'm going to take that approximated multiplied by factor one.",
                    "label": 0
                },
                {
                    "sent": "So therefore when I approximate each factor, I'll take the other factor into consideration, and So what we end up getting is this formula here, which says that if I want to approximate factor 1, first of all I take the approximation that I already made for Factor 2.",
                    "label": 0
                },
                {
                    "sent": "Which I know that I'm going to multiply by in the end.",
                    "label": 0
                },
                {
                    "sent": "I multiply it by the exact factor one.",
                    "label": 0
                },
                {
                    "sent": "I do a project divide right?",
                    "label": 0
                },
                {
                    "sent": "So this is saying that I'm going to choose F1 tilt.",
                    "label": 0
                },
                {
                    "sent": "So that when I multiplied by FT which I already have in hand.",
                    "label": 0
                },
                {
                    "sent": "But that's going to have the same moments as if I had taken F1 and multiplied by F tilt.",
                    "label": 0
                },
                {
                    "sent": "Right, so if I finalize on my FT tilled, this is definitely the right F1 tail to choose, right?",
                    "label": 0
                },
                {
                    "sent": "But now I can do it from the direction if I finalized on my choice of F1, tilt the best F2 tilt is obviously the one given by this formula, 'cause that's the one that will have the same moments.",
                    "label": 0
                },
                {
                    "sent": "And now we just go back and forth basically.",
                    "label": 0
                },
                {
                    "sent": "Until they would have won F1.",
                    "label": 0
                },
                {
                    "sent": "So, so I'm assuming that F1 and F2 are non Gaussian factors.",
                    "label": 0
                },
                {
                    "sent": "So if I multiply them together I get a non Gaussian distribution which I don't want.",
                    "label": 0
                },
                {
                    "sent": "OK, so in order to force X to have a Gaussian posterior, I'm going to approximate each of the factors connected with customers.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and the and the green is the cue, not I.",
                    "label": 0
                },
                {
                    "sent": "So does this procedure make sense?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Now here's the thing.",
                    "label": 0
                },
                {
                    "sent": "What I've done is I've I've ensured that F1 till times F2 tailed is the project F 1 * F Two Hill and on the bottom I've ensured that F1, tilt times F2 tilt.",
                    "label": 0
                },
                {
                    "sent": "Is the project F2 tilt F1 tilt?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if I run this to convergence, what I'll know is that these two things are equal.",
                    "label": 0
                },
                {
                    "sent": "OK, but that doesn't mean that I've necessarily found the prauge.",
                    "label": 0
                },
                {
                    "sent": "Of what I really wanted, which was F1F2.",
                    "label": 0
                },
                {
                    "sent": "So that's what I really wanted, which is the arguments of the actual posterior.",
                    "label": 0
                },
                {
                    "sent": "So this is not necessarily the same as this.",
                    "label": 0
                },
                {
                    "sent": "And the reason for that is because I had to.",
                    "label": 0
                },
                {
                    "sent": "I had to use a context which was Gaussian.",
                    "label": 0
                },
                {
                    "sent": "I couldn't use the exact F2 as my context for fitting F1, because that would be intractable.",
                    "label": 0
                },
                {
                    "sent": "I mean, it doesn't scale if you do that, so I had to add user Gaussian context when approximating F1.",
                    "label": 0
                },
                {
                    "sent": "Hence there's the approximation.",
                    "label": 0
                },
                {
                    "sent": "That's why I can't get the exact moments, so there's sort of sort of two approximations going on.",
                    "label": 0
                },
                {
                    "sent": "One is that.",
                    "label": 0
                },
                {
                    "sent": "I'm approximating the posterior with Gaussians.",
                    "label": 0
                },
                {
                    "sent": "That's one approximation, and Secondly I'm not getting the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "That is exactly the same moments as the real cost here, but it will be very close, as you'll see.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Hopefully you can now see how this would generalize the three factors.",
                    "label": 1
                },
                {
                    "sent": "So suppose I have X connected to three factors, all non Gaussian, and I want to make them all Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So how should I update for example F1?",
                    "label": 0
                },
                {
                    "sent": "What should F1 till B?",
                    "label": 0
                },
                {
                    "sent": "In my updating scheme.",
                    "label": 0
                },
                {
                    "sent": "Anyone like to venture a guess?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "F2 tilt.",
                    "label": 0
                },
                {
                    "sent": "And F3 tilt.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Exactly, and why can I do that?",
                    "label": 0
                },
                {
                    "sent": "The reason is that F2 till then at three till they both Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So the product of Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So again have a Gaussian context.",
                    "label": 0
                },
                {
                    "sent": "So I can I can put together all of my approximate factors into a single Gaussian and just use that as my context so I don't have to know how many factors access connected to what.",
                    "label": 0
                },
                {
                    "sent": "I'm approximately one I can just take all of them, multiply them altogether, Singleton, and just pretend as if I'm connected.",
                    "label": 0
                },
                {
                    "sent": "Only one other factor essentially.",
                    "label": 0
                },
                {
                    "sent": "And if I want to update F2 tilt, well just by symmetry.",
                    "label": 0
                },
                {
                    "sent": "I just take the exact F2, multiply it by F1 and F3 is approximation.",
                    "label": 0
                },
                {
                    "sent": "And divide by F1 of three.",
                    "label": 0
                },
                {
                    "sent": "OK, so does everyone get the general pattern at this point?",
                    "label": 0
                },
                {
                    "sent": "So essentially I have a bunch of coupled equations and and Interestingly enough what ends up working to solve this coupled equations is simply to iterate them to a fixed point.",
                    "label": 0
                },
                {
                    "sent": "It often works, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "This actually doesn't probably reach a fixed point, but it often reaches a fixed point very fast, and if you actually look at these equations in detail and compare them to, say, loopy belief propagation, it turns out it's doing essentially the same as loopy belief propagation, so it has the same sort of issues as the same sort of speed, but also lack of convergence proof as loopy belief propagation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "So what's the big picture?",
                    "label": 0
                },
                {
                    "sent": "So coming back to the big picture here, one way you can interpret one message passing is is essentially, it's a distributed optimization.",
                    "label": 1
                },
                {
                    "sent": "I'm trying to.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to solve for the best approximation zephy tilts and I'm doing it in this very distributed way, where where, where I choose MFA till to send them to send them over to a factor.",
                    "label": 0
                },
                {
                    "sent": "That factor decides how it should approximate itself and then sends its approximation to the other ones and so on.",
                    "label": 0
                },
                {
                    "sent": "Is that a question?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK. Variables that mean you are doing something you're looking for, some pizza port in a 2 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so each of these approximations has two free variables, which are the mean and variance of that approximate factor.",
                    "label": 0
                },
                {
                    "sent": "So in fact there's going to be 6 variables of this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Essentially an I'll iterate to a fixed point of all six of those numbers.",
                    "label": 0
                },
                {
                    "sent": "Is that is that?",
                    "label": 0
                },
                {
                    "sent": "It's not complicated because all I have to do is initialize these approximations to some save values.",
                    "label": 0
                },
                {
                    "sent": "So for example, uniform is what I usually use, so you just set all of these F tilts to uniform distributions and just iterate these equations in orders.",
                    "label": 0
                },
                {
                    "sent": "You have three equations, you just run those updates in order over and over and over again, and then that's how you reach your fixed point.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, so so right.",
                    "label": 1
                },
                {
                    "sent": "So back to the message passing interpretation.",
                    "label": 0
                },
                {
                    "sent": "How can we interpret this message passing so?",
                    "label": 0
                },
                {
                    "sent": "We have our exact distribution P. Which is a product of factors on X and we want to find an approximate distribution Q.",
                    "label": 0
                },
                {
                    "sent": "Which is a product of approximate factors on X.",
                    "label": 0
                },
                {
                    "sent": "And we're now trying to solve an optimization problem trying to find the best FI tools that we can.",
                    "label": 0
                },
                {
                    "sent": "And we're going to solve this in a distributed way.",
                    "label": 0
                },
                {
                    "sent": "So basically we're going to choose values for all the FIS.",
                    "label": 0
                },
                {
                    "sent": "And essentially, we're going to send the FIS.",
                    "label": 0
                },
                {
                    "sent": "We've already got to approximate the ones to re approximate the ones we have.",
                    "label": 0
                },
                {
                    "sent": "And essentially, you can think of what message passing is is just a way of choosing the parameters of Q to FTB.",
                    "label": 0
                },
                {
                    "sent": "That's essentially what it is.",
                    "label": 0
                },
                {
                    "sent": "Now when running any sort of message passing algorithm, there's essentially two types.",
                    "label": 0
                },
                {
                    "sent": "Two choices you need to make.",
                    "label": 0
                },
                {
                    "sent": "One is what type of distribution do you want to have at the end.",
                    "label": 1
                },
                {
                    "sent": "So in this case I chose a Gaussian distribution because that seem relevant for estimating X.",
                    "label": 0
                },
                {
                    "sent": "You could choose another approximating family as well, so in particular expectation propagation will work for any distributions which are closed under multiplication, because that's really the only property I needed that I could divide and multiply distributions and stay within the same family, so anything that's closed under multiplication is fine, so that includes beta distributions.",
                    "label": 0
                },
                {
                    "sent": "Gamma distributions, the visualizing so on essentially any of the standard members of exponential family, would work.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The next choice you have to make is what sort of cost function do you want to minimize, and next time I'll go into more detail of what sort of what different cost functions you could use today.",
                    "label": 0
                },
                {
                    "sent": "I'm only going to talk about one cost function, which is the moment matching cost function.",
                    "label": 0
                },
                {
                    "sent": "But it should be clear that I could.",
                    "label": 0
                },
                {
                    "sent": "I could replace my moment matching procedure with anything else and I get a similar message passing type procedure, right?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Right, so here this is just repeating that stuff again.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And I will skip this bit.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this bit.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "What happens if we actually take the procedure I just gave you, which is called expectation propagation, and we run that run all those fixed point equations to convergence on the actual clutter problem with 20 actual data points.",
                    "label": 0
                },
                {
                    "sent": "So again, blue is that exact posterior.",
                    "label": 0
                },
                {
                    "sent": "I showed you before.",
                    "label": 0
                },
                {
                    "sent": "Purple is the best possible Gaussian, which is the one that is exact same moments as the blue curve, and then green is the one that you actually find by this iterative scheme by EP.",
                    "label": 0
                },
                {
                    "sent": "And we'll see that we see that it doesn't exactly have the same moments as the purple curve because of the because of those that second approximation that we made.",
                    "label": 0
                },
                {
                    "sent": "But it's a pretty good fit.",
                    "label": 0
                },
                {
                    "sent": "And if we compare it to other algorithms that are available for fitting Gaussians, will see that it's actually quite good at this problem.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in particular I ran variational bounds.",
                    "label": 0
                },
                {
                    "sent": "I ran the plus method on the exact same problem, and next time I'll explain how you how you would run these two on this problem, But essentially these are the two Gaussians you get.",
                    "label": 0
                },
                {
                    "sent": "You probably can't see the plus one very well, so that's this.",
                    "label": 0
                },
                {
                    "sent": "Very light blue Gaussian here and the very strong balance is there red Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here, here's the comparison of the moments that you get out of those three methods.",
                    "label": 0
                },
                {
                    "sent": "So exact posterior mean was 1.64 in this problem, EP is actually quite close again.",
                    "label": 1
                },
                {
                    "sent": "1.64 Plus in VB.",
                    "label": 0
                },
                {
                    "sent": "Posterior means slightly off, so the Gaussian is a bit shifted, but even more importantly, the variance is much better approximated by EP.",
                    "label": 0
                },
                {
                    "sent": "And in particular, the variational bound approach as a much smaller variance than the real posterior.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "So all three approx.",
                    "label": 0
                },
                {
                    "sent": "All three methods give you a Gaussian approximation.",
                    "label": 0
                },
                {
                    "sent": "That's just three different ways of doing it question.",
                    "label": 0
                },
                {
                    "sent": "Does the fix?",
                    "label": 0
                },
                {
                    "sent": "It it would in a multimodal problem.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't in this case, because this is a very clearly unimodal problem and this is 1 strong mode of the posterior.",
                    "label": 0
                },
                {
                    "sent": "So you're always going to converse with that.",
                    "label": 0
                },
                {
                    "sent": "But just just as in loopy belief propagation, if you have a multimodal posterior, you will be sensitive to initial conditions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Factors to be normalized?",
                    "label": 0
                },
                {
                    "sent": "Or can you deal?",
                    "label": 0
                },
                {
                    "sent": "How do you deal with her?",
                    "label": 0
                },
                {
                    "sent": "Then you have a missing normalization constant.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question was do you have to normalize all the factors and the answer is no.",
                    "label": 0
                },
                {
                    "sent": "So in fact I wasn't assuming normalization in any of this.",
                    "label": 0
                },
                {
                    "sent": "I was only assuming that FI times Q not.",
                    "label": 0
                },
                {
                    "sent": "I was normalizable, I never had to assume that FI was normalizable, nor did I have to assume that F~ was normalizable.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So if you look at all of my equations, I never have to never compute the moments of just FYI or FYI, tilled by itself.",
                    "label": 0
                },
                {
                    "sent": "I always compute products of things.",
                    "label": 0
                },
                {
                    "sent": "Which by construction will be will be normalized.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So of course I'm going to show you probably works well, right?",
                    "label": 0
                },
                {
                    "sent": "Here's a more detailed comparison where I'm showing the computation time versus the error of different approximation methods for the clutter problem here, what I've done is I've drawn 20 points from the model and here I drew on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "I drew 200 points from the model.",
                    "label": 0
                },
                {
                    "sent": "And the real mean was too.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The way you read these curves is each iteration of EP gives you an estimate, so I can always stop EP after, say one iteration or two iterations and get an estimate, and so the Blue EP curve there is showing what you get it after every after every iteration.",
                    "label": 0
                },
                {
                    "sent": "And similarly we get a curve out of the process method in variational Bayes, because again you can stop them early and get an answer.",
                    "label": 0
                },
                {
                    "sent": "I'm also showing the results from important sampling and Gibbs sampling again, where after every sample you look at what is the quality of the answer.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "The left curve I'm showing how well you estimate the posterior mean, as you saw before, the peak is a much better result, and Interestingly enough it also gets it very fast, so it gets it incomparable amount of time as computing Laplace method or variational bounds.",
                    "label": 0
                },
                {
                    "sent": "So on the third iteration it gets, it gets closer to the posterior mean, but then corrects itself and moves back away from the posterior mean.",
                    "label": 0
                },
                {
                    "sent": "Right, so that that can certainly happen, right?",
                    "label": 0
                },
                {
                    "sent": "It's just just an iterative fixed point algorithm.",
                    "label": 0
                },
                {
                    "sent": "Similarly, gives sometimes gets closer to the posterior mean and moves away, right?",
                    "label": 0
                },
                {
                    "sent": "Because you're taking samples and averaging them.",
                    "label": 0
                },
                {
                    "sent": "So I haven't.",
                    "label": 0
                },
                {
                    "sent": "I haven't averaged the results over many problems, which is so usually you see averages over many many problems and so you see these nice smooth curves.",
                    "label": 0
                },
                {
                    "sent": "Here I'm showing it for one particular instance.",
                    "label": 0
                },
                {
                    "sent": "You see all the noise that's inherent in it.",
                    "label": 0
                },
                {
                    "sent": "Again, yeah, so right.",
                    "label": 0
                },
                {
                    "sent": "That's just the dynamics of the of the procedure.",
                    "label": 0
                },
                {
                    "sent": "It goes towards towards the correct answer and then maybe overshoots it right.",
                    "label": 0
                },
                {
                    "sent": "And so you get this.",
                    "label": 0
                },
                {
                    "sent": "You'll get this dip behavior.",
                    "label": 0
                },
                {
                    "sent": "OK, so yeah, So what I'm comparing to here is the exact posterior mean, not not the target value that the algorithm is trying to get right, which is which will be different in each of the algorithms cases.",
                    "label": 0
                },
                {
                    "sent": "Right, so interesting thing to notice on this plot is that as I go from 20 points, 200 points, the deterministic methods Laplacian EP suddenly get very good.",
                    "label": 1
                },
                {
                    "sent": "I mean, they're actually accuracy gets very high like the right, so the vertical scale is the same.",
                    "label": 0
                },
                {
                    "sent": "So these methods have suddenly become super accurate, so EP is not in the minus six, whereas the sampling methods are essentially the same error as he did in a 20 point case.",
                    "label": 1
                },
                {
                    "sent": "And the reason for that is that when you have more data, the posture becomes more and more Gaussian, so your assumption makes.",
                    "label": 0
                },
                {
                    "sent": "More and more sense, and so all of these deterministic methods get better, and that's sort of a nice property of all the deterministic inference methods which the sampling methods don't have.",
                    "label": 1
                },
                {
                    "sent": "So if you think about it, the sampling methods generally don't benefit from the fact that your posterior is is especially Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Benefit from there being one mode rather than two, but if you have one mode which is becoming more and more Gaussian, your sampling method isn't going to suddenly become better.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The hidden variable parameter yes pending here is one dimension.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah, so can you give us an intuition for how things would work in higher dimensions?",
                    "label": 0
                },
                {
                    "sent": "Well, that Gaussian property would be the same even in even higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "So I mean empirically.",
                    "label": 0
                },
                {
                    "sent": "Like you know, sampling methods versus deterministic algorithms in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "Do you have a?",
                    "label": 0
                },
                {
                    "sent": "The sense for whether qualitatively forget very different results than this, Oh well, the first of all, these results are not really based on the dimension of the problem, so you get results like this even if you make.",
                    "label": 0
                },
                {
                    "sent": "Even if you make the clutter problem high dimensional.",
                    "label": 0
                },
                {
                    "sent": "So I have a version of the clutter problem, which is where you have a K dimensional Gaussian which is observed with noise and so on.",
                    "label": 0
                },
                {
                    "sent": "And you can run all these algorithms on it and you basically exact same curves out when you're on the K dimensional version.",
                    "label": 0
                },
                {
                    "sent": "Really, the difference in performance comes down to the shape of the posterior.",
                    "label": 0
                },
                {
                    "sent": "That's really what it comes down to.",
                    "label": 0
                },
                {
                    "sent": "So if you have a multivariate Gaussian posterior, then the deterministic albums are going to work very well compared to sampling ones.",
                    "label": 0
                },
                {
                    "sent": "That's that's really what it comes down to.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "I'm wondering it feels like there's sort of a kind of deep connection with PM here, right where you sort of instead of keeping the maximum likelihood, you're just keeping the whole distribution right.",
                    "label": 0
                },
                {
                    "sent": "Yes, and in fact the variational bounds have even more of that flavor.",
                    "label": 0
                },
                {
                    "sent": "But yes, it definitely is that flavor.",
                    "label": 0
                },
                {
                    "sent": "Propagation, why did I name it expectation propagation?",
                    "label": 0
                },
                {
                    "sent": "Well, because it extends belief propagation.",
                    "label": 0
                },
                {
                    "sent": "That was essentially the reason, so belief propagation passes the entire distribution as a message rise.",
                    "label": 0
                },
                {
                    "sent": "Expectation propagation will only pass moments of the distribution.",
                    "label": 0
                },
                {
                    "sent": "Certain expectations of the distribution that allows you to have very compact messages.",
                    "label": 0
                },
                {
                    "sent": "Yep, theoretical guarantee about performance or the accuracy of this network.",
                    "label": 0
                },
                {
                    "sent": "There is hardly any.",
                    "label": 0
                },
                {
                    "sent": "I mean there's some for belief propagation, which would be a special case, but fully general case of all expectation propagation algorithms, there's hardly any results on.",
                    "label": 0
                },
                {
                    "sent": "So what I did was I took the exact mean of the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So the mean of the green curve at the blue curve, and then I used the mean of the Gaussian that came out, and I measured the absolute difference and the same for the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's the mean in both cases.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So even if you would use a Gaussian approximation or just area, yeah I could have zero errors in this.",
                    "label": 0
                },
                {
                    "sent": "Correct, yeah, that's right.",
                    "label": 0
                },
                {
                    "sent": "So yeah, OK, so OK, right?",
                    "label": 0
                },
                {
                    "sent": "So this so you're saying this metric is somehow cheating because it's measuring something that a Gaussian could capture.",
                    "label": 0
                },
                {
                    "sent": "Yes, agreed.",
                    "label": 0
                },
                {
                    "sent": "Error coming from because you said there's two type of approximation.",
                    "label": 0
                },
                {
                    "sent": "One is because of using Dustin and the other one is because you don't actually do moment matching.",
                    "label": 0
                },
                {
                    "sent": "Yeah, exactly that's right.",
                    "label": 0
                },
                {
                    "sent": "So here, if you're measuring the error due to local, that's correct, yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean, well, there are cases where the posterior mean is actually the answers of the problem.",
                    "label": 0
                },
                {
                    "sent": "So for example, if I wanted to predict for a test point, where would it appear?",
                    "label": 0
                },
                {
                    "sent": "What is the expected location of a new point then the posterior mean of X would be the answer to that question.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so earlier this morning in Chris is talk, someone asked about censoring, so I thought, why don't we censoring right?",
                    "label": 0
                },
                {
                    "sent": "Is that person here by any chance, yes.",
                    "label": 0
                },
                {
                    "sent": "So so we can write down a censoring problem which is very similar to the collector problem.",
                    "label": 0
                },
                {
                    "sent": "So here I've written down a simple centering problem where I have an ex that I want to meet from Y.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "X Again has this Gaussian prior and I have a bunch of wise.",
                    "label": 0
                },
                {
                    "sent": "We turn just Gaussian observations whose mean is X, but some of the wiser censored and the censoring process that I picked is 1 where you just know that the magnitude of why is bigger than some threshold, so you know that why is magnitude 10 or more, for example, that would be a censoring process, so my my whatever device I'm using can't measure beyond some threshold and it just says oh bigger than threshold, that's it.",
                    "label": 0
                },
                {
                    "sent": "Now for that sort of censoring problem, we can solve that using EP as well.",
                    "label": 0
                },
                {
                    "sent": "What's the first thing we do when you want to solve the problem right on the factor graph, right so?",
                    "label": 0
                },
                {
                    "sent": "The factor graph for this problem will be.",
                    "label": 0
                },
                {
                    "sent": "Mother Bunch of wise and suppose we have a special censored Y.",
                    "label": 0
                },
                {
                    "sent": "Which alright as.",
                    "label": 0
                },
                {
                    "sent": "Why for greater than T?",
                    "label": 0
                },
                {
                    "sent": "So this special censored observation.",
                    "label": 0
                },
                {
                    "sent": "OK, so these factors will be ordinary Gaussian factors connected to X. OK, and for the censored observation, I'll have this special factor whose formula I've written here.",
                    "label": 0
                },
                {
                    "sent": "So this factor says this is just the probability of observing AY which is between minus Infinity, right here.",
                    "label": 0
                },
                {
                    "sent": "Probability of observing awai whose magnitude is bigger than T. Alright, so if you're gonna get 0 -- T and T. Then it's the probability of getting an observation.",
                    "label": 0
                },
                {
                    "sent": "Here, right, so I'm just integrating the likelihood.",
                    "label": 0
                },
                {
                    "sent": "The Gaussian likelihood over that region.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now what would be the exact posterior for X in this problem?",
                    "label": 0
                },
                {
                    "sent": "Well, if I have a bunch of these censored observations will get a similar thing, is what happened before.",
                    "label": 0
                },
                {
                    "sent": "I'll have a bunch of these, so each of these censored observations gives me this sum.",
                    "label": 0
                },
                {
                    "sent": "An if I multiply together, I'll have to the end of these terms showing up each of the terms in this sum.",
                    "label": 0
                },
                {
                    "sent": "By the way, is very simple, because this term, for example, is just a cumulative Gaussian function, and so will this term be.",
                    "label": 0
                },
                {
                    "sent": "The problem is that you have two of them.",
                    "label": 0
                },
                {
                    "sent": "Two of these cumulative Gaussians.",
                    "label": 0
                },
                {
                    "sent": "So if we want to estimate approximate the posterior for X.",
                    "label": 1
                },
                {
                    "sent": "In this problem we can run expectation propagation and essentially what will happen is.",
                    "label": 0
                },
                {
                    "sent": "When we visit each of these Gaussian factors will find that their approximation is themselves because they're already Gaussian, and so when you run through that formula will just find you should just use yourself as the approximation.",
                    "label": 0
                },
                {
                    "sent": "And the only thing then we need to wear something interesting happens.",
                    "label": 0
                },
                {
                    "sent": "Is on these censored observations, where we're just going to get?",
                    "label": 0
                },
                {
                    "sent": "The following problem we're going to have this censored observation we're going to have this context term.",
                    "label": 0
                },
                {
                    "sent": "Q Not I have X, which in this case will be easier, just be the product of all the other Gaussian terms that will be my context for just one sensor observation.",
                    "label": 0
                },
                {
                    "sent": "And then all I need all I need to do is do the project that.",
                    "label": 0
                },
                {
                    "sent": "Divide that by Q, not IMX.",
                    "label": 0
                },
                {
                    "sent": "And that will be my.",
                    "label": 0
                },
                {
                    "sent": "Approximation for that censored factor.",
                    "label": 0
                },
                {
                    "sent": "And this the moments of this product.",
                    "label": 0
                },
                {
                    "sent": "Are can be worked out.",
                    "label": 0
                },
                {
                    "sent": "So basically you'll have discussing CDF times another Gaussian and just work on those moments and I'll show later.",
                    "label": 0
                },
                {
                    "sent": "A nice trick for working out moments of this type which arise quite a lot in EP.",
                    "label": 0
                },
                {
                    "sent": "OK, so hopefully that that shows how you might use this censoring in this in this framework.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's move on to some other problems and I'll illustrate how you can apply even to those problems as well.",
                    "label": 0
                },
                {
                    "sent": "Right, so here's the problem.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rises a lot in machine learning.",
                    "label": 0
                },
                {
                    "sent": "You want to sort of tracking problem right?",
                    "label": 0
                },
                {
                    "sent": "So you have you have an object which is moving around.",
                    "label": 1
                },
                {
                    "sent": "I observe the object at certain spots at certain times.",
                    "label": 0
                },
                {
                    "sent": "An my measurement is noisy, so the object is moving around that has some true location which is given by X and a certain instance in time.",
                    "label": 0
                },
                {
                    "sent": "I observe a noisy estimate of its position, so observe Y one which is a noisy version of X1Y2 is a noisy version of X2 and so on.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the factor graph for that sort of problem?",
                    "label": 1
                },
                {
                    "sent": "Well, we have suppose that the object is just undergoing some simple Markov chains, or random walk is a very common assumption.",
                    "label": 0
                },
                {
                    "sent": "So we'll have, for example, this equation for the dynamics, which turns into that familiar linear chain factor graph.",
                    "label": 0
                },
                {
                    "sent": "And our observation model is just that we add Gaussian noise to X.",
                    "label": 0
                },
                {
                    "sent": "So we have these factors hanging off.",
                    "label": 0
                },
                {
                    "sent": "And the estimation problem is that we want to estimate where was the objects we want to estimate X given the wise.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so first of all.",
                    "label": 0
                },
                {
                    "sent": "Now you might recognize this as a familiar problem, so you might say this is a common filtering problem.",
                    "label": 0
                },
                {
                    "sent": "Annual without your signal processing book and start reading the common filtering equations, but I would suggest don't do that because the algorithm is going to give you is much more general, so you can apply it not only to linear Gaussian problems, but nonlinear problems as well, and I will show you how to how you can run a nonlinear problem, so put away your signal processing book for awhile and just think in terms of graphical models.",
                    "label": 0
                },
                {
                    "sent": "So we just have a graphical model we're going to buy general purpose graphical modeling.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Makes this problem OK, so.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do is to compute the posterior distribution of the axis.",
                    "label": 0
                },
                {
                    "sent": "I'm going to make a very particular assumption.",
                    "label": 0
                },
                {
                    "sent": "Which is that I want a posterior distribution on axis which is factorized.",
                    "label": 0
                },
                {
                    "sent": "So I want to get.",
                    "label": 0
                },
                {
                    "sent": "I don't want to have a joint distribution all the access, but that's going to be way too complicated if I have 100 times.",
                    "label": 0
                },
                {
                    "sent": "I'm going to a joint solution over 100 things and that's that's unwieldy.",
                    "label": 0
                },
                {
                    "sent": "So instead I'm just going to try and get the marginal distribution of each of the axis.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do is, I'm going to look for.",
                    "label": 0
                },
                {
                    "sent": "A distribution Q of X1 which is Gaussian on X1QX2 which is Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The next two and so on and the way I can ensure that is I need to approximate my factors in a particular way.",
                    "label": 0
                },
                {
                    "sent": "All I need to do to ensure that as I is the only factors that are really bugging me.",
                    "label": 0
                },
                {
                    "sent": "So the factors that are connected.",
                    "label": 0
                },
                {
                    "sent": "Why aren't really a problem 'cause there's a Gaussian and there only one variable anyway?",
                    "label": 0
                },
                {
                    "sent": "The real problem are those transition factors.",
                    "label": 0
                },
                {
                    "sent": "The transition vectors are connecting two axes together and I don't want that because if I when I multiply those together I'll get a couple of distribution.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do is I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to approximate each of those pairwise transition factors with two separate Singleton factors.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Oh, so the transition factor is this one right?",
                    "label": 0
                },
                {
                    "sent": "So this is P of X2 given X1.",
                    "label": 0
                },
                {
                    "sent": "So it's these factors which cause coupling in my problem.",
                    "label": 0
                },
                {
                    "sent": "And I don't want that.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do is I'm going to take each one of those factors, so this used to be.",
                    "label": 0
                },
                {
                    "sent": "P of X2.",
                    "label": 0
                },
                {
                    "sent": "Given X one what I'm going to do is I'm going to replace that with two Gaussians going to replace it with a Gaussian X one and a Gaussian on X2.",
                    "label": 0
                },
                {
                    "sent": "That would be my approximation.",
                    "label": 0
                },
                {
                    "sent": "And I will call that.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Backward distribution for X1 and the other one will be called the forward distribution for X2.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just to write it a different way, I'm going to take.",
                    "label": 0
                },
                {
                    "sent": "This transition factor and I'm going to approximate it as the product of two Gaussians.",
                    "label": 0
                },
                {
                    "sent": "1X1 and 1X2.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to do that for all of the transition factors and it should be clear that after I've done that, I now have just a separate Gaussian distribution on all of my variables, right?",
                    "label": 0
                },
                {
                    "sent": "Because this distribution here.",
                    "label": 0
                },
                {
                    "sent": "Was already quite friendly.",
                    "label": 0
                },
                {
                    "sent": "That was just pure Y one given X1.",
                    "label": 0
                },
                {
                    "sent": "Which was already Gaussian in this case.",
                    "label": 0
                },
                {
                    "sent": "And all I want to do is multiply that with with the backward distribution.",
                    "label": 0
                },
                {
                    "sent": "That would be my distribution.",
                    "label": 0
                },
                {
                    "sent": "Explain, OK question.",
                    "label": 0
                },
                {
                    "sent": "Caution.",
                    "label": 0
                },
                {
                    "sent": "So could I approximated by apparel biodistribution?",
                    "label": 0
                },
                {
                    "sent": "Depends on both X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "I certainly could, but then I'd get a posterior which is a joint function of both X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "So but I said from the outset I don't want that.",
                    "label": 0
                },
                {
                    "sent": "I want just marginal distributions on each of the variables.",
                    "label": 0
                },
                {
                    "sent": "Absolutely yes.",
                    "label": 0
                },
                {
                    "sent": "So if you want a better approximation, you can use bigger, bigger neighborhoods essentially, so you can say that I want to use the first to distribute.",
                    "label": 0
                },
                {
                    "sent": "I want the first 2 variables to be in one of my approximate posteriors, the 2nd two variables will be in another one, and so on.",
                    "label": 0
                },
                {
                    "sent": "We can certainly do that, and in fact, what you would do in that case is you would just simply not break the transition between one and two apart, but you would only break the transition between two and three apart, for example, and that would give you.",
                    "label": 0
                },
                {
                    "sent": "What you wanted, I would give you a joint on one and two and three and four.",
                    "label": 0
                },
                {
                    "sent": "So it's really just the choice of.",
                    "label": 0
                },
                {
                    "sent": "I mean, once you've decided what you want your approximation to look like, how much structure you want to be in it?",
                    "label": 0
                },
                {
                    "sent": "You, then it's pretty mechanical to decide.",
                    "label": 0
                },
                {
                    "sent": "OK which factors we need to approximate in, how essentially and maybe you don't need approximate.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of them don't need to be approximated at all.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We now need to split these pairwise factors.",
                    "label": 0
                },
                {
                    "sent": "As I said.",
                    "label": 0
                },
                {
                    "sent": "It's going to have this form.",
                    "label": 0
                },
                {
                    "sent": "And this form.",
                    "label": 0
                },
                {
                    "sent": "And how can I find a good pair of Gaussians to approximate that?",
                    "label": 0
                },
                {
                    "sent": "That single joint Gaussian.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Let's see what should I do?",
                    "label": 0
                },
                {
                    "sent": "Anyone have any ideas?",
                    "label": 0
                },
                {
                    "sent": "Project project.",
                    "label": 0
                },
                {
                    "sent": "Well, let's see.",
                    "label": 0
                },
                {
                    "sent": "Suppose I chose.",
                    "label": 0
                },
                {
                    "sent": "Suppose I did this.",
                    "label": 0
                },
                {
                    "sent": "That's one option I guess.",
                    "label": 0
                },
                {
                    "sent": "It's sort of records to generalize.",
                    "label": 0
                },
                {
                    "sent": "We mean by projection, but there's an issue here, which is that I haven't taken into account any context.",
                    "label": 0
                },
                {
                    "sent": "Right, so as I said before, the best way to approximate a factor isn't clear until you know what's going to be multiplied by.",
                    "label": 0
                },
                {
                    "sent": "So in fact this is a trick question.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't should not try to approx.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The factor is this way.",
                    "label": 0
                },
                {
                    "sent": "Instead you should try to approximate it this way.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "How far?",
                    "label": 0
                },
                {
                    "sent": "Transition distribution, and now I'm going to take into account the approximations that I already made for the other transition factors, so I already have a Gaussian sitting here on X2 and I'll have another Gaussian sitting here on X3.",
                    "label": 0
                },
                {
                    "sent": "In addition to these.",
                    "label": 0
                },
                {
                    "sent": "These distributions here, which are abbreviated as Q upwards.",
                    "label": 0
                },
                {
                    "sent": "OK, so everything I've written with the Q is a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And what I've written with the IS is, well, it's a Gaussian, but not a not a Singleton Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And what I want to approximate with, well, the context is obviously going to be the same.",
                    "label": 0
                },
                {
                    "sent": "Alright, so all of that is the same.",
                    "label": 0
                },
                {
                    "sent": "We're not going to change any of that.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to change what's in the center.",
                    "label": 0
                },
                {
                    "sent": "I'm going to replace that.",
                    "label": 0
                },
                {
                    "sent": "With my 2.",
                    "label": 0
                },
                {
                    "sent": "Univariate gaussians?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Arrows.",
                    "label": 0
                },
                {
                    "sent": "You mean this?",
                    "label": 0
                },
                {
                    "sent": "That's so this is the.",
                    "label": 0
                },
                {
                    "sent": "This is the message that came from the data point.",
                    "label": 0
                },
                {
                    "sent": "It's what's the factor that's connected to that data point, which I'm not drawing because it's not important, essentially.",
                    "label": 0
                },
                {
                    "sent": "Are you confused confusion?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Before I said that you can take all the factors in the model, assume that they've all been approximated except for the one that you're looking at now, right?",
                    "label": 0
                },
                {
                    "sent": "And that's essentially what I've done, so I've assumed that I've already split apart all of the other transition factors, and if any of the if any of these, like load factors need to be approximated, I've done those as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so every every other factor in the model has been turned into a Gaussian, and the only thing I need to do left is to break this one factor part into Gaussians.",
                    "label": 0
                },
                {
                    "sent": "And so the the idea now is, how can I incorporate all the information that I've learned from my context to make to do this optimally?",
                    "label": 0
                },
                {
                    "sent": "Right now?",
                    "label": 0
                },
                {
                    "sent": "What does optimally mean?",
                    "label": 0
                },
                {
                    "sent": "So we should come back to that question?",
                    "label": 0
                },
                {
                    "sent": "What is it that we want to have happen?",
                    "label": 0
                },
                {
                    "sent": "Well, we want X twos moments to be the same in the top and the bottom, and you want X3 is mostly the same time because that's our moment matching objective.",
                    "label": 0
                },
                {
                    "sent": "That's what we've chosen that we've chosen as our things to do today.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's just write out that constraint.",
                    "label": 0
                },
                {
                    "sent": "So what we want is we want.",
                    "label": 0
                },
                {
                    "sent": "This distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I've written here on the upper right is the distribution of X2 for the top graph.",
                    "label": 0
                },
                {
                    "sent": "Right where I have marginalized out X3, so that's the exact distribution of X2 on the top graph.",
                    "label": 0
                },
                {
                    "sent": "And I want to approximate that.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "Pops the distribution I get in the bottom graph.",
                    "label": 0
                },
                {
                    "sent": "Well distribution.",
                    "label": 0
                },
                {
                    "sent": "The bottom graph is actually quite simple because I don't need to really integrate RX3, I can just ignore the fact all the factors that are not connected to.",
                    "label": 0
                },
                {
                    "sent": "So that's what I get on the bottom graph, and I want these two distributions to be similar and the notion of similar I want is having the same moments, so this should not give you the answer.",
                    "label": 0
                },
                {
                    "sent": "So if I want these two to have the same moments, how should I choose?",
                    "label": 0
                },
                {
                    "sent": "This message here.",
                    "label": 0
                },
                {
                    "sent": "So this is the only message I'm choosing in this part right?",
                    "label": 0
                },
                {
                    "sent": "All the other ones are fixed.",
                    "label": 0
                },
                {
                    "sent": "Any ideas how should I choose this message?",
                    "label": 0
                },
                {
                    "sent": "So I should choose.",
                    "label": 0
                },
                {
                    "sent": "So this will be equal to something.",
                    "label": 0
                },
                {
                    "sent": "Exactly, so we just take the projection of this big mess on the top.",
                    "label": 0
                },
                {
                    "sent": "OK Q.",
                    "label": 0
                },
                {
                    "sent": "Thanks too.",
                    "label": 0
                },
                {
                    "sent": "Integral whole bunch of stuff.",
                    "label": 0
                },
                {
                    "sent": "OK divided by.",
                    "label": 0
                },
                {
                    "sent": "This stuff.",
                    "label": 0
                },
                {
                    "sent": "Is that clear?",
                    "label": 0
                },
                {
                    "sent": "What does that do with common filtering?",
                    "label": 0
                },
                {
                    "sent": "Well, here's here's the interesting part.",
                    "label": 0
                },
                {
                    "sent": "So the distribution that's in this project.",
                    "label": 0
                },
                {
                    "sent": "Is actually a Gaussian distribution in this particular case, because that transition distribution is a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Right, so when I multiply all those Gaussians together, integrate X3 I Gaussian X2, multiplied by some more Gaussian X2, the whole thing is Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Is that clear?",
                    "label": 0
                },
                {
                    "sent": "So what's in the project?",
                    "label": 0
                },
                {
                    "sent": "Gaussian already?",
                    "label": 0
                },
                {
                    "sent": "Before I did the garage, which means that the projects and no, it doesn't actually do anything, so I can remove the project and when I remove the project now, the denominator cancels with what was in the numerator.",
                    "label": 0
                },
                {
                    "sent": "So in fact what I get out in this Gaussian case?",
                    "label": 0
                },
                {
                    "sent": "Because it's a Gaussian case, is that?",
                    "label": 0
                },
                {
                    "sent": "It's just this integral.",
                    "label": 0
                },
                {
                    "sent": "OK, this should have been nice.",
                    "label": 0
                },
                {
                    "sent": "There we go OK so now people have studied common filters or Hmm's know about forward backward equations will recognize this as the standard backward equation that you get in a Markov chain, right?",
                    "label": 0
                },
                {
                    "sent": "Because this is the backward message for X3.",
                    "label": 0
                },
                {
                    "sent": "This is the data term for X3.",
                    "label": 0
                },
                {
                    "sent": "Integrate that through the transition density and that's the message that you the backward message that you send to X2.",
                    "label": 0
                },
                {
                    "sent": "So in fact we didn't have to know this was a common filter model.",
                    "label": 0
                },
                {
                    "sent": "We didn't know that that Gaussianity was special.",
                    "label": 0
                },
                {
                    "sent": "We can just apply the same old EP equations and you get it out automatically.",
                    "label": 0
                },
                {
                    "sent": "OK, so this this would be what you normally call the backward message.",
                    "label": 0
                },
                {
                    "sent": "In a forward backward algorithm.",
                    "label": 0
                },
                {
                    "sent": "And the forward message is very similar.",
                    "label": 0
                },
                {
                    "sent": "You can go through the derivation of the forward message, which is this one.",
                    "label": 0
                },
                {
                    "sent": "So so if we try and solve for this one using the same procedure, what you'll find is it is the standard way you computer forward message in Markov model.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now how can we put this all together to get an actual to get an actual algorithm?",
                    "label": 0
                },
                {
                    "sent": "How would we actually do inference on this problem so?",
                    "label": 0
                },
                {
                    "sent": "So what is our approximation approximation?",
                    "label": 0
                },
                {
                    "sent": "Is that for each of these transition factors, we're going to break it into two separate factors.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have an iterative scheme where we just initialize all of these approximations.",
                    "label": 0
                },
                {
                    "sent": "So we just initialize all these forward and backward messages essentially.",
                    "label": 0
                },
                {
                    "sent": "And we'll start by updating this one in the context of the other approximations that we've made.",
                    "label": 0
                },
                {
                    "sent": "So these have already been.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It'll update that one.",
                    "label": 0
                },
                {
                    "sent": "And then, once that's been approximated, which then go to the second one, we say, OK, I've already got forward and backward messages here.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I will approximate this one.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "Now you see, this ones are these horizon approximated by approximately this one and then repeat.",
                    "label": 0
                },
                {
                    "sent": "So you go in a round Robin fashion.",
                    "label": 0
                },
                {
                    "sent": "And essentially if you order these updates just right, you'll get the same updates that you would do in a common filter.",
                    "label": 0
                },
                {
                    "sent": "So you would get get forward messages in backward messages.",
                    "label": 0
                },
                {
                    "sent": "Now, however, I said that EP was in iterative scheme that you iterate to get fixed point.",
                    "label": 0
                },
                {
                    "sent": "So does that mean that we're going to get more often than a common filter one?",
                    "label": 0
                },
                {
                    "sent": "So common filter would only go forward once in backward once, and it would be done.",
                    "label": 0
                },
                {
                    "sent": "There will be no further iterations, but in an EP scheme.",
                    "label": 0
                },
                {
                    "sent": "We would keep iterating well what ends up happening is as soon as you've done one iteration, you already have done the common filter, and if you iterate again, the answer won't change.",
                    "label": 0
                },
                {
                    "sent": "When you're running, so it will be, it will reach a fixed point after the very first forward backward pass, so you don't necessarily lose anything by using YP for this problem, instead of common filtering and what yeah?",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "So you have to be a bit smart about how you do the scheduling.",
                    "label": 0
                },
                {
                    "sent": "So in particular you don't necessarily have to compute both forward and backward message every time you visit one of these pairs.",
                    "label": 0
                },
                {
                    "sent": "'cause if you know that you're doing the forward version the forward pass, you only need the forward message and when you're going backward rolling into backward message so you can skip some of the computation that you would have done.",
                    "label": 0
                },
                {
                    "sent": "I mean that on the grass it looks or like.",
                    "label": 0
                },
                {
                    "sent": "Speaking.",
                    "label": 0
                },
                {
                    "sent": "Oh, absolutely yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean the same is true of loopy belief propagation as well, so anything you've heard about loopy belief propagation would apply just as much to expectation propagation.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I said, if you do, if you do common filtering, if you apply this this EP procedure to a common filtering problem, you essentially get the common filter algorithm where finishes in one iteration, so that seems you didn't gain much.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing is that now we can apply this to nonlinear problems, where now we will have to iterate.",
                    "label": 0
                },
                {
                    "sent": "It won't be done after just one forward backward pass.",
                    "label": 0
                },
                {
                    "sent": "You have to do multiple forward backward passes and you'll keep refining each of those Gaussian posteriors to get that done.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You get a good estimate, so I'll show you an example of that.",
                    "label": 0
                },
                {
                    "sent": "So I can now apply the algorithm I just gave you to all sorts of nonlinear problems, and So what I'm going to do is I'm going to apply to the problem of Passan tracking, which is where we have a state, a real valued state.",
                    "label": 0
                },
                {
                    "sent": "But what we observe is not just the Gaussian noise applied to that state, but we're going to observe an integer and that integers distribution is given by a person distribution whose rate is the exponential of X. OK, so this is the type of model you would use if you were trying to do some sort of time series modeling of counts.",
                    "label": 0
                },
                {
                    "sent": "So if you had if you had counts of for example, you know the number of cells on a plate and you had some sort of time you had a time series of those counts and you want to model what is the underlying intensity of cells on that plate, for example.",
                    "label": 0
                },
                {
                    "sent": "So any anything that's account that you've observed overtime, so we observe, for example, sales data for a store, and you want to model how?",
                    "label": 0
                },
                {
                    "sent": "What is the true underlying distribution of those sales?",
                    "label": 0
                },
                {
                    "sent": "You might use a model like this.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here I'm just giving some simple distributions.",
                    "label": 0
                },
                {
                    "sent": "So suppose the prior on the first state is just a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The transition densities again just the Gaussian transition.",
                    "label": 0
                },
                {
                    "sent": "But now the fancy thing is that the observation density is not a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So this person where the rate is the exponential of X and you get that you get that form.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Loud.",
                    "label": 0
                },
                {
                    "sent": "OK, so again, what's the first thing we do for any problem we write down the factor graph the factor graph.",
                    "label": 0
                },
                {
                    "sent": "This problem looks exactly like the common filter problem, right?",
                    "label": 0
                },
                {
                    "sent": "So we again have these transition densities between the axes and we again have these observation densities between the wise and the X is yes.",
                    "label": 0
                },
                {
                    "sent": "More like smoother.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's trying to find the posterior on each axis given all of the data.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it's a smoother.",
                    "label": 0
                },
                {
                    "sent": "OK, so right, so the factor graph has the same form.",
                    "label": 1
                },
                {
                    "sent": "The difference now is that these observation densities now are not Gaussian, which means that if we want to get Gaussian queues.",
                    "label": 0
                },
                {
                    "sent": "On each of the axes, we're going to approximate those factors as well.",
                    "label": 0
                },
                {
                    "sent": "So in addition to, in addition to breaking apart the transition densities, we're going to have to now make Gaussian approximations on the observation factors OK.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you guys should now be pros at this.",
                    "label": 0
                },
                {
                    "sent": "You should now know exactly what to do.",
                    "label": 0
                },
                {
                    "sent": "If I give you this problem.",
                    "label": 0
                },
                {
                    "sent": "So let's suppose we have a backward message for X1.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And I have my likelihood.",
                    "label": 0
                },
                {
                    "sent": "Which is in this case of course on distribution on Y1.",
                    "label": 0
                },
                {
                    "sent": "With intensity E to the X1.",
                    "label": 0
                },
                {
                    "sent": "And I want to approximate that.",
                    "label": 0
                },
                {
                    "sent": "Buy a Gaussian in X1 which will have some.",
                    "label": 0
                },
                {
                    "sent": "Mean and variance parameters.",
                    "label": 0
                },
                {
                    "sent": "How do I find?",
                    "label": 0
                },
                {
                    "sent": "That gaussian.",
                    "label": 0
                },
                {
                    "sent": "Use projection, yes.",
                    "label": 0
                },
                {
                    "sent": "We love projection.",
                    "label": 0
                },
                {
                    "sent": "So no one's answering 'cause it's so easy, right?",
                    "label": 0
                },
                {
                    "sent": "It's so obvious what you would do.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is we want.",
                    "label": 0
                },
                {
                    "sent": "To take the factor, we're going to approximate, multiply it by our context.",
                    "label": 0
                },
                {
                    "sent": "And then divide by the context.",
                    "label": 0
                },
                {
                    "sent": "And that ensures that when I multiply these two together and get a posterior distribution of the same moments as that posterior distribution, OK?",
                    "label": 0
                },
                {
                    "sent": "And so, so you just have to workout.",
                    "label": 0
                },
                {
                    "sent": "What are the moments of apasan times a Gaussian with exponential rate, and I'm sure you guys can work that out.",
                    "label": 0
                },
                {
                    "sent": "I'll leave.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a homework problem.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "And here are the results you get so so essentially, let me just briefly describe what the algorithm is like, so we have this forward backward thing on the top as we did before.",
                    "label": 0
                },
                {
                    "sent": "But now we're going to have to approximate each of the likely terms.",
                    "label": 0
                },
                {
                    "sent": "So as you're doing forward and backward, you're also going to be re approximating each of these likely terms, and each one is going to be approximated using the current messages that that that state is receiving.",
                    "label": 0
                },
                {
                    "sent": "So with that seat is currently receiving a forward and backward message, and based on those current forward and backward messages are going to approximate that likely term.",
                    "label": 0
                },
                {
                    "sent": "So the whole thing will need multiple passes, you converge.",
                    "label": 0
                },
                {
                    "sent": "And So what I'm plotting here are the state estimates after each iteration, so here, so I have my time series at 100 time steps in it, so there's 100 different states we're tracking.",
                    "label": 0
                },
                {
                    "sent": "And I'm plotting the posterior mean of each of the states.",
                    "label": 0
                },
                {
                    "sent": "So the mean of the Gaussian that I'm estimating for the state.",
                    "label": 0
                },
                {
                    "sent": "And I'm just showing what it's like after each iteration.",
                    "label": 0
                },
                {
                    "sent": "So in the first EP iteration I just blanked out all of the approximations that they were all uniform and I just ran one forward backward and this is what you get from that one forward backward and you find that the estimates are all shifted and the reason for that is because you haven't yet fully incorporated all of the information from all parts of the data set.",
                    "label": 0
                },
                {
                    "sent": "So there's sort of this sort of lag effect.",
                    "label": 0
                },
                {
                    "sent": "But now when you run additional iterations of EP, you find that it stabilizes and EP iteration tenant essentially is converged to this blue.",
                    "label": 0
                },
                {
                    "sent": "Estimate so if you remember that data set that I showed you have integer counts sort of low in the middle and high at the ends, right?",
                    "label": 0
                },
                {
                    "sent": "So it makes sense that your estimate would be low in the middle and high at the ends for the underlying state.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mean.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Here I'm showing the the exact posterior for the last state.",
                    "label": 1
                },
                {
                    "sent": "So for State 100 of the chain, given the data set and comparing that to the EP approximation, so the exact one is in black.",
                    "label": 0
                },
                {
                    "sent": "So after iteration one EP gets this blue approximation blue Gaussian an after iteration three, we get a very very close green Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Now the exact one is not Gaussian, but it sure looks Gaussian, right?",
                    "label": 0
                },
                {
                    "sent": "So it's again one of these problems where even though the exact distribution is actually quite complicated, if you were to write it out, it's an integral of a whole bunch of Gaussian states times plus on likelihoods.",
                    "label": 0
                },
                {
                    "sent": "So it's very messy analytically.",
                    "label": 0
                },
                {
                    "sent": "But when you actually plot it, it's actually very nice distribution.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Here I'm comparing different methods for this problem.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So on the top I'm showing the the posterior means that were estimated, so the same as the plot before, I'm just adding additional algorithms to it.",
                    "label": 0
                },
                {
                    "sent": "So the extra algorithms that I'm adding this time I'm adding particle smoothing, which is a well known algorithm for handling nonlinear time series problems.",
                    "label": 0
                },
                {
                    "sent": "And I'm also considering a Gibbs sampler, which I'm calling MCMC here, which is something you could also use for a time series problem, although would be very slow, and by the way the particle filter and the.",
                    "label": 0
                },
                {
                    "sent": "And the MCMC sampler were run for a very long time and they were run.",
                    "label": 0
                },
                {
                    "sent": "They used like 100 times more computer time than the EPL going to.",
                    "label": 0
                },
                {
                    "sent": "So even though yes, you could run them longer and longer and longer and get better and better results.",
                    "label": 0
                },
                {
                    "sent": "I ran them for what seemed like a feasible amount of time, and these are the results I'm getting.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the particle smoother actually doesn't do particularly good job if you look at the top plot here, you'll see that there's this again, this lag effect with the particle smoother, so it doesn't something particular.",
                    "label": 0
                },
                {
                    "sent": "Good job of smoothing.",
                    "label": 0
                },
                {
                    "sent": "But otherwise the mean is pretty close by the way.",
                    "label": 0
                },
                {
                    "sent": "You might be wondering why the why you don't see a blue curve creepy?",
                    "label": 0
                },
                {
                    "sent": "That's because it's right on top of the exact curve on this planet.",
                    "label": 0
                },
                {
                    "sent": "On the bottom plot you can just barely make out that there's a distinction between the blue and the black curve.",
                    "label": 0
                },
                {
                    "sent": "As for that for the posterior variance.",
                    "label": 0
                },
                {
                    "sent": "Now interesting thing that I've noticed here, which I've noticed in many problems, is that for the.",
                    "label": 0
                },
                {
                    "sent": "For the particle smoother, which is the red curve.",
                    "label": 0
                },
                {
                    "sent": "It's very good at filtering, so particle filters are particularly good filtering, so they give you a nice estimate right at the end of time.",
                    "label": 0
                },
                {
                    "sent": "But when it comes back to smoothing backwards, they're actually not very good at all, and so we find is that the estimate of the state posterior gets very very bad as you go back in time.",
                    "label": 0
                },
                {
                    "sent": "Yes question.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing is I'm essentially showing what MBTI would give if you stopped it early.",
                    "label": 0
                },
                {
                    "sent": "So if you ran it for a finite number of iterations and look at, the result would be, and in this case what I'm doing is I'm sampling the states of this Markov chain, which are highly correlated with each other and I'm using Gibbs, so it's not a particularly smart way of sampling states in a Markov chain, so Gibbs sampling means I have to sample one at a time condition on its two neighbors, so it makes it very, very slowly.",
                    "label": 0
                },
                {
                    "sent": "And in particular, it mixes so slowly that I always underestimate the variance of each state.",
                    "label": 0
                },
                {
                    "sent": "At this point, so systematically low in terms of my estimate of the variance.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now there people have worked on some fancier ways of sampling Markov chains, but actually it's quite a hard problem to sample to sample a Markov chain with Monte Carlo efficiently.",
                    "label": 0
                },
                {
                    "sent": "So if you were to type in, for example this model into bugs and ask bugs, what would be the state estimate you would use exactly this algorithm?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here is a comparison of time accuracy.",
                    "label": 0
                },
                {
                    "sent": "So there's two different curves.",
                    "label": 0
                },
                {
                    "sent": "Just because I use two different ways of doing the integral over the person.",
                    "label": 0
                },
                {
                    "sent": "So if you could give us an times in Gaussian, and I did two different ways of doing that, one which is sort of fast and cheap, which is what we want, another one which is more accurate.",
                    "label": 0
                },
                {
                    "sent": "So what this shows is that you know if the integrals that occur within EP are expensive, you may want to even make those approximate to make the to make the algorithm faster.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the fast but less accurate way of doing that integral in here.",
                    "label": 0
                },
                {
                    "sent": "So faster way of doing that integral.",
                    "label": 0
                },
                {
                    "sent": "And here I'm comparing the results from MTN particle filtering which are way off even with lots more time.",
                    "label": 0
                },
                {
                    "sent": "So I gave them huge amount more time orders of magnitude more time and they still were way off.",
                    "label": 0
                },
                {
                    "sent": "And again, the reason for that is not because of the dimensionality of the problem or anything like that is because it's because it's a friendly problem.",
                    "label": 0
                },
                {
                    "sent": "For EP, I mean the posterior is very very Gaussian, so you expect to get good results.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I think I should end the talk there, right?",
                    "label": 0
                },
                {
                    "sent": "So it's 5:30 and next time I will talk about other approximate inference albums.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about variational, Bayes and so on.",
                    "label": 0
                },
                {
                    "sent": "I'm so I'll see you then.",
                    "label": 0
                }
            ]
        }
    }
}