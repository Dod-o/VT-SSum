{
    "id": "6a5hc7eq4dx5eju66cz245i3pgd47ncm",
    "title": "Faster Algorithms for Testing under Conditional Sampling",
    "info": {
        "author": [
            "Ananda Theertha Suresh, Department of Computer Science and Engineering, UC San Diego"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_suresh_conditional_sampling/",
    "segmentation": [
        [
            "Hi everyone, I'll be talking about faster algorithms for Cascade.",
            "This is joint work with mowing ashtangi rajang along our Lipsky."
        ],
        [
            "So here is an outline of the talk and poster, broadly speaking, is false hunger, new emerging field of proper kick asking and where your focus is often to obtain an algorithm which is sub linear.",
            "Again number of para meters.",
            "So in this talk I'm going to focus on every powerful sampling model called conditional sampling, which allows us to come up with some very nice interactive algorithms and show that you can have a double exponential gaining sample complex key compared to the standard model."
        ],
        [
            "So let's give anger problem.",
            "So you have a very basic second.",
            "You have two distributions P&Q you want to say Vegas same or give Frank.",
            "When I say different, I mean you're having everyone just kind of at least epsilon.",
            "And you want to solve this problem with some error probability, say less than 1% or 10%.",
            "And we want to characterize the sample complexity based on the number support which is denoted by K and L1 distance epsilon.",
            "So over the last decade this problem has been scheduled extensively.",
            "You can think of two scenarios, case one, where you just called identic, asking where you know one of the distributions.",
            "In this case the sample complexity was shown to be roughly square root K. And if you don't know bogus tribulations, it was shown to be cake by three.",
            "The punchline of this line of work is it is less than K, which is the number of samples you need to take even to see all the symbols once but for the purposes of this target, sufficient cooking coffee.",
            "Get some polynomial in K. OK."
        ],
        [
            "So, uh, last few years people are canker conflict.",
            "Becker, Becker sampling models, or some assumptions which will reduce this number further, so I'm going to discuss one Afghan, which is a conditional sampling model where you get to query a set S and you get a sample condition language set.",
            "For example, if you query set 156, you get symbol one with probability P of 1 / P of 1 + 5 + 6.",
            "OK, so recently it was shown that Angus model just sample complex complex is actually reduce drastically if you know one of the distributions.",
            "Guess actual sample complex keys now accounts can't which is independent of K. And if you don't know both of them except polylog Excel polynomial in log K. Another said for the purposes of his cock, like sufficient looking over some polynomial in log K. So in just angered model it was a polynomial in K. Now it's a polynomial in log K. Give us an explicit open problem by Elder Fisher last year where the question was to find out what's your actual sample complexity and we answer this question."
        ],
        [
            "So first we show that if you know one of the distributions, in fact you can solve this problem using epsilon 3 -- 2 samples, where epsilon is gal, one distance between two distributions.",
            "And mortgages information quickly optimal because even could distinguish between birnale half and half plus epsilon you need of God's phone number epsilon square samples.",
            "For closeness casting, we reduced the Poly log to log log K and in fact is probably one of the few property question papers where you get a sample complexity which is log log K. However, we know it's almost take up the polynomial factor based on recent lower bound by Acharya Ken and Go come, so we get doubly exponential, gaining sample complexity over the standard model so."
        ],
        [
            "Ask one minute let me give you a simple tie example which maybe give you a rough idea of why your sample complexity goes from something which is polynomial in K to something which is really really small.",
            "So I want to distinguish between disco distributions.",
            "P&QP is a uniform distribution over K symbols and Q is a perk up distribution where half of the symbols have probability one plus epsilon by K. And I'll go half as probably 1 minus epsilon baking.",
            "OK.",
            "So here is my algorithm.",
            "I'm going to randomly pick a set S. Off size 2 and let's call those symbols inj condition Ganga circus get distribution would be uniform for P because probability of I anguirus is P of I / P of I + P of Jay.",
            "If I plug in one bike everywhere I get half.",
            "However, we probably get half.",
            "Disco symbols will have different properties in Q, so if you look at QS of IQ of I anger S. It is 1 minus epsilon divided by 1 minus epsilon plus one plus epsilon which is 1 minus epsilon by two.",
            "So now you have reduced the problem to solving bunk differentiating between birnale half and half plus epsilon, which a simple Chebyshev bone will give you one over epsilon square.",
            "And I showed you how to get this problem solved this problem.",
            "We could probably half you can repeat it many times, could get probability arbitrarily close to one, so this kind of approach is very different from the usual property question literature where you come up with that kiss, kiss, kick.",
            "Anger computers expectation where hearings and use Chebyshev kind bonds.",
            "So if you are in classical behavior Calculator, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, I'll be talking about faster algorithms for Cascade.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with mowing ashtangi rajang along our Lipsky.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is an outline of the talk and poster, broadly speaking, is false hunger, new emerging field of proper kick asking and where your focus is often to obtain an algorithm which is sub linear.",
                    "label": 0
                },
                {
                    "sent": "Again number of para meters.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I'm going to focus on every powerful sampling model called conditional sampling, which allows us to come up with some very nice interactive algorithms and show that you can have a double exponential gaining sample complex key compared to the standard model.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's give anger problem.",
                    "label": 0
                },
                {
                    "sent": "So you have a very basic second.",
                    "label": 0
                },
                {
                    "sent": "You have two distributions P&Q you want to say Vegas same or give Frank.",
                    "label": 0
                },
                {
                    "sent": "When I say different, I mean you're having everyone just kind of at least epsilon.",
                    "label": 0
                },
                {
                    "sent": "And you want to solve this problem with some error probability, say less than 1% or 10%.",
                    "label": 0
                },
                {
                    "sent": "And we want to characterize the sample complexity based on the number support which is denoted by K and L1 distance epsilon.",
                    "label": 0
                },
                {
                    "sent": "So over the last decade this problem has been scheduled extensively.",
                    "label": 0
                },
                {
                    "sent": "You can think of two scenarios, case one, where you just called identic, asking where you know one of the distributions.",
                    "label": 0
                },
                {
                    "sent": "In this case the sample complexity was shown to be roughly square root K. And if you don't know bogus tribulations, it was shown to be cake by three.",
                    "label": 0
                },
                {
                    "sent": "The punchline of this line of work is it is less than K, which is the number of samples you need to take even to see all the symbols once but for the purposes of this target, sufficient cooking coffee.",
                    "label": 0
                },
                {
                    "sent": "Get some polynomial in K. OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, uh, last few years people are canker conflict.",
                    "label": 0
                },
                {
                    "sent": "Becker, Becker sampling models, or some assumptions which will reduce this number further, so I'm going to discuss one Afghan, which is a conditional sampling model where you get to query a set S and you get a sample condition language set.",
                    "label": 1
                },
                {
                    "sent": "For example, if you query set 156, you get symbol one with probability P of 1 / P of 1 + 5 + 6.",
                    "label": 0
                },
                {
                    "sent": "OK, so recently it was shown that Angus model just sample complex complex is actually reduce drastically if you know one of the distributions.",
                    "label": 0
                },
                {
                    "sent": "Guess actual sample complex keys now accounts can't which is independent of K. And if you don't know both of them except polylog Excel polynomial in log K. Another said for the purposes of his cock, like sufficient looking over some polynomial in log K. So in just angered model it was a polynomial in K. Now it's a polynomial in log K. Give us an explicit open problem by Elder Fisher last year where the question was to find out what's your actual sample complexity and we answer this question.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first we show that if you know one of the distributions, in fact you can solve this problem using epsilon 3 -- 2 samples, where epsilon is gal, one distance between two distributions.",
                    "label": 0
                },
                {
                    "sent": "And mortgages information quickly optimal because even could distinguish between birnale half and half plus epsilon you need of God's phone number epsilon square samples.",
                    "label": 0
                },
                {
                    "sent": "For closeness casting, we reduced the Poly log to log log K and in fact is probably one of the few property question papers where you get a sample complexity which is log log K. However, we know it's almost take up the polynomial factor based on recent lower bound by Acharya Ken and Go come, so we get doubly exponential, gaining sample complexity over the standard model so.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ask one minute let me give you a simple tie example which maybe give you a rough idea of why your sample complexity goes from something which is polynomial in K to something which is really really small.",
                    "label": 0
                },
                {
                    "sent": "So I want to distinguish between disco distributions.",
                    "label": 0
                },
                {
                    "sent": "P&QP is a uniform distribution over K symbols and Q is a perk up distribution where half of the symbols have probability one plus epsilon by K. And I'll go half as probably 1 minus epsilon baking.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here is my algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'm going to randomly pick a set S. Off size 2 and let's call those symbols inj condition Ganga circus get distribution would be uniform for P because probability of I anguirus is P of I / P of I + P of Jay.",
                    "label": 0
                },
                {
                    "sent": "If I plug in one bike everywhere I get half.",
                    "label": 0
                },
                {
                    "sent": "However, we probably get half.",
                    "label": 0
                },
                {
                    "sent": "Disco symbols will have different properties in Q, so if you look at QS of IQ of I anger S. It is 1 minus epsilon divided by 1 minus epsilon plus one plus epsilon which is 1 minus epsilon by two.",
                    "label": 0
                },
                {
                    "sent": "So now you have reduced the problem to solving bunk differentiating between birnale half and half plus epsilon, which a simple Chebyshev bone will give you one over epsilon square.",
                    "label": 0
                },
                {
                    "sent": "And I showed you how to get this problem solved this problem.",
                    "label": 0
                },
                {
                    "sent": "We could probably half you can repeat it many times, could get probability arbitrarily close to one, so this kind of approach is very different from the usual property question literature where you come up with that kiss, kiss, kick.",
                    "label": 0
                },
                {
                    "sent": "Anger computers expectation where hearings and use Chebyshev kind bonds.",
                    "label": 0
                },
                {
                    "sent": "So if you are in classical behavior Calculator, thank you.",
                    "label": 0
                }
            ]
        }
    }
}