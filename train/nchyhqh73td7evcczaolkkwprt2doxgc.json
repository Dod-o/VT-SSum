{
    "id": "nchyhqh73td7evcczaolkkwprt2doxgc",
    "title": "Hybrid Stochastic-Adversarial On-Line Learning",
    "info": {
        "author": [
            "Alessandro Lazaric, Politecnico di Milano"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_lazaric_hsao/",
    "segmentation": [
        [
            "Bill."
        ],
        [
            "And.",
            "I will try to start with a motivating example and not so serious motivating example, but maybe.",
            "It will do the work, so let's say that we have a very beautiful girl and we want to predict whether the answer to our invitation for dinner tonight will be yes or no.",
            "This is a quite real life prediction problem.",
            "Maybe not so serious now."
        ],
        [
            "It's like the ones we used to deal with in machine learning, but it's interesting to analyze the kind of problem prediction problem we're facing, because usually we can consider inputs.",
            "In this case, the girl described by this set of features, height, weight and so on as just drawn from fixed and stationary probability distribution.",
            "This is quite reasonable, so we have a set of girls and we just pick one at random, but.",
            "What about the output?",
            "So the outcome?",
            "The answer yes or no in this case is not that reasonable to consider it as coming from a fixed distribution, and we can consider it as coming from an adversarial.",
            "Source so we can say that basically the relationship between inputs and outputs is so complex to formalize that it doesn't make any sense to consider is is.",
            "Fix is coming from a fixed distribution and so it's better to consider it as adversarial.",
            "So this can mean basically anything, so I don't know.",
            "We have a distribution with changes in time, or we have really an adversary choosing the output at each time step in order to make our prediction the most difficult possible.",
            "So in the end we can consider this prediction problem as a hybrid stochastic as far as the inputs are concerned.",
            "Adversarial for the outputs problem."
        ],
        [
            "So a little bit more serious example, let's say that we have a new model of a mobile phone.",
            "We have a set of users.",
            "Set of users.",
            "Maybe they just come from a fixed distribution.",
            "Once again we describe the users using a set of features.",
            "I don't know the age, the salary, the Saxon, so on and we want to predict whether they're going to buy or not.",
            "Our new model of mobile phone.",
            "And once again is quite difficult to formalize the kind of relationship between in."
        ],
        [
            "It's an outputs and so we prefer to consider it as adversarial.",
            "So in the kind of terminology we using this worship, we say that inputs are ID from a fixed distribution, while outputs are simply adversarial.",
            "So no matter what the kind of distribution or adversary they come from.",
            "And now moving to."
        ],
        [
            "The album outline of the presentation I will focus just on the simple case of online classification problem.",
            "Actually the work can be extended to any kind of prediction problem.",
            "We recently extended it also to regression problems, so not just classification and after defining the general case of align classification problem, I will enter in details about the hybrid stochastic adversarial setting.",
            "I will show you basically the algorithm we developed.",
            "And I will try to analyze it theoretically, showing that it has some interesting properties.",
            "I think I will go very fast through the possible extensions in the setting of bandit information and possible application to games.",
            "And finally I will discuss and conclude the presentation."
        ],
        [
            "So this is the very high level definition of online classification problem.",
            "We have an input space acts and not put space.",
            "Let's consider just the binary classification problem.",
            "So labeled zero and one hypothesis space H in which each hypothesis is a mapping between inputs and outputs.",
            "And since we are considering an online learning problem, we consider each round specific.",
            "Input is given to the learner, so we have this XT which is obviously.",
            "An element of the input space acts and the learner is supposed to choose one specific hypothesis in the side of available hypothesis and as a consequence it will predict the label Y had T, which is the result of the mapping of the function HT to the given input XD.",
            "After that, since we are considering what is called usually in online learning, the full information case, the true label is revealed to the learner and the learner will also incur a loss, which is basically whether the prediction was correct or not.",
            "And once again, these can be generalized to any loss function, but I will go with this one because makes everything much simpler.",
            "So since we are working in an online setting in which the outputs as we will see are not drawn from a fixed distribution, we are interested in minimizing the cumulative regret, which is basically the difference between the performance, the cumulative performance of our algorithm.",
            "So we sum the losses incurred by the learner from step one to step North, which is.",
            "Let's say the Aurizon of our learning problem.",
            "Mine is this term, which is the best cumulative loss we can obtain by using one fixed hypothesis in the set of hypothesis age.",
            "So this is the performance of the learner and this is somehow the target performance.",
            "The best performance we can obtain on given the set of hypothesis we have."
        ],
        [
            "No, if we consider that online learning problem and as you notice, probably I didn't specify how this."
        ],
        [
            "Estes generated and how this white is generated.",
            "This is just a general model."
        ],
        [
            "But what if we?",
            "Say that both inputs and outputs are drawn from a fixed distribution, so IID data.",
            "This is the usual fully stochastic setting, and we can easily show that the regret the cumulative regret we can obtain by just using an empirical risk minimizer is of the order of N log N with respect to dependency of the time horizon with a complexity theory, which is the usual VC dimension term, which depends obviously on the set of hypothesis we have.",
            "This is pretty fair and.",
            "There is."
        ],
        [
            "Surprising it, this is a little bit more interesting.",
            "This is a very recent result by Band of Eden at all presented this year at cold and they show that if we drop the IID assumption in an online perspective, both on inputs and outputs, what changes is not somehow the dependency on the time horizon, but the correct measure of complexity for our iPod to space.",
            "This is pretty interesting and this is called the Littlestone dimension.",
            "I don't know how many of you are familiar with this concept, but I will discuss it maybe in more details towards the towards the end of the talk, but the only thing which is interesting now is that the Little Stone dimension is greater or equal to the VC dimension, so there is a relationship, but we already know that in general this is bigger than the C dimension and I will show you if I have time towards the end of the talk.",
            "That there are also very simple example in which the VC dimension maybe is 1 and the Little Stone dimension is infinite.",
            "So there are quite nasty cases in which.",
            "Giving the possibility to an adversary to choose both X&Y is going to be very bad for the learning algorithm."
        ],
        [
            "What is interesting here is that if we just drop the IID assumption on the outputs, but we still keep it for the inputs, which sometimes could be reasonable, the kind of bound we obtain is exactly the same as in the fully stochastic setting, meaning that basically by just giving the possibility to the adversary to choose the labels but not the inputs doesn't really make the bound the kind of performance we have worse.",
            "Then the fully stochastic setting and I think this is the main message.",
            "The take home message of this token, this work, and now we will.",
            "Try to prove this bound so I will show you an algorithm able to achieve that order."
        ],
        [
            "Regret.",
            "So just to cast the general online classification problem into the hybrid stochastic adversarial setting here, now we say that X of T comes from IID sample from a fixed distribution.",
            "B&YT is adversarially chosen, so can be anything basically.",
            "At this point, which is simultaneously obviously because the adversary shouldn't be able to see our prediction before generating the YT, otherwise it wouldn't be fair.",
            "So now that the main question is how can we bound this regret in this kind of setting?"
        ],
        [
            "First, I will recall briefly the result we have for exponentially weighted forecasters.",
            "In the case we have a finite number of experts.",
            "So in our notation we say that the khaligraph gauge.",
            "So the set of positive hypothesis is finite and it contains just an predictors.",
            "In this case, we can just apply the exponentially weighted forecaster, which basically maintains a distribution over the hypothesis and just update distribution at each round by considering the cumulative.",
            "Loss in court by that hypothesis until time T. So just sketch of the algorithm, we initialize the weights over all the hypothesis we have and for at each time step we observe the input we built a distribution over all the hypothesis that an iPod physis we have and the distribution is just basically taking the weight and normalizing it and we predict.",
            "HD win with HD drone from this distribution and the way we update the distribution is just the weight that the way we update the weights.",
            "And here we have the exponential term which is minus E to and the loss incurred by this hypothesis on the last sample.",
            "This parameter is a temperature and can be optimally sad when we know that time horizon and."
        ],
        [
            "This is a well known algorithm and we know that if we apply it with an optimal value for the temperature, we can bound the regret by something of the order of square root of N log N capital N. So we have a quite mild dependencies on the number of expert.",
            "Then this is pretty nice.",
            "Oh, by the way, this can be applied in any kind of setting, so with both inputs and outputs adversarial, so we don't care about any.",
            "Assumption about the way the data are generated, but.",
            "Obviously you don't supplies to our case, in which the inputs are IID.",
            "And even if this dependency on the number of experts is mild is nice.",
            "Nonetheless, it cannot be immediately extended to the case of an infinite number of hypothesis, so this is nice, but the way to extend it to the general case of an infinite number of hypothesis is not that simple."
        ],
        [
            "No."
        ],
        [
            "Let's move to this case and.",
            "We have the assumption that the VC dimension of the hypothesis set is finite, So what follows will be called D. So the basic idea of the algorithm we developed for this case is basically an ebook based algorithm and at the beginning of each ipok we build a suitable sad finite set of hypothesis which is used throughout the epoch and in one ipok we will apply exactly the same exponentially weather forecaster.",
            "But on this suitable sofina set of hypothesis.",
            "So it's true that at the beginning we have this infinite number of hypothesis.",
            "But if we carefully choose a finite number of hypothesis out of it, we can still apply exactly the same exponentially weather forecaster as before and still obtain some good performance guarantees."
        ],
        [
            "So this suitable side of iPod this is generated this way.",
            "So let's say that so far we observed inputs from one time one to time T. So this is the input somehow of the algorithm generating the partitions and the way the set of hypothesis generated is really simple.",
            "First we partition the set of hypothesis in which each class induced by this partition is such that.",
            "Old Apolysis in this class predict exactly the same labels from time one to T. So on this inputs, we guarantee that each class of this partition contains homogeneous predictions somehow.",
            "And now it since we know that this is not the number of classes, is fine it because we know that at most is of the order of T to the power of the VC dimension.",
            "Now we just pick one hypothesis at random or whatever from each of these classes, and this is the finite set of hypothesis we will use in one ipok to do the exponentially weighted forecast are.",
            "So this is pretty simple.",
            "It's just well, at least in theory.",
            "Towards the end I will discuss about computational problems of this approach, But the nice thing is that still we can bound the number of hypothesis we're going to use using this criterion by T to the power of the VC dimension."
        ],
        [
            "So this is the sketch of the algorithm.",
            "This is another tricky point of the algorithm.",
            "Just to make the bound nice in order to prove something.",
            "Interesting, so let's say that we we are at epoch K. What we do is to do the partition as I described before and we use all the past inputs we observed so far.",
            "So from X1 to X of TK, TK is the time instant at which the epoche starts, and so we select a set of representative hypothesis which is capital HK.",
            "Now we run for 2 to the power to from Time Instant TK plus one 2T K plus one which is the final time at which they poke ends.",
            "We're just run an exponentially weighted forecast are on this side of hypothesis, which is fine it we also know the bound on the number of hypothesis it can contain.",
            "We optimally sad once again the Explorer, the temperature factor.",
            "And through all this time instance, we just run the exponentially weighted forecast are so given XT, we pick one hypothesis at random.",
            "Given this distribution, the distribution once again is defined by the weights and at the end of each round we update the weights according to the previous equation with the exponential part of the cumulative loss."
        ],
        [
            "So it turns out that this algorithm satisfies this bound over the regret improbability, so we can bound the regret.",
            "The total regret over North Time instance by something of the order of DVC.",
            "And this is the nice part.",
            "The dependency on the number of time steps is N log N, so exactly the same as before.",
            "And this term comes just from the fact that we are considering high probability bound and so everything holds with probability at least minus one minus beta.",
            "And then there are some constants."
        ],
        [
            "Now we'll go through the proof because it's really simple, so I don't think it's it's too hard to follow.",
            "So this is the definition of the regret we have.",
            "The cumulative loss of our learner, and this is the best cumulative loss of computed according to the whole ipod's side we have now.",
            "Let's say that we just maximize this term by taking the regret the sum of the regret for each epoch.",
            "So this is the sum over all the books, and this is the regret.",
            "In one specific ebook key.",
            "And we will focus on this."
        ],
        [
            "Terms are key.",
            "This term can be splitted in two parts.",
            "The first part is the cumulative loss of our algorithm minus, and this is the tricky part, not the best cumulative loss that can be obtained.",
            "Considering the whole hypothesis said but just the final number of hypothesis we consider in capital HK.",
            "This second term is what is the reminder of the regret, and this is the difference between the best cumulative loss in the finite number of hypothesis capital H and the best commutative loss in the calligraphic H, which is the whole iPod.",
            "This is set.",
            "So what this first term just depends on the learning algorithm we're using and in the specific case we use exponentially weighted for cancer, and so we can bound it exactly as the exponentially weighted forecaster, this second part.",
            "Is the part in which we really apply the stochastic assumption over the inputs?",
            "Because somehow we want to be sure that the hypothesis is in this HK will be useful to predict and epok K and useful means that we do not lose much by restricting our fortunes.",
            "So just this find a number of hypothesis.",
            "Instead of considering the whole set of hypothesis, so this is the.",
            "The main point and using the stochastic assumption over the inputs, we can easily show that this is bounded by something of the order of square root of the C dimension T log T."
        ],
        [
            "And the way to do it is pretty simple.",
            "So the first passage just to take this in from here and make it at a supremum.",
            "Now, the difference between these two losses for the specific classification problem we use can be bounded by just the empirical distance between these hypothesis H&H Prime.",
            "So this is due to the fact of the definition of the loss itself.",
            "So the difference between the losses on.",
            "Two hypothesis can be simply bounded by their number of times they predict something different and this term can be thanks to the stochastic stochastic assumption over the inputs can be seen as just the empirical value of T times the expected distance between the two hypothesis plus.",
            "Some term which goes to zero with the number of.",
            "So sorry without the T which goes to zero with the number of samples.",
            "Here obviously we have everything multiplied by T, so is of the order of T. Log T and here once again we have the VC dimension now of H square which is the VC dimension of the joint.",
            "Sad because here we are considering two hypothesis, not just one, but this is the usual VC bound.",
            "Basically there is nothing new here and once again we can apply it the very same bound.",
            "By now we transform this tee times the expected value by an empirical mean, and this empirical average now is on a different set of inputs.",
            "Now the difference?",
            "The difference between these two hypothesis is computed in the time instance from one to TK.",
            "So the past.",
            "And the nice part is in an obviously another term of this kind appears, but this is absorbed in this order and the nice part here is that by the definition of the capital age of K, this term goes to zero.",
            "In fact, no matter what H is, we can always find an H prime which is in the capital H set, which makes this zero by definition of H. Cape itself, because we know that.",
            "There is always a hypothesis which exactly taste the same sequence of predictions as age, so this term goes to 0.",
            "This is the reminder of the bound, and this is the basically the final term."
        ],
        [
            "So it's really simple.",
            "There is no fancy math here, and now taking everything, putting everything together, we just sum the two terms in which we decompose the original regret for each ebook.",
            "Then we sum over the epochs, and this is the final boundary obtained.",
            "So of the order of N log N times the VC."
        ],
        [
            "Dimension.",
            "Just few words about pot."
        ],
        [
            "Extensions.",
            "In case in which we don't observe the true label, so we just measure the loss.",
            "We moved basically to the bandit information setting, so now it won't enter in details.",
            "But let's say that we have a prediction problem with MK labels now, which in the terminology of bandits, K Arms.",
            "Once again the input is drawn from IID distribution.",
            "So we have a contextual bandit, or abandoned with side information, which is stochastic.",
            "But once again, the adversary can is free to choose the loss function now, not just the label, but the loss function.",
            "So it's a more general setting.",
            "And we just measure we just perceive as feedback the loss of the label we predicted.",
            "Once again the cumulative."
        ],
        [
            "Grad can be bounded as before.",
            "The only difference is that instead of using the exponentially weighted forecast are now we're moving to an axe for like algorithms.",
            "So a bandit algorithm basically and the by just plugging this bound in the general idea of the proof, i.e.",
            "Show you before what we obtain is once again something of this order.",
            "The only difference is now the instead of the VC dimension we have what is called the.",
            "John Dimension, but the idea is exactly the same, it's just the VC dimension generalized for multi label cases.",
            "So the concept is exactly the same as the VC dimension."
        ],
        [
            "Final possible extension."
        ],
        [
            "Location to games and hear the setting is.",
            "We really have an adversary, so we have another player and we both play according to a given input, so I don't know.",
            "Let's say that we draw a card from a deck or we just roll a dice so we have a some sort of input which is stochastic as an event or stochastic event.",
            "We given this stochastic event, we choose a strategy both player A and player B.",
            "So if player is the learner bees adversary or vice versa, and what we do as an action is or as a prediction, is this why had both for player A and player B, which is basically the application of our strategy to the input XD and once again we have two possibilities, full information or bandit, but I won't enter in details about this point."
        ],
        [
            "The only interesting part here is that, OK, I think I can just maybe just this definition.",
            "So according to.",
            "We consider.",
            "0 sum game.",
            "So this means that if I gain something, the other one loses, so it's a 0 sum game because the sum of the two losses is 0 is always 0.",
            "And this is the definition of the value of the game, so I think it's too too much details to explain it.",
            "But the interesting part, let's say that it's just.",
            "The objective is just to learn the Nash equilibrium and from a point of view of our value, that is the losses we we accumulate.",
            "We want to achieve basically the value of the game V so."
        ],
        [
            "In the end, what we can show is that by using more or less the same age to CAD algorithm show you before, so this epoch based algorithm we can show that the empirical average of the losses we incur if both the players play according to the very same algorithm converges to the value of the game, which is from the point of view of the strategy.",
            "It means that the empirical strategy we play converges to a Nash equilibrium and the convergence rate once again is.",
            "Of this order, so it's more or less what we really wanted."
        ],
        [
            "And."
        ],
        [
            "Finally, some comparison.",
            "So just to sum up what I show you in this talk, if the input is stochastic and the output is stochastic, we just use VC dimension as a measure of complexity of.",
            "For our hypothesis set and we obtain analogue times VC dimension, risk minimizer or whatever.",
            "Recent result if both inputs and outputs are adversarial, then we should use the littlestone dimension to measure how complexes are a set of hypothesis and this is the kind of bond we can obtain.",
            "This is the result for the hybrid case in which we have stochastic inputs and adversarial outputs.",
            "And it could be quite surprising to see that the DC dimensions still do the Warwick somehow, and so the bound can still be expressed in terms of the VC dimension of the hypothesis that we have.",
            "And intuitively speaking, the reason is that the VC dimension by definition is itself sort of other sariel measure of complexity, so it's not related to the distribution of the inputs we consider.",
            "So this is somehow the intuition explaining the fact that by dropping the IID assumption over the outputs, we still obtain some nice bounds defined in terms of the VC dimension.",
            "And once again, it's interesting to notice that the Little Stone dimension is greater or equal to the VC dimension.",
            "And here I have."
        ],
        [
            "A very simple example, but I don't think I have time, yeah?"
        ],
        [
            "I think I will move to the conclusions.",
            "Sir.",
            "Once again, they regret bound for the hybrid.",
            "Stochastic adversarial setting in which we employ this this epoch bases together algorithm is of the order of N log N times the VC dimension.",
            "So once again the complexity measure is the same as in the fully stochastic setting, and it's quite straightforward to extend it to multiclass classification, bandits, games and also to regression.",
            "Now we're working on it, but it should be pretty simple and I think there are still some open questions we could be.",
            "Interesting to investigate.",
            "The first one is whether it's possible to use this method analysis.",
            "So for instance, if we consider the case, the very simple case in which the VC dimension is 1 and the Little Stone dimension is infinite, and the only difference is that basically we have, we give the adversary the possibility to choose the inputs.",
            "Now what if we give the user the adversarial inputs, but we add some random noise on them, so this is the typical approach of smooth analysis.",
            "And it would be interesting to see whether it's possible to somehow redefine and find a new complexity measure explaining both the VC dimension and the latest on dimension.",
            "So basically by taking the variance of the noise, we are there to the adversary choice.",
            "If we drop it to 0, then we just recovered the serial case.",
            "If we take it very very large, then we have the fully stochastic case, so it's something in the middle and it would be nice to have this kind of analysis.",
            "Everything is obviously very computationally inefficient, and because the way we build the partition is not that simple and it takes a lot of time to find the right partition and the right hypothesis to use, and it would be interesting to understand whether it's possible to have a computationally efficient version, but I am concerned about the regret.",
            "Probably we will lose something in terms of the regret and.",
            "The reason why I think so is that there is a quite similar algorithm for online transductive learning, so it's not really stochastic setting for the inputs, but the inputs are known in advance and they show that if you use an efficient inefficient algorithm you have more or less the same bound as we have.",
            "But if you use an efficient algorithm, you lose something in terms of the regret, so it would be quite interesting and in the end it would be nice to have some empirical results because so far we just had the.",
            "Theoretical analysis and.",
            "No real date."
        ],
        [
            "And that's it.",
            "Thank you very much for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bill.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I will try to start with a motivating example and not so serious motivating example, but maybe.",
                    "label": 1
                },
                {
                    "sent": "It will do the work, so let's say that we have a very beautiful girl and we want to predict whether the answer to our invitation for dinner tonight will be yes or no.",
                    "label": 0
                },
                {
                    "sent": "This is a quite real life prediction problem.",
                    "label": 1
                },
                {
                    "sent": "Maybe not so serious now.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's like the ones we used to deal with in machine learning, but it's interesting to analyze the kind of problem prediction problem we're facing, because usually we can consider inputs.",
                    "label": 0
                },
                {
                    "sent": "In this case, the girl described by this set of features, height, weight and so on as just drawn from fixed and stationary probability distribution.",
                    "label": 0
                },
                {
                    "sent": "This is quite reasonable, so we have a set of girls and we just pick one at random, but.",
                    "label": 0
                },
                {
                    "sent": "What about the output?",
                    "label": 0
                },
                {
                    "sent": "So the outcome?",
                    "label": 0
                },
                {
                    "sent": "The answer yes or no in this case is not that reasonable to consider it as coming from a fixed distribution, and we can consider it as coming from an adversarial.",
                    "label": 0
                },
                {
                    "sent": "Source so we can say that basically the relationship between inputs and outputs is so complex to formalize that it doesn't make any sense to consider is is.",
                    "label": 1
                },
                {
                    "sent": "Fix is coming from a fixed distribution and so it's better to consider it as adversarial.",
                    "label": 0
                },
                {
                    "sent": "So this can mean basically anything, so I don't know.",
                    "label": 1
                },
                {
                    "sent": "We have a distribution with changes in time, or we have really an adversary choosing the output at each time step in order to make our prediction the most difficult possible.",
                    "label": 1
                },
                {
                    "sent": "So in the end we can consider this prediction problem as a hybrid stochastic as far as the inputs are concerned.",
                    "label": 0
                },
                {
                    "sent": "Adversarial for the outputs problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a little bit more serious example, let's say that we have a new model of a mobile phone.",
                    "label": 0
                },
                {
                    "sent": "We have a set of users.",
                    "label": 0
                },
                {
                    "sent": "Set of users.",
                    "label": 0
                },
                {
                    "sent": "Maybe they just come from a fixed distribution.",
                    "label": 0
                },
                {
                    "sent": "Once again we describe the users using a set of features.",
                    "label": 0
                },
                {
                    "sent": "I don't know the age, the salary, the Saxon, so on and we want to predict whether they're going to buy or not.",
                    "label": 0
                },
                {
                    "sent": "Our new model of mobile phone.",
                    "label": 1
                },
                {
                    "sent": "And once again is quite difficult to formalize the kind of relationship between in.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's an outputs and so we prefer to consider it as adversarial.",
                    "label": 0
                },
                {
                    "sent": "So in the kind of terminology we using this worship, we say that inputs are ID from a fixed distribution, while outputs are simply adversarial.",
                    "label": 0
                },
                {
                    "sent": "So no matter what the kind of distribution or adversary they come from.",
                    "label": 0
                },
                {
                    "sent": "And now moving to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The album outline of the presentation I will focus just on the simple case of online classification problem.",
                    "label": 1
                },
                {
                    "sent": "Actually the work can be extended to any kind of prediction problem.",
                    "label": 0
                },
                {
                    "sent": "We recently extended it also to regression problems, so not just classification and after defining the general case of align classification problem, I will enter in details about the hybrid stochastic adversarial setting.",
                    "label": 0
                },
                {
                    "sent": "I will show you basically the algorithm we developed.",
                    "label": 0
                },
                {
                    "sent": "And I will try to analyze it theoretically, showing that it has some interesting properties.",
                    "label": 0
                },
                {
                    "sent": "I think I will go very fast through the possible extensions in the setting of bandit information and possible application to games.",
                    "label": 1
                },
                {
                    "sent": "And finally I will discuss and conclude the presentation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the very high level definition of online classification problem.",
                    "label": 1
                },
                {
                    "sent": "We have an input space acts and not put space.",
                    "label": 0
                },
                {
                    "sent": "Let's consider just the binary classification problem.",
                    "label": 0
                },
                {
                    "sent": "So labeled zero and one hypothesis space H in which each hypothesis is a mapping between inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "And since we are considering an online learning problem, we consider each round specific.",
                    "label": 1
                },
                {
                    "sent": "Input is given to the learner, so we have this XT which is obviously.",
                    "label": 0
                },
                {
                    "sent": "An element of the input space acts and the learner is supposed to choose one specific hypothesis in the side of available hypothesis and as a consequence it will predict the label Y had T, which is the result of the mapping of the function HT to the given input XD.",
                    "label": 0
                },
                {
                    "sent": "After that, since we are considering what is called usually in online learning, the full information case, the true label is revealed to the learner and the learner will also incur a loss, which is basically whether the prediction was correct or not.",
                    "label": 1
                },
                {
                    "sent": "And once again, these can be generalized to any loss function, but I will go with this one because makes everything much simpler.",
                    "label": 0
                },
                {
                    "sent": "So since we are working in an online setting in which the outputs as we will see are not drawn from a fixed distribution, we are interested in minimizing the cumulative regret, which is basically the difference between the performance, the cumulative performance of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we sum the losses incurred by the learner from step one to step North, which is.",
                    "label": 0
                },
                {
                    "sent": "Let's say the Aurizon of our learning problem.",
                    "label": 0
                },
                {
                    "sent": "Mine is this term, which is the best cumulative loss we can obtain by using one fixed hypothesis in the set of hypothesis age.",
                    "label": 0
                },
                {
                    "sent": "So this is the performance of the learner and this is somehow the target performance.",
                    "label": 0
                },
                {
                    "sent": "The best performance we can obtain on given the set of hypothesis we have.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, if we consider that online learning problem and as you notice, probably I didn't specify how this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estes generated and how this white is generated.",
                    "label": 0
                },
                {
                    "sent": "This is just a general model.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But what if we?",
                    "label": 0
                },
                {
                    "sent": "Say that both inputs and outputs are drawn from a fixed distribution, so IID data.",
                    "label": 0
                },
                {
                    "sent": "This is the usual fully stochastic setting, and we can easily show that the regret the cumulative regret we can obtain by just using an empirical risk minimizer is of the order of N log N with respect to dependency of the time horizon with a complexity theory, which is the usual VC dimension term, which depends obviously on the set of hypothesis we have.",
                    "label": 1
                },
                {
                    "sent": "This is pretty fair and.",
                    "label": 0
                },
                {
                    "sent": "There is.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Surprising it, this is a little bit more interesting.",
                    "label": 0
                },
                {
                    "sent": "This is a very recent result by Band of Eden at all presented this year at cold and they show that if we drop the IID assumption in an online perspective, both on inputs and outputs, what changes is not somehow the dependency on the time horizon, but the correct measure of complexity for our iPod to space.",
                    "label": 0
                },
                {
                    "sent": "This is pretty interesting and this is called the Littlestone dimension.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many of you are familiar with this concept, but I will discuss it maybe in more details towards the towards the end of the talk, but the only thing which is interesting now is that the Little Stone dimension is greater or equal to the VC dimension, so there is a relationship, but we already know that in general this is bigger than the C dimension and I will show you if I have time towards the end of the talk.",
                    "label": 0
                },
                {
                    "sent": "That there are also very simple example in which the VC dimension maybe is 1 and the Little Stone dimension is infinite.",
                    "label": 0
                },
                {
                    "sent": "So there are quite nasty cases in which.",
                    "label": 0
                },
                {
                    "sent": "Giving the possibility to an adversary to choose both X&Y is going to be very bad for the learning algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is interesting here is that if we just drop the IID assumption on the outputs, but we still keep it for the inputs, which sometimes could be reasonable, the kind of bound we obtain is exactly the same as in the fully stochastic setting, meaning that basically by just giving the possibility to the adversary to choose the labels but not the inputs doesn't really make the bound the kind of performance we have worse.",
                    "label": 0
                },
                {
                    "sent": "Then the fully stochastic setting and I think this is the main message.",
                    "label": 1
                },
                {
                    "sent": "The take home message of this token, this work, and now we will.",
                    "label": 0
                },
                {
                    "sent": "Try to prove this bound so I will show you an algorithm able to achieve that order.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regret.",
                    "label": 0
                },
                {
                    "sent": "So just to cast the general online classification problem into the hybrid stochastic adversarial setting here, now we say that X of T comes from IID sample from a fixed distribution.",
                    "label": 1
                },
                {
                    "sent": "B&YT is adversarially chosen, so can be anything basically.",
                    "label": 0
                },
                {
                    "sent": "At this point, which is simultaneously obviously because the adversary shouldn't be able to see our prediction before generating the YT, otherwise it wouldn't be fair.",
                    "label": 1
                },
                {
                    "sent": "So now that the main question is how can we bound this regret in this kind of setting?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, I will recall briefly the result we have for exponentially weighted forecasters.",
                    "label": 0
                },
                {
                    "sent": "In the case we have a finite number of experts.",
                    "label": 1
                },
                {
                    "sent": "So in our notation we say that the khaligraph gauge.",
                    "label": 0
                },
                {
                    "sent": "So the set of positive hypothesis is finite and it contains just an predictors.",
                    "label": 1
                },
                {
                    "sent": "In this case, we can just apply the exponentially weighted forecaster, which basically maintains a distribution over the hypothesis and just update distribution at each round by considering the cumulative.",
                    "label": 0
                },
                {
                    "sent": "Loss in court by that hypothesis until time T. So just sketch of the algorithm, we initialize the weights over all the hypothesis we have and for at each time step we observe the input we built a distribution over all the hypothesis that an iPod physis we have and the distribution is just basically taking the weight and normalizing it and we predict.",
                    "label": 1
                },
                {
                    "sent": "HD win with HD drone from this distribution and the way we update the distribution is just the weight that the way we update the weights.",
                    "label": 0
                },
                {
                    "sent": "And here we have the exponential term which is minus E to and the loss incurred by this hypothesis on the last sample.",
                    "label": 0
                },
                {
                    "sent": "This parameter is a temperature and can be optimally sad when we know that time horizon and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a well known algorithm and we know that if we apply it with an optimal value for the temperature, we can bound the regret by something of the order of square root of N log N capital N. So we have a quite mild dependencies on the number of expert.",
                    "label": 0
                },
                {
                    "sent": "Then this is pretty nice.",
                    "label": 0
                },
                {
                    "sent": "Oh, by the way, this can be applied in any kind of setting, so with both inputs and outputs adversarial, so we don't care about any.",
                    "label": 0
                },
                {
                    "sent": "Assumption about the way the data are generated, but.",
                    "label": 0
                },
                {
                    "sent": "Obviously you don't supplies to our case, in which the inputs are IID.",
                    "label": 0
                },
                {
                    "sent": "And even if this dependency on the number of experts is mild is nice.",
                    "label": 0
                },
                {
                    "sent": "Nonetheless, it cannot be immediately extended to the case of an infinite number of hypothesis, so this is nice, but the way to extend it to the general case of an infinite number of hypothesis is not that simple.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's move to this case and.",
                    "label": 0
                },
                {
                    "sent": "We have the assumption that the VC dimension of the hypothesis set is finite, So what follows will be called D. So the basic idea of the algorithm we developed for this case is basically an ebook based algorithm and at the beginning of each ipok we build a suitable sad finite set of hypothesis which is used throughout the epoch and in one ipok we will apply exactly the same exponentially weather forecaster.",
                    "label": 1
                },
                {
                    "sent": "But on this suitable sofina set of hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So it's true that at the beginning we have this infinite number of hypothesis.",
                    "label": 1
                },
                {
                    "sent": "But if we carefully choose a finite number of hypothesis out of it, we can still apply exactly the same exponentially weather forecaster as before and still obtain some good performance guarantees.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this suitable side of iPod this is generated this way.",
                    "label": 0
                },
                {
                    "sent": "So let's say that so far we observed inputs from one time one to time T. So this is the input somehow of the algorithm generating the partitions and the way the set of hypothesis generated is really simple.",
                    "label": 0
                },
                {
                    "sent": "First we partition the set of hypothesis in which each class induced by this partition is such that.",
                    "label": 0
                },
                {
                    "sent": "Old Apolysis in this class predict exactly the same labels from time one to T. So on this inputs, we guarantee that each class of this partition contains homogeneous predictions somehow.",
                    "label": 0
                },
                {
                    "sent": "And now it since we know that this is not the number of classes, is fine it because we know that at most is of the order of T to the power of the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "Now we just pick one hypothesis at random or whatever from each of these classes, and this is the finite set of hypothesis we will use in one ipok to do the exponentially weighted forecast are.",
                    "label": 0
                },
                {
                    "sent": "So this is pretty simple.",
                    "label": 0
                },
                {
                    "sent": "It's just well, at least in theory.",
                    "label": 0
                },
                {
                    "sent": "Towards the end I will discuss about computational problems of this approach, But the nice thing is that still we can bound the number of hypothesis we're going to use using this criterion by T to the power of the VC dimension.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the sketch of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is another tricky point of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Just to make the bound nice in order to prove something.",
                    "label": 0
                },
                {
                    "sent": "Interesting, so let's say that we we are at epoch K. What we do is to do the partition as I described before and we use all the past inputs we observed so far.",
                    "label": 1
                },
                {
                    "sent": "So from X1 to X of TK, TK is the time instant at which the epoche starts, and so we select a set of representative hypothesis which is capital HK.",
                    "label": 1
                },
                {
                    "sent": "Now we run for 2 to the power to from Time Instant TK plus one 2T K plus one which is the final time at which they poke ends.",
                    "label": 0
                },
                {
                    "sent": "We're just run an exponentially weighted forecast are on this side of hypothesis, which is fine it we also know the bound on the number of hypothesis it can contain.",
                    "label": 0
                },
                {
                    "sent": "We optimally sad once again the Explorer, the temperature factor.",
                    "label": 0
                },
                {
                    "sent": "And through all this time instance, we just run the exponentially weighted forecast are so given XT, we pick one hypothesis at random.",
                    "label": 0
                },
                {
                    "sent": "Given this distribution, the distribution once again is defined by the weights and at the end of each round we update the weights according to the previous equation with the exponential part of the cumulative loss.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it turns out that this algorithm satisfies this bound over the regret improbability, so we can bound the regret.",
                    "label": 0
                },
                {
                    "sent": "The total regret over North Time instance by something of the order of DVC.",
                    "label": 0
                },
                {
                    "sent": "And this is the nice part.",
                    "label": 0
                },
                {
                    "sent": "The dependency on the number of time steps is N log N, so exactly the same as before.",
                    "label": 1
                },
                {
                    "sent": "And this term comes just from the fact that we are considering high probability bound and so everything holds with probability at least minus one minus beta.",
                    "label": 1
                },
                {
                    "sent": "And then there are some constants.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we'll go through the proof because it's really simple, so I don't think it's it's too hard to follow.",
                    "label": 0
                },
                {
                    "sent": "So this is the definition of the regret we have.",
                    "label": 1
                },
                {
                    "sent": "The cumulative loss of our learner, and this is the best cumulative loss of computed according to the whole ipod's side we have now.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we just maximize this term by taking the regret the sum of the regret for each epoch.",
                    "label": 1
                },
                {
                    "sent": "So this is the sum over all the books, and this is the regret.",
                    "label": 0
                },
                {
                    "sent": "In one specific ebook key.",
                    "label": 0
                },
                {
                    "sent": "And we will focus on this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Terms are key.",
                    "label": 0
                },
                {
                    "sent": "This term can be splitted in two parts.",
                    "label": 0
                },
                {
                    "sent": "The first part is the cumulative loss of our algorithm minus, and this is the tricky part, not the best cumulative loss that can be obtained.",
                    "label": 0
                },
                {
                    "sent": "Considering the whole hypothesis said but just the final number of hypothesis we consider in capital HK.",
                    "label": 0
                },
                {
                    "sent": "This second term is what is the reminder of the regret, and this is the difference between the best cumulative loss in the finite number of hypothesis capital H and the best commutative loss in the calligraphic H, which is the whole iPod.",
                    "label": 0
                },
                {
                    "sent": "This is set.",
                    "label": 0
                },
                {
                    "sent": "So what this first term just depends on the learning algorithm we're using and in the specific case we use exponentially weighted for cancer, and so we can bound it exactly as the exponentially weighted forecaster, this second part.",
                    "label": 0
                },
                {
                    "sent": "Is the part in which we really apply the stochastic assumption over the inputs?",
                    "label": 0
                },
                {
                    "sent": "Because somehow we want to be sure that the hypothesis is in this HK will be useful to predict and epok K and useful means that we do not lose much by restricting our fortunes.",
                    "label": 0
                },
                {
                    "sent": "So just this find a number of hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Instead of considering the whole set of hypothesis, so this is the.",
                    "label": 0
                },
                {
                    "sent": "The main point and using the stochastic assumption over the inputs, we can easily show that this is bounded by something of the order of square root of the C dimension T log T.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the way to do it is pretty simple.",
                    "label": 0
                },
                {
                    "sent": "So the first passage just to take this in from here and make it at a supremum.",
                    "label": 0
                },
                {
                    "sent": "Now, the difference between these two losses for the specific classification problem we use can be bounded by just the empirical distance between these hypothesis H&H Prime.",
                    "label": 0
                },
                {
                    "sent": "So this is due to the fact of the definition of the loss itself.",
                    "label": 0
                },
                {
                    "sent": "So the difference between the losses on.",
                    "label": 0
                },
                {
                    "sent": "Two hypothesis can be simply bounded by their number of times they predict something different and this term can be thanks to the stochastic stochastic assumption over the inputs can be seen as just the empirical value of T times the expected distance between the two hypothesis plus.",
                    "label": 0
                },
                {
                    "sent": "Some term which goes to zero with the number of.",
                    "label": 0
                },
                {
                    "sent": "So sorry without the T which goes to zero with the number of samples.",
                    "label": 0
                },
                {
                    "sent": "Here obviously we have everything multiplied by T, so is of the order of T. Log T and here once again we have the VC dimension now of H square which is the VC dimension of the joint.",
                    "label": 0
                },
                {
                    "sent": "Sad because here we are considering two hypothesis, not just one, but this is the usual VC bound.",
                    "label": 0
                },
                {
                    "sent": "Basically there is nothing new here and once again we can apply it the very same bound.",
                    "label": 0
                },
                {
                    "sent": "By now we transform this tee times the expected value by an empirical mean, and this empirical average now is on a different set of inputs.",
                    "label": 0
                },
                {
                    "sent": "Now the difference?",
                    "label": 0
                },
                {
                    "sent": "The difference between these two hypothesis is computed in the time instance from one to TK.",
                    "label": 0
                },
                {
                    "sent": "So the past.",
                    "label": 0
                },
                {
                    "sent": "And the nice part is in an obviously another term of this kind appears, but this is absorbed in this order and the nice part here is that by the definition of the capital age of K, this term goes to zero.",
                    "label": 0
                },
                {
                    "sent": "In fact, no matter what H is, we can always find an H prime which is in the capital H set, which makes this zero by definition of H. Cape itself, because we know that.",
                    "label": 0
                },
                {
                    "sent": "There is always a hypothesis which exactly taste the same sequence of predictions as age, so this term goes to 0.",
                    "label": 0
                },
                {
                    "sent": "This is the reminder of the bound, and this is the basically the final term.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's really simple.",
                    "label": 0
                },
                {
                    "sent": "There is no fancy math here, and now taking everything, putting everything together, we just sum the two terms in which we decompose the original regret for each ebook.",
                    "label": 1
                },
                {
                    "sent": "Then we sum over the epochs, and this is the final boundary obtained.",
                    "label": 1
                },
                {
                    "sent": "So of the order of N log N times the VC.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dimension.",
                    "label": 0
                },
                {
                    "sent": "Just few words about pot.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Extensions.",
                    "label": 0
                },
                {
                    "sent": "In case in which we don't observe the true label, so we just measure the loss.",
                    "label": 0
                },
                {
                    "sent": "We moved basically to the bandit information setting, so now it won't enter in details.",
                    "label": 1
                },
                {
                    "sent": "But let's say that we have a prediction problem with MK labels now, which in the terminology of bandits, K Arms.",
                    "label": 0
                },
                {
                    "sent": "Once again the input is drawn from IID distribution.",
                    "label": 0
                },
                {
                    "sent": "So we have a contextual bandit, or abandoned with side information, which is stochastic.",
                    "label": 1
                },
                {
                    "sent": "But once again, the adversary can is free to choose the loss function now, not just the label, but the loss function.",
                    "label": 0
                },
                {
                    "sent": "So it's a more general setting.",
                    "label": 0
                },
                {
                    "sent": "And we just measure we just perceive as feedback the loss of the label we predicted.",
                    "label": 0
                },
                {
                    "sent": "Once again the cumulative.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Grad can be bounded as before.",
                    "label": 0
                },
                {
                    "sent": "The only difference is that instead of using the exponentially weighted forecast are now we're moving to an axe for like algorithms.",
                    "label": 0
                },
                {
                    "sent": "So a bandit algorithm basically and the by just plugging this bound in the general idea of the proof, i.e.",
                    "label": 0
                },
                {
                    "sent": "Show you before what we obtain is once again something of this order.",
                    "label": 0
                },
                {
                    "sent": "The only difference is now the instead of the VC dimension we have what is called the.",
                    "label": 0
                },
                {
                    "sent": "John Dimension, but the idea is exactly the same, it's just the VC dimension generalized for multi label cases.",
                    "label": 0
                },
                {
                    "sent": "So the concept is exactly the same as the VC dimension.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Final possible extension.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location to games and hear the setting is.",
                    "label": 0
                },
                {
                    "sent": "We really have an adversary, so we have another player and we both play according to a given input, so I don't know.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we draw a card from a deck or we just roll a dice so we have a some sort of input which is stochastic as an event or stochastic event.",
                    "label": 0
                },
                {
                    "sent": "We given this stochastic event, we choose a strategy both player A and player B.",
                    "label": 0
                },
                {
                    "sent": "So if player is the learner bees adversary or vice versa, and what we do as an action is or as a prediction, is this why had both for player A and player B, which is basically the application of our strategy to the input XD and once again we have two possibilities, full information or bandit, but I won't enter in details about this point.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The only interesting part here is that, OK, I think I can just maybe just this definition.",
                    "label": 0
                },
                {
                    "sent": "So according to.",
                    "label": 0
                },
                {
                    "sent": "We consider.",
                    "label": 0
                },
                {
                    "sent": "0 sum game.",
                    "label": 0
                },
                {
                    "sent": "So this means that if I gain something, the other one loses, so it's a 0 sum game because the sum of the two losses is 0 is always 0.",
                    "label": 0
                },
                {
                    "sent": "And this is the definition of the value of the game, so I think it's too too much details to explain it.",
                    "label": 0
                },
                {
                    "sent": "But the interesting part, let's say that it's just.",
                    "label": 0
                },
                {
                    "sent": "The objective is just to learn the Nash equilibrium and from a point of view of our value, that is the losses we we accumulate.",
                    "label": 0
                },
                {
                    "sent": "We want to achieve basically the value of the game V so.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the end, what we can show is that by using more or less the same age to CAD algorithm show you before, so this epoch based algorithm we can show that the empirical average of the losses we incur if both the players play according to the very same algorithm converges to the value of the game, which is from the point of view of the strategy.",
                    "label": 0
                },
                {
                    "sent": "It means that the empirical strategy we play converges to a Nash equilibrium and the convergence rate once again is.",
                    "label": 1
                },
                {
                    "sent": "Of this order, so it's more or less what we really wanted.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, some comparison.",
                    "label": 0
                },
                {
                    "sent": "So just to sum up what I show you in this talk, if the input is stochastic and the output is stochastic, we just use VC dimension as a measure of complexity of.",
                    "label": 0
                },
                {
                    "sent": "For our hypothesis set and we obtain analogue times VC dimension, risk minimizer or whatever.",
                    "label": 0
                },
                {
                    "sent": "Recent result if both inputs and outputs are adversarial, then we should use the littlestone dimension to measure how complexes are a set of hypothesis and this is the kind of bond we can obtain.",
                    "label": 0
                },
                {
                    "sent": "This is the result for the hybrid case in which we have stochastic inputs and adversarial outputs.",
                    "label": 0
                },
                {
                    "sent": "And it could be quite surprising to see that the DC dimensions still do the Warwick somehow, and so the bound can still be expressed in terms of the VC dimension of the hypothesis that we have.",
                    "label": 0
                },
                {
                    "sent": "And intuitively speaking, the reason is that the VC dimension by definition is itself sort of other sariel measure of complexity, so it's not related to the distribution of the inputs we consider.",
                    "label": 1
                },
                {
                    "sent": "So this is somehow the intuition explaining the fact that by dropping the IID assumption over the outputs, we still obtain some nice bounds defined in terms of the VC dimension.",
                    "label": 1
                },
                {
                    "sent": "And once again, it's interesting to notice that the Little Stone dimension is greater or equal to the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "And here I have.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A very simple example, but I don't think I have time, yeah?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think I will move to the conclusions.",
                    "label": 0
                },
                {
                    "sent": "Sir.",
                    "label": 0
                },
                {
                    "sent": "Once again, they regret bound for the hybrid.",
                    "label": 0
                },
                {
                    "sent": "Stochastic adversarial setting in which we employ this this epoch bases together algorithm is of the order of N log N times the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "So once again the complexity measure is the same as in the fully stochastic setting, and it's quite straightforward to extend it to multiclass classification, bandits, games and also to regression.",
                    "label": 1
                },
                {
                    "sent": "Now we're working on it, but it should be pretty simple and I think there are still some open questions we could be.",
                    "label": 0
                },
                {
                    "sent": "Interesting to investigate.",
                    "label": 0
                },
                {
                    "sent": "The first one is whether it's possible to use this method analysis.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if we consider the case, the very simple case in which the VC dimension is 1 and the Little Stone dimension is infinite, and the only difference is that basically we have, we give the adversary the possibility to choose the inputs.",
                    "label": 0
                },
                {
                    "sent": "Now what if we give the user the adversarial inputs, but we add some random noise on them, so this is the typical approach of smooth analysis.",
                    "label": 0
                },
                {
                    "sent": "And it would be interesting to see whether it's possible to somehow redefine and find a new complexity measure explaining both the VC dimension and the latest on dimension.",
                    "label": 0
                },
                {
                    "sent": "So basically by taking the variance of the noise, we are there to the adversary choice.",
                    "label": 0
                },
                {
                    "sent": "If we drop it to 0, then we just recovered the serial case.",
                    "label": 0
                },
                {
                    "sent": "If we take it very very large, then we have the fully stochastic case, so it's something in the middle and it would be nice to have this kind of analysis.",
                    "label": 0
                },
                {
                    "sent": "Everything is obviously very computationally inefficient, and because the way we build the partition is not that simple and it takes a lot of time to find the right partition and the right hypothesis to use, and it would be interesting to understand whether it's possible to have a computationally efficient version, but I am concerned about the regret.",
                    "label": 1
                },
                {
                    "sent": "Probably we will lose something in terms of the regret and.",
                    "label": 0
                },
                {
                    "sent": "The reason why I think so is that there is a quite similar algorithm for online transductive learning, so it's not really stochastic setting for the inputs, but the inputs are known in advance and they show that if you use an efficient inefficient algorithm you have more or less the same bound as we have.",
                    "label": 0
                },
                {
                    "sent": "But if you use an efficient algorithm, you lose something in terms of the regret, so it would be quite interesting and in the end it would be nice to have some empirical results because so far we just had the.",
                    "label": 0
                },
                {
                    "sent": "Theoretical analysis and.",
                    "label": 0
                },
                {
                    "sent": "No real date.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                }
            ]
        }
    }
}