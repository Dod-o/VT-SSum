{
    "id": "xesv5capoi7kzblsdoqjt7hxn5hdjstd",
    "title": "A Decentralized Architecture for Sharing and Querying Semantic Data",
    "info": {
        "author": [
            "Christian Aebeloe, Aalborg University"
        ],
        "published": "July 19, 2019",
        "recorded": "June 2019",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2019_aebeloe_decentralized_architecture/",
    "segmentation": [
        [
            "So."
        ],
        [
            "Today open link datasets are often unavailable.",
            "In fact, the recent study found that over half of all public sparkle in points have left the 95% availability.",
            "This means in some cases following links or common entities between different and separate.",
            "Datasets can be impossible since the data is just not available.",
            "The."
        ],
        [
            "And for this often is that these kinds of interfaces, especially sparkle implants, require considerable considerable amounts of resources to maintain.",
            "And without any sort of incentive for this open datasets, it becomes a huge burden for the providers.",
            "Some recent efforts have proposed to introduce monetary incentives to this.",
            "However, we argue that the burden can be lifted from the providers through decentralisation."
        ],
        [
            "The reason why we mentioned decentralisation is it has previously been been researched and evidence to actually improve availability of of these kinds of datasets.",
            "For example, triple power fragments that proved to lower the computation under the server and thus improve availability during high current loads.",
            "Then we have for example Alissas, which replicates through pattern fragments across multiple servers, which is closer to what we want to achieve, but commonly in all these approaches we have either still a single point of entry or a fixed set of service in a fixed set of replicated fragments.",
            "So we still face some of the same issues and we.",
            "And we don't really have an architecture in which data sets can dynamically be added, and so on.",
            "So to achieve this kind of dynamic architecture, we look towards P."
        ],
        [
            "Peer systems where that two, generally two types of peer to peer system structure peer to peer systems which organized appears into some overlay.",
            "For example, distributed hash tables.",
            "The problem with these kind of systems is that if nodes leave and join the network frequently, you have to recompute that overlay all the time.",
            "So instead, in order to allow for notes to leave and join the network, we look to unstructured peer to peer system which have seemingly random connections between nodes.",
            "And thus I'm all reliable during doing churn because you don't have to recompute the overlay all the time."
        ],
        [
            "So to lift the burden of data providers, we propose the architecture called picnic, which is a peer to peer client for query processing over semantic data.",
            "And is based on unstructured peer to peer architecture.",
            "Such that each client maintains a limited local data store that uses HTTP.",
            "The reason we use HTTPS because in such architectures the amount of resources each node have available can vary quite a bit, so we want to use a compressed representation of RDF in order to use this little resources as possible.",
            "For a user wanting to to create these, all these datasets that are being uploaded to a network, they can do so just by knowing any node in the network and query on any node network."
        ],
        [
            "So of course it's.",
            "These open datasets can be quite large, millions or even billions of triples, and that's not really feasible to store on on replicate throughout a network with limited resources, and so we split these datasets into smaller fragments.",
            "In order to be able to replicate these.",
            "Do you say across the network so a fragment contains a set of triples, which is the.",
            "It was a subset of the original Knowledge Graph.",
            "Contains a set of notes or point us to notes that contains the fragment.",
            "A identifier, an identification function that, given a triple pattern, could determine whether or not the fragmente may continue answers to so if we look at this example down here, we have a bunch of tables.",
            "This could be the triples in a fragment.",
            "We note that all of them has the same predicate, which is his capital.",
            "And thus we can build a predicate based identification function that returns true if the predicate in the triple pattern is the same predicate as all the triples have in the in the fragment, or if the predicate is a variable and returns false otherwise.",
            "So for this trip and it will return true because the predicate is has capital.",
            "Well, for this triple pattern it would return false since the.",
            "Predicate is not his capital."
        ],
        [
            "So to represent entire knowledge graphs in a picnic network we.",
            "We introduced a notion of datasets and the data set kind of system closes.",
            "It closes the set of fragments from the original Knowledge Graph.",
            "But most importantly about datasets, they contain an owner note, which is the note to which the data set or the Knowledge Graph was originally.",
            "Upload 2.",
            "The owner's job is to make sure that all the fragments in the data set are replicated among or over enough nodes.",
            "So if a node fails or leaves the network which had one of the fragments, the owner will make sure to.",
            "Replicate this fragment to a new new data set so we have these three fragments.",
            "The datasets from the original Knowledge Graph just encloses the three fragments."
        ],
        [
            "So how do we fragment?",
            "Well, first, introduce customizable approach to fragmentation becausw.",
            "Sudden different kinds of fragmentation functions could be optimized for different kinds of queries.",
            "Therefore, for this paper we choose to.",
            "To have a predicate based identification function, which essentially means.",
            "The fragment is created for each unique predicate, so in the knowledge Graph here we create a fragment for all the troubles with his capital as the predicate one with all the triples that has made offers to predicate and so on.",
            "So we get these fragments."
        ],
        [
            "As I mentioned, the.",
            "Such a peer to peer architecture is based on clients also acting as service.",
            "So, so they contain a limited data store.",
            "In our case, this is just a set of fragments that are located on the server that on the other note that is its local data store.",
            "A node contains also some datasets that it owns, so that was uploaded to the specific node.",
            "And so if there are any datasets in this set.",
            "The node would have to maintain this data set.",
            "And then it's not contains a list of neighbors, which is the local view over the network.",
            "In an unstructured switch, peer network such as this, it's not really feasible to have any sort of global knowledge, so we cannot know all the all the other nodes in the network.",
            "And so this is a limited view over the network."
        ],
        [
            "Of course it's important to always up have an updated view over the network, but it's also important to always have some nodes close by that have related data, but it's also important to have some nodes close by that have unrelated data, and the reason for this is if a query is issued on the node, which on which the note has related data, two, that's a higher change.",
            "We can complete the query if completely answer if we have access to.",
            "2 notes with related data.",
            "If you query is issued that we do not have any related data to, there's a high chance we can reach part of the network that does.",
            "If we have some random neighbors.",
            "The way we achieve this is through frequent shuffles, that is, a node selects a random one of its neighbors to which it sends all of its least related neighbors.",
            "That way, we ensure that all of the all of the most related neighbors may.",
            "Are still in the interview.",
            "So determining which neighbors are the least related is based on based on the relatedness or this relatedness of the data in the node which is based on the general ability of fragments.",
            "So two fragments are joinable if they share some common entity in either the subject objects.",
            "So the list of joinable fragments between two nodes and one and two at all the fragments in one that are joinable with some fragmented into.",
            "And so when, when calculating which neighbors true to shuffle away, which neighbors are the least related, we give them a score that is the rate of which fragments in the original note are joinable with some fragment in the other note.",
            "And then this function is just a objective function that.",
            "Returns their kaliste related numbers.",
            "So."
        ],
        [
            "In this example, we have the same troubles as before in four wants to shuffle within two and with the shuffling sev one, it means only its least related neighbor will be shuffled away.",
            "And two is already selected and five as its least related neighbor.",
            "And So what we do is essentially we go through all the neighbors from from info and calculate its relatedness score.",
            "So if we start buying one, we see that if four is joinable with if one.",
            "On multiple URLs, for example Greece, Athens, Norway in Oslo.",
            "And if two is joinable with the five, unplug it and so both fragments and then for joinable with some fragmente in one and thus the relatedness scores one.",
            "Same is the case fine too, although here if far is joinable with F3 instead on Athens.",
            "If five is obviously still joinable with two.",
            "Four in three, though, we see that if five is joinable, with neither if one or three, and so only one of the fragments in four actually joinable with one of the fragments in in three.",
            "And thus the related in this course 1/2, which is the lowest and thus.",
            "And three is shuffled with within 5."
        ],
        [
            "So.",
            "Preprocessing follows a flooding approach.",
            "That means when a node receives a triple pattern to to to evaluate evaluate in this local data store and forward the request to all of its neighbors, and this happens for a certain amount of steps called the time to live value.",
            "So let's say a sparkle query is executed or issued on in seven with a time to live value of two.",
            "For each of the triple patterns.",
            "And seven will evaluate them on its local data store and forward them to its neighbors, which will, with one list TTL value.",
            "The neighbors will do the same and forward.",
            "The request to their neighbors with a TTL value of 0.",
            "And since the time to value is now 0, these notes will not forward the request any further.",
            "The notes that have answers.",
            "Will return the answers of the bindings for variables from the travel patterns directly to to the.",
            "Note that the couriers issued on.",
            "For the preprocessing approach on the query on the, note that the query is issued on.",
            "We implemented three different approaches, single, which is spaced on or.",
            "Which follows from the triple pattern fragment style of processing queries where bindings from previously evaluated triple patterns are replaced in the triple pattern individually and floated through the network.",
            "Bug which is based on bindings restricted triple pattern FRAGMENTE works much the same way, only wear these findings about together so we flood the network list times.",
            "And then we have full words only flood the network with the original parents and thus unbounded."
        ],
        [
            "So let's see how this works.",
            "We start with a single approach and this query finds all all countries and capitals that have hosted SWC so.",
            "The first thing we do is select the trouble pattern with the least amount of variables.",
            "In this case T2.",
            "We flush that through the network for the given amount of steps.",
            "In this case, we find we find out that if three's identification function returns true for the triple pattern and us, we look for bindings for V2 in.",
            "If three and get the bonding zubiena and essence.",
            "When we evaluate CP one, we take these bindings individual and replace V2 in the one with those bindings and flood those triple parents individually to to look for results."
        ],
        [
            "Bulk starts off much the same way we flood tiptoe through the network since it is the triple pattern with the least amount of variables.",
            "These findings are then not replaced in TP one.",
            "Actually only the original triple patterns floating through the network, but with a set of bindings for for some of the variables.",
            "In this case a set of bindings for V2.",
            "So we find that result in F1 like so.",
            "So we flood the network essentially this time."
        ],
        [
            "The full approach.",
            "As I said, only flush the original and evaluates the original travel patterns around the network.",
            "So the order of which we execute them or we flood them really doesn't matter.",
            "In this case we just flat TV 2 first again.",
            "A do we find some bindings and we flood?",
            "As you can see, only the original triple TP one unbounded through the network and we find quite a lot more results.",
            "Actually we also find results where we want is Denmark and we choose Copenhagen where we want is Norway.",
            "We choose a slow and so on.",
            "So flat the network less times, but you have to transfer a lot more data essentially.",
            "Yes, so after the travel patterns have been evaluated in the network, the bindings are joined."
        ],
        [
            "So in our experiments we used to set up with four 16 core processors and 500 gigabytes of RAM with 200 picnic notes running concurrently, forming forming a network.",
            "We use lots of defence for datasets, inquiries.",
            "They lots of difficult.",
            "Bench comprises 13 different datasets with over 1 billion triples.",
            "And 40 different queries in five different categories.",
            "Actually four different categories, but one of the categories called the simple queries.",
            "We chose to use the original names from from fit bins called Quest Domain in Life Sciences.",
            "These are the parameters we used for the majority of our experiments.",
            "Time to live value of five replication factor 5% which means all the fragments were replicated on 5% of the note.",
            "Being 10 notes.",
            "The amount of neighbors each note half was five."
        ],
        [
            "So the first thing we wanted to do was to compare the three preprocessing approaches.",
            "This graph shows the execution time in log scale and the Y axis and what we see is that.",
            "So for this is for the two first Kirk groups.",
            "So what we see is that bulk is generally the fastest approach of the three in the majority of the cases, and this trend continues in the other categories as well.",
            "Furthermore, we also tested how many messages were sent between nodes to incur processing and how much data were transferred between those during processing.",
            "And we found that bulk generally provides the best tradeoff between performance network traffic and data transfer."
        ],
        [
            "So the problem we wanted to solve was the availability of of datasets.",
            "We therefore ran experiments where we gradually.",
            "Failed and purposely more more notes and this graph then shows the completeness when giving the network no time to recover.",
            "That means owners of datasets did not have time to replicate fragments on failing nodes further or or to pick up ownership over datasets from from failing nodes.",
            "So we expected gradual decrease in completeness with the amount of available nodes falling, and this is exactly what we saw.",
            "When given the recovery time to the system, we we actually saw that even when 50 were actually less than 50, I think 35 or 40% of the notes.",
            "However, we're available, we see that we can maintain a really high completeness.",
            "The fall in the end there is mostly due to the nodes having more data and a square processing takes longer and longer and.",
            "And so we start to see some time out, some more timeouts.",
            "So the conclusion from this is that even when nodes fail, and even when the owners fail of the data set, we actually able to maintain access to data and we are actually able to retain a high completeness."
        ],
        [
            "So in summary, we we introduced picnic which is a peer to peer client for preprocessing over semantic data.",
            "We proposed a customizable approach for fragmentation.",
            "And three different preprocessing approaches.",
            "Single bug in full.",
            "Of which bulk provided the best tradeoff between?",
            "A.",
            "Between performance network traffic and data transfer.",
            "And the picnic was able to.",
            "Most importantly, of course, picking was able to tolerate no trailers.",
            "During the experiments with it, encounter some very large queries with very large intermediate results.",
            "This means we have to flood the network a lot of times, sometimes even 100,000, maybe more.",
            "Even times.",
            "This obviously creates an overhead, and so in our future works we would like to.",
            "To eliminate the flooding approach and to find a way to improve query processing this way.",
            "As I said we we have no global knowledge over the network, so we can never be sure that we receive a complete answer.",
            "So finding a way to assess the completeness of answers to incur processing could be interesting.",
            "And Lastly, as I also mentioned, alternative fragmentation methods could prove could prove too.",
            "To be more optimal for certain kinds of queries, and so this could be interesting to research as well."
        ],
        [
            "So thank you for the time."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today open link datasets are often unavailable.",
                    "label": 0
                },
                {
                    "sent": "In fact, the recent study found that over half of all public sparkle in points have left the 95% availability.",
                    "label": 0
                },
                {
                    "sent": "This means in some cases following links or common entities between different and separate.",
                    "label": 0
                },
                {
                    "sent": "Datasets can be impossible since the data is just not available.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for this often is that these kinds of interfaces, especially sparkle implants, require considerable considerable amounts of resources to maintain.",
                    "label": 1
                },
                {
                    "sent": "And without any sort of incentive for this open datasets, it becomes a huge burden for the providers.",
                    "label": 1
                },
                {
                    "sent": "Some recent efforts have proposed to introduce monetary incentives to this.",
                    "label": 0
                },
                {
                    "sent": "However, we argue that the burden can be lifted from the providers through decentralisation.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The reason why we mentioned decentralisation is it has previously been been researched and evidence to actually improve availability of of these kinds of datasets.",
                    "label": 1
                },
                {
                    "sent": "For example, triple power fragments that proved to lower the computation under the server and thus improve availability during high current loads.",
                    "label": 1
                },
                {
                    "sent": "Then we have for example Alissas, which replicates through pattern fragments across multiple servers, which is closer to what we want to achieve, but commonly in all these approaches we have either still a single point of entry or a fixed set of service in a fixed set of replicated fragments.",
                    "label": 1
                },
                {
                    "sent": "So we still face some of the same issues and we.",
                    "label": 0
                },
                {
                    "sent": "And we don't really have an architecture in which data sets can dynamically be added, and so on.",
                    "label": 0
                },
                {
                    "sent": "So to achieve this kind of dynamic architecture, we look towards P.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Peer systems where that two, generally two types of peer to peer system structure peer to peer systems which organized appears into some overlay.",
                    "label": 0
                },
                {
                    "sent": "For example, distributed hash tables.",
                    "label": 1
                },
                {
                    "sent": "The problem with these kind of systems is that if nodes leave and join the network frequently, you have to recompute that overlay all the time.",
                    "label": 1
                },
                {
                    "sent": "So instead, in order to allow for notes to leave and join the network, we look to unstructured peer to peer system which have seemingly random connections between nodes.",
                    "label": 1
                },
                {
                    "sent": "And thus I'm all reliable during doing churn because you don't have to recompute the overlay all the time.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to lift the burden of data providers, we propose the architecture called picnic, which is a peer to peer client for query processing over semantic data.",
                    "label": 1
                },
                {
                    "sent": "And is based on unstructured peer to peer architecture.",
                    "label": 1
                },
                {
                    "sent": "Such that each client maintains a limited local data store that uses HTTP.",
                    "label": 1
                },
                {
                    "sent": "The reason we use HTTPS because in such architectures the amount of resources each node have available can vary quite a bit, so we want to use a compressed representation of RDF in order to use this little resources as possible.",
                    "label": 0
                },
                {
                    "sent": "For a user wanting to to create these, all these datasets that are being uploaded to a network, they can do so just by knowing any node in the network and query on any node network.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course it's.",
                    "label": 0
                },
                {
                    "sent": "These open datasets can be quite large, millions or even billions of triples, and that's not really feasible to store on on replicate throughout a network with limited resources, and so we split these datasets into smaller fragments.",
                    "label": 0
                },
                {
                    "sent": "In order to be able to replicate these.",
                    "label": 0
                },
                {
                    "sent": "Do you say across the network so a fragment contains a set of triples, which is the.",
                    "label": 1
                },
                {
                    "sent": "It was a subset of the original Knowledge Graph.",
                    "label": 1
                },
                {
                    "sent": "Contains a set of notes or point us to notes that contains the fragment.",
                    "label": 0
                },
                {
                    "sent": "A identifier, an identification function that, given a triple pattern, could determine whether or not the fragmente may continue answers to so if we look at this example down here, we have a bunch of tables.",
                    "label": 1
                },
                {
                    "sent": "This could be the triples in a fragment.",
                    "label": 0
                },
                {
                    "sent": "We note that all of them has the same predicate, which is his capital.",
                    "label": 0
                },
                {
                    "sent": "And thus we can build a predicate based identification function that returns true if the predicate in the triple pattern is the same predicate as all the triples have in the in the fragment, or if the predicate is a variable and returns false otherwise.",
                    "label": 1
                },
                {
                    "sent": "So for this trip and it will return true because the predicate is has capital.",
                    "label": 0
                },
                {
                    "sent": "Well, for this triple pattern it would return false since the.",
                    "label": 0
                },
                {
                    "sent": "Predicate is not his capital.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to represent entire knowledge graphs in a picnic network we.",
                    "label": 0
                },
                {
                    "sent": "We introduced a notion of datasets and the data set kind of system closes.",
                    "label": 0
                },
                {
                    "sent": "It closes the set of fragments from the original Knowledge Graph.",
                    "label": 0
                },
                {
                    "sent": "But most importantly about datasets, they contain an owner note, which is the note to which the data set or the Knowledge Graph was originally.",
                    "label": 0
                },
                {
                    "sent": "Upload 2.",
                    "label": 0
                },
                {
                    "sent": "The owner's job is to make sure that all the fragments in the data set are replicated among or over enough nodes.",
                    "label": 0
                },
                {
                    "sent": "So if a node fails or leaves the network which had one of the fragments, the owner will make sure to.",
                    "label": 0
                },
                {
                    "sent": "Replicate this fragment to a new new data set so we have these three fragments.",
                    "label": 0
                },
                {
                    "sent": "The datasets from the original Knowledge Graph just encloses the three fragments.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we fragment?",
                    "label": 0
                },
                {
                    "sent": "Well, first, introduce customizable approach to fragmentation becausw.",
                    "label": 0
                },
                {
                    "sent": "Sudden different kinds of fragmentation functions could be optimized for different kinds of queries.",
                    "label": 0
                },
                {
                    "sent": "Therefore, for this paper we choose to.",
                    "label": 0
                },
                {
                    "sent": "To have a predicate based identification function, which essentially means.",
                    "label": 0
                },
                {
                    "sent": "The fragment is created for each unique predicate, so in the knowledge Graph here we create a fragment for all the troubles with his capital as the predicate one with all the triples that has made offers to predicate and so on.",
                    "label": 0
                },
                {
                    "sent": "So we get these fragments.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I mentioned, the.",
                    "label": 0
                },
                {
                    "sent": "Such a peer to peer architecture is based on clients also acting as service.",
                    "label": 0
                },
                {
                    "sent": "So, so they contain a limited data store.",
                    "label": 0
                },
                {
                    "sent": "In our case, this is just a set of fragments that are located on the server that on the other note that is its local data store.",
                    "label": 1
                },
                {
                    "sent": "A node contains also some datasets that it owns, so that was uploaded to the specific node.",
                    "label": 0
                },
                {
                    "sent": "And so if there are any datasets in this set.",
                    "label": 1
                },
                {
                    "sent": "The node would have to maintain this data set.",
                    "label": 0
                },
                {
                    "sent": "And then it's not contains a list of neighbors, which is the local view over the network.",
                    "label": 1
                },
                {
                    "sent": "In an unstructured switch, peer network such as this, it's not really feasible to have any sort of global knowledge, so we cannot know all the all the other nodes in the network.",
                    "label": 0
                },
                {
                    "sent": "And so this is a limited view over the network.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course it's important to always up have an updated view over the network, but it's also important to always have some nodes close by that have related data, but it's also important to have some nodes close by that have unrelated data, and the reason for this is if a query is issued on the node, which on which the note has related data, two, that's a higher change.",
                    "label": 0
                },
                {
                    "sent": "We can complete the query if completely answer if we have access to.",
                    "label": 0
                },
                {
                    "sent": "2 notes with related data.",
                    "label": 0
                },
                {
                    "sent": "If you query is issued that we do not have any related data to, there's a high chance we can reach part of the network that does.",
                    "label": 0
                },
                {
                    "sent": "If we have some random neighbors.",
                    "label": 1
                },
                {
                    "sent": "The way we achieve this is through frequent shuffles, that is, a node selects a random one of its neighbors to which it sends all of its least related neighbors.",
                    "label": 1
                },
                {
                    "sent": "That way, we ensure that all of the all of the most related neighbors may.",
                    "label": 0
                },
                {
                    "sent": "Are still in the interview.",
                    "label": 0
                },
                {
                    "sent": "So determining which neighbors are the least related is based on based on the relatedness or this relatedness of the data in the node which is based on the general ability of fragments.",
                    "label": 0
                },
                {
                    "sent": "So two fragments are joinable if they share some common entity in either the subject objects.",
                    "label": 0
                },
                {
                    "sent": "So the list of joinable fragments between two nodes and one and two at all the fragments in one that are joinable with some fragmented into.",
                    "label": 0
                },
                {
                    "sent": "And so when, when calculating which neighbors true to shuffle away, which neighbors are the least related, we give them a score that is the rate of which fragments in the original note are joinable with some fragment in the other note.",
                    "label": 1
                },
                {
                    "sent": "And then this function is just a objective function that.",
                    "label": 0
                },
                {
                    "sent": "Returns their kaliste related numbers.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this example, we have the same troubles as before in four wants to shuffle within two and with the shuffling sev one, it means only its least related neighbor will be shuffled away.",
                    "label": 0
                },
                {
                    "sent": "And two is already selected and five as its least related neighbor.",
                    "label": 0
                },
                {
                    "sent": "And So what we do is essentially we go through all the neighbors from from info and calculate its relatedness score.",
                    "label": 0
                },
                {
                    "sent": "So if we start buying one, we see that if four is joinable with if one.",
                    "label": 0
                },
                {
                    "sent": "On multiple URLs, for example Greece, Athens, Norway in Oslo.",
                    "label": 0
                },
                {
                    "sent": "And if two is joinable with the five, unplug it and so both fragments and then for joinable with some fragmente in one and thus the relatedness scores one.",
                    "label": 0
                },
                {
                    "sent": "Same is the case fine too, although here if far is joinable with F3 instead on Athens.",
                    "label": 0
                },
                {
                    "sent": "If five is obviously still joinable with two.",
                    "label": 0
                },
                {
                    "sent": "Four in three, though, we see that if five is joinable, with neither if one or three, and so only one of the fragments in four actually joinable with one of the fragments in in three.",
                    "label": 0
                },
                {
                    "sent": "And thus the related in this course 1/2, which is the lowest and thus.",
                    "label": 0
                },
                {
                    "sent": "And three is shuffled with within 5.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Preprocessing follows a flooding approach.",
                    "label": 1
                },
                {
                    "sent": "That means when a node receives a triple pattern to to to evaluate evaluate in this local data store and forward the request to all of its neighbors, and this happens for a certain amount of steps called the time to live value.",
                    "label": 0
                },
                {
                    "sent": "So let's say a sparkle query is executed or issued on in seven with a time to live value of two.",
                    "label": 0
                },
                {
                    "sent": "For each of the triple patterns.",
                    "label": 0
                },
                {
                    "sent": "And seven will evaluate them on its local data store and forward them to its neighbors, which will, with one list TTL value.",
                    "label": 0
                },
                {
                    "sent": "The neighbors will do the same and forward.",
                    "label": 0
                },
                {
                    "sent": "The request to their neighbors with a TTL value of 0.",
                    "label": 0
                },
                {
                    "sent": "And since the time to value is now 0, these notes will not forward the request any further.",
                    "label": 0
                },
                {
                    "sent": "The notes that have answers.",
                    "label": 0
                },
                {
                    "sent": "Will return the answers of the bindings for variables from the travel patterns directly to to the.",
                    "label": 0
                },
                {
                    "sent": "Note that the couriers issued on.",
                    "label": 0
                },
                {
                    "sent": "For the preprocessing approach on the query on the, note that the query is issued on.",
                    "label": 1
                },
                {
                    "sent": "We implemented three different approaches, single, which is spaced on or.",
                    "label": 0
                },
                {
                    "sent": "Which follows from the triple pattern fragment style of processing queries where bindings from previously evaluated triple patterns are replaced in the triple pattern individually and floated through the network.",
                    "label": 1
                },
                {
                    "sent": "Bug which is based on bindings restricted triple pattern FRAGMENTE works much the same way, only wear these findings about together so we flood the network list times.",
                    "label": 0
                },
                {
                    "sent": "And then we have full words only flood the network with the original parents and thus unbounded.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see how this works.",
                    "label": 0
                },
                {
                    "sent": "We start with a single approach and this query finds all all countries and capitals that have hosted SWC so.",
                    "label": 0
                },
                {
                    "sent": "The first thing we do is select the trouble pattern with the least amount of variables.",
                    "label": 0
                },
                {
                    "sent": "In this case T2.",
                    "label": 0
                },
                {
                    "sent": "We flush that through the network for the given amount of steps.",
                    "label": 0
                },
                {
                    "sent": "In this case, we find we find out that if three's identification function returns true for the triple pattern and us, we look for bindings for V2 in.",
                    "label": 0
                },
                {
                    "sent": "If three and get the bonding zubiena and essence.",
                    "label": 0
                },
                {
                    "sent": "When we evaluate CP one, we take these bindings individual and replace V2 in the one with those bindings and flood those triple parents individually to to look for results.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bulk starts off much the same way we flood tiptoe through the network since it is the triple pattern with the least amount of variables.",
                    "label": 0
                },
                {
                    "sent": "These findings are then not replaced in TP one.",
                    "label": 0
                },
                {
                    "sent": "Actually only the original triple patterns floating through the network, but with a set of bindings for for some of the variables.",
                    "label": 0
                },
                {
                    "sent": "In this case a set of bindings for V2.",
                    "label": 0
                },
                {
                    "sent": "So we find that result in F1 like so.",
                    "label": 0
                },
                {
                    "sent": "So we flood the network essentially this time.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The full approach.",
                    "label": 0
                },
                {
                    "sent": "As I said, only flush the original and evaluates the original travel patterns around the network.",
                    "label": 0
                },
                {
                    "sent": "So the order of which we execute them or we flood them really doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "In this case we just flat TV 2 first again.",
                    "label": 0
                },
                {
                    "sent": "A do we find some bindings and we flood?",
                    "label": 0
                },
                {
                    "sent": "As you can see, only the original triple TP one unbounded through the network and we find quite a lot more results.",
                    "label": 0
                },
                {
                    "sent": "Actually we also find results where we want is Denmark and we choose Copenhagen where we want is Norway.",
                    "label": 0
                },
                {
                    "sent": "We choose a slow and so on.",
                    "label": 0
                },
                {
                    "sent": "So flat the network less times, but you have to transfer a lot more data essentially.",
                    "label": 0
                },
                {
                    "sent": "Yes, so after the travel patterns have been evaluated in the network, the bindings are joined.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our experiments we used to set up with four 16 core processors and 500 gigabytes of RAM with 200 picnic notes running concurrently, forming forming a network.",
                    "label": 0
                },
                {
                    "sent": "We use lots of defence for datasets, inquiries.",
                    "label": 0
                },
                {
                    "sent": "They lots of difficult.",
                    "label": 0
                },
                {
                    "sent": "Bench comprises 13 different datasets with over 1 billion triples.",
                    "label": 0
                },
                {
                    "sent": "And 40 different queries in five different categories.",
                    "label": 0
                },
                {
                    "sent": "Actually four different categories, but one of the categories called the simple queries.",
                    "label": 0
                },
                {
                    "sent": "We chose to use the original names from from fit bins called Quest Domain in Life Sciences.",
                    "label": 0
                },
                {
                    "sent": "These are the parameters we used for the majority of our experiments.",
                    "label": 0
                },
                {
                    "sent": "Time to live value of five replication factor 5% which means all the fragments were replicated on 5% of the note.",
                    "label": 0
                },
                {
                    "sent": "Being 10 notes.",
                    "label": 0
                },
                {
                    "sent": "The amount of neighbors each note half was five.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first thing we wanted to do was to compare the three preprocessing approaches.",
                    "label": 0
                },
                {
                    "sent": "This graph shows the execution time in log scale and the Y axis and what we see is that.",
                    "label": 1
                },
                {
                    "sent": "So for this is for the two first Kirk groups.",
                    "label": 0
                },
                {
                    "sent": "So what we see is that bulk is generally the fastest approach of the three in the majority of the cases, and this trend continues in the other categories as well.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, we also tested how many messages were sent between nodes to incur processing and how much data were transferred between those during processing.",
                    "label": 0
                },
                {
                    "sent": "And we found that bulk generally provides the best tradeoff between performance network traffic and data transfer.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem we wanted to solve was the availability of of datasets.",
                    "label": 0
                },
                {
                    "sent": "We therefore ran experiments where we gradually.",
                    "label": 0
                },
                {
                    "sent": "Failed and purposely more more notes and this graph then shows the completeness when giving the network no time to recover.",
                    "label": 0
                },
                {
                    "sent": "That means owners of datasets did not have time to replicate fragments on failing nodes further or or to pick up ownership over datasets from from failing nodes.",
                    "label": 0
                },
                {
                    "sent": "So we expected gradual decrease in completeness with the amount of available nodes falling, and this is exactly what we saw.",
                    "label": 1
                },
                {
                    "sent": "When given the recovery time to the system, we we actually saw that even when 50 were actually less than 50, I think 35 or 40% of the notes.",
                    "label": 0
                },
                {
                    "sent": "However, we're available, we see that we can maintain a really high completeness.",
                    "label": 0
                },
                {
                    "sent": "The fall in the end there is mostly due to the nodes having more data and a square processing takes longer and longer and.",
                    "label": 0
                },
                {
                    "sent": "And so we start to see some time out, some more timeouts.",
                    "label": 0
                },
                {
                    "sent": "So the conclusion from this is that even when nodes fail, and even when the owners fail of the data set, we actually able to maintain access to data and we are actually able to retain a high completeness.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, we we introduced picnic which is a peer to peer client for preprocessing over semantic data.",
                    "label": 1
                },
                {
                    "sent": "We proposed a customizable approach for fragmentation.",
                    "label": 0
                },
                {
                    "sent": "And three different preprocessing approaches.",
                    "label": 0
                },
                {
                    "sent": "Single bug in full.",
                    "label": 0
                },
                {
                    "sent": "Of which bulk provided the best tradeoff between?",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "Between performance network traffic and data transfer.",
                    "label": 0
                },
                {
                    "sent": "And the picnic was able to.",
                    "label": 1
                },
                {
                    "sent": "Most importantly, of course, picking was able to tolerate no trailers.",
                    "label": 0
                },
                {
                    "sent": "During the experiments with it, encounter some very large queries with very large intermediate results.",
                    "label": 1
                },
                {
                    "sent": "This means we have to flood the network a lot of times, sometimes even 100,000, maybe more.",
                    "label": 0
                },
                {
                    "sent": "Even times.",
                    "label": 1
                },
                {
                    "sent": "This obviously creates an overhead, and so in our future works we would like to.",
                    "label": 0
                },
                {
                    "sent": "To eliminate the flooding approach and to find a way to improve query processing this way.",
                    "label": 0
                },
                {
                    "sent": "As I said we we have no global knowledge over the network, so we can never be sure that we receive a complete answer.",
                    "label": 1
                },
                {
                    "sent": "So finding a way to assess the completeness of answers to incur processing could be interesting.",
                    "label": 0
                },
                {
                    "sent": "And Lastly, as I also mentioned, alternative fragmentation methods could prove could prove too.",
                    "label": 0
                },
                {
                    "sent": "To be more optimal for certain kinds of queries, and so this could be interesting to research as well.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you for the time.",
                    "label": 0
                }
            ]
        }
    }
}