{
    "id": "s7lrgpox7hmd2u55q7xf5gcgg2wk4xgo",
    "title": "Improving Ad Relevance in Sponsored Search",
    "info": {
        "author": [
            "Dustin Hillard, Yahoo! Research Silicon Valley"
        ],
        "published": "March 18, 2010",
        "recorded": "February 2010",
        "category": [
            "Top->Computer Science->Web Mining->Search & Advertising"
        ]
    },
    "url": "http://videolectures.net/wsdm2010_hillard_iars/",
    "segmentation": [
        [
            "Thanks for coming on Saturday and staying awake right before lunch here so the this is joint work from a bunch of people in sponsored search group.",
            "Stephen Shortell aeronautical hammer Raghavan and Chris Lake."
        ],
        [
            "So the motivation here is that we want to improve the ad relevance for the Yahoo search users, and So what we'll do is develop a model to predict ad relevance and then try and leverage the use, interact user interactions in our learning and then predict use this particular relevance in a in a bunch of ways to improve our system to filter an remove that adds as a feature to improve the ad ranking and as a score to improve the ad place."
        ],
        [
            "And.",
            "So first I'll talk a little bit about our ad relevance models of baseline model and then adding some user click features to improve that, discuss the applications and."
        ],
        [
            "Give you a summary."
        ],
        [
            "So our model is just going to basically want to predict how relevant to Nat is for a particular query, so it's pretty much the very similar problem to what you would do in typical web search and will incorporate the typical features that word, character overlap and novelty and so on.",
            "The differences will basically be training just a class of machine learning classification model to.",
            "Learn that human editorial judgment."
        ],
        [
            "One query ad pairs.",
            "So the data set that we're working with here is.",
            "Sample of our ads database.",
            "So we've used a simple TF IDF system to retrieve about 20 ads per query.",
            "And we have about 7000 queries that are stratified sample from our web logs, so we haven't even representation from a bunch of the different deciles, and we have the peg fed judgments here.",
            "So we have five level judgments, but we group them into just a binary good versus bad judgment because we basically want to be identifying the bad ads because those are the ones really degrade the quality.",
            "Most owner or are served page."
        ],
        [
            "So here's some results from the baseline model.",
            "The as I mentioned there, the standard features we have character Werden, bigram overlap, and we have the ordered bigram overlaps.",
            "That is a little bit looser bigram that allows words to be in between it.",
            "The standard cosine TF IDF score in the query length to normalize by the query length, so we have a Maxent model, and add a boost in a GT model, and then I'll have pretty much the same features Adaboost and GT do a little bit better here.",
            "The Maxent model is pretty simple model, we didn't.",
            "Put any conjunctions in it."
        ],
        [
            "That's why the others are doing a little bit better.",
            "And here's a comparison at a bunch at the various operating points for precision and recall.",
            "So the purple line here is the baseline TF IDF system, which doesn't have any machine learning involved, it just has a little bit of hand weight tuning.",
            "The blue line is the maximum model, and the red and green lines are the Adaboost angithi model.",
            "So they're giving a nice a nice win."
        ],
        [
            "OK, so that set up the basic model, which is kind of standard, and what we're going to do now is try and use the user click information we have."
        ],
        [
            "To improve our predicted relevance.",
            "And so we can do this in two ways.",
            "We're going to do it by directly looking at the observed click history rates for ads, and then we want to do it more broadly with a query ad click translation model that applies to ads that we haven't seen."
        ],
        [
            "4.",
            "So for observed click history, we want to use this because the previous click history is the best predictor of future click history, and so we're going to just collect the aggregate click rates from statistics from our logs at multiple levels of granularity.",
            "So these are the same type of click feedback features that have been mentioned in the last talk, and so at the most granular level will look at a specific query, ad pairs or query advertiser pairs and then backing off a bit.",
            "We can look at the click rates for an ad or an advertiser in the context of any query.",
            "And finally, we can look at just the query level.",
            "So what's the click rate on this query in the context of any ad?",
            "So these broader advocates are less precise, but have much higher coverage.",
            "So for instance, on our relevance model training data, we only have sufficient statistics at the query ad level for about 10% of the observed ads, and at the query level we have more like 99%."
        ],
        [
            "So often we have this insufficient click history for unseen ads that are new to the system or infrequent query ad pairs that occur very rarely, and so we want to develop a model that predicts click propensity based on the query add text, which would then be independent of any individual ad so we can learn relationship between a query in an ad title that can be applied to previously unseen query ad pairs."
        ],
        [
            "Or very rare query adverse.",
            "And so we're going to use the same translation modeling approach with A twist, and so basically want to learn this query title translation model.",
            "So we're going to say what's the probability of the document, which is an add in our case, given a query and we use the IBM Model 1 as well, and the translation probabilities here.",
            "The twist is that we're going to use our web logs as a corpus, and so in computing the translation scores, we take account of the word in the query in the ad occurring together and divide that by the.",
            "Number of times in an ad word occurs.",
            "Overall queries and the main difference here is we're going to build 2 models, so we're going to build 1 model based on the click log.",
            "So we're in that case we're looking at how many times a query ad pair was clicked, or actually how many times that particular query word and Edward curd in a click context.",
            "And then we're going to look again at build a separate model over the just the views, and the reason we want to do this is if we look at only the click logs.",
            "We might overestimate particular relationships, so if a.",
            "Particular query ad word pair gets a massive amount of traffic.",
            "It might get a pretty significant click signal, but mainly because it's just finished so shown so many times.",
            "So by taking this ratio of the translation probability from our click logs divided by our view logs, we can normalize for that.",
            "So something that's shown in order amount of times and doesn't get very many clicks will have a lower ratio here.",
            "So basically if you get to the average number of clicks, this ratio will be equal to 1 and better than average will be higher and worse than average will be lower.",
            "And I should mention that the.",
            "The views we use, expected clicks and so we normalize per position so that things that occur in lower positions have less weight in higher positions, have more weight in the details of that are in the paper."
        ],
        [
            "So here are the results for using the clicks in relevance modeling problem.",
            "The first line on the table here is just the baseline model that was presented in the first part of the talk and the 2nd is by adding the directly observed click history.",
            "So you see, we get a decent boost and precision there in about the same recall.",
            "So we get a bit of a win there in the third line is using the translation model only, so here we're not using any specific click history but just the scores provided by the click translation model and then by combining them.",
            "We get a small win so I should mention the translation is basically giving us an improvement in the recall which matches our intuitive intuition because it's helping us with ads that we haven't had any previous information about, and it's giving us as compared to our baseline model, which basically just textual overlap features.",
            "We now have these translation tables, which allows us to detect semantic similarity essentially.",
            "In broad sense, we've learned some synonyms, and so we're able to detect related ads that don't have exact textual overlap, and I should mention that all of these results are pairwise statistically signif."
        ],
        [
            "So here's what the precision recall graph looks like for three of these models, the red line is the baseline GT model that has just the text features without any click information and the green line is adding the translation features to that, so we get a nice consistent when it costs all of our operating points and then by adding in this specifically observed click history, that's the blue line, and so you can see we get a win at that high precision regions.",
            "There, it's improving a bit over at having just the translation features alone.",
            "So we built this model and improved it with the user click information, and now I'll talk a bit about the applications in this."
        ],
        [
            "Search world and how we can use it to improve."
        ],
        [
            "That and I'll motivate that with a bit of an example.",
            "So first of all, here's what a typical Yahoo serve looks like for pretty commercial queries.",
            "So if you search for digital cameras, there's a fair amount of things going on, so we have everything in yellow.",
            "There is the North ads, so they add zit occur above the organic search results, and then we also have ads coming down the right hand side of the page here in the East, and so in order to build this page, we first need to do a candidate retrieval and select all of the potential ads from our ads database that we might want to show for this query.",
            "And then use the ranking model that has been talked about to choose the order and then finally we have a page placement algorithm decides how many ads do we want to put on top.",
            "Because this is a pretty commercial query that has a lot of revenue, we have the maximum number of ads in the North here."
        ],
        [
            "So, but we also have examples where we could be doing a much better job.",
            "So here's a query where the user would put in mutual information and get some results that are probably not matching their intent, and so they're basically getting mutual funds and information about mutual funds, which.",
            "Is not not what we'd like to do, So what we want to have is a model that can predict that the relevance here is low, and maybe some of these ads.",
            "We'd like to take off the page completely, and others of them we'd like to at least take out of the North of the page and move, so I won't."
        ],
        [
            "You dwell on that too long.",
            "So here's the first application of using.",
            "The relevance model is to basically remove the low quality ads off the page completely and so we can do this by just looking at our predicted relevance score, picking a threshold, and deciding to take it.",
            "Take all those ads off the page completely.",
            "So we ran this in a in a bucket for two weeks on 2% of our traffic and we basically were able to filter 50% of those ads that would be created by humans as bad and while only filtering 10% of the stuff that was.",
            "That was not bad.",
            "And in terms of what that meant for the user interactions, we reduced coverage of ads by almost 10%, and so that's the number of queries that have an ad and we reduce the add depth by 12%, which is the number of ads that you would see per query.",
            "So we have a significant reduction there.",
            "And the overall clickthrough rate went up by 10%, which is somewhat expected given the large drop in coverage and depth that we have is somewhat unexpected or positive.",
            "Result is that the total ad clicks went up by 1/2%, so even though we're showing about 10% less ads overall, the number of clicks that we got on our ads increased.",
            "So we were really able to remove only those ads that were probably not useful."
        ],
        [
            "The users.",
            "So the second application is ad ranking and this is basically just A twist on what has been presented earlier and so we want to be ranking the ads by some function of Biden, probability of click, and so we're just going to augment that probability of click model by providing our predicted relevance as a feature.",
            "And so the impact here is that we can improve when the click model history is sparse, and so the two graphs that are on the screen here are for a segment of the test data where we have either no.",
            "The left one is we have no data for the advertiser at all and the right one is that we have no data for the.",
            "For more slightly more specific case so.",
            "But basically we have not seen very many clicks or views of this at all, and so we're able to improve it by adding in this relevance model which is based more on the syntax.",
            "In the text of the ads, whereas the click model otherwise would heavily biased towards the click features.",
            "So for these kind of longer tail and new ads, we're able to improve the relevance here."
        ],
        [
            "And finally we have the optimization problem where we want to decide where to place ads on the search page.",
            "So in the example that I showed that could use some improvement, we might not be able to say that we want to take the ad off the page completely, but if we are somewhat confidence it's a lower quality ad, we can push it off the top of the page to the side, which makes it a still improves the user experience significantly, and So what we did in this experiment was to consider the ad will AD predicted ad relevance and the predicted web relevance.",
            "So we have our model that predicts the ad relevance and we also have the web search.",
            "Model and so we can compare the prediction predicted relevance of each of these two models and if we have the ad relevance at a much lower, is predicted to be much lower than the web relevance.",
            "We can basically make sure we don't show the ad on top of the page and push it off to the side.",
            "So the bucket results here where that we reduced the metric.",
            "We have called Northside impact with there's more details in the paper, but it's basically how how much putting ads on top of the page reduces the user experience and so the overall clickthrough rate on the North ads improved by 1 1/2% and the total clicks.",
            "Again improved by almost 1%.",
            "So we are these metrics latest to leave that we're improving the user."
        ],
        [
            "Parents.",
            "OK."
        ],
        [
            "So to wrap it up and get your lunch and I'll just say that we developed a useful ad relevance model and improve the performance using user click data and extended it to new ads that we haven't seen before by using a click translation model and then incorporated this in a sponsored search system to show that we can remove low quality ads, improve the ad ranking, and improve the placement of the ads."
        ],
        [
            "On the page.",
            "So thanks, thank you.",
            "Hey, any questions or no I want to give you some lunch.",
            "OK. Find a big place.",
            "Right, yeah?",
            "They say it again.",
            "Yeah, so I mean we one thing is the corpus that they learn their translation from is a different corpus, so they're basically looking at database itself, whereas we're learning the.",
            "So I think they're they're learning advertiser behavior, so what's a good match between a landing page in a bid phrase so they're learning, given an advertiser has this landing page, what's the?",
            "What's the relevant phrase?",
            "And in our context, we're learning a different translation model, which is given that we present this add to the user, and when they've typed this query, what's the click propensity?",
            "What do we think the click propensity of the ads is?",
            "And so the I think because of those because of that difference, it's not too much of a conflict of interest.",
            "And that that model we don't have it there.",
            "Model that both presented isn't in in our system right now, so it's not introducing that bias.",
            "Hi.",
            "Correct?",
            "Directions.",
            "Are analysts judgments and five level skill.",
            "But yeah.",
            "Sure, yeah, I guess basically our main motivation initially was to remove the low quality ads from the service completely so it was a classification problem that we were casting it as and so the.",
            "I guess the learning to rank is a little bit more complex problem and so we don't think we need to spend the effort on distinguishing between, say good in a in a perfect dead we mainly wanted to just focus on detecting the low quality ads, so we cast it as a classification problem.",
            "We've also tested it with the regression as a learning to rank problem and the results are essentially similar.",
            "But because our goal was basically to detect just the bad ads, we simplified it to that classification problem, but the results aren't too different.",
            "If you do learning to rank.",
            "But it could be better with toys restaurant.",
            "Yeah, so actually I didn't present the rules here, but we've we've tried both ways and for the for the tasks that I presented our live system, the results are pretty much comprable.",
            "Yep.",
            "Any other question?",
            "OK, well this concludes the session, so let's say this."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks for coming on Saturday and staying awake right before lunch here so the this is joint work from a bunch of people in sponsored search group.",
                    "label": 0
                },
                {
                    "sent": "Stephen Shortell aeronautical hammer Raghavan and Chris Lake.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the motivation here is that we want to improve the ad relevance for the Yahoo search users, and So what we'll do is develop a model to predict ad relevance and then try and leverage the use, interact user interactions in our learning and then predict use this particular relevance in a in a bunch of ways to improve our system to filter an remove that adds as a feature to improve the ad ranking and as a score to improve the ad place.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So first I'll talk a little bit about our ad relevance models of baseline model and then adding some user click features to improve that, discuss the applications and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give you a summary.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our model is just going to basically want to predict how relevant to Nat is for a particular query, so it's pretty much the very similar problem to what you would do in typical web search and will incorporate the typical features that word, character overlap and novelty and so on.",
                    "label": 1
                },
                {
                    "sent": "The differences will basically be training just a class of machine learning classification model to.",
                    "label": 0
                },
                {
                    "sent": "Learn that human editorial judgment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One query ad pairs.",
                    "label": 0
                },
                {
                    "sent": "So the data set that we're working with here is.",
                    "label": 0
                },
                {
                    "sent": "Sample of our ads database.",
                    "label": 1
                },
                {
                    "sent": "So we've used a simple TF IDF system to retrieve about 20 ads per query.",
                    "label": 1
                },
                {
                    "sent": "And we have about 7000 queries that are stratified sample from our web logs, so we haven't even representation from a bunch of the different deciles, and we have the peg fed judgments here.",
                    "label": 0
                },
                {
                    "sent": "So we have five level judgments, but we group them into just a binary good versus bad judgment because we basically want to be identifying the bad ads because those are the ones really degrade the quality.",
                    "label": 0
                },
                {
                    "sent": "Most owner or are served page.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's some results from the baseline model.",
                    "label": 1
                },
                {
                    "sent": "The as I mentioned there, the standard features we have character Werden, bigram overlap, and we have the ordered bigram overlaps.",
                    "label": 1
                },
                {
                    "sent": "That is a little bit looser bigram that allows words to be in between it.",
                    "label": 0
                },
                {
                    "sent": "The standard cosine TF IDF score in the query length to normalize by the query length, so we have a Maxent model, and add a boost in a GT model, and then I'll have pretty much the same features Adaboost and GT do a little bit better here.",
                    "label": 0
                },
                {
                    "sent": "The Maxent model is pretty simple model, we didn't.",
                    "label": 0
                },
                {
                    "sent": "Put any conjunctions in it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's why the others are doing a little bit better.",
                    "label": 0
                },
                {
                    "sent": "And here's a comparison at a bunch at the various operating points for precision and recall.",
                    "label": 0
                },
                {
                    "sent": "So the purple line here is the baseline TF IDF system, which doesn't have any machine learning involved, it just has a little bit of hand weight tuning.",
                    "label": 0
                },
                {
                    "sent": "The blue line is the maximum model, and the red and green lines are the Adaboost angithi model.",
                    "label": 0
                },
                {
                    "sent": "So they're giving a nice a nice win.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that set up the basic model, which is kind of standard, and what we're going to do now is try and use the user click information we have.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To improve our predicted relevance.",
                    "label": 1
                },
                {
                    "sent": "And so we can do this in two ways.",
                    "label": 0
                },
                {
                    "sent": "We're going to do it by directly looking at the observed click history rates for ads, and then we want to do it more broadly with a query ad click translation model that applies to ads that we haven't seen.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "4.",
                    "label": 0
                },
                {
                    "sent": "So for observed click history, we want to use this because the previous click history is the best predictor of future click history, and so we're going to just collect the aggregate click rates from statistics from our logs at multiple levels of granularity.",
                    "label": 1
                },
                {
                    "sent": "So these are the same type of click feedback features that have been mentioned in the last talk, and so at the most granular level will look at a specific query, ad pairs or query advertiser pairs and then backing off a bit.",
                    "label": 0
                },
                {
                    "sent": "We can look at the click rates for an ad or an advertiser in the context of any query.",
                    "label": 0
                },
                {
                    "sent": "And finally, we can look at just the query level.",
                    "label": 0
                },
                {
                    "sent": "So what's the click rate on this query in the context of any ad?",
                    "label": 1
                },
                {
                    "sent": "So these broader advocates are less precise, but have much higher coverage.",
                    "label": 0
                },
                {
                    "sent": "So for instance, on our relevance model training data, we only have sufficient statistics at the query ad level for about 10% of the observed ads, and at the query level we have more like 99%.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So often we have this insufficient click history for unseen ads that are new to the system or infrequent query ad pairs that occur very rarely, and so we want to develop a model that predicts click propensity based on the query add text, which would then be independent of any individual ad so we can learn relationship between a query in an ad title that can be applied to previously unseen query ad pairs.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or very rare query adverse.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to use the same translation modeling approach with A twist, and so basically want to learn this query title translation model.",
                    "label": 1
                },
                {
                    "sent": "So we're going to say what's the probability of the document, which is an add in our case, given a query and we use the IBM Model 1 as well, and the translation probabilities here.",
                    "label": 0
                },
                {
                    "sent": "The twist is that we're going to use our web logs as a corpus, and so in computing the translation scores, we take account of the word in the query in the ad occurring together and divide that by the.",
                    "label": 1
                },
                {
                    "sent": "Number of times in an ad word occurs.",
                    "label": 0
                },
                {
                    "sent": "Overall queries and the main difference here is we're going to build 2 models, so we're going to build 1 model based on the click log.",
                    "label": 0
                },
                {
                    "sent": "So we're in that case we're looking at how many times a query ad pair was clicked, or actually how many times that particular query word and Edward curd in a click context.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to look again at build a separate model over the just the views, and the reason we want to do this is if we look at only the click logs.",
                    "label": 0
                },
                {
                    "sent": "We might overestimate particular relationships, so if a.",
                    "label": 0
                },
                {
                    "sent": "Particular query ad word pair gets a massive amount of traffic.",
                    "label": 0
                },
                {
                    "sent": "It might get a pretty significant click signal, but mainly because it's just finished so shown so many times.",
                    "label": 0
                },
                {
                    "sent": "So by taking this ratio of the translation probability from our click logs divided by our view logs, we can normalize for that.",
                    "label": 0
                },
                {
                    "sent": "So something that's shown in order amount of times and doesn't get very many clicks will have a lower ratio here.",
                    "label": 0
                },
                {
                    "sent": "So basically if you get to the average number of clicks, this ratio will be equal to 1 and better than average will be higher and worse than average will be lower.",
                    "label": 0
                },
                {
                    "sent": "And I should mention that the.",
                    "label": 0
                },
                {
                    "sent": "The views we use, expected clicks and so we normalize per position so that things that occur in lower positions have less weight in higher positions, have more weight in the details of that are in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results for using the clicks in relevance modeling problem.",
                    "label": 0
                },
                {
                    "sent": "The first line on the table here is just the baseline model that was presented in the first part of the talk and the 2nd is by adding the directly observed click history.",
                    "label": 1
                },
                {
                    "sent": "So you see, we get a decent boost and precision there in about the same recall.",
                    "label": 1
                },
                {
                    "sent": "So we get a bit of a win there in the third line is using the translation model only, so here we're not using any specific click history but just the scores provided by the click translation model and then by combining them.",
                    "label": 0
                },
                {
                    "sent": "We get a small win so I should mention the translation is basically giving us an improvement in the recall which matches our intuitive intuition because it's helping us with ads that we haven't had any previous information about, and it's giving us as compared to our baseline model, which basically just textual overlap features.",
                    "label": 0
                },
                {
                    "sent": "We now have these translation tables, which allows us to detect semantic similarity essentially.",
                    "label": 0
                },
                {
                    "sent": "In broad sense, we've learned some synonyms, and so we're able to detect related ads that don't have exact textual overlap, and I should mention that all of these results are pairwise statistically signif.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what the precision recall graph looks like for three of these models, the red line is the baseline GT model that has just the text features without any click information and the green line is adding the translation features to that, so we get a nice consistent when it costs all of our operating points and then by adding in this specifically observed click history, that's the blue line, and so you can see we get a win at that high precision regions.",
                    "label": 0
                },
                {
                    "sent": "There, it's improving a bit over at having just the translation features alone.",
                    "label": 0
                },
                {
                    "sent": "So we built this model and improved it with the user click information, and now I'll talk a bit about the applications in this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Search world and how we can use it to improve.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That and I'll motivate that with a bit of an example.",
                    "label": 0
                },
                {
                    "sent": "So first of all, here's what a typical Yahoo serve looks like for pretty commercial queries.",
                    "label": 0
                },
                {
                    "sent": "So if you search for digital cameras, there's a fair amount of things going on, so we have everything in yellow.",
                    "label": 0
                },
                {
                    "sent": "There is the North ads, so they add zit occur above the organic search results, and then we also have ads coming down the right hand side of the page here in the East, and so in order to build this page, we first need to do a candidate retrieval and select all of the potential ads from our ads database that we might want to show for this query.",
                    "label": 0
                },
                {
                    "sent": "And then use the ranking model that has been talked about to choose the order and then finally we have a page placement algorithm decides how many ads do we want to put on top.",
                    "label": 0
                },
                {
                    "sent": "Because this is a pretty commercial query that has a lot of revenue, we have the maximum number of ads in the North here.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, but we also have examples where we could be doing a much better job.",
                    "label": 1
                },
                {
                    "sent": "So here's a query where the user would put in mutual information and get some results that are probably not matching their intent, and so they're basically getting mutual funds and information about mutual funds, which.",
                    "label": 0
                },
                {
                    "sent": "Is not not what we'd like to do, So what we want to have is a model that can predict that the relevance here is low, and maybe some of these ads.",
                    "label": 0
                },
                {
                    "sent": "We'd like to take off the page completely, and others of them we'd like to at least take out of the North of the page and move, so I won't.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You dwell on that too long.",
                    "label": 0
                },
                {
                    "sent": "So here's the first application of using.",
                    "label": 0
                },
                {
                    "sent": "The relevance model is to basically remove the low quality ads off the page completely and so we can do this by just looking at our predicted relevance score, picking a threshold, and deciding to take it.",
                    "label": 1
                },
                {
                    "sent": "Take all those ads off the page completely.",
                    "label": 0
                },
                {
                    "sent": "So we ran this in a in a bucket for two weeks on 2% of our traffic and we basically were able to filter 50% of those ads that would be created by humans as bad and while only filtering 10% of the stuff that was.",
                    "label": 0
                },
                {
                    "sent": "That was not bad.",
                    "label": 0
                },
                {
                    "sent": "And in terms of what that meant for the user interactions, we reduced coverage of ads by almost 10%, and so that's the number of queries that have an ad and we reduce the add depth by 12%, which is the number of ads that you would see per query.",
                    "label": 0
                },
                {
                    "sent": "So we have a significant reduction there.",
                    "label": 0
                },
                {
                    "sent": "And the overall clickthrough rate went up by 10%, which is somewhat expected given the large drop in coverage and depth that we have is somewhat unexpected or positive.",
                    "label": 1
                },
                {
                    "sent": "Result is that the total ad clicks went up by 1/2%, so even though we're showing about 10% less ads overall, the number of clicks that we got on our ads increased.",
                    "label": 0
                },
                {
                    "sent": "So we were really able to remove only those ads that were probably not useful.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The users.",
                    "label": 0
                },
                {
                    "sent": "So the second application is ad ranking and this is basically just A twist on what has been presented earlier and so we want to be ranking the ads by some function of Biden, probability of click, and so we're just going to augment that probability of click model by providing our predicted relevance as a feature.",
                    "label": 1
                },
                {
                    "sent": "And so the impact here is that we can improve when the click model history is sparse, and so the two graphs that are on the screen here are for a segment of the test data where we have either no.",
                    "label": 0
                },
                {
                    "sent": "The left one is we have no data for the advertiser at all and the right one is that we have no data for the.",
                    "label": 0
                },
                {
                    "sent": "For more slightly more specific case so.",
                    "label": 0
                },
                {
                    "sent": "But basically we have not seen very many clicks or views of this at all, and so we're able to improve it by adding in this relevance model which is based more on the syntax.",
                    "label": 0
                },
                {
                    "sent": "In the text of the ads, whereas the click model otherwise would heavily biased towards the click features.",
                    "label": 0
                },
                {
                    "sent": "So for these kind of longer tail and new ads, we're able to improve the relevance here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally we have the optimization problem where we want to decide where to place ads on the search page.",
                    "label": 1
                },
                {
                    "sent": "So in the example that I showed that could use some improvement, we might not be able to say that we want to take the ad off the page completely, but if we are somewhat confidence it's a lower quality ad, we can push it off the top of the page to the side, which makes it a still improves the user experience significantly, and So what we did in this experiment was to consider the ad will AD predicted ad relevance and the predicted web relevance.",
                    "label": 0
                },
                {
                    "sent": "So we have our model that predicts the ad relevance and we also have the web search.",
                    "label": 0
                },
                {
                    "sent": "Model and so we can compare the prediction predicted relevance of each of these two models and if we have the ad relevance at a much lower, is predicted to be much lower than the web relevance.",
                    "label": 0
                },
                {
                    "sent": "We can basically make sure we don't show the ad on top of the page and push it off to the side.",
                    "label": 0
                },
                {
                    "sent": "So the bucket results here where that we reduced the metric.",
                    "label": 0
                },
                {
                    "sent": "We have called Northside impact with there's more details in the paper, but it's basically how how much putting ads on top of the page reduces the user experience and so the overall clickthrough rate on the North ads improved by 1 1/2% and the total clicks.",
                    "label": 0
                },
                {
                    "sent": "Again improved by almost 1%.",
                    "label": 0
                },
                {
                    "sent": "So we are these metrics latest to leave that we're improving the user.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parents.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to wrap it up and get your lunch and I'll just say that we developed a useful ad relevance model and improve the performance using user click data and extended it to new ads that we haven't seen before by using a click translation model and then incorporated this in a sponsored search system to show that we can remove low quality ads, improve the ad ranking, and improve the placement of the ads.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the page.",
                    "label": 0
                },
                {
                    "sent": "So thanks, thank you.",
                    "label": 0
                },
                {
                    "sent": "Hey, any questions or no I want to give you some lunch.",
                    "label": 0
                },
                {
                    "sent": "OK. Find a big place.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah?",
                    "label": 0
                },
                {
                    "sent": "They say it again.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I mean we one thing is the corpus that they learn their translation from is a different corpus, so they're basically looking at database itself, whereas we're learning the.",
                    "label": 0
                },
                {
                    "sent": "So I think they're they're learning advertiser behavior, so what's a good match between a landing page in a bid phrase so they're learning, given an advertiser has this landing page, what's the?",
                    "label": 0
                },
                {
                    "sent": "What's the relevant phrase?",
                    "label": 0
                },
                {
                    "sent": "And in our context, we're learning a different translation model, which is given that we present this add to the user, and when they've typed this query, what's the click propensity?",
                    "label": 0
                },
                {
                    "sent": "What do we think the click propensity of the ads is?",
                    "label": 0
                },
                {
                    "sent": "And so the I think because of those because of that difference, it's not too much of a conflict of interest.",
                    "label": 0
                },
                {
                    "sent": "And that that model we don't have it there.",
                    "label": 0
                },
                {
                    "sent": "Model that both presented isn't in in our system right now, so it's not introducing that bias.",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "Correct?",
                    "label": 0
                },
                {
                    "sent": "Directions.",
                    "label": 0
                },
                {
                    "sent": "Are analysts judgments and five level skill.",
                    "label": 0
                },
                {
                    "sent": "But yeah.",
                    "label": 0
                },
                {
                    "sent": "Sure, yeah, I guess basically our main motivation initially was to remove the low quality ads from the service completely so it was a classification problem that we were casting it as and so the.",
                    "label": 0
                },
                {
                    "sent": "I guess the learning to rank is a little bit more complex problem and so we don't think we need to spend the effort on distinguishing between, say good in a in a perfect dead we mainly wanted to just focus on detecting the low quality ads, so we cast it as a classification problem.",
                    "label": 0
                },
                {
                    "sent": "We've also tested it with the regression as a learning to rank problem and the results are essentially similar.",
                    "label": 0
                },
                {
                    "sent": "But because our goal was basically to detect just the bad ads, we simplified it to that classification problem, but the results aren't too different.",
                    "label": 0
                },
                {
                    "sent": "If you do learning to rank.",
                    "label": 0
                },
                {
                    "sent": "But it could be better with toys restaurant.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so actually I didn't present the rules here, but we've we've tried both ways and for the for the tasks that I presented our live system, the results are pretty much comprable.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Any other question?",
                    "label": 0
                },
                {
                    "sent": "OK, well this concludes the session, so let's say this.",
                    "label": 0
                }
            ]
        }
    }
}