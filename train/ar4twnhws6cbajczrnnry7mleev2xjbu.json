{
    "id": "ar4twnhws6cbajczrnnry7mleev2xjbu",
    "title": "Evaluation Method For Feature Rankings And Their Aggregations For Biomarker Discovery",
    "info": {
        "author": [
            "Ivica Slavkov, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Oct. 5, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Biology",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlsb09_slavkov_emffr/",
    "segmentation": [
        [
            "So hello everybody, I'm if it's a sloth cough and how we talking about evaluation method for feature rankings and their aggregations.",
            "And as applied to biomarker discovery, so first."
        ],
        [
            "This is the outline of my talk.",
            "First, I will inspect the standard first.",
            "I will introduce the.",
            "I will introduce and give background to the problem we are considering.",
            "Then I will more formally define it.",
            "I will further present my evaluation methods for feature rankings and at the end of course experiments present experiments.",
            "The results from those experiments and some conclusions.",
            "So first."
        ],
        [
            "A little bit intro.",
            "So what are biomarkers?",
            "So this is a session about biomarkers, so I thought I first begin with defining modern biomarkers.",
            "So probably all of you know this, but their biological so basically biomarkers can be anything.",
            "Their biological parameters, which are usually used in medicine in Association with the presence or status of a certain disease.",
            "So.",
            "So connected to this would be biomarker discovery.",
            "So biomarker discovery is simply the process of finding these biological parameters that have the strongest Association with the presence or status of some disease.",
            "So I will also introduce two terms which are related to the process of buying."
        ],
        [
            "Discovery from machine learning.",
            "Those are future ranking an feature selection.",
            "So once so on one side here we have feature ranking which basically you have you input the data set and then the feature ranking algorithm outputs unordered list of features by by some importance.",
            "So this would be useful for example in the context of biomarker discovery if we're looking for drug targets.",
            "So for individual drug targets, so another thing related biomarker discovery is the process of feature selection, which actually outswim put the data set and algorithm outputs a subset of important features.",
            "So this would be useful in the context of biomarker discovery for finding diagnostic set of markers which would work to get together good As for, prognostic, or 4.",
            "Or for a?"
        ],
        [
            "Our purpose is so what's the problem now?",
            "Moving on to the problem, what's the problem with biomarker discovery?",
            "So we have.",
            "So.",
            "So we have a certain problem that we are considering.",
            "Let it be cancer versus non cancer.",
            "So one analysis on the on one axis we have different analysis methods and on the other we have different studies.",
            "So each so we have the same study and we apply different analysis methods.",
            "Each one produces different results.",
            "So different ordering of the gene genes or gene lists.",
            "And also if we apply when the same methods on the different studies of the same problem, again we will end up with completely different lists of genes or markers.",
            "So a little bit more."
        ],
        [
            "Formally, just if we have our data set D, which is composed of samples S1 through SK.",
            "And this data set D has features F1 to FN.",
            "We apply some, so we apply some ranking algorithm R on it which.",
            "In relation to some class or feature or target feature of interest, so meaning in relation to cancer or no cancer.",
            "So this ranking algorithm as output produces importance of each feature which we then used to infer.",
            "Kind of a ranking between the features.",
            "So here we have the importance of the features produced by the ranking algorithms and then we have the inferred feature rankings.",
            "So this holds true for the feature ranking that.",
            "They are ordered by by decreasing importance.",
            "So the problem is that if we have different ranking methods or different studies of the same problem, they all infer completely different.",
            "And they all give completely different importance.",
            "But the problem is they not the different importance but the different ranking, which is inferred after that.",
            "So.",
            "So."
        ],
        [
            "Go back to the slide about feature ranking and feature selection for feature selection.",
            "The evaluation of the selected subset of feature is pretty straightforward.",
            "Use the accuracy of the predictive models, but for future ranking there is no explicit measures to do that, so we're kind of trying to develop an evaluation methods method for feature ranking."
        ],
        [
            "So until now I gave the introduction and talked about the I defined the problem and now I will present the actually the method for feature rankings."
        ],
        [
            "So this graph here shows what the overall process of.",
            "Of of how this valuation method?",
            "How do we use this valuation method so we begin with a data set with sample certain samples and features and then we apply a ranking method on it which produces a ranked list of features after that.",
            "So I just want to say that this method is still based on predictive accuracy.",
            "Still tide the we still relate the feature ranking.",
            "We want to relate somehow to the predictive accuracy.",
            "So that's why from the by using the ranked list of features and the data set, we create data subsets.",
            "So we create the first data subsets subset here, which is actually the original data set but with just the top ranked feature.",
            "Then we had the second top ranked feature and we create a new data subset and we proceed with this process until we end up with all of the ranked with all of the features.",
            "So this again gives us the original data set basically, so for each one of these data subsets.",
            "After that we create predictive models and we evaluate them and then we produce and then we record the error for each one of them.",
            "So at the end we end up with a so-called error curve.",
            "So here."
        ],
        [
            "On The xx axis you have the number of features that you're using and on the Y axis you have the error in percentage.",
            "So this is kind of an idealized error code that you're getting, so you begin with just a single feature and it gives you some error and your valid.",
            "Somehow it's error, and then as you add more and more features the error decreases until it until it goes into.",
            "It basically goes into saturation.",
            "It doesn't decrease anymore.",
            "And this is again an idealized case, because usually what happens is when you add more features, the noise get bigger.",
            "And actually there also starts increasing.",
            "So besides using directly there, the first, most intuitive thing is a numerical indicator of which can be derived from.",
            "This error curve is basically using the."
        ],
        [
            "Area under the error curve for deriving some kind of a numerical score for how good is a feature ranking.",
            "So so also in the in this specific application of biomarker discovery you're most interested in what happens at the beginning of the curve.",
            "So when calculating the area under this curve, you usually we use.",
            "Some kind of a weighting function which assigns bigger weight at the beginning of the of the area and then the this waiting decreases as we move.",
            "As we increase the number of features."
        ],
        [
            "So now I'm going to talk about a little bit.",
            "The experiments which we performed with this evaluation method."
        ],
        [
            "So first, the datasets that we use.",
            "Basically they were never blossom expression data, so neuroblastoma is a childhood tumor.",
            "We we used just three public studies with different sizes.",
            "One is so we did Creator Schramm and the one study so they all have different sizes.",
            "The smallest one has 17.",
            "The second study has 63 which is kind of a normal size for microarray study and 3rd one is bigger around 100.",
            "So the target, the target of interest which were investigating was the relapse or no relapse stages of a patients of a patient.",
            "So this is biologically important.",
            "For this disease, because it's basically, this determines whether the patient needs more aggressive treatment or not.",
            "After the removal of the tumour sweater, he's in risk to have the cancer repeated after it's removed."
        ],
        [
            "So the experimental scenarios that we perform.",
            "So basically we wanted with our valuation measure to compare to compare two things, first to compare the behavior of different ranking algorithms.",
            "So basically we took different ranking algorithms, so one based on simple info game, then relief F random forest and efms redundant feature elimination.",
            "Oh, and we tested them on individual studies, so meaning we took each study and we we ran basically different ranking algorithms on it.",
            "Also we.",
            "Second issue that we wanted to explore was whether aggregating different feature rankings kind of improves the.",
            "Do we get a more robust overall ranking.",
            "So we tried basically two scenarios, first aggregating so on the same studies you run different algorithms and then you aggregate this feature rankings by using just simple aggregation functions like mean, median, minimum and maximum and the second thing which we tried with.",
            "Aggregation was actually aggregating feature rankings derived from multiple studies and we compare this with feature rankings derived just from the single studies.",
            "So for evaluating Darrow we use this so called .632 plus Bootstrap estimator which is basically normal cross validation.",
            "Which also which also has included Bootstrap in it.",
            "Basically you get the error estimate same as in cross validation, but you also do Bootstrap resampling to get a smoother curve.",
            "So is a predictive model.",
            "Although we tried different things at the end, we decided to use an Eve base, just a simple predictor at the end for for building the predictive models from the different data subsamples.",
            "So this is the how the output will look which how, which I will further discuss so basically."
        ],
        [
            "On the X axis we have.",
            "We used the logarithm of number of features because we basically wanted to focus more.",
            "What happens in the beginnings of the curve.",
            "So when you add the first features basically in that way when we when we use, when you calculate the area under the curve, we already have wait, we already have a bigger weight assigned at the beginning and on the Y axis we have the error in percentage.",
            "And in the top right corner we have the different so algorithms, so different coding conditions.",
            "Which we compare.",
            "Uh."
        ],
        [
            "So first the results from the individual studies.",
            "So their curves.",
            "So I just want to say that here there is also ordered in such a way that horizontally we have ordered the datasets by size by increasing size and here we have basically compared.",
            "Different ranking algorithms versus the different aggregation methods used.",
            "So basically first if we take a look horizontally, we can immediately notice some kind of a data set effects size.",
            "Basically, if we consider this small data set which is not a very good quality, we see that the algorithms behave very differently.",
            "So and then as the data set size increases, the algorithms have more and more similar.",
            "More and more similar error curves and also another effect is which can be notices that the curves are much more valuable when you small small data sizes, which is kind of expected.",
            "Also, when we see considering the aggregations, most of them behave similarly, but when we later when we see the.",
            "The the areas will see that usually median is the best in this case, but the major actually the major gain from using for using aggregation is that the curves that you get are much more much less variable and much more stable.",
            "And we think that this is also related to the stability of the feature rankings.",
            "Um?",
            "So if we look at the."
        ],
        [
            "Individuals, the error curves there, so the area under their curves of the individual studies.",
            "So here we have from the different algorithms and here we have the results from the different aggregations."
        ],
        [
            "So basically if we look at the bolded figures there, so the here the rule smaller is better applied, so the smaller the area under their curve the better so here.",
            "We have highlighted the actually the smallest value for each algorithm is an for each aggregate aggregate method.",
            "Actually for each study so we can see that in both cases in two cases SVM is the best and in one case the relief F algorithm is best, but for the aggregations we can see, although I have highlighted the mean value, still we consider it's highly compatible to the median value and I would say that the median is the.",
            "The best in this case.",
            "So what we can conclude basically from the.",
            "Here from the from the areas that feature rankings from different algorithms have similar error curves, but unless the data size is very small.",
            "And I'm getting feature rankings from different algorithms.",
            "If we use the median, so we usually obtain the best results.",
            "Although the area under the curve is compareable to individual algorithms but still the major gain with aggregating is the curves that we get are much less variable.",
            "So concerned."
        ],
        [
            "The multiple studies analysis scenario.",
            "So here again we have the data sets ordered by sides, but here we have.",
            "We're actually presenting testing on, so this is we learn on study one we tested on study.",
            "Let's say the prayer in the first case, then we learn on study two.",
            "We again test it on the printer so.",
            "So here we have presented if we learn on once study, test it on the learning on the other tests on the printer and we compare it to the best of the aggregations.",
            "So here we have presented aggregations and here we compare it to the best of the aggregations.",
            "So again.",
            "Here what we can see is that.",
            "Here what we can see is that basically the.",
            "When I'm gonna get in future rankings from different so basically from different studies he has some beneficial effect which makes sense becausw we're kinda pulling information from more data sets.",
            "And when testing on the smallest datasets, dairy estimates are very unstable.",
            "If."
        ],
        [
            "Take a look at the so if we take a look at the error curves so on top on top we present the test set that we're testing on and here we have not so much the ranking method but more than on how we how we derive that ranking.",
            "So the 1st two are the 1st three are the datasets that we arrived the ranking from and the 2nd three are basically the methods that we use to aggregate two studies.",
            "And here we have which datasets we aggregated.",
            "So."
        ],
        [
            "If we take a look at this results.",
            "So we can see if we use the minimum aggregation.",
            "In the first case, the area is much smaller than if we.",
            "If we if we don't aggregate well.",
            "In the second case we can see that actually there's a decrease in performance that the air curve is worse than using individual datasets.",
            "So we link this basically because we're here, we're aggregating the smallest data set with the biggest and basically are assigning the same weight to the feature ranking produced by the smaller and.",
            "Less quality data set as to the bigger one, so so the smaller data set basically has the I mean.",
            "It basically makes makes the feature ranking worse.",
            "So this this leads us to conclude that we need more sophisticated aggregation method or doing with this.",
            "Initially we show that there's an improvement when you combine feature rankings derived from different studies.",
            "But still we need to do this in a more sophisticated manner.",
            "Example to take into account different study sizes or previously assess the study quality.",
            "Oh so I'm just briefly again going to summarize."
        ],
        [
            "Represented so I've presented.",
            "I've explored the problem of biomarker discovery is a problem of evaluating feature rankings.",
            "I presented an evaluation methodology for future rankings, which is again linked to predictive performance by by producing a so-called error curve.",
            "And we also use the area under this error curve as a numerical indicator of quality.",
            "So when we believe that experimental results show that devolution method is useful for comparing feature rankings in terms that it can clearly distinguish between feature rankings that are produced.",
            "So that's why we actually took different study sizes because usually smaller study sizes have.",
            "We have much worse quality and then we would we would expect our method to be able to detect this.",
            "Actually the error curves to be able to show that one ranking derived from from a smaller data set is worse than the ranking derives from a bigger one, and we also then we can also conclude that the aggregation of rankings weather different algorithms so different studies are beneficial for deriving more robust biomarker signatures.",
            "Although a proper way to aggregate this ranking is still to be explored.",
            "So.",
            "Thank you.",
            "So you're using accuracy for estimating the quality of the way you are going places, rankings and of course then you need to build a predictive model and you will be using nice days.",
            "Yes, I see that you are even arguing in the text in favor of not using an SVM where you select it with.",
            "Which to me is very strange because you say you think that you don't want to favor departure feature ranking of feature selection methods when you choose your predictive model.",
            "But as you must know, I mean the feature selection and the predictive model.",
            "There are linked together.",
            "I mean there are relationship with it.",
            "I mean SVM, RFE.",
            "Clearly we tend to use a linear SVM for classifier ready if you tend to use KNN or under arrest you tend to use random forests whatever.",
            "So it seems that all your.",
            "Kind of bias by the fact that you you are using feature ranking on one side and you are using predictive model that that do not fit well together.",
            "So especially and SVN Morrison multivariate technique in Naive Bayes use.",
            "Use consider feature independently of each other, so that seems very.",
            "Well, I don't think that there is always I wouldn't agree with that.",
            "There is a rule if use ranking algorithm A and then and also I don't have the data here presented, but we actually we actually compared using different classifiers at the end.",
            "So what was important for us is to have so basically.",
            "When using different classifiers at the end, you still end up with the similar results, so still.",
            "Phil ranking method one is better than ranking method to know no matter which classifier you use.",
            "So we basically wanted to avoid here.",
            "You know using a method that is completely the same for deriving the future rankings and then for building the predictive models.",
            "Because in that case, let's in that case we wouldn't be able to compare really the different algorithms.",
            "So if you use hmes for deriving the ranking and then SMS is classifier, I would expect that ACMS would always pop out as the best.",
            "But then.",
            "Over the best features.",
            "After all, metric is accuracy to Arthur building the best model.",
            "So if there are links between the feature ranking methods and the classifier used, but as you said if you did this to do, that's fine, but I would think that that would strengthen the results by showing that you may be for the purpose if you want.",
            "I agree with you for the purpose.",
            "If you want the purpose of this here was basically to.",
            "Not much to derive exactly.",
            "The most accurate biomarker set for a certain disease, so this was more to compare.",
            "Different ranking algorithms and I don't think that I would be able to compare them correctly if I used.",
            "If if I use coupled SVM SVM and then if I use relief F and SVM and then it would turn out that SVM is the best.",
            "But do you think that if we do that will change your conclusion if you switch like race or something, yeah.",
            "I I just wanted to avoid well having a bias, basically because I don't think that it will.",
            "It will change which ranking algorithm would be best in that contest.",
            "No, I we we tried actually different so.",
            "Yes.",
            "What, well, that's what I'm saying at the end the results are same ranking algorithm A is best no matter which classifier.",
            "Use after that.",
            "But I wanted to do this in a more neutral fashion than coupling it really to the same method.",
            "This is probably related to the absence of the gold standard here, and because yes.",
            "You can re late, geez, two particular diseases.",
            "I mean there's a lot of literature index.",
            "So not just optimizing the selection of features for particular classifier, which in a sense I agree with the comment before you are using.",
            "I mean you are doing right, but trying to use some other data source so literature to see if you're ranking corresponds to the carnal knowledge.",
            "OK, we thought about that.",
            "Yes, but that's not so easy.",
            "I mean, you would basically have to check this manually, and that's not so.",
            "So easy to do.",
            "Maybe you would have to go and.",
            "Search for everything manually and I haven't done that.",
            "But I would agree that at the end it would be the best validation would be to derive the best, let's say ranking and then to see how much this overlaps with the literature.",
            "So.",
            "Screams wait?",
            "The normal usage is that you're looking for biomarkers one or a few things he wants to measure.",
            "Measure.",
            "Very strong.",
            "Yes.",
            "Proper experience is that their fight against that.",
            "Learning outcomes with paper or smaller.",
            "Uh, so.",
            "Yeah.",
            "You're using the term very strangely, not normal.",
            "Well, uh.",
            "I'm using the term.",
            "Basically I I don't think that I'm using the term.",
            "Strangely, at the end you would want to end up with small number.",
            "I agree about that but but the whole but the whole process of this.",
            "But don't they do screening first 4 so like the whole genes when you do the microarray thing first?",
            "4.",
            "Sorry.",
            "Grab sign up to Margaret 4 which is put that stands for.",
            "No, my marker.",
            "No, but you're but here you weren't actually selecting the biomarkers would just you begin with the whole list of genes from the microarray.",
            "You get them sorted somehow and you want to know how much that sorting is OK. Why isn't I?",
            "I don't understand.",
            "Why isn't biomarker discovery feature selection at all?",
            "Yeah, so it's.",
            "Yeah, but that's why I have put put weight on it so it's.",
            "Then use our initial parts.",
            "You know very very small number of markers.",
            "Yes, yes.",
            "When you do the area.",
            "This initial part count is much, much more than those expected.",
            "So that's very much consistent with what you have been saying, yes.",
            "I'm going to go to a terminology issue that it got really using tons of them.",
            "They are no longer part.",
            "Yes, I yeah, I agree.",
            "Question that was asked before about using some external gold standard.",
            "OK.",
            "Sometimes, if that's really what the task is that you know, if it were a perfect world and you had labels on jeans, then you could just value with respect to those.",
            "And this is a way to get close to that by using predictive accuracy of the class label.",
            "I don't think that this actually accomplishes the same thing, because a lot of these models are optimizing accuracy, so they're they're discriminative, so you know if you imagine a case where you have two, 100% identical paralogs that are doing essentially the same thing.",
            "The SVM, RFE, for example, will give one of them arbitrarily a high rank, and the second one doesn't introduce any new information, so it gets a low rank, and that would be the right thing to do for the discriminative POV exactly.",
            "The information that in fact there.",
            "Second one is just as important.",
            "As a as a possible good target.",
            "So I wonder whether this is a different formulation or or basically, but it seems like this this approach doesn't solve the problem of finding which genes are relevant to a particular task.",
            "It solves a different, more directed task of optimizing accuracy.",
            "Yes.",
            "Yeah it is, I think.",
            "I want to make approach in the previous talk that you go group by group.",
            "Sure.",
            "Questions include this session."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everybody, I'm if it's a sloth cough and how we talking about evaluation method for feature rankings and their aggregations.",
                    "label": 0
                },
                {
                    "sent": "And as applied to biomarker discovery, so first.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "First, I will inspect the standard first.",
                    "label": 0
                },
                {
                    "sent": "I will introduce the.",
                    "label": 0
                },
                {
                    "sent": "I will introduce and give background to the problem we are considering.",
                    "label": 0
                },
                {
                    "sent": "Then I will more formally define it.",
                    "label": 0
                },
                {
                    "sent": "I will further present my evaluation methods for feature rankings and at the end of course experiments present experiments.",
                    "label": 1
                },
                {
                    "sent": "The results from those experiments and some conclusions.",
                    "label": 0
                },
                {
                    "sent": "So first.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit intro.",
                    "label": 0
                },
                {
                    "sent": "So what are biomarkers?",
                    "label": 0
                },
                {
                    "sent": "So this is a session about biomarkers, so I thought I first begin with defining modern biomarkers.",
                    "label": 0
                },
                {
                    "sent": "So probably all of you know this, but their biological so basically biomarkers can be anything.",
                    "label": 0
                },
                {
                    "sent": "Their biological parameters, which are usually used in medicine in Association with the presence or status of a certain disease.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So connected to this would be biomarker discovery.",
                    "label": 0
                },
                {
                    "sent": "So biomarker discovery is simply the process of finding these biological parameters that have the strongest Association with the presence or status of some disease.",
                    "label": 1
                },
                {
                    "sent": "So I will also introduce two terms which are related to the process of buying.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Discovery from machine learning.",
                    "label": 0
                },
                {
                    "sent": "Those are future ranking an feature selection.",
                    "label": 1
                },
                {
                    "sent": "So once so on one side here we have feature ranking which basically you have you input the data set and then the feature ranking algorithm outputs unordered list of features by by some importance.",
                    "label": 1
                },
                {
                    "sent": "So this would be useful for example in the context of biomarker discovery if we're looking for drug targets.",
                    "label": 0
                },
                {
                    "sent": "So for individual drug targets, so another thing related biomarker discovery is the process of feature selection, which actually outswim put the data set and algorithm outputs a subset of important features.",
                    "label": 1
                },
                {
                    "sent": "So this would be useful in the context of biomarker discovery for finding diagnostic set of markers which would work to get together good As for, prognostic, or 4.",
                    "label": 0
                },
                {
                    "sent": "Or for a?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our purpose is so what's the problem now?",
                    "label": 0
                },
                {
                    "sent": "Moving on to the problem, what's the problem with biomarker discovery?",
                    "label": 1
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we have a certain problem that we are considering.",
                    "label": 0
                },
                {
                    "sent": "Let it be cancer versus non cancer.",
                    "label": 1
                },
                {
                    "sent": "So one analysis on the on one axis we have different analysis methods and on the other we have different studies.",
                    "label": 0
                },
                {
                    "sent": "So each so we have the same study and we apply different analysis methods.",
                    "label": 0
                },
                {
                    "sent": "Each one produces different results.",
                    "label": 0
                },
                {
                    "sent": "So different ordering of the gene genes or gene lists.",
                    "label": 0
                },
                {
                    "sent": "And also if we apply when the same methods on the different studies of the same problem, again we will end up with completely different lists of genes or markers.",
                    "label": 0
                },
                {
                    "sent": "So a little bit more.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formally, just if we have our data set D, which is composed of samples S1 through SK.",
                    "label": 0
                },
                {
                    "sent": "And this data set D has features F1 to FN.",
                    "label": 0
                },
                {
                    "sent": "We apply some, so we apply some ranking algorithm R on it which.",
                    "label": 0
                },
                {
                    "sent": "In relation to some class or feature or target feature of interest, so meaning in relation to cancer or no cancer.",
                    "label": 0
                },
                {
                    "sent": "So this ranking algorithm as output produces importance of each feature which we then used to infer.",
                    "label": 0
                },
                {
                    "sent": "Kind of a ranking between the features.",
                    "label": 0
                },
                {
                    "sent": "So here we have the importance of the features produced by the ranking algorithms and then we have the inferred feature rankings.",
                    "label": 0
                },
                {
                    "sent": "So this holds true for the feature ranking that.",
                    "label": 0
                },
                {
                    "sent": "They are ordered by by decreasing importance.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that if we have different ranking methods or different studies of the same problem, they all infer completely different.",
                    "label": 0
                },
                {
                    "sent": "And they all give completely different importance.",
                    "label": 0
                },
                {
                    "sent": "But the problem is they not the different importance but the different ranking, which is inferred after that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go back to the slide about feature ranking and feature selection for feature selection.",
                    "label": 1
                },
                {
                    "sent": "The evaluation of the selected subset of feature is pretty straightforward.",
                    "label": 1
                },
                {
                    "sent": "Use the accuracy of the predictive models, but for future ranking there is no explicit measures to do that, so we're kind of trying to develop an evaluation methods method for feature ranking.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So until now I gave the introduction and talked about the I defined the problem and now I will present the actually the method for feature rankings.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this graph here shows what the overall process of.",
                    "label": 0
                },
                {
                    "sent": "Of of how this valuation method?",
                    "label": 0
                },
                {
                    "sent": "How do we use this valuation method so we begin with a data set with sample certain samples and features and then we apply a ranking method on it which produces a ranked list of features after that.",
                    "label": 1
                },
                {
                    "sent": "So I just want to say that this method is still based on predictive accuracy.",
                    "label": 0
                },
                {
                    "sent": "Still tide the we still relate the feature ranking.",
                    "label": 0
                },
                {
                    "sent": "We want to relate somehow to the predictive accuracy.",
                    "label": 0
                },
                {
                    "sent": "So that's why from the by using the ranked list of features and the data set, we create data subsets.",
                    "label": 1
                },
                {
                    "sent": "So we create the first data subsets subset here, which is actually the original data set but with just the top ranked feature.",
                    "label": 0
                },
                {
                    "sent": "Then we had the second top ranked feature and we create a new data subset and we proceed with this process until we end up with all of the ranked with all of the features.",
                    "label": 0
                },
                {
                    "sent": "So this again gives us the original data set basically, so for each one of these data subsets.",
                    "label": 1
                },
                {
                    "sent": "After that we create predictive models and we evaluate them and then we produce and then we record the error for each one of them.",
                    "label": 0
                },
                {
                    "sent": "So at the end we end up with a so-called error curve.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On The xx axis you have the number of features that you're using and on the Y axis you have the error in percentage.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of an idealized error code that you're getting, so you begin with just a single feature and it gives you some error and your valid.",
                    "label": 0
                },
                {
                    "sent": "Somehow it's error, and then as you add more and more features the error decreases until it until it goes into.",
                    "label": 0
                },
                {
                    "sent": "It basically goes into saturation.",
                    "label": 0
                },
                {
                    "sent": "It doesn't decrease anymore.",
                    "label": 0
                },
                {
                    "sent": "And this is again an idealized case, because usually what happens is when you add more features, the noise get bigger.",
                    "label": 0
                },
                {
                    "sent": "And actually there also starts increasing.",
                    "label": 0
                },
                {
                    "sent": "So besides using directly there, the first, most intuitive thing is a numerical indicator of which can be derived from.",
                    "label": 0
                },
                {
                    "sent": "This error curve is basically using the.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Area under the error curve for deriving some kind of a numerical score for how good is a feature ranking.",
                    "label": 1
                },
                {
                    "sent": "So so also in the in this specific application of biomarker discovery you're most interested in what happens at the beginning of the curve.",
                    "label": 0
                },
                {
                    "sent": "So when calculating the area under this curve, you usually we use.",
                    "label": 0
                },
                {
                    "sent": "Some kind of a weighting function which assigns bigger weight at the beginning of the of the area and then the this waiting decreases as we move.",
                    "label": 0
                },
                {
                    "sent": "As we increase the number of features.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm going to talk about a little bit.",
                    "label": 0
                },
                {
                    "sent": "The experiments which we performed with this evaluation method.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first, the datasets that we use.",
                    "label": 0
                },
                {
                    "sent": "Basically they were never blossom expression data, so neuroblastoma is a childhood tumor.",
                    "label": 1
                },
                {
                    "sent": "We we used just three public studies with different sizes.",
                    "label": 1
                },
                {
                    "sent": "One is so we did Creator Schramm and the one study so they all have different sizes.",
                    "label": 0
                },
                {
                    "sent": "The smallest one has 17.",
                    "label": 0
                },
                {
                    "sent": "The second study has 63 which is kind of a normal size for microarray study and 3rd one is bigger around 100.",
                    "label": 0
                },
                {
                    "sent": "So the target, the target of interest which were investigating was the relapse or no relapse stages of a patients of a patient.",
                    "label": 1
                },
                {
                    "sent": "So this is biologically important.",
                    "label": 0
                },
                {
                    "sent": "For this disease, because it's basically, this determines whether the patient needs more aggressive treatment or not.",
                    "label": 0
                },
                {
                    "sent": "After the removal of the tumour sweater, he's in risk to have the cancer repeated after it's removed.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the experimental scenarios that we perform.",
                    "label": 1
                },
                {
                    "sent": "So basically we wanted with our valuation measure to compare to compare two things, first to compare the behavior of different ranking algorithms.",
                    "label": 0
                },
                {
                    "sent": "So basically we took different ranking algorithms, so one based on simple info game, then relief F random forest and efms redundant feature elimination.",
                    "label": 1
                },
                {
                    "sent": "Oh, and we tested them on individual studies, so meaning we took each study and we we ran basically different ranking algorithms on it.",
                    "label": 0
                },
                {
                    "sent": "Also we.",
                    "label": 0
                },
                {
                    "sent": "Second issue that we wanted to explore was whether aggregating different feature rankings kind of improves the.",
                    "label": 0
                },
                {
                    "sent": "Do we get a more robust overall ranking.",
                    "label": 0
                },
                {
                    "sent": "So we tried basically two scenarios, first aggregating so on the same studies you run different algorithms and then you aggregate this feature rankings by using just simple aggregation functions like mean, median, minimum and maximum and the second thing which we tried with.",
                    "label": 0
                },
                {
                    "sent": "Aggregation was actually aggregating feature rankings derived from multiple studies and we compare this with feature rankings derived just from the single studies.",
                    "label": 1
                },
                {
                    "sent": "So for evaluating Darrow we use this so called .632 plus Bootstrap estimator which is basically normal cross validation.",
                    "label": 0
                },
                {
                    "sent": "Which also which also has included Bootstrap in it.",
                    "label": 0
                },
                {
                    "sent": "Basically you get the error estimate same as in cross validation, but you also do Bootstrap resampling to get a smoother curve.",
                    "label": 0
                },
                {
                    "sent": "So is a predictive model.",
                    "label": 0
                },
                {
                    "sent": "Although we tried different things at the end, we decided to use an Eve base, just a simple predictor at the end for for building the predictive models from the different data subsamples.",
                    "label": 0
                },
                {
                    "sent": "So this is the how the output will look which how, which I will further discuss so basically.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the X axis we have.",
                    "label": 0
                },
                {
                    "sent": "We used the logarithm of number of features because we basically wanted to focus more.",
                    "label": 0
                },
                {
                    "sent": "What happens in the beginnings of the curve.",
                    "label": 0
                },
                {
                    "sent": "So when you add the first features basically in that way when we when we use, when you calculate the area under the curve, we already have wait, we already have a bigger weight assigned at the beginning and on the Y axis we have the error in percentage.",
                    "label": 0
                },
                {
                    "sent": "And in the top right corner we have the different so algorithms, so different coding conditions.",
                    "label": 0
                },
                {
                    "sent": "Which we compare.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first the results from the individual studies.",
                    "label": 1
                },
                {
                    "sent": "So their curves.",
                    "label": 0
                },
                {
                    "sent": "So I just want to say that here there is also ordered in such a way that horizontally we have ordered the datasets by size by increasing size and here we have basically compared.",
                    "label": 0
                },
                {
                    "sent": "Different ranking algorithms versus the different aggregation methods used.",
                    "label": 0
                },
                {
                    "sent": "So basically first if we take a look horizontally, we can immediately notice some kind of a data set effects size.",
                    "label": 0
                },
                {
                    "sent": "Basically, if we consider this small data set which is not a very good quality, we see that the algorithms behave very differently.",
                    "label": 0
                },
                {
                    "sent": "So and then as the data set size increases, the algorithms have more and more similar.",
                    "label": 0
                },
                {
                    "sent": "More and more similar error curves and also another effect is which can be notices that the curves are much more valuable when you small small data sizes, which is kind of expected.",
                    "label": 0
                },
                {
                    "sent": "Also, when we see considering the aggregations, most of them behave similarly, but when we later when we see the.",
                    "label": 0
                },
                {
                    "sent": "The the areas will see that usually median is the best in this case, but the major actually the major gain from using for using aggregation is that the curves that you get are much more much less variable and much more stable.",
                    "label": 1
                },
                {
                    "sent": "And we think that this is also related to the stability of the feature rankings.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So if we look at the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Individuals, the error curves there, so the area under their curves of the individual studies.",
                    "label": 0
                },
                {
                    "sent": "So here we have from the different algorithms and here we have the results from the different aggregations.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basically if we look at the bolded figures there, so the here the rule smaller is better applied, so the smaller the area under their curve the better so here.",
                    "label": 0
                },
                {
                    "sent": "We have highlighted the actually the smallest value for each algorithm is an for each aggregate aggregate method.",
                    "label": 0
                },
                {
                    "sent": "Actually for each study so we can see that in both cases in two cases SVM is the best and in one case the relief F algorithm is best, but for the aggregations we can see, although I have highlighted the mean value, still we consider it's highly compatible to the median value and I would say that the median is the.",
                    "label": 0
                },
                {
                    "sent": "The best in this case.",
                    "label": 0
                },
                {
                    "sent": "So what we can conclude basically from the.",
                    "label": 0
                },
                {
                    "sent": "Here from the from the areas that feature rankings from different algorithms have similar error curves, but unless the data size is very small.",
                    "label": 1
                },
                {
                    "sent": "And I'm getting feature rankings from different algorithms.",
                    "label": 0
                },
                {
                    "sent": "If we use the median, so we usually obtain the best results.",
                    "label": 0
                },
                {
                    "sent": "Although the area under the curve is compareable to individual algorithms but still the major gain with aggregating is the curves that we get are much less variable.",
                    "label": 1
                },
                {
                    "sent": "So concerned.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The multiple studies analysis scenario.",
                    "label": 1
                },
                {
                    "sent": "So here again we have the data sets ordered by sides, but here we have.",
                    "label": 0
                },
                {
                    "sent": "We're actually presenting testing on, so this is we learn on study one we tested on study.",
                    "label": 0
                },
                {
                    "sent": "Let's say the prayer in the first case, then we learn on study two.",
                    "label": 0
                },
                {
                    "sent": "We again test it on the printer so.",
                    "label": 0
                },
                {
                    "sent": "So here we have presented if we learn on once study, test it on the learning on the other tests on the printer and we compare it to the best of the aggregations.",
                    "label": 0
                },
                {
                    "sent": "So here we have presented aggregations and here we compare it to the best of the aggregations.",
                    "label": 0
                },
                {
                    "sent": "So again.",
                    "label": 0
                },
                {
                    "sent": "Here what we can see is that.",
                    "label": 0
                },
                {
                    "sent": "Here what we can see is that basically the.",
                    "label": 0
                },
                {
                    "sent": "When I'm gonna get in future rankings from different so basically from different studies he has some beneficial effect which makes sense becausw we're kinda pulling information from more data sets.",
                    "label": 0
                },
                {
                    "sent": "And when testing on the smallest datasets, dairy estimates are very unstable.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Take a look at the so if we take a look at the error curves so on top on top we present the test set that we're testing on and here we have not so much the ranking method but more than on how we how we derive that ranking.",
                    "label": 1
                },
                {
                    "sent": "So the 1st two are the 1st three are the datasets that we arrived the ranking from and the 2nd three are basically the methods that we use to aggregate two studies.",
                    "label": 0
                },
                {
                    "sent": "And here we have which datasets we aggregated.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we take a look at this results.",
                    "label": 0
                },
                {
                    "sent": "So we can see if we use the minimum aggregation.",
                    "label": 0
                },
                {
                    "sent": "In the first case, the area is much smaller than if we.",
                    "label": 0
                },
                {
                    "sent": "If we if we don't aggregate well.",
                    "label": 0
                },
                {
                    "sent": "In the second case we can see that actually there's a decrease in performance that the air curve is worse than using individual datasets.",
                    "label": 0
                },
                {
                    "sent": "So we link this basically because we're here, we're aggregating the smallest data set with the biggest and basically are assigning the same weight to the feature ranking produced by the smaller and.",
                    "label": 0
                },
                {
                    "sent": "Less quality data set as to the bigger one, so so the smaller data set basically has the I mean.",
                    "label": 0
                },
                {
                    "sent": "It basically makes makes the feature ranking worse.",
                    "label": 0
                },
                {
                    "sent": "So this this leads us to conclude that we need more sophisticated aggregation method or doing with this.",
                    "label": 1
                },
                {
                    "sent": "Initially we show that there's an improvement when you combine feature rankings derived from different studies.",
                    "label": 1
                },
                {
                    "sent": "But still we need to do this in a more sophisticated manner.",
                    "label": 0
                },
                {
                    "sent": "Example to take into account different study sizes or previously assess the study quality.",
                    "label": 1
                },
                {
                    "sent": "Oh so I'm just briefly again going to summarize.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Represented so I've presented.",
                    "label": 0
                },
                {
                    "sent": "I've explored the problem of biomarker discovery is a problem of evaluating feature rankings.",
                    "label": 1
                },
                {
                    "sent": "I presented an evaluation methodology for future rankings, which is again linked to predictive performance by by producing a so-called error curve.",
                    "label": 0
                },
                {
                    "sent": "And we also use the area under this error curve as a numerical indicator of quality.",
                    "label": 0
                },
                {
                    "sent": "So when we believe that experimental results show that devolution method is useful for comparing feature rankings in terms that it can clearly distinguish between feature rankings that are produced.",
                    "label": 1
                },
                {
                    "sent": "So that's why we actually took different study sizes because usually smaller study sizes have.",
                    "label": 0
                },
                {
                    "sent": "We have much worse quality and then we would we would expect our method to be able to detect this.",
                    "label": 0
                },
                {
                    "sent": "Actually the error curves to be able to show that one ranking derived from from a smaller data set is worse than the ranking derives from a bigger one, and we also then we can also conclude that the aggregation of rankings weather different algorithms so different studies are beneficial for deriving more robust biomarker signatures.",
                    "label": 1
                },
                {
                    "sent": "Although a proper way to aggregate this ranking is still to be explored.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So you're using accuracy for estimating the quality of the way you are going places, rankings and of course then you need to build a predictive model and you will be using nice days.",
                    "label": 0
                },
                {
                    "sent": "Yes, I see that you are even arguing in the text in favor of not using an SVM where you select it with.",
                    "label": 0
                },
                {
                    "sent": "Which to me is very strange because you say you think that you don't want to favor departure feature ranking of feature selection methods when you choose your predictive model.",
                    "label": 0
                },
                {
                    "sent": "But as you must know, I mean the feature selection and the predictive model.",
                    "label": 0
                },
                {
                    "sent": "There are linked together.",
                    "label": 0
                },
                {
                    "sent": "I mean there are relationship with it.",
                    "label": 0
                },
                {
                    "sent": "I mean SVM, RFE.",
                    "label": 0
                },
                {
                    "sent": "Clearly we tend to use a linear SVM for classifier ready if you tend to use KNN or under arrest you tend to use random forests whatever.",
                    "label": 0
                },
                {
                    "sent": "So it seems that all your.",
                    "label": 0
                },
                {
                    "sent": "Kind of bias by the fact that you you are using feature ranking on one side and you are using predictive model that that do not fit well together.",
                    "label": 0
                },
                {
                    "sent": "So especially and SVN Morrison multivariate technique in Naive Bayes use.",
                    "label": 0
                },
                {
                    "sent": "Use consider feature independently of each other, so that seems very.",
                    "label": 0
                },
                {
                    "sent": "Well, I don't think that there is always I wouldn't agree with that.",
                    "label": 0
                },
                {
                    "sent": "There is a rule if use ranking algorithm A and then and also I don't have the data here presented, but we actually we actually compared using different classifiers at the end.",
                    "label": 0
                },
                {
                    "sent": "So what was important for us is to have so basically.",
                    "label": 0
                },
                {
                    "sent": "When using different classifiers at the end, you still end up with the similar results, so still.",
                    "label": 0
                },
                {
                    "sent": "Phil ranking method one is better than ranking method to know no matter which classifier you use.",
                    "label": 0
                },
                {
                    "sent": "So we basically wanted to avoid here.",
                    "label": 0
                },
                {
                    "sent": "You know using a method that is completely the same for deriving the future rankings and then for building the predictive models.",
                    "label": 0
                },
                {
                    "sent": "Because in that case, let's in that case we wouldn't be able to compare really the different algorithms.",
                    "label": 0
                },
                {
                    "sent": "So if you use hmes for deriving the ranking and then SMS is classifier, I would expect that ACMS would always pop out as the best.",
                    "label": 0
                },
                {
                    "sent": "But then.",
                    "label": 0
                },
                {
                    "sent": "Over the best features.",
                    "label": 0
                },
                {
                    "sent": "After all, metric is accuracy to Arthur building the best model.",
                    "label": 0
                },
                {
                    "sent": "So if there are links between the feature ranking methods and the classifier used, but as you said if you did this to do, that's fine, but I would think that that would strengthen the results by showing that you may be for the purpose if you want.",
                    "label": 0
                },
                {
                    "sent": "I agree with you for the purpose.",
                    "label": 0
                },
                {
                    "sent": "If you want the purpose of this here was basically to.",
                    "label": 0
                },
                {
                    "sent": "Not much to derive exactly.",
                    "label": 0
                },
                {
                    "sent": "The most accurate biomarker set for a certain disease, so this was more to compare.",
                    "label": 0
                },
                {
                    "sent": "Different ranking algorithms and I don't think that I would be able to compare them correctly if I used.",
                    "label": 0
                },
                {
                    "sent": "If if I use coupled SVM SVM and then if I use relief F and SVM and then it would turn out that SVM is the best.",
                    "label": 0
                },
                {
                    "sent": "But do you think that if we do that will change your conclusion if you switch like race or something, yeah.",
                    "label": 0
                },
                {
                    "sent": "I I just wanted to avoid well having a bias, basically because I don't think that it will.",
                    "label": 0
                },
                {
                    "sent": "It will change which ranking algorithm would be best in that contest.",
                    "label": 0
                },
                {
                    "sent": "No, I we we tried actually different so.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What, well, that's what I'm saying at the end the results are same ranking algorithm A is best no matter which classifier.",
                    "label": 0
                },
                {
                    "sent": "Use after that.",
                    "label": 0
                },
                {
                    "sent": "But I wanted to do this in a more neutral fashion than coupling it really to the same method.",
                    "label": 0
                },
                {
                    "sent": "This is probably related to the absence of the gold standard here, and because yes.",
                    "label": 0
                },
                {
                    "sent": "You can re late, geez, two particular diseases.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a lot of literature index.",
                    "label": 0
                },
                {
                    "sent": "So not just optimizing the selection of features for particular classifier, which in a sense I agree with the comment before you are using.",
                    "label": 0
                },
                {
                    "sent": "I mean you are doing right, but trying to use some other data source so literature to see if you're ranking corresponds to the carnal knowledge.",
                    "label": 0
                },
                {
                    "sent": "OK, we thought about that.",
                    "label": 0
                },
                {
                    "sent": "Yes, but that's not so easy.",
                    "label": 0
                },
                {
                    "sent": "I mean, you would basically have to check this manually, and that's not so.",
                    "label": 0
                },
                {
                    "sent": "So easy to do.",
                    "label": 0
                },
                {
                    "sent": "Maybe you would have to go and.",
                    "label": 0
                },
                {
                    "sent": "Search for everything manually and I haven't done that.",
                    "label": 0
                },
                {
                    "sent": "But I would agree that at the end it would be the best validation would be to derive the best, let's say ranking and then to see how much this overlaps with the literature.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Screams wait?",
                    "label": 0
                },
                {
                    "sent": "The normal usage is that you're looking for biomarkers one or a few things he wants to measure.",
                    "label": 0
                },
                {
                    "sent": "Measure.",
                    "label": 0
                },
                {
                    "sent": "Very strong.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Proper experience is that their fight against that.",
                    "label": 0
                },
                {
                    "sent": "Learning outcomes with paper or smaller.",
                    "label": 0
                },
                {
                    "sent": "Uh, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "You're using the term very strangely, not normal.",
                    "label": 0
                },
                {
                    "sent": "Well, uh.",
                    "label": 0
                },
                {
                    "sent": "I'm using the term.",
                    "label": 0
                },
                {
                    "sent": "Basically I I don't think that I'm using the term.",
                    "label": 0
                },
                {
                    "sent": "Strangely, at the end you would want to end up with small number.",
                    "label": 0
                },
                {
                    "sent": "I agree about that but but the whole but the whole process of this.",
                    "label": 0
                },
                {
                    "sent": "But don't they do screening first 4 so like the whole genes when you do the microarray thing first?",
                    "label": 0
                },
                {
                    "sent": "4.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Grab sign up to Margaret 4 which is put that stands for.",
                    "label": 0
                },
                {
                    "sent": "No, my marker.",
                    "label": 0
                },
                {
                    "sent": "No, but you're but here you weren't actually selecting the biomarkers would just you begin with the whole list of genes from the microarray.",
                    "label": 0
                },
                {
                    "sent": "You get them sorted somehow and you want to know how much that sorting is OK. Why isn't I?",
                    "label": 0
                },
                {
                    "sent": "I don't understand.",
                    "label": 0
                },
                {
                    "sent": "Why isn't biomarker discovery feature selection at all?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but that's why I have put put weight on it so it's.",
                    "label": 0
                },
                {
                    "sent": "Then use our initial parts.",
                    "label": 0
                },
                {
                    "sent": "You know very very small number of markers.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "When you do the area.",
                    "label": 0
                },
                {
                    "sent": "This initial part count is much, much more than those expected.",
                    "label": 0
                },
                {
                    "sent": "So that's very much consistent with what you have been saying, yes.",
                    "label": 0
                },
                {
                    "sent": "I'm going to go to a terminology issue that it got really using tons of them.",
                    "label": 0
                },
                {
                    "sent": "They are no longer part.",
                    "label": 0
                },
                {
                    "sent": "Yes, I yeah, I agree.",
                    "label": 0
                },
                {
                    "sent": "Question that was asked before about using some external gold standard.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Sometimes, if that's really what the task is that you know, if it were a perfect world and you had labels on jeans, then you could just value with respect to those.",
                    "label": 0
                },
                {
                    "sent": "And this is a way to get close to that by using predictive accuracy of the class label.",
                    "label": 0
                },
                {
                    "sent": "I don't think that this actually accomplishes the same thing, because a lot of these models are optimizing accuracy, so they're they're discriminative, so you know if you imagine a case where you have two, 100% identical paralogs that are doing essentially the same thing.",
                    "label": 0
                },
                {
                    "sent": "The SVM, RFE, for example, will give one of them arbitrarily a high rank, and the second one doesn't introduce any new information, so it gets a low rank, and that would be the right thing to do for the discriminative POV exactly.",
                    "label": 0
                },
                {
                    "sent": "The information that in fact there.",
                    "label": 0
                },
                {
                    "sent": "Second one is just as important.",
                    "label": 0
                },
                {
                    "sent": "As a as a possible good target.",
                    "label": 0
                },
                {
                    "sent": "So I wonder whether this is a different formulation or or basically, but it seems like this this approach doesn't solve the problem of finding which genes are relevant to a particular task.",
                    "label": 0
                },
                {
                    "sent": "It solves a different, more directed task of optimizing accuracy.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah it is, I think.",
                    "label": 0
                },
                {
                    "sent": "I want to make approach in the previous talk that you go group by group.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Questions include this session.",
                    "label": 0
                }
            ]
        }
    }
}