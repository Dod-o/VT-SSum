{
    "id": "oyqgmxlqe5zzzk5llxfqx6rs72onzmpb",
    "title": "MCMC, SMC,... What next ?",
    "info": {
        "author": [
            "Eric Moulines, ENST Paris"
        ],
        "published": "Dec. 17, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Mathematics->Statistics",
            "Top->Science->Complexity Science"
        ]
    },
    "url": "http://videolectures.net/acs07_moulines_mcm/",
    "segmentation": [
        [
            "Originally I planned to speak about Microchip Monte Carlo and Sequential Monte Carlo method, but it was perhaps too ambitious in half an hour to cover all the topics, so I choose chosen to concentrate mostly on uniquely on Markov chain."
        ],
        [
            "Decarlo"
        ],
        [
            "And."
        ],
        [
            "So because it's a, it's a workshop about complex system, so it would think that I think that the simulation method play OK. Key role in complex system and in particular among the simulation methods.",
            "Markov chain Monte Carlo player, prominent role, especially because they used basically in Bayesian statistics or infrequently statistic to solve.",
            "Inference problems.",
            "So basically what is a Markov chain Monte Carlo?",
            "Of course all of you in this room know what is marketing Monte Carlo.",
            "It's a technique to simulate from any probability distribution.",
            "And what you know also is that this is one of the main difficulty with Markov chain Monte Carlo is that it depends generally upon many tuning parameters.",
            "And when you are experienced Markov chain Monte Carlo, perhaps notice that it's general tremendously depends upon the choice of these tuning parameters, 'cause This is why despite the fact that.",
            "Especially becausw Markov chain Monte Carlo.",
            "I'm now used."
        ],
        [
            "Routine leads it's extremely important to find method to choose the parameter automatically is This is why I say that that's a way behind traditional marketing Monte Carlo and this will be the subject of my talk to show how you can try to learn from past examples in order to adapt the way you are simulating."
        ],
        [
            "Microchip Monte Carlo.",
            "OK, so we will start.",
            "This talk by just walking out very simple example, which is perhaps the simplest example you can imagine about Markov chain Monte Carlo, which is called Metropolis algorithms for Metropolitan Things algorithm.",
            "So there are many other forms.",
            "Of course of MCMC, but this one is easy to understand.",
            "So what happened?",
            "You construct a Markov chain, so at each XN is a state of the Markov chain at each stage XN you propose YN plus one.",
            "Which is proposed according to this proposal distribution which has a density Q.",
            "We assume that we have all the distribution of density with respect to some."
        ],
        [
            "Dominating measure.",
            "So this is the move that you propose from the point XN and according to this distribution and you will accept or reject this move according to probability, which is Alpha of XNYN plus one, which depends upon the current point and the point where you have proposed to move, and this acceptance ratio is defined exists.",
            "By Y, which is the stationary distribution of the chain, which is a distribution you want to target distribution you want to simulate.",
            "QYX is a proposal distribution by X is the target distribution evaluated at XNQXY?",
            "Is the proposal distribution, but this time from X to Y and as you see that this proposal, this ratio this acceptance ratio depends only on the ratio of the of the pie at point Y or X.",
            "Or you don't need to know the.",
            "The norming constant, which is of most interest in many bodies and problem where it's almost impossible, or it's impossible to compute so normalizing."
        ],
        [
            "And then you accept the move.",
            "So if you accept the moves, the next position of the chain will be the one given by YN plus one or otherwise you stay at your current position."
        ],
        [
            "OK, so there is an even simpler algorithm which is 1 which has been proposed in statistical physics perhaps 60 years ago by Metro police.",
            "So it was in 53.",
            "Which is simply that you propose, according to random walk.",
            "So you take a Q which is increment distribution, which is you take it as a symmetric distribution and you just move according to this."
        ],
        [
            "Random walk so big cause the move is symmetric according to X, so now the acceptance ratio can be simplified like this so it's P y / P X."
        ],
        [
            "So it depends only on the target distribution and therefore you can prove that Pi is under extremely weak condition will be the stationary distribution of this Markov chain.",
            "And you can see that Metro police sting algorithm is a way to simulate from any.",
            "To construct a Markov chain with special distribution \u03c0 as a random walk with some stopped, you just reject some proposed moved.",
            "So this is extremely simple, so you can say OK, I try any pie.",
            "So in any dimension I can put any say for example I can take if I am R to the power DI can take Gaussian distributions there and I can do something with that.",
            "And if you do that blindly, it will not work at all, of course."
        ],
        [
            "I will just explain you why, so here I just look at three plots.",
            "So here that's the trajectory of the Markov chain.",
            "And this is here's the correlation function from of these trajectories.",
            "So what I simulated simulated here.",
            "I want to simulate pie, which is a Gaussian distribution at 01.",
            "So this dimension one and I use a proposal distribution Gaussian kernel and I just change the variance of the Ocean Colonel.",
            "So what happens?",
            "You see here the trajectory where the proposal are two small variants.",
            "So when the proposal are two small variants, if you look at the ratio to P, Y / P X.",
            "Would be extremely close to 1 because you make very small move around as a distribution around the point X.",
            "So this means that you have something which looks like like a random walk and when at this scaling it looks like a trajectory of abroad and motion here.",
            "So the auto correlation.",
            "So correlation is extremely extremely positively correlated.",
            "You accept more or less all the move and as you know that.",
            "Random Walk on real line is not positive recurrent.",
            "That is is simply recurrent.",
            "Then you have this kind of behavior so that this means that the ears is scaling is too small and this means that you accept too often.",
            "The move here is this is another type of trajectories where this time you make large moves.",
            "So because you make large moves, these moves are not very frequently accepted 'cause you are often.",
            "Going outside the support between codes of the target distribution, so which means there's that you will be stuck.",
            "A lot of very long time at some points, and you have this kind of step function and cause.",
            "For for a reason which is totally different, you stay very long at some points before moving.",
            "Then you also extremely positively correlated, and this is here Markov chain which will correct tuning of these of these scaling is optimal in the sense that we'll discuss later.",
            "OK, so just to warn you that this is in a single dimension, this is very very simple example and it is not already extremely simple to tune the parameters.",
            "So if you start to look at complex model like the one used for example in.",
            "Image processing where you can simulate from years in the state space are the state of the pixel.",
            "So you have 10,000 of states.",
            "To simulate.",
            "This situation is even much worse of course.",
            "So to understand."
        ],
        [
            "A little bit more what happened.",
            "I will think on part of my talk and we discuss a little bit about the scaling limits just to understand a little bit more about this example.",
            "So scaling limits as these are some connection with the talk given this morning because we will use the same type of mean field approximation.",
            "So the idea is to look at some kind of asymptotic's at the behavior of Markov chain in large dimension in order to understand what are the key points.",
            "So here you assume that the target distribution is a product of marginal.",
            "So you have dimension D and distribution is simply a product of the same density F. OK, so you are in Rd and use you want to simulate from this distribution of this vector which is a vector with independent component and each component is distributed according to F. And what you do you do a Metro police asking proposal, but with this time you propose according to normal distribution.",
            "OK, the normal distribution with covariance matrix, which is identity matrix scaled by 1 / D D viewing the dimension of the state multiplied by Theta square.",
            "OK, so you decrease what you do that when you increase, when you increase the dimension of the state space you will decrease accordingly the the variance."
        ],
        [
            "So the proposal and you will look at the interpolated process, so it's a continuous time process.",
            "That TD which I have indexed this process by D because all the synthetic will be D here, which is X at time.",
            "So it's an integral part of TD.",
            "Dash 1, which means that I look simply as the first component of this vector, so I have a vector in dimension DI look simply at what is a single component of the vector and which I do I speed up time so I will scaling analysis.",
            "I reduce the variance when the increase I reduce the variance and I speed up time.",
            "And they do so."
        ],
        [
            "Interpolation.",
            "And what happened?",
            "What what is interesting to look at?",
            "This kind of model?",
            "And because it's a wait so simple to analyze what happened, 'cause what happened is that all because of cause you make a global proposal.",
            "Despite the fact that this distribution is a product of.",
            "Is a product of independent source of all the components are independent here?",
            "Because you do a global proposal, you have the kind of coupling all off this chain.",
            "But when you are in dimension D, What happens is that all the authors are look at kind of average, so there is kind of interaction, but they limit the interaction will vanish will?",
            "I will not show that but just the idea is that the.",
            "What happened is that a single component see basically the mean of the authors, so.",
            "Hold the order.",
            "Now the whole move, so it's a global move, so you pay off.",
            "D is a is over Rd.",
            "OK so here Q feta X1XD.",
            "It's a proposal that the increment distribution you move all the all the.",
            "Yeah, you just look at single one you propose on Rd, but you just look at the first component.",
            "Yeah, This is why there is."
        ],
        [
            "Yeah, so this is just plots which are easy to understand.",
            "So that's when these equals 5.",
            "Then I just D equal to 10.",
            "So each time I reduces the size of the jumps becausw variants of the proposal is this finished and also I speed up time.",
            "So at the end of the story I am here in this looks obviously like kind of."
        ],
        [
            "Diffusion, so what's the thing which can be proved?",
            "Rigorously with the first we have proved that is Roberts in 98, but there are many works scenes that.",
            "At least the techniques which are much better, much better understood now so that you can prove that this Z of DZ DT of the converges to Langevin stochastic differential equation Langevin diffusion.",
            "And in this Langevin diffusion, the the.",
            "To drift term is the Jacobian of the logarithm of log of F, where F is the distribution of a single marginal multiplied by V of feta and via fetus is very nice form, where five is a distribution, is a cumulative distribution function of the standard Goshen.",
            "And square root of I is."
        ],
        [
            "The Fisher information linked with F which is defined axis.",
            "So there's official information of the translation model and BT of course is the standard Brownian motion.",
            "So it's a convergence.",
            "Of course in this core, because it is called hold space."
        ],
        [
            "Convergence.",
            "OK, So what?",
            "When you see that you can see that?",
            "Z of T. If you make this time change so you just multiply the time by via feta, where via filter is divided by this OT can be written like Zedd, Tilda, FT where the~ of T is normalized in Japan division.",
            "So you can interpret via Vita.",
            "This quantity can be looked at the speed of the diffusion.",
            "So you have the diffusion set of tea with limiting diffusion is standard efficient which depends upon the parameter of my model.",
            "But applied, which is time scaled linearly.",
            "Timescale Bivio feat Aware View filter is defined like this.",
            "So what I need if I want to ideally.",
            "What I want to if I want to have the fastest rate speed of convergence I need basically to optimize this quantity so I have a syntactically in that model I want need."
        ],
        [
            "Optimize this quantity, which is not really extremely.",
            "Easy, but there is a.",
            "There is an easy way."
        ],
        [
            "Which comes there now if I look at the if I look at the mean acceptance rate.",
            "So if I look at the acceptance rate so that the acceptance rates of my Metro police lasting algorithm.",
            "So here should be it's OK.",
            "So the acceptance rates of the Metropolis algorithm.",
            "And that's the expression of the mean acceptance rates becausw part of D is a stationary distribution of the Markov chain OK Khufi to D y -- X is.",
            "Proposal distribution when I start from X and this is the acceptance probability, so that's the main acceptance rate.",
            "And we can prove is that Wendy goes to Infinity, that the acceptance rate converge."
        ],
        [
            "Sure, to a certain constant, and this thing which is extremely nice is that this constant is directly this.",
            "To Infinity of filter, which is a Mexican's race, is directly related to the speed of the limiting diffusion.",
            "So what I need to do in fact to optimize the speed of the limiting diffusion is to tune my algorithm in such a way that this quantity is maximized, so the speed will be fastest and I can show that the parameter fetus star which maximize acceptance rate is such that the mean acceptance rate is equal to this magic number, which is 0.2.",
            "34 and it stops there.",
            "So so it's so.",
            "So."
        ],
        [
            "What is the?"
        ],
        [
            "Now what is the philosophy that we can draw from that?",
            "We can rule from that philosophy is that when I have a Markov chain.",
            "Of course it is true only for that model, but it's it's.",
            "It's sensible.",
            "What is it sensible to do is to tune the parameter of my Markov chain orders at the on the average.",
            "The acceptance rate is around 20 between 20 and 50% OK, which is compatible with what I've looked before.",
            "If I have a very high acceptance rate which is in this kind of Metropolis algorithm, this means that I accept almost all moves and I am very close to random walk, so the convergence will be very slow, which means that typically that the move are too small, and if I do too much, if I propose with the scaling which is too large.",
            "I will do big jumps across the support of my distribution, in which case I will be stuck at .2 long and which is also not very good.",
            "So I have.",
            "This is a good good.",
            "Kind of motivation in order to tune the algorithm in order to access it."
        ],
        [
            "This type of acceptance rate, which is a rule in general."
        ],
        [
            "Yeah yeah yeah yeah, yeah, so that's that's is that yeah yeah yeah it's it's not universal at all that is that.",
            "So that's another problem.",
            "Yeah, yeah yeah you can you can, you can.",
            "We just present results where it's a little bit more general, but you are, but you have also result for Markov random fields or you have to specify a lot.",
            "It's not a general result, but I perfectly agree with you."
        ],
        [
            "OK, so now I want to exploit that in order to do to do a type of adaptive, what I call and adaptive Monte Carlo algorithm.",
            "So what I know is that I should try to tune the parameter in order that the parameter Theta, which is a scaling parameter here will be equal will be such that the mean acceptance rate is equal to some target acceptance rate which is equal to your toolbar, which is 0.234."
        ],
        [
            "So what is that model?",
            "Of course, it's easy to prove that edge of feta is a monotone function, and if which which are."
        ],
        [
            "Nicer."
        ],
        [
            "Ending behavior, but of course you cannot compute each of the tax.",
            "Basically be cause if you know how to compute that you know to compute general, you don't know how to integrate with respect to \u03c0.",
            "But what you do is that you you will lose stochastic approximation type algorithm.",
            "Which means that you can look at this instantaneous estimate as noisy observation of edge of filter K OK. And which suggests this type of."
        ],
        [
            "Gore ISM."
        ],
        [
            "So."
        ],
        [
            "That's the the algorithm suggested by.",
            "From this analysis we say, OK, what you do is that you at each iteration.",
            "I will tune the by Metro police asking algorithm as follows, so I I just starting from XKI.",
            "Do a proposal according to N 0 with.",
            "Identity covariance matrix multiplied by 50K.",
            "Next step I will accept or reject according to this probability.",
            "And because I want to implement my stochastic approximation procedure, I will tune Now the scaling of my algorithm and to change the scaling of the algorithm I will compute filter K like this so and which is compatible with what I saw before.",
            "So this procedure will typically converge on the average to the root of because on the limit, if everything goes well, this quantity will converge.",
            "They will be decision with regime fee to K will also converge, so this quantity in the limit will be kind of estimate of this.",
            "Of this average of the stationary acceptance acceptance rate.",
            "OK, so that's what I call a controlled Metropolis algorithm which implements the type of idea want to, which is the idea of trying to use the path simulation in order to be able to adapt your algorithm.",
            "And this is of course the simplest you can imagine and you I will try to convince you that this type of.",
            "The argument can be extended."
        ],
        [
            "More general fitting.",
            "So just to see how it how it works.",
            "So here it's.",
            "It's the Metro police algorithm with an optimal scaling, so the scaling which has been computed from value optimizing feet times the previous model, and for that model.",
            "And here is the metropolis algorithm, where you learn the scaling during the run and you can see that it's it's.",
            "It's a pretty so pretty it works pretty nicely even if the dimension is not very.",
            "Within a dimensional is not very large.",
            "We obtain a reasonable algorithms."
        ],
        [
            "OK, time flies like an arrow."
        ],
        [
            "So now you can extend this.",
            "So as.",
            "You have said that the model is very, extremely, but is not general at all, because you pretend that you want to simulate from distribution with the product of F of XI.",
            "So first generalization.",
            "Is to assume that you want the target distribution is not something like this, but something which can be written exist, so it's just transform linearly X according to the inverse of this matrix.",
            "Signal D and Pi of these is a product of this marginal distribution.",
            "OK, that's that's kind of.",
            "Elliptically symmetric is not general, but it's slightly more general than.",
            "Is slightly more general than.",
            "Then the previous model, so you're glad you can analyze this.",
            "This has been analyzed by in particular very recently by a student of PhD student of Jeff Rosenthal called Milan Bidar, which may make this thesis on that topic and very very nice thesis and and she proved that the acceptance rate is still.",
            "The 0.234, which seems to be a robust number, but.",
            "Uh.",
            "The the achievable maximal speed is strongly affected by signal of these.",
            "So so if you assume that you propose according to, so if you know if your distribution is the target distribution is distributed is like this and if you propose according to move which are still according to the identity matrix, then the maximum speed of the loss you improve a loss which is linked with conditional number of this covariance matrix.",
            "OK, so this."
        ],
        [
            "It is rather obvious."
        ],
        [
            "And this calls for what I call multi."
        ],
        [
            "Dimensional scaling, which was the algorithm which was originally proposed by Ariel and Saxman and which goes like this.",
            "But they analyze this algorithm with totally different in a way which is totally different than which is brother.",
            "They did not obtain the type of results we had we had."
        ],
        [
            "So the algorithm goes like this.",
            "So the idea when you have an MCMC algorithm with.",
            "Recovery is matching gamma K OK when the target distribution of this type of behavior.",
            "What you you should propose.",
            "You should propose according to an increment distribution, which is the gamma K which is the same covariance and the target distribution.",
            "Multiplied by a scaling constant and the scaling constant should be So what we have called gamma K general is not known.",
            "So what we do to do adaptation is that we will adapt both gamma K. So according to that of course, obvious recursion and also the target distribution."
        ],
        [
            "OK, so that's the algorithm so so you you propose according to this at step K you will accept or reject.",
            "Then you will update an estimate of the covariance of the target distribution which we use also as the covariance of the increment distribution.",
            "And then you will adapt to the global scale of the Organism I'm running."
        ],
        [
            "Out of time, OK, just to convince you that it's worthwhile to do that.",
            "This is I am in dimension D = 12.",
            "So target distribution is normal distribution with covariance matrix gamma, so condition number is 100, which is not very large in that dimension, but bad, but it's not extreme.",
            "And here I propose according to.",
            "And increment distribution, which is also normal with covariance matrix, which is the identity.",
            "And with the optimal scaling.",
            "And I see you're just applaud the.",
            "Cloud so it should be 1000 number 1000 simulation taken from Iran.",
            "And it's projected on the largest first just eigenvalue.",
            "So 2 first largest eigenvalue and you see that it is the chain is extremely badly.",
            "Mix mixing is extremely bad.",
            "And you just you do not visit.",
            "You are the cloud is move extremely slowly, which is also when you look at the trajectory of each individual component.",
            "This is obvious and when you see also the correlation, the correlation show also that the mixing is extreme."
        ],
        [
            "And now that's.",
            "That's the algorithm where you you propose now according to this, with the same covariance at the target distribution and then you can see that the cloud is much.",
            "Correlation is much better.",
            "And the cloud also is spread over the."
        ],
        [
            "The... and this is with the adaptive algorithm sopor."
        ],
        [
            "Yes I should."
        ],
        [
            "The.",
            "OK, so how many tricks and improvements to be?"
        ],
        [
            "Be done here."
        ],
        [
            "Of course, I just want to if I have 5 minutes, I would just want to describe another type of.",
            "Algorithms where this time I use radiometric listings but instead of proposing according to random Walk, I propose."
        ],
        [
            "Running two independent."
        ],
        [
            "Puzzles.",
            "So this time he.",
            "What you do is that you propose from a proposal distribution Q which is selected independently from the past.",
            "So you propose according to distribution and you accept this time with this ratio.",
            "So what you can prove it is rather easy to prove is that the changes dramatically ergodic if and only if the target distribution in the proposal distribution satisfies this relation and the rate of convergence is controlled by the constant end.",
            "So the idea is that in this type of algorithm what you need to to obtain the fastest rate of convergence you choose you choose propose according to distribution which which is which resemble to the.",
            "Distribution with exactly the same thing like you do.",
            "For example access project.",
            "It's extremely close the Metropolitan stick with independent proposal is extremely close to the accept reject mechanism and the only difference in some in some way with the accept reject mechanism is that you don't know to know the bounding constant.",
            "Between the ratio of the proposal the target distribute."
        ],
        [
            "OK."
        ],
        [
            "So what to do is that you use a technique which is rather standard in important sampling literature.",
            "So you start with the parametric family of proposal distribution.",
            "With two constraints, the two constraints are you.",
            "Should you choose a family which is easy to sample from of course, and the second constraint is that you want to family, which is flexible enough in order to capture most of the detail of the target distribution.",
            "So you really want to have family, which is the kind of universal approximation procedure, and what you do.",
            "As I said before.",
            "What you can prove is that the speed of convergence is maximized when Q is resembled 2\u03c0.",
            "And what we measure the resemblance of the closeness of the target distribution Pi and Q filter using the callback label."
        ],
        [
            "Divergent and you can obtain an algorithm which is.",
            "Global online Yamaga Rhythm, which is a variant of this which is detailed in this paper when, and also in the paper with my wrote on the topic in with Crystal fundraiser which appeared this year on.",
            "The analysis of applied this probability."
        ],
        [
            "Well, all this algorithm is described and this is just to show you a nice picture so that we want to simulate from this distribution.",
            "So here it's a distribution which is in dimension 2 and which has a very complex shape is called abandoners.",
            "That could be so this is a distribution constructed from the billionaire function in.",
            "In which is used in from nonlinear optimization, which is a badly behaved function because he had."
        ],
        [
            "It's a kind."
        ],
        [
            "Fern.",
            "And at the end of the story, you have a reasonable fee to buy.",
            "And here's the algorithm grows extremely fast."
        ],
        [
            "So."
        ],
        [
            "OK so I will just skip.",
            "So what are the results and they just conclude with that with the results of what we approved to sell paper as appeared.",
            "I think I think it it appears in 2000s.",
            "So perhaps it last year, but brother or in January, and I don't remember.",
            "So what we have proved is that under certain assumption I did not describe.",
            "This type of adaptive algorithms have converges.",
            "So you can establish low of large numbers.",
            "And their condition, which does not imply the convergence of the parameter filter K. So there are condition of course.",
            "So the type of algorithm I've described with something which is important, I have really couple.",
            "MCMC with stochastic approximation with decreasing step size.",
            "OK, so you have condition on the Gamma cave that should be fulfilled.",
            "So first we can prove the law of large number and then you can prove also.",
            "Central limit theorems or weak invariance principle.",
            "To be more precise, becausw and what you can prove is that this variance appearing in this Z is variance which is which would have been obtained with the optimal choice of the parameter Theta star.",
            "So simplistically at least there is no.",
            "Adaptation cost OK, so that I skip this part and I move to the conclusion."
        ],
        [
            "OK, so adaptive in this very brief presentation just to see that there is so MCMC now there.",
            "And since it's also there is a kind of new type of MCMC method called adaptive methods.",
            "It would be special issue on MCMC Adaptive MCMC method in statistics and computing.",
            "I think in November.",
            "And the idea behind all these methods is to try to make algorithm which self tune according to the path simulation.",
            "So this is a way of there another way to try to self tune and this this is this is a way to do that as mean you learn from what you have did before in order to.",
            "At every iteration you try to improve your strategy according to the previous draw OK. As I tried to to illustrate, there are many possible ways to adapt to signature strategy, so you can adapt to scaling.",
            "You can adapt the kovar and you can adapt even you can do more complex strategy like in what I did for independent Metropolis Hastings Dynamics.",
            "And as I said, the most difficult part is often to find what to adapt cause this is the gold standard would be to nab.",
            "OK, I can if I if I had, for example, an expression for the limiting variance of.",
            "Montecarlo average.",
            "That would be a standard, but it's not easy to compute so so you, so it's it's.",
            "It's very difficult when you run a Markov chain to compute the variance of these estimates, you can at least theoretically be cause this is linked with moment of the poison solution, according according to linked with Markov kernel, but in practice it's not computable, so it's a it's a.",
            "It's the thing which is very difficult to try to find proper adaptation."
        ],
        [
            "Criteria and This is why it's it's.",
            "It's always interesting to look at sensible criterion and to to use also a syntactic analysis like.",
            "So I described here, you too you to adapt according to scaling dimension.",
            "But we have also made adaptation according to other type of asymptotics, which are not synthetics in terms of dimension of the space met, but asymptotic switch are the free limits which are used in queueing networks, where the idea is more.",
            "Year to start far in the state space in order to obtain and to re scale, you will scale.",
            "It's a different scaling from this scaling and which also gives you a kind of understanding of the dynamic of the chain which allowed to obtain some kind of sensible criterion for adaptation."
        ],
        [
            "OK, just lost some last comment.",
            "There are many, many things to do.",
            "Many many open issues, so we are in the we are trying to look because in large dimension most of the algorithm hybrid algorithms and hybrid agoris of are extremely difficult to analyze and to understand.",
            "So we are working on that right now with just info.",
            "There are obviously linked links with the problem of control Markov chain and reinforcement learning, so that's something it's in black 'cause I don't.",
            "I don't work on that topic, but.",
            "It would be interesting to start something with that.",
            "So there are this in red.",
            "It's trying to couple MCMC which are cereal with particle which are parallel methods which are which is I think the way we will solve the.",
            "Simulation problems, so it's a it's a.",
            "It's before there was, say, the serial MCMC where you make a single run that you go very far and then you have parallel MCMC where you run the MCMC without interaction, and I think the good thing is to get parent EMC with interaction.",
            "So that's something we are working on.",
            "There also extension, but it's more for the values and stuff then extension to translational simulation methods where you want to sample from not a single space, but collection of space like when you do for example model selection.",
            "And we are working on.",
            "There is already a kind of toolbox returning R partly by us and partly by Jeff Rosenthal, which is available on the Jeff Rosenthal.",
            "Website, I thank you for your attention and I was a little bit too long so I'm sorry for that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Originally I planned to speak about Microchip Monte Carlo and Sequential Monte Carlo method, but it was perhaps too ambitious in half an hour to cover all the topics, so I choose chosen to concentrate mostly on uniquely on Markov chain.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decarlo",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So because it's a, it's a workshop about complex system, so it would think that I think that the simulation method play OK. Key role in complex system and in particular among the simulation methods.",
                    "label": 0
                },
                {
                    "sent": "Markov chain Monte Carlo player, prominent role, especially because they used basically in Bayesian statistics or infrequently statistic to solve.",
                    "label": 0
                },
                {
                    "sent": "Inference problems.",
                    "label": 0
                },
                {
                    "sent": "So basically what is a Markov chain Monte Carlo?",
                    "label": 0
                },
                {
                    "sent": "Of course all of you in this room know what is marketing Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "It's a technique to simulate from any probability distribution.",
                    "label": 1
                },
                {
                    "sent": "And what you know also is that this is one of the main difficulty with Markov chain Monte Carlo is that it depends generally upon many tuning parameters.",
                    "label": 1
                },
                {
                    "sent": "And when you are experienced Markov chain Monte Carlo, perhaps notice that it's general tremendously depends upon the choice of these tuning parameters, 'cause This is why despite the fact that.",
                    "label": 0
                },
                {
                    "sent": "Especially becausw Markov chain Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "I'm now used.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Routine leads it's extremely important to find method to choose the parameter automatically is This is why I say that that's a way behind traditional marketing Monte Carlo and this will be the subject of my talk to show how you can try to learn from past examples in order to adapt the way you are simulating.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Microchip Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "OK, so we will start.",
                    "label": 0
                },
                {
                    "sent": "This talk by just walking out very simple example, which is perhaps the simplest example you can imagine about Markov chain Monte Carlo, which is called Metropolis algorithms for Metropolitan Things algorithm.",
                    "label": 0
                },
                {
                    "sent": "So there are many other forms.",
                    "label": 0
                },
                {
                    "sent": "Of course of MCMC, but this one is easy to understand.",
                    "label": 0
                },
                {
                    "sent": "So what happened?",
                    "label": 0
                },
                {
                    "sent": "You construct a Markov chain, so at each XN is a state of the Markov chain at each stage XN you propose YN plus one.",
                    "label": 0
                },
                {
                    "sent": "Which is proposed according to this proposal distribution which has a density Q.",
                    "label": 0
                },
                {
                    "sent": "We assume that we have all the distribution of density with respect to some.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dominating measure.",
                    "label": 0
                },
                {
                    "sent": "So this is the move that you propose from the point XN and according to this distribution and you will accept or reject this move according to probability, which is Alpha of XNYN plus one, which depends upon the current point and the point where you have proposed to move, and this acceptance ratio is defined exists.",
                    "label": 0
                },
                {
                    "sent": "By Y, which is the stationary distribution of the chain, which is a distribution you want to target distribution you want to simulate.",
                    "label": 0
                },
                {
                    "sent": "QYX is a proposal distribution by X is the target distribution evaluated at XNQXY?",
                    "label": 0
                },
                {
                    "sent": "Is the proposal distribution, but this time from X to Y and as you see that this proposal, this ratio this acceptance ratio depends only on the ratio of the of the pie at point Y or X.",
                    "label": 0
                },
                {
                    "sent": "Or you don't need to know the.",
                    "label": 0
                },
                {
                    "sent": "The norming constant, which is of most interest in many bodies and problem where it's almost impossible, or it's impossible to compute so normalizing.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you accept the move.",
                    "label": 0
                },
                {
                    "sent": "So if you accept the moves, the next position of the chain will be the one given by YN plus one or otherwise you stay at your current position.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there is an even simpler algorithm which is 1 which has been proposed in statistical physics perhaps 60 years ago by Metro police.",
                    "label": 0
                },
                {
                    "sent": "So it was in 53.",
                    "label": 0
                },
                {
                    "sent": "Which is simply that you propose, according to random walk.",
                    "label": 0
                },
                {
                    "sent": "So you take a Q which is increment distribution, which is you take it as a symmetric distribution and you just move according to this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Random walk so big cause the move is symmetric according to X, so now the acceptance ratio can be simplified like this so it's P y / P X.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it depends only on the target distribution and therefore you can prove that Pi is under extremely weak condition will be the stationary distribution of this Markov chain.",
                    "label": 1
                },
                {
                    "sent": "And you can see that Metro police sting algorithm is a way to simulate from any.",
                    "label": 0
                },
                {
                    "sent": "To construct a Markov chain with special distribution \u03c0 as a random walk with some stopped, you just reject some proposed moved.",
                    "label": 0
                },
                {
                    "sent": "So this is extremely simple, so you can say OK, I try any pie.",
                    "label": 0
                },
                {
                    "sent": "So in any dimension I can put any say for example I can take if I am R to the power DI can take Gaussian distributions there and I can do something with that.",
                    "label": 0
                },
                {
                    "sent": "And if you do that blindly, it will not work at all, of course.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will just explain you why, so here I just look at three plots.",
                    "label": 0
                },
                {
                    "sent": "So here that's the trajectory of the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "And this is here's the correlation function from of these trajectories.",
                    "label": 0
                },
                {
                    "sent": "So what I simulated simulated here.",
                    "label": 0
                },
                {
                    "sent": "I want to simulate pie, which is a Gaussian distribution at 01.",
                    "label": 0
                },
                {
                    "sent": "So this dimension one and I use a proposal distribution Gaussian kernel and I just change the variance of the Ocean Colonel.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                },
                {
                    "sent": "You see here the trajectory where the proposal are two small variants.",
                    "label": 0
                },
                {
                    "sent": "So when the proposal are two small variants, if you look at the ratio to P, Y / P X.",
                    "label": 0
                },
                {
                    "sent": "Would be extremely close to 1 because you make very small move around as a distribution around the point X.",
                    "label": 0
                },
                {
                    "sent": "So this means that you have something which looks like like a random walk and when at this scaling it looks like a trajectory of abroad and motion here.",
                    "label": 0
                },
                {
                    "sent": "So the auto correlation.",
                    "label": 0
                },
                {
                    "sent": "So correlation is extremely extremely positively correlated.",
                    "label": 0
                },
                {
                    "sent": "You accept more or less all the move and as you know that.",
                    "label": 0
                },
                {
                    "sent": "Random Walk on real line is not positive recurrent.",
                    "label": 0
                },
                {
                    "sent": "That is is simply recurrent.",
                    "label": 0
                },
                {
                    "sent": "Then you have this kind of behavior so that this means that the ears is scaling is too small and this means that you accept too often.",
                    "label": 0
                },
                {
                    "sent": "The move here is this is another type of trajectories where this time you make large moves.",
                    "label": 0
                },
                {
                    "sent": "So because you make large moves, these moves are not very frequently accepted 'cause you are often.",
                    "label": 0
                },
                {
                    "sent": "Going outside the support between codes of the target distribution, so which means there's that you will be stuck.",
                    "label": 0
                },
                {
                    "sent": "A lot of very long time at some points, and you have this kind of step function and cause.",
                    "label": 0
                },
                {
                    "sent": "For for a reason which is totally different, you stay very long at some points before moving.",
                    "label": 0
                },
                {
                    "sent": "Then you also extremely positively correlated, and this is here Markov chain which will correct tuning of these of these scaling is optimal in the sense that we'll discuss later.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to warn you that this is in a single dimension, this is very very simple example and it is not already extremely simple to tune the parameters.",
                    "label": 0
                },
                {
                    "sent": "So if you start to look at complex model like the one used for example in.",
                    "label": 0
                },
                {
                    "sent": "Image processing where you can simulate from years in the state space are the state of the pixel.",
                    "label": 0
                },
                {
                    "sent": "So you have 10,000 of states.",
                    "label": 0
                },
                {
                    "sent": "To simulate.",
                    "label": 0
                },
                {
                    "sent": "This situation is even much worse of course.",
                    "label": 0
                },
                {
                    "sent": "So to understand.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little bit more what happened.",
                    "label": 0
                },
                {
                    "sent": "I will think on part of my talk and we discuss a little bit about the scaling limits just to understand a little bit more about this example.",
                    "label": 0
                },
                {
                    "sent": "So scaling limits as these are some connection with the talk given this morning because we will use the same type of mean field approximation.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to look at some kind of asymptotic's at the behavior of Markov chain in large dimension in order to understand what are the key points.",
                    "label": 0
                },
                {
                    "sent": "So here you assume that the target distribution is a product of marginal.",
                    "label": 0
                },
                {
                    "sent": "So you have dimension D and distribution is simply a product of the same density F. OK, so you are in Rd and use you want to simulate from this distribution of this vector which is a vector with independent component and each component is distributed according to F. And what you do you do a Metro police asking proposal, but with this time you propose according to normal distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, the normal distribution with covariance matrix, which is identity matrix scaled by 1 / D D viewing the dimension of the state multiplied by Theta square.",
                    "label": 0
                },
                {
                    "sent": "OK, so you decrease what you do that when you increase, when you increase the dimension of the state space you will decrease accordingly the the variance.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the proposal and you will look at the interpolated process, so it's a continuous time process.",
                    "label": 1
                },
                {
                    "sent": "That TD which I have indexed this process by D because all the synthetic will be D here, which is X at time.",
                    "label": 0
                },
                {
                    "sent": "So it's an integral part of TD.",
                    "label": 0
                },
                {
                    "sent": "Dash 1, which means that I look simply as the first component of this vector, so I have a vector in dimension DI look simply at what is a single component of the vector and which I do I speed up time so I will scaling analysis.",
                    "label": 1
                },
                {
                    "sent": "I reduce the variance when the increase I reduce the variance and I speed up time.",
                    "label": 0
                },
                {
                    "sent": "And they do so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interpolation.",
                    "label": 0
                },
                {
                    "sent": "And what happened?",
                    "label": 0
                },
                {
                    "sent": "What what is interesting to look at?",
                    "label": 0
                },
                {
                    "sent": "This kind of model?",
                    "label": 0
                },
                {
                    "sent": "And because it's a wait so simple to analyze what happened, 'cause what happened is that all because of cause you make a global proposal.",
                    "label": 0
                },
                {
                    "sent": "Despite the fact that this distribution is a product of.",
                    "label": 0
                },
                {
                    "sent": "Is a product of independent source of all the components are independent here?",
                    "label": 0
                },
                {
                    "sent": "Because you do a global proposal, you have the kind of coupling all off this chain.",
                    "label": 0
                },
                {
                    "sent": "But when you are in dimension D, What happens is that all the authors are look at kind of average, so there is kind of interaction, but they limit the interaction will vanish will?",
                    "label": 0
                },
                {
                    "sent": "I will not show that but just the idea is that the.",
                    "label": 0
                },
                {
                    "sent": "What happened is that a single component see basically the mean of the authors, so.",
                    "label": 1
                },
                {
                    "sent": "Hold the order.",
                    "label": 0
                },
                {
                    "sent": "Now the whole move, so it's a global move, so you pay off.",
                    "label": 0
                },
                {
                    "sent": "D is a is over Rd.",
                    "label": 0
                },
                {
                    "sent": "OK so here Q feta X1XD.",
                    "label": 0
                },
                {
                    "sent": "It's a proposal that the increment distribution you move all the all the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you just look at single one you propose on Rd, but you just look at the first component.",
                    "label": 0
                },
                {
                    "sent": "Yeah, This is why there is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so this is just plots which are easy to understand.",
                    "label": 0
                },
                {
                    "sent": "So that's when these equals 5.",
                    "label": 0
                },
                {
                    "sent": "Then I just D equal to 10.",
                    "label": 0
                },
                {
                    "sent": "So each time I reduces the size of the jumps becausw variants of the proposal is this finished and also I speed up time.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the story I am here in this looks obviously like kind of.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Diffusion, so what's the thing which can be proved?",
                    "label": 0
                },
                {
                    "sent": "Rigorously with the first we have proved that is Roberts in 98, but there are many works scenes that.",
                    "label": 0
                },
                {
                    "sent": "At least the techniques which are much better, much better understood now so that you can prove that this Z of DZ DT of the converges to Langevin stochastic differential equation Langevin diffusion.",
                    "label": 0
                },
                {
                    "sent": "And in this Langevin diffusion, the the.",
                    "label": 0
                },
                {
                    "sent": "To drift term is the Jacobian of the logarithm of log of F, where F is the distribution of a single marginal multiplied by V of feta and via fetus is very nice form, where five is a distribution, is a cumulative distribution function of the standard Goshen.",
                    "label": 1
                },
                {
                    "sent": "And square root of I is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The Fisher information linked with F which is defined axis.",
                    "label": 1
                },
                {
                    "sent": "So there's official information of the translation model and BT of course is the standard Brownian motion.",
                    "label": 1
                },
                {
                    "sent": "So it's a convergence.",
                    "label": 0
                },
                {
                    "sent": "Of course in this core, because it is called hold space.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convergence.",
                    "label": 0
                },
                {
                    "sent": "OK, So what?",
                    "label": 0
                },
                {
                    "sent": "When you see that you can see that?",
                    "label": 0
                },
                {
                    "sent": "Z of T. If you make this time change so you just multiply the time by via feta, where via filter is divided by this OT can be written like Zedd, Tilda, FT where the~ of T is normalized in Japan division.",
                    "label": 0
                },
                {
                    "sent": "So you can interpret via Vita.",
                    "label": 0
                },
                {
                    "sent": "This quantity can be looked at the speed of the diffusion.",
                    "label": 1
                },
                {
                    "sent": "So you have the diffusion set of tea with limiting diffusion is standard efficient which depends upon the parameter of my model.",
                    "label": 0
                },
                {
                    "sent": "But applied, which is time scaled linearly.",
                    "label": 0
                },
                {
                    "sent": "Timescale Bivio feat Aware View filter is defined like this.",
                    "label": 0
                },
                {
                    "sent": "So what I need if I want to ideally.",
                    "label": 0
                },
                {
                    "sent": "What I want to if I want to have the fastest rate speed of convergence I need basically to optimize this quantity so I have a syntactically in that model I want need.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optimize this quantity, which is not really extremely.",
                    "label": 0
                },
                {
                    "sent": "Easy, but there is a.",
                    "label": 0
                },
                {
                    "sent": "There is an easy way.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which comes there now if I look at the if I look at the mean acceptance rate.",
                    "label": 0
                },
                {
                    "sent": "So if I look at the acceptance rate so that the acceptance rates of my Metro police lasting algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here should be it's OK.",
                    "label": 0
                },
                {
                    "sent": "So the acceptance rates of the Metropolis algorithm.",
                    "label": 0
                },
                {
                    "sent": "And that's the expression of the mean acceptance rates becausw part of D is a stationary distribution of the Markov chain OK Khufi to D y -- X is.",
                    "label": 1
                },
                {
                    "sent": "Proposal distribution when I start from X and this is the acceptance probability, so that's the main acceptance rate.",
                    "label": 0
                },
                {
                    "sent": "And we can prove is that Wendy goes to Infinity, that the acceptance rate converge.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sure, to a certain constant, and this thing which is extremely nice is that this constant is directly this.",
                    "label": 0
                },
                {
                    "sent": "To Infinity of filter, which is a Mexican's race, is directly related to the speed of the limiting diffusion.",
                    "label": 0
                },
                {
                    "sent": "So what I need to do in fact to optimize the speed of the limiting diffusion is to tune my algorithm in such a way that this quantity is maximized, so the speed will be fastest and I can show that the parameter fetus star which maximize acceptance rate is such that the mean acceptance rate is equal to this magic number, which is 0.2.",
                    "label": 1
                },
                {
                    "sent": "34 and it stops there.",
                    "label": 0
                },
                {
                    "sent": "So so it's so.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is the?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what is the philosophy that we can draw from that?",
                    "label": 0
                },
                {
                    "sent": "We can rule from that philosophy is that when I have a Markov chain.",
                    "label": 1
                },
                {
                    "sent": "Of course it is true only for that model, but it's it's.",
                    "label": 1
                },
                {
                    "sent": "It's sensible.",
                    "label": 0
                },
                {
                    "sent": "What is it sensible to do is to tune the parameter of my Markov chain orders at the on the average.",
                    "label": 0
                },
                {
                    "sent": "The acceptance rate is around 20 between 20 and 50% OK, which is compatible with what I've looked before.",
                    "label": 0
                },
                {
                    "sent": "If I have a very high acceptance rate which is in this kind of Metropolis algorithm, this means that I accept almost all moves and I am very close to random walk, so the convergence will be very slow, which means that typically that the move are too small, and if I do too much, if I propose with the scaling which is too large.",
                    "label": 0
                },
                {
                    "sent": "I will do big jumps across the support of my distribution, in which case I will be stuck at .2 long and which is also not very good.",
                    "label": 0
                },
                {
                    "sent": "So I have.",
                    "label": 0
                },
                {
                    "sent": "This is a good good.",
                    "label": 0
                },
                {
                    "sent": "Kind of motivation in order to tune the algorithm in order to access it.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This type of acceptance rate, which is a rule in general.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah yeah yeah yeah, yeah, so that's that's is that yeah yeah yeah it's it's not universal at all that is that.",
                    "label": 0
                },
                {
                    "sent": "So that's another problem.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah yeah you can you can, you can.",
                    "label": 0
                },
                {
                    "sent": "We just present results where it's a little bit more general, but you are, but you have also result for Markov random fields or you have to specify a lot.",
                    "label": 0
                },
                {
                    "sent": "It's not a general result, but I perfectly agree with you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now I want to exploit that in order to do to do a type of adaptive, what I call and adaptive Monte Carlo algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what I know is that I should try to tune the parameter in order that the parameter Theta, which is a scaling parameter here will be equal will be such that the mean acceptance rate is equal to some target acceptance rate which is equal to your toolbar, which is 0.234.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is that model?",
                    "label": 0
                },
                {
                    "sent": "Of course, it's easy to prove that edge of feta is a monotone function, and if which which are.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nicer.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ending behavior, but of course you cannot compute each of the tax.",
                    "label": 0
                },
                {
                    "sent": "Basically be cause if you know how to compute that you know to compute general, you don't know how to integrate with respect to \u03c0.",
                    "label": 0
                },
                {
                    "sent": "But what you do is that you you will lose stochastic approximation type algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which means that you can look at this instantaneous estimate as noisy observation of edge of filter K OK. And which suggests this type of.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gore ISM.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's the the algorithm suggested by.",
                    "label": 0
                },
                {
                    "sent": "From this analysis we say, OK, what you do is that you at each iteration.",
                    "label": 0
                },
                {
                    "sent": "I will tune the by Metro police asking algorithm as follows, so I I just starting from XKI.",
                    "label": 0
                },
                {
                    "sent": "Do a proposal according to N 0 with.",
                    "label": 0
                },
                {
                    "sent": "Identity covariance matrix multiplied by 50K.",
                    "label": 0
                },
                {
                    "sent": "Next step I will accept or reject according to this probability.",
                    "label": 0
                },
                {
                    "sent": "And because I want to implement my stochastic approximation procedure, I will tune Now the scaling of my algorithm and to change the scaling of the algorithm I will compute filter K like this so and which is compatible with what I saw before.",
                    "label": 0
                },
                {
                    "sent": "So this procedure will typically converge on the average to the root of because on the limit, if everything goes well, this quantity will converge.",
                    "label": 0
                },
                {
                    "sent": "They will be decision with regime fee to K will also converge, so this quantity in the limit will be kind of estimate of this.",
                    "label": 0
                },
                {
                    "sent": "Of this average of the stationary acceptance acceptance rate.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's what I call a controlled Metropolis algorithm which implements the type of idea want to, which is the idea of trying to use the path simulation in order to be able to adapt your algorithm.",
                    "label": 1
                },
                {
                    "sent": "And this is of course the simplest you can imagine and you I will try to convince you that this type of.",
                    "label": 0
                },
                {
                    "sent": "The argument can be extended.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More general fitting.",
                    "label": 0
                },
                {
                    "sent": "So just to see how it how it works.",
                    "label": 0
                },
                {
                    "sent": "So here it's.",
                    "label": 0
                },
                {
                    "sent": "It's the Metro police algorithm with an optimal scaling, so the scaling which has been computed from value optimizing feet times the previous model, and for that model.",
                    "label": 0
                },
                {
                    "sent": "And here is the metropolis algorithm, where you learn the scaling during the run and you can see that it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's a pretty so pretty it works pretty nicely even if the dimension is not very.",
                    "label": 0
                },
                {
                    "sent": "Within a dimensional is not very large.",
                    "label": 0
                },
                {
                    "sent": "We obtain a reasonable algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, time flies like an arrow.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now you can extend this.",
                    "label": 0
                },
                {
                    "sent": "So as.",
                    "label": 0
                },
                {
                    "sent": "You have said that the model is very, extremely, but is not general at all, because you pretend that you want to simulate from distribution with the product of F of XI.",
                    "label": 0
                },
                {
                    "sent": "So first generalization.",
                    "label": 0
                },
                {
                    "sent": "Is to assume that you want the target distribution is not something like this, but something which can be written exist, so it's just transform linearly X according to the inverse of this matrix.",
                    "label": 0
                },
                {
                    "sent": "Signal D and Pi of these is a product of this marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, that's that's kind of.",
                    "label": 0
                },
                {
                    "sent": "Elliptically symmetric is not general, but it's slightly more general than.",
                    "label": 0
                },
                {
                    "sent": "Is slightly more general than.",
                    "label": 0
                },
                {
                    "sent": "Then the previous model, so you're glad you can analyze this.",
                    "label": 0
                },
                {
                    "sent": "This has been analyzed by in particular very recently by a student of PhD student of Jeff Rosenthal called Milan Bidar, which may make this thesis on that topic and very very nice thesis and and she proved that the acceptance rate is still.",
                    "label": 0
                },
                {
                    "sent": "The 0.234, which seems to be a robust number, but.",
                    "label": 1
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "The the achievable maximal speed is strongly affected by signal of these.",
                    "label": 1
                },
                {
                    "sent": "So so if you assume that you propose according to, so if you know if your distribution is the target distribution is distributed is like this and if you propose according to move which are still according to the identity matrix, then the maximum speed of the loss you improve a loss which is linked with conditional number of this covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so this.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is rather obvious.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this calls for what I call multi.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dimensional scaling, which was the algorithm which was originally proposed by Ariel and Saxman and which goes like this.",
                    "label": 0
                },
                {
                    "sent": "But they analyze this algorithm with totally different in a way which is totally different than which is brother.",
                    "label": 0
                },
                {
                    "sent": "They did not obtain the type of results we had we had.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the algorithm goes like this.",
                    "label": 0
                },
                {
                    "sent": "So the idea when you have an MCMC algorithm with.",
                    "label": 0
                },
                {
                    "sent": "Recovery is matching gamma K OK when the target distribution of this type of behavior.",
                    "label": 0
                },
                {
                    "sent": "What you you should propose.",
                    "label": 0
                },
                {
                    "sent": "You should propose according to an increment distribution, which is the gamma K which is the same covariance and the target distribution.",
                    "label": 0
                },
                {
                    "sent": "Multiplied by a scaling constant and the scaling constant should be So what we have called gamma K general is not known.",
                    "label": 0
                },
                {
                    "sent": "So what we do to do adaptation is that we will adapt both gamma K. So according to that of course, obvious recursion and also the target distribution.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's the algorithm so so you you propose according to this at step K you will accept or reject.",
                    "label": 0
                },
                {
                    "sent": "Then you will update an estimate of the covariance of the target distribution which we use also as the covariance of the increment distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you will adapt to the global scale of the Organism I'm running.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out of time, OK, just to convince you that it's worthwhile to do that.",
                    "label": 0
                },
                {
                    "sent": "This is I am in dimension D = 12.",
                    "label": 0
                },
                {
                    "sent": "So target distribution is normal distribution with covariance matrix gamma, so condition number is 100, which is not very large in that dimension, but bad, but it's not extreme.",
                    "label": 0
                },
                {
                    "sent": "And here I propose according to.",
                    "label": 0
                },
                {
                    "sent": "And increment distribution, which is also normal with covariance matrix, which is the identity.",
                    "label": 0
                },
                {
                    "sent": "And with the optimal scaling.",
                    "label": 0
                },
                {
                    "sent": "And I see you're just applaud the.",
                    "label": 0
                },
                {
                    "sent": "Cloud so it should be 1000 number 1000 simulation taken from Iran.",
                    "label": 0
                },
                {
                    "sent": "And it's projected on the largest first just eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So 2 first largest eigenvalue and you see that it is the chain is extremely badly.",
                    "label": 0
                },
                {
                    "sent": "Mix mixing is extremely bad.",
                    "label": 0
                },
                {
                    "sent": "And you just you do not visit.",
                    "label": 0
                },
                {
                    "sent": "You are the cloud is move extremely slowly, which is also when you look at the trajectory of each individual component.",
                    "label": 0
                },
                {
                    "sent": "This is obvious and when you see also the correlation, the correlation show also that the mixing is extreme.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now that's.",
                    "label": 0
                },
                {
                    "sent": "That's the algorithm where you you propose now according to this, with the same covariance at the target distribution and then you can see that the cloud is much.",
                    "label": 0
                },
                {
                    "sent": "Correlation is much better.",
                    "label": 0
                },
                {
                    "sent": "And the cloud also is spread over the.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The... and this is with the adaptive algorithm sopor.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes I should.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "OK, so how many tricks and improvements to be?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be done here.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, I just want to if I have 5 minutes, I would just want to describe another type of.",
                    "label": 0
                },
                {
                    "sent": "Algorithms where this time I use radiometric listings but instead of proposing according to random Walk, I propose.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Running two independent.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Puzzles.",
                    "label": 0
                },
                {
                    "sent": "So this time he.",
                    "label": 0
                },
                {
                    "sent": "What you do is that you propose from a proposal distribution Q which is selected independently from the past.",
                    "label": 0
                },
                {
                    "sent": "So you propose according to distribution and you accept this time with this ratio.",
                    "label": 0
                },
                {
                    "sent": "So what you can prove it is rather easy to prove is that the changes dramatically ergodic if and only if the target distribution in the proposal distribution satisfies this relation and the rate of convergence is controlled by the constant end.",
                    "label": 1
                },
                {
                    "sent": "So the idea is that in this type of algorithm what you need to to obtain the fastest rate of convergence you choose you choose propose according to distribution which which is which resemble to the.",
                    "label": 1
                },
                {
                    "sent": "Distribution with exactly the same thing like you do.",
                    "label": 0
                },
                {
                    "sent": "For example access project.",
                    "label": 1
                },
                {
                    "sent": "It's extremely close the Metropolitan stick with independent proposal is extremely close to the accept reject mechanism and the only difference in some in some way with the accept reject mechanism is that you don't know to know the bounding constant.",
                    "label": 0
                },
                {
                    "sent": "Between the ratio of the proposal the target distribute.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what to do is that you use a technique which is rather standard in important sampling literature.",
                    "label": 0
                },
                {
                    "sent": "So you start with the parametric family of proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "With two constraints, the two constraints are you.",
                    "label": 0
                },
                {
                    "sent": "Should you choose a family which is easy to sample from of course, and the second constraint is that you want to family, which is flexible enough in order to capture most of the detail of the target distribution.",
                    "label": 0
                },
                {
                    "sent": "So you really want to have family, which is the kind of universal approximation procedure, and what you do.",
                    "label": 0
                },
                {
                    "sent": "As I said before.",
                    "label": 0
                },
                {
                    "sent": "What you can prove is that the speed of convergence is maximized when Q is resembled 2\u03c0.",
                    "label": 0
                },
                {
                    "sent": "And what we measure the resemblance of the closeness of the target distribution Pi and Q filter using the callback label.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Divergent and you can obtain an algorithm which is.",
                    "label": 0
                },
                {
                    "sent": "Global online Yamaga Rhythm, which is a variant of this which is detailed in this paper when, and also in the paper with my wrote on the topic in with Crystal fundraiser which appeared this year on.",
                    "label": 0
                },
                {
                    "sent": "The analysis of applied this probability.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, all this algorithm is described and this is just to show you a nice picture so that we want to simulate from this distribution.",
                    "label": 0
                },
                {
                    "sent": "So here it's a distribution which is in dimension 2 and which has a very complex shape is called abandoners.",
                    "label": 0
                },
                {
                    "sent": "That could be so this is a distribution constructed from the billionaire function in.",
                    "label": 0
                },
                {
                    "sent": "In which is used in from nonlinear optimization, which is a badly behaved function because he had.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a kind.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fern.",
                    "label": 0
                },
                {
                    "sent": "And at the end of the story, you have a reasonable fee to buy.",
                    "label": 0
                },
                {
                    "sent": "And here's the algorithm grows extremely fast.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I will just skip.",
                    "label": 0
                },
                {
                    "sent": "So what are the results and they just conclude with that with the results of what we approved to sell paper as appeared.",
                    "label": 0
                },
                {
                    "sent": "I think I think it it appears in 2000s.",
                    "label": 0
                },
                {
                    "sent": "So perhaps it last year, but brother or in January, and I don't remember.",
                    "label": 0
                },
                {
                    "sent": "So what we have proved is that under certain assumption I did not describe.",
                    "label": 0
                },
                {
                    "sent": "This type of adaptive algorithms have converges.",
                    "label": 0
                },
                {
                    "sent": "So you can establish low of large numbers.",
                    "label": 0
                },
                {
                    "sent": "And their condition, which does not imply the convergence of the parameter filter K. So there are condition of course.",
                    "label": 0
                },
                {
                    "sent": "So the type of algorithm I've described with something which is important, I have really couple.",
                    "label": 0
                },
                {
                    "sent": "MCMC with stochastic approximation with decreasing step size.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have condition on the Gamma cave that should be fulfilled.",
                    "label": 0
                },
                {
                    "sent": "So first we can prove the law of large number and then you can prove also.",
                    "label": 0
                },
                {
                    "sent": "Central limit theorems or weak invariance principle.",
                    "label": 0
                },
                {
                    "sent": "To be more precise, becausw and what you can prove is that this variance appearing in this Z is variance which is which would have been obtained with the optimal choice of the parameter Theta star.",
                    "label": 0
                },
                {
                    "sent": "So simplistically at least there is no.",
                    "label": 0
                },
                {
                    "sent": "Adaptation cost OK, so that I skip this part and I move to the conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so adaptive in this very brief presentation just to see that there is so MCMC now there.",
                    "label": 0
                },
                {
                    "sent": "And since it's also there is a kind of new type of MCMC method called adaptive methods.",
                    "label": 0
                },
                {
                    "sent": "It would be special issue on MCMC Adaptive MCMC method in statistics and computing.",
                    "label": 0
                },
                {
                    "sent": "I think in November.",
                    "label": 0
                },
                {
                    "sent": "And the idea behind all these methods is to try to make algorithm which self tune according to the path simulation.",
                    "label": 0
                },
                {
                    "sent": "So this is a way of there another way to try to self tune and this this is this is a way to do that as mean you learn from what you have did before in order to.",
                    "label": 0
                },
                {
                    "sent": "At every iteration you try to improve your strategy according to the previous draw OK. As I tried to to illustrate, there are many possible ways to adapt to signature strategy, so you can adapt to scaling.",
                    "label": 0
                },
                {
                    "sent": "You can adapt the kovar and you can adapt even you can do more complex strategy like in what I did for independent Metropolis Hastings Dynamics.",
                    "label": 0
                },
                {
                    "sent": "And as I said, the most difficult part is often to find what to adapt cause this is the gold standard would be to nab.",
                    "label": 0
                },
                {
                    "sent": "OK, I can if I if I had, for example, an expression for the limiting variance of.",
                    "label": 0
                },
                {
                    "sent": "Montecarlo average.",
                    "label": 0
                },
                {
                    "sent": "That would be a standard, but it's not easy to compute so so you, so it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's very difficult when you run a Markov chain to compute the variance of these estimates, you can at least theoretically be cause this is linked with moment of the poison solution, according according to linked with Markov kernel, but in practice it's not computable, so it's a it's a.",
                    "label": 0
                },
                {
                    "sent": "It's the thing which is very difficult to try to find proper adaptation.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Criteria and This is why it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's always interesting to look at sensible criterion and to to use also a syntactic analysis like.",
                    "label": 0
                },
                {
                    "sent": "So I described here, you too you to adapt according to scaling dimension.",
                    "label": 0
                },
                {
                    "sent": "But we have also made adaptation according to other type of asymptotics, which are not synthetics in terms of dimension of the space met, but asymptotic switch are the free limits which are used in queueing networks, where the idea is more.",
                    "label": 0
                },
                {
                    "sent": "Year to start far in the state space in order to obtain and to re scale, you will scale.",
                    "label": 0
                },
                {
                    "sent": "It's a different scaling from this scaling and which also gives you a kind of understanding of the dynamic of the chain which allowed to obtain some kind of sensible criterion for adaptation.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, just lost some last comment.",
                    "label": 0
                },
                {
                    "sent": "There are many, many things to do.",
                    "label": 0
                },
                {
                    "sent": "Many many open issues, so we are in the we are trying to look because in large dimension most of the algorithm hybrid algorithms and hybrid agoris of are extremely difficult to analyze and to understand.",
                    "label": 0
                },
                {
                    "sent": "So we are working on that right now with just info.",
                    "label": 0
                },
                {
                    "sent": "There are obviously linked links with the problem of control Markov chain and reinforcement learning, so that's something it's in black 'cause I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't work on that topic, but.",
                    "label": 0
                },
                {
                    "sent": "It would be interesting to start something with that.",
                    "label": 0
                },
                {
                    "sent": "So there are this in red.",
                    "label": 0
                },
                {
                    "sent": "It's trying to couple MCMC which are cereal with particle which are parallel methods which are which is I think the way we will solve the.",
                    "label": 0
                },
                {
                    "sent": "Simulation problems, so it's a it's a.",
                    "label": 0
                },
                {
                    "sent": "It's before there was, say, the serial MCMC where you make a single run that you go very far and then you have parallel MCMC where you run the MCMC without interaction, and I think the good thing is to get parent EMC with interaction.",
                    "label": 0
                },
                {
                    "sent": "So that's something we are working on.",
                    "label": 0
                },
                {
                    "sent": "There also extension, but it's more for the values and stuff then extension to translational simulation methods where you want to sample from not a single space, but collection of space like when you do for example model selection.",
                    "label": 0
                },
                {
                    "sent": "And we are working on.",
                    "label": 0
                },
                {
                    "sent": "There is already a kind of toolbox returning R partly by us and partly by Jeff Rosenthal, which is available on the Jeff Rosenthal.",
                    "label": 0
                },
                {
                    "sent": "Website, I thank you for your attention and I was a little bit too long so I'm sorry for that.",
                    "label": 0
                }
            ]
        }
    }
}