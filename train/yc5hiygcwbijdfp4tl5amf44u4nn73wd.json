{
    "id": "yc5hiygcwbijdfp4tl5amf44u4nn73wd",
    "title": "Constrained Approximate Maximum Entropy Learning of Markov Random Fields",
    "info": {
        "author": [
            "Varun Ganapathi, Computer Science Department, Stanford University"
        ],
        "published": "July 30, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/uai08_ganapathi_camel/",
    "segmentation": [
        [
            "OK, so for the purpose of this."
        ],
        [
            "We're concerned with undirected graphical models.",
            "So many real world problems can be accurately represented by undirected graphical models.",
            "These models attempt to model a probability distribution on a set of random variables.",
            "Um, where the nodes in the graphical model correspond to the variables and undirected.",
            "The model is parameterized by some parameter vector Theta.",
            "Um?",
            "In many cases, this graphical model can be densely connected, which means that exact inference is computationally intractable.",
            "However, much work has been much recent work is focused on approximate inference techniques, so in practice, belief approximate inference techniques like belief propagation can work very well in practice.",
            "On real world problems.",
            "However, the problem we're concerned with is not performing inference on these models, but instead on learning the parameters for these models from data.",
            "It is well known that.",
            "Choosing parameters from data can result in improve performance on many tests, and so of course it's interesting to know how to automatically learn these models from data.",
            "So how do we learn the parameters of undirected graphical?"
        ],
        [
            "Well, first.",
            "The likelihood of undirected likely design have a closed form solution.",
            "However, it is convex, and so we can apply centered optimization techniques such as CG or LB FGS to this problem.",
            "However, these gradient descent techniques operate by essentially choosing descent directions and also figuring out how far to go along that direction, and in order to do so, they need to be able to compute the gradient and the objective of the problem they're optimizing.",
            "For this means in the case when undirected graphical model, to compute the likelihood and its gradient, we have to run inference on the underlying network and as I just said, this is often intractable, and so we often have to resort to approximate inference techniques.",
            "And in practice, as cited in the references here, belief propagation is often been used in order to approximate these quantities.",
            "However, we must remember that BP is itself trying to find the fixed point of a non convex optimization problem, and as such it can fall into multiple local minima and it can sometimes not converge for certain settings of the parameters.",
            "This can pose problems for the outer loop optimization procedure because it expects the gradient estimates to be stable, and so if in subsequent steps the great BP is gone to a different local minima, you can imagine that this would cause problems for the optimization procedure.",
            "So essentially using BP in the inner loop of an optimization procedure like this can lead to a very unstable learning algorithm."
        ],
        [
            "As an example, we consider the task of multi class image segmentation.",
            "This is in this task.",
            "The goal is to divide an image into a set of regions and to label each region with according to what it is.",
            "One model commonly used for this is conditional random field, where the nodes are the labels of the Super pixels or pixels and then there are independent their edges between.",
            "Nodes in the graph, which in codependency relationships.",
            "This is a dense network.",
            "This is often a very dense network with tight loops, which you which could cause cause problems for BP in general.",
            "But however because of the certain certain settings of the potentials, BP tends to work very well in practice, so everything is great, right?",
            "Well, not really.",
            "The problem is that to actually learn these models from data when we use BP in the inner loop, the actual learning algorithm doesn't work.",
            "So even though BP works when we have some good parameters, when we try to use it to learn the parameters, it doesn't work at all.",
            "And so that's."
        ],
        [
            "Problem we're trying to solve.",
            "So the solution we propose is to define a, you know, unified variational objective for parameters for parameter learning that combines inference and learning into one objective.",
            "It can be applied to any entropy approximation that has been used for approximate inference techniques.",
            "Um, it's and if you choose to use a non convex entropy which has been shown to work well in work better than convex entropies, in practice in certain cases we also provide a convergent method that will get to a local minimum of this problem and is very stable and efficient.",
            "Furthermore, the objectively proposed accommodates generalized general parameter sharing regularization and conditional training, which has been which is very important in practice for many applications that use undirected graphical models.",
            "In doing so, we we extend several existing methods that are listed on the slide here that were proposed in the literature."
        ],
        [
            "OK.",
            "So let me introduce some notation and terminology so that I can define the objective.",
            "First of all, we're going to restrict our discussion to log linear pairwise MRF's, although everything that I'm about to say also generalizes to arbitrary to General Emerson region graphs.",
            "So log linear pairwise MRF has node potentials and Ed potentials which are parameterized by multiplying some features by some parameters Theta.",
            "Furthermore the graph has cliques and we define pseudo marginals or marginals of variables in these cliques by the variable Pi.",
            "So Pi Subsea is the marginal of the variables in the clique C."
        ],
        [
            "OK.",
            "So.",
            "And then, just as I said earlier, we're trying to do maximum likelihood learning.",
            "But in order to define our unified objective or first going to go to the dual of maximum likelihood, which is maximum entropy and it's equivalent to maximum likelihood, because these are maximum liquid is a convex problem.",
            "So the dual is convex and also strong duality obtains, so that any solution to this problem can be converted to a solution of the other problem?",
            "The intuition behind maximum entropy is that we want to assume nothing about our distribution, except that it agrees with our, except that the expectations of features according to this distribution, the distribution Q that we're going to learn, agrees with expectations of the features on the data set.",
            "So essentially, this is we call this moment matching 'cause we're trying to match the moments of these features to learn feature the moment anyways.",
            "Regularization and conditional training can be handled easily just like in maximum likelihood an we provide details in the paper.",
            "However, switching to maximum entropy doesn't really make the problem anymore tractable.",
            "Q is still exponential in the number of variables, and so we still need to come up with something else."
        ],
        [
            "So the basic idea is to 1st optimize over pseudo marginals pie instead of the whole distribution queue.",
            "So that means we're now the number of variables we're optimizing over much smaller.",
            "In addition, instead of using optimizing the actual entropy of the distribution Q, we optimize an approximate entropy that's constructed from entropies of the pseudo marginals.",
            "The moment matching constraints are now calculated by expectations using the pseudo marginals.",
            "And finally, because we're no longer optimizing a real distribution queue, we have to introduce constraints so that our pseudo marginals can actually be the marginals of some real distribution.",
            "Here we actually use an outer bound of the marginal polytope, just as used in the derivation of BP.",
            "Ann and essentially the local consistency constraint.",
            "The last line here says that clusters that share variables should agree on the marginals of those variables."
        ],
        [
            "So the camel objective is this is the camel objective and the concavity of the camel objective depends on the counting numbers.",
            "In general, there are many different counting numbers you could use, and there are many different approximate entropy that people have come up with.",
            "One particular setting of these counting numbers is implied by the beta approximation to the entropy, which consists of a sum of positive entropies and a sum of negative entropies.",
            "As a result, it's a non concave objective, which means that we have to come up with some way of optimizing it."
        ],
        [
            "Additionally, we can just choose to come up with a simpler objective by just dropping the negative terms just so that we have a concave objective, and this is one other variation of camel."
        ],
        [
            "This simple version of Camel that I just talked about is surprisingly related to recently proposed parameter estimation approach called piecewise training, introduced in 2005 by sudden McCallum, in particular, piecewise training was was defined as basically optimizing the sum of local likelihood terms, one per click.",
            "If we just drop the marginal consistency constraints in this objective here and take the dual will get the same objective as piecewise training.",
            "So this provides insight into what piecewise training is doing."
        ],
        [
            "OK. OK, so we want to actually optimize the original beta camel version because we think that the beta approximation entropy could work better and so we have to come up with some way to do this.",
            "And So what we observe is that we can write this objective as a sum of convex terms and concave terms.",
            "And now we're going to use a realtor isation trick that was applied by you'll in 2003 for inference, and we're going to apply here for doing simultaneous inference and learning.",
            "So the basic way works is that we first approximate or objective by a linear by linearizing the convex term and just keeping the concave term, and so this resulting objective is concave because it's linear plus concave.",
            "And we just optimize this and then after once we've finished optimizing it, we choose a new approximation at the next point, and we repeat this procedure until convergence.",
            "It has been shown that this is guaranteed to converge to a fixed point of our original."
        ],
        [
            "Active.",
            "So here we apply this to our actual the actual objective function we have and So what we have to do is we keep the positive entropies as I discussed and we linearize the negative entropies by choosing a vector G. Right?",
            "Now, in order to solve this problem, we use we first."
        ],
        [
            "Arrive the dual unconstrained optimization problem.",
            "This results in a sum of local likelihood terms.",
            "This is very similar to multiclass logistic regression, where G is simply a bias term for each cluster.",
            "The local consistency constraints reduced to just another type of feature.",
            "It might appear initially that the local consistency constraints look very different from the moment matching constraints, but they're both just equality constraints, so we can define a set of features such that the whole problem looks simply like logistic regression.",
            "The LaGrange multipliers that correspond to the these different types of constraints we can think of as corresponding to the weights and messages.",
            "If we were doing the double loop algorithm.",
            "And this is performing simultaneous learning and inference in that pseudo marginal gets gets along the way are not consistent and nor is the gradient 0.",
            "But at convergence both we get both a consistent set of pseudo marginals and we have optimized entire problem."
        ],
        [
            "OK, so how does this work in practice?",
            "We compare several different algorithms.",
            "The first algorithm is a double loop algorithm that uses belief propagation in the inner loop.",
            "Here we tried the best we could to actually make BP work.",
            "In particular, we use residual belief propagation, which has been shown to converge much more often than standard loopy.",
            "We also take several other measures to try to make the algorithm as stable as possible and try to make it converge to the same local Optima each time.",
            "Um?",
            "We also test the two variants of Camel, Camel plus the beta approximation and the simple camel that uses a convex concave entropy.",
            "And finally, we also test piecewise, which is simply will just simple camel with the local consistency constraints dropped.",
            "For all of these things algorithms we use lbsu optimization procedure and we use BP at Test time to actually to calculate the accuracy of the result."
        ],
        [
            "Parameters.",
            "The first data set we tried was the segmentation data set which I described earlier here.",
            "Each node can take on 7 classes listed there.",
            "There are only 84 parameters in this model because there's extensive parameter sharing every node, potential shares, parameters, and every edge potential shares parameters.",
            "There are lots of loops and it's a very densely connected."
        ],
        [
            "Work.",
            "The other data set that we try is named entity recognition.",
            "Here the goal is to essentially take newswire or other document and label each word according to its class, which can either be person, location, organization, or miscellaneous.",
            "The Skip chain CRF model or conditional random field was proposed by sudden McCallum to target this task, and what happens is you connect the words together in a chain and then you introduce long range links between words that are the same.",
            "The idea is that Mr Smith, as in this example, should take on the same class as it does in the earlier.",
            "Every occurrence of some it should have the same class.",
            "Unlike the segmentation data set, this one has four 100,000 features and more than 3 million weights, which is common to many NLP applications.",
            "Although it's important to note that these features don't appear in every click, so there are just many features, but the number of features per cluster could."
        ],
        [
            "Not be that big.",
            "OK, so here are the results.",
            "On the named entity recognition data set, we see that all the algorithms perform roughly equivalently BP.",
            "Better camel and loopy do better than simple camel and piecewise, but though not by a very significant amount, although it is statistically significant.",
            "Um?",
            "On the segmentation data set, though, the story is much different.",
            "Loopy does extremely badly, even though we tried to give it all the chances we could.",
            "Piecewise training does a lot better, but it's beaten by both simple camel embedded camel.",
            "We see the simple Campbell does significantly better than piecewise, and the better approximately camel does slightly better than simple Cam."
        ],
        [
            "So while I did, why did we do get such a performance improvement on the segmentation data set, but not that much on the named entity recognition data set?",
            "Well, first thing to observe is that the local consistency constraints add good bias.",
            "It's goodbye is because we know these constraints have to be true for any real distribution.",
            "Any real distribution has marginals that agree with each other.",
            "So introducing this into the named entity recognition datasets still didn't do anything, and the reason is because the name that data set has millions of moment matching constraints, each moment matching constraint constrains the pseudo marginals to agree with the data set on yet another feature.",
            "With every subsequent constraint, this distribution is becoming more and more similar to the empirical data set in empirical distribution, and this means that the more similar to that, the harder it is for it to also violate the local consistency constraints because it's so similar to a real distribution.",
            "In fact, when we ran in our experiments, what we first did was run piecewise training and then introduce the marginal that consistency constraints, and we found that these were already satisfied after piecewise training.",
            "In contrast, in the segmentation data set, when we ran piecewise and then added these constraints that were completely violated, the local consisting concerns are not satisfied and the reason is that there are only 84 parameters, so there are very few moment matching constraints, but they tie together a large numbers of clusters.",
            "But this means that essentially there are a lot of lot of pseudo marginal satisfy these constraints yet do not satisfy the local consistency constraints, so therefore introducing them made of."
        ],
        [
            "Difference.",
            "So what have we done?",
            "We basically introduced the camel algorithm and objective, which unifies learning and inference.",
            "It optimizes the beta approximation to entropy, which is desirable, and it does so using a repeated convex optimization with a simple form.",
            "Furthermore, only few linearizations are required.",
            "For instance in our experiments, then not with greatest number of linearizations was just 7.",
            "And you can just stop early if you want.",
            "Furthermore, it is very convergent and stable.",
            "In addition to showing this objective and introducing this objective and showing how well it works in practice, our results also suggest that the constraints on the probability distribution are far more important in the context of learning than entropy approximation.",
            "So introducing these marginal consistent constraints helped a lot, and there were."
        ],
        [
            "Changing the entropy didn't, and so this naturally suggests maybe this is a similar question for inference, so can we evaluate the relative benefits of the approximation to the entropy in the constraints?",
            "Maybe when we go from the beta approximation to the Kikuchi approximation, the change in the entropy is not really what gives us the benefit, but it's really more the marginal polytope constraints and the fact that we have a tighter bound on them.",
            "Of course, since these constraints helped just introducing these constraints helped here.",
            "Maybe we can Institute in tighter constraints by using the work of Sontag at all to introduce a constraint on three clusters with three variables, and so on.",
            "And we could imagine that this should should help learning as well, and this can also be naturally integrated with the approach we gave here.",
            "Finally knew optimization methods are needed to exploit the structure of the constraints when doing belief propagation, the constraints often only tie together small groups of variables is neighboring clusters.",
            "This is not true for learning the moment matching constraints.",
            "Tie together multiple clusters, every feature, every cluster that shares a feature is now tide together.",
            "This means that coordinate descent type approaches are not going to work well because just updating one wait could cause many other weights to become suboptimal.",
            "So we need to think of other ways to exploit the structure of the matrix in order to make optimization faster.",
            "Alright, that's it, thanks.",
            "So how long does it take?",
            "So for the NLP data set, it takes about a day to run experiments and introducing the constraints it takes about twice as long to do it with additional constraints and without if you actually started with those constraints.",
            "But because we start without them and then introduce some, it takes exactly the same amount of time with and without the constraints on the vision data set, it takes much longer to learn with the additional constraints and without and that took about.",
            "Also, I think 10 hours per data set.",
            "Local.",
            "BP during learning.",
            "But what about during test time?",
            "Since that wants to, it could be that there are some particular explains that he used during training with which which test time use different different fixed points which.",
            "Different performance, that's true.",
            "These are on different graphs, of course, so the fixed points are incomparable, but.",
            "That is true I I think.",
            "That's a good point.",
            "I actually don't know.",
            "There's I mean, the fact is loopy belief propagation has multiple fixed points, so there's not really anything you can do about that, but it helps to at least use the same approximation of entropy during learning as test at Test time.",
            "Then using a different approximation, I think.",
            "Yesterday.",
            "But as you learn.",
            "Problem.",
            "Back then, what other problem?",
            "Exactly, yeah."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so for the purpose of this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're concerned with undirected graphical models.",
                    "label": 1
                },
                {
                    "sent": "So many real world problems can be accurately represented by undirected graphical models.",
                    "label": 0
                },
                {
                    "sent": "These models attempt to model a probability distribution on a set of random variables.",
                    "label": 0
                },
                {
                    "sent": "Um, where the nodes in the graphical model correspond to the variables and undirected.",
                    "label": 0
                },
                {
                    "sent": "The model is parameterized by some parameter vector Theta.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "In many cases, this graphical model can be densely connected, which means that exact inference is computationally intractable.",
                    "label": 0
                },
                {
                    "sent": "However, much work has been much recent work is focused on approximate inference techniques, so in practice, belief approximate inference techniques like belief propagation can work very well in practice.",
                    "label": 0
                },
                {
                    "sent": "On real world problems.",
                    "label": 0
                },
                {
                    "sent": "However, the problem we're concerned with is not performing inference on these models, but instead on learning the parameters for these models from data.",
                    "label": 0
                },
                {
                    "sent": "It is well known that.",
                    "label": 1
                },
                {
                    "sent": "Choosing parameters from data can result in improve performance on many tests, and so of course it's interesting to know how to automatically learn these models from data.",
                    "label": 0
                },
                {
                    "sent": "So how do we learn the parameters of undirected graphical?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, first.",
                    "label": 0
                },
                {
                    "sent": "The likelihood of undirected likely design have a closed form solution.",
                    "label": 0
                },
                {
                    "sent": "However, it is convex, and so we can apply centered optimization techniques such as CG or LB FGS to this problem.",
                    "label": 0
                },
                {
                    "sent": "However, these gradient descent techniques operate by essentially choosing descent directions and also figuring out how far to go along that direction, and in order to do so, they need to be able to compute the gradient and the objective of the problem they're optimizing.",
                    "label": 0
                },
                {
                    "sent": "For this means in the case when undirected graphical model, to compute the likelihood and its gradient, we have to run inference on the underlying network and as I just said, this is often intractable, and so we often have to resort to approximate inference techniques.",
                    "label": 0
                },
                {
                    "sent": "And in practice, as cited in the references here, belief propagation is often been used in order to approximate these quantities.",
                    "label": 0
                },
                {
                    "sent": "However, we must remember that BP is itself trying to find the fixed point of a non convex optimization problem, and as such it can fall into multiple local minima and it can sometimes not converge for certain settings of the parameters.",
                    "label": 1
                },
                {
                    "sent": "This can pose problems for the outer loop optimization procedure because it expects the gradient estimates to be stable, and so if in subsequent steps the great BP is gone to a different local minima, you can imagine that this would cause problems for the optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "So essentially using BP in the inner loop of an optimization procedure like this can lead to a very unstable learning algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As an example, we consider the task of multi class image segmentation.",
                    "label": 0
                },
                {
                    "sent": "This is in this task.",
                    "label": 0
                },
                {
                    "sent": "The goal is to divide an image into a set of regions and to label each region with according to what it is.",
                    "label": 0
                },
                {
                    "sent": "One model commonly used for this is conditional random field, where the nodes are the labels of the Super pixels or pixels and then there are independent their edges between.",
                    "label": 0
                },
                {
                    "sent": "Nodes in the graph, which in codependency relationships.",
                    "label": 0
                },
                {
                    "sent": "This is a dense network.",
                    "label": 0
                },
                {
                    "sent": "This is often a very dense network with tight loops, which you which could cause cause problems for BP in general.",
                    "label": 1
                },
                {
                    "sent": "But however because of the certain certain settings of the potentials, BP tends to work very well in practice, so everything is great, right?",
                    "label": 0
                },
                {
                    "sent": "Well, not really.",
                    "label": 0
                },
                {
                    "sent": "The problem is that to actually learn these models from data when we use BP in the inner loop, the actual learning algorithm doesn't work.",
                    "label": 0
                },
                {
                    "sent": "So even though BP works when we have some good parameters, when we try to use it to learn the parameters, it doesn't work at all.",
                    "label": 0
                },
                {
                    "sent": "And so that's.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem we're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "So the solution we propose is to define a, you know, unified variational objective for parameters for parameter learning that combines inference and learning into one objective.",
                    "label": 1
                },
                {
                    "sent": "It can be applied to any entropy approximation that has been used for approximate inference techniques.",
                    "label": 1
                },
                {
                    "sent": "Um, it's and if you choose to use a non convex entropy which has been shown to work well in work better than convex entropies, in practice in certain cases we also provide a convergent method that will get to a local minimum of this problem and is very stable and efficient.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, the objectively proposed accommodates generalized general parameter sharing regularization and conditional training, which has been which is very important in practice for many applications that use undirected graphical models.",
                    "label": 0
                },
                {
                    "sent": "In doing so, we we extend several existing methods that are listed on the slide here that were proposed in the literature.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let me introduce some notation and terminology so that I can define the objective.",
                    "label": 0
                },
                {
                    "sent": "First of all, we're going to restrict our discussion to log linear pairwise MRF's, although everything that I'm about to say also generalizes to arbitrary to General Emerson region graphs.",
                    "label": 1
                },
                {
                    "sent": "So log linear pairwise MRF has node potentials and Ed potentials which are parameterized by multiplying some features by some parameters Theta.",
                    "label": 0
                },
                {
                    "sent": "Furthermore the graph has cliques and we define pseudo marginals or marginals of variables in these cliques by the variable Pi.",
                    "label": 0
                },
                {
                    "sent": "So Pi Subsea is the marginal of the variables in the clique C.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And then, just as I said earlier, we're trying to do maximum likelihood learning.",
                    "label": 0
                },
                {
                    "sent": "But in order to define our unified objective or first going to go to the dual of maximum likelihood, which is maximum entropy and it's equivalent to maximum likelihood, because these are maximum liquid is a convex problem.",
                    "label": 0
                },
                {
                    "sent": "So the dual is convex and also strong duality obtains, so that any solution to this problem can be converted to a solution of the other problem?",
                    "label": 0
                },
                {
                    "sent": "The intuition behind maximum entropy is that we want to assume nothing about our distribution, except that it agrees with our, except that the expectations of features according to this distribution, the distribution Q that we're going to learn, agrees with expectations of the features on the data set.",
                    "label": 0
                },
                {
                    "sent": "So essentially, this is we call this moment matching 'cause we're trying to match the moments of these features to learn feature the moment anyways.",
                    "label": 0
                },
                {
                    "sent": "Regularization and conditional training can be handled easily just like in maximum likelihood an we provide details in the paper.",
                    "label": 1
                },
                {
                    "sent": "However, switching to maximum entropy doesn't really make the problem anymore tractable.",
                    "label": 1
                },
                {
                    "sent": "Q is still exponential in the number of variables, and so we still need to come up with something else.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the basic idea is to 1st optimize over pseudo marginals pie instead of the whole distribution queue.",
                    "label": 0
                },
                {
                    "sent": "So that means we're now the number of variables we're optimizing over much smaller.",
                    "label": 0
                },
                {
                    "sent": "In addition, instead of using optimizing the actual entropy of the distribution Q, we optimize an approximate entropy that's constructed from entropies of the pseudo marginals.",
                    "label": 0
                },
                {
                    "sent": "The moment matching constraints are now calculated by expectations using the pseudo marginals.",
                    "label": 1
                },
                {
                    "sent": "And finally, because we're no longer optimizing a real distribution queue, we have to introduce constraints so that our pseudo marginals can actually be the marginals of some real distribution.",
                    "label": 0
                },
                {
                    "sent": "Here we actually use an outer bound of the marginal polytope, just as used in the derivation of BP.",
                    "label": 0
                },
                {
                    "sent": "Ann and essentially the local consistency constraint.",
                    "label": 1
                },
                {
                    "sent": "The last line here says that clusters that share variables should agree on the marginals of those variables.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the camel objective is this is the camel objective and the concavity of the camel objective depends on the counting numbers.",
                    "label": 1
                },
                {
                    "sent": "In general, there are many different counting numbers you could use, and there are many different approximate entropy that people have come up with.",
                    "label": 0
                },
                {
                    "sent": "One particular setting of these counting numbers is implied by the beta approximation to the entropy, which consists of a sum of positive entropies and a sum of negative entropies.",
                    "label": 0
                },
                {
                    "sent": "As a result, it's a non concave objective, which means that we have to come up with some way of optimizing it.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additionally, we can just choose to come up with a simpler objective by just dropping the negative terms just so that we have a concave objective, and this is one other variation of camel.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This simple version of Camel that I just talked about is surprisingly related to recently proposed parameter estimation approach called piecewise training, introduced in 2005 by sudden McCallum, in particular, piecewise training was was defined as basically optimizing the sum of local likelihood terms, one per click.",
                    "label": 1
                },
                {
                    "sent": "If we just drop the marginal consistency constraints in this objective here and take the dual will get the same objective as piecewise training.",
                    "label": 1
                },
                {
                    "sent": "So this provides insight into what piecewise training is doing.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, so we want to actually optimize the original beta camel version because we think that the beta approximation entropy could work better and so we have to come up with some way to do this.",
                    "label": 0
                },
                {
                    "sent": "And So what we observe is that we can write this objective as a sum of convex terms and concave terms.",
                    "label": 0
                },
                {
                    "sent": "And now we're going to use a realtor isation trick that was applied by you'll in 2003 for inference, and we're going to apply here for doing simultaneous inference and learning.",
                    "label": 0
                },
                {
                    "sent": "So the basic way works is that we first approximate or objective by a linear by linearizing the convex term and just keeping the concave term, and so this resulting objective is concave because it's linear plus concave.",
                    "label": 0
                },
                {
                    "sent": "And we just optimize this and then after once we've finished optimizing it, we choose a new approximation at the next point, and we repeat this procedure until convergence.",
                    "label": 0
                },
                {
                    "sent": "It has been shown that this is guaranteed to converge to a fixed point of our original.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Active.",
                    "label": 0
                },
                {
                    "sent": "So here we apply this to our actual the actual objective function we have and So what we have to do is we keep the positive entropies as I discussed and we linearize the negative entropies by choosing a vector G. Right?",
                    "label": 0
                },
                {
                    "sent": "Now, in order to solve this problem, we use we first.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Arrive the dual unconstrained optimization problem.",
                    "label": 0
                },
                {
                    "sent": "This results in a sum of local likelihood terms.",
                    "label": 1
                },
                {
                    "sent": "This is very similar to multiclass logistic regression, where G is simply a bias term for each cluster.",
                    "label": 1
                },
                {
                    "sent": "The local consistency constraints reduced to just another type of feature.",
                    "label": 1
                },
                {
                    "sent": "It might appear initially that the local consistency constraints look very different from the moment matching constraints, but they're both just equality constraints, so we can define a set of features such that the whole problem looks simply like logistic regression.",
                    "label": 0
                },
                {
                    "sent": "The LaGrange multipliers that correspond to the these different types of constraints we can think of as corresponding to the weights and messages.",
                    "label": 0
                },
                {
                    "sent": "If we were doing the double loop algorithm.",
                    "label": 0
                },
                {
                    "sent": "And this is performing simultaneous learning and inference in that pseudo marginal gets gets along the way are not consistent and nor is the gradient 0.",
                    "label": 0
                },
                {
                    "sent": "But at convergence both we get both a consistent set of pseudo marginals and we have optimized entire problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how does this work in practice?",
                    "label": 0
                },
                {
                    "sent": "We compare several different algorithms.",
                    "label": 0
                },
                {
                    "sent": "The first algorithm is a double loop algorithm that uses belief propagation in the inner loop.",
                    "label": 1
                },
                {
                    "sent": "Here we tried the best we could to actually make BP work.",
                    "label": 0
                },
                {
                    "sent": "In particular, we use residual belief propagation, which has been shown to converge much more often than standard loopy.",
                    "label": 0
                },
                {
                    "sent": "We also take several other measures to try to make the algorithm as stable as possible and try to make it converge to the same local Optima each time.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We also test the two variants of Camel, Camel plus the beta approximation and the simple camel that uses a convex concave entropy.",
                    "label": 0
                },
                {
                    "sent": "And finally, we also test piecewise, which is simply will just simple camel with the local consistency constraints dropped.",
                    "label": 1
                },
                {
                    "sent": "For all of these things algorithms we use lbsu optimization procedure and we use BP at Test time to actually to calculate the accuracy of the result.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parameters.",
                    "label": 0
                },
                {
                    "sent": "The first data set we tried was the segmentation data set which I described earlier here.",
                    "label": 0
                },
                {
                    "sent": "Each node can take on 7 classes listed there.",
                    "label": 1
                },
                {
                    "sent": "There are only 84 parameters in this model because there's extensive parameter sharing every node, potential shares, parameters, and every edge potential shares parameters.",
                    "label": 0
                },
                {
                    "sent": "There are lots of loops and it's a very densely connected.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "The other data set that we try is named entity recognition.",
                    "label": 0
                },
                {
                    "sent": "Here the goal is to essentially take newswire or other document and label each word according to its class, which can either be person, location, organization, or miscellaneous.",
                    "label": 0
                },
                {
                    "sent": "The Skip chain CRF model or conditional random field was proposed by sudden McCallum to target this task, and what happens is you connect the words together in a chain and then you introduce long range links between words that are the same.",
                    "label": 1
                },
                {
                    "sent": "The idea is that Mr Smith, as in this example, should take on the same class as it does in the earlier.",
                    "label": 0
                },
                {
                    "sent": "Every occurrence of some it should have the same class.",
                    "label": 0
                },
                {
                    "sent": "Unlike the segmentation data set, this one has four 100,000 features and more than 3 million weights, which is common to many NLP applications.",
                    "label": 0
                },
                {
                    "sent": "Although it's important to note that these features don't appear in every click, so there are just many features, but the number of features per cluster could.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not be that big.",
                    "label": 0
                },
                {
                    "sent": "OK, so here are the results.",
                    "label": 0
                },
                {
                    "sent": "On the named entity recognition data set, we see that all the algorithms perform roughly equivalently BP.",
                    "label": 0
                },
                {
                    "sent": "Better camel and loopy do better than simple camel and piecewise, but though not by a very significant amount, although it is statistically significant.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "On the segmentation data set, though, the story is much different.",
                    "label": 0
                },
                {
                    "sent": "Loopy does extremely badly, even though we tried to give it all the chances we could.",
                    "label": 0
                },
                {
                    "sent": "Piecewise training does a lot better, but it's beaten by both simple camel embedded camel.",
                    "label": 0
                },
                {
                    "sent": "We see the simple Campbell does significantly better than piecewise, and the better approximately camel does slightly better than simple Cam.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So while I did, why did we do get such a performance improvement on the segmentation data set, but not that much on the named entity recognition data set?",
                    "label": 0
                },
                {
                    "sent": "Well, first thing to observe is that the local consistency constraints add good bias.",
                    "label": 1
                },
                {
                    "sent": "It's goodbye is because we know these constraints have to be true for any real distribution.",
                    "label": 0
                },
                {
                    "sent": "Any real distribution has marginals that agree with each other.",
                    "label": 0
                },
                {
                    "sent": "So introducing this into the named entity recognition datasets still didn't do anything, and the reason is because the name that data set has millions of moment matching constraints, each moment matching constraint constrains the pseudo marginals to agree with the data set on yet another feature.",
                    "label": 0
                },
                {
                    "sent": "With every subsequent constraint, this distribution is becoming more and more similar to the empirical data set in empirical distribution, and this means that the more similar to that, the harder it is for it to also violate the local consistency constraints because it's so similar to a real distribution.",
                    "label": 0
                },
                {
                    "sent": "In fact, when we ran in our experiments, what we first did was run piecewise training and then introduce the marginal that consistency constraints, and we found that these were already satisfied after piecewise training.",
                    "label": 0
                },
                {
                    "sent": "In contrast, in the segmentation data set, when we ran piecewise and then added these constraints that were completely violated, the local consisting concerns are not satisfied and the reason is that there are only 84 parameters, so there are very few moment matching constraints, but they tie together a large numbers of clusters.",
                    "label": 0
                },
                {
                    "sent": "But this means that essentially there are a lot of lot of pseudo marginal satisfy these constraints yet do not satisfy the local consistency constraints, so therefore introducing them made of.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Difference.",
                    "label": 0
                },
                {
                    "sent": "So what have we done?",
                    "label": 0
                },
                {
                    "sent": "We basically introduced the camel algorithm and objective, which unifies learning and inference.",
                    "label": 1
                },
                {
                    "sent": "It optimizes the beta approximation to entropy, which is desirable, and it does so using a repeated convex optimization with a simple form.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, only few linearizations are required.",
                    "label": 0
                },
                {
                    "sent": "For instance in our experiments, then not with greatest number of linearizations was just 7.",
                    "label": 0
                },
                {
                    "sent": "And you can just stop early if you want.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, it is very convergent and stable.",
                    "label": 0
                },
                {
                    "sent": "In addition to showing this objective and introducing this objective and showing how well it works in practice, our results also suggest that the constraints on the probability distribution are far more important in the context of learning than entropy approximation.",
                    "label": 1
                },
                {
                    "sent": "So introducing these marginal consistent constraints helped a lot, and there were.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Changing the entropy didn't, and so this naturally suggests maybe this is a similar question for inference, so can we evaluate the relative benefits of the approximation to the entropy in the constraints?",
                    "label": 0
                },
                {
                    "sent": "Maybe when we go from the beta approximation to the Kikuchi approximation, the change in the entropy is not really what gives us the benefit, but it's really more the marginal polytope constraints and the fact that we have a tighter bound on them.",
                    "label": 0
                },
                {
                    "sent": "Of course, since these constraints helped just introducing these constraints helped here.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can Institute in tighter constraints by using the work of Sontag at all to introduce a constraint on three clusters with three variables, and so on.",
                    "label": 0
                },
                {
                    "sent": "And we could imagine that this should should help learning as well, and this can also be naturally integrated with the approach we gave here.",
                    "label": 0
                },
                {
                    "sent": "Finally knew optimization methods are needed to exploit the structure of the constraints when doing belief propagation, the constraints often only tie together small groups of variables is neighboring clusters.",
                    "label": 1
                },
                {
                    "sent": "This is not true for learning the moment matching constraints.",
                    "label": 0
                },
                {
                    "sent": "Tie together multiple clusters, every feature, every cluster that shares a feature is now tide together.",
                    "label": 0
                },
                {
                    "sent": "This means that coordinate descent type approaches are not going to work well because just updating one wait could cause many other weights to become suboptimal.",
                    "label": 0
                },
                {
                    "sent": "So we need to think of other ways to exploit the structure of the matrix in order to make optimization faster.",
                    "label": 0
                },
                {
                    "sent": "Alright, that's it, thanks.",
                    "label": 0
                },
                {
                    "sent": "So how long does it take?",
                    "label": 0
                },
                {
                    "sent": "So for the NLP data set, it takes about a day to run experiments and introducing the constraints it takes about twice as long to do it with additional constraints and without if you actually started with those constraints.",
                    "label": 0
                },
                {
                    "sent": "But because we start without them and then introduce some, it takes exactly the same amount of time with and without the constraints on the vision data set, it takes much longer to learn with the additional constraints and without and that took about.",
                    "label": 0
                },
                {
                    "sent": "Also, I think 10 hours per data set.",
                    "label": 0
                },
                {
                    "sent": "Local.",
                    "label": 0
                },
                {
                    "sent": "BP during learning.",
                    "label": 0
                },
                {
                    "sent": "But what about during test time?",
                    "label": 0
                },
                {
                    "sent": "Since that wants to, it could be that there are some particular explains that he used during training with which which test time use different different fixed points which.",
                    "label": 0
                },
                {
                    "sent": "Different performance, that's true.",
                    "label": 0
                },
                {
                    "sent": "These are on different graphs, of course, so the fixed points are incomparable, but.",
                    "label": 0
                },
                {
                    "sent": "That is true I I think.",
                    "label": 0
                },
                {
                    "sent": "That's a good point.",
                    "label": 0
                },
                {
                    "sent": "I actually don't know.",
                    "label": 0
                },
                {
                    "sent": "There's I mean, the fact is loopy belief propagation has multiple fixed points, so there's not really anything you can do about that, but it helps to at least use the same approximation of entropy during learning as test at Test time.",
                    "label": 0
                },
                {
                    "sent": "Then using a different approximation, I think.",
                    "label": 0
                },
                {
                    "sent": "Yesterday.",
                    "label": 0
                },
                {
                    "sent": "But as you learn.",
                    "label": 0
                },
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "Back then, what other problem?",
                    "label": 0
                },
                {
                    "sent": "Exactly, yeah.",
                    "label": 0
                }
            ]
        }
    }
}