{
    "id": "5dh6qfadnxzhwjwpfrejoo3etqa6y4sr",
    "title": "An introduction to causal inference in neuroimaging",
    "info": {
        "author": [
            "Moritz Grosse-Wentrup, Max Planck Institute for Intelligent Systems, Max Planck Institute"
        ],
        "published": "April 3, 2014",
        "recorded": "February 2014",
        "category": [
            "Top->Technology->Neurotechnology",
            "Top->Medicine"
        ]
    },
    "url": "http://videolectures.net/bbci2014_grosse_wentrup_causal_inference/",
    "segmentation": [
        [
            "Thanks a lot to the organizers for inviting me, and of course thanks a lot to all of you coming here this morning, so I got into causal inference roughly six years ago when I went as a poster to the Max Planck Institute in Tubingen.",
            "And cause inference is a really really complex and tough topic and I think it took me more more less.",
            "Two years until I felt that I had a decent understanding of this topic.",
            "So when I started preparing this talk I thought how can I make the most of 1 1/2 hours and give you an introduction to causal inference?",
            "And I don't think there's much point in giving you the details of all the algorithms because that is just too much to cram into 1 1/2 or two hours.",
            "So what I try to focus on other high level concepts.",
            "So my goal is for you to understand why closet inference is interesting.",
            "What it is all about WHI?",
            "Is it such an incredibly tough problem and what are the most common ways to tackle it?",
            "What assumptions are being made on the way, and what consequences does this have for interpreting the data?",
            "So I hope that in the end of this talk you will have a somewhat an overview of what in causal inferences interests you and what you would like to read more about.",
            "So to start with."
        ],
        [
            "I want to talk a little bit about why we actually should be interested in causal inference in the 1st place, so it seems to be really hot topic in your image Ng.",
            "Right now there's lots of papers, lots of algorithms, but I think it's not such a trivial question why it's actually interesting.",
            "So why do causal models or causal inference?",
            "Why does that tell us more about how the brain works than non causal models?",
            "And I want to address this question by first speaking briefly about what we expect off a scientific theory in the 1st place.",
            "And if you go to the literature and philosophy of science and whatever and you look at what are the conditions, what makes a good theory or scientific theory?",
            "Good theory, you will usually."
        ],
        [
            "Find 2 conditions and the 1st."
        ],
        [
            "One is well, but good theory should explain the data that we have already observed.",
            "If a theory that we have can't even explain what we already know or have already observed, then there's a little point in accepting the theory.",
            "But that's not enough, and this every good machine learner knows you can easily overfit with theories, so you should also be able to."
        ],
        [
            "Use your theory to correctly predict future observations.",
            "And that's usually it.",
            "Usually these conditions are the ones that are listed for a good theory and obviously causalities absent from that.",
            "And I think causality enters when you think a bit more about the second point.",
            "What it means to correctly predict future observations, and they would like to distinguish between 2 cases.",
            "The one cases where you try to understand a system."
        ],
        [
            "That you just passively observe.",
            "You just look at the system how it evolves on its own and you would like to predict what happens on the system if it further evolves on its own.",
            "And that's one thing, but a different and much more difficult thing is to."
        ],
        [
            "What actually happens to a system if you actively intervene on it when you intervene and do something to the system and you want to predict how the system responds to this intervention?",
            "And this is where causal inference really enters."
        ],
        [
            "In my understanding.",
            "The aim of causal inference is to predict how a system reacts to an intervention that you might do to this system, and I would like to give you an example from our my own research group, so we're very interested or becoming very interested in stroke rehabilitation.",
            "So what we do is we invite stroke patients to come to our lab and we give the motor learning task.",
            "So for example, reaching in three dimensions to different targets and maybe perturbing their movements.",
            "And why are they learned this task?",
            "We measure the EG and then we try to find correlates in these signals.",
            "E.g signals off the motor learning performance and we expect to see that there are some processes that we can observe in the G that are correlated with how well the stroke patients can learn.",
            "And that should tell us something about what makes for good rehabilitation for poor stroke reputation.",
            "But of course it's not enough just to understand how the brain signals of good stroke, rebillot, eighters, and poor stroke rehabilitators look like.",
            "We would like to be able to actively intervene.",
            "Would like to be able to stimulate worth, for instance.",
            "Transcranial alternating current stimulation neural processes in these patients to turn them from poor into good rehabilitators, and for that we need to know not only which process is correlate with good rehabilitation, but we need to know which are the causes of that, and that is one reason why we are very interested in causal inference."
        ],
        [
            "So you probably have learned in your classes that correlation does not imply causation, and that you often read, but I think that understanding why this is the case is not that trivial.",
            "And this is the main reason why causal inference is such a tremendously difficult task.",
            "So before I go to these algorithms in neuroimaging that are being used there, I want to develop a little bit on the potential outcomes framework, because this is the framework that has been developed in statistics in the 60s and 70s mostly, but on Ruben at Harvard University that really forms the backbone of all.",
            "This randomized controlled studies that people do nowadays in science, and this is kind of so the.",
            "The Golden way.",
            "The best way to do causal inference.",
            "And if you are very interesting that I highly recommend this paper here by a pool Hall, and I think he's at Princeton.",
            "Former student of Donald Rubin and the Journal of the American Statistical Association.",
            "By the way, I in the end I give you a link where you can download all the papers that I talk about.",
            "So and."
        ],
        [
            "Is this framework is rather complex, so we first introduced the notation to make it a bit more illustrative.",
            "Will also list examples of the notation at the same time."
        ],
        [
            "So we start with the population you set you."
        ],
        [
            "And this might be, for instance, a set of patients that come and visit you in a clinic."
        ],
        [
            "And in individual individual unit of the set U."
        ],
        [
            "Might be an individual patient.",
            "And now."
        ],
        [
            "It might be the case that you have a treatment that you could or could not apply to this patient.",
            "For instance, you have a truck and a placebo treatment and you could assign each patient too.",
            "The treatment or two?"
        ],
        [
            "Placebo treatment so S of you is an assignment that assigns for every patient, whether that patient is going to be treated or other patients going to be assigned to the control group."
        ],
        [
            "And then you need an outcome variable Y that Maps the unit.",
            "And a treatment assignment to some real valued number now."
        ],
        [
            "For instance, this might be the survival time of a patient under the certain treatment that you give to that patient.",
            "To measure the outcome."
        ],
        [
            "OK, and now comes the fundamental problem of course inference."
        ],
        [
            "The effect of a cost T. On you is measured as the difference between Y of you given 50 years assigned or sees assigned.",
            "This means the survival time of a patient when you given the treatment minus the survivor time.",
            "A patient when you give him the placebo treatment.",
            "No, but."
        ],
        [
            "It is impossible to observe this on the same unit.",
            "You cannot assign a patient first to the control to the treatment group.",
            "Observe how long he survives and then assigned to the placebo group and observe how long it survives.",
            "So this is impossible.",
            "And this is called the fundamental problem, of course inference."
        ],
        [
            "Now, there are several solutions to tackle this."
        ],
        [
            "The first solution is to assume unit homogeneity and you just simply assume that different units that you have are absolutely identical, and this might be OK in mechanical engineering.",
            "We can manufacture these units, but if you're working for instance with humans, this is obviously not a reasonable assumption.",
            "No two patients are ever going to be alive."
        ],
        [
            "The second solution is to assume causal transients, so you assume you can first apply the one treatment, observe its effects.",
            "And then you assume that the patient enters into the original state again, and then you apply the second treatment.",
            "But again, for patients this is not a reasonable assumption and often impossible if you think about survival times."
        ],
        [
            "So the third solution that's the solution that is usually adopted is to say, OK, we can't observe the causal effect on individual units.",
            "So let's not try to compute in that.",
            "Let's compute the average causal effect key.",
            "Let's compute the average of our survival time in this example.",
            "If patients are treated.",
            "Minus the expected value of the survival time when patients are assigned to the control group.",
            "And this is a certainly much easier thing to compute."
        ],
        [
            "However, we cannot observe that either.",
            "Because this expected value here goes over the whole set of patients.",
            "But we have to assign patients to one or the other group.",
            "We can only observe this value here.",
            "The expected value of the survival time under the treatment for those patients who have been assigned to the treatment.",
            "And that's a different value in general than this one here, yes.",
            "So this means either T or C. And so the expected survival time under the treatment, given that a patient has the patients have been assigned to treatment or the expected survival time.",
            "Given that the patients have been for the control group.",
            "Given that they have been assigned to the control group.",
            "So it just means either T or C. So these two are not the same, because this here runs over the whole population.",
            "In this year only over those parts of the population that have been assigned to a certain treatment.",
            "There's no reason in particular why they need to be the same.",
            "Bad luck, but there are further ways to make sure that these two values here are exactly the same."
        ],
        [
            "So we want this value to be exactly this one here.",
            "And well, basic probability tells us the expected value of Y given S is the same as the expected value of Y if Y&S are independent."
        ],
        [
            "If wind essay independent, then these two values here are exactly the same, and when are they independent?",
            "While they're independent when you make them independent, you have to assign treatments randomly.",
            "Whenever patient comes to your lap, you randomly assign him to the treatment or to the control group and then you have ensured.",
            "That these two values are the same and that you can actually compute the average causal effect of your treatment versus your placebo treatment.",
            "And this is the way that the causal inference is usually done in randomized clinical trials.",
            "And two."
        ],
        [
            "Um?",
            "To make it a little bit more illustrative why this is so important, I have a very simple constructed example here, so let us assume that you're a doctor and people come to your lab or to your office and they want to get some treatment for some certain disease and you want to test two different drugs on their effect.",
            "But let us now assume that these two drugs actually have absolutely no influence on survival time.",
            "You're completely useless."
        ],
        [
            "Also, the expected survival time under the treatment equals the expected survival time.",
            "Another control, no difference at all, but."
        ],
        [
            "Let us further assume that actually there's a sex specific difference.",
            "Now that for some reason female women are more likely to survive longer than men.",
            "And now if a patient comes to your lap, let us further assume that you don't assign them randomly by that you talk to them that you tell them what these treatments are about, and then let them choose whether they want to have treatment a or treatment B.",
            "And let us further assume that women."
        ],
        [
            "For some reason I'm more likely to choose treatment a versus treatment B because I don't know as a nicer name.",
            "More appealing, less side effects for women, whatever."
        ],
        [
            "Then we have the problem that now in the treatment group you have more women who are more likely to survive longer and then the survival time in the treatment is greater than the survival time.",
            "Another control treatment.",
            "And now."
        ],
        [
            "You have confounding you now believe oops, my treatment actually improves survival time, even though in reality there really is absolutely no effect there.",
            "Now you could say, well, of course I have to make sure that that I have the same number of females and males in my groups.",
            "And I can control for others.",
            "And yes, of course you should, as much as you can, but this example of."
        ],
        [
            "Cost applies to any hidden confounder.",
            "This this confounding variable may be anything that you may not have measured, that you may not even know exists.",
            "So you can't exclude that.",
            "There's no way that you can make sure that such confounding doesn't happen, because there can always be confounding effects that you don't even know that they might exist.",
            "And the only way to be absolutely certain that this doesn't happen, and you can really compute the cause and effect of your treatment, is the random assignment.",
            "If you can't do that.",
            "You're lost.",
            "So."
        ],
        [
            "Sounds a bit depressing.",
            "So when we talk about causal inference on newer imaging."
        ],
        [
            "We are asking the question can we do without that?",
            "Can we do causal inference based on observation of the data only without any randomized treatments or assignments of causes?",
            "And the."
        ],
        [
            "And there's no.",
            "In general we cannot, but we are machine learners.",
            "We always make assumptions to do inferences, and we're quite happy to make assumptions as long as these assumptions are reasonable and turn out to be useful."
        ],
        [
            "And if you're willing to make some assumptions in this context here, then yes, you can do causal inference, but it's always based on assumptions, and these assumptions are usually untestable.",
            "You just have to live with it.",
            "But if they turn out to be useful empirically, then fine, then we can live with these assumptions."
        ],
        [
            "So before I go to these cause inference algorithms in detail, I want to spend a few minutes on saying what I believe makes for a good cause.",
            "Inference algorithms.",
            "How should they be scored?",
            "How should they be compared?"
        ],
        [
            "And I think one important condition is that an algorithm should be probably correct and a reasonable assumptions.",
            "You want this.",
            "You want to be able to accept these assumptions.",
            "You want to think that they are reasonable, and then you want to be able to prove that.",
            "Then make these assumptions that you will get the correct result."
        ],
        [
            "The second point is, I think, causal inference algorithm should make testable predictions on the effect of interventions.",
            "This is, I don't think everybody in your science would agree to that, but I think that causal inferences about making testable predictions on the effect of interventions, and if you have an algorithm that doesn't really make these predictions, I don't find it that useful."
        ],
        [
            "Then it should be able to deal with hidden confound us, and this is of course part of the reasonable assumptions here, but it's one of the main problems.",
            "Do you have to assume that no hidden confounders are present?",
            "Or can an algorithm in some way deal with confirms that you haven't observed?"
        ],
        [
            "And theoretically prove theoretical proofs and performance are great, but if your algorithm doesn't perform well on finite data that you observe, then it's of little use.",
            "So this is, I think, the last condition that is very important."
        ],
        [
            "OK, so this is now then the outline of my talk.",
            "I will talk about four methods, Granger, causality, causation networks, dynamic causal modeling and nonlinear non Gaussian acyclic models.",
            "Or call it non lingam.",
            "And I should probably be open about my my own preferences.",
            "So I started working initially with Granger causality an, but the more I worked with it, the less I liked it.",
            "So I switched from Granger causality, causation networks and that is the framework that I have to admit.",
            "I like most, I believe it's the most rigorous framework and I'm still working on it, so my preference is conservation networks.",
            "At the same time, was very interested in dynamic causal modeling, which is more from the neuroimaging side.",
            "And I organized several workshops at NIPS, for instance, where brought together dynamic causal modeling guys in the machine learning communities, and I thought this was really cool.",
            "But the more I learned about dynamic causal modeling, the less I liked it, and so I have to be honest, I do not like dynamic causal modeling.",
            "I would bet it a little bit.",
            "And the last one nonlinear non caution acyclic models that has been developed in part of the Max Planck Institute in tubing.",
            "So there's a little bit of a bias there as well.",
            "So when I go now into this algorithms, please do interrupt me at any point when you have any questions when when I'm going too fast or slow or anything so it would be great to have already a little bit of a discussion here."
        ],
        [
            "So Granger, causality widely used in neuroscience.",
            "And if you open a neuroscience paper on Granger causality and you look for the definition of Granger, causality will find something along.",
            "These lines will sometimes be a bit different, but usually we say one stochastic process is causal to a second if the auto regressive predictability of the second process at a given time point is improved by including measurements from the immediate past of the first.",
            "So if you read the sense for the first time, it's probably a bit hard to parse."
        ],
        [
            "So let me illustrate it with a simple example.",
            "Let us assume we observe two variables, two time series X&Y.",
            "This might be time series of local field potentials or EG signals and let us assume that.",
            "They are generated by first order autoregressive process, so X of T is a function of X at the previous time step times some noise variable.",
            "So X only drives itself.",
            "Why is also seemed to be determined by its previous time point plus some noise so driving itself.",
            "But we also assume that there is a link here from XT minus one to Y, so the previous time points of X influence the next time points of the Y.",
            "And if you not right."
        ],
        [
            "2.",
            "Device and inference procedure to test whether X causes Y the wave."
        ],
        [
            "If you do this the following you try to predict first Y from its past values.",
            "So you look at the variants of your process Y.",
            "If you're given the previous value, like usually, you would consider more than one value, but we assumed it's a first order process, so we only considering the last one.",
            "And this kind of residual variance of why the part of the variance in the time series that you can't explain by looking at the past of the time series and kind of the innovation that enters into this time series."
        ],
        [
            "And then you do a second prediction.",
            "We try to predict Y from its own past and the past of X.",
            "So you now include X in the prediction.",
            "So you look at the unexplained variance of Y at time T given the past of Y and the past of X.",
            "And then you compare the two."
        ],
        [
            "And if you find that if you use XX as well, the past of X that then your prediction error is smaller than when you only use the past of Y.",
            "Then then you conclude, according to this definition here, that X causes Y.",
            "Yes.",
            "No, right now we assume that oh OK, right now we assume that we can observe X&Y, but that we do not know this.",
            "Good point, thank you class.",
            "Yeah, so you ask is this model hidden?",
            "What do we know about this model?",
            "What do we not know about this model here?",
            "In this example we only observe that I'm serious.",
            "What we do not know this model we would like to infer this model.",
            "That we do by looking at these prediction errors.",
            "OK, so this sounds like a reasonable idea.",
            "Sounds pretty much straight forward and people say yeah, and this is the work that Granger here published in 1969 in Econometrica, and this is what you got the Nobel Prize for.",
            "And so this is the way that it's often used."
        ],
        [
            "Neuroscience is the definition again.",
            "But Interestingly, if you really.",
            "Read Granger's original paper.",
            "You find out that his definition is quite different.",
            "And I found this a little bit shocking, so this is the definition that you always find in neuroscience journals.",
            "And they say Granger defined causality as, or Granger causality is defined as.",
            "But if you look at really at grangers paper, what you wrote."
        ],
        [
            "This is definition, and that's a bit different.",
            "I want to spend a few minutes on explaining why this is a bit different, so Granger said if Sigma squared of Y given U is smaller than Sigma squared of Y, given you minus X with this bar on top, we say that X is causing why denoted by XT causing YT.",
            "So what does this mean?",
            "This is eat muskrat is again the prediction error.",
            "Why is again that I'm serious so he's also looking at the predictability of a time series.",
            "But this U is a bit of a strange concept.",
            "For Granger you is all information in the universe.",
            "It's questionable whether you would like to include the term.",
            "All information in the universe in a definition.",
            "But so he did, and now this humans X means you take all the information in the universe.",
            "You remove X from it and then.",
            "You see how well you can predict?",
            "So it's the other way round then here.",
            "Up here we say, OK, we include X in the predictions and see if our predictions get better.",
            "And Granger said, Nope, we're going to predict Y from all information in the universe.",
            "Then remove X.",
            "And if our prediction gets worse, then we say X causes Y.",
            "So why is there a difference?",
            "And does it matter that there is?"
        ],
        [
            "Definition and I think yes, it does matter a lot in this related to conf."
        ],
        [
            "Morning again, so here's an example.",
            "Let us assume that we have three time series.",
            "Again, 1st order autoregressive processes.",
            "We have observed all of them X drives itself.",
            "Why H drives itself and why drives itself.",
            "But let us further assume."
        ],
        [
            "That eight has an influence on X&Y, but with different time lags, so H causes X in the next time step.",
            "But why only two?",
            "It's time steps later?",
            "No.",
            "If you now.",
            "Try to predict.",
            "Why using X you will find the text will help in predicting Y because information from H first goes to X and then to Y.",
            "So the past of X helps you to predict the future of life.",
            "And if you invoke this definition up here, then you have to say, oh, cool, yeah, X is causing why.",
            "But obviously it would be nonsense to to put forward a definition.",
            "When this example you would have to conclude by the definition that X is a cause of why because there's a hidden confounder that actually enables you to make better predictions.",
            "Yes.",
            "So just said X minus.",
            "Estimize one could be a sequence of.",
            "Composed yes, yes, it could be composed of all the past, but still that doesn't.",
            "That doesn't make a difference to this this confounding issue because.",
            "Here, even if you take all the past, you will always learn more information here from H that will help you in predicting the future of life.",
            "So when you invoke, when you use this definition here, you would have to conclude that X is causing Y in this example.",
            "But you don't want to conclude that because there is no causal relation between the two of us, just this hidden confounder.",
            "Yes.",
            "Awesome.",
            "Did you say OK X is cause of why?",
            "And then also page is causing X in one model, yes?",
            "To say that if X is causing why, but age is also in an earlier time point is causing X.",
            "Why do you think it would be possible to say, OK, I should investigate.",
            "If there is this indirect way from each, yes, yes.",
            "I fully agree you should investigate whether there is this this path this interactive way."
        ],
        [
            "And indeed, that is the way that you should do it if you have observed H. What you should do is you should control for.",
            "It should look at the prediction error of Y given the path of Y&X given 8.",
            "And the prediction of Y given only passively in the path of H, and then you've controlled for it and then.",
            "Then you inference is going to be correct.",
            "Now the problem again is you may have observed some age, but do you want to assume that you have observed all potentially potential age that can exist in the universe?",
            "It's a bit unreasonable, but there are two things here on the one inside, it's how do you do inferences when you have to do it on empirical data?",
            "And how do you construct your theoretical definitions?",
            "And I think it's very important to note that Granger was clever enough to note that he needs a definition where he doesn't say that X causes wife.",
            "There's a confounder present.",
            "It's important to at least have the definition right.",
            "Whether you can test or apply this definition in practice is an altogether different thing.",
            "And I'm a little bit annoyed sometimes when I read in neuroscience journals that this problem of hidden confounders is simply brushed under the carpet.",
            "And people even attribute a definition to Granger that he didn't make.",
            "It's perfectly fine to say we can't do Granger causality inference with hidden confounders.",
            "At least I don't know of anything any way to do that, but that's OK. We're going to make the assumptions that we have observed everything that's causally relevant then it's still interesting what you get, but you're open about your assumptions, and I think this is really important.",
            "Everybody knows that causes inferences based on assumptions, so just be open about it and live with it.",
            "But do not attribute something to Granger that he didn't say.",
            "OK, so this I think is the biggest problem that I have with Granger causality and I have not yet seen a way to control for hidden confounders for this time series H. If you have not observed this and I'm uncomfortable with making this assumption that there are no such inconformes."
        ],
        [
            "Yeah."
        ],
        [
            "So, however, when you look at neuroscience journals that you would not often find Granger causality applied in this way.",
            "Most oftenly you will find a variant of it that is called the direct transfer function and I want to briefly introduce this.",
            "And it's really just a small variant of its published initially I think by Cummins Catalent Biologics."
        ],
        [
            "In 2001, and the way it works is the following.",
            "You observe T samples of some multivariate time series and dimensional.",
            "For example, N could be the number of your EG channels."
        ],
        [
            "Then you have to pick an order P of your auto regressive process.",
            "And this is of course a difficult choice.",
            "How do you pick it?",
            "There's several ways to pick it.",
            "Optimally.",
            "My own take is that you should try several different P and check whether you cause it influences our robust with respect to your choice of P and if they are not robust with respect to Pi would be careful."
        ],
        [
            "And then you learn the parameters AI.",
            "This AI is a matrix of an autoregressive process of order P. So you try to model.",
            "Your observations X by Delate versions of it.",
            "With these matrices A plus some noise variable and there are many ways to do that in Matlab, R, Python.",
            "They all have these methods implemented, so I want well on that."
        ],
        [
            "And then if you let a of 0.",
            "AB minus the identity matrix.",
            "Then you can write this equation as this term here and if you have done some certain processes and you note that this year actually."
        ],
        [
            "A convolution of a with X and a convolution in the time domain is equivalent to a multiplication in the frequency domain.",
            "So what you do then as you."
        ],
        [
            "By the Fourier transform to move to the frequency domain of these signals.",
            "Then you have minus a of F * X of F equals epsilon of F."
        ],
        [
            "And then rearranging it, you get this matrix H of F, which is the inverse of minus A of F. That tells you how these noise variables drive.",
            "You observe processes in a frequency specific way."
        ],
        [
            "So.",
            "The element of the I throw in the Jeff column of H. At frequency F, describes the frequency specific effect of the Jason Time series on the Ice Time series.",
            "And this is the way that you will most often find Granger causality applied to neural data.",
            "And I am trying to."
        ],
        [
            "The case study for every inference algorithm that I present, and this is.",
            "Probably in my my opinion, the most interesting study on Granger causality, at least that I've read in a long time.",
            "It's about Bozeman at all, from the group of Pascal Freeze at the Instrument Institute in Frankfurt, and what they did is they recorded ECOG in monkeys.",
            "So a huge huge ECG grid that cover the whole left hemisphere of monkeys.",
            "And then they show two different stimulate with these monkeys and they trained the monkeys to either attend to one stimulus or the other stimulus and they found that in lower visual areas for the one stimulus.",
            "This region here was most important for the other stimulus.",
            "This region here was most important and then they looked with Granger causality at Granger.",
            "Causal interactions between these lower level visual areas and a higher level visual areas in ECG data.",
            "And they use the variance of this direct transfer function.",
            "What they found is that if you look at the interaction from V1A2V4 when monkeys attended this red stimulus that you had this strong Granger causal effect at around 70 Hertz.",
            "Interestingly, the other way round from V for a 2V1 a you didn't see that.",
            "And when monkeys attended the other stimulus, the blue stimulus bill wasn't really blue anyhow.",
            "Then they found it the other way round.",
            "They didn't see that between V1 A but V. 1B and also they didn't find a top down influence.",
            "And I think this is really interesting result.",
            "Of course, there could have been hidden confounders present.",
            "But this dissociation between top down influences and attending the one or the other stimulus and seeing this clear effects, I think makes for very interesting data.",
            "And if you're interested to see how Granger causality can be reasonably applied to neural data, I highly recommend this one paper here class.",
            "OK, so maybe 1 one issue in this Granger.",
            "Causal studies is also that if you have noise in both signals, then you may find some influence just because of the noise and so.",
            "So if I look at this data you still see a little nob in the lower role.",
            "So I think that maybe from that noise.",
            "So I mean it's also Granger by the way said that.",
            "You know the way he thought about his stuff was not noise robust.",
            "Yeah, I thought Ranger also said that quote that I like that, he said.",
            "The causality that he defined is.",
            "Complex enough to be interesting, yet simple enough for ecoa metrics to understand.",
            "So he was quite aware that there are limitations, and maybe I should list a few more limitations that are rather interesting.",
            "Granger causality also applied to fMRI data a lot, but the boat response.",
            "Has different dynamics at different boxes, so there different delays in the boat response depending on where you look in the brain.",
            "And this is definitely a problem for Granger causality apply to fMRI data.",
            "And also some people argue that Granger causality is not really that much about causality, but more about information flow information transfer, because you can construct examples where there is 0 Granger causality but certainly a causal interaction going on.",
            "But these are just some side points and I'd be happy to discuss that later with you in the breaks.",
            "OK, so before I move away from Granger causality, any questions about it?",
            "OK then let me."
        ],
        [
            "Oh, I forgot about this.",
            "This is the table that I make to a little bit score these different algorithms against one another.",
            "It's a very subjective view, some scoring it whether they're probably correct, whether they make testament inventions, can deal with hidden confounders and how they perform empirically."
        ],
        [
            "Granger, causality.",
            "I don't see that this probably correct unreasonable assumptions with these hidden confounders and news of the way that it's done with the linear models, and I don't like that."
        ],
        [
            "I think it does make testable interventions.",
            "It has to.",
            "If you stimulate with a certain frequency in one process, you should observe or not observe frequency specific effect in another time series."
        ],
        [
            "I don't know of any way to deal with hidden confounders, but of course somebody may come up with a reasonable way to address this in the future.",
            "And in terms of empirical performance, I want to postpone this to the summary of my talk."
        ],
        [
            "OK, then the next one is cause of Asian networks.",
            "My own favorite."
        ],
        [
            "And cause abrasion networks have been developed by Judea Pearl at UCLA and Peter's parties and others at Carnegie Mellon University.",
            "And Interestingly they more or less developed exactly the framework more or less independently.",
            "They both published a book on it in 2000, and I think both books are.",
            "Phenomenal.",
            "Grainger in Granger Judea Pearl got the Turing award.",
            "I think two years ago for his work on vision networks and cause abrasion networks.",
            "Which is the Nobel Prize in computer science?",
            "And this book is.",
            "Badger Depot is really incredible.",
            "I've started reading it six years ago and still not done and it's always worth reading a few parts of it again.",
            "I highly recommend it, but it's not a book that you just read in one semester and to start with, I want to give you a simple example how inference in this framework works.",
            "What's the philosophy behind it?",
            "And let us assume that we have a very simple causal structure.",
            "XY and Z3 variables that we observe an X causes Y&Y causes COX&Y could be two different neural processes that we observe.",
            "I don't know.",
            "Band Palace in certain regions in certain frequency bands, NZ could be for instance the performance of our stroke.",
            "Patients are more to learning task.",
            "Let us assume that the call is the structure is such that indeed X&Y.",
            "Both are A cause of Z, but this causes structures unknown to us.",
            "We cannot directly observe this.",
            "What?"
        ],
        [
            "We can observe, however."
        ],
        [
            "It's empirical data so we can sample from our system and we all can always observe a pair of these three variables XY and Z, and we can sample that many times.",
            "For instance, we can observe many patients and then we get N samples of this pair.",
            "Of these three variables.",
            "And if we do this infinitely many times."
        ],
        [
            "Of course, we can infer the joint distribution of XY&Z from it, so this is what we can in principle observe.",
            "And for now I will assume for the next few slides that we have always access to this joint distribution.",
            "This is, of course, a rather unreasonable assumption.",
            "We have to estimate that from finite data, and doing that will be very tough.",
            "But for now, for the conceptual issues, I assume that we have access to this joint distribution.",
            "And from this joint Distr."
        ],
        [
            "Use and what we can read off this dependency structure between these variables we can test which variables are dependent on one another and which ones are independent.",
            "So for this one called structure here, what we will find is this dependency structure.",
            "X in Z will be dependent and Y&Z will be dependent because there's a direct causal link from X to Z and from Y to Z.",
            "But X&Y, they will be independent, because there's no causal link, no no common cause of this, so they will be independent.",
            "And now if we empirically observe this dependency structure.",
            "We can ask the question.",
            "What causes structures could have given rise to this?",
            "What causes structures could have generated such a dependency structure?",
            "No so."
        ],
        [
            "Let's go through it through a few, so we already know that this causes structure generates this dependency structure, so this is a potential causes structure that's consistent with observations."
        ],
        [
            "What about this causes structure where you only have one link?",
            "Well, if you only have 1 Lincoln, why is not related causally to any of these two variables?",
            "You don't have independence here, so you know.",
            "OK, if I observe this.",
            "Can't have been discourse structure."
        ],
        [
            "What about this graph here, where X causes Y&Z causes Y, where then you dependency structure will look like this.",
            "Because X will influence Y via C and hence X&Y will be in general independent.",
            "And then again, you know, OK, this is inconsistent with this cost structure."
        ],
        [
            "So what about this one here where X&Y are actually independent are not causally related, but they're both influenced by Z.",
            "Then again, you will find that they are all dependent X&Z.",
            "Because of this direct causal link and Z&Y.",
            "Also because of the start causal link.",
            "But now Z is a joint common cause and that introduces a dependency between X&Y.",
            "Yeah, and in this way you can cycle or you can try out all causes structures that there are.",
            "Check their dependency structures and see if there's any causes structure involving three variables.",
            "Other than this one that generates this dependency structure.",
            "And you will find under some assumptions that I will talk about in a minute that this year is the only one.",
            "So if you observe three variables with this.",
            "Dependency structure, you know there can only have been under some reasonable assumptions.",
            "This caused a graph that generated it.",
            "If you observe something like this, you can't say anything.",
            "So this is very important principle.",
            "It's like inference by exclusion.",
            "Observe something you check what could have generated it, and if there's only one cause of structure that could have generated it, you're done.",
            "If you find multiple causal structures that could have generated it, you can't make any inferences.",
            "And this principle."
        ],
        [
            "This tries to three routes for causal inference in this framework, and the first one is the rule for potential causation, and it goes as follows under the assumption assumptions of faithfulness and causes sufficiency, which I will explain in a minute.",
            "The following conditions are sufficient for X to be a cause of Y. X needs to be independent of the.",
            "I write this with this independent sign WHI needs to be independent of the.",
            "Sorry, dependent dependent Excellency need to be dependent Y&Z need to be dependent and X&Y need to be independent, so exactly exactly this depends this structure.",
            "And under these assumptions, you may infer that the causes structure that generated this is this one here.",
            "Now the two assumptions are causes sufficiency and faithfulness causes.",
            "Sufficiency means that there are no hidden confounders present because."
        ],
        [
            "There were hidden confounder H here.",
            "That were cause of X end of Z you would get exactly the same dependence structure.",
            "So this is again this problem of in confounding.",
            "Faithfulness I will get to in a minute.",
            "But what I like so much about this conservation networks framework is that there are rules to deal with hidden confounders.",
            "And I think this is pretty unique."
        ],
        [
            "There's one rule for spurious Association.",
            "So again, under the assumption of faithfulness, there are conditions that you can test.",
            "That will tell you whether there is a hidden confounder present in your data.",
            "And the conditions are as follows.",
            "You need fall variables this time, so cause abrasion networks is always about observing dependency structures between more than two variables and making inferences from that.",
            "Now if you only have two variables, you can't say anything with conservation networks.",
            "You need Z&X to be dependent.",
            "You need X&Y to be dependent, and you need W&Y to be dependent.",
            "But there may be no cross dependencies here.",
            "And if that is the case, you've observed such a dependency structure, you may infer that there is a hidden confounder between X.",
            "And why?",
            "And to illustrate why this is the case, and let us assume."
        ],
        [
            "There's actually a causal link from X to Y.",
            "Then there would be a dependency in general between Z&Y, because whatever information on these that is contained in X is passed onto Y, then you would have this link.",
            "Other ways?"
        ],
        [
            "Round if the cause infants were different Y 2X then you would have a dependence between W index."
        ],
        [
            "And if you don't find this cross talk, then you know that the Association between X&Y must have been caused by a hidden confounder that you haven't observed.",
            "And this is really cool to be able to test for that in general.",
            "But conservation networks even more."
        ],
        [
            "Awesome, there is a rule for genuine causation.",
            "You can test.",
            "That there's a genuine causal link between two variables that cannot have been confounded by any hidden confounder.",
            "However, it's a pretty complex and tough rule, and understanding why this is the case is, well, it took me a while to figure out.",
            "Nevertheless, I will try to give you an intuitive explanation.",
            "So you need 4 variables this time.",
            "Again ZXW&Y and you need different independence, bivariate and conditional independence relations.",
            "First of all, you need Z to be a potential cause of X and potentially cause all this means you have to observe this V structure.",
            "Here, this V structures are crucial.",
            "Building block of inferences in this framework and if this V structure here, then you know that Z is a potential cause of X due to this rule for potential causation two slides back.",
            "Now you need to observe that X&Y are dependent and Z&Y are dependent.",
            "And Furthermore, you need to observe that if you now condition on X, if you now know what happens at X that, then this dependence between Z&W needs to vanish.",
            "And if this is the case, which is rather complex condition, then you can infer that X is a genuine cause of Y, and that there can be no hidden confounder between X&Y.",
            "And the reason why this works is that X blocks all information that can flow from Z to Y.",
            "And if there would be hidden confounder present here in between, then X would not be able to block this path from Z to Y.",
            "And the proof of that is quite illuminating and very exciting.",
            "But it's rather complex, yes.",
            "What does it mean?",
            "The end condition between the two?",
            "This means these are two separate tests that you need to do these.",
            "Here are dependency tests that you need to do on your data.",
            "Bivariate Lee.",
            "You need to check the Z&Y are by variety dependent.",
            "You should check that X&Y are by very dependent and Xion ex need to be by very dependent, but then you again need to check whether Z&Y are not independent anymore when you condition on X.",
            "So just simply means it's additional tests that you have to perform and the shading here means now condition on X and then test for bivariate dependence between these like condition of X.",
            "You mean you can in.",
            "Sex or no buy conditioner.",
            "So the definition of independence that you take the joint distribution of X&Y and can factor it into its marginals.",
            "So if U of X and Y = P of X * P of Y, the two are independent.",
            "Do we have a board here?",
            "We can write this.",
            "OK, unconditional means P of X&Y, given Z, needs to factorize as P of X given Z * P of Y given Z.",
            "It's it's it's.",
            "If you have the joint distributions and you can write them down then it's easy to check.",
            "Doing this empirically is very, very hard and I will get to that in a minute.",
            "Essentially, it means that you need to build some regression algorithms and you need to regress from.",
            "You need to use X to regress out all information from Z&Y that they could contain about X, and then you need to check whether they are dependent anymore and maybe dependence and correlation.",
            "Maybe I should say what about that dependence is stronger than correlation, so correlation is linear dependence and if you find.",
            "Ann to various to be correlated, then they are also dependent, but if you find 2 variables to be uncorrelated, it doesn't mean that they are independent.",
            "So independence is like a nonlinear concept by correlations and linear concept.",
            "Yes.",
            "Yes, you need W to make sure that these are potential cause of X.",
            "You need to have this study to make sure that X is actually not a potential cause of Z the other way round, because then this rule doesn't work.",
            "OK, any further questions about this?",
            "OK, so these are the three rules that form the backbone of causal inference.",
            "In conservation networks."
        ],
        [
            "And now what you can do with that is you can easily predict the effect of interventions, and This is why one more reason why I like these cause abrasion networks that much.",
            "So we assume that we are given a causal structure, a directed acyclic graph, a deck like this one here.",
            "And it's joint distribution.",
            "This is assuming quite a bit, so this joint distribution has to be estimated, usually from finite data.",
            "That's hard, but let's assume we have it.",
            "And this causes structure that has to be inferred from the strong distribution.",
            "It's also hard, but let's assume that we have it.",
            "And then what we would like to do is we would now like to predict the effect of experimentally controlling Z of intervening on on X.",
            "For instance, X could be newer process and you want to stimulate it."
        ],
        [
            "And the way to do this is to take this joint distribution and factorize it according to its tag."
        ],
        [
            "So that works as follows.",
            "You take the joint distribution in start with a W here and W only depends on Z.",
            "So right P of W given Z only because WS only influence busy.",
            "Then you start with a Z.",
            "That's the next.",
            "And P of Z is influenced by X&YOP of Z is.",
            "Conditional on X&Y&X&Y are not influenced by any other variables, so you simply write P of X&P of Y.",
            "This factorization of this joint distribution according to its causes structure."
        ],
        [
            "And now you compute the so called interventional distribution and Judea Pearl intra."
        ],
        [
            "Use this whole quote Doom caculus for this, so he writes it as follows.",
            "This joint distribution given do of X = X~ and that means not just to observe that X has been external, but to experimentally intervene and fix the value of X at this value X to do.",
            "And to get from this observation and distribution to this intervention of distribution is rather simple.",
            "You simply take a look at where the X turns up here, which is there and there.",
            "And this P of X does not vanish is this is set to 1 because it's not a random variable anymore.",
            "You have set it to a value, it's determined so.",
            "No randomness anymore this years one.",
            "And here's the given X.",
            "You now have given X~ because this is the value that you set it to.",
            "Now you get this new distribution here.",
            "This intervention of distribution.",
            "Off those variables, if you have intervened on X.",
            "And now."
        ],
        [
            "You might say, OK, I'm now interested in what the distribution of W is after I have set X to this one specific value."
        ],
        [
            "And once you do this, you simply marginalized out those variables you're not interested in.",
            "In this case, Y&Z.",
            "By integrating this out.",
            "And then you obtain this distribution of data you under this intervention, and this is really so interesting, because now you can easily ask the question if I have a certain set of interventions that I can do and I have a certain goal of my system, how it should behave, what intervention that I can do is most likely to give me the goal that I want.",
            "So how can I intervene on the system to make it behave in the way that I wanted to behave?",
            "And in the example that I gave in the beginning, this means we want to know how and where to stimulate in the brain to turn poor stroke rehabilitators into good stroke regulators."
        ],
        [
            "OK, now this sounds awesome, but of course there's a catch there smaller than one catch as there always is and the first kitchen 'cause the major networks is this assumption of faithfulness.",
            "And that is really integral to all inferences in this framework, and faithfulness describes the notion of the assumption that all observed independence is or conditional independences are structural.",
            "And to explain what that means."
        ],
        [
            "I have a simple example, so let us assume again.",
            "We have three variables XY and Z and that we have this complete deck where there is a link between every node.",
            "Now let us assume that there's a very simple functional model underneath this that all relations are linear, so that X is simply some noise variable.",
            "UXY is a function of linear function of X&Z plus some noise variable, and Z is a linear function of X plus some noise verb, and we assume these noise variables to independent of one another.",
            "Then in general, what we observe is this dependency structure.",
            "Everything is going to be dependent on everything else.",
            "However, you can choose the parameters here."
        ],
        [
            "Such that this dependency vanishes.",
            "If you choose this very parameter, A is minus BC.",
            "Then why is all of a sudden only influenced by Z anymore and not by X?",
            "And that is because the influence of X on Y via this path has been exactly cancelled by the influence via this path.",
            "Yes.",
            "Position applies, yes you can't.",
            "Yeah.",
            "So how can you say that?",
            "Why is like a X + B set?",
            "Plus you why it's proposition?",
            "It's linear system.",
            "Yeah, it's just an example, it's just an example right now to illustrate what can happen.",
            "And faithfulness the assumption of faithfulness does not apply now, so it's just let's just assume that that this is the case in some data that we observe.",
            "So."
        ],
        [
            "In general, you observe this dependence structure.",
            "If you observe that you cannot make any inferences at all, but."
        ],
        [
            "If the parameters are chosen a very particular way, then this dependency vanish is and then you all of a sudden have a dependency structure where your potential causation rule tells you not cool X is.",
            "And why are potential causes of Z?",
            "And that of course would be an incorrect inference.",
            "And the reason why you would make this incorrect inference is that.",
            "Well, this parametrization hides a dependence from you, that is structural and faithfulness, as if there is a structural dependence of causal relation.",
            "Then you will also see it in your data.",
            "Nature will not hide this dependency from you by choosing is very specific parameterization of the process.",
            "No.",
            "And now the question is, is this a strong assumption or is this a reasonable assumption?",
            "Unfortunately, there's a reason."
        ],
        [
            "By Christopher meek.",
            "Published at UI in 1995 that says that for any given causes structure deck the unfaithful distributions have measure 0 in the space of all distributions that can be generated by the deck.",
            "So to explain this a little bit more in detail.",
            "You take a deck and there can be many joint distributions that this deck can generate.",
            "And now you look at which distributions that this deck can generate are faithful and which ones are not faithful.",
            "And it turns out that the unfaithful distributions the deck and generate has measure 0.",
            "Meaning if you randomly pick a graph and randomly let it generate some joint distribution, you have, it's extremely unlikely that you will observe an unfaithful distribution.",
            "And this is being used to reason that, well, it's unlikely that you will ever encounter an unfaithful distribution in practice.",
            "However, this is based on the additional assumption that nature has no reason to favor unfaithful distributions.",
            "It might be that for some reason it is efficient to generate an unfaithful distribution by nature, if nature decides to fool you, there's nothing you can do.",
            "So this is the strongest assumption that enters here, yes.",
            "If you have noise, is this still possible?",
            "Sir, I'm not sure.",
            "Yeah yeah, the cool thing about this is that you're basing all your influences on your joint distributions and how U joint distributions have been generated with.",
            "It's a linear process and nonlinear process.",
            "What noise there is.",
            "Or that there is any?",
            "What distribution the noise has it?",
            "All, it doesn't matter.",
            "It's all nonparametric because all inferences are based on these independence tests.",
            "You don't make any modeling assumptions, so in general it works for any variables under the assumptions of faithfulness.",
            "Are this constellation OK?",
            "This is possible disconsolation under noise.",
            "Good question.",
            "Probably depends on where the noise and just.",
            "I mean you have noise here in every variable.",
            "This UX UI and you see these are noises and the different noises are assumed to be independent of one another and then this can happen.",
            "So in general, yes.",
            "But what happens if you have measurement noise?",
            "Yes, I think it can happen.",
            "Yeah, yeah.",
            "No, because this this parametrization hides this dependency from you and you won't get that dependence back because the add noise on top of it.",
            "So yeah, I think it can happen with noise.",
            "OK, so this is the fundamental assumptions that you have to make when you work with causation networks.",
            "But there is another catch."
        ],
        [
            "It's great that cause abrasion networks work so well in theory, but in practice it's much, much harder.",
            "And that is because of these conditional independence tests.",
            "So far we have assumed that we have the joint distribution and then you can simply write it down and check whether things are dependent or not.",
            "That's easy, but in practice you have to do these conditional independence tests on finite data."
        ],
        [
            "That's really, really tough."
        ],
        [
            "Aunt Uncorrelatedness does not imply independence, so you could check for Uncorrelatedness.",
            "Assume everything is linear and then would get a lot easier, and indeed there is that at heart algorithm developer Peters purchase at CMU in this collaborators that you can download off the web and that is based on linear models.",
            "But just uncorrelatedness doesn't imply independence, and hence you cannot make this inference is just from uncorrelatedness.",
            "So you really need non linear in it."
        ],
        [
            "These tests and they are difficult.",
            "But I always use the one that has been developed by Arthur Gretton at the MPI into being called the H Stick test.",
            "Which is a nonparametric kernel based independence test and I find that to work pretty well.",
            "That's the one that I use.",
            "However, that only works as long as you're interested in a potential causation in spurious causation.",
            "If you want to move on to testing for genuine causation, you need these conditional independence tests."
        ],
        [
            "And conditionally independent tests are even harder, and the best method that I know so far for that is by Quinn Sung who supposed toknow actually now group leader at the MPI into being published UI in 2012.",
            "So in practice, these tests are very, very hard.",
            "And there's one conceptual problem.",
            "And that is really quite severe."
        ],
        [
            "Not finding a dependence is not evidence for independence.",
            "No.",
            "So you need to make these inferences from independence.",
            "You need to check your variables and you need to say haha.",
            "These two are independent.",
            "Hence I can make an inference from that.",
            "But not finding a dependence is not evidence for independence.",
            "If you look at 1000 crows and none of them is white, you cannot conclude that there are no white cross growth.",
            "So you have to make this assumption that.",
            "Your data is rich enough and your algorithms are powerful enough that you would have found a dependence if there were one.",
            "And of course, it could always be that if you had used a more powerful algorithm that if you had observed more data, you would find independence and then this would invalidate your inferences.",
            "So this is a big conceptual problem.",
            "You can't really give evidence for this, but then again, this is pretty much the same way that we do usual inferences in.",
            "I don't know if my analysis or hypothesis testing.",
            "If you have a usual hypothesis you test, you know hypothesis and you reject your null hypothesis that you have evidenced against it, but evidenced against the null hypothesis is not evidence for its negation.",
            "And this is kind of the same problem, just the other way around.",
            "Yeah, and this is a severe limitation.",
            "Good."
        ],
        [
            "Then in a case study on conservation networks, and this is now my own work so.",
            "When working on PC's or a few years ago, let's work on sensorimotor Rhythm, brain computer interfaces, and was very interested in explaining why some subjects are good performers, and why some subjects are poor performance in Bcis.",
            "And and.",
            "Interestingly, I found that that subjects are not per say, good or poor performance, but they are sometimes good and sometimes poor and I wanted to understand this variation.",
            "And so we try to predict the performance of our subjects from neuro segments in different frequency ranges and what we actually found is that distributed, range oscillations correlated with how well our subjects could operate in PCI.",
            "And from the."
        ],
        [
            "We formed the hypothesis that the causal graph in our data was like this, that we gave our PR subjects instructions whether to perform left or right hand motor imagery.",
            "And we observe that this instruction to perform left or right and motor imagery led to a modulation of the sensory motor rhythm.",
            "So there's some reason become became more lateralized for the one versus the other condition.",
            "And Interestingly, we found that this gamma power here.",
            "They told us many let us predict how lateralized, the sensorimotor rhythm would be, and so we formulated this hypothesis that these gamma range oscillations are potential cause of this sensory motor rhythms."
        ],
        [
            "And then we tested that and our data with this nonlinear H Stick test.",
            "And we found that one instruction what type of motor imagery to perform in the sensory motor rhythm was highly correlated.",
            "The P value for rejecting independence was 1 * 10 to the power minus 4.",
            "Also we found gamma power and the sensorimotor rhythm to be highly correlated with the P value.",
            "For rejecting that was 2 * 10 to the power minus four.",
            "But interesting with this non linear independence test, we didn't find any evidence for dependence of this instruction.",
            "What type of motor imagery to perform and gamma power that we observed?",
            "And now, because we didn't find any dependence, we said, OK, we're now going to interpret this as evidence for independence, even though we know that this is a bit quirky.",
            "And then we can invoke the rule for potential causation and argue that indeed gamma power is a potential cause of the sensorimotor rhythm.",
            "And this was really interesting to us because we then start OK.",
            "Probably there's some attentional processes that generate these gamma oscillations that have an effect on those processes that generate our sensory motor rhythm.",
            "But of course this is only potential causation.",
            "We didn't invoke the roofer genuine causation, so there might be hidden confounders."
        ],
        [
            "Fortunately, in our setup, we could say a bit more because this instruction here that could only be a cause of other observations because we gave it to the subjects.",
            "This is what we randomized and hence we could make a bit more strong inferences and say there has to be some neural substrate potentially of attention.",
            "That generates are, stellations.",
            "And some new substrate that generates all motor imagery signals or sensory motor rhythm and our data tells us that there has to be causal link from this substrate to the motor imagery substrate and that link cannot be the other way around, because then we would have expected to find independence between the instruction and gamma power via this link, which we didn't find.",
            "Yes.",
            "OK, in the simplest case, train the support vector machine.",
            "Of course, yes.",
            "Always forget that.",
            "Or maybe you give me that and I will give it yeah.",
            "I just I just don't get what do you mean between with dependency between instruction and gamma power like?",
            "Maybe a step backward and try to explain the setup because I don't.",
            "So we checked dependence between instruction and SMR and instruction gamma power in two different ways.",
            "The dependence of the instruction that we gave to the subjects and SMR.",
            "We simply did both support vector machine we try to decode from the sensory motor rhythm what the instruction was that we gave to the subject minus one for left hand motor imagery in plus one for motor imagery.",
            "And we saw that with the support vector machine we could predict that and we could reject the null hypothesis of chance level performance and hence we said that we have something to do with one another.",
            "They are dependent.",
            "Now for this, installations it was a bit more tricky because we also try to use a support vector machine.",
            "To predict the instruction, the type of instruction from gamma power.",
            "So we couldn't with it, so we used a nonlinear support vector machine.",
            "This H stick tests and we still couldn't do that.",
            "And then we looked at the relation of SMR and gamma power and try to find independence there.",
            "So we tried to predict the SMR from gamma power and with the linear methods we didn't manage to do that, but with nonlinear methods we actually did.",
            "We notice that gamma power predicted not the side of the SMR literalization, but the extent of it.",
            "The absolute value of it.",
            "So we found this nonlinear dependence between the two, and that's the basis of these tests.",
            "How strong or someone depends highly.",
            "Thank you highly, highly subject very some subjects had extremely strong dependence.",
            "Also for low gamma power they want chance level for high gamma power they were at 95% decoding accuracy.",
            "For other subjects we didn't find any dependence at all, so was highly very high intrasubject variance.",
            "OK, so this concludes the part on the."
        ],
        [
            "Observation networks so let me square them according to my own beliefs I."
        ],
        [
            "Cause of Asian networks are probably correct and unreasonable assumptions, and that's what I really, really like about them."
        ],
        [
            "They also make testable interventions and they have a well developed framework for making these testable interventions, which is great."
        ],
        [
            "They can deal with hidden confounders and this is amazing.",
            "The only the only framework that I know that I'm not really reasonable assumptions can deal with in conformers.",
            "Bye."
        ],
        [
            "Empirical performance is a nightmare.",
            "These conditional independence tests are really, really hard, but people are working on that very, very.",
            "Intelligence statisticians are working on that, so I'm hopeful that these tests will improve and make these conservation networks more applicable in the future.",
            "So any questions about conservation networks before we move on two dynamic causal modeling?"
        ],
        [
            "So dynamic causal modeling.",
            "My disclaimer again, I was very interested in that in the beginning I organized a few.",
            "Workshops on that I went to visit car, for instance lab who developed that I had a small collaboration with one of his methods guys.",
            "But the more I learned about it, the less I liked it.",
            "So it's a bit of a biased view.",
            "I hope you will forgive."
        ],
        [
            "So to start with, in dynamic causal modeling is interesting to us, and what is the concept of causality behind dynamic causal modeling and colorist?",
            "And who is it?",
            "In London wrote in one of these papers, causality in TCM is used in a control theory sense and means that under the model activity in one brain area causes dynamics in another and that these dynamics caused the observations.",
            "Now I don't like definitions that include the term.",
            "That is to be defined.",
            "Causality is when a causes B.",
            "That doesn't tell me much.",
            "And I actually did my PhD in control theory.",
            "I think I know what kind means, but I've never ever heard a control theory guy speak of causality.",
            "Yeah, so let me try to illustrate what I."
        ],
        [
            "Think he means and this is straight, but the general inference procedure.",
            "But this is going to be very high."
        ],
        [
            "Level.",
            "So first of all, we observe an N dimensional time series X of T. 40 time points and this might be both signals recorded by for my, but this might also be easy signals, so dynamic causal modeling has been first developed for fMRI data, but has been extended to e.g imaging and so on."
        ],
        [
            "And then we define a set of models M. In different models, where each model consists of a set of differential equations with a different connectivity structure, so you have very detailed models.",
            "And how your data has been generated.",
            "And each model consists of a set of differential equations so that dynamic system and there are certain connectivities between the variables in your system, how they are allowed to interact, and how they are not allowed to interact.",
            "And Friston and his collaborators say it is very important that these models are plausable.",
            "You have to only include plausible models in there, whatever that means possible from your prior knowledge."
        ],
        [
            "And then you fit each model to the data, which is tough is really really a tough machine learning problem, but I won't go into that for now.",
            "It's implemented in this toolbox SPM."
        ],
        [
            "And then you compare these models and how well they fit your data.",
            "Where they explain your data.",
            "And of course you have some ways to make sure that you're not overfitting that's in there, and then you take the connectivity of the model with the best data fit as the true causes structure.",
            "So you compare all your models or where they explain your data.",
            "And you said in the beginning, or your models are plausable anyhow.",
            "And then the model that explains to date and the best way.",
            "Making sure that it's not overly complex, that is the one that gives you the connectivity structure and thus the causal structure between your variables.",
            "That is the true one.",
            "And these models underneath that they are rather complex and I want to spend a few minutes on explaining these models."
        ],
        [
            "So the first part of this model is the hemodynamic model, also called the balloon model, and this model tells you how neural activity translates into your boat signal.",
            "So this block is simply input is neuro in their input Z.",
            "And then there's this nonlinear function.",
            "This system here and that gives you an output why that is your hemodynamic response and people have spent a lot of time developing this model, and I think it's the most advanced model for modeling board responses, and it has here some activity pendant 1st order differential equation.",
            "Then this is being integrated again to compute the flow induction.",
            "Then you have changes in volume.",
            "This differential equation changes in HB, the hemodynamic signal and all of this is combined and this really complex way to form this chemo dynamic response.",
            "And now this is your kind of observation model on your activity translates into your boat signal, but underneath that is the dynamic system that describes how you're different neural."
        ],
        [
            "Processes interact.",
            "And this is one of the plots from from call it's original publication.",
            "So you have a set of stimuli.",
            "Any set of context variables?",
            "And for each region in the brain that you want to consider, you have one differential equation.",
            "So Z1Z2Z3C4C5 means you're looking at 5 different regions in the brain, and the neural dynamics in each of these regions.",
            "I assume to be governed by these differential equations here.",
            "And these differential equations.",
            "Are driven by.",
            "The activity in other regions and these arrows here they define your connectivity structure and also that here you have this link from Z1 to Z2 means that in the differential equation of Z2 you have one term that includes the one.",
            "This defines your connectivity structure and now will you observe your data, you have your stimuli give you context for your data you have.",
            "You assumed connectivity structure that gives you the neural dynamics in each brain region and then you have your hemodynamic model.",
            "That tells you how the Neurodynamics actually map in the fMRI signal that you observe.",
            "Yes.",
            "For example, for the block on the bottom, A323 is a function of the derivation of Z3 I assume, or 8th.",
            "One, yeah, that means that the two is a function of the three, and you have this Z3 included in here as a function.",
            "Yeah yeah, all I see here many algebraic algebraic loops basically so.",
            "I and everything is working in the first level derivation, so there's no integration in between.",
            "Is there an order for calculating or well, these?",
            "These are all first order differential equations, right?",
            "And of course if when you want to fit them to your data you have to integrate them.",
            "You have to have your numerical solvers, and doing that is really really tough and I think it's called variational inference and I think class can tell you more about that than I can.",
            "It's a very, very hard problem, and SPM solves it for you an sceptical whether it solves it in an optimal fashion.",
            "So organized Nips Workshop where there was a guy from Kathryn slept who presented all this stuff and it was very proud that I got really good machine learners there into my workshop I had Chris Williams and bad from cotton and.",
            "They explained the guy this is being recorded right.",
            "They explained the guy from Karsten slap that his algorithms only converge to local minima.",
            "Yeah anyhow, but yes one more question back there.",
            "So this set of models.",
            "I, I guess you're suggesting they are not minimal.",
            "Is that what you're saying?",
            "I'm saying that what is not minimum.",
            "These models in the set of models.",
            "You mean with minimal there?",
            "No, no, I mean too complex too for the for the data that you have.",
            "Whether the models are too complex for the data.",
            "Hard to say, I don't really.",
            "I'm not really sure whether I understood the question completely.",
            "Try to continue how these different models are compared and you ask the question again if it hasn't become clear, maybe it will become clear in the next slide.",
            "Alcohol, can you reformulate your question?",
            "That is what you're saying is that you don't have enough evidence to really decide?",
            "OK, no, not necessarily.",
            "The reasons why why it appears that if you fit these models to your data, that's really tough problem.",
            "That depends on many assumptions and whether you end up in your global minimum or not is a difficult problem.",
            "But apart from that, there's also the question that I will get to in a second is how realistic these models are.",
            "But for now I would like just like you to accept that this is a very good model of how neural dynamics work and how fMRI signals are being generated, because this is more less the underlying assumption of these of these methods and the important thing is that that any set of models that you want to compare, so you have the set of models.",
            "Here any set of models is one such model with one connectivity structure.",
            "Yeah, and now if you want to compare different models."
        ],
        [
            "What you do is very high level speaking.",
            "You take a look at which regions in your brain and your vote response are relevant for your task.",
            "Maybe he was prior knowledge to determine that, and then for each of these regions that you believe are relevant."
        ],
        [
            "You use one of these differential equations.",
            "Yeah, yes we should.",
            "Just to get it straight before you continue on the slide before you show."
        ],
        [
            "It's a possible hemodynamic model, yes, and it reappears in several."
        ],
        [
            "Points in the next slide, yes, so when you talk about the set of models that you check for how they fit the data, would that be the combination of that graph here, including those sub models of hemodynamic accuracy, or just the hemodynamic activity?",
            "Or just know it includes the set of both?",
            "OK, so for each region here you place one differential equation here that models uneral dynamics plus one equation that models or the one system that models.",
            "How are these newer dynamics?",
            "Translate"
        ],
        [
            "To the boat signal that you actually see.",
            "Yeah.",
            "There's a lot to optimize.",
            "Yes, and now let us assume that for this given setup, we only have two models that we consider plausable usually have more, but let us assume they are just two.",
            "Let us assume that we want to compare these two models.",
            "Which are identical in the connectivity structure here.",
            "But in this model you want to test whether prefrontal, precuneus modulate sensory motor cortex and here you want to test whether the motor cortex actually modulates prefrontal importunes.",
            "These are the two models that you want to compare.",
            "Then you put these hemodynamics and these newer dynamics models.",
            "Into your areas.",
            "Here you fit the data that you observed in your program to this model you fit into that model.",
            "You compare how well they fit, and then you decide that the true model is the one that has the better fit.",
            "Yeah, this is the general inference procedure."
        ],
        [
            "So and now my main problem is here, and I think that's a very conceptual problem and this has been very nice."
        ],
        [
            "Addressed.",
            "In a paper by Gabriella Lumen recently, which has triggered a lot of controversy so.",
            "If M does not contain the true model.",
            "Which I think is unreasonable to assume the relevant question to me is is the best fitting model in M similar to the true one in terms of its connectivity structure?",
            "And this is really important issue.",
            "This set M contains some models.",
            "That you test doesn't contain the true model.",
            "I would say no, certainly not.",
            "So first of all, you don't know whether the true model is contained with the true model in terms of the connectivity structure, but it goes even further.",
            "The true model is really the model that exactly models to hemodynamics and your neural dynamics perfectly entails exactly how everything works.",
            "We are working with models, and models are only approximations of reality, so there's no way that we can assume that in this set of models we actually have the true data generating process.",
            "In there we can at best hope that we have a good approximation of it.",
            "Yeah.",
            "And then the question is if we don't have the true model in here but only good approximations of it.",
            "Does best model fit translate into similarity in connectivity structure?",
            "Yeah, this is a really tough question.",
            "This is not an obvious question.",
            "Just because the model explains your data reasonably well doesn't mean that the connectivity structure of that model is similar to the true connectivity structure that you can't observe.",
            "And this is some."
        ],
        [
            "Thing that guaranteed Alumin investigated in a paper published in your image in 2012.",
            "Yeah, can you go back to?"
        ],
        [
            "So so.",
            "From in your brackets it says, which would be unreasonable to assume, but which would not be unreasonable to assume is what you wanted.",
            "Say oh thank you.",
            "Yes, that's a typo.",
            "Thank you so much.",
            "Yeah, yes, of course this doesn't match which would not be unreasonable to assume.",
            "Thank you very much.",
            "Yeah, good."
        ],
        [
            "So, and this is not the paper back up little woman account little man was at the MPI Elastic and recently joined us into being so this is again a disclaimer here.",
            "I'm collaborating with her so I'm a bit confounded.",
            "Yes, and there's a big controversy.",
            "Neuroimage going on about this, and it's very fun to read, especially cards comments.",
            "And what she did is she took some data that had been published years ago with dynamic causal modeling.",
            "And so she said, OK, in this publication.",
            "With this data there were a few models that were plausible that were tested.",
            "Now let me test a lot of unplausible models.",
            "Let me randomly generate connectivity structures and let me test all these connectivity structures for how well they explain the data.",
            "And now I want to see do Unplausible models really explain the data not as well as the one that had been identified as the true causal model in the original publication."
        ],
        [
            "And this is the graph.",
            "This is modesitt.",
            "This is the number of models.",
            "This green one.",
            "That's the model fit of the original model that had been identified as the best fitting model in the original publication and higher values mean higher model fit and every blue dot.",
            "Here these are models that she randomly generated and tests away.",
            "They explained the data and she found that 23% all models here on the right hand side.",
            "Of those models that she randomly generated, explained that that it had better than the one in the original publication.",
            "That's already not good news.",
            "23% of miles that you randomly generate.",
            "Explain your data better than the one that you thought was the true one.",
            "But I think the crucial point is.",
            "Not only that, but you have to look at these models that explain the data better.",
            "And are these models similar in terms of the connectivity structure to the one that was taken to be the true model?",
            "Because if that were the case and all these models, they wouldn't make similar influences on your major connections in the brain.",
            "Great, fine, then you would have some robustness in terms of connectivity structure."
        ],
        [
            "Unfortunately, she didn't find it so similarity in terms of the model fit did not translate into similarity in connectivity structure.",
            "In fact, some of the best models here.",
            "Where models where the stimulus didn't enter the brain or where the visual stimulus did enter the brain, but visual cortex was not connected to the rest of the brain, so they were highly implausible models in there with the connectivity structure that we know to be nonsense by our priority knowledge, and these explained the data better than the model that had been identified in the original publication as the true model.",
            "And so of course the conclusion is."
        ],
        [
            "Well, if the true model is not contained in the set of tested model, TCM is unfortunately rather likely to select a causal structure pretty much at random.",
            "So why should you trust it?",
            "And couldn't there also?",
            "I mean, is there also the issue that that if you fit a model then you you may overfit and and you should rather look at the generalization?",
            "And that could be another inference.",
            "I fully agree with that, and the way that they control model fit or overfitting is by using like the AIC criterion by secret invasion generalizations of that and corriston has long argued.",
            "I don't know whether he still does that.",
            "You shouldn't do cross validation that using all the data and using controlling the complexity of your models with these methods is better than using cross validation.",
            "And he has been criticized a lot for that.",
            "I don't know whether he has changed his.",
            "Used by now, but I also think that it would be very important to check the generalizability of these models, but I haven't seen that yet.",
            "Because then, if this was properly done.",
            "My.",
            "Hope would be that that this solution would not be the same.",
            "Yes, yeah, you would hope that all these models out here would end up over there.",
            "Lucas so I can help but notice that original model probably lies around the median of all.",
            "Does random moles have they looked at why?",
            "I mean, it's looks kind of good.",
            "Not that I know of.",
            "And Furthermore, I think Lumen and I raised the issue that model validation is not done in terms of absolute value, it's just that the models that are that are inserted to the to the TCM procedure are compared amongst each other.",
            "But the model fit is not really looked at.",
            "You know, could you?",
            "You don't, that's how well the model explains the data measured.",
            "I think that's part of the this part of the procedure.",
            "I think they do compute model fit.",
            "I think Gary Lumen has indeed argued that that.",
            "But the way that modified is evaluated in the procedure is not the best way that you could do it, but I think in general it is being evaluated.",
            "At least models are scored according to the Model Fit.",
            "OK. OK, so this is actually a proposed method too.",
            "OK, say that some random model perfectly and perform better than the one that was cleverly fought and put inside the original set of tested models.",
            "But then why not just?",
            "OK, do a similar procedure and then remove from this set than biologically implausible models and then pick up the yeah.",
            "Remaining best one.",
            "Yeah, so the argument there goes.",
            "If DCN cannot reasonably well discriminate between plausable an unplausible models and cannot even rank them WHI, should we believe that it can properly rank plausable models?",
            "At the beginning, you in fact showed that first and asked for only entering possible models into that can you can you expand on that a little bit.",
            "Well.",
            "I think the reason for that is that of course in theory you would like to test all possible models that there are, but that's a combinatorial explosion and presently difficult to handle.",
            "Maybe it can be handled in the future, and so initially firstness colleagues have.",
            "I've argued that he should only enter the few models that you think to be plausable.",
            "Anyhow, to reduce the computational load.",
            "But I think they are extending these.",
            "Methods to search bigger spaces of models.",
            "My question is just regarding whether this.",
            "In Lomas paper this is the best plausable model.",
            "Actually the one that was chosen and the other 23% were all implausible.",
            "The war also plausible once they were also plausibly once among them, yes, but they were also very implausible ones.",
            "OK, so let me move on."
        ],
        [
            "So I think ECM."
        ],
        [
            "Is not provably correct under reasonable assumptions, sorry."
        ],
        [
            "No, I don't see how it makes Testament inventions.",
            "I mean, in general you could try to fit around with these nonlinear differential equations or bilinear differential equations and test how you would have to intervene to make the system behave in a certain way.",
            "But that's again a really tough inference problems.",
            "It's not straightforward, probably can be done, but it's not easy so.",
            "I don't like that."
        ],
        [
            "Hidden confounders never seen that addressed in this framework empirical performance."
        ],
        [
            "Well, from the luminosity would say no.",
            "Sorry no way."
        ],
        [
            "OK, nonlinear caution, acyclic models and this is going to be rather brief and this is more recent work done at the Max Planck Institute."
        ],
        [
            "So you have two datasets.",
            "Actually.",
            "It's the same data set, it's exactly the same data here, and here is just flipped.",
            "The X axis is now here and the Y axis is now there and this data has been fitted with a nonlinear curve.",
            "Now I want you to guess which is the cause of direction.",
            "Here X generates Y and here Y generates X.",
            "And what do you think which direction is the true cause of one?",
            "And can you even come up with some intuition why that might be the case?",
            "It's tough.",
            "OK, so the reason why didn't you say in the Bayesian network case that you need more than two variables?",
            "Yes, in conservation networks you do that, but if you're willing to make additional assumptions you don't.",
            "And Dominic dancing and Patrick Oyer who were the guys who were most responsible for this, they introduced additional assumptions that they think are reasonable, under which you can look at the bivariate case.",
            "And this is one of their examples.",
            "Yes, yeah.",
            "So in a sense, I would assume that there's not only X&Y, but there's also noise added to something, so we probably have to look at the spread of the execution in some way.",
            "The point is, you look at the noise, but we couldn't figure out whether it's left or the right now, so the idea is that you look at the residual CMU try to fit a nonlinear curve that explains, as we say, right because it just to say something.",
            "Thank you close.",
            "You look at the noise, the residuals and the idea is that here the residuals are largely independent of X.",
            "The noise here is more or less the same no matter which X you look at.",
            "Of course, you observe less and it's here, but here the noise depends on the value here, so here the noise seems to be.",
            "The residuals seem to be be depend on your X and here they not depend on the accent.",
            "Here they do."
        ],
        [
            "And in fact, this is this data from shell from shellfish, and this is the age of the fish and this is its length.",
            "Of course, by a priori knowledge is reasonable to say OK, the age causes the length and not the other way round, so this would be the true cause of direction or not that one."
        ],
        [
            "This can be formalized a bit, so let us assume that the relation between Y&X is some nonlinear function that X generates Y through some nonlinear function, and then we have some additive noise and and this is the crucial assumption.",
            "Here we have additive noise and this noise is to assume to be independent of X and it's just edit on top, doesn't tell us anything about X.",
            "And all the question that that Patrick and Dominic and balance on asked is, can you invert this model?",
            "Can you take the same?"
        ],
        [
            "Joint distribution, but right this model the other very Rhonda's X being oops X being an only a function of why this would be why?",
            "Sorry?",
            "Plus some noise variable.",
            "And if you do that can you still find LG such that X and sorry Y and enter our independent?",
            "So we assume that in the generative model there's independent noise.",
            "Edit On top of it.",
            "Now if you model the other way round, can you still do that with independent noise?",
            "Or does the noise have to be dependent?",
            "And that would be this thing here.",
            "Here the noise is largely independent of the value on the X axis.",
            "Here the variance of the noise varies as a function on the X axis.",
            "That's the assumption that you put in and there."
        ],
        [
            "Result is in generally no, you can't write it the other way round.",
            "If there is here independence and is independent of X, then if N is if everything is caution and F is linear, then you can write it the other way round and they even some very obscure cases where you can also write it the other way around.",
            "For more complex cases.",
            "But in general it's not possible.",
            "It's very unlikely to be possible and this is their inference procedure."
        ],
        [
            "So what they do is they observe N samples of two variables X&Y."
        ],
        [
            "And then they perform a non linear regression from X to Y and they test whether the residuals of this regression.",
            "Are independent of the regressor."
        ],
        [
            "And then they do it the other way round.",
            "Perform nonaggression from Y to X, and again test for independence of the residuals and the explanatory variable."
        ],
        [
            "And if they find that these residuals between Y&X are independent, they decide that X causes Y."
        ],
        [
            "If they find it the other way round, they decide that Y causes."
        ],
        [
            "And if they don't have enough evidence for one or the other, they decide that we don't really know.",
            "And this is very simple inference procedure and they have collected lots of datasets where we know the causal relation are priority.",
            "For example, they collect data from the River Rhine and the water levels of the Rhine and they know from the flow of the Rhine that water levels in Switzerland cause water levels in Germany and so on.",
            "And they collected lots of datasets like that and tested how work performed and it was not too bad I think.",
            "Also like 68% or so.",
            "So it seems to be a reasonable assumption that doesn't always hold, of course, but that allows you to do some causal inference between bivariate variables.",
            "Can you, can you?",
            "You know 'cause this is it custom to a testing framework?",
            "I don't recall this paper because you you should also.",
            "So what are the conditions not to accept either one?",
            "That's yeah, this is of course, there's of course very variable.",
            "Where do you choose?",
            "You cut off and in the end in the paper that NIPS 2008, they again used H62.",
            "Actually kind of based on linear regression.",
            "And then they tested the residuals with IHC test and looked at which residuals for more independent than the other in the one way or the other way.",
            "And if they didn't find a big difference, they didn't decide if they found a big difference data.",
            "They decided for one cause of direction.",
            "Now.",
            "OK."
        ],
        [
            "So non lingam proof be correct in a reason."
        ],
        [
            "Assumptions in arm.",
            "I don't know whether I should have put a green mark there.",
            "It is probably correct and assumptions, but whether they are reasonable or not to have this additive noise models OK, there's a big question."
        ],
        [
            "Test interventions, yes.",
            "They give you tested interventions.",
            "They tell you with this nonlinear regression what exactly you have to do."
        ],
        [
            "I haven't spoken about hidden confounders, but they have continued working on that, so there are methods in this framework to take care of hidden confounders.",
            "OK, so the last thing that in each address is empirically performance, of course improved."
        ],
        [
            "Performance is really tough because we don't have ground truth data sets in your imaging."
        ],
        [
            "But there is a great study by Steve Smith at Oxford that he published in 2011 in your image and what he did there.",
            "Is he used these dynamic causal modeling models.",
            "This differential equation systems.",
            "To generate lot of simulated data, because these models asked her the best models that we have for my data and he had 28 different simulations.",
            "Lots of different parameters and lots of different lengths of data recording.",
            "And then you tested a variety of causal inference methods where they performed.",
            "If you have the direct transfer function Lingam, that's the linear version of this non linium.",
            "That address presented partial directed coherence.",
            "This is a variant of DTF base Nets.",
            "That's the conservation networks Granger causality.",
            "And generalized synchrony patterns tower two measures that are more heuristics that people proposed.",
            "And I'm showing this graph for one reason a.",
            "And all of the algorithms performed really well.",
            "Pretty much they're all pretty bad.",
            "50% would be absolute chance level.",
            "This Gray line means above chance level and only a few algorithms are above chance level.",
            "So if you believe that this dynamic causal models are a good approximation of reality.",
            "And then you apply a different inference algorithms to that you won't do very well.",
            "But, and this is also something important.",
            "There are some methods that perform above chance level that's already something.",
            "I mean 'cause it interest such a hard task and it will be unreasonable to assume that you always get the correct result.",
            "But you have algorithms that can perform above chance level is already quite something is really quite amazing.",
            "So this brings me to my so.",
            "First of all just one question.",
            "So on the left this is the method you didn't.",
            "This is heuristic, so through your graph it says the heuristics best.",
            "Yes indeed it supported stores, I think published in 2008 in human brain mapping and it's really just a heuristic, but it seems to work well.",
            "I don't understand it why so I didn't talk about it here, but it's an interesting paper."
        ],
        [
            "Anne, OK."
        ],
        [
            "I think an Imperial terms of empirical performance and none of the algorithms works reliably, but some work above chance level and this."
        ],
        [
            "Some important consequences for when calls that infants should be used and when it should not be used."
        ],
        [
            "So first of all, every causal inference algorithm rests on untestable assumptions.",
            "You have to decide whether you're willing to accept these assumptions or not, and please be open about these assumptions.",
            "That's something that's important to me.",
            "And I want to illustrate why I had a chat with a neurosurgeon sometime ago and this neurosurgeon told me, oh I had this.",
            "I have this patient and I read about this paper on Granger causality and they showed that there is a causal relation between brain areas A&B and I think that's relevant for this patient.",
            "I will now implant an electrode in this patient and stimulate him with a deep brain stimulation chronically implant and was like, oh, you know that Granger causality is not that reliable and that you assuming that there are no hidden confounders.",
            "So be careful.",
            "Was like no, I'm not interested in mathematical details.",
            "I'm interested in the practicality of this.",
            "And we'll say, yeah, but you know your assumptions.",
            "They are practically relevant.",
            "But he didn't care about that.",
            "And I think in neuroscience often people are not careful enough with stating their assumptions.",
            "And if you are writing such a paper, Please remember that you are honest about it, because if you're not honest about it over say, your results, some crazy neurosurgeon may decide to open up the brain of a patient and plug electrodes in because of your paper."
        ],
        [
            "So several causal inference algorithms appear to perform at least above chance level, and this is already quite amazing."
        ],
        [
            "So that for me means cause inference maybe?"
        ],
        [
            "Full to guide the design of interventional studies and there's a wonderful example by group.",
            "From ETA to Zurich, not on your imaging published Nature Methods in 2010, and they worked with plant biologists.",
            "These plant biologists.",
            "They do genetic interventions on their plants and they grow these plants.",
            "This genetically modified plants and observe what effects this genetic interventions had.",
            "But most genetic interventions don't lead to plants that grow.",
            "Most plants die before they flower intends to constitute a better data point.",
            "And this is time consuming and costly and they try to reduce these costs.",
            "They try to predict which genetic interventions would lead to flowering plants that give you a reason.",
            "A good data point.",
            "And they compared normal prediction methods with causal inference.",
            "Methods on could show that by using causal inference methods they could significantly reduce the number of experiments they had to do on average to get one good data point.",
            "And this saves a lot of time and money.",
            "And this is.",
            "This is really reasonable.",
            "This is great because there you have a study where it doesn't matter so much whether one causal inference is correct or not.",
            "If you're in buff chance level, on average, it will help you design your studies."
        ],
        [
            "And I think it's also OK to use causal inference when you qualitative conclusions do not depend on individual results.",
            "If you have 1000 tests that you can do and you qualitative conclusions only depend on being right on average, then I think it's OK.",
            "User info."
        ],
        [
            "But be very careful at present, at least to use causal inference when you qualitative conclusions depend on one individual inference, because most likely you will be correct with the chance of I don't know, 58 percent, 56 percent 61%, so don't trust causal inference too much.",
            "OK, that brings me to the end of the talk.",
            "I have two more slides that are private advertisements.",
            "I hope that's OK for the organ."
        ],
        [
            "First of all, I'm organizing this pattern.",
            "Recognition your image in workshop on my 2014 tubing clouds is actually one of our invited speakers.",
            "We have a great program.",
            "It's from June 4 to 6 and this is a small conference with roughly 100 people.",
            "Great machine learners who knew your image Ng.",
            "So if your machine learning person and or you want to know more about machine learning for neuroimaging, I think this is the place to go.",
            "Submission Deadline is March 7th and it would be great if I would see some of you back into Bingham and also.",
            "And we're currently looking for one year PhD student, so please forgive me for making an advertisement for that.",
            "So in the stroke project we want to find the causal newer processes that are causally relevant for structure abilitation.",
            "We're looking for one year PhD student with a background engineering, computer, science, mathematics.",
            "And was interested in causal inference and neuroscience.",
            "And if you're interested, please to send me an email.",
            "And also all my slides and the references to all papers that I have mentioned today can be downloaded on my homepage and the password for that is BBC 2014.",
            "So thank you very much for your attention.",
            "I'm looking for discussions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thanks a lot to the organizers for inviting me, and of course thanks a lot to all of you coming here this morning, so I got into causal inference roughly six years ago when I went as a poster to the Max Planck Institute in Tubingen.",
                    "label": 0
                },
                {
                    "sent": "And cause inference is a really really complex and tough topic and I think it took me more more less.",
                    "label": 0
                },
                {
                    "sent": "Two years until I felt that I had a decent understanding of this topic.",
                    "label": 0
                },
                {
                    "sent": "So when I started preparing this talk I thought how can I make the most of 1 1/2 hours and give you an introduction to causal inference?",
                    "label": 1
                },
                {
                    "sent": "And I don't think there's much point in giving you the details of all the algorithms because that is just too much to cram into 1 1/2 or two hours.",
                    "label": 0
                },
                {
                    "sent": "So what I try to focus on other high level concepts.",
                    "label": 0
                },
                {
                    "sent": "So my goal is for you to understand why closet inference is interesting.",
                    "label": 0
                },
                {
                    "sent": "What it is all about WHI?",
                    "label": 0
                },
                {
                    "sent": "Is it such an incredibly tough problem and what are the most common ways to tackle it?",
                    "label": 0
                },
                {
                    "sent": "What assumptions are being made on the way, and what consequences does this have for interpreting the data?",
                    "label": 0
                },
                {
                    "sent": "So I hope that in the end of this talk you will have a somewhat an overview of what in causal inferences interests you and what you would like to read more about.",
                    "label": 0
                },
                {
                    "sent": "So to start with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to talk a little bit about why we actually should be interested in causal inference in the 1st place, so it seems to be really hot topic in your image Ng.",
                    "label": 1
                },
                {
                    "sent": "Right now there's lots of papers, lots of algorithms, but I think it's not such a trivial question why it's actually interesting.",
                    "label": 1
                },
                {
                    "sent": "So why do causal models or causal inference?",
                    "label": 0
                },
                {
                    "sent": "Why does that tell us more about how the brain works than non causal models?",
                    "label": 0
                },
                {
                    "sent": "And I want to address this question by first speaking briefly about what we expect off a scientific theory in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "And if you go to the literature and philosophy of science and whatever and you look at what are the conditions, what makes a good theory or scientific theory?",
                    "label": 0
                },
                {
                    "sent": "Good theory, you will usually.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find 2 conditions and the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One is well, but good theory should explain the data that we have already observed.",
                    "label": 1
                },
                {
                    "sent": "If a theory that we have can't even explain what we already know or have already observed, then there's a little point in accepting the theory.",
                    "label": 0
                },
                {
                    "sent": "But that's not enough, and this every good machine learner knows you can easily overfit with theories, so you should also be able to.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use your theory to correctly predict future observations.",
                    "label": 1
                },
                {
                    "sent": "And that's usually it.",
                    "label": 0
                },
                {
                    "sent": "Usually these conditions are the ones that are listed for a good theory and obviously causalities absent from that.",
                    "label": 0
                },
                {
                    "sent": "And I think causality enters when you think a bit more about the second point.",
                    "label": 0
                },
                {
                    "sent": "What it means to correctly predict future observations, and they would like to distinguish between 2 cases.",
                    "label": 0
                },
                {
                    "sent": "The one cases where you try to understand a system.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That you just passively observe.",
                    "label": 0
                },
                {
                    "sent": "You just look at the system how it evolves on its own and you would like to predict what happens on the system if it further evolves on its own.",
                    "label": 0
                },
                {
                    "sent": "And that's one thing, but a different and much more difficult thing is to.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What actually happens to a system if you actively intervene on it when you intervene and do something to the system and you want to predict how the system responds to this intervention?",
                    "label": 0
                },
                {
                    "sent": "And this is where causal inference really enters.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In my understanding.",
                    "label": 0
                },
                {
                    "sent": "The aim of causal inference is to predict how a system reacts to an intervention that you might do to this system, and I would like to give you an example from our my own research group, so we're very interested or becoming very interested in stroke rehabilitation.",
                    "label": 1
                },
                {
                    "sent": "So what we do is we invite stroke patients to come to our lab and we give the motor learning task.",
                    "label": 0
                },
                {
                    "sent": "So for example, reaching in three dimensions to different targets and maybe perturbing their movements.",
                    "label": 0
                },
                {
                    "sent": "And why are they learned this task?",
                    "label": 0
                },
                {
                    "sent": "We measure the EG and then we try to find correlates in these signals.",
                    "label": 0
                },
                {
                    "sent": "E.g signals off the motor learning performance and we expect to see that there are some processes that we can observe in the G that are correlated with how well the stroke patients can learn.",
                    "label": 0
                },
                {
                    "sent": "And that should tell us something about what makes for good rehabilitation for poor stroke reputation.",
                    "label": 0
                },
                {
                    "sent": "But of course it's not enough just to understand how the brain signals of good stroke, rebillot, eighters, and poor stroke rehabilitators look like.",
                    "label": 0
                },
                {
                    "sent": "We would like to be able to actively intervene.",
                    "label": 0
                },
                {
                    "sent": "Would like to be able to stimulate worth, for instance.",
                    "label": 0
                },
                {
                    "sent": "Transcranial alternating current stimulation neural processes in these patients to turn them from poor into good rehabilitators, and for that we need to know not only which process is correlate with good rehabilitation, but we need to know which are the causes of that, and that is one reason why we are very interested in causal inference.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you probably have learned in your classes that correlation does not imply causation, and that you often read, but I think that understanding why this is the case is not that trivial.",
                    "label": 0
                },
                {
                    "sent": "And this is the main reason why causal inference is such a tremendously difficult task.",
                    "label": 1
                },
                {
                    "sent": "So before I go to these algorithms in neuroimaging that are being used there, I want to develop a little bit on the potential outcomes framework, because this is the framework that has been developed in statistics in the 60s and 70s mostly, but on Ruben at Harvard University that really forms the backbone of all.",
                    "label": 0
                },
                {
                    "sent": "This randomized controlled studies that people do nowadays in science, and this is kind of so the.",
                    "label": 0
                },
                {
                    "sent": "The Golden way.",
                    "label": 0
                },
                {
                    "sent": "The best way to do causal inference.",
                    "label": 1
                },
                {
                    "sent": "And if you are very interesting that I highly recommend this paper here by a pool Hall, and I think he's at Princeton.",
                    "label": 0
                },
                {
                    "sent": "Former student of Donald Rubin and the Journal of the American Statistical Association.",
                    "label": 0
                },
                {
                    "sent": "By the way, I in the end I give you a link where you can download all the papers that I talk about.",
                    "label": 0
                },
                {
                    "sent": "So and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is this framework is rather complex, so we first introduced the notation to make it a bit more illustrative.",
                    "label": 0
                },
                {
                    "sent": "Will also list examples of the notation at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we start with the population you set you.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this might be, for instance, a set of patients that come and visit you in a clinic.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in individual individual unit of the set U.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might be an individual patient.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It might be the case that you have a treatment that you could or could not apply to this patient.",
                    "label": 0
                },
                {
                    "sent": "For instance, you have a truck and a placebo treatment and you could assign each patient too.",
                    "label": 0
                },
                {
                    "sent": "The treatment or two?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Placebo treatment so S of you is an assignment that assigns for every patient, whether that patient is going to be treated or other patients going to be assigned to the control group.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you need an outcome variable Y that Maps the unit.",
                    "label": 0
                },
                {
                    "sent": "And a treatment assignment to some real valued number now.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For instance, this might be the survival time of a patient under the certain treatment that you give to that patient.",
                    "label": 0
                },
                {
                    "sent": "To measure the outcome.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and now comes the fundamental problem of course inference.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The effect of a cost T. On you is measured as the difference between Y of you given 50 years assigned or sees assigned.",
                    "label": 1
                },
                {
                    "sent": "This means the survival time of a patient when you given the treatment minus the survivor time.",
                    "label": 0
                },
                {
                    "sent": "A patient when you give him the placebo treatment.",
                    "label": 0
                },
                {
                    "sent": "No, but.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is impossible to observe this on the same unit.",
                    "label": 1
                },
                {
                    "sent": "You cannot assign a patient first to the control to the treatment group.",
                    "label": 0
                },
                {
                    "sent": "Observe how long he survives and then assigned to the placebo group and observe how long it survives.",
                    "label": 0
                },
                {
                    "sent": "So this is impossible.",
                    "label": 1
                },
                {
                    "sent": "And this is called the fundamental problem, of course inference.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, there are several solutions to tackle this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first solution is to assume unit homogeneity and you just simply assume that different units that you have are absolutely identical, and this might be OK in mechanical engineering.",
                    "label": 0
                },
                {
                    "sent": "We can manufacture these units, but if you're working for instance with humans, this is obviously not a reasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "No two patients are ever going to be alive.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second solution is to assume causal transients, so you assume you can first apply the one treatment, observe its effects.",
                    "label": 0
                },
                {
                    "sent": "And then you assume that the patient enters into the original state again, and then you apply the second treatment.",
                    "label": 0
                },
                {
                    "sent": "But again, for patients this is not a reasonable assumption and often impossible if you think about survival times.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the third solution that's the solution that is usually adopted is to say, OK, we can't observe the causal effect on individual units.",
                    "label": 0
                },
                {
                    "sent": "So let's not try to compute in that.",
                    "label": 0
                },
                {
                    "sent": "Let's compute the average causal effect key.",
                    "label": 1
                },
                {
                    "sent": "Let's compute the average of our survival time in this example.",
                    "label": 0
                },
                {
                    "sent": "If patients are treated.",
                    "label": 1
                },
                {
                    "sent": "Minus the expected value of the survival time when patients are assigned to the control group.",
                    "label": 0
                },
                {
                    "sent": "And this is a certainly much easier thing to compute.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, we cannot observe that either.",
                    "label": 0
                },
                {
                    "sent": "Because this expected value here goes over the whole set of patients.",
                    "label": 0
                },
                {
                    "sent": "But we have to assign patients to one or the other group.",
                    "label": 0
                },
                {
                    "sent": "We can only observe this value here.",
                    "label": 1
                },
                {
                    "sent": "The expected value of the survival time under the treatment for those patients who have been assigned to the treatment.",
                    "label": 0
                },
                {
                    "sent": "And that's a different value in general than this one here, yes.",
                    "label": 0
                },
                {
                    "sent": "So this means either T or C. And so the expected survival time under the treatment, given that a patient has the patients have been assigned to treatment or the expected survival time.",
                    "label": 0
                },
                {
                    "sent": "Given that the patients have been for the control group.",
                    "label": 0
                },
                {
                    "sent": "Given that they have been assigned to the control group.",
                    "label": 0
                },
                {
                    "sent": "So it just means either T or C. So these two are not the same, because this here runs over the whole population.",
                    "label": 0
                },
                {
                    "sent": "In this year only over those parts of the population that have been assigned to a certain treatment.",
                    "label": 0
                },
                {
                    "sent": "There's no reason in particular why they need to be the same.",
                    "label": 0
                },
                {
                    "sent": "Bad luck, but there are further ways to make sure that these two values here are exactly the same.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want this value to be exactly this one here.",
                    "label": 0
                },
                {
                    "sent": "And well, basic probability tells us the expected value of Y given S is the same as the expected value of Y if Y&S are independent.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If wind essay independent, then these two values here are exactly the same, and when are they independent?",
                    "label": 0
                },
                {
                    "sent": "While they're independent when you make them independent, you have to assign treatments randomly.",
                    "label": 0
                },
                {
                    "sent": "Whenever patient comes to your lap, you randomly assign him to the treatment or to the control group and then you have ensured.",
                    "label": 0
                },
                {
                    "sent": "That these two values are the same and that you can actually compute the average causal effect of your treatment versus your placebo treatment.",
                    "label": 1
                },
                {
                    "sent": "And this is the way that the causal inference is usually done in randomized clinical trials.",
                    "label": 0
                },
                {
                    "sent": "And two.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "To make it a little bit more illustrative why this is so important, I have a very simple constructed example here, so let us assume that you're a doctor and people come to your lab or to your office and they want to get some treatment for some certain disease and you want to test two different drugs on their effect.",
                    "label": 0
                },
                {
                    "sent": "But let us now assume that these two drugs actually have absolutely no influence on survival time.",
                    "label": 0
                },
                {
                    "sent": "You're completely useless.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, the expected survival time under the treatment equals the expected survival time.",
                    "label": 0
                },
                {
                    "sent": "Another control, no difference at all, but.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let us further assume that actually there's a sex specific difference.",
                    "label": 0
                },
                {
                    "sent": "Now that for some reason female women are more likely to survive longer than men.",
                    "label": 0
                },
                {
                    "sent": "And now if a patient comes to your lap, let us further assume that you don't assign them randomly by that you talk to them that you tell them what these treatments are about, and then let them choose whether they want to have treatment a or treatment B.",
                    "label": 0
                },
                {
                    "sent": "And let us further assume that women.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For some reason I'm more likely to choose treatment a versus treatment B because I don't know as a nicer name.",
                    "label": 0
                },
                {
                    "sent": "More appealing, less side effects for women, whatever.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we have the problem that now in the treatment group you have more women who are more likely to survive longer and then the survival time in the treatment is greater than the survival time.",
                    "label": 0
                },
                {
                    "sent": "Another control treatment.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have confounding you now believe oops, my treatment actually improves survival time, even though in reality there really is absolutely no effect there.",
                    "label": 0
                },
                {
                    "sent": "Now you could say, well, of course I have to make sure that that I have the same number of females and males in my groups.",
                    "label": 0
                },
                {
                    "sent": "And I can control for others.",
                    "label": 0
                },
                {
                    "sent": "And yes, of course you should, as much as you can, but this example of.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cost applies to any hidden confounder.",
                    "label": 0
                },
                {
                    "sent": "This this confounding variable may be anything that you may not have measured, that you may not even know exists.",
                    "label": 0
                },
                {
                    "sent": "So you can't exclude that.",
                    "label": 0
                },
                {
                    "sent": "There's no way that you can make sure that such confounding doesn't happen, because there can always be confounding effects that you don't even know that they might exist.",
                    "label": 0
                },
                {
                    "sent": "And the only way to be absolutely certain that this doesn't happen, and you can really compute the cause and effect of your treatment, is the random assignment.",
                    "label": 0
                },
                {
                    "sent": "If you can't do that.",
                    "label": 0
                },
                {
                    "sent": "You're lost.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sounds a bit depressing.",
                    "label": 0
                },
                {
                    "sent": "So when we talk about causal inference on newer imaging.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are asking the question can we do without that?",
                    "label": 0
                },
                {
                    "sent": "Can we do causal inference based on observation of the data only without any randomized treatments or assignments of causes?",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there's no.",
                    "label": 0
                },
                {
                    "sent": "In general we cannot, but we are machine learners.",
                    "label": 0
                },
                {
                    "sent": "We always make assumptions to do inferences, and we're quite happy to make assumptions as long as these assumptions are reasonable and turn out to be useful.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you're willing to make some assumptions in this context here, then yes, you can do causal inference, but it's always based on assumptions, and these assumptions are usually untestable.",
                    "label": 0
                },
                {
                    "sent": "You just have to live with it.",
                    "label": 0
                },
                {
                    "sent": "But if they turn out to be useful empirically, then fine, then we can live with these assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before I go to these cause inference algorithms in detail, I want to spend a few minutes on saying what I believe makes for a good cause.",
                    "label": 0
                },
                {
                    "sent": "Inference algorithms.",
                    "label": 0
                },
                {
                    "sent": "How should they be scored?",
                    "label": 0
                },
                {
                    "sent": "How should they be compared?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I think one important condition is that an algorithm should be probably correct and a reasonable assumptions.",
                    "label": 0
                },
                {
                    "sent": "You want this.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to accept these assumptions.",
                    "label": 0
                },
                {
                    "sent": "You want to think that they are reasonable, and then you want to be able to prove that.",
                    "label": 0
                },
                {
                    "sent": "Then make these assumptions that you will get the correct result.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second point is, I think, causal inference algorithm should make testable predictions on the effect of interventions.",
                    "label": 0
                },
                {
                    "sent": "This is, I don't think everybody in your science would agree to that, but I think that causal inferences about making testable predictions on the effect of interventions, and if you have an algorithm that doesn't really make these predictions, I don't find it that useful.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then it should be able to deal with hidden confound us, and this is of course part of the reasonable assumptions here, but it's one of the main problems.",
                    "label": 1
                },
                {
                    "sent": "Do you have to assume that no hidden confounders are present?",
                    "label": 1
                },
                {
                    "sent": "Or can an algorithm in some way deal with confirms that you haven't observed?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And theoretically prove theoretical proofs and performance are great, but if your algorithm doesn't perform well on finite data that you observe, then it's of little use.",
                    "label": 0
                },
                {
                    "sent": "So this is, I think, the last condition that is very important.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is now then the outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "I will talk about four methods, Granger, causality, causation networks, dynamic causal modeling and nonlinear non Gaussian acyclic models.",
                    "label": 0
                },
                {
                    "sent": "Or call it non lingam.",
                    "label": 0
                },
                {
                    "sent": "And I should probably be open about my my own preferences.",
                    "label": 0
                },
                {
                    "sent": "So I started working initially with Granger causality an, but the more I worked with it, the less I liked it.",
                    "label": 0
                },
                {
                    "sent": "So I switched from Granger causality, causation networks and that is the framework that I have to admit.",
                    "label": 0
                },
                {
                    "sent": "I like most, I believe it's the most rigorous framework and I'm still working on it, so my preference is conservation networks.",
                    "label": 0
                },
                {
                    "sent": "At the same time, was very interested in dynamic causal modeling, which is more from the neuroimaging side.",
                    "label": 0
                },
                {
                    "sent": "And I organized several workshops at NIPS, for instance, where brought together dynamic causal modeling guys in the machine learning communities, and I thought this was really cool.",
                    "label": 0
                },
                {
                    "sent": "But the more I learned about dynamic causal modeling, the less I liked it, and so I have to be honest, I do not like dynamic causal modeling.",
                    "label": 0
                },
                {
                    "sent": "I would bet it a little bit.",
                    "label": 0
                },
                {
                    "sent": "And the last one nonlinear non caution acyclic models that has been developed in part of the Max Planck Institute in tubing.",
                    "label": 0
                },
                {
                    "sent": "So there's a little bit of a bias there as well.",
                    "label": 0
                },
                {
                    "sent": "So when I go now into this algorithms, please do interrupt me at any point when you have any questions when when I'm going too fast or slow or anything so it would be great to have already a little bit of a discussion here.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Granger, causality widely used in neuroscience.",
                    "label": 0
                },
                {
                    "sent": "And if you open a neuroscience paper on Granger causality and you look for the definition of Granger, causality will find something along.",
                    "label": 0
                },
                {
                    "sent": "These lines will sometimes be a bit different, but usually we say one stochastic process is causal to a second if the auto regressive predictability of the second process at a given time point is improved by including measurements from the immediate past of the first.",
                    "label": 1
                },
                {
                    "sent": "So if you read the sense for the first time, it's probably a bit hard to parse.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me illustrate it with a simple example.",
                    "label": 0
                },
                {
                    "sent": "Let us assume we observe two variables, two time series X&Y.",
                    "label": 0
                },
                {
                    "sent": "This might be time series of local field potentials or EG signals and let us assume that.",
                    "label": 0
                },
                {
                    "sent": "They are generated by first order autoregressive process, so X of T is a function of X at the previous time step times some noise variable.",
                    "label": 0
                },
                {
                    "sent": "So X only drives itself.",
                    "label": 0
                },
                {
                    "sent": "Why is also seemed to be determined by its previous time point plus some noise so driving itself.",
                    "label": 0
                },
                {
                    "sent": "But we also assume that there is a link here from XT minus one to Y, so the previous time points of X influence the next time points of the Y.",
                    "label": 0
                },
                {
                    "sent": "And if you not right.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Device and inference procedure to test whether X causes Y the wave.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you do this the following you try to predict first Y from its past values.",
                    "label": 1
                },
                {
                    "sent": "So you look at the variants of your process Y.",
                    "label": 0
                },
                {
                    "sent": "If you're given the previous value, like usually, you would consider more than one value, but we assumed it's a first order process, so we only considering the last one.",
                    "label": 1
                },
                {
                    "sent": "And this kind of residual variance of why the part of the variance in the time series that you can't explain by looking at the past of the time series and kind of the innovation that enters into this time series.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then you do a second prediction.",
                    "label": 0
                },
                {
                    "sent": "We try to predict Y from its own past and the past of X.",
                    "label": 0
                },
                {
                    "sent": "So you now include X in the prediction.",
                    "label": 0
                },
                {
                    "sent": "So you look at the unexplained variance of Y at time T given the past of Y and the past of X.",
                    "label": 1
                },
                {
                    "sent": "And then you compare the two.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if you find that if you use XX as well, the past of X that then your prediction error is smaller than when you only use the past of Y.",
                    "label": 1
                },
                {
                    "sent": "Then then you conclude, according to this definition here, that X causes Y.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "No, right now we assume that oh OK, right now we assume that we can observe X&Y, but that we do not know this.",
                    "label": 0
                },
                {
                    "sent": "Good point, thank you class.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you ask is this model hidden?",
                    "label": 0
                },
                {
                    "sent": "What do we know about this model?",
                    "label": 0
                },
                {
                    "sent": "What do we not know about this model here?",
                    "label": 0
                },
                {
                    "sent": "In this example we only observe that I'm serious.",
                    "label": 0
                },
                {
                    "sent": "What we do not know this model we would like to infer this model.",
                    "label": 0
                },
                {
                    "sent": "That we do by looking at these prediction errors.",
                    "label": 0
                },
                {
                    "sent": "OK, so this sounds like a reasonable idea.",
                    "label": 0
                },
                {
                    "sent": "Sounds pretty much straight forward and people say yeah, and this is the work that Granger here published in 1969 in Econometrica, and this is what you got the Nobel Prize for.",
                    "label": 0
                },
                {
                    "sent": "And so this is the way that it's often used.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Neuroscience is the definition again.",
                    "label": 0
                },
                {
                    "sent": "But Interestingly, if you really.",
                    "label": 0
                },
                {
                    "sent": "Read Granger's original paper.",
                    "label": 0
                },
                {
                    "sent": "You find out that his definition is quite different.",
                    "label": 0
                },
                {
                    "sent": "And I found this a little bit shocking, so this is the definition that you always find in neuroscience journals.",
                    "label": 0
                },
                {
                    "sent": "And they say Granger defined causality as, or Granger causality is defined as.",
                    "label": 0
                },
                {
                    "sent": "But if you look at really at grangers paper, what you wrote.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is definition, and that's a bit different.",
                    "label": 0
                },
                {
                    "sent": "I want to spend a few minutes on explaining why this is a bit different, so Granger said if Sigma squared of Y given U is smaller than Sigma squared of Y, given you minus X with this bar on top, we say that X is causing why denoted by XT causing YT.",
                    "label": 1
                },
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "This is eat muskrat is again the prediction error.",
                    "label": 0
                },
                {
                    "sent": "Why is again that I'm serious so he's also looking at the predictability of a time series.",
                    "label": 0
                },
                {
                    "sent": "But this U is a bit of a strange concept.",
                    "label": 0
                },
                {
                    "sent": "For Granger you is all information in the universe.",
                    "label": 0
                },
                {
                    "sent": "It's questionable whether you would like to include the term.",
                    "label": 0
                },
                {
                    "sent": "All information in the universe in a definition.",
                    "label": 0
                },
                {
                    "sent": "But so he did, and now this humans X means you take all the information in the universe.",
                    "label": 0
                },
                {
                    "sent": "You remove X from it and then.",
                    "label": 0
                },
                {
                    "sent": "You see how well you can predict?",
                    "label": 0
                },
                {
                    "sent": "So it's the other way round then here.",
                    "label": 0
                },
                {
                    "sent": "Up here we say, OK, we include X in the predictions and see if our predictions get better.",
                    "label": 0
                },
                {
                    "sent": "And Granger said, Nope, we're going to predict Y from all information in the universe.",
                    "label": 0
                },
                {
                    "sent": "Then remove X.",
                    "label": 0
                },
                {
                    "sent": "And if our prediction gets worse, then we say X causes Y.",
                    "label": 0
                },
                {
                    "sent": "So why is there a difference?",
                    "label": 0
                },
                {
                    "sent": "And does it matter that there is?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Definition and I think yes, it does matter a lot in this related to conf.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Morning again, so here's an example.",
                    "label": 0
                },
                {
                    "sent": "Let us assume that we have three time series.",
                    "label": 0
                },
                {
                    "sent": "Again, 1st order autoregressive processes.",
                    "label": 0
                },
                {
                    "sent": "We have observed all of them X drives itself.",
                    "label": 0
                },
                {
                    "sent": "Why H drives itself and why drives itself.",
                    "label": 0
                },
                {
                    "sent": "But let us further assume.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That eight has an influence on X&Y, but with different time lags, so H causes X in the next time step.",
                    "label": 0
                },
                {
                    "sent": "But why only two?",
                    "label": 0
                },
                {
                    "sent": "It's time steps later?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "If you now.",
                    "label": 0
                },
                {
                    "sent": "Try to predict.",
                    "label": 0
                },
                {
                    "sent": "Why using X you will find the text will help in predicting Y because information from H first goes to X and then to Y.",
                    "label": 0
                },
                {
                    "sent": "So the past of X helps you to predict the future of life.",
                    "label": 0
                },
                {
                    "sent": "And if you invoke this definition up here, then you have to say, oh, cool, yeah, X is causing why.",
                    "label": 0
                },
                {
                    "sent": "But obviously it would be nonsense to to put forward a definition.",
                    "label": 0
                },
                {
                    "sent": "When this example you would have to conclude by the definition that X is a cause of why because there's a hidden confounder that actually enables you to make better predictions.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So just said X minus.",
                    "label": 0
                },
                {
                    "sent": "Estimize one could be a sequence of.",
                    "label": 0
                },
                {
                    "sent": "Composed yes, yes, it could be composed of all the past, but still that doesn't.",
                    "label": 0
                },
                {
                    "sent": "That doesn't make a difference to this this confounding issue because.",
                    "label": 0
                },
                {
                    "sent": "Here, even if you take all the past, you will always learn more information here from H that will help you in predicting the future of life.",
                    "label": 0
                },
                {
                    "sent": "So when you invoke, when you use this definition here, you would have to conclude that X is causing Y in this example.",
                    "label": 1
                },
                {
                    "sent": "But you don't want to conclude that because there is no causal relation between the two of us, just this hidden confounder.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Awesome.",
                    "label": 0
                },
                {
                    "sent": "Did you say OK X is cause of why?",
                    "label": 0
                },
                {
                    "sent": "And then also page is causing X in one model, yes?",
                    "label": 0
                },
                {
                    "sent": "To say that if X is causing why, but age is also in an earlier time point is causing X.",
                    "label": 1
                },
                {
                    "sent": "Why do you think it would be possible to say, OK, I should investigate.",
                    "label": 0
                },
                {
                    "sent": "If there is this indirect way from each, yes, yes.",
                    "label": 0
                },
                {
                    "sent": "I fully agree you should investigate whether there is this this path this interactive way.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And indeed, that is the way that you should do it if you have observed H. What you should do is you should control for.",
                    "label": 0
                },
                {
                    "sent": "It should look at the prediction error of Y given the path of Y&X given 8.",
                    "label": 0
                },
                {
                    "sent": "And the prediction of Y given only passively in the path of H, and then you've controlled for it and then.",
                    "label": 0
                },
                {
                    "sent": "Then you inference is going to be correct.",
                    "label": 0
                },
                {
                    "sent": "Now the problem again is you may have observed some age, but do you want to assume that you have observed all potentially potential age that can exist in the universe?",
                    "label": 0
                },
                {
                    "sent": "It's a bit unreasonable, but there are two things here on the one inside, it's how do you do inferences when you have to do it on empirical data?",
                    "label": 0
                },
                {
                    "sent": "And how do you construct your theoretical definitions?",
                    "label": 0
                },
                {
                    "sent": "And I think it's very important to note that Granger was clever enough to note that he needs a definition where he doesn't say that X causes wife.",
                    "label": 0
                },
                {
                    "sent": "There's a confounder present.",
                    "label": 0
                },
                {
                    "sent": "It's important to at least have the definition right.",
                    "label": 0
                },
                {
                    "sent": "Whether you can test or apply this definition in practice is an altogether different thing.",
                    "label": 0
                },
                {
                    "sent": "And I'm a little bit annoyed sometimes when I read in neuroscience journals that this problem of hidden confounders is simply brushed under the carpet.",
                    "label": 0
                },
                {
                    "sent": "And people even attribute a definition to Granger that he didn't make.",
                    "label": 0
                },
                {
                    "sent": "It's perfectly fine to say we can't do Granger causality inference with hidden confounders.",
                    "label": 0
                },
                {
                    "sent": "At least I don't know of anything any way to do that, but that's OK. We're going to make the assumptions that we have observed everything that's causally relevant then it's still interesting what you get, but you're open about your assumptions, and I think this is really important.",
                    "label": 0
                },
                {
                    "sent": "Everybody knows that causes inferences based on assumptions, so just be open about it and live with it.",
                    "label": 0
                },
                {
                    "sent": "But do not attribute something to Granger that he didn't say.",
                    "label": 0
                },
                {
                    "sent": "OK, so this I think is the biggest problem that I have with Granger causality and I have not yet seen a way to control for hidden confounders for this time series H. If you have not observed this and I'm uncomfortable with making this assumption that there are no such inconformes.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, however, when you look at neuroscience journals that you would not often find Granger causality applied in this way.",
                    "label": 0
                },
                {
                    "sent": "Most oftenly you will find a variant of it that is called the direct transfer function and I want to briefly introduce this.",
                    "label": 0
                },
                {
                    "sent": "And it's really just a small variant of its published initially I think by Cummins Catalent Biologics.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In 2001, and the way it works is the following.",
                    "label": 0
                },
                {
                    "sent": "You observe T samples of some multivariate time series and dimensional.",
                    "label": 0
                },
                {
                    "sent": "For example, N could be the number of your EG channels.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then you have to pick an order P of your auto regressive process.",
                    "label": 1
                },
                {
                    "sent": "And this is of course a difficult choice.",
                    "label": 0
                },
                {
                    "sent": "How do you pick it?",
                    "label": 0
                },
                {
                    "sent": "There's several ways to pick it.",
                    "label": 0
                },
                {
                    "sent": "Optimally.",
                    "label": 0
                },
                {
                    "sent": "My own take is that you should try several different P and check whether you cause it influences our robust with respect to your choice of P and if they are not robust with respect to Pi would be careful.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you learn the parameters AI.",
                    "label": 0
                },
                {
                    "sent": "This AI is a matrix of an autoregressive process of order P. So you try to model.",
                    "label": 0
                },
                {
                    "sent": "Your observations X by Delate versions of it.",
                    "label": 0
                },
                {
                    "sent": "With these matrices A plus some noise variable and there are many ways to do that in Matlab, R, Python.",
                    "label": 0
                },
                {
                    "sent": "They all have these methods implemented, so I want well on that.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then if you let a of 0.",
                    "label": 0
                },
                {
                    "sent": "AB minus the identity matrix.",
                    "label": 0
                },
                {
                    "sent": "Then you can write this equation as this term here and if you have done some certain processes and you note that this year actually.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A convolution of a with X and a convolution in the time domain is equivalent to a multiplication in the frequency domain.",
                    "label": 0
                },
                {
                    "sent": "So what you do then as you.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By the Fourier transform to move to the frequency domain of these signals.",
                    "label": 0
                },
                {
                    "sent": "Then you have minus a of F * X of F equals epsilon of F.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then rearranging it, you get this matrix H of F, which is the inverse of minus A of F. That tells you how these noise variables drive.",
                    "label": 0
                },
                {
                    "sent": "You observe processes in a frequency specific way.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The element of the I throw in the Jeff column of H. At frequency F, describes the frequency specific effect of the Jason Time series on the Ice Time series.",
                    "label": 1
                },
                {
                    "sent": "And this is the way that you will most often find Granger causality applied to neural data.",
                    "label": 0
                },
                {
                    "sent": "And I am trying to.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The case study for every inference algorithm that I present, and this is.",
                    "label": 1
                },
                {
                    "sent": "Probably in my my opinion, the most interesting study on Granger causality, at least that I've read in a long time.",
                    "label": 0
                },
                {
                    "sent": "It's about Bozeman at all, from the group of Pascal Freeze at the Instrument Institute in Frankfurt, and what they did is they recorded ECOG in monkeys.",
                    "label": 0
                },
                {
                    "sent": "So a huge huge ECG grid that cover the whole left hemisphere of monkeys.",
                    "label": 0
                },
                {
                    "sent": "And then they show two different stimulate with these monkeys and they trained the monkeys to either attend to one stimulus or the other stimulus and they found that in lower visual areas for the one stimulus.",
                    "label": 0
                },
                {
                    "sent": "This region here was most important for the other stimulus.",
                    "label": 0
                },
                {
                    "sent": "This region here was most important and then they looked with Granger causality at Granger.",
                    "label": 0
                },
                {
                    "sent": "Causal interactions between these lower level visual areas and a higher level visual areas in ECG data.",
                    "label": 0
                },
                {
                    "sent": "And they use the variance of this direct transfer function.",
                    "label": 0
                },
                {
                    "sent": "What they found is that if you look at the interaction from V1A2V4 when monkeys attended this red stimulus that you had this strong Granger causal effect at around 70 Hertz.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, the other way round from V for a 2V1 a you didn't see that.",
                    "label": 0
                },
                {
                    "sent": "And when monkeys attended the other stimulus, the blue stimulus bill wasn't really blue anyhow.",
                    "label": 0
                },
                {
                    "sent": "Then they found it the other way round.",
                    "label": 0
                },
                {
                    "sent": "They didn't see that between V1 A but V. 1B and also they didn't find a top down influence.",
                    "label": 0
                },
                {
                    "sent": "And I think this is really interesting result.",
                    "label": 0
                },
                {
                    "sent": "Of course, there could have been hidden confounders present.",
                    "label": 0
                },
                {
                    "sent": "But this dissociation between top down influences and attending the one or the other stimulus and seeing this clear effects, I think makes for very interesting data.",
                    "label": 0
                },
                {
                    "sent": "And if you're interested to see how Granger causality can be reasonably applied to neural data, I highly recommend this one paper here class.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe 1 one issue in this Granger.",
                    "label": 0
                },
                {
                    "sent": "Causal studies is also that if you have noise in both signals, then you may find some influence just because of the noise and so.",
                    "label": 0
                },
                {
                    "sent": "So if I look at this data you still see a little nob in the lower role.",
                    "label": 0
                },
                {
                    "sent": "So I think that maybe from that noise.",
                    "label": 0
                },
                {
                    "sent": "So I mean it's also Granger by the way said that.",
                    "label": 0
                },
                {
                    "sent": "You know the way he thought about his stuff was not noise robust.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I thought Ranger also said that quote that I like that, he said.",
                    "label": 0
                },
                {
                    "sent": "The causality that he defined is.",
                    "label": 0
                },
                {
                    "sent": "Complex enough to be interesting, yet simple enough for ecoa metrics to understand.",
                    "label": 0
                },
                {
                    "sent": "So he was quite aware that there are limitations, and maybe I should list a few more limitations that are rather interesting.",
                    "label": 1
                },
                {
                    "sent": "Granger causality also applied to fMRI data a lot, but the boat response.",
                    "label": 0
                },
                {
                    "sent": "Has different dynamics at different boxes, so there different delays in the boat response depending on where you look in the brain.",
                    "label": 0
                },
                {
                    "sent": "And this is definitely a problem for Granger causality apply to fMRI data.",
                    "label": 0
                },
                {
                    "sent": "And also some people argue that Granger causality is not really that much about causality, but more about information flow information transfer, because you can construct examples where there is 0 Granger causality but certainly a causal interaction going on.",
                    "label": 0
                },
                {
                    "sent": "But these are just some side points and I'd be happy to discuss that later with you in the breaks.",
                    "label": 0
                },
                {
                    "sent": "OK, so before I move away from Granger causality, any questions about it?",
                    "label": 0
                },
                {
                    "sent": "OK then let me.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, I forgot about this.",
                    "label": 0
                },
                {
                    "sent": "This is the table that I make to a little bit score these different algorithms against one another.",
                    "label": 0
                },
                {
                    "sent": "It's a very subjective view, some scoring it whether they're probably correct, whether they make testament inventions, can deal with hidden confounders and how they perform empirically.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Granger, causality.",
                    "label": 0
                },
                {
                    "sent": "I don't see that this probably correct unreasonable assumptions with these hidden confounders and news of the way that it's done with the linear models, and I don't like that.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think it does make testable interventions.",
                    "label": 1
                },
                {
                    "sent": "It has to.",
                    "label": 0
                },
                {
                    "sent": "If you stimulate with a certain frequency in one process, you should observe or not observe frequency specific effect in another time series.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't know of any way to deal with hidden confounders, but of course somebody may come up with a reasonable way to address this in the future.",
                    "label": 0
                },
                {
                    "sent": "And in terms of empirical performance, I want to postpone this to the summary of my talk.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, then the next one is cause of Asian networks.",
                    "label": 0
                },
                {
                    "sent": "My own favorite.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And cause abrasion networks have been developed by Judea Pearl at UCLA and Peter's parties and others at Carnegie Mellon University.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly they more or less developed exactly the framework more or less independently.",
                    "label": 0
                },
                {
                    "sent": "They both published a book on it in 2000, and I think both books are.",
                    "label": 0
                },
                {
                    "sent": "Phenomenal.",
                    "label": 0
                },
                {
                    "sent": "Grainger in Granger Judea Pearl got the Turing award.",
                    "label": 0
                },
                {
                    "sent": "I think two years ago for his work on vision networks and cause abrasion networks.",
                    "label": 0
                },
                {
                    "sent": "Which is the Nobel Prize in computer science?",
                    "label": 0
                },
                {
                    "sent": "And this book is.",
                    "label": 0
                },
                {
                    "sent": "Badger Depot is really incredible.",
                    "label": 0
                },
                {
                    "sent": "I've started reading it six years ago and still not done and it's always worth reading a few parts of it again.",
                    "label": 0
                },
                {
                    "sent": "I highly recommend it, but it's not a book that you just read in one semester and to start with, I want to give you a simple example how inference in this framework works.",
                    "label": 1
                },
                {
                    "sent": "What's the philosophy behind it?",
                    "label": 0
                },
                {
                    "sent": "And let us assume that we have a very simple causal structure.",
                    "label": 1
                },
                {
                    "sent": "XY and Z3 variables that we observe an X causes Y&Y causes COX&Y could be two different neural processes that we observe.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Band Palace in certain regions in certain frequency bands, NZ could be for instance the performance of our stroke.",
                    "label": 0
                },
                {
                    "sent": "Patients are more to learning task.",
                    "label": 0
                },
                {
                    "sent": "Let us assume that the call is the structure is such that indeed X&Y.",
                    "label": 0
                },
                {
                    "sent": "Both are A cause of Z, but this causes structures unknown to us.",
                    "label": 0
                },
                {
                    "sent": "We cannot directly observe this.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can observe, however.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's empirical data so we can sample from our system and we all can always observe a pair of these three variables XY and Z, and we can sample that many times.",
                    "label": 0
                },
                {
                    "sent": "For instance, we can observe many patients and then we get N samples of this pair.",
                    "label": 0
                },
                {
                    "sent": "Of these three variables.",
                    "label": 0
                },
                {
                    "sent": "And if we do this infinitely many times.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, we can infer the joint distribution of XY&Z from it, so this is what we can in principle observe.",
                    "label": 0
                },
                {
                    "sent": "And for now I will assume for the next few slides that we have always access to this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "This is, of course, a rather unreasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "We have to estimate that from finite data, and doing that will be very tough.",
                    "label": 0
                },
                {
                    "sent": "But for now, for the conceptual issues, I assume that we have access to this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "And from this joint Distr.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use and what we can read off this dependency structure between these variables we can test which variables are dependent on one another and which ones are independent.",
                    "label": 0
                },
                {
                    "sent": "So for this one called structure here, what we will find is this dependency structure.",
                    "label": 0
                },
                {
                    "sent": "X in Z will be dependent and Y&Z will be dependent because there's a direct causal link from X to Z and from Y to Z.",
                    "label": 0
                },
                {
                    "sent": "But X&Y, they will be independent, because there's no causal link, no no common cause of this, so they will be independent.",
                    "label": 0
                },
                {
                    "sent": "And now if we empirically observe this dependency structure.",
                    "label": 0
                },
                {
                    "sent": "We can ask the question.",
                    "label": 0
                },
                {
                    "sent": "What causes structures could have given rise to this?",
                    "label": 0
                },
                {
                    "sent": "What causes structures could have generated such a dependency structure?",
                    "label": 0
                },
                {
                    "sent": "No so.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's go through it through a few, so we already know that this causes structure generates this dependency structure, so this is a potential causes structure that's consistent with observations.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What about this causes structure where you only have one link?",
                    "label": 0
                },
                {
                    "sent": "Well, if you only have 1 Lincoln, why is not related causally to any of these two variables?",
                    "label": 0
                },
                {
                    "sent": "You don't have independence here, so you know.",
                    "label": 0
                },
                {
                    "sent": "OK, if I observe this.",
                    "label": 0
                },
                {
                    "sent": "Can't have been discourse structure.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What about this graph here, where X causes Y&Z causes Y, where then you dependency structure will look like this.",
                    "label": 0
                },
                {
                    "sent": "Because X will influence Y via C and hence X&Y will be in general independent.",
                    "label": 0
                },
                {
                    "sent": "And then again, you know, OK, this is inconsistent with this cost structure.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what about this one here where X&Y are actually independent are not causally related, but they're both influenced by Z.",
                    "label": 0
                },
                {
                    "sent": "Then again, you will find that they are all dependent X&Z.",
                    "label": 0
                },
                {
                    "sent": "Because of this direct causal link and Z&Y.",
                    "label": 0
                },
                {
                    "sent": "Also because of the start causal link.",
                    "label": 0
                },
                {
                    "sent": "But now Z is a joint common cause and that introduces a dependency between X&Y.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and in this way you can cycle or you can try out all causes structures that there are.",
                    "label": 0
                },
                {
                    "sent": "Check their dependency structures and see if there's any causes structure involving three variables.",
                    "label": 0
                },
                {
                    "sent": "Other than this one that generates this dependency structure.",
                    "label": 0
                },
                {
                    "sent": "And you will find under some assumptions that I will talk about in a minute that this year is the only one.",
                    "label": 0
                },
                {
                    "sent": "So if you observe three variables with this.",
                    "label": 0
                },
                {
                    "sent": "Dependency structure, you know there can only have been under some reasonable assumptions.",
                    "label": 0
                },
                {
                    "sent": "This caused a graph that generated it.",
                    "label": 0
                },
                {
                    "sent": "If you observe something like this, you can't say anything.",
                    "label": 0
                },
                {
                    "sent": "So this is very important principle.",
                    "label": 0
                },
                {
                    "sent": "It's like inference by exclusion.",
                    "label": 0
                },
                {
                    "sent": "Observe something you check what could have generated it, and if there's only one cause of structure that could have generated it, you're done.",
                    "label": 0
                },
                {
                    "sent": "If you find multiple causal structures that could have generated it, you can't make any inferences.",
                    "label": 0
                },
                {
                    "sent": "And this principle.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This tries to three routes for causal inference in this framework, and the first one is the rule for potential causation, and it goes as follows under the assumption assumptions of faithfulness and causes sufficiency, which I will explain in a minute.",
                    "label": 0
                },
                {
                    "sent": "The following conditions are sufficient for X to be a cause of Y. X needs to be independent of the.",
                    "label": 1
                },
                {
                    "sent": "I write this with this independent sign WHI needs to be independent of the.",
                    "label": 0
                },
                {
                    "sent": "Sorry, dependent dependent Excellency need to be dependent Y&Z need to be dependent and X&Y need to be independent, so exactly exactly this depends this structure.",
                    "label": 0
                },
                {
                    "sent": "And under these assumptions, you may infer that the causes structure that generated this is this one here.",
                    "label": 0
                },
                {
                    "sent": "Now the two assumptions are causes sufficiency and faithfulness causes.",
                    "label": 0
                },
                {
                    "sent": "Sufficiency means that there are no hidden confounders present because.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There were hidden confounder H here.",
                    "label": 0
                },
                {
                    "sent": "That were cause of X end of Z you would get exactly the same dependence structure.",
                    "label": 0
                },
                {
                    "sent": "So this is again this problem of in confounding.",
                    "label": 0
                },
                {
                    "sent": "Faithfulness I will get to in a minute.",
                    "label": 0
                },
                {
                    "sent": "But what I like so much about this conservation networks framework is that there are rules to deal with hidden confounders.",
                    "label": 0
                },
                {
                    "sent": "And I think this is pretty unique.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's one rule for spurious Association.",
                    "label": 1
                },
                {
                    "sent": "So again, under the assumption of faithfulness, there are conditions that you can test.",
                    "label": 1
                },
                {
                    "sent": "That will tell you whether there is a hidden confounder present in your data.",
                    "label": 0
                },
                {
                    "sent": "And the conditions are as follows.",
                    "label": 0
                },
                {
                    "sent": "You need fall variables this time, so cause abrasion networks is always about observing dependency structures between more than two variables and making inferences from that.",
                    "label": 0
                },
                {
                    "sent": "Now if you only have two variables, you can't say anything with conservation networks.",
                    "label": 0
                },
                {
                    "sent": "You need Z&X to be dependent.",
                    "label": 0
                },
                {
                    "sent": "You need X&Y to be dependent, and you need W&Y to be dependent.",
                    "label": 0
                },
                {
                    "sent": "But there may be no cross dependencies here.",
                    "label": 0
                },
                {
                    "sent": "And if that is the case, you've observed such a dependency structure, you may infer that there is a hidden confounder between X.",
                    "label": 0
                },
                {
                    "sent": "And why?",
                    "label": 0
                },
                {
                    "sent": "And to illustrate why this is the case, and let us assume.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's actually a causal link from X to Y.",
                    "label": 0
                },
                {
                    "sent": "Then there would be a dependency in general between Z&Y, because whatever information on these that is contained in X is passed onto Y, then you would have this link.",
                    "label": 0
                },
                {
                    "sent": "Other ways?",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Round if the cause infants were different Y 2X then you would have a dependence between W index.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you don't find this cross talk, then you know that the Association between X&Y must have been caused by a hidden confounder that you haven't observed.",
                    "label": 0
                },
                {
                    "sent": "And this is really cool to be able to test for that in general.",
                    "label": 0
                },
                {
                    "sent": "But conservation networks even more.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Awesome, there is a rule for genuine causation.",
                    "label": 0
                },
                {
                    "sent": "You can test.",
                    "label": 0
                },
                {
                    "sent": "That there's a genuine causal link between two variables that cannot have been confounded by any hidden confounder.",
                    "label": 0
                },
                {
                    "sent": "However, it's a pretty complex and tough rule, and understanding why this is the case is, well, it took me a while to figure out.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, I will try to give you an intuitive explanation.",
                    "label": 0
                },
                {
                    "sent": "So you need 4 variables this time.",
                    "label": 0
                },
                {
                    "sent": "Again ZXW&Y and you need different independence, bivariate and conditional independence relations.",
                    "label": 0
                },
                {
                    "sent": "First of all, you need Z to be a potential cause of X and potentially cause all this means you have to observe this V structure.",
                    "label": 1
                },
                {
                    "sent": "Here, this V structures are crucial.",
                    "label": 0
                },
                {
                    "sent": "Building block of inferences in this framework and if this V structure here, then you know that Z is a potential cause of X due to this rule for potential causation two slides back.",
                    "label": 0
                },
                {
                    "sent": "Now you need to observe that X&Y are dependent and Z&Y are dependent.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, you need to observe that if you now condition on X, if you now know what happens at X that, then this dependence between Z&W needs to vanish.",
                    "label": 1
                },
                {
                    "sent": "And if this is the case, which is rather complex condition, then you can infer that X is a genuine cause of Y, and that there can be no hidden confounder between X&Y.",
                    "label": 0
                },
                {
                    "sent": "And the reason why this works is that X blocks all information that can flow from Z to Y.",
                    "label": 0
                },
                {
                    "sent": "And if there would be hidden confounder present here in between, then X would not be able to block this path from Z to Y.",
                    "label": 0
                },
                {
                    "sent": "And the proof of that is quite illuminating and very exciting.",
                    "label": 0
                },
                {
                    "sent": "But it's rather complex, yes.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "The end condition between the two?",
                    "label": 0
                },
                {
                    "sent": "This means these are two separate tests that you need to do these.",
                    "label": 0
                },
                {
                    "sent": "Here are dependency tests that you need to do on your data.",
                    "label": 0
                },
                {
                    "sent": "Bivariate Lee.",
                    "label": 0
                },
                {
                    "sent": "You need to check the Z&Y are by variety dependent.",
                    "label": 0
                },
                {
                    "sent": "You should check that X&Y are by very dependent and Xion ex need to be by very dependent, but then you again need to check whether Z&Y are not independent anymore when you condition on X.",
                    "label": 0
                },
                {
                    "sent": "So just simply means it's additional tests that you have to perform and the shading here means now condition on X and then test for bivariate dependence between these like condition of X.",
                    "label": 0
                },
                {
                    "sent": "You mean you can in.",
                    "label": 0
                },
                {
                    "sent": "Sex or no buy conditioner.",
                    "label": 0
                },
                {
                    "sent": "So the definition of independence that you take the joint distribution of X&Y and can factor it into its marginals.",
                    "label": 0
                },
                {
                    "sent": "So if U of X and Y = P of X * P of Y, the two are independent.",
                    "label": 0
                },
                {
                    "sent": "Do we have a board here?",
                    "label": 0
                },
                {
                    "sent": "We can write this.",
                    "label": 0
                },
                {
                    "sent": "OK, unconditional means P of X&Y, given Z, needs to factorize as P of X given Z * P of Y given Z.",
                    "label": 0
                },
                {
                    "sent": "It's it's it's.",
                    "label": 0
                },
                {
                    "sent": "If you have the joint distributions and you can write them down then it's easy to check.",
                    "label": 0
                },
                {
                    "sent": "Doing this empirically is very, very hard and I will get to that in a minute.",
                    "label": 0
                },
                {
                    "sent": "Essentially, it means that you need to build some regression algorithms and you need to regress from.",
                    "label": 0
                },
                {
                    "sent": "You need to use X to regress out all information from Z&Y that they could contain about X, and then you need to check whether they are dependent anymore and maybe dependence and correlation.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should say what about that dependence is stronger than correlation, so correlation is linear dependence and if you find.",
                    "label": 0
                },
                {
                    "sent": "Ann to various to be correlated, then they are also dependent, but if you find 2 variables to be uncorrelated, it doesn't mean that they are independent.",
                    "label": 0
                },
                {
                    "sent": "So independence is like a nonlinear concept by correlations and linear concept.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, you need W to make sure that these are potential cause of X.",
                    "label": 0
                },
                {
                    "sent": "You need to have this study to make sure that X is actually not a potential cause of Z the other way round, because then this rule doesn't work.",
                    "label": 0
                },
                {
                    "sent": "OK, any further questions about this?",
                    "label": 0
                },
                {
                    "sent": "OK, so these are the three rules that form the backbone of causal inference.",
                    "label": 0
                },
                {
                    "sent": "In conservation networks.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now what you can do with that is you can easily predict the effect of interventions, and This is why one more reason why I like these cause abrasion networks that much.",
                    "label": 0
                },
                {
                    "sent": "So we assume that we are given a causal structure, a directed acyclic graph, a deck like this one here.",
                    "label": 0
                },
                {
                    "sent": "And it's joint distribution.",
                    "label": 0
                },
                {
                    "sent": "This is assuming quite a bit, so this joint distribution has to be estimated, usually from finite data.",
                    "label": 0
                },
                {
                    "sent": "That's hard, but let's assume we have it.",
                    "label": 0
                },
                {
                    "sent": "And this causes structure that has to be inferred from the strong distribution.",
                    "label": 0
                },
                {
                    "sent": "It's also hard, but let's assume that we have it.",
                    "label": 0
                },
                {
                    "sent": "And then what we would like to do is we would now like to predict the effect of experimentally controlling Z of intervening on on X.",
                    "label": 1
                },
                {
                    "sent": "For instance, X could be newer process and you want to stimulate it.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the way to do this is to take this joint distribution and factorize it according to its tag.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that works as follows.",
                    "label": 0
                },
                {
                    "sent": "You take the joint distribution in start with a W here and W only depends on Z.",
                    "label": 0
                },
                {
                    "sent": "So right P of W given Z only because WS only influence busy.",
                    "label": 0
                },
                {
                    "sent": "Then you start with a Z.",
                    "label": 0
                },
                {
                    "sent": "That's the next.",
                    "label": 0
                },
                {
                    "sent": "And P of Z is influenced by X&YOP of Z is.",
                    "label": 0
                },
                {
                    "sent": "Conditional on X&Y&X&Y are not influenced by any other variables, so you simply write P of X&P of Y.",
                    "label": 0
                },
                {
                    "sent": "This factorization of this joint distribution according to its causes structure.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now you compute the so called interventional distribution and Judea Pearl intra.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use this whole quote Doom caculus for this, so he writes it as follows.",
                    "label": 0
                },
                {
                    "sent": "This joint distribution given do of X = X~ and that means not just to observe that X has been external, but to experimentally intervene and fix the value of X at this value X to do.",
                    "label": 0
                },
                {
                    "sent": "And to get from this observation and distribution to this intervention of distribution is rather simple.",
                    "label": 0
                },
                {
                    "sent": "You simply take a look at where the X turns up here, which is there and there.",
                    "label": 0
                },
                {
                    "sent": "And this P of X does not vanish is this is set to 1 because it's not a random variable anymore.",
                    "label": 0
                },
                {
                    "sent": "You have set it to a value, it's determined so.",
                    "label": 0
                },
                {
                    "sent": "No randomness anymore this years one.",
                    "label": 0
                },
                {
                    "sent": "And here's the given X.",
                    "label": 0
                },
                {
                    "sent": "You now have given X~ because this is the value that you set it to.",
                    "label": 0
                },
                {
                    "sent": "Now you get this new distribution here.",
                    "label": 0
                },
                {
                    "sent": "This intervention of distribution.",
                    "label": 0
                },
                {
                    "sent": "Off those variables, if you have intervened on X.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You might say, OK, I'm now interested in what the distribution of W is after I have set X to this one specific value.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once you do this, you simply marginalized out those variables you're not interested in.",
                    "label": 0
                },
                {
                    "sent": "In this case, Y&Z.",
                    "label": 0
                },
                {
                    "sent": "By integrating this out.",
                    "label": 0
                },
                {
                    "sent": "And then you obtain this distribution of data you under this intervention, and this is really so interesting, because now you can easily ask the question if I have a certain set of interventions that I can do and I have a certain goal of my system, how it should behave, what intervention that I can do is most likely to give me the goal that I want.",
                    "label": 0
                },
                {
                    "sent": "So how can I intervene on the system to make it behave in the way that I wanted to behave?",
                    "label": 0
                },
                {
                    "sent": "And in the example that I gave in the beginning, this means we want to know how and where to stimulate in the brain to turn poor stroke rehabilitators into good stroke regulators.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now this sounds awesome, but of course there's a catch there smaller than one catch as there always is and the first kitchen 'cause the major networks is this assumption of faithfulness.",
                    "label": 0
                },
                {
                    "sent": "And that is really integral to all inferences in this framework, and faithfulness describes the notion of the assumption that all observed independence is or conditional independences are structural.",
                    "label": 0
                },
                {
                    "sent": "And to explain what that means.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have a simple example, so let us assume again.",
                    "label": 0
                },
                {
                    "sent": "We have three variables XY and Z and that we have this complete deck where there is a link between every node.",
                    "label": 0
                },
                {
                    "sent": "Now let us assume that there's a very simple functional model underneath this that all relations are linear, so that X is simply some noise variable.",
                    "label": 0
                },
                {
                    "sent": "UXY is a function of linear function of X&Z plus some noise variable, and Z is a linear function of X plus some noise verb, and we assume these noise variables to independent of one another.",
                    "label": 0
                },
                {
                    "sent": "Then in general, what we observe is this dependency structure.",
                    "label": 0
                },
                {
                    "sent": "Everything is going to be dependent on everything else.",
                    "label": 0
                },
                {
                    "sent": "However, you can choose the parameters here.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such that this dependency vanishes.",
                    "label": 0
                },
                {
                    "sent": "If you choose this very parameter, A is minus BC.",
                    "label": 0
                },
                {
                    "sent": "Then why is all of a sudden only influenced by Z anymore and not by X?",
                    "label": 0
                },
                {
                    "sent": "And that is because the influence of X on Y via this path has been exactly cancelled by the influence via this path.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Position applies, yes you can't.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So how can you say that?",
                    "label": 0
                },
                {
                    "sent": "Why is like a X + B set?",
                    "label": 0
                },
                {
                    "sent": "Plus you why it's proposition?",
                    "label": 0
                },
                {
                    "sent": "It's linear system.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's just an example, it's just an example right now to illustrate what can happen.",
                    "label": 0
                },
                {
                    "sent": "And faithfulness the assumption of faithfulness does not apply now, so it's just let's just assume that that this is the case in some data that we observe.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In general, you observe this dependence structure.",
                    "label": 0
                },
                {
                    "sent": "If you observe that you cannot make any inferences at all, but.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the parameters are chosen a very particular way, then this dependency vanish is and then you all of a sudden have a dependency structure where your potential causation rule tells you not cool X is.",
                    "label": 0
                },
                {
                    "sent": "And why are potential causes of Z?",
                    "label": 0
                },
                {
                    "sent": "And that of course would be an incorrect inference.",
                    "label": 0
                },
                {
                    "sent": "And the reason why you would make this incorrect inference is that.",
                    "label": 0
                },
                {
                    "sent": "Well, this parametrization hides a dependence from you, that is structural and faithfulness, as if there is a structural dependence of causal relation.",
                    "label": 0
                },
                {
                    "sent": "Then you will also see it in your data.",
                    "label": 0
                },
                {
                    "sent": "Nature will not hide this dependency from you by choosing is very specific parameterization of the process.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "And now the question is, is this a strong assumption or is this a reasonable assumption?",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there's a reason.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By Christopher meek.",
                    "label": 0
                },
                {
                    "sent": "Published at UI in 1995 that says that for any given causes structure deck the unfaithful distributions have measure 0 in the space of all distributions that can be generated by the deck.",
                    "label": 1
                },
                {
                    "sent": "So to explain this a little bit more in detail.",
                    "label": 0
                },
                {
                    "sent": "You take a deck and there can be many joint distributions that this deck can generate.",
                    "label": 0
                },
                {
                    "sent": "And now you look at which distributions that this deck can generate are faithful and which ones are not faithful.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the unfaithful distributions the deck and generate has measure 0.",
                    "label": 0
                },
                {
                    "sent": "Meaning if you randomly pick a graph and randomly let it generate some joint distribution, you have, it's extremely unlikely that you will observe an unfaithful distribution.",
                    "label": 0
                },
                {
                    "sent": "And this is being used to reason that, well, it's unlikely that you will ever encounter an unfaithful distribution in practice.",
                    "label": 0
                },
                {
                    "sent": "However, this is based on the additional assumption that nature has no reason to favor unfaithful distributions.",
                    "label": 0
                },
                {
                    "sent": "It might be that for some reason it is efficient to generate an unfaithful distribution by nature, if nature decides to fool you, there's nothing you can do.",
                    "label": 0
                },
                {
                    "sent": "So this is the strongest assumption that enters here, yes.",
                    "label": 0
                },
                {
                    "sent": "If you have noise, is this still possible?",
                    "label": 0
                },
                {
                    "sent": "Sir, I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, the cool thing about this is that you're basing all your influences on your joint distributions and how U joint distributions have been generated with.",
                    "label": 0
                },
                {
                    "sent": "It's a linear process and nonlinear process.",
                    "label": 0
                },
                {
                    "sent": "What noise there is.",
                    "label": 0
                },
                {
                    "sent": "Or that there is any?",
                    "label": 0
                },
                {
                    "sent": "What distribution the noise has it?",
                    "label": 0
                },
                {
                    "sent": "All, it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "It's all nonparametric because all inferences are based on these independence tests.",
                    "label": 0
                },
                {
                    "sent": "You don't make any modeling assumptions, so in general it works for any variables under the assumptions of faithfulness.",
                    "label": 0
                },
                {
                    "sent": "Are this constellation OK?",
                    "label": 0
                },
                {
                    "sent": "This is possible disconsolation under noise.",
                    "label": 0
                },
                {
                    "sent": "Good question.",
                    "label": 0
                },
                {
                    "sent": "Probably depends on where the noise and just.",
                    "label": 0
                },
                {
                    "sent": "I mean you have noise here in every variable.",
                    "label": 0
                },
                {
                    "sent": "This UX UI and you see these are noises and the different noises are assumed to be independent of one another and then this can happen.",
                    "label": 0
                },
                {
                    "sent": "So in general, yes.",
                    "label": 0
                },
                {
                    "sent": "But what happens if you have measurement noise?",
                    "label": 0
                },
                {
                    "sent": "Yes, I think it can happen.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "No, because this this parametrization hides this dependency from you and you won't get that dependence back because the add noise on top of it.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I think it can happen with noise.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the fundamental assumptions that you have to make when you work with causation networks.",
                    "label": 0
                },
                {
                    "sent": "But there is another catch.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's great that cause abrasion networks work so well in theory, but in practice it's much, much harder.",
                    "label": 0
                },
                {
                    "sent": "And that is because of these conditional independence tests.",
                    "label": 0
                },
                {
                    "sent": "So far we have assumed that we have the joint distribution and then you can simply write it down and check whether things are dependent or not.",
                    "label": 0
                },
                {
                    "sent": "That's easy, but in practice you have to do these conditional independence tests on finite data.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's really, really tough.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Aunt Uncorrelatedness does not imply independence, so you could check for Uncorrelatedness.",
                    "label": 1
                },
                {
                    "sent": "Assume everything is linear and then would get a lot easier, and indeed there is that at heart algorithm developer Peters purchase at CMU in this collaborators that you can download off the web and that is based on linear models.",
                    "label": 0
                },
                {
                    "sent": "But just uncorrelatedness doesn't imply independence, and hence you cannot make this inference is just from uncorrelatedness.",
                    "label": 0
                },
                {
                    "sent": "So you really need non linear in it.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These tests and they are difficult.",
                    "label": 0
                },
                {
                    "sent": "But I always use the one that has been developed by Arthur Gretton at the MPI into being called the H Stick test.",
                    "label": 0
                },
                {
                    "sent": "Which is a nonparametric kernel based independence test and I find that to work pretty well.",
                    "label": 0
                },
                {
                    "sent": "That's the one that I use.",
                    "label": 0
                },
                {
                    "sent": "However, that only works as long as you're interested in a potential causation in spurious causation.",
                    "label": 0
                },
                {
                    "sent": "If you want to move on to testing for genuine causation, you need these conditional independence tests.",
                    "label": 1
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And conditionally independent tests are even harder, and the best method that I know so far for that is by Quinn Sung who supposed toknow actually now group leader at the MPI into being published UI in 2012.",
                    "label": 0
                },
                {
                    "sent": "So in practice, these tests are very, very hard.",
                    "label": 1
                },
                {
                    "sent": "And there's one conceptual problem.",
                    "label": 0
                },
                {
                    "sent": "And that is really quite severe.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not finding a dependence is not evidence for independence.",
                    "label": 1
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So you need to make these inferences from independence.",
                    "label": 0
                },
                {
                    "sent": "You need to check your variables and you need to say haha.",
                    "label": 0
                },
                {
                    "sent": "These two are independent.",
                    "label": 0
                },
                {
                    "sent": "Hence I can make an inference from that.",
                    "label": 0
                },
                {
                    "sent": "But not finding a dependence is not evidence for independence.",
                    "label": 0
                },
                {
                    "sent": "If you look at 1000 crows and none of them is white, you cannot conclude that there are no white cross growth.",
                    "label": 0
                },
                {
                    "sent": "So you have to make this assumption that.",
                    "label": 0
                },
                {
                    "sent": "Your data is rich enough and your algorithms are powerful enough that you would have found a dependence if there were one.",
                    "label": 0
                },
                {
                    "sent": "And of course, it could always be that if you had used a more powerful algorithm that if you had observed more data, you would find independence and then this would invalidate your inferences.",
                    "label": 0
                },
                {
                    "sent": "So this is a big conceptual problem.",
                    "label": 0
                },
                {
                    "sent": "You can't really give evidence for this, but then again, this is pretty much the same way that we do usual inferences in.",
                    "label": 0
                },
                {
                    "sent": "I don't know if my analysis or hypothesis testing.",
                    "label": 0
                },
                {
                    "sent": "If you have a usual hypothesis you test, you know hypothesis and you reject your null hypothesis that you have evidenced against it, but evidenced against the null hypothesis is not evidence for its negation.",
                    "label": 0
                },
                {
                    "sent": "And this is kind of the same problem, just the other way around.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and this is a severe limitation.",
                    "label": 0
                },
                {
                    "sent": "Good.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then in a case study on conservation networks, and this is now my own work so.",
                    "label": 0
                },
                {
                    "sent": "When working on PC's or a few years ago, let's work on sensorimotor Rhythm, brain computer interfaces, and was very interested in explaining why some subjects are good performers, and why some subjects are poor performance in Bcis.",
                    "label": 0
                },
                {
                    "sent": "And and.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, I found that that subjects are not per say, good or poor performance, but they are sometimes good and sometimes poor and I wanted to understand this variation.",
                    "label": 0
                },
                {
                    "sent": "And so we try to predict the performance of our subjects from neuro segments in different frequency ranges and what we actually found is that distributed, range oscillations correlated with how well our subjects could operate in PCI.",
                    "label": 0
                },
                {
                    "sent": "And from the.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We formed the hypothesis that the causal graph in our data was like this, that we gave our PR subjects instructions whether to perform left or right hand motor imagery.",
                    "label": 0
                },
                {
                    "sent": "And we observe that this instruction to perform left or right and motor imagery led to a modulation of the sensory motor rhythm.",
                    "label": 0
                },
                {
                    "sent": "So there's some reason become became more lateralized for the one versus the other condition.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, we found that this gamma power here.",
                    "label": 0
                },
                {
                    "sent": "They told us many let us predict how lateralized, the sensorimotor rhythm would be, and so we formulated this hypothesis that these gamma range oscillations are potential cause of this sensory motor rhythms.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we tested that and our data with this nonlinear H Stick test.",
                    "label": 0
                },
                {
                    "sent": "And we found that one instruction what type of motor imagery to perform in the sensory motor rhythm was highly correlated.",
                    "label": 0
                },
                {
                    "sent": "The P value for rejecting independence was 1 * 10 to the power minus 4.",
                    "label": 0
                },
                {
                    "sent": "Also we found gamma power and the sensorimotor rhythm to be highly correlated with the P value.",
                    "label": 0
                },
                {
                    "sent": "For rejecting that was 2 * 10 to the power minus four.",
                    "label": 0
                },
                {
                    "sent": "But interesting with this non linear independence test, we didn't find any evidence for dependence of this instruction.",
                    "label": 0
                },
                {
                    "sent": "What type of motor imagery to perform and gamma power that we observed?",
                    "label": 0
                },
                {
                    "sent": "And now, because we didn't find any dependence, we said, OK, we're now going to interpret this as evidence for independence, even though we know that this is a bit quirky.",
                    "label": 0
                },
                {
                    "sent": "And then we can invoke the rule for potential causation and argue that indeed gamma power is a potential cause of the sensorimotor rhythm.",
                    "label": 0
                },
                {
                    "sent": "And this was really interesting to us because we then start OK.",
                    "label": 0
                },
                {
                    "sent": "Probably there's some attentional processes that generate these gamma oscillations that have an effect on those processes that generate our sensory motor rhythm.",
                    "label": 0
                },
                {
                    "sent": "But of course this is only potential causation.",
                    "label": 0
                },
                {
                    "sent": "We didn't invoke the roofer genuine causation, so there might be hidden confounders.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fortunately, in our setup, we could say a bit more because this instruction here that could only be a cause of other observations because we gave it to the subjects.",
                    "label": 0
                },
                {
                    "sent": "This is what we randomized and hence we could make a bit more strong inferences and say there has to be some neural substrate potentially of attention.",
                    "label": 1
                },
                {
                    "sent": "That generates are, stellations.",
                    "label": 0
                },
                {
                    "sent": "And some new substrate that generates all motor imagery signals or sensory motor rhythm and our data tells us that there has to be causal link from this substrate to the motor imagery substrate and that link cannot be the other way around, because then we would have expected to find independence between the instruction and gamma power via this link, which we didn't find.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK, in the simplest case, train the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "Of course, yes.",
                    "label": 0
                },
                {
                    "sent": "Always forget that.",
                    "label": 0
                },
                {
                    "sent": "Or maybe you give me that and I will give it yeah.",
                    "label": 0
                },
                {
                    "sent": "I just I just don't get what do you mean between with dependency between instruction and gamma power like?",
                    "label": 0
                },
                {
                    "sent": "Maybe a step backward and try to explain the setup because I don't.",
                    "label": 0
                },
                {
                    "sent": "So we checked dependence between instruction and SMR and instruction gamma power in two different ways.",
                    "label": 0
                },
                {
                    "sent": "The dependence of the instruction that we gave to the subjects and SMR.",
                    "label": 0
                },
                {
                    "sent": "We simply did both support vector machine we try to decode from the sensory motor rhythm what the instruction was that we gave to the subject minus one for left hand motor imagery in plus one for motor imagery.",
                    "label": 0
                },
                {
                    "sent": "And we saw that with the support vector machine we could predict that and we could reject the null hypothesis of chance level performance and hence we said that we have something to do with one another.",
                    "label": 0
                },
                {
                    "sent": "They are dependent.",
                    "label": 0
                },
                {
                    "sent": "Now for this, installations it was a bit more tricky because we also try to use a support vector machine.",
                    "label": 0
                },
                {
                    "sent": "To predict the instruction, the type of instruction from gamma power.",
                    "label": 0
                },
                {
                    "sent": "So we couldn't with it, so we used a nonlinear support vector machine.",
                    "label": 0
                },
                {
                    "sent": "This H stick tests and we still couldn't do that.",
                    "label": 0
                },
                {
                    "sent": "And then we looked at the relation of SMR and gamma power and try to find independence there.",
                    "label": 0
                },
                {
                    "sent": "So we tried to predict the SMR from gamma power and with the linear methods we didn't manage to do that, but with nonlinear methods we actually did.",
                    "label": 0
                },
                {
                    "sent": "We notice that gamma power predicted not the side of the SMR literalization, but the extent of it.",
                    "label": 0
                },
                {
                    "sent": "The absolute value of it.",
                    "label": 0
                },
                {
                    "sent": "So we found this nonlinear dependence between the two, and that's the basis of these tests.",
                    "label": 0
                },
                {
                    "sent": "How strong or someone depends highly.",
                    "label": 0
                },
                {
                    "sent": "Thank you highly, highly subject very some subjects had extremely strong dependence.",
                    "label": 0
                },
                {
                    "sent": "Also for low gamma power they want chance level for high gamma power they were at 95% decoding accuracy.",
                    "label": 0
                },
                {
                    "sent": "For other subjects we didn't find any dependence at all, so was highly very high intrasubject variance.",
                    "label": 1
                },
                {
                    "sent": "OK, so this concludes the part on the.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observation networks so let me square them according to my own beliefs I.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cause of Asian networks are probably correct and unreasonable assumptions, and that's what I really, really like about them.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They also make testable interventions and they have a well developed framework for making these testable interventions, which is great.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They can deal with hidden confounders and this is amazing.",
                    "label": 1
                },
                {
                    "sent": "The only the only framework that I know that I'm not really reasonable assumptions can deal with in conformers.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Empirical performance is a nightmare.",
                    "label": 1
                },
                {
                    "sent": "These conditional independence tests are really, really hard, but people are working on that very, very.",
                    "label": 0
                },
                {
                    "sent": "Intelligence statisticians are working on that, so I'm hopeful that these tests will improve and make these conservation networks more applicable in the future.",
                    "label": 0
                },
                {
                    "sent": "So any questions about conservation networks before we move on two dynamic causal modeling?",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So dynamic causal modeling.",
                    "label": 0
                },
                {
                    "sent": "My disclaimer again, I was very interested in that in the beginning I organized a few.",
                    "label": 0
                },
                {
                    "sent": "Workshops on that I went to visit car, for instance lab who developed that I had a small collaboration with one of his methods guys.",
                    "label": 0
                },
                {
                    "sent": "But the more I learned about it, the less I liked it.",
                    "label": 0
                },
                {
                    "sent": "So it's a bit of a biased view.",
                    "label": 0
                },
                {
                    "sent": "I hope you will forgive.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to start with, in dynamic causal modeling is interesting to us, and what is the concept of causality behind dynamic causal modeling and colorist?",
                    "label": 0
                },
                {
                    "sent": "And who is it?",
                    "label": 0
                },
                {
                    "sent": "In London wrote in one of these papers, causality in TCM is used in a control theory sense and means that under the model activity in one brain area causes dynamics in another and that these dynamics caused the observations.",
                    "label": 0
                },
                {
                    "sent": "Now I don't like definitions that include the term.",
                    "label": 0
                },
                {
                    "sent": "That is to be defined.",
                    "label": 0
                },
                {
                    "sent": "Causality is when a causes B.",
                    "label": 0
                },
                {
                    "sent": "That doesn't tell me much.",
                    "label": 0
                },
                {
                    "sent": "And I actually did my PhD in control theory.",
                    "label": 0
                },
                {
                    "sent": "I think I know what kind means, but I've never ever heard a control theory guy speak of causality.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so let me try to illustrate what I.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think he means and this is straight, but the general inference procedure.",
                    "label": 0
                },
                {
                    "sent": "But this is going to be very high.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Level.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we observe an N dimensional time series X of T. 40 time points and this might be both signals recorded by for my, but this might also be easy signals, so dynamic causal modeling has been first developed for fMRI data, but has been extended to e.g imaging and so on.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we define a set of models M. In different models, where each model consists of a set of differential equations with a different connectivity structure, so you have very detailed models.",
                    "label": 1
                },
                {
                    "sent": "And how your data has been generated.",
                    "label": 0
                },
                {
                    "sent": "And each model consists of a set of differential equations so that dynamic system and there are certain connectivities between the variables in your system, how they are allowed to interact, and how they are not allowed to interact.",
                    "label": 0
                },
                {
                    "sent": "And Friston and his collaborators say it is very important that these models are plausable.",
                    "label": 0
                },
                {
                    "sent": "You have to only include plausible models in there, whatever that means possible from your prior knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you fit each model to the data, which is tough is really really a tough machine learning problem, but I won't go into that for now.",
                    "label": 0
                },
                {
                    "sent": "It's implemented in this toolbox SPM.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then you compare these models and how well they fit your data.",
                    "label": 0
                },
                {
                    "sent": "Where they explain your data.",
                    "label": 0
                },
                {
                    "sent": "And of course you have some ways to make sure that you're not overfitting that's in there, and then you take the connectivity of the model with the best data fit as the true causes structure.",
                    "label": 1
                },
                {
                    "sent": "So you compare all your models or where they explain your data.",
                    "label": 0
                },
                {
                    "sent": "And you said in the beginning, or your models are plausable anyhow.",
                    "label": 1
                },
                {
                    "sent": "And then the model that explains to date and the best way.",
                    "label": 0
                },
                {
                    "sent": "Making sure that it's not overly complex, that is the one that gives you the connectivity structure and thus the causal structure between your variables.",
                    "label": 0
                },
                {
                    "sent": "That is the true one.",
                    "label": 0
                },
                {
                    "sent": "And these models underneath that they are rather complex and I want to spend a few minutes on explaining these models.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first part of this model is the hemodynamic model, also called the balloon model, and this model tells you how neural activity translates into your boat signal.",
                    "label": 1
                },
                {
                    "sent": "So this block is simply input is neuro in their input Z.",
                    "label": 0
                },
                {
                    "sent": "And then there's this nonlinear function.",
                    "label": 0
                },
                {
                    "sent": "This system here and that gives you an output why that is your hemodynamic response and people have spent a lot of time developing this model, and I think it's the most advanced model for modeling board responses, and it has here some activity pendant 1st order differential equation.",
                    "label": 0
                },
                {
                    "sent": "Then this is being integrated again to compute the flow induction.",
                    "label": 0
                },
                {
                    "sent": "Then you have changes in volume.",
                    "label": 0
                },
                {
                    "sent": "This differential equation changes in HB, the hemodynamic signal and all of this is combined and this really complex way to form this chemo dynamic response.",
                    "label": 0
                },
                {
                    "sent": "And now this is your kind of observation model on your activity translates into your boat signal, but underneath that is the dynamic system that describes how you're different neural.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Processes interact.",
                    "label": 0
                },
                {
                    "sent": "And this is one of the plots from from call it's original publication.",
                    "label": 0
                },
                {
                    "sent": "So you have a set of stimuli.",
                    "label": 0
                },
                {
                    "sent": "Any set of context variables?",
                    "label": 0
                },
                {
                    "sent": "And for each region in the brain that you want to consider, you have one differential equation.",
                    "label": 0
                },
                {
                    "sent": "So Z1Z2Z3C4C5 means you're looking at 5 different regions in the brain, and the neural dynamics in each of these regions.",
                    "label": 0
                },
                {
                    "sent": "I assume to be governed by these differential equations here.",
                    "label": 0
                },
                {
                    "sent": "And these differential equations.",
                    "label": 0
                },
                {
                    "sent": "Are driven by.",
                    "label": 0
                },
                {
                    "sent": "The activity in other regions and these arrows here they define your connectivity structure and also that here you have this link from Z1 to Z2 means that in the differential equation of Z2 you have one term that includes the one.",
                    "label": 0
                },
                {
                    "sent": "This defines your connectivity structure and now will you observe your data, you have your stimuli give you context for your data you have.",
                    "label": 0
                },
                {
                    "sent": "You assumed connectivity structure that gives you the neural dynamics in each brain region and then you have your hemodynamic model.",
                    "label": 0
                },
                {
                    "sent": "That tells you how the Neurodynamics actually map in the fMRI signal that you observe.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "For example, for the block on the bottom, A323 is a function of the derivation of Z3 I assume, or 8th.",
                    "label": 0
                },
                {
                    "sent": "One, yeah, that means that the two is a function of the three, and you have this Z3 included in here as a function.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, all I see here many algebraic algebraic loops basically so.",
                    "label": 0
                },
                {
                    "sent": "I and everything is working in the first level derivation, so there's no integration in between.",
                    "label": 0
                },
                {
                    "sent": "Is there an order for calculating or well, these?",
                    "label": 0
                },
                {
                    "sent": "These are all first order differential equations, right?",
                    "label": 0
                },
                {
                    "sent": "And of course if when you want to fit them to your data you have to integrate them.",
                    "label": 0
                },
                {
                    "sent": "You have to have your numerical solvers, and doing that is really really tough and I think it's called variational inference and I think class can tell you more about that than I can.",
                    "label": 0
                },
                {
                    "sent": "It's a very, very hard problem, and SPM solves it for you an sceptical whether it solves it in an optimal fashion.",
                    "label": 0
                },
                {
                    "sent": "So organized Nips Workshop where there was a guy from Kathryn slept who presented all this stuff and it was very proud that I got really good machine learners there into my workshop I had Chris Williams and bad from cotton and.",
                    "label": 0
                },
                {
                    "sent": "They explained the guy this is being recorded right.",
                    "label": 0
                },
                {
                    "sent": "They explained the guy from Karsten slap that his algorithms only converge to local minima.",
                    "label": 0
                },
                {
                    "sent": "Yeah anyhow, but yes one more question back there.",
                    "label": 0
                },
                {
                    "sent": "So this set of models.",
                    "label": 0
                },
                {
                    "sent": "I, I guess you're suggesting they are not minimal.",
                    "label": 0
                },
                {
                    "sent": "Is that what you're saying?",
                    "label": 0
                },
                {
                    "sent": "I'm saying that what is not minimum.",
                    "label": 0
                },
                {
                    "sent": "These models in the set of models.",
                    "label": 0
                },
                {
                    "sent": "You mean with minimal there?",
                    "label": 0
                },
                {
                    "sent": "No, no, I mean too complex too for the for the data that you have.",
                    "label": 0
                },
                {
                    "sent": "Whether the models are too complex for the data.",
                    "label": 0
                },
                {
                    "sent": "Hard to say, I don't really.",
                    "label": 0
                },
                {
                    "sent": "I'm not really sure whether I understood the question completely.",
                    "label": 0
                },
                {
                    "sent": "Try to continue how these different models are compared and you ask the question again if it hasn't become clear, maybe it will become clear in the next slide.",
                    "label": 0
                },
                {
                    "sent": "Alcohol, can you reformulate your question?",
                    "label": 0
                },
                {
                    "sent": "That is what you're saying is that you don't have enough evidence to really decide?",
                    "label": 0
                },
                {
                    "sent": "OK, no, not necessarily.",
                    "label": 0
                },
                {
                    "sent": "The reasons why why it appears that if you fit these models to your data, that's really tough problem.",
                    "label": 0
                },
                {
                    "sent": "That depends on many assumptions and whether you end up in your global minimum or not is a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "But apart from that, there's also the question that I will get to in a second is how realistic these models are.",
                    "label": 0
                },
                {
                    "sent": "But for now I would like just like you to accept that this is a very good model of how neural dynamics work and how fMRI signals are being generated, because this is more less the underlying assumption of these of these methods and the important thing is that that any set of models that you want to compare, so you have the set of models.",
                    "label": 0
                },
                {
                    "sent": "Here any set of models is one such model with one connectivity structure.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and now if you want to compare different models.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you do is very high level speaking.",
                    "label": 0
                },
                {
                    "sent": "You take a look at which regions in your brain and your vote response are relevant for your task.",
                    "label": 0
                },
                {
                    "sent": "Maybe he was prior knowledge to determine that, and then for each of these regions that you believe are relevant.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You use one of these differential equations.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes we should.",
                    "label": 0
                },
                {
                    "sent": "Just to get it straight before you continue on the slide before you show.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a possible hemodynamic model, yes, and it reappears in several.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Points in the next slide, yes, so when you talk about the set of models that you check for how they fit the data, would that be the combination of that graph here, including those sub models of hemodynamic accuracy, or just the hemodynamic activity?",
                    "label": 0
                },
                {
                    "sent": "Or just know it includes the set of both?",
                    "label": 0
                },
                {
                    "sent": "OK, so for each region here you place one differential equation here that models uneral dynamics plus one equation that models or the one system that models.",
                    "label": 0
                },
                {
                    "sent": "How are these newer dynamics?",
                    "label": 0
                },
                {
                    "sent": "Translate",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the boat signal that you actually see.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "There's a lot to optimize.",
                    "label": 0
                },
                {
                    "sent": "Yes, and now let us assume that for this given setup, we only have two models that we consider plausable usually have more, but let us assume they are just two.",
                    "label": 0
                },
                {
                    "sent": "Let us assume that we want to compare these two models.",
                    "label": 0
                },
                {
                    "sent": "Which are identical in the connectivity structure here.",
                    "label": 0
                },
                {
                    "sent": "But in this model you want to test whether prefrontal, precuneus modulate sensory motor cortex and here you want to test whether the motor cortex actually modulates prefrontal importunes.",
                    "label": 0
                },
                {
                    "sent": "These are the two models that you want to compare.",
                    "label": 0
                },
                {
                    "sent": "Then you put these hemodynamics and these newer dynamics models.",
                    "label": 0
                },
                {
                    "sent": "Into your areas.",
                    "label": 0
                },
                {
                    "sent": "Here you fit the data that you observed in your program to this model you fit into that model.",
                    "label": 0
                },
                {
                    "sent": "You compare how well they fit, and then you decide that the true model is the one that has the better fit.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is the general inference procedure.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and now my main problem is here, and I think that's a very conceptual problem and this has been very nice.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Addressed.",
                    "label": 0
                },
                {
                    "sent": "In a paper by Gabriella Lumen recently, which has triggered a lot of controversy so.",
                    "label": 0
                },
                {
                    "sent": "If M does not contain the true model.",
                    "label": 1
                },
                {
                    "sent": "Which I think is unreasonable to assume the relevant question to me is is the best fitting model in M similar to the true one in terms of its connectivity structure?",
                    "label": 1
                },
                {
                    "sent": "And this is really important issue.",
                    "label": 0
                },
                {
                    "sent": "This set M contains some models.",
                    "label": 0
                },
                {
                    "sent": "That you test doesn't contain the true model.",
                    "label": 0
                },
                {
                    "sent": "I would say no, certainly not.",
                    "label": 0
                },
                {
                    "sent": "So first of all, you don't know whether the true model is contained with the true model in terms of the connectivity structure, but it goes even further.",
                    "label": 0
                },
                {
                    "sent": "The true model is really the model that exactly models to hemodynamics and your neural dynamics perfectly entails exactly how everything works.",
                    "label": 0
                },
                {
                    "sent": "We are working with models, and models are only approximations of reality, so there's no way that we can assume that in this set of models we actually have the true data generating process.",
                    "label": 0
                },
                {
                    "sent": "In there we can at best hope that we have a good approximation of it.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And then the question is if we don't have the true model in here but only good approximations of it.",
                    "label": 0
                },
                {
                    "sent": "Does best model fit translate into similarity in connectivity structure?",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is a really tough question.",
                    "label": 0
                },
                {
                    "sent": "This is not an obvious question.",
                    "label": 0
                },
                {
                    "sent": "Just because the model explains your data reasonably well doesn't mean that the connectivity structure of that model is similar to the true connectivity structure that you can't observe.",
                    "label": 0
                },
                {
                    "sent": "And this is some.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing that guaranteed Alumin investigated in a paper published in your image in 2012.",
                    "label": 0
                },
                {
                    "sent": "Yeah, can you go back to?",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "From in your brackets it says, which would be unreasonable to assume, but which would not be unreasonable to assume is what you wanted.",
                    "label": 0
                },
                {
                    "sent": "Say oh thank you.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's a typo.",
                    "label": 0
                },
                {
                    "sent": "Thank you so much.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes, of course this doesn't match which would not be unreasonable to assume.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Yeah, good.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, and this is not the paper back up little woman account little man was at the MPI Elastic and recently joined us into being so this is again a disclaimer here.",
                    "label": 0
                },
                {
                    "sent": "I'm collaborating with her so I'm a bit confounded.",
                    "label": 0
                },
                {
                    "sent": "Yes, and there's a big controversy.",
                    "label": 0
                },
                {
                    "sent": "Neuroimage going on about this, and it's very fun to read, especially cards comments.",
                    "label": 0
                },
                {
                    "sent": "And what she did is she took some data that had been published years ago with dynamic causal modeling.",
                    "label": 0
                },
                {
                    "sent": "And so she said, OK, in this publication.",
                    "label": 0
                },
                {
                    "sent": "With this data there were a few models that were plausible that were tested.",
                    "label": 0
                },
                {
                    "sent": "Now let me test a lot of unplausible models.",
                    "label": 0
                },
                {
                    "sent": "Let me randomly generate connectivity structures and let me test all these connectivity structures for how well they explain the data.",
                    "label": 0
                },
                {
                    "sent": "And now I want to see do Unplausible models really explain the data not as well as the one that had been identified as the true causal model in the original publication.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is the graph.",
                    "label": 0
                },
                {
                    "sent": "This is modesitt.",
                    "label": 0
                },
                {
                    "sent": "This is the number of models.",
                    "label": 1
                },
                {
                    "sent": "This green one.",
                    "label": 1
                },
                {
                    "sent": "That's the model fit of the original model that had been identified as the best fitting model in the original publication and higher values mean higher model fit and every blue dot.",
                    "label": 0
                },
                {
                    "sent": "Here these are models that she randomly generated and tests away.",
                    "label": 0
                },
                {
                    "sent": "They explained the data and she found that 23% all models here on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Of those models that she randomly generated, explained that that it had better than the one in the original publication.",
                    "label": 0
                },
                {
                    "sent": "That's already not good news.",
                    "label": 0
                },
                {
                    "sent": "23% of miles that you randomly generate.",
                    "label": 0
                },
                {
                    "sent": "Explain your data better than the one that you thought was the true one.",
                    "label": 0
                },
                {
                    "sent": "But I think the crucial point is.",
                    "label": 0
                },
                {
                    "sent": "Not only that, but you have to look at these models that explain the data better.",
                    "label": 0
                },
                {
                    "sent": "And are these models similar in terms of the connectivity structure to the one that was taken to be the true model?",
                    "label": 0
                },
                {
                    "sent": "Because if that were the case and all these models, they wouldn't make similar influences on your major connections in the brain.",
                    "label": 0
                },
                {
                    "sent": "Great, fine, then you would have some robustness in terms of connectivity structure.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unfortunately, she didn't find it so similarity in terms of the model fit did not translate into similarity in connectivity structure.",
                    "label": 1
                },
                {
                    "sent": "In fact, some of the best models here.",
                    "label": 0
                },
                {
                    "sent": "Where models where the stimulus didn't enter the brain or where the visual stimulus did enter the brain, but visual cortex was not connected to the rest of the brain, so they were highly implausible models in there with the connectivity structure that we know to be nonsense by our priority knowledge, and these explained the data better than the model that had been identified in the original publication as the true model.",
                    "label": 0
                },
                {
                    "sent": "And so of course the conclusion is.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, if the true model is not contained in the set of tested model, TCM is unfortunately rather likely to select a causal structure pretty much at random.",
                    "label": 1
                },
                {
                    "sent": "So why should you trust it?",
                    "label": 0
                },
                {
                    "sent": "And couldn't there also?",
                    "label": 0
                },
                {
                    "sent": "I mean, is there also the issue that that if you fit a model then you you may overfit and and you should rather look at the generalization?",
                    "label": 0
                },
                {
                    "sent": "And that could be another inference.",
                    "label": 0
                },
                {
                    "sent": "I fully agree with that, and the way that they control model fit or overfitting is by using like the AIC criterion by secret invasion generalizations of that and corriston has long argued.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether he still does that.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't do cross validation that using all the data and using controlling the complexity of your models with these methods is better than using cross validation.",
                    "label": 0
                },
                {
                    "sent": "And he has been criticized a lot for that.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether he has changed his.",
                    "label": 0
                },
                {
                    "sent": "Used by now, but I also think that it would be very important to check the generalizability of these models, but I haven't seen that yet.",
                    "label": 0
                },
                {
                    "sent": "Because then, if this was properly done.",
                    "label": 0
                },
                {
                    "sent": "My.",
                    "label": 0
                },
                {
                    "sent": "Hope would be that that this solution would not be the same.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, you would hope that all these models out here would end up over there.",
                    "label": 0
                },
                {
                    "sent": "Lucas so I can help but notice that original model probably lies around the median of all.",
                    "label": 0
                },
                {
                    "sent": "Does random moles have they looked at why?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's looks kind of good.",
                    "label": 0
                },
                {
                    "sent": "Not that I know of.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, I think Lumen and I raised the issue that model validation is not done in terms of absolute value, it's just that the models that are that are inserted to the to the TCM procedure are compared amongst each other.",
                    "label": 0
                },
                {
                    "sent": "But the model fit is not really looked at.",
                    "label": 0
                },
                {
                    "sent": "You know, could you?",
                    "label": 0
                },
                {
                    "sent": "You don't, that's how well the model explains the data measured.",
                    "label": 0
                },
                {
                    "sent": "I think that's part of the this part of the procedure.",
                    "label": 0
                },
                {
                    "sent": "I think they do compute model fit.",
                    "label": 0
                },
                {
                    "sent": "I think Gary Lumen has indeed argued that that.",
                    "label": 0
                },
                {
                    "sent": "But the way that modified is evaluated in the procedure is not the best way that you could do it, but I think in general it is being evaluated.",
                    "label": 1
                },
                {
                    "sent": "At least models are scored according to the Model Fit.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, so this is actually a proposed method too.",
                    "label": 0
                },
                {
                    "sent": "OK, say that some random model perfectly and perform better than the one that was cleverly fought and put inside the original set of tested models.",
                    "label": 0
                },
                {
                    "sent": "But then why not just?",
                    "label": 0
                },
                {
                    "sent": "OK, do a similar procedure and then remove from this set than biologically implausible models and then pick up the yeah.",
                    "label": 0
                },
                {
                    "sent": "Remaining best one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the argument there goes.",
                    "label": 0
                },
                {
                    "sent": "If DCN cannot reasonably well discriminate between plausable an unplausible models and cannot even rank them WHI, should we believe that it can properly rank plausable models?",
                    "label": 0
                },
                {
                    "sent": "At the beginning, you in fact showed that first and asked for only entering possible models into that can you can you expand on that a little bit.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "I think the reason for that is that of course in theory you would like to test all possible models that there are, but that's a combinatorial explosion and presently difficult to handle.",
                    "label": 0
                },
                {
                    "sent": "Maybe it can be handled in the future, and so initially firstness colleagues have.",
                    "label": 0
                },
                {
                    "sent": "I've argued that he should only enter the few models that you think to be plausable.",
                    "label": 0
                },
                {
                    "sent": "Anyhow, to reduce the computational load.",
                    "label": 0
                },
                {
                    "sent": "But I think they are extending these.",
                    "label": 0
                },
                {
                    "sent": "Methods to search bigger spaces of models.",
                    "label": 0
                },
                {
                    "sent": "My question is just regarding whether this.",
                    "label": 0
                },
                {
                    "sent": "In Lomas paper this is the best plausable model.",
                    "label": 0
                },
                {
                    "sent": "Actually the one that was chosen and the other 23% were all implausible.",
                    "label": 0
                },
                {
                    "sent": "The war also plausible once they were also plausibly once among them, yes, but they were also very implausible ones.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me move on.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I think ECM.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is not provably correct under reasonable assumptions, sorry.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, I don't see how it makes Testament inventions.",
                    "label": 0
                },
                {
                    "sent": "I mean, in general you could try to fit around with these nonlinear differential equations or bilinear differential equations and test how you would have to intervene to make the system behave in a certain way.",
                    "label": 0
                },
                {
                    "sent": "But that's again a really tough inference problems.",
                    "label": 0
                },
                {
                    "sent": "It's not straightforward, probably can be done, but it's not easy so.",
                    "label": 0
                },
                {
                    "sent": "I don't like that.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hidden confounders never seen that addressed in this framework empirical performance.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, from the luminosity would say no.",
                    "label": 0
                },
                {
                    "sent": "Sorry no way.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, nonlinear caution, acyclic models and this is going to be rather brief and this is more recent work done at the Max Planck Institute.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you have two datasets.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "It's the same data set, it's exactly the same data here, and here is just flipped.",
                    "label": 0
                },
                {
                    "sent": "The X axis is now here and the Y axis is now there and this data has been fitted with a nonlinear curve.",
                    "label": 0
                },
                {
                    "sent": "Now I want you to guess which is the cause of direction.",
                    "label": 0
                },
                {
                    "sent": "Here X generates Y and here Y generates X.",
                    "label": 0
                },
                {
                    "sent": "And what do you think which direction is the true cause of one?",
                    "label": 0
                },
                {
                    "sent": "And can you even come up with some intuition why that might be the case?",
                    "label": 0
                },
                {
                    "sent": "It's tough.",
                    "label": 0
                },
                {
                    "sent": "OK, so the reason why didn't you say in the Bayesian network case that you need more than two variables?",
                    "label": 0
                },
                {
                    "sent": "Yes, in conservation networks you do that, but if you're willing to make additional assumptions you don't.",
                    "label": 0
                },
                {
                    "sent": "And Dominic dancing and Patrick Oyer who were the guys who were most responsible for this, they introduced additional assumptions that they think are reasonable, under which you can look at the bivariate case.",
                    "label": 0
                },
                {
                    "sent": "And this is one of their examples.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, I would assume that there's not only X&Y, but there's also noise added to something, so we probably have to look at the spread of the execution in some way.",
                    "label": 0
                },
                {
                    "sent": "The point is, you look at the noise, but we couldn't figure out whether it's left or the right now, so the idea is that you look at the residual CMU try to fit a nonlinear curve that explains, as we say, right because it just to say something.",
                    "label": 0
                },
                {
                    "sent": "Thank you close.",
                    "label": 0
                },
                {
                    "sent": "You look at the noise, the residuals and the idea is that here the residuals are largely independent of X.",
                    "label": 0
                },
                {
                    "sent": "The noise here is more or less the same no matter which X you look at.",
                    "label": 0
                },
                {
                    "sent": "Of course, you observe less and it's here, but here the noise depends on the value here, so here the noise seems to be.",
                    "label": 0
                },
                {
                    "sent": "The residuals seem to be be depend on your X and here they not depend on the accent.",
                    "label": 0
                },
                {
                    "sent": "Here they do.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in fact, this is this data from shell from shellfish, and this is the age of the fish and this is its length.",
                    "label": 0
                },
                {
                    "sent": "Of course, by a priori knowledge is reasonable to say OK, the age causes the length and not the other way round, so this would be the true cause of direction or not that one.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This can be formalized a bit, so let us assume that the relation between Y&X is some nonlinear function that X generates Y through some nonlinear function, and then we have some additive noise and and this is the crucial assumption.",
                    "label": 0
                },
                {
                    "sent": "Here we have additive noise and this noise is to assume to be independent of X and it's just edit on top, doesn't tell us anything about X.",
                    "label": 0
                },
                {
                    "sent": "And all the question that that Patrick and Dominic and balance on asked is, can you invert this model?",
                    "label": 0
                },
                {
                    "sent": "Can you take the same?",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Joint distribution, but right this model the other very Rhonda's X being oops X being an only a function of why this would be why?",
                    "label": 0
                },
                {
                    "sent": "Sorry?",
                    "label": 0
                },
                {
                    "sent": "Plus some noise variable.",
                    "label": 0
                },
                {
                    "sent": "And if you do that can you still find LG such that X and sorry Y and enter our independent?",
                    "label": 0
                },
                {
                    "sent": "So we assume that in the generative model there's independent noise.",
                    "label": 0
                },
                {
                    "sent": "Edit On top of it.",
                    "label": 0
                },
                {
                    "sent": "Now if you model the other way round, can you still do that with independent noise?",
                    "label": 0
                },
                {
                    "sent": "Or does the noise have to be dependent?",
                    "label": 0
                },
                {
                    "sent": "And that would be this thing here.",
                    "label": 0
                },
                {
                    "sent": "Here the noise is largely independent of the value on the X axis.",
                    "label": 0
                },
                {
                    "sent": "Here the variance of the noise varies as a function on the X axis.",
                    "label": 0
                },
                {
                    "sent": "That's the assumption that you put in and there.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result is in generally no, you can't write it the other way round.",
                    "label": 0
                },
                {
                    "sent": "If there is here independence and is independent of X, then if N is if everything is caution and F is linear, then you can write it the other way round and they even some very obscure cases where you can also write it the other way around.",
                    "label": 0
                },
                {
                    "sent": "For more complex cases.",
                    "label": 0
                },
                {
                    "sent": "But in general it's not possible.",
                    "label": 0
                },
                {
                    "sent": "It's very unlikely to be possible and this is their inference procedure.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what they do is they observe N samples of two variables X&Y.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then they perform a non linear regression from X to Y and they test whether the residuals of this regression.",
                    "label": 0
                },
                {
                    "sent": "Are independent of the regressor.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then they do it the other way round.",
                    "label": 0
                },
                {
                    "sent": "Perform nonaggression from Y to X, and again test for independence of the residuals and the explanatory variable.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if they find that these residuals between Y&X are independent, they decide that X causes Y.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If they find it the other way round, they decide that Y causes.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if they don't have enough evidence for one or the other, they decide that we don't really know.",
                    "label": 0
                },
                {
                    "sent": "And this is very simple inference procedure and they have collected lots of datasets where we know the causal relation are priority.",
                    "label": 0
                },
                {
                    "sent": "For example, they collect data from the River Rhine and the water levels of the Rhine and they know from the flow of the Rhine that water levels in Switzerland cause water levels in Germany and so on.",
                    "label": 0
                },
                {
                    "sent": "And they collected lots of datasets like that and tested how work performed and it was not too bad I think.",
                    "label": 0
                },
                {
                    "sent": "Also like 68% or so.",
                    "label": 0
                },
                {
                    "sent": "So it seems to be a reasonable assumption that doesn't always hold, of course, but that allows you to do some causal inference between bivariate variables.",
                    "label": 0
                },
                {
                    "sent": "Can you, can you?",
                    "label": 0
                },
                {
                    "sent": "You know 'cause this is it custom to a testing framework?",
                    "label": 0
                },
                {
                    "sent": "I don't recall this paper because you you should also.",
                    "label": 0
                },
                {
                    "sent": "So what are the conditions not to accept either one?",
                    "label": 0
                },
                {
                    "sent": "That's yeah, this is of course, there's of course very variable.",
                    "label": 0
                },
                {
                    "sent": "Where do you choose?",
                    "label": 0
                },
                {
                    "sent": "You cut off and in the end in the paper that NIPS 2008, they again used H62.",
                    "label": 0
                },
                {
                    "sent": "Actually kind of based on linear regression.",
                    "label": 0
                },
                {
                    "sent": "And then they tested the residuals with IHC test and looked at which residuals for more independent than the other in the one way or the other way.",
                    "label": 0
                },
                {
                    "sent": "And if they didn't find a big difference, they didn't decide if they found a big difference data.",
                    "label": 0
                },
                {
                    "sent": "They decided for one cause of direction.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So non lingam proof be correct in a reason.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assumptions in arm.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether I should have put a green mark there.",
                    "label": 0
                },
                {
                    "sent": "It is probably correct and assumptions, but whether they are reasonable or not to have this additive noise models OK, there's a big question.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Test interventions, yes.",
                    "label": 0
                },
                {
                    "sent": "They give you tested interventions.",
                    "label": 0
                },
                {
                    "sent": "They tell you with this nonlinear regression what exactly you have to do.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I haven't spoken about hidden confounders, but they have continued working on that, so there are methods in this framework to take care of hidden confounders.",
                    "label": 0
                },
                {
                    "sent": "OK, so the last thing that in each address is empirically performance, of course improved.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performance is really tough because we don't have ground truth data sets in your imaging.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there is a great study by Steve Smith at Oxford that he published in 2011 in your image and what he did there.",
                    "label": 0
                },
                {
                    "sent": "Is he used these dynamic causal modeling models.",
                    "label": 0
                },
                {
                    "sent": "This differential equation systems.",
                    "label": 0
                },
                {
                    "sent": "To generate lot of simulated data, because these models asked her the best models that we have for my data and he had 28 different simulations.",
                    "label": 0
                },
                {
                    "sent": "Lots of different parameters and lots of different lengths of data recording.",
                    "label": 0
                },
                {
                    "sent": "And then you tested a variety of causal inference methods where they performed.",
                    "label": 0
                },
                {
                    "sent": "If you have the direct transfer function Lingam, that's the linear version of this non linium.",
                    "label": 0
                },
                {
                    "sent": "That address presented partial directed coherence.",
                    "label": 0
                },
                {
                    "sent": "This is a variant of DTF base Nets.",
                    "label": 0
                },
                {
                    "sent": "That's the conservation networks Granger causality.",
                    "label": 0
                },
                {
                    "sent": "And generalized synchrony patterns tower two measures that are more heuristics that people proposed.",
                    "label": 0
                },
                {
                    "sent": "And I'm showing this graph for one reason a.",
                    "label": 0
                },
                {
                    "sent": "And all of the algorithms performed really well.",
                    "label": 0
                },
                {
                    "sent": "Pretty much they're all pretty bad.",
                    "label": 0
                },
                {
                    "sent": "50% would be absolute chance level.",
                    "label": 0
                },
                {
                    "sent": "This Gray line means above chance level and only a few algorithms are above chance level.",
                    "label": 0
                },
                {
                    "sent": "So if you believe that this dynamic causal models are a good approximation of reality.",
                    "label": 0
                },
                {
                    "sent": "And then you apply a different inference algorithms to that you won't do very well.",
                    "label": 0
                },
                {
                    "sent": "But, and this is also something important.",
                    "label": 0
                },
                {
                    "sent": "There are some methods that perform above chance level that's already something.",
                    "label": 0
                },
                {
                    "sent": "I mean 'cause it interest such a hard task and it will be unreasonable to assume that you always get the correct result.",
                    "label": 0
                },
                {
                    "sent": "But you have algorithms that can perform above chance level is already quite something is really quite amazing.",
                    "label": 0
                },
                {
                    "sent": "So this brings me to my so.",
                    "label": 0
                },
                {
                    "sent": "First of all just one question.",
                    "label": 0
                },
                {
                    "sent": "So on the left this is the method you didn't.",
                    "label": 0
                },
                {
                    "sent": "This is heuristic, so through your graph it says the heuristics best.",
                    "label": 0
                },
                {
                    "sent": "Yes indeed it supported stores, I think published in 2008 in human brain mapping and it's really just a heuristic, but it seems to work well.",
                    "label": 0
                },
                {
                    "sent": "I don't understand it why so I didn't talk about it here, but it's an interesting paper.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne, OK.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think an Imperial terms of empirical performance and none of the algorithms works reliably, but some work above chance level and this.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some important consequences for when calls that infants should be used and when it should not be used.",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, every causal inference algorithm rests on untestable assumptions.",
                    "label": 0
                },
                {
                    "sent": "You have to decide whether you're willing to accept these assumptions or not, and please be open about these assumptions.",
                    "label": 0
                },
                {
                    "sent": "That's something that's important to me.",
                    "label": 0
                },
                {
                    "sent": "And I want to illustrate why I had a chat with a neurosurgeon sometime ago and this neurosurgeon told me, oh I had this.",
                    "label": 0
                },
                {
                    "sent": "I have this patient and I read about this paper on Granger causality and they showed that there is a causal relation between brain areas A&B and I think that's relevant for this patient.",
                    "label": 0
                },
                {
                    "sent": "I will now implant an electrode in this patient and stimulate him with a deep brain stimulation chronically implant and was like, oh, you know that Granger causality is not that reliable and that you assuming that there are no hidden confounders.",
                    "label": 0
                },
                {
                    "sent": "So be careful.",
                    "label": 0
                },
                {
                    "sent": "Was like no, I'm not interested in mathematical details.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in the practicality of this.",
                    "label": 0
                },
                {
                    "sent": "And we'll say, yeah, but you know your assumptions.",
                    "label": 0
                },
                {
                    "sent": "They are practically relevant.",
                    "label": 0
                },
                {
                    "sent": "But he didn't care about that.",
                    "label": 0
                },
                {
                    "sent": "And I think in neuroscience often people are not careful enough with stating their assumptions.",
                    "label": 0
                },
                {
                    "sent": "And if you are writing such a paper, Please remember that you are honest about it, because if you're not honest about it over say, your results, some crazy neurosurgeon may decide to open up the brain of a patient and plug electrodes in because of your paper.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So several causal inference algorithms appear to perform at least above chance level, and this is already quite amazing.",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that for me means cause inference maybe?",
                    "label": 0
                }
            ]
        },
        "clip_169": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Full to guide the design of interventional studies and there's a wonderful example by group.",
                    "label": 0
                },
                {
                    "sent": "From ETA to Zurich, not on your imaging published Nature Methods in 2010, and they worked with plant biologists.",
                    "label": 0
                },
                {
                    "sent": "These plant biologists.",
                    "label": 0
                },
                {
                    "sent": "They do genetic interventions on their plants and they grow these plants.",
                    "label": 0
                },
                {
                    "sent": "This genetically modified plants and observe what effects this genetic interventions had.",
                    "label": 0
                },
                {
                    "sent": "But most genetic interventions don't lead to plants that grow.",
                    "label": 0
                },
                {
                    "sent": "Most plants die before they flower intends to constitute a better data point.",
                    "label": 0
                },
                {
                    "sent": "And this is time consuming and costly and they try to reduce these costs.",
                    "label": 0
                },
                {
                    "sent": "They try to predict which genetic interventions would lead to flowering plants that give you a reason.",
                    "label": 0
                },
                {
                    "sent": "A good data point.",
                    "label": 0
                },
                {
                    "sent": "And they compared normal prediction methods with causal inference.",
                    "label": 1
                },
                {
                    "sent": "Methods on could show that by using causal inference methods they could significantly reduce the number of experiments they had to do on average to get one good data point.",
                    "label": 0
                },
                {
                    "sent": "And this saves a lot of time and money.",
                    "label": 0
                },
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "This is really reasonable.",
                    "label": 1
                },
                {
                    "sent": "This is great because there you have a study where it doesn't matter so much whether one causal inference is correct or not.",
                    "label": 0
                },
                {
                    "sent": "If you're in buff chance level, on average, it will help you design your studies.",
                    "label": 0
                }
            ]
        },
        "clip_170": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I think it's also OK to use causal inference when you qualitative conclusions do not depend on individual results.",
                    "label": 0
                },
                {
                    "sent": "If you have 1000 tests that you can do and you qualitative conclusions only depend on being right on average, then I think it's OK.",
                    "label": 0
                },
                {
                    "sent": "User info.",
                    "label": 0
                }
            ]
        },
        "clip_171": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But be very careful at present, at least to use causal inference when you qualitative conclusions depend on one individual inference, because most likely you will be correct with the chance of I don't know, 58 percent, 56 percent 61%, so don't trust causal inference too much.",
                    "label": 1
                },
                {
                    "sent": "OK, that brings me to the end of the talk.",
                    "label": 0
                },
                {
                    "sent": "I have two more slides that are private advertisements.",
                    "label": 0
                },
                {
                    "sent": "I hope that's OK for the organ.",
                    "label": 0
                }
            ]
        },
        "clip_172": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, I'm organizing this pattern.",
                    "label": 0
                },
                {
                    "sent": "Recognition your image in workshop on my 2014 tubing clouds is actually one of our invited speakers.",
                    "label": 0
                },
                {
                    "sent": "We have a great program.",
                    "label": 0
                },
                {
                    "sent": "It's from June 4 to 6 and this is a small conference with roughly 100 people.",
                    "label": 0
                },
                {
                    "sent": "Great machine learners who knew your image Ng.",
                    "label": 0
                },
                {
                    "sent": "So if your machine learning person and or you want to know more about machine learning for neuroimaging, I think this is the place to go.",
                    "label": 0
                },
                {
                    "sent": "Submission Deadline is March 7th and it would be great if I would see some of you back into Bingham and also.",
                    "label": 0
                },
                {
                    "sent": "And we're currently looking for one year PhD student, so please forgive me for making an advertisement for that.",
                    "label": 0
                },
                {
                    "sent": "So in the stroke project we want to find the causal newer processes that are causally relevant for structure abilitation.",
                    "label": 0
                },
                {
                    "sent": "We're looking for one year PhD student with a background engineering, computer, science, mathematics.",
                    "label": 0
                },
                {
                    "sent": "And was interested in causal inference and neuroscience.",
                    "label": 0
                },
                {
                    "sent": "And if you're interested, please to send me an email.",
                    "label": 0
                },
                {
                    "sent": "And also all my slides and the references to all papers that I have mentioned today can be downloaded on my homepage and the password for that is BBC 2014.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "I'm looking for discussions.",
                    "label": 0
                }
            ]
        }
    }
}