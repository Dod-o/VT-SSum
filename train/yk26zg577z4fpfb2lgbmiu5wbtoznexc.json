{
    "id": "yk26zg577z4fpfb2lgbmiu5wbtoznexc",
    "title": "PAC-Bayes Analysis: Links to Luckiness and Applications",
    "info": {
        "author": [
            "John Shawe-Taylor, Centre for Computational Statistics and Machine Learning, University College London"
        ],
        "published": "April 14, 2010",
        "recorded": "March 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/pacbayesian_shawe_taylor_pba/",
    "segmentation": [
        [
            "And I have that discussion.",
            "Really this is more at the level you know David.",
            "What was the word used?",
            "Lucy Lucy Lucy I like that yeah Lucy Lucy discussion unluckiness and."
        ],
        [
            "Sort of forward pointers to guy and she lands, talks and then I've got two applications I probably won't do both.",
            "I might skip this and then just talk a little bit about this.",
            "'cause I'd like to get.",
            "Matthias is views on this.",
            "So OK, so really to this was going back to the."
        ],
        [
            "Luckiness definitions in the paper that.",
            "We did back in in 98 and Martin's here, so this is good stuff.",
            "So we were looking there at trying to understand how large margin classification works and we you know.",
            "Came up with this idea of Luckiness function, which was I think, probably overkill for the application.",
            "It was, so the idea was you had this function that measured how compatible the sample was with the functions in the class, and obviously the one we were interested in was the margin, which was quite nice.",
            "So it was sort of a measure of fit between hypothese."
        ],
        [
            "Listen training samples and then you had this sort of level of luckiness that came out of that which was basically sort of the class of functions that were luckier than your particular one.",
            "You were interested in.",
            "So sorry, the set of functions, so it was a bit like pruning the space in the way that John was talking about.",
            "And then there was something called.",
            "You know any old Luckiness function wouldn't do because you had to be able to kind of go from a single to a double sample.",
            "So there was this thing that we called probable smoothness.",
            "I think it was.",
            "And it was again a rather complicated definition which I won't give you.",
            "And anyway to."
        ],
        [
            "Applied to this large margin classification and that was the motivating example.",
            "Luckiness was measured by the margin on the sample."
        ],
        [
            "And then the problem was that the ranking of the hypothesis could not be made until you'd seen the sample.",
            "So it appeared you needed to have this sort of way of measuring quality by this luckiness function, and probable smoothness was really about saying that this could be this sort of quality of hypothesis could be estimated from the sample as well as save the learning and would sort of carry forward to new samples."
        ],
        [
            "The problem with Luckiness is sort of a story with the margin.",
            "Is that actually it can be solved without really going into this rather complicated setup, because you can sort of convert to real valued functions, require the outputs to be plus and minus one on the on the on the negative and positives, and then you measure complexity by the normal weight vector, which is doesn't depend on the sample, so you just minimize, you know in the normal way the normal weight vector and that sort of measures your complexity.",
            "So you sort of have a way around this rather complicated.",
            "Construction.",
            "That we'd created."
        ],
        [
            "So that's sort of obscures the role of luckiness in capturing this alignment between hypothesis and data generating distributions.",
            "I mean what we, you know, the thing we were really trying to capture with this idea, that the density of the distribution close to the hyperplane being being low would mean the hyperplane is a good one and should be given a higher weighting.",
            "Or you know higher luckiness in this.",
            "In this sense, so this is actually related to the idea of compatibility that Balcon and Bloom introduced in a semi supervised setting where they were using unlabeled data."
        ],
        [
            "To measure compatibility of functions and then they would reduce their set of functions that considering so sort of prune down their class of functions using this compatibility measure.",
            "And it's all."
        ],
        [
            "So related to the local PAC Bayes analysis of Olivia Kotone.",
            "Who uses a prior distribution generated ID from the data sample?"
        ],
        [
            "So this is what I'd like to just think about a bit more defining priors from data distributions, which I think is the sort of thrust that we were essentially trying to get at with the with the margin idea or with the luckiness idea.",
            "So there are various ways of doing this, so defining priors from data distribution.",
            "So the idea is that you want to.",
            "Not just having apriori defined prior, but you'd like to have the IT will be defined prior to seeing the actual data sample.",
            "But you're thinking that being dependent or some way a function of the data generating distribution.",
            "OK, so you wouldn't actually be able to write it down because you don't know what the data generating distribution is.",
            "You're only going to learn about it through the sample, but as you learn about as you look at the sample you learn about the data generating distribution, but you also then also learn the function.",
            "That you're trying to, actually, you know the classifier or whatever regressive which approaches that.",
            "You're so one way of doing this is sort of very.",
            "Natural thing to do is to just split the training data in half and use half of it to learn a prior and then use the second half to learn a function in that prior and indeed Francois mentioned results of this type in his talk this morning and Amelia will give some results using this approach later on where we use prior, possibly to guide the learning or just to to actually inform the.",
            "The bound.",
            "Both cases."
        ],
        [
            "But you could use also expectation over the two true distribution of some other function, like this one here.",
            "So you say, OK, my prior is going to be a Gaussian centered at this weight vector, which is the expectation under the true distribution of Y * 5 X. I'm thinking of projecting into a feature space here, so that's a you know uniquely defined distribution.",
            "Or you could in."
        ],
        [
            "And indeed, take a more complicated thing and say look, I'm going to have some.",
            "Number of samples and not less than M and I'm going to consider samples of that size.",
            "Generate an SVM on samples of that size and take the expected value of that as the center of my Gaussian.",
            "So this is now my prior.",
            "Of course, I don't know what it is, but I can estimate it because I can estimate this with high probability from the sample.",
            "This value and similarly this one by just, you know, taking samples of size N nought and."
        ],
        [
            "So in in the latter cases, you can use empirical version."
        ],
        [
            "Of this actual power bound, the difference between the empirical versions and the true the data distribution prior.",
            "And then."
        ],
        [
            "And use this to upper bound the KL between true prior and posterior, right?",
            "So you don't compute the true prior you bound yes.",
            "Of course, if you know if you're using Gaussians, all this is just bounding norms of the differences between weight vectors, so you can actually upper bound this KL."
        ],
        [
            "So the complexity term now will typically decay with increasing sample size.",
            "So rather than having a KL, you're sort of having a KL that will decay in your PAC Bayes bound, so she Lang will will describe this theory for this case, and Amelia will."
        ],
        [
            "Some afraid not very exciting empirical results, but anyway, empirical results."
        ],
        [
            "Um?",
            "We can also define the prior based on the true risk and this is.",
            "You know what's a Livia was doing kotone, and you know, or the expectation of over support vector machine weights on samples of training set size M. And."
        ],
        [
            "Guy will be presenting tighter bounds.",
            "With extensions to manifold learning based on this idea.",
            "And this is."
        ],
        [
            "To say is closer to Kotone's approach, so I just wanted to sort of paint that picture and I think link back to the Luckiness framework to try and sort of motivate some of this this work, but I'm not going to move on and if there are any questions about that.",
            "OK. OK, so."
        ],
        [
            "So the."
        ],
        [
            "I'm going to skip this."
        ],
        [
            "Maximum entropy."
        ],
        [
            "Because I only got."
        ],
        [
            "Short period, so I'm."
        ],
        [
            "No."
        ],
        [
            "Skip through."
        ],
        [
            "Due to the."
        ],
        [
            "Gas."
        ],
        [
            "In process regression."
        ],
        [
            "So.",
            "Gassing process GP is a distribution over the real valued functions that is a multivariate Gaussian when restricted to any finite subset of inputs.",
            "It's characterized by a kernel that spell."
        ],
        [
            "Advise the covariance function when marginalizing."
        ],
        [
            "On any finite subset, if you have a finite set of input, output observations generated with additive Gaussian noise, then the posterior is also."
        ],
        [
            "A Gaussian process and we can workout the KL divergent between prior and posterior.",
            "Where here is 1 formula for that?",
            "OK so."
        ],
        [
            "Question now is, this suggests using a PAC Bayes theorem which goes back to quite a long way.",
            "Index by real value."
        ],
        [
            "It functions and the way we choose."
        ],
        [
            "So look at doing this.",
            "Is to just turn them into classifiers using this, you know, sort of epsilon tube tricks.",
            "So basically, if the classifier, sorry if the function that we were looking at for a particular input an output is within epsilon of the desired output, then you say tick otherwise 0.",
            "So it's a bit counterintuitive 'cause I've turned it around.",
            "You know, in terms of the higher the score, the better rather than you know this is not an error measure, it sort of an accuracy measure.",
            "And you can compute the expected value of this under the posterior function and and it's an exact computation.",
            "So basically you can just crank the hand."
        ],
        [
            "Evil.",
            "And you apply a pacbase bound.",
            "There's a little bit of a trick in terms of the.",
            "Sort of, the variance that you need to handle, but you can get a lower bound on the expected probability.",
            "Sorry, the probability of your output in the posterior distribution.",
            "And this is the form that it actually ends up as the expected value of the output in the posterior distribution plus this sort of adjustment factor is lower bounded by this quantity.",
            "Where?",
            "E of epsilon.",
            "This is KL inverse, so it's just the you know the value that the maximum value that's consistent with this empirical value.",
            "And this you know KL divergent between this value and this.",
            "And this is the empirical value of which I just showed you on the previous slide.",
            "You hear evaluated empirically on the sample.",
            "And.",
            "D is the KL divergent that I had on a few slides earlier.",
            "That's here between prior posterior.",
            "So this is a I think quite an interesting idea, but maybe I would just be interested to hear views.",
            "Also, you know particularly media this view, but I think you know the idea that you can get some.",
            "So in a way you know there's this question.",
            "What is PAC bayes?",
            "Giving us?",
            "The Bayesians don't already have, so I think one thing is that we're weakening our assumptions and we're not making any.",
            "Belief in the correctness of the prior.",
            "We're only saying this is true.",
            "With high probability, under the IID assumption.",
            "Of course, if we have a bad prior, then this will be a very weak result.",
            "But if it's a good prior, it will hold and give us useful information hopefully.",
            "So just to show some experimental results."
        ],
        [
            "On various example problems.",
            "So there are three datasets here, robot arm problem busting 1000 and the forest fire problem, and these are the lower bounds and this is the empirical test, so they're not actually, you know that bad in terms of they seem to be giving us some.",
            "You know reasonable bounds on the actual test performance.",
            "And the nice thing about this is we can apply it even when you know the exact Bayesian inference breaks down.",
            "You know this is a variational where we looking at a different noise model.",
            "I think the Laplace noise and we get a higher lower bound and more accurate in this case for that particular data set.",
            "So again, it seems to be giving the right indication of the the the more.",
            "Correct noise model in that situation?"
        ],
        [
            "Um, these are plots that show how things vary as we vary the epsilon.",
            "If you remember there was that epsilon of the size of the tube, and as we increase epsilon, of course we get more and more accurate because more and more things fall inside the tube.",
            "But this is a match between the bound and the actual empirical test error.",
            "And there seems to be sort of a reasonable surprising shape match as well.",
            "In some of these.",
            "Uh.",
            "This is for varying noise level eater measures the noise."
        ],
        [
            "And this is with the Laplace noise I mentioned before.",
            "OK, so again, we might be able to even distinguish different types of noise."
        ],
        [
            "And these are.",
            "So those before sorry those two pre those previous plots were for artificial data 6 plus these three in this.",
            "And this is for real data, so it's a lot looser, but still seems to be tracking a reasonably similar shape.",
            "OK, so."
        ],
        [
            "Actually, we did this two things in the other order.",
            "I mean actually where we started was looking at this stochastic differential equation work.",
            "And I should say all of this work.",
            "I mean, I mentioned in the beginning is jointly with Manfred Opper, Cedric Archambeau and Matt Higgs has also been involved, and so there's been quite a team of people involved in this.",
            "But this was part of a project we were looking at doing inference in with priors that were defined by nonlinear stochastic differential equations.",
            "So that gives you a prior over possible paths.",
            "And the idea was to use variational inference so the posterior would be defined by a time varying linear differential equation.",
            "And the idea was that you would then optimize the posterior to two.",
            "Minimize the KL divergent between prior and posterior distributions.",
            "So here the this is the nonlinear."
        ],
        [
            "If term.",
            "DW zevina process."
        ],
        [
            "And this is sort of time limit of the discrete time equation.",
            "Which is given by this.",
            "This form here with these are Gaussian.",
            "Unit variance, Gaussian noise."
        ],
        [
            "So the Bayesian approach to data modeling with the noise model given by this.",
            "So there's an observation fixed here observation linear observation matrix H, taking the state too, and this is then modeled as a Gaussian with some.",
            "Observation color to it."
        ],
        [
            "And what we're doing, as I said, is to use a variational approximation with a time varying linear.",
            "So this is the linear approximation which is given by this linear a matrix A of T and offset B of T. But this is varying with time.",
            "Hey."
        ],
        [
            "So the measure over the.",
            "Pause given by the prior is defined to be P and the one for the posterior IQ."
        ],
        [
            "You can actually workout the KL divergent in this infinite dimensional setting by using the raddon nikodym derivative of Q with respect to P, which can be computed.",
            "And.",
            "So this actually allows you to compute this KL divergent even though the prior is not a Gaussian or process, so it's an only if you know if it's a linear differential equation, then the paths.",
            "Distribution is a Gaussian process, but for nonlinear it's not.",
            "So you can compute this even though because the posterior is Gaussian, you can actually compute this.",
            "Um?"
        ],
        [
            "And so it's actually this quantity where cutey is the marginal distribution at time T, and you have to integrate over the.",
            "The time and this is the nonlinear drift.",
            "This is the linear drift term.",
            "This is the fixed again covariance matrix.",
            "OK, so that's that's how you compute it.",
            "This is approximating Estey.",
            "The marginal distribution is it is."
        ],
        [
            "Gaussian and."
        ],
        [
            "You can compute the mean and covariance of that marginal by these ordinary differential equations.",
            "So I'm skipping quite fast over stuff here, so."
        ],
        [
            "Using the Grandjean methods, you can derive an algorithm that finds the variational approximation by minimizing this KL divergent between posterior and approximating."
        ],
        [
            "Distribution, so there's a natural question.",
            "Can you plug all that?",
            "Come on, we're minimizing the KL divergent to get a fit between on on some samples.",
            "Surely we can get a pack base.",
            "Application here.",
            "So the idea is to you want to Los Overpass the paths.",
            "I like your hypothesis in such a way that you can apply the capture the properties that you're interested in.",
            "An applied math based."
        ],
        [
            "So it's you know it's taking the idea that I presented for the Gaussian process and just applying it in this more complicated setting.",
            "Again, we have a tube around the path.",
            "Applying I mean the path is in the sort of state space, so we have to apply the observation operator and then take a norm being less than epsilon.",
            "Then we get a hit.",
            "That's a that's a good one, and we're trying to, you know, increase the accuracy, get as accurate as possible."
        ],
        [
            "So this is again the actual observations are linear functions of the state variable given by this operator H."
        ],
        [
            "Prior and posterior distributions over functions are inherited from the P&Q distributions over paths.",
            "Because these functions are just indexed by the path.",
            "So the prior is as I said, it's a non Gaussian distribution defined by this non."
        ],
        [
            "Near stochastic differential equation and the posterior is is this Gaussian process?"
        ],
        [
            "So we were able to compute the KL as I indicated earlier.",
            "We need to also compute EQ&E hat Q."
        ],
        [
            "So the way in which we want to look at this is the expected sort of value of this, which is the East of Cuori Hat Q, which is the expected value that probability that this is less than or equal to epsilon, and so here."
        ],
        [
            "Things get a little bit approximate because we basically will approximate that with.",
            "Looking at the as if you're in a region of uniform density.",
            "So we just look at the volume of the sphere around this point and then this is the probability of the center.",
            "So this is probably a little bit suspect.",
            "I would say here, but it will be good when you're close to accurate, it will be very bad as you move away from the center of the distribution.",
            "OK, so that's the way anyway.",
            "We've been looking at it at the moment."
        ],
        [
            "And so you end up with EQ being approximately equal to, or at least proportional to, this again accuracy.",
            "So what we're doing is the expected accuracy of the likelihood of the observation.",
            "In the marginal distribution that we've got, the posterior distribution, so you're computing this posterior distribution.",
            "You pick a time and what you're interested in, how probable was the observation at that time and your lower bounding that probability as your measure of quality of your your modeling."
        ],
        [
            "So there's a slight problem.",
            "This is more like a technical detail that the in setting this this epsilon tube size.",
            "Because if you're setting epsilon too large, you get the approximation is inaccurate.",
            "On the other hand, if."
        ],
        [
            "Sun is too small then both EQ and he had Q become very small and so the bound implied by this KL divergences becomes very weak because they're both very small."
        ],
        [
            "So the way we you can overcome that is by doing this sort of multiple sampling tricks so you can take a K fold product of paths.",
            "You just sample K paths and then you say I'm accurate.",
            "If I'm in at least one of the paths, so this will up the likelihood of you hitting on one of your paths from from the posterior sample, and."
        ],
        [
            "And you can see that now that.",
            "The chances of you not hitting a path can be essentially is approximately K times the probability that you are.",
            "You know the accuracy, so plugging all this together, you get a bound of the following form, which looks pretty messy.",
            "I have to admit, but basically again lower bounds.",
            "The accuracy of your, you know your posterior.",
            "Observations, so your sum your test observation."
        ],
        [
            "In terms of the quality of your empirical fit, an this KL divergent's that you measure between your posterior and prior where you know you can you can integrate this in the way that I indicated.",
            "That's the same formula as before."
        ],
        [
            "So here's the sort of.",
            "Most complicated example we've run, which is the ruins the tractor, and here's some observations and sort of the true path and the fit, which looks quite good."
        ],
        [
            "And we chose this value to optimize the bound.",
            "Unfortunately, the man was."
        ],
        [
            "A week, so the here's the.",
            "True error or accuracy?",
            "Here's the lower bound, which is .004, so there's still clearly, you know, quite a bit, which we were not clear about precisely why the bound is so weak in this case, but I think you know, from point of view of seeing an attempt, at least to apply Cal downs to something more realistic in terms of the inference complexity.",
            "And also more complex in terms of, you know, sort of dynamical system fitting.",
            "I think it's still an interesting application.",
            "So they can."
        ],
        [
            "Ilusions just wanted to introduce this link with luckiness and choosing the prior based on the data distrib."
        ],
        [
            "I missed."
        ],
        [
            "Now the applications to maximum entropy talked about the Gaussian process application."
        ],
        [
            "And then this extension to approximate Bayesian inference for dynamical systems.",
            "So in a sense, the motivation also is to try and see how far we can potentially motivate alternative algorithms.",
            "The idea being that OK, Bayesian inference has a sort of fixed.",
            "It has to stick to trying to do exactly what the Bayesian model says, whereas if you can get a bound that maybe doesn't depend on that particular choice, you maybe can cut loose.",
            "And try something a bit different that may be algorithmically more efficient and still have the bound hold.",
            "We haven't done that yet, but that's one of the motivations."
        ],
        [
            "So the prior in this case is defined by nonlinear static differential equation."
        ],
        [
            "And variational approximation results in a posterior given by an approximating linear SD, and so it's a Gaussian process posterior and you can apply the bound.",
            "OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I have that discussion.",
                    "label": 0
                },
                {
                    "sent": "Really this is more at the level you know David.",
                    "label": 0
                },
                {
                    "sent": "What was the word used?",
                    "label": 0
                },
                {
                    "sent": "Lucy Lucy Lucy I like that yeah Lucy Lucy discussion unluckiness and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of forward pointers to guy and she lands, talks and then I've got two applications I probably won't do both.",
                    "label": 0
                },
                {
                    "sent": "I might skip this and then just talk a little bit about this.",
                    "label": 0
                },
                {
                    "sent": "'cause I'd like to get.",
                    "label": 0
                },
                {
                    "sent": "Matthias is views on this.",
                    "label": 0
                },
                {
                    "sent": "So OK, so really to this was going back to the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Luckiness definitions in the paper that.",
                    "label": 0
                },
                {
                    "sent": "We did back in in 98 and Martin's here, so this is good stuff.",
                    "label": 0
                },
                {
                    "sent": "So we were looking there at trying to understand how large margin classification works and we you know.",
                    "label": 0
                },
                {
                    "sent": "Came up with this idea of Luckiness function, which was I think, probably overkill for the application.",
                    "label": 0
                },
                {
                    "sent": "It was, so the idea was you had this function that measured how compatible the sample was with the functions in the class, and obviously the one we were interested in was the margin, which was quite nice.",
                    "label": 0
                },
                {
                    "sent": "So it was sort of a measure of fit between hypothese.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Listen training samples and then you had this sort of level of luckiness that came out of that which was basically sort of the class of functions that were luckier than your particular one.",
                    "label": 1
                },
                {
                    "sent": "You were interested in.",
                    "label": 0
                },
                {
                    "sent": "So sorry, the set of functions, so it was a bit like pruning the space in the way that John was talking about.",
                    "label": 0
                },
                {
                    "sent": "And then there was something called.",
                    "label": 0
                },
                {
                    "sent": "You know any old Luckiness function wouldn't do because you had to be able to kind of go from a single to a double sample.",
                    "label": 0
                },
                {
                    "sent": "So there was this thing that we called probable smoothness.",
                    "label": 0
                },
                {
                    "sent": "I think it was.",
                    "label": 0
                },
                {
                    "sent": "And it was again a rather complicated definition which I won't give you.",
                    "label": 0
                },
                {
                    "sent": "And anyway to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applied to this large margin classification and that was the motivating example.",
                    "label": 0
                },
                {
                    "sent": "Luckiness was measured by the margin on the sample.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the problem was that the ranking of the hypothesis could not be made until you'd seen the sample.",
                    "label": 0
                },
                {
                    "sent": "So it appeared you needed to have this sort of way of measuring quality by this luckiness function, and probable smoothness was really about saying that this could be this sort of quality of hypothesis could be estimated from the sample as well as save the learning and would sort of carry forward to new samples.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem with Luckiness is sort of a story with the margin.",
                    "label": 1
                },
                {
                    "sent": "Is that actually it can be solved without really going into this rather complicated setup, because you can sort of convert to real valued functions, require the outputs to be plus and minus one on the on the on the negative and positives, and then you measure complexity by the normal weight vector, which is doesn't depend on the sample, so you just minimize, you know in the normal way the normal weight vector and that sort of measures your complexity.",
                    "label": 1
                },
                {
                    "sent": "So you sort of have a way around this rather complicated.",
                    "label": 0
                },
                {
                    "sent": "Construction.",
                    "label": 0
                },
                {
                    "sent": "That we'd created.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's sort of obscures the role of luckiness in capturing this alignment between hypothesis and data generating distributions.",
                    "label": 1
                },
                {
                    "sent": "I mean what we, you know, the thing we were really trying to capture with this idea, that the density of the distribution close to the hyperplane being being low would mean the hyperplane is a good one and should be given a higher weighting.",
                    "label": 1
                },
                {
                    "sent": "Or you know higher luckiness in this.",
                    "label": 0
                },
                {
                    "sent": "In this sense, so this is actually related to the idea of compatibility that Balcon and Bloom introduced in a semi supervised setting where they were using unlabeled data.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To measure compatibility of functions and then they would reduce their set of functions that considering so sort of prune down their class of functions using this compatibility measure.",
                    "label": 0
                },
                {
                    "sent": "And it's all.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So related to the local PAC Bayes analysis of Olivia Kotone.",
                    "label": 0
                },
                {
                    "sent": "Who uses a prior distribution generated ID from the data sample?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is what I'd like to just think about a bit more defining priors from data distributions, which I think is the sort of thrust that we were essentially trying to get at with the with the margin idea or with the luckiness idea.",
                    "label": 1
                },
                {
                    "sent": "So there are various ways of doing this, so defining priors from data distribution.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you want to.",
                    "label": 1
                },
                {
                    "sent": "Not just having apriori defined prior, but you'd like to have the IT will be defined prior to seeing the actual data sample.",
                    "label": 0
                },
                {
                    "sent": "But you're thinking that being dependent or some way a function of the data generating distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so you wouldn't actually be able to write it down because you don't know what the data generating distribution is.",
                    "label": 1
                },
                {
                    "sent": "You're only going to learn about it through the sample, but as you learn about as you look at the sample you learn about the data generating distribution, but you also then also learn the function.",
                    "label": 0
                },
                {
                    "sent": "That you're trying to, actually, you know the classifier or whatever regressive which approaches that.",
                    "label": 0
                },
                {
                    "sent": "You're so one way of doing this is sort of very.",
                    "label": 0
                },
                {
                    "sent": "Natural thing to do is to just split the training data in half and use half of it to learn a prior and then use the second half to learn a function in that prior and indeed Francois mentioned results of this type in his talk this morning and Amelia will give some results using this approach later on where we use prior, possibly to guide the learning or just to to actually inform the.",
                    "label": 0
                },
                {
                    "sent": "The bound.",
                    "label": 0
                },
                {
                    "sent": "Both cases.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But you could use also expectation over the two true distribution of some other function, like this one here.",
                    "label": 1
                },
                {
                    "sent": "So you say, OK, my prior is going to be a Gaussian centered at this weight vector, which is the expectation under the true distribution of Y * 5 X. I'm thinking of projecting into a feature space here, so that's a you know uniquely defined distribution.",
                    "label": 1
                },
                {
                    "sent": "Or you could in.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And indeed, take a more complicated thing and say look, I'm going to have some.",
                    "label": 0
                },
                {
                    "sent": "Number of samples and not less than M and I'm going to consider samples of that size.",
                    "label": 0
                },
                {
                    "sent": "Generate an SVM on samples of that size and take the expected value of that as the center of my Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So this is now my prior.",
                    "label": 0
                },
                {
                    "sent": "Of course, I don't know what it is, but I can estimate it because I can estimate this with high probability from the sample.",
                    "label": 0
                },
                {
                    "sent": "This value and similarly this one by just, you know, taking samples of size N nought and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in in the latter cases, you can use empirical version.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this actual power bound, the difference between the empirical versions and the true the data distribution prior.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And use this to upper bound the KL between true prior and posterior, right?",
                    "label": 1
                },
                {
                    "sent": "So you don't compute the true prior you bound yes.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you know if you're using Gaussians, all this is just bounding norms of the differences between weight vectors, so you can actually upper bound this KL.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the complexity term now will typically decay with increasing sample size.",
                    "label": 0
                },
                {
                    "sent": "So rather than having a KL, you're sort of having a KL that will decay in your PAC Bayes bound, so she Lang will will describe this theory for this case, and Amelia will.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some afraid not very exciting empirical results, but anyway, empirical results.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We can also define the prior based on the true risk and this is.",
                    "label": 1
                },
                {
                    "sent": "You know what's a Livia was doing kotone, and you know, or the expectation of over support vector machine weights on samples of training set size M. And.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Guy will be presenting tighter bounds.",
                    "label": 0
                },
                {
                    "sent": "With extensions to manifold learning based on this idea.",
                    "label": 1
                },
                {
                    "sent": "And this is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To say is closer to Kotone's approach, so I just wanted to sort of paint that picture and I think link back to the Luckiness framework to try and sort of motivate some of this this work, but I'm not going to move on and if there are any questions about that.",
                    "label": 0
                },
                {
                    "sent": "OK. OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to skip this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maximum entropy.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because I only got.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Short period, so I'm.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skip through.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Due to the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gas.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In process regression.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Gassing process GP is a distribution over the real valued functions that is a multivariate Gaussian when restricted to any finite subset of inputs.",
                    "label": 0
                },
                {
                    "sent": "It's characterized by a kernel that spell.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Advise the covariance function when marginalizing.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On any finite subset, if you have a finite set of input, output observations generated with additive Gaussian noise, then the posterior is also.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A Gaussian process and we can workout the KL divergent between prior and posterior.",
                    "label": 0
                },
                {
                    "sent": "Where here is 1 formula for that?",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question now is, this suggests using a PAC Bayes theorem which goes back to quite a long way.",
                    "label": 0
                },
                {
                    "sent": "Index by real value.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It functions and the way we choose.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So look at doing this.",
                    "label": 0
                },
                {
                    "sent": "Is to just turn them into classifiers using this, you know, sort of epsilon tube tricks.",
                    "label": 0
                },
                {
                    "sent": "So basically, if the classifier, sorry if the function that we were looking at for a particular input an output is within epsilon of the desired output, then you say tick otherwise 0.",
                    "label": 0
                },
                {
                    "sent": "So it's a bit counterintuitive 'cause I've turned it around.",
                    "label": 0
                },
                {
                    "sent": "You know, in terms of the higher the score, the better rather than you know this is not an error measure, it sort of an accuracy measure.",
                    "label": 0
                },
                {
                    "sent": "And you can compute the expected value of this under the posterior function and and it's an exact computation.",
                    "label": 0
                },
                {
                    "sent": "So basically you can just crank the hand.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evil.",
                    "label": 0
                },
                {
                    "sent": "And you apply a pacbase bound.",
                    "label": 0
                },
                {
                    "sent": "There's a little bit of a trick in terms of the.",
                    "label": 0
                },
                {
                    "sent": "Sort of, the variance that you need to handle, but you can get a lower bound on the expected probability.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the probability of your output in the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "And this is the form that it actually ends up as the expected value of the output in the posterior distribution plus this sort of adjustment factor is lower bounded by this quantity.",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                },
                {
                    "sent": "E of epsilon.",
                    "label": 0
                },
                {
                    "sent": "This is KL inverse, so it's just the you know the value that the maximum value that's consistent with this empirical value.",
                    "label": 0
                },
                {
                    "sent": "And this you know KL divergent between this value and this.",
                    "label": 0
                },
                {
                    "sent": "And this is the empirical value of which I just showed you on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "You hear evaluated empirically on the sample.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "D is the KL divergent that I had on a few slides earlier.",
                    "label": 0
                },
                {
                    "sent": "That's here between prior posterior.",
                    "label": 0
                },
                {
                    "sent": "So this is a I think quite an interesting idea, but maybe I would just be interested to hear views.",
                    "label": 0
                },
                {
                    "sent": "Also, you know particularly media this view, but I think you know the idea that you can get some.",
                    "label": 0
                },
                {
                    "sent": "So in a way you know there's this question.",
                    "label": 0
                },
                {
                    "sent": "What is PAC bayes?",
                    "label": 0
                },
                {
                    "sent": "Giving us?",
                    "label": 0
                },
                {
                    "sent": "The Bayesians don't already have, so I think one thing is that we're weakening our assumptions and we're not making any.",
                    "label": 0
                },
                {
                    "sent": "Belief in the correctness of the prior.",
                    "label": 0
                },
                {
                    "sent": "We're only saying this is true.",
                    "label": 0
                },
                {
                    "sent": "With high probability, under the IID assumption.",
                    "label": 0
                },
                {
                    "sent": "Of course, if we have a bad prior, then this will be a very weak result.",
                    "label": 0
                },
                {
                    "sent": "But if it's a good prior, it will hold and give us useful information hopefully.",
                    "label": 0
                },
                {
                    "sent": "So just to show some experimental results.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On various example problems.",
                    "label": 0
                },
                {
                    "sent": "So there are three datasets here, robot arm problem busting 1000 and the forest fire problem, and these are the lower bounds and this is the empirical test, so they're not actually, you know that bad in terms of they seem to be giving us some.",
                    "label": 0
                },
                {
                    "sent": "You know reasonable bounds on the actual test performance.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about this is we can apply it even when you know the exact Bayesian inference breaks down.",
                    "label": 0
                },
                {
                    "sent": "You know this is a variational where we looking at a different noise model.",
                    "label": 0
                },
                {
                    "sent": "I think the Laplace noise and we get a higher lower bound and more accurate in this case for that particular data set.",
                    "label": 0
                },
                {
                    "sent": "So again, it seems to be giving the right indication of the the the more.",
                    "label": 0
                },
                {
                    "sent": "Correct noise model in that situation?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, these are plots that show how things vary as we vary the epsilon.",
                    "label": 0
                },
                {
                    "sent": "If you remember there was that epsilon of the size of the tube, and as we increase epsilon, of course we get more and more accurate because more and more things fall inside the tube.",
                    "label": 0
                },
                {
                    "sent": "But this is a match between the bound and the actual empirical test error.",
                    "label": 0
                },
                {
                    "sent": "And there seems to be sort of a reasonable surprising shape match as well.",
                    "label": 0
                },
                {
                    "sent": "In some of these.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "This is for varying noise level eater measures the noise.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is with the Laplace noise I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "OK, so again, we might be able to even distinguish different types of noise.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these are.",
                    "label": 0
                },
                {
                    "sent": "So those before sorry those two pre those previous plots were for artificial data 6 plus these three in this.",
                    "label": 0
                },
                {
                    "sent": "And this is for real data, so it's a lot looser, but still seems to be tracking a reasonably similar shape.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, we did this two things in the other order.",
                    "label": 0
                },
                {
                    "sent": "I mean actually where we started was looking at this stochastic differential equation work.",
                    "label": 0
                },
                {
                    "sent": "And I should say all of this work.",
                    "label": 0
                },
                {
                    "sent": "I mean, I mentioned in the beginning is jointly with Manfred Opper, Cedric Archambeau and Matt Higgs has also been involved, and so there's been quite a team of people involved in this.",
                    "label": 0
                },
                {
                    "sent": "But this was part of a project we were looking at doing inference in with priors that were defined by nonlinear stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "So that gives you a prior over possible paths.",
                    "label": 0
                },
                {
                    "sent": "And the idea was to use variational inference so the posterior would be defined by a time varying linear differential equation.",
                    "label": 1
                },
                {
                    "sent": "And the idea was that you would then optimize the posterior to two.",
                    "label": 0
                },
                {
                    "sent": "Minimize the KL divergent between prior and posterior distributions.",
                    "label": 1
                },
                {
                    "sent": "So here the this is the nonlinear.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If term.",
                    "label": 0
                },
                {
                    "sent": "DW zevina process.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is sort of time limit of the discrete time equation.",
                    "label": 0
                },
                {
                    "sent": "Which is given by this.",
                    "label": 0
                },
                {
                    "sent": "This form here with these are Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Unit variance, Gaussian noise.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the Bayesian approach to data modeling with the noise model given by this.",
                    "label": 0
                },
                {
                    "sent": "So there's an observation fixed here observation linear observation matrix H, taking the state too, and this is then modeled as a Gaussian with some.",
                    "label": 0
                },
                {
                    "sent": "Observation color to it.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we're doing, as I said, is to use a variational approximation with a time varying linear.",
                    "label": 0
                },
                {
                    "sent": "So this is the linear approximation which is given by this linear a matrix A of T and offset B of T. But this is varying with time.",
                    "label": 0
                },
                {
                    "sent": "Hey.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the measure over the.",
                    "label": 0
                },
                {
                    "sent": "Pause given by the prior is defined to be P and the one for the posterior IQ.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can actually workout the KL divergent in this infinite dimensional setting by using the raddon nikodym derivative of Q with respect to P, which can be computed.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So this actually allows you to compute this KL divergent even though the prior is not a Gaussian or process, so it's an only if you know if it's a linear differential equation, then the paths.",
                    "label": 0
                },
                {
                    "sent": "Distribution is a Gaussian process, but for nonlinear it's not.",
                    "label": 0
                },
                {
                    "sent": "So you can compute this even though because the posterior is Gaussian, you can actually compute this.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so it's actually this quantity where cutey is the marginal distribution at time T, and you have to integrate over the.",
                    "label": 0
                },
                {
                    "sent": "The time and this is the nonlinear drift.",
                    "label": 0
                },
                {
                    "sent": "This is the linear drift term.",
                    "label": 0
                },
                {
                    "sent": "This is the fixed again covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's how you compute it.",
                    "label": 0
                },
                {
                    "sent": "This is approximating Estey.",
                    "label": 0
                },
                {
                    "sent": "The marginal distribution is it is.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gaussian and.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can compute the mean and covariance of that marginal by these ordinary differential equations.",
                    "label": 0
                },
                {
                    "sent": "So I'm skipping quite fast over stuff here, so.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using the Grandjean methods, you can derive an algorithm that finds the variational approximation by minimizing this KL divergent between posterior and approximating.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution, so there's a natural question.",
                    "label": 0
                },
                {
                    "sent": "Can you plug all that?",
                    "label": 0
                },
                {
                    "sent": "Come on, we're minimizing the KL divergent to get a fit between on on some samples.",
                    "label": 0
                },
                {
                    "sent": "Surely we can get a pack base.",
                    "label": 0
                },
                {
                    "sent": "Application here.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to you want to Los Overpass the paths.",
                    "label": 0
                },
                {
                    "sent": "I like your hypothesis in such a way that you can apply the capture the properties that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "An applied math based.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's you know it's taking the idea that I presented for the Gaussian process and just applying it in this more complicated setting.",
                    "label": 0
                },
                {
                    "sent": "Again, we have a tube around the path.",
                    "label": 0
                },
                {
                    "sent": "Applying I mean the path is in the sort of state space, so we have to apply the observation operator and then take a norm being less than epsilon.",
                    "label": 0
                },
                {
                    "sent": "Then we get a hit.",
                    "label": 0
                },
                {
                    "sent": "That's a that's a good one, and we're trying to, you know, increase the accuracy, get as accurate as possible.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is again the actual observations are linear functions of the state variable given by this operator H.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior and posterior distributions over functions are inherited from the P&Q distributions over paths.",
                    "label": 0
                },
                {
                    "sent": "Because these functions are just indexed by the path.",
                    "label": 0
                },
                {
                    "sent": "So the prior is as I said, it's a non Gaussian distribution defined by this non.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Near stochastic differential equation and the posterior is is this Gaussian process?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we were able to compute the KL as I indicated earlier.",
                    "label": 0
                },
                {
                    "sent": "We need to also compute EQ&E hat Q.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way in which we want to look at this is the expected sort of value of this, which is the East of Cuori Hat Q, which is the expected value that probability that this is less than or equal to epsilon, and so here.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things get a little bit approximate because we basically will approximate that with.",
                    "label": 0
                },
                {
                    "sent": "Looking at the as if you're in a region of uniform density.",
                    "label": 0
                },
                {
                    "sent": "So we just look at the volume of the sphere around this point and then this is the probability of the center.",
                    "label": 0
                },
                {
                    "sent": "So this is probably a little bit suspect.",
                    "label": 0
                },
                {
                    "sent": "I would say here, but it will be good when you're close to accurate, it will be very bad as you move away from the center of the distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the way anyway.",
                    "label": 0
                },
                {
                    "sent": "We've been looking at it at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you end up with EQ being approximately equal to, or at least proportional to, this again accuracy.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing is the expected accuracy of the likelihood of the observation.",
                    "label": 0
                },
                {
                    "sent": "In the marginal distribution that we've got, the posterior distribution, so you're computing this posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "You pick a time and what you're interested in, how probable was the observation at that time and your lower bounding that probability as your measure of quality of your your modeling.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a slight problem.",
                    "label": 0
                },
                {
                    "sent": "This is more like a technical detail that the in setting this this epsilon tube size.",
                    "label": 0
                },
                {
                    "sent": "Because if you're setting epsilon too large, you get the approximation is inaccurate.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sun is too small then both EQ and he had Q become very small and so the bound implied by this KL divergences becomes very weak because they're both very small.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way we you can overcome that is by doing this sort of multiple sampling tricks so you can take a K fold product of paths.",
                    "label": 0
                },
                {
                    "sent": "You just sample K paths and then you say I'm accurate.",
                    "label": 0
                },
                {
                    "sent": "If I'm in at least one of the paths, so this will up the likelihood of you hitting on one of your paths from from the posterior sample, and.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see that now that.",
                    "label": 0
                },
                {
                    "sent": "The chances of you not hitting a path can be essentially is approximately K times the probability that you are.",
                    "label": 0
                },
                {
                    "sent": "You know the accuracy, so plugging all this together, you get a bound of the following form, which looks pretty messy.",
                    "label": 0
                },
                {
                    "sent": "I have to admit, but basically again lower bounds.",
                    "label": 0
                },
                {
                    "sent": "The accuracy of your, you know your posterior.",
                    "label": 0
                },
                {
                    "sent": "Observations, so your sum your test observation.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of the quality of your empirical fit, an this KL divergent's that you measure between your posterior and prior where you know you can you can integrate this in the way that I indicated.",
                    "label": 0
                },
                {
                    "sent": "That's the same formula as before.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the sort of.",
                    "label": 0
                },
                {
                    "sent": "Most complicated example we've run, which is the ruins the tractor, and here's some observations and sort of the true path and the fit, which looks quite good.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we chose this value to optimize the bound.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the man was.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A week, so the here's the.",
                    "label": 0
                },
                {
                    "sent": "True error or accuracy?",
                    "label": 0
                },
                {
                    "sent": "Here's the lower bound, which is .004, so there's still clearly, you know, quite a bit, which we were not clear about precisely why the bound is so weak in this case, but I think you know, from point of view of seeing an attempt, at least to apply Cal downs to something more realistic in terms of the inference complexity.",
                    "label": 0
                },
                {
                    "sent": "And also more complex in terms of, you know, sort of dynamical system fitting.",
                    "label": 0
                },
                {
                    "sent": "I think it's still an interesting application.",
                    "label": 0
                },
                {
                    "sent": "So they can.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ilusions just wanted to introduce this link with luckiness and choosing the prior based on the data distrib.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I missed.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the applications to maximum entropy talked about the Gaussian process application.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this extension to approximate Bayesian inference for dynamical systems.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, the motivation also is to try and see how far we can potentially motivate alternative algorithms.",
                    "label": 0
                },
                {
                    "sent": "The idea being that OK, Bayesian inference has a sort of fixed.",
                    "label": 0
                },
                {
                    "sent": "It has to stick to trying to do exactly what the Bayesian model says, whereas if you can get a bound that maybe doesn't depend on that particular choice, you maybe can cut loose.",
                    "label": 0
                },
                {
                    "sent": "And try something a bit different that may be algorithmically more efficient and still have the bound hold.",
                    "label": 0
                },
                {
                    "sent": "We haven't done that yet, but that's one of the motivations.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the prior in this case is defined by nonlinear static differential equation.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And variational approximation results in a posterior given by an approximating linear SD, and so it's a Gaussian process posterior and you can apply the bound.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        }
    }
}