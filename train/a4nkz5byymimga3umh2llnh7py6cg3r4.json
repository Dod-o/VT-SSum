{
    "id": "a4nkz5byymimga3umh2llnh7py6cg3r4",
    "title": "Nonparametric Relational Learning with Applications to Decision Support and Bioinformatics and with a Perspective for the Semantic Web",
    "info": {
        "author": [
            "Volker Tresp, Siemens AG"
        ],
        "published": "Jan. 28, 2008",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ecml07_tresp_nrl/",
    "segmentation": [
        [
            "OK so I can use this for moving probably so thank you very much for the nice introduction, so I should mention my cool authors or the people also contributed here so.",
            "So most of the stuff I'm presenting is part of the dissertation work of joshu and also for like half contributed.",
            "And there were a lot of discussions with KU shipping.",
            "You and Hans Peter Krieger from."
        ],
        [
            "University of Munich, so is this also.",
            "So this is.",
            "Pretty research oriented, at least the first part.",
            "So the topic is relational representation of statistical machine learning.",
            "So most of you are probably familiar with this problematic, but I like to still introduce it so relational representation is a truthful view of many relevant domains and is the basis for 1st order logic.",
            "So there are relational databases everywhere, and there's a good reason why their relational databases, because they reflect the content quite truthfully.",
            "Statistical machine learning has mostly worked with a flat table representation.",
            "It has been a lot of work on the combination of statistical machine learning with relation representations, often called statistical, relational learning SRL.",
            "So you might know the probabilistic relational model.",
            "The DARPA formulation, or Markov logic networks.",
            "So I will use the DARPA formalism extensively so that today I will present a nonparametric Bayesian view on statistical relational learning in form of the infinite in relational model, which has many interesting advantages.",
            "There's no structure learning involved.",
            "We achieve multi relational clustering and then I also want to comment on applications to the semantic web or statistical machine learning.",
            "So this is more maybe provocative and might lead to some discussions 'cause I don't claim to be an expert on the semantic web.",
            "I'm looking at it as a machine learning person and try to make sense of it.",
            "So let's first look at the relational work."
        ],
        [
            "So this is a big family and if these guys would not have been related, the course of history of the 20th century would probably have been quite different, so it's important to know who's related."
        ],
        [
            "To whom, because their social networks, so I don't have to introduce this, but we have friends.",
            "We have colleagues.",
            "We have superiors, subordinates, they have friends, they have colleagues and so on.",
            "And we know that we are closely connected to almost everybody in the world to only a small number of links."
        ],
        [
            "Then there's of course the web, which is a big relational system of interconnected hyperlinked web pages, and we know that in the information about the linkage, there's a lot of information to be exploited.",
            "For example, in terms of."
        ],
        [
            "Search engine.",
            "And this is our DF, which is the basis for the semantic web.",
            "And we also see that this is a relational graph, for example.",
            "Gone with the wind.",
            "The author of Gone with Windows Mitchell.",
            "So you see that different objects involved and there's not a simple table representation which we use here."
        ],
        [
            "Then also patient.",
            "This is also something closer to Siemens is part of relational world with many different entities, physicians, hospitals, medications, orders, diagnosis, context.",
            "This person had bacterial viral strains and we think there's a lot of potential for exploiting this relational information in the medical domain.",
            "If you want to for exam."
        ],
        [
            "Think about recommendation systems for physicians.",
            "Then often relationships are more informative than attributes.",
            "We all know that in recommender systems you exploit relation information about what you have bought before or what you were interested in before gives a lot of information about what you might be interested in the future and not so much your own properties or your own attributes are not so much the attributes of the object.",
            "So most recommended systems ignore these attributes and completely rely on the relation information and for example, social settings might be.",
            "More telling, if you're member of a club, then many, many attributes you have.",
            "Um also often information about relations as relationships is easier to obtain and more reliable than information about attributes.",
            "For example, if you look at the page rank algorithm which exploits the linkage information and not so much attributes and of course relational databases are everywhere.",
            "So that might mean or should mean that there's something."
        ],
        [
            "Important in this representation, computational biology is another application where you have interacting genes, so you have a network of genes.",
            "Genes have attributes and you want to study properties of gene."
        ],
        [
            "And interaction properties of proteins.",
            "Another application, of course, is the extraction of textual analysis of textual information, extraction of content from text.",
            "So you can describe it extracted information as entities and relationships between entities named entity recognition, relation extraction and of course there also cited citations in scientific papers and patterns which you can exploit.",
            "So if you."
        ],
        [
            "Take a closer look.",
            "You see relation learning everywhere, so this is some speculation about cognitive aspects.",
            "Some fascinated with this along, which seem to remember many, many things in great detail and even more interesting is that some research suggests that the ability can be induced which might support the view that so long abilities are latent with all people, but are obscured by the normal functioning intellect.",
            "So it means that we all have this capability.",
            "We just don't know how to use it.",
            "But how is this all stored?",
            "So maybe a relation representation in some sense is also used in biology?"
        ],
        [
            "So we might conclude that we are all embedded in a relational world where everything and everybody is connected and over some links.",
            "Everything depends on everything.",
            "So so I like to call it John Donne principle.",
            "So who is John Dunn?"
        ],
        [
            "He is a Jacobian poet and teacher and is famous for many things.",
            "And mother, among other things, this piece of text, which was also used by Hemingway in the novel for whom the Bell tolls.",
            "So he puts it in this way.",
            "No man is an island, and tie off itself.",
            "Every man is a piece of the continent apart of the main immense.",
            "Death diminishes me because I am involved in mankind and therefore never send to know for whom the Bell tolls.",
            "It talks for the so this is a nice poetic formulation of everything depends."
        ],
        [
            "Everything.",
            "That's better this previous work.",
            "A lot of ongoing work, and you're probably familiar with a lot of it mean that specialized algorithms to solve special problems petrang collaborative filtering.",
            "There's this huge body of work on LP type of approaches, and this is one of the conferences where this is presented, and a lot of detail.",
            "And so I want to focus on this view, which I called principled.",
            "Probabilistic approaches statistical relational learning, and there's a PRM approach.",
            "Kohler, Friedman, Keturah, Peppa and others.",
            "They combine a later description with components from frame based systems and Bayesian networks when very related.",
            "Is the DARPA formalism of Heckerman, Meek and color, which used the entity relationship model in combination with patient networks?",
            "So this is what I'm using in my presentation here.",
            "Then the relation of Markov networks and Markov logic networks, and probably a few more I don't."
        ],
        [
            "Mention.",
            "So some problems of the previous workers.",
            "It's often not so easily applicable, at least for example, the PRM model requires.",
            "Typically, extensive structure learning and structure learning is quite difficult, and PRM models because the search space is so large, so you need reliable prior knowledge clauses in Markov logic networks, although I guess I learned that it's easier to apply than I thought, so the clauses.",
            "You have to come up in Markov logic networks.",
            "It's not, it's difficult 'cause they're not.",
            "They're sort of features and rules.",
            "So often the relational modeling unique identity, often the unique identity of an entity, has predictive power, as in collaborative filtering, and this is difficult for some of the approaches, and missing attributes require often complex inference.",
            "So people use loopy belief propagation."
        ],
        [
            "Another approximate methods.",
            "So in this work we apply a nonparametric hierarchical Bayesian modeling to relational learning and achieve nonparametric relational basin form of the infinite hidden relational model.",
            "So we're taking two very complicated things and hope I can convince you what comes out is sort of simpler than the individual things.",
            "So Adventure is straightforward to apply without extensive structure, learning attributes and identities of entities can have predictive power.",
            "And we achieve a clustering in the relational domain."
        ],
        [
            "So cluster analysis.",
            "So let's take the path from traditional learning to relational learning.",
            "So this is nobody you probably know.",
            "Also not running for president, or he might be.",
            "The leader of the world after the nuclear Holocaust or this is this guy has been dead for 50,000 years or so.",
            "But the photo was taken with digital camera exactly.",
            "Reconstructed him like forensic experts or something."
        ],
        [
            "Yeah, so we're used to IID learning at least.",
            "The non LP people at better this way so we all love the matrix and because we can present our data typically in the matrix with an idea assumption.",
            "So this is a patient.",
            "A patient has properties and outcome of a disease or something and you might want to model the dependency of patient property and outcome and this is how you can draw it in adapter model and this is how you represent it as a table and so this is what we're all familiar with.",
            "Data are sampled independently."
        ],
        [
            "And we can just plug it into any learning."
        ],
        [
            "Russian support vector machine or something.",
            "So the time series is already a little bit different, so if you model the Dow Jones mean there's only one Dow Jones, you cannot have independent samples of many.",
            "Dow Jones is, but of course you can do learning because you assume there's some invariants in the model, so this template of local dependency can be copied in time, and this allows you to.",
            "To do learning, this already has a flavor of relational learning because you have this sort of template idea and you have this idea that in fact you really only have one data point in some sense and also everything you know all the excess influence all the pages and influence other predictions.",
            "So there is sort of glow."
        ],
        [
            "Dependencies.",
            "So the next step towards relation learning is very hierarchical Bayesian modeling.",
            "So here's an application to unitology.",
            "Which gives you impression."
        ],
        [
            "How this works?",
            "So the idea is that a patient is in a hospital in this example, and.",
            "I mean, you assume probably this.",
            "This model should be slightly different in the hospitals because they have different training, different physicians, different environments, different ages.",
            "But you also don't think that every hospital should have its own model.",
            "So this is sort of shown here.",
            "If you introduce the identical, the idea of the hospital as an input variable, you might get a model which is separate for each hospital.",
            "So if you have a lot of data for each hospital is fine, but if you want to sort of share.",
            "The statistical strength this is a bad idea, so the solution."
        ],
        [
            "So one solution is hierarchical Bayesian modeling.",
            "Essentially, you still allow for each hospital to have its own parameters.",
            "But they are coupled by a common prior distribution.",
            "And in some sense, by learning this prior distribution, you can transport knowledge across hospitals.",
            "So if you have a new hospital and you want to learn a model, you can start with a very informative prior distribution which has been learned from the previous hospitals.",
            "Of course, the tube Asian would say OK have to integrate, integrate, integrate, but in effect this is sort of going on and you assume you achieve great flexibility if you assume that you have a very flexible prior distribution.",
            "And it's very convenient to work with seriously processes here.",
            "'cause the sample of additional process is very, very flexible.",
            "So write it like this.",
            "DP of Jeannerod is called base distribution.",
            "An iPhone or twitches concentration parameter Ann."
        ],
        [
            "Let's look what's going on, so hopefully this is makes it clear.",
            "So if you start to learn a model, you might start off with some uninformative prior distribution on the parameters, so this sort of should indicate a Gaussian uniform variance and mean zero, and then you Start learning and the posterior parameter distribution gets changed and eventually it becomes a dot.",
            "So you have a point distribution.",
            "If you see many many, many data.",
            "And this thought we we draw into this graph, and then we do it for the next hospital for the next hospital.",
            "And so on.",
            "And then we see the distribution of all these parameters.",
            "Of all the hospitals under consideration.",
            "And if this, if this is also can be described by a Gaussian, like in this case, then this is called hierarchical Bayesian modeling, because what effect is going on this parameters in discussion change to the parameters to describe this question.",
            "So the mean is changed and the covariance is changed.",
            "But then the question is, I mean do we?",
            "Can we really believe that sort of actual distribution of hospital parameters follows this simple distribution?",
            "Isn't it often odd, shaped and maybe multimodal?",
            "Some weird thing and that's why we should have a prior distribution which can represent these strange things?",
            "And this is how the where the nonparametric Bayesian model comes in.",
            "Because if you study this, the.",
            "Distributions can be rich, can be represented, extremely flexible, and can model these type of distributions."
        ],
        [
            "That's another view on this, which is maybe more intuitive.",
            "Another way to approach this problem is to say, OK, there's a cluster variable which each hospital, so each hospital is in some cluster, and if you know in which cluster it is, we also know which parameters to pick.",
            "So this is just a clustering formulation.",
            "Now there's another way of saying there's something hidden in the hospitals which I don't know about that I should model.",
            "And it turns out now if you let the number of states in Z.",
            "Go to Infinity.",
            "You achieve the so called directly process mixture model.",
            "And it turns out this is exactly equivalent to the nonparametric hierarchical Bayesian approach, with it usually processed prior.",
            "So what I told you before is exactly equivalent to this.",
            "But here I like this much better because here is easier to think about everything.",
            "We sort of know how to work with clustering.",
            "We know how to work with mixture models, so we have an intuition of what is going on here.",
            "Whereas in the other formula formalism it's more difficult to get intuition of how to do to do with this.",
            "So one thing is just too.",
            "Think of it as a finite model.",
            "Do something with finite mixture models and then just say OK, let me let the number of states approach Infinity and then I have to actually process mixture model.",
            "That's a nice thing.",
            "Of course one of the attractive things here is that you give the model infinite number of clusters, but the model will only use a small number of clusters and you can think of this extra number of clusters.",
            "The model is using as the estimated number of two clusters in your system, so you don't have to do this extensive.",
            "Model selection anymore to try to determine the true number of cluster components.",
            "This seriously process mixture model does it automatically because there's a tuning parameter, but it's not very sensitive to this tuning parameter."
        ],
        [
            "OK, I think that."
        ],
        [
            "Set this OK so the next thing then is now relational modeling and learning.",
            "So Tom literally said we're in the middle of the relation."
        ],
        [
            "Evolution.",
            "Yeah, not surprisingly."
        ],
        [
            "We have to deal with relational databases and there's one way to describe a model of a database schema in terms of this entity relationship model.",
            "So this is a short introduction into the ER model, so we have entity classes, so these are sets of objects.",
            "For example students and courses.",
            "We have attributes so students might have an IQ of course might have a difficulty, and there's a relationship class which sort of tells you about relationships between the objects.",
            "In this case, a student takes a class and also this this guy might have an attribute because the student will get a grade in the class, so this is.",
            "What we have to know about databases today, and I think it's quite intuitive and graphics."
        ],
        [
            "So this is the Doppler motive.",
            "So here you simply add a template for probabilistic dependencies.",
            "So you add the arcs without the error.",
            "So these are dependencies in the sense of herb Asian Network Now, so this is dependent on its parents.",
            "Then you have to add the local distribution class which quantifies this dependency and you might have to introduce constraints which are in this case trivial.",
            "So only the IQ of the student who takes the course will influence his grade and not the IQ of another student.",
            "So we don't have to do this constraints in the following, so just.",
            "For completeness, so this indicates what the probabilistic dependencies are, and of course."
        ],
        [
            "We don't.",
            "The real world doesn't consist of these templates, but of real data.",
            "So you apply this data to a real database of real students and real courses and you obtain this sort of ground network.",
            "So these are accused of three different students.",
            "These are the difficulties of two causes, and these are the grades the student got in the course.",
            "So this is what you really have to deal with, and you see already the problem here.",
            "Everything is connected.",
            "It's a huge page network.",
            "You have to do big influence.",
            "You also see why it's only one data point, it's really.",
            "Everything depends on everything sort of thing.",
            "This is the same thing for recommendation system.",
            "You have users, movies, user attributes, movie attributes, and maybe you model.",
            "If a user will see a movie and this.",
            "This is how it looks.",
            "The ground network looks in this case."
        ],
        [
            "As I said, this relational modeling often involves a lot of structure learning, so this here is a result of the guys who worked on the PRM model and this is painful because it's even more complicated than normal Bayesian networks.",
            "So people have done this and people get these nice results about dependencies and medical domain.",
            "But if you just want to straightforwardly apply.",
            "Relational modeling statistical learning to relational model this is."
        ],
        [
            "We live in two painful, so let's combine relational learning with nonparametric hierarchical Bayes."
        ],
        [
            "OK, so questions please ask them.",
            "OK, yeah, Particulation models are also the top performers.",
            "They're pretty much equivalent if you extend a little bit PRM models their equivalent, their templates leading to parameter sharing in the ground Bayesian network.",
            "So it's a template you apply all over the place, but this might be too stiff for many applications.",
            "Ever seen that sometimes you want to have this hierarchical basian stuff of parameter sharing or parameter.",
            "Visual parameters which are tight by some prior distribution.",
            "So how do we do that?",
            "So the question is how to generalize hierarchical patient modeling to relational learning.",
            "If you think of parametric hierarchical Bayesian modeling, I think it's very difficult and I couldn't really figure out how to do that.",
            "But the nonparametric hierarchical Bayesian approaches is much easier to generalize because you have this interpretation as this infinite cluster problem, so that's why we jump right away to the non parameter case.",
            "I don't care about the price."
        ],
        [
            "Better case.",
            "I should also mention that the two groups working in this mainly is our own group here in Munich.",
            "And then there's the group of Camp Group for Tennenbaum, Yamada and Wajda, who in 2006 we came up with almost the same model.",
            "Not quite, but almost an almost the same title as well, so and if you don't follow my presentation, look at their papers.",
            "It's also very excellent paper."
        ],
        [
            "But slightly different point of view.",
            "What's the idea and the idea is very simple.",
            "A recommendation engine, so you predict the rating based on user attributes and movie attributes, and if these are strong attributes, if you really know a lot about the movie and a lot about the movie and the user, this is maybe all you want to do and you're perfectly happy, but now."
        ],
        [
            "So of course, in reality you don't know too much about the user, so you must assume there's some hidden information which is relevant for the model which you don't know about, and that's why we introduced this clustering variable.",
            "This latent variable ZU for the user and tire to the attribute information, so it so we can also exploit user attributes, and this is not a predictor for the relation, and this is very much very similar to the hospital problem I showed you before.",
            "There's a before this was a hospital and it was associated with a hidden variable and now it's the user associated with a hidden variable.",
            "And this is pretty much standard recognition modeling.",
            "Of course you can."
        ],
        [
            "The same thing with the movies.",
            "So we also introduce the latent variable here and tie the movie attributes in this fashion, 'cause we also assume that we don't have a complete description of a movie.",
            "And this now gives you, and of course, now we let the number of states go to Infinity, and then we have interacting, usually process mixture models and so this is all we're doing.",
            "And this is the key slide of the talk.",
            "So very simple 1 hidden variable, another hidden."
        ],
        [
            "So the this is when we add the parameters, which becomes a bit more complicated if you're an expert in DP thick breaking representations, you will recognize these things, otherwise it's not too difficult to hear something was screwed up.",
            "Essentially, this state of this depends on the cluster states, the state of the cluster, variables of the associated entities.",
            "This is what I was showing."
        ],
        [
            "Here and.",
            "So the recipe is very simple for each entity, or at least for the ones which you need to model in a probabilistic fashion.",
            "Introduce an infinite latent variable.",
            "Specific to each entity class, so you can have several different kinds of latent variables.",
            "So before I get one for user, one for movies and this latent variables, the parent of the remaining attributes of the entity and it's also the parent of the relationships.",
            "This entity is involved in.",
            "So this is the model, so the question might be, is this to limit it because we assume very local dependencies now totally before and PRM you have to do this expensive structure learning and consider long-term dependencies too.",
            "High complexity, so this seems to be very simple, but we have an argument why this might still be."
        ],
        [
            "Sufficient, and the reason is that if you look at the ground network for this recommendation system and the simple way without the latent variable, you predict from attributes the relation of the ratings here.",
            "And of course, here the information is blocked because if you know the attributes now, then in the Bayesian network this pass is blocked and no information can propagate, which is also nice because you can do local inference.",
            "But if you introduce this latent variables here Z then you get this type of ground network and now since this one is unknown this is open.",
            "This opens up and can propagate through this Collider and so on.",
            "So information can propagate globally in the system so even long range dependencies kind of principle.",
            "Followed by the."
        ],
        [
            "By this model, this is another example, so I drew this a little bit more like an image.",
            "So the ACE might be sort of pixels and Ers are relations between pixels, so indicating this is a neighbor neighboring pixel, for example.",
            "So here information will be blocked if you know a."
        ],
        [
            "It blocks all the information, but if you introduce the latent variable, this is open, and this is also open because it's unknown and this is you might recognize this as a model of image reconstruction, often used so the Z would be the unknown pixel values are would indicate I'm a neighboring pixel and a would be the noisy measurement of a pixel, so this, so in some sense this image reconstruction model can be thought of as a special case.",
            "Of the infinite hidden relation of model."
        ],
        [
            "So there are some advantages.",
            "We can predict attributes we can predict, links.",
            "We can handle relationships and entities of multiple types.",
            "If if some if the mother decides that some person is quite unique, he can get its own cluster, so we can completely personalize.",
            "Otherwise we share sophistical strength.",
            "Yeah, we don't need to do structure learning store.",
            "The information can flow through the system.",
            "We have no loops.",
            "By construction we have no partition function.",
            "No compass point, complex aggregation, no problem with many to many."
        ],
        [
            "We achieved clustering and relational domain and later on we will analyze some of the clusters.",
            "Each entity class can determine its own optimal number of components, so we don't have to do this complex model selection process where we have to change the number of latent states for each entity and would be very, very complicated.",
            "Missing data can be ignored because we have colliders there, so they just drop out.",
            "Um?",
            "So these are some."
        ],
        [
            "Dentist, there's some scaling issues I don't want to necessarily get into this too much, but one thing we can exploit is if there's a strong default relationship.",
            "For example, in many applications, default relationship is, there is no relation, you only have one parent and not 3 billion or something.",
            "This can be exploited because only the."
        ],
        [
            "Listing relation give you information about the missing ones.",
            "OK, now yeah, this was the."
        ],
        [
            "Positive story another.",
            "Of course there's the problem in all of this is inference.",
            "But it's not a terrible problem.",
            "Typically, if you have, you might have heard of this in this type of systems, you do something like the Chinese restaurant sampling process or different approximations to that.",
            "So we have worked with the Chinese restaurant process sampling usually multinomial allocation truncated.",
            "Usually process is these are two approximation of those so called stick breaking process.",
            "But these are details I don't want to get into it too much.",
            "We also investigated to mean field approximations and some simple memory based empirical approximation."
        ],
        [
            "So."
        ],
        [
            "122 is too slow.",
            "So the first task is exactly a recommended recommended system, the ones."
        ],
        [
            "I showed you before and these are the attributes of the user and the movies, so age, gender, occupation, general of the movie, year of the movie."
        ],
        [
            "And this is the results we were getting.",
            "So GS always stands for Gibbs sampler and me MF4 mean field and the empirical approximation.",
            "This is a given the active user has seen 5 or rated 5 movies 1015 Twenty I mean the main result is that the sampling approaches are slightly better than the midfield approximations.",
            "Empirical approximation was not quite as good here, but the speed is there's a lot of speed improvement if you go to the mean field approximations compared to the sampling approaches.",
            "Of components found is also different.",
            "Gibbs sampler found more components I mean needed more cluster states than the mean field approximations.",
            "But if you look at the occupied states of the clusters, you recognize that they are pretty much the same, so they simply have longer tails which are not heavily occupied by objects.",
            "Um?"
        ],
        [
            "Interesting to analyze the clusters and I was so personally quite surprised to see pretty clear clusters because the attributes don't have so much predictive power, so most of the information is in the rating.",
            "So in the relationships and I didn't expect that the classes would be very meaningful, but I thought I think the labels we found quite interesting, so this means I think 207 movies are in this cluster and 161 of them are sort of stable in this cluster and don't change in the sampling process.",
            "And the sampling process is.",
            "Movies get assigned to different clusters, but some of state.",
            "So this is the biggest one is very new and so this is from 1997.",
            "So at that time it was very new and popular movies Sabrina and so on.",
            "Then the second one old older non US, typically non US and drama movies then here comedy Get Shorty.",
            "So.",
            "Swingers these are my children oriented movies.",
            "These are new action movies at that time.",
            "The game the Rock would older action movies.",
            "Fugitive Indiana Jones older drama and Harrison Ford leads his own cluster, of course."
        ],
        [
            "This is a distribution on clusters, so you see.",
            "Green ones are Gibbs sampler.",
            "Brahmins are Greenfield approximation and in the left part there's some agreement on that.",
            "They're not so cool.",
            "Two different here."
        ],
        [
            "Key.",
            "These are some technical details so important.",
            "One is probably here on 99143 users, 600 movies."
        ],
        [
            "The second problem we analyzed is from bioinformatics.",
            "So the task here is cluster analysis of genes in a in a dynamic network and also prediction of gene functions given information on the gene level and the protein level as well as the interactions between the genes.",
            "We used data from the sick D database, comprehensive use genome database.",
            "From the Munich Information Center for protein sequences, we used 1000 genes in this experiment.",
            "Another experiment we use slightly different number and the attributes are OK.",
            "I will discuss in a second the interaction data are from the DIP data based on interacting proteins."
        ],
        [
            "So this is.",
            "The Top Model we used in this case, so there's actually only one entity.",
            "This is gene with the cluster variable over here and the gene can interact with other genes is modeled in this way.",
            "And so this is the variable which decides if the gene interacts with another gene and then there are several sort of attributes which describe the gene.",
            "So here are some of the attributes gene function.",
            "Different functions that gene might interact with another gene, different phenotypes, expression of the gene, complex with others to form.",
            "Larger proteins, structure categories, motives and gene.",
            "Another gene attributes like essential, and on which chromosome it located again.",
            "I mean, it's interesting here to look at the ground network, which looks sort of like this so you see this Ascension interacting network of genes so.",
            "These are the latent variants of the jeans, and they have interactions to other jeans.",
            "And here you see sort of the attributes, which are sort of derived from the hidden latent states of the jeans.",
            "But this is a ground network."
        ],
        [
            "And and this result we were getting.",
            "So this shows a subset of the genes and you see that the colors correspond to the cluster membership.",
            "So you see sort of isolated gene clusters.",
            "Here's a connected set.",
            "You can also try to interpret those clusters, so I'm not the expert in bioinformatics so that this doesn't necessarily tell me too much.",
            "We don't show the connections or relations to.",
            "Jeans and other clusters not too.",
            "Clutter the image too much, so these are the connections in these groups of clusters shown here and you might notice that the clustering sort of follows the graph structure, so this indicates that the gene interaction is a very important information in the analysis of the clustering and is not ignored by the model, so it doesn't just rely on the attributes, but it also includes very much the interaction information.",
            "So the notes are the jeans.",
            "The links are the interactions and the colors of the clusters."
        ],
        [
            "So here's some statistics.",
            "This shows you if you were to remove that information, how much performance you would lose.",
            "So the most important information is information about the complex.",
            "If you remove that, the performance drops considerably, but the next important information is about the interaction between the genes, so.",
            "Which is also indicated in the clustering inside that the interaction information is quite important.",
            "So in this case we don't evaluate.",
            "In some sense the clustering quality, but the prediction of the function.",
            "So that's why I didn't tell you that.",
            "So this is predictive information, not the cluster information, but to predict function.",
            "These are the most important attributes are relationships used and which also indicates in this study that interaction is so very important."
        ],
        [
            "Information.",
            "We also work on including ontological information there is.",
            "The gene ontology surround of different kinds kinds, and we consider this to be very important.",
            "Prior information which you should include into learning.",
            "That's at least one one way to look at that, and so we give the information about the.",
            "Position in the taxonomy also to the system.",
            "And of course, this cannot be treated simply as classes because there are some constraints here, because if you're active in some.",
            "Subclass here all the classes you are derived from should also be active, and we can also so, but it's very easy to include this into the IRM model.",
            "Just especially use this as additional attribute information and you could also integrate several ontologies, do some sort of ontology integration.",
            "A very simple way."
        ],
        [
            "And we could show that by increasing, including ontologies, we can improve performance.",
            "So this is these are RC curves concerning the prediction of function of genes and we used an ontology about complex of jeans.",
            "And so these are our C curves, and you see with ontologies 800.",
            "Training 200 test we show a significant increase in performance.",
            "So the ontology helps you there.",
            "Here we reduce the number of training data and.",
            "The increase is even a little larger here because if you have enough data you don't need to ontology 'cause it's sort of a prior knowledge.",
            "We can integrate here."
        ],
        [
            "The third experiment.",
            "So I should tell you that we are interested in all these three application settings at Siemens, so we are currently working on a recommend assistant for videos home entertainment systems.",
            "We are.",
            "There's also a lot of interest in bioinformatics currently because of the potential for medical applications and this goes in the direction of medical recommendation systems so.",
            "As I told you before, patients are also part of a relational world of diagnosis.",
            "Procedures, physicians, hospitals and so on.",
            "But we didn't.",
            "We only model these sort of things, procedures, patients diagnosis in their properties.",
            "So related to classes.",
            "Or may I show you the."
        ],
        [
            "Plot right away.",
            "Looks like this or this slightly simplified from the model we worked before, so there's a patient takes a procedure and decision is made about the patient and all these.",
            "Yeah, this usually processes should interact and should exploit all this information.",
            "I mean, as I told you before this, there's always this collaborative filtering effect which is automatically in the system as in the collaborative filtering approach, which is nice because we know we can exploit exactly what procedures have already been taken by the patient to make a prediction for the new patient for the new for the new page or our predictor.",
            "New procedure for the same patient.",
            "So we have this also information about attributes here, but we also have.",
            "Information about procedures already taken which correspond to movies already watched or something like that."
        ],
        [
            "And these are also RC curves based on the 1st procedure is known and we have to predict the second procedure and.",
            "IRM is over here so it can exploit all this information in a very nice way.",
            "So this is pure content based system where we don't have this relation information or this is information about previous procedure.",
            "So it's basically a prediction just based on properties of patients and diseases and so on.",
            "And so you see that.",
            "It pays off, sort of to invest into this more sophisticated system because it has a way to smartly exploit all the knowledge in the system.",
            "And so this is for all patients.",
            "That is, for patients with the prime complaint circulatory.",
            "Problem, so we hope that we can."
        ],
        [
            "Convince the.",
            "Business unit to invest into this direction.",
            "OK, so the conclusion for the first part will have some time.",
            "So we have introduced by a time to realize nonparametric relational base an suggest that it might be an interesting model for a number of relational problems, so we don't have to do structural learning.",
            "I guess, as in the Mac of Logic Network, I should probably say.",
            "We have expressive ability.",
            "We're coupling between heterogeneous relationships.",
            "The model can decide itself about the optimal number of states for the latent variables.",
            "I mean, I said this is 1 tuning parameter or not, but it's not very critical.",
            "I mean, you can sort of say OK.",
            "I mean, you can tune it that you looking for really large number of clusters or really a small number of classes or something in between.",
            "But you cannot unit to produce seven or six clusters, so you have to tune it sensibly, but you don't have to tune it very, very carefully.",
            "And the classes can be analyzed and you can understand.",
            "Gain some understanding about the domain and the three applications are presented with recommendation systems.",
            "Prediction of gene functions and medical decision support.",
            "So and then so this.",
            "Then I said, because this is in just a second session, I should also talk more about industrial perspectives.",
            "And since I'm involved in this German funded project and I need to learn more about semantic Web, I thought let me also talk about the semantic web.",
            "But of course it's very preliminary and not very.",
            "I don't claim to be an expert, but maybe it."
        ],
        [
            "Sort of.",
            "Stats would be based for some discussion.",
            "So of course the semantic web.",
            "This is a perfect fit.",
            "Maritza relational domains relational learning fits quite well.",
            "It has a route based component which is very interesting to learn about.",
            "So in some sense, IOP would be the perfect match.",
            "But I also think statistical most artistical approaches should make very valuable contributions here.",
            "So this again is sort of an RDF network and you see right away that this is a relational domain connecting many, many different kinds of objects."
        ],
        [
            "Together OK, this is a test voice, so it's a national funded project for.",
            "I say my web 123, so the web three is supposed to be the semantic web and there's a lot of activity there, but it will also contain web two components or social network components, social web components, social tagging ideas, and so on, and not so much web one.",
            "So it's quite huge.",
            "19 million euros over five years.",
            "With a lot of industrial partners, alot of.",
            "Research institutes Fraunhofer universities DF Cayey other research institutes there six use cases which focus on different application scenarios and are driven by companies like Siemens S IP battles Man Lycos and so on.",
            "And there's also core technology cluster to develop the basic technologies to support the use cases.",
            "So and I thought, oh, this is great."
        ],
        [
            "I get involved in this.",
            "I'm interested in this list perfect, so I just want to essentially comment on some things on this semantic web.",
            "As I said, I'm not definitely not the expert, so this is the structure you find.",
            "A lot of places about how the semantic web is supposed supposed to work, so you gain in semantic power if you go up this hierarchy over here.",
            "But maybe let's look at some of the."
        ],
        [
            "First, from my personal point of view, I think this is.",
            "This is great and this works.",
            "I would say growth should work today.",
            "This is something we should all benefit from the day we know that XML is the basis for data exchange industry and this is already very powerful thing and as many commercial applications in the next layer.",
            "The RDF layer, which has more of a relational structure should also be without question a great thing unless people in software design think there's some mistakes that I know for my point of view this is.",
            "Undoubtedly very good thing and you can exchange distributed information using this format.",
            "It's very intuitive to work with.",
            "Has this simple subject predicate object sort of construct, and there's in my mind no doubt that this is a very useful thing.",
            "It might happen first on the web, it might happen first in other applications because it's just a very convenient way to exchange structured data.",
            "And agents would love."
        ],
        [
            "This and other applications.",
            "So then there's the ontology layer, which from my point of view, specifies the schema of course, and also adds a lot of sort of logical constraints.",
            "So your domain and people spend a lot of time designing carefully ontological domains like jeans or medical many others, so they typically contain as hierarchical modeling a taxonomy, but they also include root root based constraints.",
            "And I also think this is a great thing, because this is from a machine learning point.",
            "Great source of prior knowledge and we should definitely use this in learning and probably other applications.",
            "Should also use this.",
            "So it's a great thing.",
            "Then the neck."
        ],
        [
            "Players are.",
            "Logic proof and trust and my what I learned.",
            "Also at this meeting is we're sort of here and haven't touched proof and trust yet, so I firmly believe that logical reasoning can contribute greatly to the semantic web.",
            "But my point would be.",
            "It should not be dependent on the power of reasoning and logic, because we know there are some.",
            "It's not so easy to solve.",
            "This problem is to scale it up to get people who are supposed to use the summoning deck to get a deep understanding of these issues.",
            "So my point would be, let's just for now a little bit separated.",
            "Work on this and.",
            "Expect that these people have contributed greatly to the semantic web, but we shouldn't wait for them to solve all the problems.",
            "That would be my main."
        ],
        [
            "Discussion point.",
            "So let's set up a few important tasks, classification and search, and so I just try to come up with a way I think."
        ],
        [
            "In machine learning to it and how the semantic Web people probably would do so in machine learning you you have some inputs and you you don't care if this is semantic or not.",
            "Could be structured or unstructured, could be flat or relational, was missing data are a problem.",
            "So if you have typical feedforward system like a support vector machine or something like that you don't like missing data.",
            "But that's OK. That's a problem.",
            "Then you have feature extraction.",
            "You calculate features, but these features are rarely semantically in terms of a human level semantic.",
            "I mean there might be some interpretation, but even if they have an interpretation they will typically not.",
            "Yes it's there.",
            "Oh no, it's not there, so it's sort of some continuous value.",
            "You get out of a feature and then you have a classifier and you classify your system and this of course is has human level semantics because you want to know what you classify.",
            "So this is typically what's going on a machine learning classifier, and if you."
        ],
        [
            "Want to use this for search?",
            "Probably.",
            "Not too useful currently in the sense that you cannot do end keyword search because this is continuous.",
            "This is probably uncertain, so search engine's my understanding at least is that currently they are not so good at working with this type of information, or at least let's say you will sit in front of your computer.",
            "You type some keywords and you might not want to have this probabilistic thing that you want to have the documents which really contain this information and not maybe contain this information or.",
            "I thought it might contain this information, so at least today a search engine seems to love this too much.",
            "And of course you can do search based on similarity and other things of course.",
            "Also the ranking function is a very important machine learning problem, but so this is sort of the way I look at the machine learning issue here, if you."
        ],
        [
            "Look at the semantic web.",
            "So in one view is, do you assume you have two knowledge about your domain?",
            "So and this should have human level semantics, so it should be understandable to a human what these things are.",
            "Then you have ontological background knowledge and then you do reasoning and can derive additional effects.",
            "For example, the type of an object or class or other things.",
            "And of course this type of reasoning in some sense can deal with missing data because it's sort of a connected thing.",
            "So something might conclude something and then the next sort of rule can catch on that.",
            "Of course, also only limited in a limited way, because if you cannot prove something."
        ],
        [
            "Then it's also unknown to you.",
            "In many cases, particularly many applications concerning with his eyes, the input consists of unstructured data, so you have to do some form of pre processing to do it from unstructured to structured data is the strongest one would be human tagging supported by a machine and in many applications this might be a good option and this might be so there might be so much.",
            "Special interests or other interests that people are willing to do that.",
            "And of course, our task machine learning people task is to automate this to do automatic processing from text to RDF.",
            "Image to RDF.",
            "So this is a big problem, But if this is solved and this is again semantic level and also sort of deterministic Now, we don't have too much probability here then this is great and then the reason I can work with this and we can do many interesting things over here.",
            "And."
        ],
        [
            "If you look here, the perspective from a search engine, I think there's a lot of interesting information here.",
            "Which search engine would love to have additional keyword additional semantic information which we can search for additional things.",
            "We concluded type or class of an object, synonyms multilinguality, so this is.",
            "This is sort of the vision as far as I understand it, there different.",
            "Definitely many interesting machine learning problems.",
            "Definitely on the left side, but maybe also here we want.",
            "Would like to do some problems.",
            "Start with a reasonable with the machine learning problem.",
            "So for example if you want to predict if somebody's who's described on its webpage would like to buy your product, there's a lot of probability involved and you probably don't want to work with logical roots here, so we also here on the right side I see a lot of potential for machine learning."
        ],
        [
            "So my my personal and my current conclusion on the second part is that RDF is a data model and a uniform data exchange format can be very useful today and people should.",
            "Use this and.",
            "And write smart applications are smart agents who can exploit this type of text which are written in this format or another format ontology is also great because they supply a lot of prior knowledge about the domain which the application also should exploit.",
            "But my main point would be that maybe logic based reasoning and statistical machine learning will both make great contributions in the future.",
            "But maybe the the semantic Web version should not depend on.",
            "Either of them, so we should go ahead with the vision today because the community or the public expects us to produce results quickly and not in the far future.",
            "And then we expect that logic, reasoning and static machine learning.",
            "We have important contributions which will also contribute to the vision, but it should not rely on that.",
            "That's what we might point.",
            "So here's some example of where I see static machine learning.",
            "Of course, generators of metadata is a big point.",
            "Also, a big point in case there's all sorts of classification task, recommendation tasks and so on.",
            "Maybe you also need search engines and agents which can easier deal with continuous data and probabilistic data.",
            "So we can better exploit things generated by something like a privacy classifier, another point, or the final point is maybe that semantic web version might not be realized on the web first, because a lot of people also industry get inspired by looking at this constructions the ontologies and so on to sort of approach more.",
            "EA Shun Spired solutions again.",
            "For example, in the use case we're working on.",
            "In medical, which is essentially medical search engine for medical images?",
            "We expect to be able to exploit a lot of ontology ontological knowledge which has been encoded to improve the solutions we're working on all the problems we are working on, so this is so maybe a lot will happen here, not on the web 1st and then the web will follow.",
            "So don't always just think if people talk about semantic web like it's on the web.",
            "It could also be very special data, only accessible to one company and not really on the web.",
            "OK so this then and thank you very much for your patience.",
            "Thank you very much, thanks.",
            "Hopefully you can come back to your earlier Clock from the Lake."
        ],
        [
            "So can you tell us something about scalability of these algorithms?",
            "In particular, suppose I have classes beyond small HMO only have 10 million patients."
        ],
        [
            "You have people.",
            "Yeah, people have worked on this.",
            "There was a recent conference.",
            "Somebody presented a very similar approach.",
            "He had made 200,000 entities.",
            "And he was doing clustering in that domain.",
            "I think it was.",
            "Sort of artists or something like that, so this seems to be a number one can reach, and he I think he said he needed two or three hours for this to work.",
            "It scales basically with the number of relations, so if it's a sparse domain, if you don't have too many interactions, so if every new identity is connected to all the existing entities, then the scaling is very bad.",
            "But if the number of relations sort of stays constant, it's sort of also scales.",
            "Constant with the number of entities, so I wouldn't think a million or 10,000,000.",
            "Skilled in it and is a number of.",
            "Yeah, it's proportional.",
            "Definitely the number of entities.",
            "And to the number of relationships this entity typically is involved in.",
            "And then you need number of iterations to converge, so which is difficult to estimate?",
            "Having said that, leaving Bibles at Blockbuster open up, yeah.",
            "Yeah, sure."
        ],
        [
            "OK, so here's here's example.",
            "So innovation network.",
            "If you have a Collider, it's open OK, and if you have a parent and its parent is unknown, then it also opened.",
            "Don't tell me I'm wrong.",
            "It opens up if you have evidence.",
            "Yes, you've never collide is closed, and then you have the.",
            "If you have a Collider, it opens up now this so this path opens up if the relationship is known.",
            "If it's unknown, yeah, know if this is our is known it opens up.",
            "Our goal.",
            "Adding the.",
            "Valuable.",
            "Oh, it doesn't.",
            "It doesn't change this this this this is open here too, and so because it's a Collider and has received evidence.",
            "But here the attributes block the path, so there's no way this.",
            "The information about this can propagate to this guy because it's blocked by this attributes.",
            "But if there's a latent variable, then it's open and information can flow through the latent variable.",
            "Mission.",
            "OK, so.",
            "Come back to the point of model selection, so your model you is a force of the order.",
            "Is this even variable?",
            "Is latent variables.",
            "In fact that with this run better operational performance but.",
            "Does it make your model more complex?",
            "In which way you can have when you run road trip and we will have many local minima.",
            "Can you explain this as you are?",
            "Yeah, you can probably have local minima here, I.",
            "It seems we didn't, we never.",
            "I mean, there's so much so castec there that you always sort of have the tendency that local minima might be average hour.",
            "They jump out of them.",
            "But I don't think there's a we can really guarantee that there no local Optima.",
            "I think we have local Optima and but the nice thing is that since I mean.",
            "Since there is a chance that the information from this guy and this attribute sort of propagates to the latent state here.",
            "So if the system decides it has a better modeling capability, if it doesn't, just look at the OK. Let's say this is a person.",
            "This is father, his grandfather and father.",
            "So this guy might get a disease if his father has a disease or if it's grand Father had the disease, but we don't introduct introduce a direct connection here, so we hope and expect that information from the Grand Father can propagate.",
            "To the grandson through this network of latent variables mean similar as in an image processing application are you are in hidden Markov model, you the the model itself is very local, but information in the time series model.",
            "For example, hidden Markov model can propagate globally.",
            "So this is sort of the thing we're hoping.",
            "We can explore.",
            "Application to buy.",
            "Fishing boat.",
            "Prediction function prediction."
        ],
        [
            "Interactions.",
            "Um?",
            "It seems to me that you want your interaction, yes.",
            "Now we know some interactions we don't know.",
            "We didn't do that.",
            "We only in this case we only.",
            "So this is this is data which is inspired by a KDD club competition, so it's not the same data about this similar and there are the task was to predict the function.",
            "So this was one task we were looking at and then we said oh.",
            "Let's also look at the clusters but we didn't try to predict the links.",
            "But it's an interesting.",
            "Idea we should probably try to do that too.",
            "Also command last slide you're in view of the semantic web OK. Name?",
            "Um?",
            "Just once."
        ],
        [
            "This this one.",
            "Could be a nice domain to produce this kind of ship.",
            "For your application, bioinformatics Rob Lowe that I'm teaching his relations in direction and if you consider the task of scientific discovery.",
            "That can be related to your yeah yeah, I mean some of my colleagues have worked on relation extraction from textual data from medical bioinformatics and then in the course of the writing the paper they learned about this representation RDF and decided then to present the extracted relations in terms of this RDF framework, which also gives me a very high motivation that this is a nice description of.",
            "This relational information, because it's sort of human readable, it's exchangeable, so you don't have to sort of provide it into some strange relational data format, so I think I really agree with you that this whole framework can be quite relevant there, and of course also it's very general if you so if you build your application on top of RDF then you can assume there will be hopefully a lot of RDF in the future, and it's very universally applicable.",
            "Other people can use it, and if we also have more ways to integrate.",
            "The logical knowledge, for example, again North right away, applicable to many many applications, and hopefully that's the vision at least.",
            "This point in in biology, the viruses are more or they want more uncertain T. Information which I expected.",
            "But yeah, I think there's a lot of a lot of my understanding and I'm definitely not expert.",
            "Is that in the semantic web community?",
            "There's also a lot of activity in terms of probabilistic, including probability and uncertainty.",
            "Not much, but.",
            "Yeah.",
            "Windows structure OK. OK, so immigration.",
            "OK, so thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I can use this for moving probably so thank you very much for the nice introduction, so I should mention my cool authors or the people also contributed here so.",
                    "label": 0
                },
                {
                    "sent": "So most of the stuff I'm presenting is part of the dissertation work of joshu and also for like half contributed.",
                    "label": 0
                },
                {
                    "sent": "And there were a lot of discussions with KU shipping.",
                    "label": 0
                },
                {
                    "sent": "You and Hans Peter Krieger from.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "University of Munich, so is this also.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Pretty research oriented, at least the first part.",
                    "label": 0
                },
                {
                    "sent": "So the topic is relational representation of statistical machine learning.",
                    "label": 0
                },
                {
                    "sent": "So most of you are probably familiar with this problematic, but I like to still introduce it so relational representation is a truthful view of many relevant domains and is the basis for 1st order logic.",
                    "label": 1
                },
                {
                    "sent": "So there are relational databases everywhere, and there's a good reason why their relational databases, because they reflect the content quite truthfully.",
                    "label": 1
                },
                {
                    "sent": "Statistical machine learning has mostly worked with a flat table representation.",
                    "label": 0
                },
                {
                    "sent": "It has been a lot of work on the combination of statistical machine learning with relation representations, often called statistical, relational learning SRL.",
                    "label": 0
                },
                {
                    "sent": "So you might know the probabilistic relational model.",
                    "label": 1
                },
                {
                    "sent": "The DARPA formulation, or Markov logic networks.",
                    "label": 0
                },
                {
                    "sent": "So I will use the DARPA formalism extensively so that today I will present a nonparametric Bayesian view on statistical relational learning in form of the infinite in relational model, which has many interesting advantages.",
                    "label": 1
                },
                {
                    "sent": "There's no structure learning involved.",
                    "label": 1
                },
                {
                    "sent": "We achieve multi relational clustering and then I also want to comment on applications to the semantic web or statistical machine learning.",
                    "label": 0
                },
                {
                    "sent": "So this is more maybe provocative and might lead to some discussions 'cause I don't claim to be an expert on the semantic web.",
                    "label": 0
                },
                {
                    "sent": "I'm looking at it as a machine learning person and try to make sense of it.",
                    "label": 0
                },
                {
                    "sent": "So let's first look at the relational work.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a big family and if these guys would not have been related, the course of history of the 20th century would probably have been quite different, so it's important to know who's related.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To whom, because their social networks, so I don't have to introduce this, but we have friends.",
                    "label": 1
                },
                {
                    "sent": "We have colleagues.",
                    "label": 0
                },
                {
                    "sent": "We have superiors, subordinates, they have friends, they have colleagues and so on.",
                    "label": 1
                },
                {
                    "sent": "And we know that we are closely connected to almost everybody in the world to only a small number of links.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then there's of course the web, which is a big relational system of interconnected hyperlinked web pages, and we know that in the information about the linkage, there's a lot of information to be exploited.",
                    "label": 0
                },
                {
                    "sent": "For example, in terms of.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Search engine.",
                    "label": 0
                },
                {
                    "sent": "And this is our DF, which is the basis for the semantic web.",
                    "label": 1
                },
                {
                    "sent": "And we also see that this is a relational graph, for example.",
                    "label": 0
                },
                {
                    "sent": "Gone with the wind.",
                    "label": 0
                },
                {
                    "sent": "The author of Gone with Windows Mitchell.",
                    "label": 0
                },
                {
                    "sent": "So you see that different objects involved and there's not a simple table representation which we use here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then also patient.",
                    "label": 0
                },
                {
                    "sent": "This is also something closer to Siemens is part of relational world with many different entities, physicians, hospitals, medications, orders, diagnosis, context.",
                    "label": 1
                },
                {
                    "sent": "This person had bacterial viral strains and we think there's a lot of potential for exploiting this relational information in the medical domain.",
                    "label": 0
                },
                {
                    "sent": "If you want to for exam.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Think about recommendation systems for physicians.",
                    "label": 0
                },
                {
                    "sent": "Then often relationships are more informative than attributes.",
                    "label": 1
                },
                {
                    "sent": "We all know that in recommender systems you exploit relation information about what you have bought before or what you were interested in before gives a lot of information about what you might be interested in the future and not so much your own properties or your own attributes are not so much the attributes of the object.",
                    "label": 0
                },
                {
                    "sent": "So most recommended systems ignore these attributes and completely rely on the relation information and for example, social settings might be.",
                    "label": 0
                },
                {
                    "sent": "More telling, if you're member of a club, then many, many attributes you have.",
                    "label": 0
                },
                {
                    "sent": "Um also often information about relations as relationships is easier to obtain and more reliable than information about attributes.",
                    "label": 1
                },
                {
                    "sent": "For example, if you look at the page rank algorithm which exploits the linkage information and not so much attributes and of course relational databases are everywhere.",
                    "label": 0
                },
                {
                    "sent": "So that might mean or should mean that there's something.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important in this representation, computational biology is another application where you have interacting genes, so you have a network of genes.",
                    "label": 0
                },
                {
                    "sent": "Genes have attributes and you want to study properties of gene.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And interaction properties of proteins.",
                    "label": 0
                },
                {
                    "sent": "Another application, of course, is the extraction of textual analysis of textual information, extraction of content from text.",
                    "label": 0
                },
                {
                    "sent": "So you can describe it extracted information as entities and relationships between entities named entity recognition, relation extraction and of course there also cited citations in scientific papers and patterns which you can exploit.",
                    "label": 1
                },
                {
                    "sent": "So if you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Take a closer look.",
                    "label": 0
                },
                {
                    "sent": "You see relation learning everywhere, so this is some speculation about cognitive aspects.",
                    "label": 0
                },
                {
                    "sent": "Some fascinated with this along, which seem to remember many, many things in great detail and even more interesting is that some research suggests that the ability can be induced which might support the view that so long abilities are latent with all people, but are obscured by the normal functioning intellect.",
                    "label": 1
                },
                {
                    "sent": "So it means that we all have this capability.",
                    "label": 0
                },
                {
                    "sent": "We just don't know how to use it.",
                    "label": 0
                },
                {
                    "sent": "But how is this all stored?",
                    "label": 0
                },
                {
                    "sent": "So maybe a relation representation in some sense is also used in biology?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we might conclude that we are all embedded in a relational world where everything and everybody is connected and over some links.",
                    "label": 1
                },
                {
                    "sent": "Everything depends on everything.",
                    "label": 0
                },
                {
                    "sent": "So so I like to call it John Donne principle.",
                    "label": 0
                },
                {
                    "sent": "So who is John Dunn?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He is a Jacobian poet and teacher and is famous for many things.",
                    "label": 0
                },
                {
                    "sent": "And mother, among other things, this piece of text, which was also used by Hemingway in the novel for whom the Bell tolls.",
                    "label": 0
                },
                {
                    "sent": "So he puts it in this way.",
                    "label": 0
                },
                {
                    "sent": "No man is an island, and tie off itself.",
                    "label": 1
                },
                {
                    "sent": "Every man is a piece of the continent apart of the main immense.",
                    "label": 1
                },
                {
                    "sent": "Death diminishes me because I am involved in mankind and therefore never send to know for whom the Bell tolls.",
                    "label": 1
                },
                {
                    "sent": "It talks for the so this is a nice poetic formulation of everything depends.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Everything.",
                    "label": 0
                },
                {
                    "sent": "That's better this previous work.",
                    "label": 0
                },
                {
                    "sent": "A lot of ongoing work, and you're probably familiar with a lot of it mean that specialized algorithms to solve special problems petrang collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "There's this huge body of work on LP type of approaches, and this is one of the conferences where this is presented, and a lot of detail.",
                    "label": 0
                },
                {
                    "sent": "And so I want to focus on this view, which I called principled.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic approaches statistical relational learning, and there's a PRM approach.",
                    "label": 0
                },
                {
                    "sent": "Kohler, Friedman, Keturah, Peppa and others.",
                    "label": 0
                },
                {
                    "sent": "They combine a later description with components from frame based systems and Bayesian networks when very related.",
                    "label": 1
                },
                {
                    "sent": "Is the DARPA formalism of Heckerman, Meek and color, which used the entity relationship model in combination with patient networks?",
                    "label": 0
                },
                {
                    "sent": "So this is what I'm using in my presentation here.",
                    "label": 1
                },
                {
                    "sent": "Then the relation of Markov networks and Markov logic networks, and probably a few more I don't.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mention.",
                    "label": 0
                },
                {
                    "sent": "So some problems of the previous workers.",
                    "label": 1
                },
                {
                    "sent": "It's often not so easily applicable, at least for example, the PRM model requires.",
                    "label": 0
                },
                {
                    "sent": "Typically, extensive structure learning and structure learning is quite difficult, and PRM models because the search space is so large, so you need reliable prior knowledge clauses in Markov logic networks, although I guess I learned that it's easier to apply than I thought, so the clauses.",
                    "label": 1
                },
                {
                    "sent": "You have to come up in Markov logic networks.",
                    "label": 0
                },
                {
                    "sent": "It's not, it's difficult 'cause they're not.",
                    "label": 0
                },
                {
                    "sent": "They're sort of features and rules.",
                    "label": 0
                },
                {
                    "sent": "So often the relational modeling unique identity, often the unique identity of an entity, has predictive power, as in collaborative filtering, and this is difficult for some of the approaches, and missing attributes require often complex inference.",
                    "label": 1
                },
                {
                    "sent": "So people use loopy belief propagation.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another approximate methods.",
                    "label": 0
                },
                {
                    "sent": "So in this work we apply a nonparametric hierarchical Bayesian modeling to relational learning and achieve nonparametric relational basin form of the infinite hidden relational model.",
                    "label": 1
                },
                {
                    "sent": "So we're taking two very complicated things and hope I can convince you what comes out is sort of simpler than the individual things.",
                    "label": 1
                },
                {
                    "sent": "So Adventure is straightforward to apply without extensive structure, learning attributes and identities of entities can have predictive power.",
                    "label": 0
                },
                {
                    "sent": "And we achieve a clustering in the relational domain.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So cluster analysis.",
                    "label": 0
                },
                {
                    "sent": "So let's take the path from traditional learning to relational learning.",
                    "label": 1
                },
                {
                    "sent": "So this is nobody you probably know.",
                    "label": 0
                },
                {
                    "sent": "Also not running for president, or he might be.",
                    "label": 0
                },
                {
                    "sent": "The leader of the world after the nuclear Holocaust or this is this guy has been dead for 50,000 years or so.",
                    "label": 0
                },
                {
                    "sent": "But the photo was taken with digital camera exactly.",
                    "label": 0
                },
                {
                    "sent": "Reconstructed him like forensic experts or something.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so we're used to IID learning at least.",
                    "label": 0
                },
                {
                    "sent": "The non LP people at better this way so we all love the matrix and because we can present our data typically in the matrix with an idea assumption.",
                    "label": 0
                },
                {
                    "sent": "So this is a patient.",
                    "label": 0
                },
                {
                    "sent": "A patient has properties and outcome of a disease or something and you might want to model the dependency of patient property and outcome and this is how you can draw it in adapter model and this is how you represent it as a table and so this is what we're all familiar with.",
                    "label": 0
                },
                {
                    "sent": "Data are sampled independently.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can just plug it into any learning.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Russian support vector machine or something.",
                    "label": 0
                },
                {
                    "sent": "So the time series is already a little bit different, so if you model the Dow Jones mean there's only one Dow Jones, you cannot have independent samples of many.",
                    "label": 1
                },
                {
                    "sent": "Dow Jones is, but of course you can do learning because you assume there's some invariants in the model, so this template of local dependency can be copied in time, and this allows you to.",
                    "label": 1
                },
                {
                    "sent": "To do learning, this already has a flavor of relational learning because you have this sort of template idea and you have this idea that in fact you really only have one data point in some sense and also everything you know all the excess influence all the pages and influence other predictions.",
                    "label": 0
                },
                {
                    "sent": "So there is sort of glow.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dependencies.",
                    "label": 0
                },
                {
                    "sent": "So the next step towards relation learning is very hierarchical Bayesian modeling.",
                    "label": 1
                },
                {
                    "sent": "So here's an application to unitology.",
                    "label": 0
                },
                {
                    "sent": "Which gives you impression.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How this works?",
                    "label": 0
                },
                {
                    "sent": "So the idea is that a patient is in a hospital in this example, and.",
                    "label": 1
                },
                {
                    "sent": "I mean, you assume probably this.",
                    "label": 0
                },
                {
                    "sent": "This model should be slightly different in the hospitals because they have different training, different physicians, different environments, different ages.",
                    "label": 0
                },
                {
                    "sent": "But you also don't think that every hospital should have its own model.",
                    "label": 1
                },
                {
                    "sent": "So this is sort of shown here.",
                    "label": 0
                },
                {
                    "sent": "If you introduce the identical, the idea of the hospital as an input variable, you might get a model which is separate for each hospital.",
                    "label": 1
                },
                {
                    "sent": "So if you have a lot of data for each hospital is fine, but if you want to sort of share.",
                    "label": 0
                },
                {
                    "sent": "The statistical strength this is a bad idea, so the solution.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one solution is hierarchical Bayesian modeling.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you still allow for each hospital to have its own parameters.",
                    "label": 0
                },
                {
                    "sent": "But they are coupled by a common prior distribution.",
                    "label": 0
                },
                {
                    "sent": "And in some sense, by learning this prior distribution, you can transport knowledge across hospitals.",
                    "label": 1
                },
                {
                    "sent": "So if you have a new hospital and you want to learn a model, you can start with a very informative prior distribution which has been learned from the previous hospitals.",
                    "label": 1
                },
                {
                    "sent": "Of course, the tube Asian would say OK have to integrate, integrate, integrate, but in effect this is sort of going on and you assume you achieve great flexibility if you assume that you have a very flexible prior distribution.",
                    "label": 0
                },
                {
                    "sent": "And it's very convenient to work with seriously processes here.",
                    "label": 0
                },
                {
                    "sent": "'cause the sample of additional process is very, very flexible.",
                    "label": 0
                },
                {
                    "sent": "So write it like this.",
                    "label": 0
                },
                {
                    "sent": "DP of Jeannerod is called base distribution.",
                    "label": 0
                },
                {
                    "sent": "An iPhone or twitches concentration parameter Ann.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look what's going on, so hopefully this is makes it clear.",
                    "label": 0
                },
                {
                    "sent": "So if you start to learn a model, you might start off with some uninformative prior distribution on the parameters, so this sort of should indicate a Gaussian uniform variance and mean zero, and then you Start learning and the posterior parameter distribution gets changed and eventually it becomes a dot.",
                    "label": 0
                },
                {
                    "sent": "So you have a point distribution.",
                    "label": 0
                },
                {
                    "sent": "If you see many many, many data.",
                    "label": 0
                },
                {
                    "sent": "And this thought we we draw into this graph, and then we do it for the next hospital for the next hospital.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And then we see the distribution of all these parameters.",
                    "label": 0
                },
                {
                    "sent": "Of all the hospitals under consideration.",
                    "label": 0
                },
                {
                    "sent": "And if this, if this is also can be described by a Gaussian, like in this case, then this is called hierarchical Bayesian modeling, because what effect is going on this parameters in discussion change to the parameters to describe this question.",
                    "label": 0
                },
                {
                    "sent": "So the mean is changed and the covariance is changed.",
                    "label": 0
                },
                {
                    "sent": "But then the question is, I mean do we?",
                    "label": 0
                },
                {
                    "sent": "Can we really believe that sort of actual distribution of hospital parameters follows this simple distribution?",
                    "label": 0
                },
                {
                    "sent": "Isn't it often odd, shaped and maybe multimodal?",
                    "label": 0
                },
                {
                    "sent": "Some weird thing and that's why we should have a prior distribution which can represent these strange things?",
                    "label": 0
                },
                {
                    "sent": "And this is how the where the nonparametric Bayesian model comes in.",
                    "label": 0
                },
                {
                    "sent": "Because if you study this, the.",
                    "label": 0
                },
                {
                    "sent": "Distributions can be rich, can be represented, extremely flexible, and can model these type of distributions.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's another view on this, which is maybe more intuitive.",
                    "label": 0
                },
                {
                    "sent": "Another way to approach this problem is to say, OK, there's a cluster variable which each hospital, so each hospital is in some cluster, and if you know in which cluster it is, we also know which parameters to pick.",
                    "label": 0
                },
                {
                    "sent": "So this is just a clustering formulation.",
                    "label": 0
                },
                {
                    "sent": "Now there's another way of saying there's something hidden in the hospitals which I don't know about that I should model.",
                    "label": 0
                },
                {
                    "sent": "And it turns out now if you let the number of states in Z.",
                    "label": 0
                },
                {
                    "sent": "Go to Infinity.",
                    "label": 0
                },
                {
                    "sent": "You achieve the so called directly process mixture model.",
                    "label": 0
                },
                {
                    "sent": "And it turns out this is exactly equivalent to the nonparametric hierarchical Bayesian approach, with it usually processed prior.",
                    "label": 1
                },
                {
                    "sent": "So what I told you before is exactly equivalent to this.",
                    "label": 0
                },
                {
                    "sent": "But here I like this much better because here is easier to think about everything.",
                    "label": 0
                },
                {
                    "sent": "We sort of know how to work with clustering.",
                    "label": 0
                },
                {
                    "sent": "We know how to work with mixture models, so we have an intuition of what is going on here.",
                    "label": 0
                },
                {
                    "sent": "Whereas in the other formula formalism it's more difficult to get intuition of how to do to do with this.",
                    "label": 0
                },
                {
                    "sent": "So one thing is just too.",
                    "label": 0
                },
                {
                    "sent": "Think of it as a finite model.",
                    "label": 0
                },
                {
                    "sent": "Do something with finite mixture models and then just say OK, let me let the number of states approach Infinity and then I have to actually process mixture model.",
                    "label": 1
                },
                {
                    "sent": "That's a nice thing.",
                    "label": 0
                },
                {
                    "sent": "Of course one of the attractive things here is that you give the model infinite number of clusters, but the model will only use a small number of clusters and you can think of this extra number of clusters.",
                    "label": 0
                },
                {
                    "sent": "The model is using as the estimated number of two clusters in your system, so you don't have to do this extensive.",
                    "label": 0
                },
                {
                    "sent": "Model selection anymore to try to determine the true number of cluster components.",
                    "label": 0
                },
                {
                    "sent": "This seriously process mixture model does it automatically because there's a tuning parameter, but it's not very sensitive to this tuning parameter.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I think that.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set this OK so the next thing then is now relational modeling and learning.",
                    "label": 0
                },
                {
                    "sent": "So Tom literally said we're in the middle of the relation.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evolution.",
                    "label": 0
                },
                {
                    "sent": "Yeah, not surprisingly.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have to deal with relational databases and there's one way to describe a model of a database schema in terms of this entity relationship model.",
                    "label": 0
                },
                {
                    "sent": "So this is a short introduction into the ER model, so we have entity classes, so these are sets of objects.",
                    "label": 1
                },
                {
                    "sent": "For example students and courses.",
                    "label": 0
                },
                {
                    "sent": "We have attributes so students might have an IQ of course might have a difficulty, and there's a relationship class which sort of tells you about relationships between the objects.",
                    "label": 0
                },
                {
                    "sent": "In this case, a student takes a class and also this this guy might have an attribute because the student will get a grade in the class, so this is.",
                    "label": 0
                },
                {
                    "sent": "What we have to know about databases today, and I think it's quite intuitive and graphics.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the Doppler motive.",
                    "label": 0
                },
                {
                    "sent": "So here you simply add a template for probabilistic dependencies.",
                    "label": 1
                },
                {
                    "sent": "So you add the arcs without the error.",
                    "label": 0
                },
                {
                    "sent": "So these are dependencies in the sense of herb Asian Network Now, so this is dependent on its parents.",
                    "label": 1
                },
                {
                    "sent": "Then you have to add the local distribution class which quantifies this dependency and you might have to introduce constraints which are in this case trivial.",
                    "label": 1
                },
                {
                    "sent": "So only the IQ of the student who takes the course will influence his grade and not the IQ of another student.",
                    "label": 0
                },
                {
                    "sent": "So we don't have to do this constraints in the following, so just.",
                    "label": 0
                },
                {
                    "sent": "For completeness, so this indicates what the probabilistic dependencies are, and of course.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "The real world doesn't consist of these templates, but of real data.",
                    "label": 0
                },
                {
                    "sent": "So you apply this data to a real database of real students and real courses and you obtain this sort of ground network.",
                    "label": 0
                },
                {
                    "sent": "So these are accused of three different students.",
                    "label": 0
                },
                {
                    "sent": "These are the difficulties of two causes, and these are the grades the student got in the course.",
                    "label": 0
                },
                {
                    "sent": "So this is what you really have to deal with, and you see already the problem here.",
                    "label": 0
                },
                {
                    "sent": "Everything is connected.",
                    "label": 0
                },
                {
                    "sent": "It's a huge page network.",
                    "label": 0
                },
                {
                    "sent": "You have to do big influence.",
                    "label": 0
                },
                {
                    "sent": "You also see why it's only one data point, it's really.",
                    "label": 0
                },
                {
                    "sent": "Everything depends on everything sort of thing.",
                    "label": 0
                },
                {
                    "sent": "This is the same thing for recommendation system.",
                    "label": 0
                },
                {
                    "sent": "You have users, movies, user attributes, movie attributes, and maybe you model.",
                    "label": 1
                },
                {
                    "sent": "If a user will see a movie and this.",
                    "label": 0
                },
                {
                    "sent": "This is how it looks.",
                    "label": 0
                },
                {
                    "sent": "The ground network looks in this case.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said, this relational modeling often involves a lot of structure learning, so this here is a result of the guys who worked on the PRM model and this is painful because it's even more complicated than normal Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "So people have done this and people get these nice results about dependencies and medical domain.",
                    "label": 0
                },
                {
                    "sent": "But if you just want to straightforwardly apply.",
                    "label": 0
                },
                {
                    "sent": "Relational modeling statistical learning to relational model this is.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We live in two painful, so let's combine relational learning with nonparametric hierarchical Bayes.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so questions please ask them.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, Particulation models are also the top performers.",
                    "label": 0
                },
                {
                    "sent": "They're pretty much equivalent if you extend a little bit PRM models their equivalent, their templates leading to parameter sharing in the ground Bayesian network.",
                    "label": 1
                },
                {
                    "sent": "So it's a template you apply all over the place, but this might be too stiff for many applications.",
                    "label": 1
                },
                {
                    "sent": "Ever seen that sometimes you want to have this hierarchical basian stuff of parameter sharing or parameter.",
                    "label": 0
                },
                {
                    "sent": "Visual parameters which are tight by some prior distribution.",
                    "label": 0
                },
                {
                    "sent": "So how do we do that?",
                    "label": 1
                },
                {
                    "sent": "So the question is how to generalize hierarchical patient modeling to relational learning.",
                    "label": 0
                },
                {
                    "sent": "If you think of parametric hierarchical Bayesian modeling, I think it's very difficult and I couldn't really figure out how to do that.",
                    "label": 0
                },
                {
                    "sent": "But the nonparametric hierarchical Bayesian approaches is much easier to generalize because you have this interpretation as this infinite cluster problem, so that's why we jump right away to the non parameter case.",
                    "label": 0
                },
                {
                    "sent": "I don't care about the price.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Better case.",
                    "label": 0
                },
                {
                    "sent": "I should also mention that the two groups working in this mainly is our own group here in Munich.",
                    "label": 0
                },
                {
                    "sent": "And then there's the group of Camp Group for Tennenbaum, Yamada and Wajda, who in 2006 we came up with almost the same model.",
                    "label": 0
                },
                {
                    "sent": "Not quite, but almost an almost the same title as well, so and if you don't follow my presentation, look at their papers.",
                    "label": 0
                },
                {
                    "sent": "It's also very excellent paper.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But slightly different point of view.",
                    "label": 0
                },
                {
                    "sent": "What's the idea and the idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "A recommendation engine, so you predict the rating based on user attributes and movie attributes, and if these are strong attributes, if you really know a lot about the movie and a lot about the movie and the user, this is maybe all you want to do and you're perfectly happy, but now.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course, in reality you don't know too much about the user, so you must assume there's some hidden information which is relevant for the model which you don't know about, and that's why we introduced this clustering variable.",
                    "label": 0
                },
                {
                    "sent": "This latent variable ZU for the user and tire to the attribute information, so it so we can also exploit user attributes, and this is not a predictor for the relation, and this is very much very similar to the hospital problem I showed you before.",
                    "label": 0
                },
                {
                    "sent": "There's a before this was a hospital and it was associated with a hidden variable and now it's the user associated with a hidden variable.",
                    "label": 0
                },
                {
                    "sent": "And this is pretty much standard recognition modeling.",
                    "label": 0
                },
                {
                    "sent": "Of course you can.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The same thing with the movies.",
                    "label": 0
                },
                {
                    "sent": "So we also introduce the latent variable here and tie the movie attributes in this fashion, 'cause we also assume that we don't have a complete description of a movie.",
                    "label": 0
                },
                {
                    "sent": "And this now gives you, and of course, now we let the number of states go to Infinity, and then we have interacting, usually process mixture models and so this is all we're doing.",
                    "label": 0
                },
                {
                    "sent": "And this is the key slide of the talk.",
                    "label": 1
                },
                {
                    "sent": "So very simple 1 hidden variable, another hidden.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the this is when we add the parameters, which becomes a bit more complicated if you're an expert in DP thick breaking representations, you will recognize these things, otherwise it's not too difficult to hear something was screwed up.",
                    "label": 0
                },
                {
                    "sent": "Essentially, this state of this depends on the cluster states, the state of the cluster, variables of the associated entities.",
                    "label": 0
                },
                {
                    "sent": "This is what I was showing.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here and.",
                    "label": 0
                },
                {
                    "sent": "So the recipe is very simple for each entity, or at least for the ones which you need to model in a probabilistic fashion.",
                    "label": 0
                },
                {
                    "sent": "Introduce an infinite latent variable.",
                    "label": 1
                },
                {
                    "sent": "Specific to each entity class, so you can have several different kinds of latent variables.",
                    "label": 1
                },
                {
                    "sent": "So before I get one for user, one for movies and this latent variables, the parent of the remaining attributes of the entity and it's also the parent of the relationships.",
                    "label": 1
                },
                {
                    "sent": "This entity is involved in.",
                    "label": 0
                },
                {
                    "sent": "So this is the model, so the question might be, is this to limit it because we assume very local dependencies now totally before and PRM you have to do this expensive structure learning and consider long-term dependencies too.",
                    "label": 0
                },
                {
                    "sent": "High complexity, so this seems to be very simple, but we have an argument why this might still be.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sufficient, and the reason is that if you look at the ground network for this recommendation system and the simple way without the latent variable, you predict from attributes the relation of the ratings here.",
                    "label": 1
                },
                {
                    "sent": "And of course, here the information is blocked because if you know the attributes now, then in the Bayesian network this pass is blocked and no information can propagate, which is also nice because you can do local inference.",
                    "label": 0
                },
                {
                    "sent": "But if you introduce this latent variables here Z then you get this type of ground network and now since this one is unknown this is open.",
                    "label": 0
                },
                {
                    "sent": "This opens up and can propagate through this Collider and so on.",
                    "label": 0
                },
                {
                    "sent": "So information can propagate globally in the system so even long range dependencies kind of principle.",
                    "label": 0
                },
                {
                    "sent": "Followed by the.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By this model, this is another example, so I drew this a little bit more like an image.",
                    "label": 0
                },
                {
                    "sent": "So the ACE might be sort of pixels and Ers are relations between pixels, so indicating this is a neighbor neighboring pixel, for example.",
                    "label": 0
                },
                {
                    "sent": "So here information will be blocked if you know a.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It blocks all the information, but if you introduce the latent variable, this is open, and this is also open because it's unknown and this is you might recognize this as a model of image reconstruction, often used so the Z would be the unknown pixel values are would indicate I'm a neighboring pixel and a would be the noisy measurement of a pixel, so this, so in some sense this image reconstruction model can be thought of as a special case.",
                    "label": 0
                },
                {
                    "sent": "Of the infinite hidden relation of model.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are some advantages.",
                    "label": 0
                },
                {
                    "sent": "We can predict attributes we can predict, links.",
                    "label": 1
                },
                {
                    "sent": "We can handle relationships and entities of multiple types.",
                    "label": 1
                },
                {
                    "sent": "If if some if the mother decides that some person is quite unique, he can get its own cluster, so we can completely personalize.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we share sophistical strength.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we don't need to do structure learning store.",
                    "label": 0
                },
                {
                    "sent": "The information can flow through the system.",
                    "label": 1
                },
                {
                    "sent": "We have no loops.",
                    "label": 1
                },
                {
                    "sent": "By construction we have no partition function.",
                    "label": 0
                },
                {
                    "sent": "No compass point, complex aggregation, no problem with many to many.",
                    "label": 1
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We achieved clustering and relational domain and later on we will analyze some of the clusters.",
                    "label": 0
                },
                {
                    "sent": "Each entity class can determine its own optimal number of components, so we don't have to do this complex model selection process where we have to change the number of latent states for each entity and would be very, very complicated.",
                    "label": 1
                },
                {
                    "sent": "Missing data can be ignored because we have colliders there, so they just drop out.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So these are some.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dentist, there's some scaling issues I don't want to necessarily get into this too much, but one thing we can exploit is if there's a strong default relationship.",
                    "label": 0
                },
                {
                    "sent": "For example, in many applications, default relationship is, there is no relation, you only have one parent and not 3 billion or something.",
                    "label": 0
                },
                {
                    "sent": "This can be exploited because only the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Listing relation give you information about the missing ones.",
                    "label": 0
                },
                {
                    "sent": "OK, now yeah, this was the.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Positive story another.",
                    "label": 0
                },
                {
                    "sent": "Of course there's the problem in all of this is inference.",
                    "label": 0
                },
                {
                    "sent": "But it's not a terrible problem.",
                    "label": 0
                },
                {
                    "sent": "Typically, if you have, you might have heard of this in this type of systems, you do something like the Chinese restaurant sampling process or different approximations to that.",
                    "label": 1
                },
                {
                    "sent": "So we have worked with the Chinese restaurant process sampling usually multinomial allocation truncated.",
                    "label": 1
                },
                {
                    "sent": "Usually process is these are two approximation of those so called stick breaking process.",
                    "label": 0
                },
                {
                    "sent": "But these are details I don't want to get into it too much.",
                    "label": 1
                },
                {
                    "sent": "We also investigated to mean field approximations and some simple memory based empirical approximation.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "122 is too slow.",
                    "label": 0
                },
                {
                    "sent": "So the first task is exactly a recommended recommended system, the ones.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I showed you before and these are the attributes of the user and the movies, so age, gender, occupation, general of the movie, year of the movie.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the results we were getting.",
                    "label": 0
                },
                {
                    "sent": "So GS always stands for Gibbs sampler and me MF4 mean field and the empirical approximation.",
                    "label": 0
                },
                {
                    "sent": "This is a given the active user has seen 5 or rated 5 movies 1015 Twenty I mean the main result is that the sampling approaches are slightly better than the midfield approximations.",
                    "label": 0
                },
                {
                    "sent": "Empirical approximation was not quite as good here, but the speed is there's a lot of speed improvement if you go to the mean field approximations compared to the sampling approaches.",
                    "label": 0
                },
                {
                    "sent": "Of components found is also different.",
                    "label": 0
                },
                {
                    "sent": "Gibbs sampler found more components I mean needed more cluster states than the mean field approximations.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the occupied states of the clusters, you recognize that they are pretty much the same, so they simply have longer tails which are not heavily occupied by objects.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting to analyze the clusters and I was so personally quite surprised to see pretty clear clusters because the attributes don't have so much predictive power, so most of the information is in the rating.",
                    "label": 0
                },
                {
                    "sent": "So in the relationships and I didn't expect that the classes would be very meaningful, but I thought I think the labels we found quite interesting, so this means I think 207 movies are in this cluster and 161 of them are sort of stable in this cluster and don't change in the sampling process.",
                    "label": 0
                },
                {
                    "sent": "And the sampling process is.",
                    "label": 0
                },
                {
                    "sent": "Movies get assigned to different clusters, but some of state.",
                    "label": 0
                },
                {
                    "sent": "So this is the biggest one is very new and so this is from 1997.",
                    "label": 0
                },
                {
                    "sent": "So at that time it was very new and popular movies Sabrina and so on.",
                    "label": 0
                },
                {
                    "sent": "Then the second one old older non US, typically non US and drama movies then here comedy Get Shorty.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Swingers these are my children oriented movies.",
                    "label": 0
                },
                {
                    "sent": "These are new action movies at that time.",
                    "label": 0
                },
                {
                    "sent": "The game the Rock would older action movies.",
                    "label": 0
                },
                {
                    "sent": "Fugitive Indiana Jones older drama and Harrison Ford leads his own cluster, of course.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a distribution on clusters, so you see.",
                    "label": 0
                },
                {
                    "sent": "Green ones are Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "Brahmins are Greenfield approximation and in the left part there's some agreement on that.",
                    "label": 0
                },
                {
                    "sent": "They're not so cool.",
                    "label": 0
                },
                {
                    "sent": "Two different here.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Key.",
                    "label": 0
                },
                {
                    "sent": "These are some technical details so important.",
                    "label": 0
                },
                {
                    "sent": "One is probably here on 99143 users, 600 movies.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second problem we analyzed is from bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "So the task here is cluster analysis of genes in a in a dynamic network and also prediction of gene functions given information on the gene level and the protein level as well as the interactions between the genes.",
                    "label": 1
                },
                {
                    "sent": "We used data from the sick D database, comprehensive use genome database.",
                    "label": 1
                },
                {
                    "sent": "From the Munich Information Center for protein sequences, we used 1000 genes in this experiment.",
                    "label": 0
                },
                {
                    "sent": "Another experiment we use slightly different number and the attributes are OK.",
                    "label": 0
                },
                {
                    "sent": "I will discuss in a second the interaction data are from the DIP data based on interacting proteins.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "The Top Model we used in this case, so there's actually only one entity.",
                    "label": 0
                },
                {
                    "sent": "This is gene with the cluster variable over here and the gene can interact with other genes is modeled in this way.",
                    "label": 1
                },
                {
                    "sent": "And so this is the variable which decides if the gene interacts with another gene and then there are several sort of attributes which describe the gene.",
                    "label": 0
                },
                {
                    "sent": "So here are some of the attributes gene function.",
                    "label": 1
                },
                {
                    "sent": "Different functions that gene might interact with another gene, different phenotypes, expression of the gene, complex with others to form.",
                    "label": 1
                },
                {
                    "sent": "Larger proteins, structure categories, motives and gene.",
                    "label": 1
                },
                {
                    "sent": "Another gene attributes like essential, and on which chromosome it located again.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's interesting here to look at the ground network, which looks sort of like this so you see this Ascension interacting network of genes so.",
                    "label": 0
                },
                {
                    "sent": "These are the latent variants of the jeans, and they have interactions to other jeans.",
                    "label": 1
                },
                {
                    "sent": "And here you see sort of the attributes, which are sort of derived from the hidden latent states of the jeans.",
                    "label": 0
                },
                {
                    "sent": "But this is a ground network.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And and this result we were getting.",
                    "label": 0
                },
                {
                    "sent": "So this shows a subset of the genes and you see that the colors correspond to the cluster membership.",
                    "label": 0
                },
                {
                    "sent": "So you see sort of isolated gene clusters.",
                    "label": 1
                },
                {
                    "sent": "Here's a connected set.",
                    "label": 0
                },
                {
                    "sent": "You can also try to interpret those clusters, so I'm not the expert in bioinformatics so that this doesn't necessarily tell me too much.",
                    "label": 0
                },
                {
                    "sent": "We don't show the connections or relations to.",
                    "label": 0
                },
                {
                    "sent": "Jeans and other clusters not too.",
                    "label": 0
                },
                {
                    "sent": "Clutter the image too much, so these are the connections in these groups of clusters shown here and you might notice that the clustering sort of follows the graph structure, so this indicates that the gene interaction is a very important information in the analysis of the clustering and is not ignored by the model, so it doesn't just rely on the attributes, but it also includes very much the interaction information.",
                    "label": 0
                },
                {
                    "sent": "So the notes are the jeans.",
                    "label": 1
                },
                {
                    "sent": "The links are the interactions and the colors of the clusters.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's some statistics.",
                    "label": 0
                },
                {
                    "sent": "This shows you if you were to remove that information, how much performance you would lose.",
                    "label": 0
                },
                {
                    "sent": "So the most important information is information about the complex.",
                    "label": 0
                },
                {
                    "sent": "If you remove that, the performance drops considerably, but the next important information is about the interaction between the genes, so.",
                    "label": 0
                },
                {
                    "sent": "Which is also indicated in the clustering inside that the interaction information is quite important.",
                    "label": 0
                },
                {
                    "sent": "So in this case we don't evaluate.",
                    "label": 0
                },
                {
                    "sent": "In some sense the clustering quality, but the prediction of the function.",
                    "label": 0
                },
                {
                    "sent": "So that's why I didn't tell you that.",
                    "label": 0
                },
                {
                    "sent": "So this is predictive information, not the cluster information, but to predict function.",
                    "label": 0
                },
                {
                    "sent": "These are the most important attributes are relationships used and which also indicates in this study that interaction is so very important.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Information.",
                    "label": 0
                },
                {
                    "sent": "We also work on including ontological information there is.",
                    "label": 0
                },
                {
                    "sent": "The gene ontology surround of different kinds kinds, and we consider this to be very important.",
                    "label": 0
                },
                {
                    "sent": "Prior information which you should include into learning.",
                    "label": 0
                },
                {
                    "sent": "That's at least one one way to look at that, and so we give the information about the.",
                    "label": 0
                },
                {
                    "sent": "Position in the taxonomy also to the system.",
                    "label": 0
                },
                {
                    "sent": "And of course, this cannot be treated simply as classes because there are some constraints here, because if you're active in some.",
                    "label": 0
                },
                {
                    "sent": "Subclass here all the classes you are derived from should also be active, and we can also so, but it's very easy to include this into the IRM model.",
                    "label": 0
                },
                {
                    "sent": "Just especially use this as additional attribute information and you could also integrate several ontologies, do some sort of ontology integration.",
                    "label": 0
                },
                {
                    "sent": "A very simple way.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we could show that by increasing, including ontologies, we can improve performance.",
                    "label": 0
                },
                {
                    "sent": "So this is these are RC curves concerning the prediction of function of genes and we used an ontology about complex of jeans.",
                    "label": 0
                },
                {
                    "sent": "And so these are our C curves, and you see with ontologies 800.",
                    "label": 0
                },
                {
                    "sent": "Training 200 test we show a significant increase in performance.",
                    "label": 1
                },
                {
                    "sent": "So the ontology helps you there.",
                    "label": 0
                },
                {
                    "sent": "Here we reduce the number of training data and.",
                    "label": 0
                },
                {
                    "sent": "The increase is even a little larger here because if you have enough data you don't need to ontology 'cause it's sort of a prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "We can integrate here.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The third experiment.",
                    "label": 0
                },
                {
                    "sent": "So I should tell you that we are interested in all these three application settings at Siemens, so we are currently working on a recommend assistant for videos home entertainment systems.",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "There's also a lot of interest in bioinformatics currently because of the potential for medical applications and this goes in the direction of medical recommendation systems so.",
                    "label": 0
                },
                {
                    "sent": "As I told you before, patients are also part of a relational world of diagnosis.",
                    "label": 0
                },
                {
                    "sent": "Procedures, physicians, hospitals and so on.",
                    "label": 0
                },
                {
                    "sent": "But we didn't.",
                    "label": 0
                },
                {
                    "sent": "We only model these sort of things, procedures, patients diagnosis in their properties.",
                    "label": 0
                },
                {
                    "sent": "So related to classes.",
                    "label": 0
                },
                {
                    "sent": "Or may I show you the.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plot right away.",
                    "label": 0
                },
                {
                    "sent": "Looks like this or this slightly simplified from the model we worked before, so there's a patient takes a procedure and decision is made about the patient and all these.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this usually processes should interact and should exploit all this information.",
                    "label": 0
                },
                {
                    "sent": "I mean, as I told you before this, there's always this collaborative filtering effect which is automatically in the system as in the collaborative filtering approach, which is nice because we know we can exploit exactly what procedures have already been taken by the patient to make a prediction for the new patient for the new for the new page or our predictor.",
                    "label": 0
                },
                {
                    "sent": "New procedure for the same patient.",
                    "label": 0
                },
                {
                    "sent": "So we have this also information about attributes here, but we also have.",
                    "label": 0
                },
                {
                    "sent": "Information about procedures already taken which correspond to movies already watched or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these are also RC curves based on the 1st procedure is known and we have to predict the second procedure and.",
                    "label": 0
                },
                {
                    "sent": "IRM is over here so it can exploit all this information in a very nice way.",
                    "label": 0
                },
                {
                    "sent": "So this is pure content based system where we don't have this relation information or this is information about previous procedure.",
                    "label": 0
                },
                {
                    "sent": "So it's basically a prediction just based on properties of patients and diseases and so on.",
                    "label": 0
                },
                {
                    "sent": "And so you see that.",
                    "label": 0
                },
                {
                    "sent": "It pays off, sort of to invest into this more sophisticated system because it has a way to smartly exploit all the knowledge in the system.",
                    "label": 0
                },
                {
                    "sent": "And so this is for all patients.",
                    "label": 1
                },
                {
                    "sent": "That is, for patients with the prime complaint circulatory.",
                    "label": 1
                },
                {
                    "sent": "Problem, so we hope that we can.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convince the.",
                    "label": 0
                },
                {
                    "sent": "Business unit to invest into this direction.",
                    "label": 0
                },
                {
                    "sent": "OK, so the conclusion for the first part will have some time.",
                    "label": 0
                },
                {
                    "sent": "So we have introduced by a time to realize nonparametric relational base an suggest that it might be an interesting model for a number of relational problems, so we don't have to do structural learning.",
                    "label": 1
                },
                {
                    "sent": "I guess, as in the Mac of Logic Network, I should probably say.",
                    "label": 0
                },
                {
                    "sent": "We have expressive ability.",
                    "label": 1
                },
                {
                    "sent": "We're coupling between heterogeneous relationships.",
                    "label": 1
                },
                {
                    "sent": "The model can decide itself about the optimal number of states for the latent variables.",
                    "label": 0
                },
                {
                    "sent": "I mean, I said this is 1 tuning parameter or not, but it's not very critical.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can sort of say OK.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can tune it that you looking for really large number of clusters or really a small number of classes or something in between.",
                    "label": 0
                },
                {
                    "sent": "But you cannot unit to produce seven or six clusters, so you have to tune it sensibly, but you don't have to tune it very, very carefully.",
                    "label": 0
                },
                {
                    "sent": "And the classes can be analyzed and you can understand.",
                    "label": 1
                },
                {
                    "sent": "Gain some understanding about the domain and the three applications are presented with recommendation systems.",
                    "label": 0
                },
                {
                    "sent": "Prediction of gene functions and medical decision support.",
                    "label": 0
                },
                {
                    "sent": "So and then so this.",
                    "label": 0
                },
                {
                    "sent": "Then I said, because this is in just a second session, I should also talk more about industrial perspectives.",
                    "label": 0
                },
                {
                    "sent": "And since I'm involved in this German funded project and I need to learn more about semantic Web, I thought let me also talk about the semantic web.",
                    "label": 0
                },
                {
                    "sent": "But of course it's very preliminary and not very.",
                    "label": 0
                },
                {
                    "sent": "I don't claim to be an expert, but maybe it.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "Stats would be based for some discussion.",
                    "label": 0
                },
                {
                    "sent": "So of course the semantic web.",
                    "label": 1
                },
                {
                    "sent": "This is a perfect fit.",
                    "label": 0
                },
                {
                    "sent": "Maritza relational domains relational learning fits quite well.",
                    "label": 0
                },
                {
                    "sent": "It has a route based component which is very interesting to learn about.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, IOP would be the perfect match.",
                    "label": 0
                },
                {
                    "sent": "But I also think statistical most artistical approaches should make very valuable contributions here.",
                    "label": 0
                },
                {
                    "sent": "So this again is sort of an RDF network and you see right away that this is a relational domain connecting many, many different kinds of objects.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Together OK, this is a test voice, so it's a national funded project for.",
                    "label": 1
                },
                {
                    "sent": "I say my web 123, so the web three is supposed to be the semantic web and there's a lot of activity there, but it will also contain web two components or social network components, social web components, social tagging ideas, and so on, and not so much web one.",
                    "label": 0
                },
                {
                    "sent": "So it's quite huge.",
                    "label": 0
                },
                {
                    "sent": "19 million euros over five years.",
                    "label": 0
                },
                {
                    "sent": "With a lot of industrial partners, alot of.",
                    "label": 0
                },
                {
                    "sent": "Research institutes Fraunhofer universities DF Cayey other research institutes there six use cases which focus on different application scenarios and are driven by companies like Siemens S IP battles Man Lycos and so on.",
                    "label": 0
                },
                {
                    "sent": "And there's also core technology cluster to develop the basic technologies to support the use cases.",
                    "label": 1
                },
                {
                    "sent": "So and I thought, oh, this is great.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I get involved in this.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in this list perfect, so I just want to essentially comment on some things on this semantic web.",
                    "label": 0
                },
                {
                    "sent": "As I said, I'm not definitely not the expert, so this is the structure you find.",
                    "label": 0
                },
                {
                    "sent": "A lot of places about how the semantic web is supposed supposed to work, so you gain in semantic power if you go up this hierarchy over here.",
                    "label": 0
                },
                {
                    "sent": "But maybe let's look at some of the.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, from my personal point of view, I think this is.",
                    "label": 0
                },
                {
                    "sent": "This is great and this works.",
                    "label": 0
                },
                {
                    "sent": "I would say growth should work today.",
                    "label": 0
                },
                {
                    "sent": "This is something we should all benefit from the day we know that XML is the basis for data exchange industry and this is already very powerful thing and as many commercial applications in the next layer.",
                    "label": 0
                },
                {
                    "sent": "The RDF layer, which has more of a relational structure should also be without question a great thing unless people in software design think there's some mistakes that I know for my point of view this is.",
                    "label": 0
                },
                {
                    "sent": "Undoubtedly very good thing and you can exchange distributed information using this format.",
                    "label": 0
                },
                {
                    "sent": "It's very intuitive to work with.",
                    "label": 0
                },
                {
                    "sent": "Has this simple subject predicate object sort of construct, and there's in my mind no doubt that this is a very useful thing.",
                    "label": 0
                },
                {
                    "sent": "It might happen first on the web, it might happen first in other applications because it's just a very convenient way to exchange structured data.",
                    "label": 0
                },
                {
                    "sent": "And agents would love.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This and other applications.",
                    "label": 0
                },
                {
                    "sent": "So then there's the ontology layer, which from my point of view, specifies the schema of course, and also adds a lot of sort of logical constraints.",
                    "label": 0
                },
                {
                    "sent": "So your domain and people spend a lot of time designing carefully ontological domains like jeans or medical many others, so they typically contain as hierarchical modeling a taxonomy, but they also include root root based constraints.",
                    "label": 0
                },
                {
                    "sent": "And I also think this is a great thing, because this is from a machine learning point.",
                    "label": 0
                },
                {
                    "sent": "Great source of prior knowledge and we should definitely use this in learning and probably other applications.",
                    "label": 0
                },
                {
                    "sent": "Should also use this.",
                    "label": 0
                },
                {
                    "sent": "So it's a great thing.",
                    "label": 0
                },
                {
                    "sent": "Then the neck.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Players are.",
                    "label": 0
                },
                {
                    "sent": "Logic proof and trust and my what I learned.",
                    "label": 1
                },
                {
                    "sent": "Also at this meeting is we're sort of here and haven't touched proof and trust yet, so I firmly believe that logical reasoning can contribute greatly to the semantic web.",
                    "label": 0
                },
                {
                    "sent": "But my point would be.",
                    "label": 0
                },
                {
                    "sent": "It should not be dependent on the power of reasoning and logic, because we know there are some.",
                    "label": 0
                },
                {
                    "sent": "It's not so easy to solve.",
                    "label": 0
                },
                {
                    "sent": "This problem is to scale it up to get people who are supposed to use the summoning deck to get a deep understanding of these issues.",
                    "label": 0
                },
                {
                    "sent": "So my point would be, let's just for now a little bit separated.",
                    "label": 0
                },
                {
                    "sent": "Work on this and.",
                    "label": 0
                },
                {
                    "sent": "Expect that these people have contributed greatly to the semantic web, but we shouldn't wait for them to solve all the problems.",
                    "label": 0
                },
                {
                    "sent": "That would be my main.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Discussion point.",
                    "label": 0
                },
                {
                    "sent": "So let's set up a few important tasks, classification and search, and so I just try to come up with a way I think.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In machine learning to it and how the semantic Web people probably would do so in machine learning you you have some inputs and you you don't care if this is semantic or not.",
                    "label": 0
                },
                {
                    "sent": "Could be structured or unstructured, could be flat or relational, was missing data are a problem.",
                    "label": 1
                },
                {
                    "sent": "So if you have typical feedforward system like a support vector machine or something like that you don't like missing data.",
                    "label": 0
                },
                {
                    "sent": "But that's OK. That's a problem.",
                    "label": 0
                },
                {
                    "sent": "Then you have feature extraction.",
                    "label": 1
                },
                {
                    "sent": "You calculate features, but these features are rarely semantically in terms of a human level semantic.",
                    "label": 0
                },
                {
                    "sent": "I mean there might be some interpretation, but even if they have an interpretation they will typically not.",
                    "label": 0
                },
                {
                    "sent": "Yes it's there.",
                    "label": 0
                },
                {
                    "sent": "Oh no, it's not there, so it's sort of some continuous value.",
                    "label": 1
                },
                {
                    "sent": "You get out of a feature and then you have a classifier and you classify your system and this of course is has human level semantics because you want to know what you classify.",
                    "label": 0
                },
                {
                    "sent": "So this is typically what's going on a machine learning classifier, and if you.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Want to use this for search?",
                    "label": 0
                },
                {
                    "sent": "Probably.",
                    "label": 0
                },
                {
                    "sent": "Not too useful currently in the sense that you cannot do end keyword search because this is continuous.",
                    "label": 0
                },
                {
                    "sent": "This is probably uncertain, so search engine's my understanding at least is that currently they are not so good at working with this type of information, or at least let's say you will sit in front of your computer.",
                    "label": 0
                },
                {
                    "sent": "You type some keywords and you might not want to have this probabilistic thing that you want to have the documents which really contain this information and not maybe contain this information or.",
                    "label": 0
                },
                {
                    "sent": "I thought it might contain this information, so at least today a search engine seems to love this too much.",
                    "label": 0
                },
                {
                    "sent": "And of course you can do search based on similarity and other things of course.",
                    "label": 1
                },
                {
                    "sent": "Also the ranking function is a very important machine learning problem, but so this is sort of the way I look at the machine learning issue here, if you.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at the semantic web.",
                    "label": 0
                },
                {
                    "sent": "So in one view is, do you assume you have two knowledge about your domain?",
                    "label": 0
                },
                {
                    "sent": "So and this should have human level semantics, so it should be understandable to a human what these things are.",
                    "label": 0
                },
                {
                    "sent": "Then you have ontological background knowledge and then you do reasoning and can derive additional effects.",
                    "label": 0
                },
                {
                    "sent": "For example, the type of an object or class or other things.",
                    "label": 0
                },
                {
                    "sent": "And of course this type of reasoning in some sense can deal with missing data because it's sort of a connected thing.",
                    "label": 1
                },
                {
                    "sent": "So something might conclude something and then the next sort of rule can catch on that.",
                    "label": 0
                },
                {
                    "sent": "Of course, also only limited in a limited way, because if you cannot prove something.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then it's also unknown to you.",
                    "label": 0
                },
                {
                    "sent": "In many cases, particularly many applications concerning with his eyes, the input consists of unstructured data, so you have to do some form of pre processing to do it from unstructured to structured data is the strongest one would be human tagging supported by a machine and in many applications this might be a good option and this might be so there might be so much.",
                    "label": 1
                },
                {
                    "sent": "Special interests or other interests that people are willing to do that.",
                    "label": 0
                },
                {
                    "sent": "And of course, our task machine learning people task is to automate this to do automatic processing from text to RDF.",
                    "label": 0
                },
                {
                    "sent": "Image to RDF.",
                    "label": 0
                },
                {
                    "sent": "So this is a big problem, But if this is solved and this is again semantic level and also sort of deterministic Now, we don't have too much probability here then this is great and then the reason I can work with this and we can do many interesting things over here.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you look here, the perspective from a search engine, I think there's a lot of interesting information here.",
                    "label": 0
                },
                {
                    "sent": "Which search engine would love to have additional keyword additional semantic information which we can search for additional things.",
                    "label": 0
                },
                {
                    "sent": "We concluded type or class of an object, synonyms multilinguality, so this is.",
                    "label": 1
                },
                {
                    "sent": "This is sort of the vision as far as I understand it, there different.",
                    "label": 1
                },
                {
                    "sent": "Definitely many interesting machine learning problems.",
                    "label": 0
                },
                {
                    "sent": "Definitely on the left side, but maybe also here we want.",
                    "label": 0
                },
                {
                    "sent": "Would like to do some problems.",
                    "label": 0
                },
                {
                    "sent": "Start with a reasonable with the machine learning problem.",
                    "label": 0
                },
                {
                    "sent": "So for example if you want to predict if somebody's who's described on its webpage would like to buy your product, there's a lot of probability involved and you probably don't want to work with logical roots here, so we also here on the right side I see a lot of potential for machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So my my personal and my current conclusion on the second part is that RDF is a data model and a uniform data exchange format can be very useful today and people should.",
                    "label": 1
                },
                {
                    "sent": "Use this and.",
                    "label": 0
                },
                {
                    "sent": "And write smart applications are smart agents who can exploit this type of text which are written in this format or another format ontology is also great because they supply a lot of prior knowledge about the domain which the application also should exploit.",
                    "label": 1
                },
                {
                    "sent": "But my main point would be that maybe logic based reasoning and statistical machine learning will both make great contributions in the future.",
                    "label": 0
                },
                {
                    "sent": "But maybe the the semantic Web version should not depend on.",
                    "label": 0
                },
                {
                    "sent": "Either of them, so we should go ahead with the vision today because the community or the public expects us to produce results quickly and not in the far future.",
                    "label": 0
                },
                {
                    "sent": "And then we expect that logic, reasoning and static machine learning.",
                    "label": 0
                },
                {
                    "sent": "We have important contributions which will also contribute to the vision, but it should not rely on that.",
                    "label": 0
                },
                {
                    "sent": "That's what we might point.",
                    "label": 0
                },
                {
                    "sent": "So here's some example of where I see static machine learning.",
                    "label": 1
                },
                {
                    "sent": "Of course, generators of metadata is a big point.",
                    "label": 0
                },
                {
                    "sent": "Also, a big point in case there's all sorts of classification task, recommendation tasks and so on.",
                    "label": 0
                },
                {
                    "sent": "Maybe you also need search engines and agents which can easier deal with continuous data and probabilistic data.",
                    "label": 0
                },
                {
                    "sent": "So we can better exploit things generated by something like a privacy classifier, another point, or the final point is maybe that semantic web version might not be realized on the web first, because a lot of people also industry get inspired by looking at this constructions the ontologies and so on to sort of approach more.",
                    "label": 0
                },
                {
                    "sent": "EA Shun Spired solutions again.",
                    "label": 0
                },
                {
                    "sent": "For example, in the use case we're working on.",
                    "label": 0
                },
                {
                    "sent": "In medical, which is essentially medical search engine for medical images?",
                    "label": 0
                },
                {
                    "sent": "We expect to be able to exploit a lot of ontology ontological knowledge which has been encoded to improve the solutions we're working on all the problems we are working on, so this is so maybe a lot will happen here, not on the web 1st and then the web will follow.",
                    "label": 0
                },
                {
                    "sent": "So don't always just think if people talk about semantic web like it's on the web.",
                    "label": 0
                },
                {
                    "sent": "It could also be very special data, only accessible to one company and not really on the web.",
                    "label": 0
                },
                {
                    "sent": "OK so this then and thank you very much for your patience.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much, thanks.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you can come back to your earlier Clock from the Lake.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So can you tell us something about scalability of these algorithms?",
                    "label": 0
                },
                {
                    "sent": "In particular, suppose I have classes beyond small HMO only have 10 million patients.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have people.",
                    "label": 0
                },
                {
                    "sent": "Yeah, people have worked on this.",
                    "label": 0
                },
                {
                    "sent": "There was a recent conference.",
                    "label": 0
                },
                {
                    "sent": "Somebody presented a very similar approach.",
                    "label": 0
                },
                {
                    "sent": "He had made 200,000 entities.",
                    "label": 0
                },
                {
                    "sent": "And he was doing clustering in that domain.",
                    "label": 0
                },
                {
                    "sent": "I think it was.",
                    "label": 0
                },
                {
                    "sent": "Sort of artists or something like that, so this seems to be a number one can reach, and he I think he said he needed two or three hours for this to work.",
                    "label": 0
                },
                {
                    "sent": "It scales basically with the number of relations, so if it's a sparse domain, if you don't have too many interactions, so if every new identity is connected to all the existing entities, then the scaling is very bad.",
                    "label": 0
                },
                {
                    "sent": "But if the number of relations sort of stays constant, it's sort of also scales.",
                    "label": 0
                },
                {
                    "sent": "Constant with the number of entities, so I wouldn't think a million or 10,000,000.",
                    "label": 0
                },
                {
                    "sent": "Skilled in it and is a number of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's proportional.",
                    "label": 0
                },
                {
                    "sent": "Definitely the number of entities.",
                    "label": 0
                },
                {
                    "sent": "And to the number of relationships this entity typically is involved in.",
                    "label": 0
                },
                {
                    "sent": "And then you need number of iterations to converge, so which is difficult to estimate?",
                    "label": 0
                },
                {
                    "sent": "Having said that, leaving Bibles at Blockbuster open up, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's here's example.",
                    "label": 0
                },
                {
                    "sent": "So innovation network.",
                    "label": 0
                },
                {
                    "sent": "If you have a Collider, it's open OK, and if you have a parent and its parent is unknown, then it also opened.",
                    "label": 0
                },
                {
                    "sent": "Don't tell me I'm wrong.",
                    "label": 0
                },
                {
                    "sent": "It opens up if you have evidence.",
                    "label": 0
                },
                {
                    "sent": "Yes, you've never collide is closed, and then you have the.",
                    "label": 0
                },
                {
                    "sent": "If you have a Collider, it opens up now this so this path opens up if the relationship is known.",
                    "label": 0
                },
                {
                    "sent": "If it's unknown, yeah, know if this is our is known it opens up.",
                    "label": 0
                },
                {
                    "sent": "Our goal.",
                    "label": 0
                },
                {
                    "sent": "Adding the.",
                    "label": 0
                },
                {
                    "sent": "Valuable.",
                    "label": 0
                },
                {
                    "sent": "Oh, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't change this this this this is open here too, and so because it's a Collider and has received evidence.",
                    "label": 0
                },
                {
                    "sent": "But here the attributes block the path, so there's no way this.",
                    "label": 0
                },
                {
                    "sent": "The information about this can propagate to this guy because it's blocked by this attributes.",
                    "label": 0
                },
                {
                    "sent": "But if there's a latent variable, then it's open and information can flow through the latent variable.",
                    "label": 0
                },
                {
                    "sent": "Mission.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Come back to the point of model selection, so your model you is a force of the order.",
                    "label": 0
                },
                {
                    "sent": "Is this even variable?",
                    "label": 0
                },
                {
                    "sent": "Is latent variables.",
                    "label": 0
                },
                {
                    "sent": "In fact that with this run better operational performance but.",
                    "label": 0
                },
                {
                    "sent": "Does it make your model more complex?",
                    "label": 0
                },
                {
                    "sent": "In which way you can have when you run road trip and we will have many local minima.",
                    "label": 0
                },
                {
                    "sent": "Can you explain this as you are?",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can probably have local minima here, I.",
                    "label": 0
                },
                {
                    "sent": "It seems we didn't, we never.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's so much so castec there that you always sort of have the tendency that local minima might be average hour.",
                    "label": 0
                },
                {
                    "sent": "They jump out of them.",
                    "label": 0
                },
                {
                    "sent": "But I don't think there's a we can really guarantee that there no local Optima.",
                    "label": 0
                },
                {
                    "sent": "I think we have local Optima and but the nice thing is that since I mean.",
                    "label": 0
                },
                {
                    "sent": "Since there is a chance that the information from this guy and this attribute sort of propagates to the latent state here.",
                    "label": 0
                },
                {
                    "sent": "So if the system decides it has a better modeling capability, if it doesn't, just look at the OK. Let's say this is a person.",
                    "label": 0
                },
                {
                    "sent": "This is father, his grandfather and father.",
                    "label": 0
                },
                {
                    "sent": "So this guy might get a disease if his father has a disease or if it's grand Father had the disease, but we don't introduct introduce a direct connection here, so we hope and expect that information from the Grand Father can propagate.",
                    "label": 0
                },
                {
                    "sent": "To the grandson through this network of latent variables mean similar as in an image processing application are you are in hidden Markov model, you the the model itself is very local, but information in the time series model.",
                    "label": 0
                },
                {
                    "sent": "For example, hidden Markov model can propagate globally.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the thing we're hoping.",
                    "label": 0
                },
                {
                    "sent": "We can explore.",
                    "label": 0
                },
                {
                    "sent": "Application to buy.",
                    "label": 0
                },
                {
                    "sent": "Fishing boat.",
                    "label": 0
                },
                {
                    "sent": "Prediction function prediction.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interactions.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It seems to me that you want your interaction, yes.",
                    "label": 0
                },
                {
                    "sent": "Now we know some interactions we don't know.",
                    "label": 0
                },
                {
                    "sent": "We didn't do that.",
                    "label": 0
                },
                {
                    "sent": "We only in this case we only.",
                    "label": 0
                },
                {
                    "sent": "So this is this is data which is inspired by a KDD club competition, so it's not the same data about this similar and there are the task was to predict the function.",
                    "label": 0
                },
                {
                    "sent": "So this was one task we were looking at and then we said oh.",
                    "label": 0
                },
                {
                    "sent": "Let's also look at the clusters but we didn't try to predict the links.",
                    "label": 0
                },
                {
                    "sent": "But it's an interesting.",
                    "label": 0
                },
                {
                    "sent": "Idea we should probably try to do that too.",
                    "label": 0
                },
                {
                    "sent": "Also command last slide you're in view of the semantic web OK. Name?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Just once.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This this one.",
                    "label": 0
                },
                {
                    "sent": "Could be a nice domain to produce this kind of ship.",
                    "label": 0
                },
                {
                    "sent": "For your application, bioinformatics Rob Lowe that I'm teaching his relations in direction and if you consider the task of scientific discovery.",
                    "label": 0
                },
                {
                    "sent": "That can be related to your yeah yeah, I mean some of my colleagues have worked on relation extraction from textual data from medical bioinformatics and then in the course of the writing the paper they learned about this representation RDF and decided then to present the extracted relations in terms of this RDF framework, which also gives me a very high motivation that this is a nice description of.",
                    "label": 0
                },
                {
                    "sent": "This relational information, because it's sort of human readable, it's exchangeable, so you don't have to sort of provide it into some strange relational data format, so I think I really agree with you that this whole framework can be quite relevant there, and of course also it's very general if you so if you build your application on top of RDF then you can assume there will be hopefully a lot of RDF in the future, and it's very universally applicable.",
                    "label": 0
                },
                {
                    "sent": "Other people can use it, and if we also have more ways to integrate.",
                    "label": 0
                },
                {
                    "sent": "The logical knowledge, for example, again North right away, applicable to many many applications, and hopefully that's the vision at least.",
                    "label": 0
                },
                {
                    "sent": "This point in in biology, the viruses are more or they want more uncertain T. Information which I expected.",
                    "label": 0
                },
                {
                    "sent": "But yeah, I think there's a lot of a lot of my understanding and I'm definitely not expert.",
                    "label": 0
                },
                {
                    "sent": "Is that in the semantic web community?",
                    "label": 0
                },
                {
                    "sent": "There's also a lot of activity in terms of probabilistic, including probability and uncertainty.",
                    "label": 0
                },
                {
                    "sent": "Not much, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Windows structure OK. OK, so immigration.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}