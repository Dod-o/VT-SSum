{
    "id": "a4kbreoyvab5deztv2wfdxgrme7zmm4q",
    "title": "Classification in Graphs using Discriminative Random Walks",
    "info": {
        "author": [
            "Jerome Callut, University of Louvain"
        ],
        "published": "Aug. 25, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Mathematics->Graph Theory",
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/mlg08_callut_cgdrw/",
    "segmentation": [
        [
            "We have called our approach the D watch so we can.",
            "You can recognize this with our T shirts.",
            "In yeah now I did miss night.",
            "OK, maybe I can start with another version.",
            "I don't like.",
            "It was a PowerPoint presentation, so maybe.",
            "Didn't work OK.",
            "I don't understand what's the problem here.",
            "My trip.",
            "OK.",
            "Cool, so I'm going to present so I talk about some asparagus vacation from discriminative random walk.",
            "So it's a methods based on the random walk.",
            "Next"
        ],
        [
            "OK.",
            "So here is the outline and I will quickly show explain you why dismiss Provisor running classification in classic data and graphs.",
            "Then they will come up with our approach called the Walk.",
            "Which is a methods biz and run the world that's performed classification in grass.",
            "And after that I will just to give you the idea of some.",
            "Performance of initial use and experimental results.",
            "Following the conclusion and then some extension that we would like to.",
            "Do it."
        ],
        [
            "OK, so here is the typical case of our.",
            "Studysoup we have the following settings so we have a certain.",
            "Label said he wished to class the red class in the green glass and another set of unlabeled mode, which we want to predict.",
            "So we would like to.",
            "Obtain the the good classification results under right so."
        ],
        [
            "It's what we would like to do.",
            "But you see that we're going, so we're going to try to use.",
            "Supervised data which are labeled with an unlabeled data.",
            "Because.",
            "Using only supervised if I could be not.",
            "Enough because.",
            "Super visits are expensive to to obtain because each point in your datasets at, for example, to be manually obtained and that can could cost a lot.",
            "For example, if you would like to.",
            "Perform fix categorisation.",
            "Some people have to manually classify the Captain curious of the text, for example, or if you want to find the 3D printing structure of of molecule chemist steps to perform the test, and 2 + 4 to classify the.",
            "Data points.",
            "But on the other hand.",
            "Just having the unlabeled data is just much more easier to think and can give us knowledge.",
            "For our model and what kind of the kind of knowledge they can give us, is just the distribution of the of the data points."
        ],
        [
            "OK, so that was on classical data.",
            "Graph so.",
            "Typical setting is.",
            "We have given some nodes that are being labeled and we want to predict or classify the missing label node.",
            "And in most of the cases, we have much more in label node than label node.",
            "So here is some real world application like linked document categorization, classification of individual insert individuals in social network etc.",
            "And we want to meet The Jets, should be able to.",
            "Handles very large work because we we think that in most of the cases in real world application, the graphs and the data are large.",
            "So, and we also want a method that can help end the wide variety of grass so we don't have to bother with the aggressive whether the graph is connected or not directed, or unless we just apply the approach and wait for the result.",
            "Because it gives classification results.",
            "So obviously that gives us good predictive results and that is very fast."
        ],
        [
            "OK so here is some related approach.",
            "We know our approach.",
            "Use the random walk techniques.",
            "And we are going to compare our approach with some kernel methods, like the regularised, some Laplacian based kernel.",
            "And also.",
            "Benefit framework from Mexico City and Provost, which is a risk for a rational approach in the graph.",
            "And.",
            "When you, you can also notice that current on that.",
            "This can also be interpreted in terms of random walk.",
            "But I think that there is some advantages too.",
            "To handle.",
            "The classification problems in graphs just using the random walks without.",
            "Using the current methods."
        ],
        [
            "So on the graph.",
            "We have the agency matrix possibly waited.",
            "And by normalizing that matrix, we can obtain the probability transition matrix that and that.",
            "Are going to.",
            "Hello this to see the grand ASMR.",
            "Marcus James.",
            "So each node under graph will be.",
            "It can be seen as a state of the Markov chain.",
            "So for input the random variable XT and the market chain represents the state of the market chain at the state of the market chain.",
            "I thanked them striptease.",
            "OK."
        ],
        [
            "So.",
            "But how can we use our techniques which is?",
            "First, mini bear used on graph unclassical data.",
            "We can just for example use a neighboring.",
            "Delivering around the nude to construct the links between node in the feature space based on the similarities.",
            "For example, then construct a graph.",
            "So that we can apply or approves later.",
            "There was an animation on my PowerPoint here so."
        ],
        [
            "Just a PDF here.",
            "OK. Let's consider that road map here and I will give you the idea of how the D word approach is working.",
            "OK, so you can see that there is two class, the red class in the green class and some unable node that we want to predict.",
            "For the example here, we just want to predict the nude marked with?"
        ],
        [
            "We're going to define a certain type of random walk.",
            "We cool that the walk and Adi walk is a random walk that starts and ends in nodes of the same class.",
            "Any debt?",
            "Pass babe nude of interest.",
            "So the question Mark knows here."
        ],
        [
            "So you can see here the random walk here respected the definition of the walk."
        ],
        [
            "We didn't have other cases, like for example if you will can start for from a nude of a certain class and end in the same node so we can have go go and come back on the same node."
        ],
        [
            "Adele can Kristen label news.",
            "So for who we we start again from that."
        ],
        [
            "Read new then.",
            "Go to the question Mark Noden.",
            "Oh, completely terminating the the work on the same node.",
            "So as soon as the random water meets a node of the same class."
        ],
        [
            "We can also cross notes from other classes."
        ],
        [
            "N as you walk and also pasarela timing the same node, each node is not of the red class."
        ],
        [
            "So that's the general idea here.",
            "Is that a deal?",
            "Work is a random walk that starts on the note of research of a certain class and ends on another note.",
            "As soon as another noodles with some classes reached for the first time.",
            "So we can discuss it.",
            "We can define a lot of the work for each unlabeled nodes for each class.",
            "So do you?",
            "Work will define sort of.",
            "Centric measure for each class.",
            "And of course, we can compute the work for the other classes to compute the.",
            "The centric measure the betweenness measure for the question mark node among Europe."
        ],
        [
            "So the green class.",
            "So here there is 2 definition.",
            "So as you walk everyday, I already explained it, just a random walk that starts in the label nodes and ending when any new that the same class is rich for the first time.",
            "Then we define a measure that the war between this for each class, which is the expected passage time on the unlabeled node for each class for the class in question so.",
            "Between this for you know, 2% of the Class Y.",
            "So in the example there was only."
        ],
        [
            "2 two class.",
            "Great question because.",
            "OK, how do we compute that?",
            "We're going to compute the betweeness of another queue for certain class Y.",
            "By computing the expected message time on a node Q towards the towards the question mark, knowing a certain day walk on a certain class.",
            "OK, and how do we compute the passage time of the nodes?",
            "We're going to compute it by using the standard absorption marketing technique in the market."
        ],
        [
            "Change theory.",
            "So.",
            "I can explain it quickly to to you here too because we have the kind of graph with two class and quick question, a nude cute to classify.",
            "Or just to count the number of presents islandwood?",
            "The standard absorption technique.",
            "Will replicate the notes.",
            "Of the class of interest, the red class in some starting node markets.",
            "Q Prime and some absorbing nodes.",
            "We are running a blue circle, so if you computer one random walk on the second graph, she's the new graph.",
            "We replicated node.",
            "You can see that.",
            "The random Walker will start from a note Q prime, which is the class of interest then.",
            "Walk in cycle inside the.",
            "Then leaving within the notes from the other class and end up as soon as is it reach a node of the class, right?",
            "And that can be materialized, but you can see that with the block partitioning metrics over there.",
            "So we had a transition probability matrix P. In that matrix can be transformed in that block partition matrix with PT being the transition probability from nodes from unlabeled maiden North of the yoga class are the transition between nodes and absorbing nodes.",
            "And then the rest.",
            "So using that matrix and.",
            "More Berkeley using the Matrix PT we can compute.",
            "And walk around and watch.",
            "Up to the Infinity.",
            "By computing.",
            "This this is formula so.",
            "Is that the sum of the transition probability to the power of the number of steps of step?",
            "And because PT is itself stochastic.",
            "But for me it can be reduced as this one with the.",
            "Matrix inversion.",
            "And in most of the cases, the current methods used, that matrix inversion compute dear your kernel and.",
            "Everyone know that a metric conversion is very slow to compute, and that's a problem if you want to use or to work in very large graph.",
            "When I say large eyes, I can say million of."
        ],
        [
            "Millions of nodes.",
            "Sue the beauty of the approach here will be too.",
            "22 bones, the random water up to afriski a certain length.",
            "And we can and you will see that it has major benefits like better classification results.",
            "The Betweeness measure let's I talk about can be computed very efficiently, much more efficiently.",
            "And if you want to retrieve the unbounded measure, you can consider large L. So large bounded walk."
        ],
        [
            "And how this between this measure can be computed?",
            "We are going to use the.",
            "Forward and backward nutrients like this, like those using the boom wells are we algorithm for hmm?",
            "And here they are.",
            "To be very fast when we compute AD walk.",
            "We are going to compute the work in the two direction at the same time, so a forwards for able in the backward variable.",
            "So we're going to use the latest to compute that.",
            "And.",
            "For the forward, very recurrences can be explained as the probability to reach a new queue in the graph after these steps.",
            "Without passing through nodes in the class, why?",
            "Because you cannot pass.",
            "You cannot continue.",
            "You reach the class, why?",
            "Um?",
            "And the backwards reference.",
            "Compute the probability that in the queue is reached by process these steps before having reached any nude label with the same class, why?"
        ],
        [
            "And if we merge that two reference variable, we can compute.",
            "The the probability to be on the queue knowing a certain.",
            "At the time T knowing certainty, walk on the glass.",
            "Why?",
            "And that's how we compute the expected passage.",
            "Time for certainly works for you on the class YN for certain length L."
        ],
        [
            "And to compute that, do work for all the links from the linked one.",
            "Tooling Big L, We just send with a certain number normalization constant, the message that they expected passage time on the new queue for each view, walk of a certain length.",
            "That give us the hour between this measure on a queue for a certain class, why?"
        ],
        [
            "And having that between this measure for.",
            "All the classes are hour.",
            "Graph.",
            "We are going to to classify the node using a maximum a priori decision rule for each between S of each class."
        ],
        [
            "OK.",
            "So here is some datasets that I want to show you the number of nodes.",
            "So seems to be.",
            "Quotes low because I was talking about large graph and the bigger graph here is only a 3000 nodes graph, but I want to be able to compare the deer walk approach with other state of the art approach so.",
            "With the kernel inversion, again not consider much more large threatened already.",
            "This is and those this glass are.",
            "We found in which found them on the paper of Mexico City in Provo."
        ],
        [
            "OK, so here is the four data set I presented and.",
            "We can see for each data set, which we consider a certain percentage of labeling sets compared to the labeling set of nodes.",
            "So here for example and open two, it's only 20% of living set.",
            "And 80% of them little.",
            "Note that we want to predict.",
            "And this is the classification rates.",
            "So how are methods the black line?",
            "The Red line is the regularization method.",
            "The.",
            "The Green one is the method of zoo and shortcut, which is a normalized Laplacian method.",
            "And the blue line is the.",
            "NET Framework from Maxine Provost.",
            "And you can see that in most of the case we kind of outperformed the performances of those methods on those graphs.",
            "2.",
            "Objective put up with her for."
        ],
        [
            "Is it achieved?",
            "OK, what about the learning here?",
            "So I. Um?",
            "We can consider the walk up to a certain length alright, but how is the best length and how can we compute the best length on a certain graph on with a certain laboring rate?",
            "Because we just have to.",
            "Find the optimum so there L the number of steps.",
            "The so the earliest member of a walk up to that L that give the best results.",
            "And because it's very cheap to compute, we just compute it.",
            "On the right, on the wide range it's there 250 or 200 of steps, and we compute it with the crystallization.",
            "Each time the the performances that we get.",
            "And then choose the best L that Evas, Undergrass and with.",
            "That is, the setting in question the best performances.",
            "In for example here and the current data set.",
            "We believe billing rate of 90%, so there is only 10% of the building and labeling nodes.",
            "The best.",
            "What length fix this maximum warp link so the watch with laying up to six are the best.",
            "And give the best results so we can see that.",
            "On the data sets the walk the number of states that gives the best results are quite low and we don't have to watch very far to get information you we can stay very local, so very.",
            "And also compute.",
            "Obviously that's different, is very fast.",
            "And I don't have the graph here, but on the current data set, we've 10% of labeling nodes and night person as only being node.",
            "The optimal work length was about 30.",
            "So when there is less information in the graph, the D walk have to go far to get some information."
        ],
        [
            "15 in general is quite low.",
            "And So what about the CPU time?",
            "So here is a graph that is generated graph.",
            "We've the number of edges 10 times the number of nodes.",
            "So here is a million nodes in 10,000,000 edges.",
            "And then you have the CPU time there so you can see that.",
            "4.",
            "Very low.",
            "Maximum walkling the complexity is very very low because.",
            "It depends on the number.",
            "It's linear in, the number of edges times the number of maximum warping that we consider the so even on a huge graph.",
            "If we lower the maximum work, then we can still handle it.",
            "And I know the things that you can see is that.",
            "Under 1 million nodes graph, if you can see the walk length of 250.",
            "And then up to 100 you can see that the complexity is just twice the time, so it's kind of a proof of the linear time.",
            "And obviously we can handle.",
            "Any grab that can fit in the memory, kind of."
        ],
        [
            "So the conclusion is that that you will define a betweenness measure, a kind of a centrality measure for each class.",
            "Ends in liberal news are classified in the class that is that give the best between this.",
            "For that new.",
            "And we also see that bounding the walk length.",
            "Give better performance on classification and that's a little the the algorithm to be very fast.",
            "And that also gives us the possibility to deal with the really large graph."
        ],
        [
            "We've also some possible extension, like the possibility to incorporate feature in inside some every nodes.",
            "We like also to the River Kernel from Adi watch so that it can be used in the kernel.",
            "Methods like SVM for example.",
            "Or any we also would like to try to use the D walk approach on recommendation system.",
            "On on this time Bisom bounded random walk.",
            "Like they just show you.",
            "OK, so thank you for your patience and excuse me for some of the problems.",
            "I guess at the beginning of my talk and I'm here to answer your question.",
            "Hey.",
            "Microphone.",
            "Is actually.",
            "Can you repeat your question about me?",
            "In this case.",
            "Yeah, so Nick, it is a modular framework so you can instantiate some.",
            "An older model with some methods, and we use the instantiation that gives the best results based on the paper of Maxine Provost, which is.",
            "A relational weighted votes classification are underground.",
            "Wouldn't it make more sense to down weight larger random walks?",
            "So do you consider I mean?",
            "Right now, you're just considering all possible length walks, so if there is a walk which is of a very large length, you still give it the same weight as another work which is very close.",
            "So you mean that we give the same weights for each steps on our.",
            "No, I mean when you have this information right, you're considering you so a walk which starts from a node and goes to another node in five steps is given the same weight as another walk which say it takes 10 steps to go to another node.",
            "So have you considered weighting schemes?",
            "I think the answer is yes, we consider we give the same weights for each walk.",
            "No, but I'm talking of down waiting a walk based on its length, yeah?",
            "Permit yeah yeah yeah.",
            "That guy that can give Brazil because most of the tournament excuse that's damping parameter too.",
            "To lower the the Infinity random walk, but you still have to compute the matrix inversion.",
            "So.",
            "But you can still do that with the steps to do that with your finite steps too.",
            "Um?",
            "With our method, we can you.",
            "We can use a damping parameter.",
            "Yes we can do that, but we don't test it and we don't think that.",
            "It may give better results.",
            "So yeah, we should try it, thanks.",
            "OK.",
            "I'm I would like to know if you compare your results of your random walk and classifier to the results of some more naive classifiers like nearest neighbor classifier classifier, also an extension that we have to do is to compare our method with very simple algorithm classification algorithm in graph.",
            "So like a KNN or neighboring.",
            "So yes, we still have to do that.",
            "So I think it's time."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have called our approach the D watch so we can.",
                    "label": 0
                },
                {
                    "sent": "You can recognize this with our T shirts.",
                    "label": 0
                },
                {
                    "sent": "In yeah now I did miss night.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe I can start with another version.",
                    "label": 0
                },
                {
                    "sent": "I don't like.",
                    "label": 0
                },
                {
                    "sent": "It was a PowerPoint presentation, so maybe.",
                    "label": 0
                },
                {
                    "sent": "Didn't work OK.",
                    "label": 0
                },
                {
                    "sent": "I don't understand what's the problem here.",
                    "label": 0
                },
                {
                    "sent": "My trip.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Cool, so I'm going to present so I talk about some asparagus vacation from discriminative random walk.",
                    "label": 0
                },
                {
                    "sent": "So it's a methods based on the random walk.",
                    "label": 0
                },
                {
                    "sent": "Next",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here is the outline and I will quickly show explain you why dismiss Provisor running classification in classic data and graphs.",
                    "label": 0
                },
                {
                    "sent": "Then they will come up with our approach called the Walk.",
                    "label": 0
                },
                {
                    "sent": "Which is a methods biz and run the world that's performed classification in grass.",
                    "label": 0
                },
                {
                    "sent": "And after that I will just to give you the idea of some.",
                    "label": 0
                },
                {
                    "sent": "Performance of initial use and experimental results.",
                    "label": 0
                },
                {
                    "sent": "Following the conclusion and then some extension that we would like to.",
                    "label": 0
                },
                {
                    "sent": "Do it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here is the typical case of our.",
                    "label": 0
                },
                {
                    "sent": "Studysoup we have the following settings so we have a certain.",
                    "label": 0
                },
                {
                    "sent": "Label said he wished to class the red class in the green glass and another set of unlabeled mode, which we want to predict.",
                    "label": 0
                },
                {
                    "sent": "So we would like to.",
                    "label": 0
                },
                {
                    "sent": "Obtain the the good classification results under right so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's what we would like to do.",
                    "label": 0
                },
                {
                    "sent": "But you see that we're going, so we're going to try to use.",
                    "label": 0
                },
                {
                    "sent": "Supervised data which are labeled with an unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                },
                {
                    "sent": "Using only supervised if I could be not.",
                    "label": 0
                },
                {
                    "sent": "Enough because.",
                    "label": 0
                },
                {
                    "sent": "Super visits are expensive to to obtain because each point in your datasets at, for example, to be manually obtained and that can could cost a lot.",
                    "label": 0
                },
                {
                    "sent": "For example, if you would like to.",
                    "label": 0
                },
                {
                    "sent": "Perform fix categorisation.",
                    "label": 0
                },
                {
                    "sent": "Some people have to manually classify the Captain curious of the text, for example, or if you want to find the 3D printing structure of of molecule chemist steps to perform the test, and 2 + 4 to classify the.",
                    "label": 0
                },
                {
                    "sent": "Data points.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand.",
                    "label": 0
                },
                {
                    "sent": "Just having the unlabeled data is just much more easier to think and can give us knowledge.",
                    "label": 0
                },
                {
                    "sent": "For our model and what kind of the kind of knowledge they can give us, is just the distribution of the of the data points.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that was on classical data.",
                    "label": 0
                },
                {
                    "sent": "Graph so.",
                    "label": 0
                },
                {
                    "sent": "Typical setting is.",
                    "label": 0
                },
                {
                    "sent": "We have given some nodes that are being labeled and we want to predict or classify the missing label node.",
                    "label": 0
                },
                {
                    "sent": "And in most of the cases, we have much more in label node than label node.",
                    "label": 0
                },
                {
                    "sent": "So here is some real world application like linked document categorization, classification of individual insert individuals in social network etc.",
                    "label": 0
                },
                {
                    "sent": "And we want to meet The Jets, should be able to.",
                    "label": 0
                },
                {
                    "sent": "Handles very large work because we we think that in most of the cases in real world application, the graphs and the data are large.",
                    "label": 0
                },
                {
                    "sent": "So, and we also want a method that can help end the wide variety of grass so we don't have to bother with the aggressive whether the graph is connected or not directed, or unless we just apply the approach and wait for the result.",
                    "label": 0
                },
                {
                    "sent": "Because it gives classification results.",
                    "label": 0
                },
                {
                    "sent": "So obviously that gives us good predictive results and that is very fast.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here is some related approach.",
                    "label": 0
                },
                {
                    "sent": "We know our approach.",
                    "label": 0
                },
                {
                    "sent": "Use the random walk techniques.",
                    "label": 0
                },
                {
                    "sent": "And we are going to compare our approach with some kernel methods, like the regularised, some Laplacian based kernel.",
                    "label": 1
                },
                {
                    "sent": "And also.",
                    "label": 0
                },
                {
                    "sent": "Benefit framework from Mexico City and Provost, which is a risk for a rational approach in the graph.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "When you, you can also notice that current on that.",
                    "label": 0
                },
                {
                    "sent": "This can also be interpreted in terms of random walk.",
                    "label": 0
                },
                {
                    "sent": "But I think that there is some advantages too.",
                    "label": 0
                },
                {
                    "sent": "To handle.",
                    "label": 0
                },
                {
                    "sent": "The classification problems in graphs just using the random walks without.",
                    "label": 1
                },
                {
                    "sent": "Using the current methods.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So on the graph.",
                    "label": 0
                },
                {
                    "sent": "We have the agency matrix possibly waited.",
                    "label": 0
                },
                {
                    "sent": "And by normalizing that matrix, we can obtain the probability transition matrix that and that.",
                    "label": 0
                },
                {
                    "sent": "Are going to.",
                    "label": 0
                },
                {
                    "sent": "Hello this to see the grand ASMR.",
                    "label": 0
                },
                {
                    "sent": "Marcus James.",
                    "label": 0
                },
                {
                    "sent": "So each node under graph will be.",
                    "label": 0
                },
                {
                    "sent": "It can be seen as a state of the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So for input the random variable XT and the market chain represents the state of the market chain at the state of the market chain.",
                    "label": 0
                },
                {
                    "sent": "I thanked them striptease.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But how can we use our techniques which is?",
                    "label": 0
                },
                {
                    "sent": "First, mini bear used on graph unclassical data.",
                    "label": 0
                },
                {
                    "sent": "We can just for example use a neighboring.",
                    "label": 0
                },
                {
                    "sent": "Delivering around the nude to construct the links between node in the feature space based on the similarities.",
                    "label": 0
                },
                {
                    "sent": "For example, then construct a graph.",
                    "label": 0
                },
                {
                    "sent": "So that we can apply or approves later.",
                    "label": 0
                },
                {
                    "sent": "There was an animation on my PowerPoint here so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a PDF here.",
                    "label": 0
                },
                {
                    "sent": "OK. Let's consider that road map here and I will give you the idea of how the D word approach is working.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can see that there is two class, the red class in the green class and some unable node that we want to predict.",
                    "label": 0
                },
                {
                    "sent": "For the example here, we just want to predict the nude marked with?",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going to define a certain type of random walk.",
                    "label": 0
                },
                {
                    "sent": "We cool that the walk and Adi walk is a random walk that starts and ends in nodes of the same class.",
                    "label": 0
                },
                {
                    "sent": "Any debt?",
                    "label": 0
                },
                {
                    "sent": "Pass babe nude of interest.",
                    "label": 0
                },
                {
                    "sent": "So the question Mark knows here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can see here the random walk here respected the definition of the walk.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We didn't have other cases, like for example if you will can start for from a nude of a certain class and end in the same node so we can have go go and come back on the same node.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adele can Kristen label news.",
                    "label": 0
                },
                {
                    "sent": "So for who we we start again from that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Read new then.",
                    "label": 0
                },
                {
                    "sent": "Go to the question Mark Noden.",
                    "label": 0
                },
                {
                    "sent": "Oh, completely terminating the the work on the same node.",
                    "label": 0
                },
                {
                    "sent": "So as soon as the random water meets a node of the same class.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also cross notes from other classes.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "N as you walk and also pasarela timing the same node, each node is not of the red class.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the general idea here.",
                    "label": 0
                },
                {
                    "sent": "Is that a deal?",
                    "label": 0
                },
                {
                    "sent": "Work is a random walk that starts on the note of research of a certain class and ends on another note.",
                    "label": 0
                },
                {
                    "sent": "As soon as another noodles with some classes reached for the first time.",
                    "label": 0
                },
                {
                    "sent": "So we can discuss it.",
                    "label": 0
                },
                {
                    "sent": "We can define a lot of the work for each unlabeled nodes for each class.",
                    "label": 0
                },
                {
                    "sent": "So do you?",
                    "label": 0
                },
                {
                    "sent": "Work will define sort of.",
                    "label": 0
                },
                {
                    "sent": "Centric measure for each class.",
                    "label": 0
                },
                {
                    "sent": "And of course, we can compute the work for the other classes to compute the.",
                    "label": 0
                },
                {
                    "sent": "The centric measure the betweenness measure for the question mark node among Europe.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the green class.",
                    "label": 0
                },
                {
                    "sent": "So here there is 2 definition.",
                    "label": 0
                },
                {
                    "sent": "So as you walk everyday, I already explained it, just a random walk that starts in the label nodes and ending when any new that the same class is rich for the first time.",
                    "label": 0
                },
                {
                    "sent": "Then we define a measure that the war between this for each class, which is the expected passage time on the unlabeled node for each class for the class in question so.",
                    "label": 0
                },
                {
                    "sent": "Between this for you know, 2% of the Class Y.",
                    "label": 0
                },
                {
                    "sent": "So in the example there was only.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2 two class.",
                    "label": 0
                },
                {
                    "sent": "Great question because.",
                    "label": 0
                },
                {
                    "sent": "OK, how do we compute that?",
                    "label": 0
                },
                {
                    "sent": "We're going to compute the betweeness of another queue for certain class Y.",
                    "label": 0
                },
                {
                    "sent": "By computing the expected message time on a node Q towards the towards the question mark, knowing a certain day walk on a certain class.",
                    "label": 0
                },
                {
                    "sent": "OK, and how do we compute the passage time of the nodes?",
                    "label": 0
                },
                {
                    "sent": "We're going to compute it by using the standard absorption marketing technique in the market.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change theory.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I can explain it quickly to to you here too because we have the kind of graph with two class and quick question, a nude cute to classify.",
                    "label": 0
                },
                {
                    "sent": "Or just to count the number of presents islandwood?",
                    "label": 0
                },
                {
                    "sent": "The standard absorption technique.",
                    "label": 0
                },
                {
                    "sent": "Will replicate the notes.",
                    "label": 0
                },
                {
                    "sent": "Of the class of interest, the red class in some starting node markets.",
                    "label": 0
                },
                {
                    "sent": "Q Prime and some absorbing nodes.",
                    "label": 0
                },
                {
                    "sent": "We are running a blue circle, so if you computer one random walk on the second graph, she's the new graph.",
                    "label": 0
                },
                {
                    "sent": "We replicated node.",
                    "label": 0
                },
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "The random Walker will start from a note Q prime, which is the class of interest then.",
                    "label": 0
                },
                {
                    "sent": "Walk in cycle inside the.",
                    "label": 0
                },
                {
                    "sent": "Then leaving within the notes from the other class and end up as soon as is it reach a node of the class, right?",
                    "label": 0
                },
                {
                    "sent": "And that can be materialized, but you can see that with the block partitioning metrics over there.",
                    "label": 0
                },
                {
                    "sent": "So we had a transition probability matrix P. In that matrix can be transformed in that block partition matrix with PT being the transition probability from nodes from unlabeled maiden North of the yoga class are the transition between nodes and absorbing nodes.",
                    "label": 0
                },
                {
                    "sent": "And then the rest.",
                    "label": 0
                },
                {
                    "sent": "So using that matrix and.",
                    "label": 0
                },
                {
                    "sent": "More Berkeley using the Matrix PT we can compute.",
                    "label": 0
                },
                {
                    "sent": "And walk around and watch.",
                    "label": 0
                },
                {
                    "sent": "Up to the Infinity.",
                    "label": 0
                },
                {
                    "sent": "By computing.",
                    "label": 0
                },
                {
                    "sent": "This this is formula so.",
                    "label": 0
                },
                {
                    "sent": "Is that the sum of the transition probability to the power of the number of steps of step?",
                    "label": 0
                },
                {
                    "sent": "And because PT is itself stochastic.",
                    "label": 0
                },
                {
                    "sent": "But for me it can be reduced as this one with the.",
                    "label": 0
                },
                {
                    "sent": "Matrix inversion.",
                    "label": 0
                },
                {
                    "sent": "And in most of the cases, the current methods used, that matrix inversion compute dear your kernel and.",
                    "label": 0
                },
                {
                    "sent": "Everyone know that a metric conversion is very slow to compute, and that's a problem if you want to use or to work in very large graph.",
                    "label": 0
                },
                {
                    "sent": "When I say large eyes, I can say million of.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Millions of nodes.",
                    "label": 0
                },
                {
                    "sent": "Sue the beauty of the approach here will be too.",
                    "label": 0
                },
                {
                    "sent": "22 bones, the random water up to afriski a certain length.",
                    "label": 0
                },
                {
                    "sent": "And we can and you will see that it has major benefits like better classification results.",
                    "label": 0
                },
                {
                    "sent": "The Betweeness measure let's I talk about can be computed very efficiently, much more efficiently.",
                    "label": 0
                },
                {
                    "sent": "And if you want to retrieve the unbounded measure, you can consider large L. So large bounded walk.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how this between this measure can be computed?",
                    "label": 0
                },
                {
                    "sent": "We are going to use the.",
                    "label": 0
                },
                {
                    "sent": "Forward and backward nutrients like this, like those using the boom wells are we algorithm for hmm?",
                    "label": 0
                },
                {
                    "sent": "And here they are.",
                    "label": 0
                },
                {
                    "sent": "To be very fast when we compute AD walk.",
                    "label": 0
                },
                {
                    "sent": "We are going to compute the work in the two direction at the same time, so a forwards for able in the backward variable.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use the latest to compute that.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For the forward, very recurrences can be explained as the probability to reach a new queue in the graph after these steps.",
                    "label": 0
                },
                {
                    "sent": "Without passing through nodes in the class, why?",
                    "label": 0
                },
                {
                    "sent": "Because you cannot pass.",
                    "label": 0
                },
                {
                    "sent": "You cannot continue.",
                    "label": 0
                },
                {
                    "sent": "You reach the class, why?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And the backwards reference.",
                    "label": 0
                },
                {
                    "sent": "Compute the probability that in the queue is reached by process these steps before having reached any nude label with the same class, why?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we merge that two reference variable, we can compute.",
                    "label": 0
                },
                {
                    "sent": "The the probability to be on the queue knowing a certain.",
                    "label": 1
                },
                {
                    "sent": "At the time T knowing certainty, walk on the glass.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 1
                },
                {
                    "sent": "And that's how we compute the expected passage.",
                    "label": 0
                },
                {
                    "sent": "Time for certainly works for you on the class YN for certain length L.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to compute that, do work for all the links from the linked one.",
                    "label": 0
                },
                {
                    "sent": "Tooling Big L, We just send with a certain number normalization constant, the message that they expected passage time on the new queue for each view, walk of a certain length.",
                    "label": 0
                },
                {
                    "sent": "That give us the hour between this measure on a queue for a certain class, why?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And having that between this measure for.",
                    "label": 0
                },
                {
                    "sent": "All the classes are hour.",
                    "label": 0
                },
                {
                    "sent": "Graph.",
                    "label": 0
                },
                {
                    "sent": "We are going to to classify the node using a maximum a priori decision rule for each between S of each class.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here is some datasets that I want to show you the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "So seems to be.",
                    "label": 0
                },
                {
                    "sent": "Quotes low because I was talking about large graph and the bigger graph here is only a 3000 nodes graph, but I want to be able to compare the deer walk approach with other state of the art approach so.",
                    "label": 0
                },
                {
                    "sent": "With the kernel inversion, again not consider much more large threatened already.",
                    "label": 0
                },
                {
                    "sent": "This is and those this glass are.",
                    "label": 0
                },
                {
                    "sent": "We found in which found them on the paper of Mexico City in Provo.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here is the four data set I presented and.",
                    "label": 0
                },
                {
                    "sent": "We can see for each data set, which we consider a certain percentage of labeling sets compared to the labeling set of nodes.",
                    "label": 0
                },
                {
                    "sent": "So here for example and open two, it's only 20% of living set.",
                    "label": 0
                },
                {
                    "sent": "And 80% of them little.",
                    "label": 0
                },
                {
                    "sent": "Note that we want to predict.",
                    "label": 0
                },
                {
                    "sent": "And this is the classification rates.",
                    "label": 0
                },
                {
                    "sent": "So how are methods the black line?",
                    "label": 0
                },
                {
                    "sent": "The Red line is the regularization method.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The Green one is the method of zoo and shortcut, which is a normalized Laplacian method.",
                    "label": 0
                },
                {
                    "sent": "And the blue line is the.",
                    "label": 0
                },
                {
                    "sent": "NET Framework from Maxine Provost.",
                    "label": 0
                },
                {
                    "sent": "And you can see that in most of the case we kind of outperformed the performances of those methods on those graphs.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Objective put up with her for.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is it achieved?",
                    "label": 0
                },
                {
                    "sent": "OK, what about the learning here?",
                    "label": 0
                },
                {
                    "sent": "So I. Um?",
                    "label": 0
                },
                {
                    "sent": "We can consider the walk up to a certain length alright, but how is the best length and how can we compute the best length on a certain graph on with a certain laboring rate?",
                    "label": 0
                },
                {
                    "sent": "Because we just have to.",
                    "label": 0
                },
                {
                    "sent": "Find the optimum so there L the number of steps.",
                    "label": 0
                },
                {
                    "sent": "The so the earliest member of a walk up to that L that give the best results.",
                    "label": 0
                },
                {
                    "sent": "And because it's very cheap to compute, we just compute it.",
                    "label": 0
                },
                {
                    "sent": "On the right, on the wide range it's there 250 or 200 of steps, and we compute it with the crystallization.",
                    "label": 0
                },
                {
                    "sent": "Each time the the performances that we get.",
                    "label": 0
                },
                {
                    "sent": "And then choose the best L that Evas, Undergrass and with.",
                    "label": 0
                },
                {
                    "sent": "That is, the setting in question the best performances.",
                    "label": 0
                },
                {
                    "sent": "In for example here and the current data set.",
                    "label": 0
                },
                {
                    "sent": "We believe billing rate of 90%, so there is only 10% of the building and labeling nodes.",
                    "label": 0
                },
                {
                    "sent": "The best.",
                    "label": 0
                },
                {
                    "sent": "What length fix this maximum warp link so the watch with laying up to six are the best.",
                    "label": 0
                },
                {
                    "sent": "And give the best results so we can see that.",
                    "label": 0
                },
                {
                    "sent": "On the data sets the walk the number of states that gives the best results are quite low and we don't have to watch very far to get information you we can stay very local, so very.",
                    "label": 0
                },
                {
                    "sent": "And also compute.",
                    "label": 0
                },
                {
                    "sent": "Obviously that's different, is very fast.",
                    "label": 0
                },
                {
                    "sent": "And I don't have the graph here, but on the current data set, we've 10% of labeling nodes and night person as only being node.",
                    "label": 0
                },
                {
                    "sent": "The optimal work length was about 30.",
                    "label": 0
                },
                {
                    "sent": "So when there is less information in the graph, the D walk have to go far to get some information.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "15 in general is quite low.",
                    "label": 0
                },
                {
                    "sent": "And So what about the CPU time?",
                    "label": 0
                },
                {
                    "sent": "So here is a graph that is generated graph.",
                    "label": 0
                },
                {
                    "sent": "We've the number of edges 10 times the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "So here is a million nodes in 10,000,000 edges.",
                    "label": 0
                },
                {
                    "sent": "And then you have the CPU time there so you can see that.",
                    "label": 0
                },
                {
                    "sent": "4.",
                    "label": 0
                },
                {
                    "sent": "Very low.",
                    "label": 0
                },
                {
                    "sent": "Maximum walkling the complexity is very very low because.",
                    "label": 0
                },
                {
                    "sent": "It depends on the number.",
                    "label": 0
                },
                {
                    "sent": "It's linear in, the number of edges times the number of maximum warping that we consider the so even on a huge graph.",
                    "label": 0
                },
                {
                    "sent": "If we lower the maximum work, then we can still handle it.",
                    "label": 0
                },
                {
                    "sent": "And I know the things that you can see is that.",
                    "label": 0
                },
                {
                    "sent": "Under 1 million nodes graph, if you can see the walk length of 250.",
                    "label": 0
                },
                {
                    "sent": "And then up to 100 you can see that the complexity is just twice the time, so it's kind of a proof of the linear time.",
                    "label": 0
                },
                {
                    "sent": "And obviously we can handle.",
                    "label": 0
                },
                {
                    "sent": "Any grab that can fit in the memory, kind of.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the conclusion is that that you will define a betweenness measure, a kind of a centrality measure for each class.",
                    "label": 0
                },
                {
                    "sent": "Ends in liberal news are classified in the class that is that give the best between this.",
                    "label": 0
                },
                {
                    "sent": "For that new.",
                    "label": 0
                },
                {
                    "sent": "And we also see that bounding the walk length.",
                    "label": 0
                },
                {
                    "sent": "Give better performance on classification and that's a little the the algorithm to be very fast.",
                    "label": 0
                },
                {
                    "sent": "And that also gives us the possibility to deal with the really large graph.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've also some possible extension, like the possibility to incorporate feature in inside some every nodes.",
                    "label": 0
                },
                {
                    "sent": "We like also to the River Kernel from Adi watch so that it can be used in the kernel.",
                    "label": 0
                },
                {
                    "sent": "Methods like SVM for example.",
                    "label": 0
                },
                {
                    "sent": "Or any we also would like to try to use the D walk approach on recommendation system.",
                    "label": 0
                },
                {
                    "sent": "On on this time Bisom bounded random walk.",
                    "label": 0
                },
                {
                    "sent": "Like they just show you.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you for your patience and excuse me for some of the problems.",
                    "label": 0
                },
                {
                    "sent": "I guess at the beginning of my talk and I'm here to answer your question.",
                    "label": 0
                },
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "Microphone.",
                    "label": 0
                },
                {
                    "sent": "Is actually.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat your question about me?",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so Nick, it is a modular framework so you can instantiate some.",
                    "label": 0
                },
                {
                    "sent": "An older model with some methods, and we use the instantiation that gives the best results based on the paper of Maxine Provost, which is.",
                    "label": 0
                },
                {
                    "sent": "A relational weighted votes classification are underground.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't it make more sense to down weight larger random walks?",
                    "label": 0
                },
                {
                    "sent": "So do you consider I mean?",
                    "label": 0
                },
                {
                    "sent": "Right now, you're just considering all possible length walks, so if there is a walk which is of a very large length, you still give it the same weight as another work which is very close.",
                    "label": 0
                },
                {
                    "sent": "So you mean that we give the same weights for each steps on our.",
                    "label": 0
                },
                {
                    "sent": "No, I mean when you have this information right, you're considering you so a walk which starts from a node and goes to another node in five steps is given the same weight as another walk which say it takes 10 steps to go to another node.",
                    "label": 0
                },
                {
                    "sent": "So have you considered weighting schemes?",
                    "label": 0
                },
                {
                    "sent": "I think the answer is yes, we consider we give the same weights for each walk.",
                    "label": 0
                },
                {
                    "sent": "No, but I'm talking of down waiting a walk based on its length, yeah?",
                    "label": 0
                },
                {
                    "sent": "Permit yeah yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "That guy that can give Brazil because most of the tournament excuse that's damping parameter too.",
                    "label": 0
                },
                {
                    "sent": "To lower the the Infinity random walk, but you still have to compute the matrix inversion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But you can still do that with the steps to do that with your finite steps too.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "With our method, we can you.",
                    "label": 0
                },
                {
                    "sent": "We can use a damping parameter.",
                    "label": 0
                },
                {
                    "sent": "Yes we can do that, but we don't test it and we don't think that.",
                    "label": 0
                },
                {
                    "sent": "It may give better results.",
                    "label": 0
                },
                {
                    "sent": "So yeah, we should try it, thanks.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I'm I would like to know if you compare your results of your random walk and classifier to the results of some more naive classifiers like nearest neighbor classifier classifier, also an extension that we have to do is to compare our method with very simple algorithm classification algorithm in graph.",
                    "label": 0
                },
                {
                    "sent": "So like a KNN or neighboring.",
                    "label": 0
                },
                {
                    "sent": "So yes, we still have to do that.",
                    "label": 0
                },
                {
                    "sent": "So I think it's time.",
                    "label": 0
                }
            ]
        }
    }
}