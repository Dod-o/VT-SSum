{
    "id": "ws3tcbz4hxm2esdnfulojsamspgyniqs",
    "title": "Efficient Online Learning via Randomized Rounding",
    "info": {
        "author": [
            "Ohad Shamir, Faculty of Mathematics and Computer Science, Weizmann Institute of Science"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/nips2011_shamir_rounding/",
    "segmentation": [
        [
            "So our."
        ],
        [
            "Paper deals with online learning, which in a nutshell is this sequential process, wherein each round in adversary picks a certain loss function.",
            "The learner then predicts with some predictor, WT and stuff, and the goal in this setting is to minimize the regrets, namely the difference between the learners cumulative loss and the loss of the best single fixed predictor in hindsight, in some fixed a predictor Class A capital W. Now, this framework we received a lot of attention in recent years because it has a lot of strong advantages.",
            "So for instance, we don't need to make any sort of stochastic assumptions on the loss.",
            "It doesn't have to be a picked I ID or anything like that.",
            "It can be a completely arbitrary.",
            "This setting usually results in algorithms which are very simple, really efficient.",
            "They really work in practice.",
            "Please for convex problems and they also come with strong theoretical guarantees."
        ],
        [
            "However, the current state of online learning also has something which might be seen as a certain conceptual drawback, namely that most online algorithms that people use it can be seen as variants of the same underlying algorithmic principle.",
            "She's noted either as Mirror descent or follow the regularised leader, namely that each time we're going to pick your next predictor by minimizing this combination of an expression involving the gradient of your current class and the current predictor and a divergent Sturm forcing you to remain close to the previous predictor.",
            "In fact, in this nips there is a very nice paper by Srebro pseudo ran into Ari, which actually show that if you ignore the issue of computational tractability, then mirror descent is in some sense, universal, it would.",
            "Work for any sort of convex online problem, and the emerging question is really whether this is the only way we can do online learning, namely for any sort of convex online learning problem, we don't need to look further than some mirror descent algorithm."
        ],
        [
            "So in our paper, we present an approach which is at least as far as we can judge completely different to do efficient online learning, computationally efficient.",
            "We present an algorithm we called the R-squared forecaster, which is based on a certain randomized play out technique.",
            "Will see shortly what I mean by that and randomized rounding are floss, subgradients and this algorithm is computationally efficient as long as you can efficiently compute an empirical risk minimizer with respect to the absolute loss.",
            "We use this forecaster for two applications.",
            "The first one is that we solve the longstanding open problem linking between efficient batch learning and online, transductive learning, and the second application is that we present what is to the best of our knowledge, the very first efficient online algorithm for doing collaborative filtering with the trace norm.",
            "This problem received a lot of attention in recent years in a statistical setting, assuming entries in the matrix or pick the ID for instance.",
            "But we show that actually can also do it in an online setting where the entries in their values are chosen a in a completely arbitrary manner."
        ],
        [
            "So our starting point would be a very basic online learning problem, maybe the simplest one can come up with, namely prediction of binary sequences.",
            "So the adversary at each round is going to pick a binary value YT and we need to guess this value and we measure ourselves using the 01 loss.",
            "Either we predicted correctly or not, and we also randomize predictions, so we can predict something between plus one or minus one.",
            "Quantifying the probability that we would pick one of these two values.",
            "And we suffered the expected loss, which in this case would be just the absolute class, and our goal is to minimize regret with respect to some fixed comparison class of binary A of prediction sequences.",
            "Now for this very simple setting, there's been a mini maxi regret analysis provided by Chung and Colt 1994, and by choosing Bianchi Freund, Haeussler, Humboldt, Shapira and Warmoth in 1997."
        ],
        [
            "And it turns out so that analysis just focused on the regret that one can achieve.",
            "But implicit in this analysis, there was also a very simple, although computationally inefficient algorithm which is minimax optimal, and the algorithm works as follows.",
            "So at each round we are defining 2 random sequences, S minus an S plus the prefix of.",
            "Both are just the previous outcomes.",
            "Then we plug in either minus one and plus one and fill the rest just by.",
            "Iid Rademacher and variables taking values of plus one or minus one with equal probability.",
            "We then define what we call the ear and difference value.",
            "So this is just the difference between a the empirical, the minimal empirical risk achievable on the sequence S minus with respect to the absolute class overall sequences in capital F minus the same thing on a S plus.",
            "So assuming we can compute in ear M and then we can compute the value of this for any fixed choice of the Rademacher.",
            "Random variables and then our prediction is simply going to be the expected value of this difference and expectation over the Rademacher variables is sort of a rough game theoretic intuition why this algorithm works is that in this kind of setting the minimax regret achievable by the minimax optimal strategy for the learner is the same as the maximum regret achievable by the maximin.",
            "Optimal strategy for the adversary.",
            "And for the adversary, turns out that the best thing he can do is to be as random as possible and just pick a values uniformly at random.",
            "So what the learner does is to basically simulate such an adversary conditioned on the previous rounds fill assumed that the rest of the values chosen by the adversary would just be chosen uniformly at random and predict based on that."
        ],
        [
            "And in terms of the regret analysis, one can show that the regret of this algorithm in a mini Mac sense equals the Rademacher complexity of our comparison class F. Which is interesting because this is exactly the standard way that we measure the sample complexity of fit this problem in a batch statistical setting.",
            "So assuming we get ID examples, this is also exactly the expression quantifying how many samples we would need in order to learn in a statistical set."
        ],
        [
            "So our first observation.",
            "So the algorithm is not efficient because you as I showed it because you need to average over exponentially many choices of the values for the Rademacher random variables.",
            "So first observation is that you can pretty easily make it computationally efficient by using just a single draw off RT instead of the expectation anusa Martingale argument.",
            "However, this still results in an algorithm which only applies for a very, very limited setting.",
            "Just for binary sequences and just 4:01 or absolute losses.",
            "So next I'm going to show you how we can deal with a much more realistic setting where the outcomes are real valued and the loss can be general convex and Lipschitz loss function."
        ],
        [
            "So how do we go about doing it?",
            "So this is going to be our R-squared forecaster, so maybe the 1st way.",
            "First attempt one I think of is to try and extend this minimax analysis to more general setup, so more outcomes or other loss functions.",
            "But it turns out that it doesn't work.",
            "So the man that you change even the smallest thing in this analysis, things breakdown and you no longer get anything tractable.",
            "So we take a different approach and our approach is to reduce.",
            "The general problem to the problem of predicting binary sequences, so I'm going to share an explicit pseudocode in the next slide, but sort of.",
            "The general architecture is that we take the values that we've seen in previous rounds.",
            "We compute gradients of the losses in the previous rounds, and we convert it in a certain way to a binary sequence, which we then feed to the basic algorithm.",
            "An we take its output and converted back to something we can use in our general framework."
        ],
        [
            "So this is the pseudocode an I sort of marked in bold.",
            "The main things which are different from the basic algorithm.",
            "So it has a few more parameters and in each round we again define two random sequences were.",
            "Now we use a certain sequence of values E12, Z, T -- 1, which is chosen in a certain way.",
            "Then we compute Attati independent draws of the ear of a scaled version of the year and may difference value.",
            "We're at is some parameter and we predict their empirical average.",
            "Then after we get the outcome and suffered the loss, we're going to let ZTE, which we use here to be either plus one or minus one, with the probability depending on the gradient or the sub gradient with respect to our current prediction in the current round."
        ],
        [
            "And in terms of the analysis, we can show that as long as the loss is bounded and one Lipschitz without loss of generality, then with high probability the regret of this forecaster is going to be the Rademacher complexity of our comparison class plus another term which skills like square root of T and the remember.",
            "We have this parameter, Etta, so it's a free parameter, it's user defined and it allows us to trade off between the regret term here.",
            "And the computational complexity of the forecaster.",
            "So we can pick better to be large.",
            "Making the this term in the regret.",
            "Small, but the prices will pay is that we now need more time in order to run this forecaster, because we're going to need to compute more year ends in each round."
        ],
        [
            "OK, so our first application is related to transductive online learning.",
            "So in NIPS 2005 card in Kali.",
            "Ask the following questions so we know that in general, given an efficient online learning algorithm, we can convert it to an efficient batch learning algorithm using online to batch conversions and they ask whether the reverse is in some sense true and what they showed is that for the case of binary classification, if you can do a batch learning efficiently, in particular if you can compute, ERM, efficiently, then you can also do transductive online learning efficiently.",
            "However, they were only able to show it at an inferior rate, so for the best learning algorithm, the rate is square root of T and the corresponding online learning algorithm is only two to 3/4 and the main open questions they pose is whether you can improve this.",
            "So with our new algorithm, it's actually quite straightforward to get the optimal air 8 sqrt T one up to log factors.",
            "Anwer over this thing works not just for binary classification, but for general convex Lipschitz loss fun."
        ],
        [
            "Oceans.",
            "Our second application is collaborative filtering, which received a lot of attention in recent years.",
            "In a nutshell, the goal is given a mostly unknown matrix with just a few entries revealed to us.",
            "We want to predict remaining entries and this problem has quite a few motivations such as the collaborative filtering in recommender systems such as the Netflix Challenge, a dealing with incomplete data, and so on, and the most of the work so far focused on a bad statistical setting that we assume that.",
            "The entries that are revealed to us or say chosen a ID.",
            "However, this sort of idea assumption is not really a.",
            "It's questionable in practice, so if we look at recommender systems often you have very strong time elements, so assuming just IID process is not always very realistic and we might want to be able to have an online version of this problem where we don't need to make any sort of statistical assumptions."
        ],
        [
            "So in an online setting, what the way we can model it is that we start with some unknown matrix and in each round adversary chooses an entry location and the value for this entry.",
            "It then reveals this location learner has to predict what is the value there and then the values revealed in the learner suffers the corresponding loss and both the choice of the entry location and the value is of course completely arbitrary.",
            "We're also going to make him very mild assumption that each entry is going to be revealed just a once an we want to measure ourselves with respect to all N by N matrices who has a bounded trace norm where the right scaling here is sqrt N * N."
        ],
        [
            "So it turns out that if you try a standard mirror descent approach, then this thing doesn't work, as is the kind of regret that you get is square root.",
            "The average regret per round is something like square root of M N / T which only becomes nontrivial once there were M * N rounds, nearly all of the entries more less in the matrix were already revealed.",
            "A also our forecaster doesn't seem to work as is because it requires certain things which don't seem to be satisfied here.",
            "For instance, we need to know the sequence of the entry locations in advance.",
            "We need to know exactly on how many entries were going to be asked.",
            "We need to know the horizon.",
            "Which doesn't really hold here.",
            "However, we show that it is still possible to adapt the R-squared forecaster to this setting using some unique properties of the Rademacher complexity.",
            "In this setting, in a nutshell, that the complexity doesn't scale with the number of frowns fundamentally it has to do with the fact that the domain is finite.",
            "It's a finite matrix, and the kind of regret guarantees that we get parallel.",
            "Those that you can get in a fully distribution free.",
            "Statistical setting which were results obtained in the cold in the last cult and consider poster for the details on how exactly we do it."
        ],
        [
            "So to conclude, our paper presents in novel and as far as we can judge, a very different approach to do online learning efficiently, and it's efficient as long as you can compute efficiently and erm with respect to the absolute loss, we showed two applications for this, one solving an open problem connecting a transductive online learning and batch learning, and the second presenting the first online algorithm for collaborative filtering with trace norm.",
            "There's still quite a few open questions left, for instance whether there are other applications for this.",
            "Framework whether you can relax some of the conditions, another issue is to make this algorithm fully practical so it is efficient in terms of that it runs in polynomial time.",
            "But still you need to solve quite a lot of erm's in each round, which makes it not fully practical and they finally, despite it, it looks very different than a mirror descent or further regularised leader approaches.",
            "I wonder if there is some sort of deep relationship between the R-squared forecaster and these.",
            "Kind of standard methods, so that's it.",
            "Thank you very much.",
            "In so the question was whether we have any other applications that we currently guess know about or things that can be applied so not at the minute.",
            "I mean, this thing can be applied to all kinds of variants of the collaborative filtering problem using some other assumptions.",
            "At the moment we don't have a good idea of something completely different, but we suspected that there should be out there."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Paper deals with online learning, which in a nutshell is this sequential process, wherein each round in adversary picks a certain loss function.",
                    "label": 1
                },
                {
                    "sent": "The learner then predicts with some predictor, WT and stuff, and the goal in this setting is to minimize the regrets, namely the difference between the learners cumulative loss and the loss of the best single fixed predictor in hindsight, in some fixed a predictor Class A capital W. Now, this framework we received a lot of attention in recent years because it has a lot of strong advantages.",
                    "label": 0
                },
                {
                    "sent": "So for instance, we don't need to make any sort of stochastic assumptions on the loss.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to be a picked I ID or anything like that.",
                    "label": 0
                },
                {
                    "sent": "It can be a completely arbitrary.",
                    "label": 0
                },
                {
                    "sent": "This setting usually results in algorithms which are very simple, really efficient.",
                    "label": 0
                },
                {
                    "sent": "They really work in practice.",
                    "label": 0
                },
                {
                    "sent": "Please for convex problems and they also come with strong theoretical guarantees.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, the current state of online learning also has something which might be seen as a certain conceptual drawback, namely that most online algorithms that people use it can be seen as variants of the same underlying algorithmic principle.",
                    "label": 0
                },
                {
                    "sent": "She's noted either as Mirror descent or follow the regularised leader, namely that each time we're going to pick your next predictor by minimizing this combination of an expression involving the gradient of your current class and the current predictor and a divergent Sturm forcing you to remain close to the previous predictor.",
                    "label": 0
                },
                {
                    "sent": "In fact, in this nips there is a very nice paper by Srebro pseudo ran into Ari, which actually show that if you ignore the issue of computational tractability, then mirror descent is in some sense, universal, it would.",
                    "label": 0
                },
                {
                    "sent": "Work for any sort of convex online problem, and the emerging question is really whether this is the only way we can do online learning, namely for any sort of convex online learning problem, we don't need to look further than some mirror descent algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in our paper, we present an approach which is at least as far as we can judge completely different to do efficient online learning, computationally efficient.",
                    "label": 0
                },
                {
                    "sent": "We present an algorithm we called the R-squared forecaster, which is based on a certain randomized play out technique.",
                    "label": 0
                },
                {
                    "sent": "Will see shortly what I mean by that and randomized rounding are floss, subgradients and this algorithm is computationally efficient as long as you can efficiently compute an empirical risk minimizer with respect to the absolute loss.",
                    "label": 1
                },
                {
                    "sent": "We use this forecaster for two applications.",
                    "label": 0
                },
                {
                    "sent": "The first one is that we solve the longstanding open problem linking between efficient batch learning and online, transductive learning, and the second application is that we present what is to the best of our knowledge, the very first efficient online algorithm for doing collaborative filtering with the trace norm.",
                    "label": 1
                },
                {
                    "sent": "This problem received a lot of attention in recent years in a statistical setting, assuming entries in the matrix or pick the ID for instance.",
                    "label": 0
                },
                {
                    "sent": "But we show that actually can also do it in an online setting where the entries in their values are chosen a in a completely arbitrary manner.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our starting point would be a very basic online learning problem, maybe the simplest one can come up with, namely prediction of binary sequences.",
                    "label": 1
                },
                {
                    "sent": "So the adversary at each round is going to pick a binary value YT and we need to guess this value and we measure ourselves using the 01 loss.",
                    "label": 0
                },
                {
                    "sent": "Either we predicted correctly or not, and we also randomize predictions, so we can predict something between plus one or minus one.",
                    "label": 0
                },
                {
                    "sent": "Quantifying the probability that we would pick one of these two values.",
                    "label": 0
                },
                {
                    "sent": "And we suffered the expected loss, which in this case would be just the absolute class, and our goal is to minimize regret with respect to some fixed comparison class of binary A of prediction sequences.",
                    "label": 0
                },
                {
                    "sent": "Now for this very simple setting, there's been a mini maxi regret analysis provided by Chung and Colt 1994, and by choosing Bianchi Freund, Haeussler, Humboldt, Shapira and Warmoth in 1997.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it turns out so that analysis just focused on the regret that one can achieve.",
                    "label": 0
                },
                {
                    "sent": "But implicit in this analysis, there was also a very simple, although computationally inefficient algorithm which is minimax optimal, and the algorithm works as follows.",
                    "label": 0
                },
                {
                    "sent": "So at each round we are defining 2 random sequences, S minus an S plus the prefix of.",
                    "label": 0
                },
                {
                    "sent": "Both are just the previous outcomes.",
                    "label": 1
                },
                {
                    "sent": "Then we plug in either minus one and plus one and fill the rest just by.",
                    "label": 1
                },
                {
                    "sent": "Iid Rademacher and variables taking values of plus one or minus one with equal probability.",
                    "label": 0
                },
                {
                    "sent": "We then define what we call the ear and difference value.",
                    "label": 0
                },
                {
                    "sent": "So this is just the difference between a the empirical, the minimal empirical risk achievable on the sequence S minus with respect to the absolute class overall sequences in capital F minus the same thing on a S plus.",
                    "label": 0
                },
                {
                    "sent": "So assuming we can compute in ear M and then we can compute the value of this for any fixed choice of the Rademacher.",
                    "label": 0
                },
                {
                    "sent": "Random variables and then our prediction is simply going to be the expected value of this difference and expectation over the Rademacher variables is sort of a rough game theoretic intuition why this algorithm works is that in this kind of setting the minimax regret achievable by the minimax optimal strategy for the learner is the same as the maximum regret achievable by the maximin.",
                    "label": 0
                },
                {
                    "sent": "Optimal strategy for the adversary.",
                    "label": 0
                },
                {
                    "sent": "And for the adversary, turns out that the best thing he can do is to be as random as possible and just pick a values uniformly at random.",
                    "label": 0
                },
                {
                    "sent": "So what the learner does is to basically simulate such an adversary conditioned on the previous rounds fill assumed that the rest of the values chosen by the adversary would just be chosen uniformly at random and predict based on that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in terms of the regret analysis, one can show that the regret of this algorithm in a mini Mac sense equals the Rademacher complexity of our comparison class F. Which is interesting because this is exactly the standard way that we measure the sample complexity of fit this problem in a batch statistical setting.",
                    "label": 0
                },
                {
                    "sent": "So assuming we get ID examples, this is also exactly the expression quantifying how many samples we would need in order to learn in a statistical set.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our first observation.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is not efficient because you as I showed it because you need to average over exponentially many choices of the values for the Rademacher random variables.",
                    "label": 0
                },
                {
                    "sent": "So first observation is that you can pretty easily make it computationally efficient by using just a single draw off RT instead of the expectation anusa Martingale argument.",
                    "label": 0
                },
                {
                    "sent": "However, this still results in an algorithm which only applies for a very, very limited setting.",
                    "label": 0
                },
                {
                    "sent": "Just for binary sequences and just 4:01 or absolute losses.",
                    "label": 1
                },
                {
                    "sent": "So next I'm going to show you how we can deal with a much more realistic setting where the outcomes are real valued and the loss can be general convex and Lipschitz loss function.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we go about doing it?",
                    "label": 0
                },
                {
                    "sent": "So this is going to be our R-squared forecaster, so maybe the 1st way.",
                    "label": 0
                },
                {
                    "sent": "First attempt one I think of is to try and extend this minimax analysis to more general setup, so more outcomes or other loss functions.",
                    "label": 1
                },
                {
                    "sent": "But it turns out that it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "So the man that you change even the smallest thing in this analysis, things breakdown and you no longer get anything tractable.",
                    "label": 0
                },
                {
                    "sent": "So we take a different approach and our approach is to reduce.",
                    "label": 1
                },
                {
                    "sent": "The general problem to the problem of predicting binary sequences, so I'm going to share an explicit pseudocode in the next slide, but sort of.",
                    "label": 0
                },
                {
                    "sent": "The general architecture is that we take the values that we've seen in previous rounds.",
                    "label": 0
                },
                {
                    "sent": "We compute gradients of the losses in the previous rounds, and we convert it in a certain way to a binary sequence, which we then feed to the basic algorithm.",
                    "label": 0
                },
                {
                    "sent": "An we take its output and converted back to something we can use in our general framework.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the pseudocode an I sort of marked in bold.",
                    "label": 0
                },
                {
                    "sent": "The main things which are different from the basic algorithm.",
                    "label": 0
                },
                {
                    "sent": "So it has a few more parameters and in each round we again define two random sequences were.",
                    "label": 0
                },
                {
                    "sent": "Now we use a certain sequence of values E12, Z, T -- 1, which is chosen in a certain way.",
                    "label": 0
                },
                {
                    "sent": "Then we compute Attati independent draws of the ear of a scaled version of the year and may difference value.",
                    "label": 0
                },
                {
                    "sent": "We're at is some parameter and we predict their empirical average.",
                    "label": 0
                },
                {
                    "sent": "Then after we get the outcome and suffered the loss, we're going to let ZTE, which we use here to be either plus one or minus one, with the probability depending on the gradient or the sub gradient with respect to our current prediction in the current round.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in terms of the analysis, we can show that as long as the loss is bounded and one Lipschitz without loss of generality, then with high probability the regret of this forecaster is going to be the Rademacher complexity of our comparison class plus another term which skills like square root of T and the remember.",
                    "label": 0
                },
                {
                    "sent": "We have this parameter, Etta, so it's a free parameter, it's user defined and it allows us to trade off between the regret term here.",
                    "label": 0
                },
                {
                    "sent": "And the computational complexity of the forecaster.",
                    "label": 0
                },
                {
                    "sent": "So we can pick better to be large.",
                    "label": 0
                },
                {
                    "sent": "Making the this term in the regret.",
                    "label": 0
                },
                {
                    "sent": "Small, but the prices will pay is that we now need more time in order to run this forecaster, because we're going to need to compute more year ends in each round.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so our first application is related to transductive online learning.",
                    "label": 1
                },
                {
                    "sent": "So in NIPS 2005 card in Kali.",
                    "label": 0
                },
                {
                    "sent": "Ask the following questions so we know that in general, given an efficient online learning algorithm, we can convert it to an efficient batch learning algorithm using online to batch conversions and they ask whether the reverse is in some sense true and what they showed is that for the case of binary classification, if you can do a batch learning efficiently, in particular if you can compute, ERM, efficiently, then you can also do transductive online learning efficiently.",
                    "label": 0
                },
                {
                    "sent": "However, they were only able to show it at an inferior rate, so for the best learning algorithm, the rate is square root of T and the corresponding online learning algorithm is only two to 3/4 and the main open questions they pose is whether you can improve this.",
                    "label": 0
                },
                {
                    "sent": "So with our new algorithm, it's actually quite straightforward to get the optimal air 8 sqrt T one up to log factors.",
                    "label": 0
                },
                {
                    "sent": "Anwer over this thing works not just for binary classification, but for general convex Lipschitz loss fun.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oceans.",
                    "label": 0
                },
                {
                    "sent": "Our second application is collaborative filtering, which received a lot of attention in recent years.",
                    "label": 0
                },
                {
                    "sent": "In a nutshell, the goal is given a mostly unknown matrix with just a few entries revealed to us.",
                    "label": 1
                },
                {
                    "sent": "We want to predict remaining entries and this problem has quite a few motivations such as the collaborative filtering in recommender systems such as the Netflix Challenge, a dealing with incomplete data, and so on, and the most of the work so far focused on a bad statistical setting that we assume that.",
                    "label": 1
                },
                {
                    "sent": "The entries that are revealed to us or say chosen a ID.",
                    "label": 0
                },
                {
                    "sent": "However, this sort of idea assumption is not really a.",
                    "label": 0
                },
                {
                    "sent": "It's questionable in practice, so if we look at recommender systems often you have very strong time elements, so assuming just IID process is not always very realistic and we might want to be able to have an online version of this problem where we don't need to make any sort of statistical assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in an online setting, what the way we can model it is that we start with some unknown matrix and in each round adversary chooses an entry location and the value for this entry.",
                    "label": 0
                },
                {
                    "sent": "It then reveals this location learner has to predict what is the value there and then the values revealed in the learner suffers the corresponding loss and both the choice of the entry location and the value is of course completely arbitrary.",
                    "label": 0
                },
                {
                    "sent": "We're also going to make him very mild assumption that each entry is going to be revealed just a once an we want to measure ourselves with respect to all N by N matrices who has a bounded trace norm where the right scaling here is sqrt N * N.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it turns out that if you try a standard mirror descent approach, then this thing doesn't work, as is the kind of regret that you get is square root.",
                    "label": 0
                },
                {
                    "sent": "The average regret per round is something like square root of M N / T which only becomes nontrivial once there were M * N rounds, nearly all of the entries more less in the matrix were already revealed.",
                    "label": 0
                },
                {
                    "sent": "A also our forecaster doesn't seem to work as is because it requires certain things which don't seem to be satisfied here.",
                    "label": 0
                },
                {
                    "sent": "For instance, we need to know the sequence of the entry locations in advance.",
                    "label": 0
                },
                {
                    "sent": "We need to know exactly on how many entries were going to be asked.",
                    "label": 0
                },
                {
                    "sent": "We need to know the horizon.",
                    "label": 0
                },
                {
                    "sent": "Which doesn't really hold here.",
                    "label": 0
                },
                {
                    "sent": "However, we show that it is still possible to adapt the R-squared forecaster to this setting using some unique properties of the Rademacher complexity.",
                    "label": 0
                },
                {
                    "sent": "In this setting, in a nutshell, that the complexity doesn't scale with the number of frowns fundamentally it has to do with the fact that the domain is finite.",
                    "label": 0
                },
                {
                    "sent": "It's a finite matrix, and the kind of regret guarantees that we get parallel.",
                    "label": 0
                },
                {
                    "sent": "Those that you can get in a fully distribution free.",
                    "label": 0
                },
                {
                    "sent": "Statistical setting which were results obtained in the cold in the last cult and consider poster for the details on how exactly we do it.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, our paper presents in novel and as far as we can judge, a very different approach to do online learning efficiently, and it's efficient as long as you can compute efficiently and erm with respect to the absolute loss, we showed two applications for this, one solving an open problem connecting a transductive online learning and batch learning, and the second presenting the first online algorithm for collaborative filtering with trace norm.",
                    "label": 1
                },
                {
                    "sent": "There's still quite a few open questions left, for instance whether there are other applications for this.",
                    "label": 0
                },
                {
                    "sent": "Framework whether you can relax some of the conditions, another issue is to make this algorithm fully practical so it is efficient in terms of that it runs in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "But still you need to solve quite a lot of erm's in each round, which makes it not fully practical and they finally, despite it, it looks very different than a mirror descent or further regularised leader approaches.",
                    "label": 1
                },
                {
                    "sent": "I wonder if there is some sort of deep relationship between the R-squared forecaster and these.",
                    "label": 0
                },
                {
                    "sent": "Kind of standard methods, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "In so the question was whether we have any other applications that we currently guess know about or things that can be applied so not at the minute.",
                    "label": 0
                },
                {
                    "sent": "I mean, this thing can be applied to all kinds of variants of the collaborative filtering problem using some other assumptions.",
                    "label": 0
                },
                {
                    "sent": "At the moment we don't have a good idea of something completely different, but we suspected that there should be out there.",
                    "label": 0
                }
            ]
        }
    }
}