{
    "id": "lup7qm5kscqdqffv7ter5iaaf2isjfbv",
    "title": "Context-Aware Saliency Detection",
    "info": {
        "author": [
            "Lihi Zelnik-Manor, Department of Electrical Engineering, Technion - Israel Institute of Technology"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_zelnik_manor_casd/",
    "segmentation": [
        [
            "OK, so our second speaker is leahi."
        ],
        [
            "Like an keeping in the realm of silence?",
            "Saliency, she'll be talking about context aware saliency detection.",
            "Thank you.",
            "If after this."
        ],
        [
            "Try this picture.",
            "What title would you give it?",
            "So I can't wait for answers.",
            "We cannot move into an interactive style of talk here, so I ask.",
            "People are priority and these are some of the titles that I got.",
            "An Olympic weightlifter Olympic victory Olympic achievement.",
            "Now if you look at that, we don't really need all the pixels in the image to describe this."
        ],
        [
            "Titles we only need part of them, which you call them the important pixels.",
            "This would be the pixels on the weightlifter, the weights and Olympic logo, and in this particular picture we don't really need the background pixels."
        ],
        [
            "In recent years many works have been published on Silence East.",
            "Imagine we just someone in the previous talk and most of you tried to find the focus of attention that a human would look at at first glance.",
            "Now, if you remember the silence, the Maps you just signed a previous presentation, they look like blobby white things over dark background.",
            "They don't necessarily capture all the pixels required to describe the titles of for this particular image."
        ],
        [
            "Other science algorithms try to find a bounding box around the single or the main dominant object."
        ],
        [
            "Where segmentation algorithm try to segment the dominant object accurately, none of these capture all the P."
        ],
        [
            "Cells that need to describe the image.",
            "This is our goal in this talk.",
            "We wanted to find all the pixels required to convey the content of the image.",
            "To tell the story.",
            "To convey the story, the image tells the user.",
            "In this example we need the pixels on the weightlifter, the Olympic logo and the weights and what you see here is actually one of our results."
        ],
        [
            "So now comes the title of our talk.",
            "Usually this is the first slide we title it.",
            "Context aware salience because we want to find the silent pixels part of the context that is required to convey the content of the image and.",
            "OK, not the answer, so this was.",
            "This work was done together with US government and a little and you can meet Ayala 10 myself later on in the poster."
        ],
        [
            "Right?",
            "So let's see what, what, how we do that.",
            "Our contributions or three fault.",
            "First, I will describe the principles for this type of silencing.",
            "For context aware silencing, then I will describe an algorithm based on those principles and 3rd I will show that this type of silenci is useful for two applications in."
        ],
        [
            "Retargeting and collage.",
            "As."
        ],
        [
            "That was the principles, and we believe that the good algorithm should be based on strong principles.",
            "So we went out and checked the literature on human perception, and we found four principles that guided our."
        ],
        [
            "Work, the first one is locality for pixel to be silent it would be locally silent.",
            "It should have unique contrast and color.",
            "If you take a look at this example, this leaf image you see on the right is the result when algorithm by Walter on call and this is a typical result of most of the algorithms that are tried to follow human attention.",
            "They look for locally salient pixels that have unique contrast in a picture like this, they capture mostly the textures seem behind the fence rather than the leaf.",
            "So this is the first principle.",
            "The second principle comes out is very intuitive now."
        ],
        [
            "A pixel should be also globally silent.",
            "An interview prior to 2007 who exact proposed method based on Fourier analysis of the image which detects those pixels that generate unique frequencies in the Fourier domain, so they find those pixels that are globally silent.",
            "Now in this example, they don't succeed in detecting the leaf because they have scale issues.",
            "Usually they do detect the dominant object, but in a course manner an you will see fur."
        ],
        [
            "The result later on in the in the presentation.",
            "In Syria 2007 little proposed merging both locality Angle ability and global salience.",
            "They took the ETN car style approach for silence estimation for the local aspect and then they combine it with a global silencing measure, which essentially was looking for rectangular regions with unique color, and you can see here in this example that since the leaf is not, it's not rectangular, it is it has a concave shape.",
            "Parts of the liver excluded.",
            "There are not as silent as the rest of the leaf.",
            "We will also combine local and global silence, but in a different way."
        ],
        [
            "We also have two other principles that guide our work.",
            "The third principle comes from the dished out stream and they observe that visual forms are usually organized around a few centers of gravity.",
            "There are a few centers of attention and the silent pixels are grouped around them.",
            "What you see here on the right is the focus of attention points that our algorithm produced, and the silent pixels are those on the leaf that are close to this focus of attention."
        ],
        [
            "And the 4th principle that we will use is high level.",
            "This was shown to be useful by Jad at all in ICC 2009 and high level.",
            "We mean faces, cars, pedestrians, objects.",
            "We should just as a post processing step detect those such objects and mark all the pixels on them as salient."
        ],
        [
            "And here you see the result of our algorithm combining these four principles on this leafy image."
        ],
        [
            "And in comparison with the previous works that I showed you and I think that our result is the only one that detects all the pixels on the leaf accurately, including the Vine, and then just a little bit of defense of the context around it, which is what was the goal of our work."
        ],
        [
            "So let's see how we do that."
        ],
        [
            "I'll start with the first 2 principles, so pixel should for pixel to be silent it should be silent both locally and globally.",
            "So for each pixel we will look at the local neighborhood around it.",
            "The Patch surrounding it, and if this Patch is unique, it has a unique appearance.",
            "You don't find dispatch elsewhere in the image, then dispatches silent, while if you take a Patch like the one marked in yellow, this Patch.",
            "There are other similar patches elsewhere in the image, so it is not silent."
        ],
        [
            "So let's let's see how we measure that we take the Patch and we compare it to all other patches in the image."
        ],
        [
            "We start by comparing just colors.",
            "Euclidean distance between the color of the patches."
        ],
        [
            "If this distance is high for all other patches, then our Patch is silent and vice versa.",
            "Now this incorporates the first 2 principles, but we have another principle."
        ],
        [
            "Which says that position is important and that visual forms are organized around a few centers of gravity.",
            "So let's put that in.",
            "If you look at this Patch here, this background Patch, you notice that it has similar patches both near and far.",
            "This is because it is a background pixels."
        ],
        [
            "By while foreground pixel has similar patches only nearby and it is more salient, we want to incorporate."
        ],
        [
            "That so when we compare patches, we look at their positional."
        ],
        [
            "Distance.",
            "And we define our final distance measure between a pair of patches, as is the ratio between.",
            "The color difference.",
            "And a function of the positional distance so they are distance between a pair of patches is proportional to the color difference when inverse proportion to the position distance."
        ],
        [
            "And now, just to recap, we compare every Patch to all other patches.",
            "We compute this distance and if it is high for all other patches, then our Patch is silent.",
            "Now, in practice we don't need to look at the distance to all the path."
        ],
        [
            "Just it is sufficient if we compute the distance to the K most similar ones.",
            "And based on those distances, this K distances we build our silenci formula."
        ],
        [
            "She looks like this.",
            "Our saliency measure at the single scale is just an exponential function over the considers the sum of the distances to decay most similar patches."
        ],
        [
            "Never use a certain size of patches.",
            "This is the result."
        ],
        [
            "But if we change the Patch size, you could get a somewhat different result.",
            "So we need to consider multiple scales and we notice again that if a Patch is silent at multiple scales, like patches on the bird here, then it belongs to the foreground.",
            "Well, if a Patch is silent only with a few skills, like patches here on the wire.",
            "It is probably belong to the background, so we averaged multiple sudden see Maps at multiple scales, and in practice we actually compare patches of different size."
        ],
        [
            "Is.",
            "So this would probably give us find all the pixels on the bird, but our goal was slightly different.",
            "For us, this picture is a picture of a bird on a wire, not just a bird, and we want to capture some of the immediate context of the bird and we go back to the third principle, which told us that visual forms are organized around a few centers of gravity.",
            "So."
        ],
        [
            "So now we're going to find those and consider them.",
            "We take our multiscale silenci with threshold to find the focus of attention.",
            "Here you see the result we got for the bird.",
            "And now we compute the distance map.",
            "So for each pixel we compute its distance from the nearest focus of attention.",
            "And we use this to wait the silence.",
            "The map that we obtained before.",
            "So picks us on the bird.",
            "The Silenci will be increased pixels far away from the bird.",
            "On the background will be there silence, he will be decreased, and but pixels on the on the wire, which had some salience and there are close to the word there silently will also be somewhat in half."
        ],
        [
            "And here is our final result."
        ],
        [
            "And then we have the 4th principle, which is high level object and this is excluded from this stock for fair comparison with other works.",
            "Because this is like a post processing step."
        ],
        [
            "So let's recap.",
            "Our algorithm works as follows, we compute.",
            "Assignments we measure based on the distance between patches.",
            "This distance considers both appearance differences and positional differences.",
            "We do it at multiple scales and then we enhance the map that the sun and sea map that we got by considering the distance from the nearest focus of attention."
        ],
        [
            "So let's see some."
        ],
        [
            "Lots.",
            "We start from an image with an an interesting background and you can see that.",
            "On the right top right is our result.",
            "Bottom Left result of Walter and car.",
            "This is the standard human based human attention based algorithm and you can see the which considered actually only local silencing and you consider that mistakenly detects all the pixels in the background is silent because there's texture on the water.",
            "On the bottom right you see the global approach of who in zangon they detect the people, but not very accurately."
        ],
        [
            "Another example, within an interesting background.",
            "Again, we are algorithms.",
            "The only one that detects all the pixels on the dominant object."
        ],
        [
            "In some images we want to detect not only the main object, but also part of the background, that is, that is interesting.",
            "For example, here we want to detect the motorcyclist and part of his reflection on the wet road, and you can see that this is nicely captured by our silence."
        ],
        [
            "Map.",
            "And here we capture both the swimmer and the foam he generates and look what happens to the local approach that just the bottom left.",
            "They just detect all the pixels because there's texture all over."
        ],
        [
            "Complex scene again are very complicated and very difficult for other algorithms, and we can handle him very well.",
            "We detect very nicely both the car and the fire."
        ],
        [
            "And here we detect the people and actually this sorry this guy here with the red towel is task government who's done most of the work in this talk."
        ],
        [
            "We have some quantitative evaluation.",
            "You're welcome to come to the poster to look at it.",
            "Obviously our curve is the blue one and has the best result here."
        ],
        [
            "I won't talk much about this, and we also compared Tooele, UT an which had an algorithm for detecting a single dominant object, an here it's a different approach.",
            "So given these images you can see the middle row they detect they detect here a man, a bird and a lady while we detect two men talking a burden, it's feature links Anna Lady leaning against the wall, so it's."
        ],
        [
            "Different approaches."
        ],
        [
            "So now to applications.",
            "I promise you to applications.",
            "The first one is image retargeting.",
            "We took this seam carving code and there they also have their own silence algorithm which is based on local silenci.",
            "An in seam carving.",
            "You change the aspect ratio of the image, but by getting rid of non important pixels an when using their algorithm in the middle column we see using their salience.",
            "The leaf is totally distorted while taking the exact same algorithm but plugging in our saliency the leaf is remain.",
            "Remains intact."
        ],
        [
            "Another example of the same kind dear silenci is distracted by the texture on the background while we detect the man and it's his immediate surrounding.",
            "So when you carve, the image, demand remains intact.",
            "While in their approach, the man disappears."
        ],
        [
            "And another example of the same type."
        ],
        [
            "And another application where this is useful is image collage.",
            "Here we want to take our photographs that we took in our last trip.",
            "This one is a trip to a area from eight years ago I think, and we want to create a collage.",
            "So we want to get rid of all the redundant pixels in all the images.",
            "We do that by."
        ],
        [
            "Putting the silence in Maps.",
            "Now we found all."
        ],
        [
            "Important pixels.",
            "We cut out all of the regions.",
            "That contain."
        ],
        [
            "And the important pixels.",
            "And then we compose them into a collage like this one.",
            "So this work this work was presented in Eurographics just a month or two ago.",
            "So you're welcome to take a look at it.",
            "The colleges are really nice."
        ],
        [
            "So let's summarize, I showed you.",
            "And you definition for saliency?",
            "The context that were assigned and see which is different from the standard definition for saliency?",
            "I presented an algorithm which is based on four perceptual principles.",
            "And finally, I showed you two applications where this is useful."
        ],
        [
            "I hope you like this work and welcome to our poster an to try that.",
            "Thank you.",
            "You mentioned that you combine the scales and if the objects really salient, it should be salient at all the scales.",
            "Then why did you use the sum instead of the multiplication?",
            "We tried this, some seem to work well.",
            "I'm not sure there was something principled here of trying this thing.",
            "Maybe the multiplication will work better or as well, I don't know.",
            "You mentioned that you compute K nearest neighbors.",
            "I'm wondering how quickly you do that.",
            "We didn't do it quickly at all.",
            "We did it very, very slowly.",
            "We computed the distances to all other patches and just took the K nearest ones you could.",
            "You could use approximate nearest neighbors approaches an actually I just heard from a colleague that her students implemented our work and it runs in real time for them.",
            "I don't know exactly what they did, but I'm going to talk to them after the conference and see how they do that.",
            "Other quick question is if you have a bunch of faces in the image.",
            "Would you pick up all the faces?",
            "Doubtful because you may get a if you look at the face Patch, you may find a match in another place.",
            "OK, so if we do have so with faces, usually if you have multiple faces in the same picture, usually we won't have much of a problem.",
            "I think I showed you there was one here with a guy holding his daughter and there was no problem.",
            "Both of them were detected.",
            "Faces for in particular we we run it.",
            "You should run a face detector, but if we had a different example of an image with objects that repeat, we had the exact identical object in several places in the image.",
            "This was caused.",
            "This would cause us trouble, right?",
            "Have you done the sensitivity studies between?",
            "Basically some of the key parameters?",
            "First you mentioned that position wise.",
            "Basically they have to be close together for salient features versus the basically that I mean how those affect performance.",
            "I basically some of the basic heuristics are turned into basically parameter settings.",
            "So so how sensitive are those OK?",
            "So regarding parameter settings, so in all the examples you saw you saw here in all the experiments we ran on datasets.",
            "We found that there was a set of parameters that we decided is good and we used it.",
            "We don't have an extensive parameter evaluation tests, so we chose something and it was fixed for all the hundreds of images that we tried, but we should maybe run more serious tests there.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so our second speaker is leahi.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like an keeping in the realm of silence?",
                    "label": 0
                },
                {
                    "sent": "Saliency, she'll be talking about context aware saliency detection.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "If after this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try this picture.",
                    "label": 0
                },
                {
                    "sent": "What title would you give it?",
                    "label": 0
                },
                {
                    "sent": "So I can't wait for answers.",
                    "label": 0
                },
                {
                    "sent": "We cannot move into an interactive style of talk here, so I ask.",
                    "label": 0
                },
                {
                    "sent": "People are priority and these are some of the titles that I got.",
                    "label": 0
                },
                {
                    "sent": "An Olympic weightlifter Olympic victory Olympic achievement.",
                    "label": 1
                },
                {
                    "sent": "Now if you look at that, we don't really need all the pixels in the image to describe this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Titles we only need part of them, which you call them the important pixels.",
                    "label": 0
                },
                {
                    "sent": "This would be the pixels on the weightlifter, the weights and Olympic logo, and in this particular picture we don't really need the background pixels.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In recent years many works have been published on Silence East.",
                    "label": 0
                },
                {
                    "sent": "Imagine we just someone in the previous talk and most of you tried to find the focus of attention that a human would look at at first glance.",
                    "label": 0
                },
                {
                    "sent": "Now, if you remember the silence, the Maps you just signed a previous presentation, they look like blobby white things over dark background.",
                    "label": 0
                },
                {
                    "sent": "They don't necessarily capture all the pixels required to describe the titles of for this particular image.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other science algorithms try to find a bounding box around the single or the main dominant object.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where segmentation algorithm try to segment the dominant object accurately, none of these capture all the P.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cells that need to describe the image.",
                    "label": 0
                },
                {
                    "sent": "This is our goal in this talk.",
                    "label": 0
                },
                {
                    "sent": "We wanted to find all the pixels required to convey the content of the image.",
                    "label": 0
                },
                {
                    "sent": "To tell the story.",
                    "label": 0
                },
                {
                    "sent": "To convey the story, the image tells the user.",
                    "label": 0
                },
                {
                    "sent": "In this example we need the pixels on the weightlifter, the Olympic logo and the weights and what you see here is actually one of our results.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now comes the title of our talk.",
                    "label": 0
                },
                {
                    "sent": "Usually this is the first slide we title it.",
                    "label": 0
                },
                {
                    "sent": "Context aware salience because we want to find the silent pixels part of the context that is required to convey the content of the image and.",
                    "label": 0
                },
                {
                    "sent": "OK, not the answer, so this was.",
                    "label": 0
                },
                {
                    "sent": "This work was done together with US government and a little and you can meet Ayala 10 myself later on in the poster.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So let's see what, what, how we do that.",
                    "label": 0
                },
                {
                    "sent": "Our contributions or three fault.",
                    "label": 0
                },
                {
                    "sent": "First, I will describe the principles for this type of silencing.",
                    "label": 1
                },
                {
                    "sent": "For context aware silencing, then I will describe an algorithm based on those principles and 3rd I will show that this type of silenci is useful for two applications in.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Retargeting and collage.",
                    "label": 0
                },
                {
                    "sent": "As.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That was the principles, and we believe that the good algorithm should be based on strong principles.",
                    "label": 0
                },
                {
                    "sent": "So we went out and checked the literature on human perception, and we found four principles that guided our.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work, the first one is locality for pixel to be silent it would be locally silent.",
                    "label": 0
                },
                {
                    "sent": "It should have unique contrast and color.",
                    "label": 0
                },
                {
                    "sent": "If you take a look at this example, this leaf image you see on the right is the result when algorithm by Walter on call and this is a typical result of most of the algorithms that are tried to follow human attention.",
                    "label": 0
                },
                {
                    "sent": "They look for locally salient pixels that have unique contrast in a picture like this, they capture mostly the textures seem behind the fence rather than the leaf.",
                    "label": 0
                },
                {
                    "sent": "So this is the first principle.",
                    "label": 0
                },
                {
                    "sent": "The second principle comes out is very intuitive now.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A pixel should be also globally silent.",
                    "label": 0
                },
                {
                    "sent": "An interview prior to 2007 who exact proposed method based on Fourier analysis of the image which detects those pixels that generate unique frequencies in the Fourier domain, so they find those pixels that are globally silent.",
                    "label": 0
                },
                {
                    "sent": "Now in this example, they don't succeed in detecting the leaf because they have scale issues.",
                    "label": 0
                },
                {
                    "sent": "Usually they do detect the dominant object, but in a course manner an you will see fur.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result later on in the in the presentation.",
                    "label": 0
                },
                {
                    "sent": "In Syria 2007 little proposed merging both locality Angle ability and global salience.",
                    "label": 0
                },
                {
                    "sent": "They took the ETN car style approach for silence estimation for the local aspect and then they combine it with a global silencing measure, which essentially was looking for rectangular regions with unique color, and you can see here in this example that since the leaf is not, it's not rectangular, it is it has a concave shape.",
                    "label": 0
                },
                {
                    "sent": "Parts of the liver excluded.",
                    "label": 0
                },
                {
                    "sent": "There are not as silent as the rest of the leaf.",
                    "label": 0
                },
                {
                    "sent": "We will also combine local and global silence, but in a different way.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also have two other principles that guide our work.",
                    "label": 0
                },
                {
                    "sent": "The third principle comes from the dished out stream and they observe that visual forms are usually organized around a few centers of gravity.",
                    "label": 1
                },
                {
                    "sent": "There are a few centers of attention and the silent pixels are grouped around them.",
                    "label": 0
                },
                {
                    "sent": "What you see here on the right is the focus of attention points that our algorithm produced, and the silent pixels are those on the leaf that are close to this focus of attention.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the 4th principle that we will use is high level.",
                    "label": 0
                },
                {
                    "sent": "This was shown to be useful by Jad at all in ICC 2009 and high level.",
                    "label": 0
                },
                {
                    "sent": "We mean faces, cars, pedestrians, objects.",
                    "label": 0
                },
                {
                    "sent": "We should just as a post processing step detect those such objects and mark all the pixels on them as salient.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here you see the result of our algorithm combining these four principles on this leafy image.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in comparison with the previous works that I showed you and I think that our result is the only one that detects all the pixels on the leaf accurately, including the Vine, and then just a little bit of defense of the context around it, which is what was the goal of our work.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see how we do that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll start with the first 2 principles, so pixel should for pixel to be silent it should be silent both locally and globally.",
                    "label": 0
                },
                {
                    "sent": "So for each pixel we will look at the local neighborhood around it.",
                    "label": 0
                },
                {
                    "sent": "The Patch surrounding it, and if this Patch is unique, it has a unique appearance.",
                    "label": 1
                },
                {
                    "sent": "You don't find dispatch elsewhere in the image, then dispatches silent, while if you take a Patch like the one marked in yellow, this Patch.",
                    "label": 0
                },
                {
                    "sent": "There are other similar patches elsewhere in the image, so it is not silent.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's let's see how we measure that we take the Patch and we compare it to all other patches in the image.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We start by comparing just colors.",
                    "label": 0
                },
                {
                    "sent": "Euclidean distance between the color of the patches.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If this distance is high for all other patches, then our Patch is silent and vice versa.",
                    "label": 0
                },
                {
                    "sent": "Now this incorporates the first 2 principles, but we have another principle.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which says that position is important and that visual forms are organized around a few centers of gravity.",
                    "label": 0
                },
                {
                    "sent": "So let's put that in.",
                    "label": 0
                },
                {
                    "sent": "If you look at this Patch here, this background Patch, you notice that it has similar patches both near and far.",
                    "label": 1
                },
                {
                    "sent": "This is because it is a background pixels.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By while foreground pixel has similar patches only nearby and it is more salient, we want to incorporate.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That so when we compare patches, we look at their positional.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distance.",
                    "label": 0
                },
                {
                    "sent": "And we define our final distance measure between a pair of patches, as is the ratio between.",
                    "label": 1
                },
                {
                    "sent": "The color difference.",
                    "label": 0
                },
                {
                    "sent": "And a function of the positional distance so they are distance between a pair of patches is proportional to the color difference when inverse proportion to the position distance.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now, just to recap, we compare every Patch to all other patches.",
                    "label": 0
                },
                {
                    "sent": "We compute this distance and if it is high for all other patches, then our Patch is silent.",
                    "label": 0
                },
                {
                    "sent": "Now, in practice we don't need to look at the distance to all the path.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just it is sufficient if we compute the distance to the K most similar ones.",
                    "label": 0
                },
                {
                    "sent": "And based on those distances, this K distances we build our silenci formula.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She looks like this.",
                    "label": 0
                },
                {
                    "sent": "Our saliency measure at the single scale is just an exponential function over the considers the sum of the distances to decay most similar patches.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Never use a certain size of patches.",
                    "label": 0
                },
                {
                    "sent": "This is the result.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But if we change the Patch size, you could get a somewhat different result.",
                    "label": 0
                },
                {
                    "sent": "So we need to consider multiple scales and we notice again that if a Patch is silent at multiple scales, like patches on the bird here, then it belongs to the foreground.",
                    "label": 0
                },
                {
                    "sent": "Well, if a Patch is silent only with a few skills, like patches here on the wire.",
                    "label": 0
                },
                {
                    "sent": "It is probably belong to the background, so we averaged multiple sudden see Maps at multiple scales, and in practice we actually compare patches of different size.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "So this would probably give us find all the pixels on the bird, but our goal was slightly different.",
                    "label": 0
                },
                {
                    "sent": "For us, this picture is a picture of a bird on a wire, not just a bird, and we want to capture some of the immediate context of the bird and we go back to the third principle, which told us that visual forms are organized around a few centers of gravity.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we're going to find those and consider them.",
                    "label": 0
                },
                {
                    "sent": "We take our multiscale silenci with threshold to find the focus of attention.",
                    "label": 0
                },
                {
                    "sent": "Here you see the result we got for the bird.",
                    "label": 0
                },
                {
                    "sent": "And now we compute the distance map.",
                    "label": 1
                },
                {
                    "sent": "So for each pixel we compute its distance from the nearest focus of attention.",
                    "label": 0
                },
                {
                    "sent": "And we use this to wait the silence.",
                    "label": 0
                },
                {
                    "sent": "The map that we obtained before.",
                    "label": 0
                },
                {
                    "sent": "So picks us on the bird.",
                    "label": 0
                },
                {
                    "sent": "The Silenci will be increased pixels far away from the bird.",
                    "label": 0
                },
                {
                    "sent": "On the background will be there silence, he will be decreased, and but pixels on the on the wire, which had some salience and there are close to the word there silently will also be somewhat in half.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is our final result.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we have the 4th principle, which is high level object and this is excluded from this stock for fair comparison with other works.",
                    "label": 0
                },
                {
                    "sent": "Because this is like a post processing step.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's recap.",
                    "label": 0
                },
                {
                    "sent": "Our algorithm works as follows, we compute.",
                    "label": 0
                },
                {
                    "sent": "Assignments we measure based on the distance between patches.",
                    "label": 0
                },
                {
                    "sent": "This distance considers both appearance differences and positional differences.",
                    "label": 0
                },
                {
                    "sent": "We do it at multiple scales and then we enhance the map that the sun and sea map that we got by considering the distance from the nearest focus of attention.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see some.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lots.",
                    "label": 0
                },
                {
                    "sent": "We start from an image with an an interesting background and you can see that.",
                    "label": 0
                },
                {
                    "sent": "On the right top right is our result.",
                    "label": 1
                },
                {
                    "sent": "Bottom Left result of Walter and car.",
                    "label": 0
                },
                {
                    "sent": "This is the standard human based human attention based algorithm and you can see the which considered actually only local silencing and you consider that mistakenly detects all the pixels in the background is silent because there's texture on the water.",
                    "label": 0
                },
                {
                    "sent": "On the bottom right you see the global approach of who in zangon they detect the people, but not very accurately.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example, within an interesting background.",
                    "label": 0
                },
                {
                    "sent": "Again, we are algorithms.",
                    "label": 0
                },
                {
                    "sent": "The only one that detects all the pixels on the dominant object.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some images we want to detect not only the main object, but also part of the background, that is, that is interesting.",
                    "label": 0
                },
                {
                    "sent": "For example, here we want to detect the motorcyclist and part of his reflection on the wet road, and you can see that this is nicely captured by our silence.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Map.",
                    "label": 0
                },
                {
                    "sent": "And here we capture both the swimmer and the foam he generates and look what happens to the local approach that just the bottom left.",
                    "label": 0
                },
                {
                    "sent": "They just detect all the pixels because there's texture all over.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complex scene again are very complicated and very difficult for other algorithms, and we can handle him very well.",
                    "label": 0
                },
                {
                    "sent": "We detect very nicely both the car and the fire.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we detect the people and actually this sorry this guy here with the red towel is task government who's done most of the work in this talk.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have some quantitative evaluation.",
                    "label": 0
                },
                {
                    "sent": "You're welcome to come to the poster to look at it.",
                    "label": 0
                },
                {
                    "sent": "Obviously our curve is the blue one and has the best result here.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I won't talk much about this, and we also compared Tooele, UT an which had an algorithm for detecting a single dominant object, an here it's a different approach.",
                    "label": 0
                },
                {
                    "sent": "So given these images you can see the middle row they detect they detect here a man, a bird and a lady while we detect two men talking a burden, it's feature links Anna Lady leaning against the wall, so it's.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different approaches.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now to applications.",
                    "label": 0
                },
                {
                    "sent": "I promise you to applications.",
                    "label": 0
                },
                {
                    "sent": "The first one is image retargeting.",
                    "label": 0
                },
                {
                    "sent": "We took this seam carving code and there they also have their own silence algorithm which is based on local silenci.",
                    "label": 0
                },
                {
                    "sent": "An in seam carving.",
                    "label": 0
                },
                {
                    "sent": "You change the aspect ratio of the image, but by getting rid of non important pixels an when using their algorithm in the middle column we see using their salience.",
                    "label": 0
                },
                {
                    "sent": "The leaf is totally distorted while taking the exact same algorithm but plugging in our saliency the leaf is remain.",
                    "label": 0
                },
                {
                    "sent": "Remains intact.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example of the same kind dear silenci is distracted by the texture on the background while we detect the man and it's his immediate surrounding.",
                    "label": 0
                },
                {
                    "sent": "So when you carve, the image, demand remains intact.",
                    "label": 0
                },
                {
                    "sent": "While in their approach, the man disappears.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another example of the same type.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another application where this is useful is image collage.",
                    "label": 0
                },
                {
                    "sent": "Here we want to take our photographs that we took in our last trip.",
                    "label": 0
                },
                {
                    "sent": "This one is a trip to a area from eight years ago I think, and we want to create a collage.",
                    "label": 0
                },
                {
                    "sent": "So we want to get rid of all the redundant pixels in all the images.",
                    "label": 0
                },
                {
                    "sent": "We do that by.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Putting the silence in Maps.",
                    "label": 0
                },
                {
                    "sent": "Now we found all.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important pixels.",
                    "label": 0
                },
                {
                    "sent": "We cut out all of the regions.",
                    "label": 0
                },
                {
                    "sent": "That contain.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the important pixels.",
                    "label": 0
                },
                {
                    "sent": "And then we compose them into a collage like this one.",
                    "label": 0
                },
                {
                    "sent": "So this work this work was presented in Eurographics just a month or two ago.",
                    "label": 0
                },
                {
                    "sent": "So you're welcome to take a look at it.",
                    "label": 0
                },
                {
                    "sent": "The colleges are really nice.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's summarize, I showed you.",
                    "label": 0
                },
                {
                    "sent": "And you definition for saliency?",
                    "label": 0
                },
                {
                    "sent": "The context that were assigned and see which is different from the standard definition for saliency?",
                    "label": 0
                },
                {
                    "sent": "I presented an algorithm which is based on four perceptual principles.",
                    "label": 1
                },
                {
                    "sent": "And finally, I showed you two applications where this is useful.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I hope you like this work and welcome to our poster an to try that.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that you combine the scales and if the objects really salient, it should be salient at all the scales.",
                    "label": 0
                },
                {
                    "sent": "Then why did you use the sum instead of the multiplication?",
                    "label": 0
                },
                {
                    "sent": "We tried this, some seem to work well.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure there was something principled here of trying this thing.",
                    "label": 0
                },
                {
                    "sent": "Maybe the multiplication will work better or as well, I don't know.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that you compute K nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "I'm wondering how quickly you do that.",
                    "label": 0
                },
                {
                    "sent": "We didn't do it quickly at all.",
                    "label": 0
                },
                {
                    "sent": "We did it very, very slowly.",
                    "label": 0
                },
                {
                    "sent": "We computed the distances to all other patches and just took the K nearest ones you could.",
                    "label": 0
                },
                {
                    "sent": "You could use approximate nearest neighbors approaches an actually I just heard from a colleague that her students implemented our work and it runs in real time for them.",
                    "label": 0
                },
                {
                    "sent": "I don't know exactly what they did, but I'm going to talk to them after the conference and see how they do that.",
                    "label": 0
                },
                {
                    "sent": "Other quick question is if you have a bunch of faces in the image.",
                    "label": 0
                },
                {
                    "sent": "Would you pick up all the faces?",
                    "label": 0
                },
                {
                    "sent": "Doubtful because you may get a if you look at the face Patch, you may find a match in another place.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we do have so with faces, usually if you have multiple faces in the same picture, usually we won't have much of a problem.",
                    "label": 0
                },
                {
                    "sent": "I think I showed you there was one here with a guy holding his daughter and there was no problem.",
                    "label": 0
                },
                {
                    "sent": "Both of them were detected.",
                    "label": 0
                },
                {
                    "sent": "Faces for in particular we we run it.",
                    "label": 0
                },
                {
                    "sent": "You should run a face detector, but if we had a different example of an image with objects that repeat, we had the exact identical object in several places in the image.",
                    "label": 0
                },
                {
                    "sent": "This was caused.",
                    "label": 0
                },
                {
                    "sent": "This would cause us trouble, right?",
                    "label": 0
                },
                {
                    "sent": "Have you done the sensitivity studies between?",
                    "label": 0
                },
                {
                    "sent": "Basically some of the key parameters?",
                    "label": 0
                },
                {
                    "sent": "First you mentioned that position wise.",
                    "label": 0
                },
                {
                    "sent": "Basically they have to be close together for salient features versus the basically that I mean how those affect performance.",
                    "label": 0
                },
                {
                    "sent": "I basically some of the basic heuristics are turned into basically parameter settings.",
                    "label": 0
                },
                {
                    "sent": "So so how sensitive are those OK?",
                    "label": 0
                },
                {
                    "sent": "So regarding parameter settings, so in all the examples you saw you saw here in all the experiments we ran on datasets.",
                    "label": 0
                },
                {
                    "sent": "We found that there was a set of parameters that we decided is good and we used it.",
                    "label": 0
                },
                {
                    "sent": "We don't have an extensive parameter evaluation tests, so we chose something and it was fixed for all the hundreds of images that we tried, but we should maybe run more serious tests there.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}