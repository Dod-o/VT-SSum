{
    "id": "2qzq7wvvfvrr6f4gxayyegvav2tprhlg",
    "title": "Bash Datalog: Answering Datalog Queries with Unix Shell Commands",
    "info": {
        "author": [
            "Fabian M. Suchanek, INRIA Saclay - \u00cele-de-France"
        ],
        "published": "Nov. 22, 2018",
        "recorded": "October 2018",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2018_suchanek_bash_datalog/",
    "segmentation": [
        [
            "My name is Tammy and I'm going to talk about answering Della queries with Unix Shell commands, which is in itself a pretty bizarre idea and this is joint work with two of my PhD students, Thomas and Toma.",
            "So suppose you have a key."
        ],
        [
            "So for example, whom did Elvis Presley influence by his music, his lyrics and so on?",
            "So the standard way to answer such query is to take a knowledge base wiki data Yagi pedia.",
            "Any to load that into a triple store."
        ],
        [
            "And then to format it."
        ],
        [
            "Quickly on top and you get the result.",
            "So this works nicely.",
            "The problem is that just loading the data into a triple store is pretty slow also."
        ],
        [
            "Thiago takes a few hours, and with Wikidata can take half a day or even longer.",
            "So if I just have a single query then I will probably not do that.",
            "I would probably just go to the source files, which are like entropies files or TSV files.",
            "I just."
        ],
        [
            "Something in bash, some grippin cut and sort, and I'll get that result.",
            "So that makes sense if you have just a single query.",
            "If you have several queries, then the loading through the database pays off because you're going to be faster in the end, but if you just have a single query then the hacking might just work better.",
            "So what are these cases where it makes sense to just hack it?"
        ],
        [
            "It is useful whenever you just have a single query.",
            "For example, if you want to check whether the knowledge base is useful at all for your purposes.",
            "So rather than loading wiki data for half a day into the triplestore and then finding that it doesn't contain what I'm interested in.",
            "I'd rather first check that before lowering it, or if you want to filter the data you're only interested in a subset of the data.",
            "You wouldn't want to the entire data index it and then remove the data that you're not interested in.",
            "Or if you want to process the data you want to remove the 4th colour pop store or we do have developed the YAGO knowledge base and we often have to debug the knowledge base and then we just want to launch a single query without actually loading the data.",
            "So this is our scenario."
        ],
        [
            "We have a single query in Sparkle or Datalog.",
            "We have data which can be enterprise files or tab separated values, TSV files or text files.",
            "Basically we need anything that is tabular.",
            "And then we want to write a Bash script that answers the query and this is obviously the complicated part, so this."
        ],
        [
            "Paper is concerned with translating a single query into a batch script.",
            "That's the purpose.",
            "So how do we do this?",
            "We've."
        ],
        [
            "Just translate our sparkle free two day to look and why are we doing this?",
            "We do this because Datalog can handle arbitrary arities, so just not just triples or quadruples, but arbitrary number of columns.",
            "And this is a pretty standard translation you see, here is the query.",
            "Select a where Elvis influence plus.",
            "I'm interested in that relative closure, somebody.",
            "Now we're going to make it in today to look at.",
            "Photos were going to print the facts into a fact predicate directly from disk, and then we're going to find the influence predicate recursively.",
            "Will say, X influences Y if X enters Y or if there is an intermediate and then we have the final predicate that just asked for.",
            "Give me all people whom analysts influenced.",
            "In the end, this is the first step."
        ],
        [
            "We're going to.",
            "I know we want to be more specific here.",
            "Our Datalog dialect supports arbitrary Arity, obviously joins the junction selections, projections and unions.",
            "Recursion, as we're seeing here, an stratified negation.",
            "Plus we support arbitrary Unix commands that print into a predicate.",
            "Here we print just the TSV file, which obviously generates a tab separated data stream.",
            "But you can use any other Unix command that produces a tab separated value file.",
            "You can also use enterprise files."
        ],
        [
            "The second step is to translate this deadlock program into a into a relational algebra tree, and we do this because we can optimize the tree more easily than we can optimize the program.",
            "So in this example, the tree has three components, one is the recursion start, which basically computes who influenced whom.",
            "And then we have a recurrence step which tries to add 1 hop and do the transitive closure of this of this procedure and then the blue one says OK and none of this translator.",
            "Please give me just those people whoever is influenced and you see that this is pretty inefficient calculation because rather than first computing the entire trend of closure and then selecting only the ones with ever you would rather first selectable service and then do the hops and we can do this optimization automatically."
        ],
        [
            "So we have.",
            "And enter optimizer that pushes down the selections.",
            "And you see this here in purple.",
            "So the purple part selects all facts that go with the subject.",
            "An object that go with the influence relationship.",
            "And the green part here starts, bootstraps the recursion directly, only with the facts where the subject is Elvis and the relationship is influenced.",
            "And this is how we optimize it.",
            "So just to explain the parts, the green part does the first hop in the in the knowledge base and then comes the purple part which does one up in the influence relationship.",
            "And then you have the red part, which adds the remaining, which as the transit pump.",
            "Basically there is one more thing that you can optimize here.",
            "This purple part here.",
            "We just select one hop from the from.",
            "The data is executed every time in every single iteration of the recursion, so that's not efficient.",
            "So we're going to outsource that, and we're going to put that."
        ],
        [
            "Into a materialization node, so we're going to compute it once up front, and then we're going to reuse that as an intermediate result in our.",
            "Recursion and our optimizer does these things automatically.",
            "Figures out which parts to outsource and to preprocess.",
            "So this leads us to the last step, which is that."
        ],
        [
            "Translation of the Algebra Tree, two Bash and let's start with something simple.",
            "This part here runs basically through the file and select all lines where the subject is Elvis and the predicate is influence and then it just projects on the third line on 3rd column on the object.",
            "This works with a simple or command.",
            "Ark is a small Unix utility.",
            "That is.",
            "Fantastic for these types of purposes.",
            "Now you may say OK, why don't you just program everything in awe kitfox so cool and the reason is that arc works in memory an we will encounter data that doesn't fit in memory, so we cannot just program everything in Ark, but these things where we run linearly through a file that works great in log.",
            "Same thing here."
        ],
        [
            "On the right, inside this precomputation of finding the one hop in the data.",
            "This can be done in AWK.",
            "And now comes the trick.",
            "We want to reuse this part that's being done here in the join later, so this is a preprocessing step and we do this by piping."
        ],
        [
            "It's basically into a fire and then using that file in our later join here and we want to do this in parallel, so we're going to do is we want to start many processes in parallel and then use the data as it arrives.",
            "The problem here is that if the joint starts before this preprocessing is done, then the joint will be incomplete.",
            "So what we do in order to prevent this is we create a log."
        ],
        [
            "Which is basically a named pipe and then this lock is basically is a Piper.",
            "There is no data.",
            "And then before doing the join we read from that lock.",
            "And so that this cat command just blocks because there's no data in parallel.",
            "This means in parallel we execute the preprocessing part and then once that's done we free the lock, which is a pain in Unix.",
            "But this is the way it goes.",
            "It's these three commands.",
            "And once that's done, this runs in parallel.",
            "Then the cat command will see, oh, there is no more data, it quits, and then the joint starts.",
            "So this is how we launch server process in parallel.",
            "Each process waits for the respective other ones to finish."
        ],
        [
            "So let's talk about the recursion.",
            "We have basically the first recursion step, which is the green part.",
            "Selecting the people whom Elvis influence directly, and then we're going to have a loop here a while loop and each while loop is just going to add one more hop, so the green part is.",
            "Whom did Elvis influence then we do in blue one more hop who made their influence again and we have new renew people who were transitively influenced and from these will remove the ones we already had.",
            "So we compute the Delta, the difference and then we see only if there are really new people.",
            "Then we continue with the loop and this loop will eventually terminate cause we have only stratified negation.",
            "Absolutely this works.",
            "Cool so here."
        ],
        [
            "Our our experiments.",
            "We connect experience with four types of systems, Datalog based systems that deal Visa play, Aria Fox and Big Datalog, Triplestores, Janus startup Virtuoso database management systems wanted to be an Postgres an others RDF slice which is not strictly a triple store and know deep.",
            "So in all of these experiments we're going to count we're going to measure also the time that these are projects need to load the data, so I'd say that's unfair, right?",
            "I mean, why do you measure the time, then load the data?",
            "Because once you noted the data and the subsequent crews will be faster.",
            "And that's totally true.",
            "And so remember that our scenario is that we just have a single query.",
            "If we have a single query, then you need to count the loading time.",
            "Once you have several queries, just don't use our system, so we are in a case where you just have one single query.",
            "So."
        ],
        [
            "Here are the numbers you see that some lines are dashed, which means that these systems cannot answer all queries.",
            "So for example, Postgres doesn't support all types of recursions, and virtuoso does not support the full Sparkle subset that we needed, so they don't answer all queries and then you see this the runtime here and you see that best dialogue is fast.",
            "It is on this graph the fastest, but we don't actually claim that we are always there.",
            "Caste system because there could be other systems and maybe there's some people in the audience who knows system that's faster, an that's all.",
            "Granted our main point here is to say we are competitive with the state of the art.",
            "Now we are maybe not here in this example the fastest, but we're at least compatible.",
            "Yeah, yeah we are competitive with the state of the art.",
            "That's not everything.",
            "There's something more the."
        ],
        [
            "Scaling actually, so our system scales to large datasets.",
            "So here you have four datasets.",
            "Live Journal orchid fencer wiki data.",
            "And you see that RDF box is always the fastest system and this is because RDF box loads the entire data memory and is there super fast and answering curse increase.",
            "The problem is if the data does not fit into the main memory then are the folks cannot answer any query even if the query is simple it just cannot load the data.",
            "It doesn't do anything.",
            "And so are the Xbox runs out of memory.",
            "Big Data lock run, I mean is already pretty slow anyway and then ran out of space.",
            "An Stardock was just too slow.",
            "So we abortive.",
            "Where is Bash runs pretty decent in terms of minutes.",
            "Here it takes 4 hours, which is still long here.",
            "It takes an hour, which is still decent compared to the other approaches, so one of the reasons why we scale so well we believe is that Unix, the Unix actually optimized for running several small processes that are IO intensive in parallel.",
            "And this is exactly what we were doing, so we're heavily relying on the optimization.",
            "The operating system actually does for us.",
            "But this is not even the coolest part, so it's not just as fast as scalable.",
            "The coolest part."
        ],
        [
            "Is that you do not need any software, so in order to use our system you just go to that web page and you enter your sparkle query and click convert to Bash script.",
            "Then you get back script you copy, paste that into a terminal and you trust us a lot and then.",
            "Then you're going to get the results.",
            "Yeah, so that's really the key point of this.",
            "You can also use this in develop mode, and we have an API that you can use with curve from the command line directly.",
            "So that can."
        ],
        [
            "In my talk I presented approach that translates deadlock or spark queries directly to bash.",
            "This is competitive if you have just a single query.",
            "This is our setting just one single query, then it's competitive in terms of speed with the state of the art, it scales for large datasets better than many of our competitors.",
            "Plus it doesn't need any installation of software.",
            "You just need a Unix bash shell and if you want to know how many people were influenced by Elvis on yoga, that's 12 people and the query took six minutes.",
            "And with this I would like to thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Tammy and I'm going to talk about answering Della queries with Unix Shell commands, which is in itself a pretty bizarre idea and this is joint work with two of my PhD students, Thomas and Toma.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have a key.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, whom did Elvis Presley influence by his music, his lyrics and so on?",
                    "label": 0
                },
                {
                    "sent": "So the standard way to answer such query is to take a knowledge base wiki data Yagi pedia.",
                    "label": 0
                },
                {
                    "sent": "Any to load that into a triple store.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then to format it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quickly on top and you get the result.",
                    "label": 0
                },
                {
                    "sent": "So this works nicely.",
                    "label": 0
                },
                {
                    "sent": "The problem is that just loading the data into a triple store is pretty slow also.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thiago takes a few hours, and with Wikidata can take half a day or even longer.",
                    "label": 0
                },
                {
                    "sent": "So if I just have a single query then I will probably not do that.",
                    "label": 0
                },
                {
                    "sent": "I would probably just go to the source files, which are like entropies files or TSV files.",
                    "label": 0
                },
                {
                    "sent": "I just.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something in bash, some grippin cut and sort, and I'll get that result.",
                    "label": 0
                },
                {
                    "sent": "So that makes sense if you have just a single query.",
                    "label": 0
                },
                {
                    "sent": "If you have several queries, then the loading through the database pays off because you're going to be faster in the end, but if you just have a single query then the hacking might just work better.",
                    "label": 0
                },
                {
                    "sent": "So what are these cases where it makes sense to just hack it?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is useful whenever you just have a single query.",
                    "label": 0
                },
                {
                    "sent": "For example, if you want to check whether the knowledge base is useful at all for your purposes.",
                    "label": 0
                },
                {
                    "sent": "So rather than loading wiki data for half a day into the triplestore and then finding that it doesn't contain what I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "I'd rather first check that before lowering it, or if you want to filter the data you're only interested in a subset of the data.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't want to the entire data index it and then remove the data that you're not interested in.",
                    "label": 0
                },
                {
                    "sent": "Or if you want to process the data you want to remove the 4th colour pop store or we do have developed the YAGO knowledge base and we often have to debug the knowledge base and then we just want to launch a single query without actually loading the data.",
                    "label": 0
                },
                {
                    "sent": "So this is our scenario.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a single query in Sparkle or Datalog.",
                    "label": 0
                },
                {
                    "sent": "We have data which can be enterprise files or tab separated values, TSV files or text files.",
                    "label": 0
                },
                {
                    "sent": "Basically we need anything that is tabular.",
                    "label": 0
                },
                {
                    "sent": "And then we want to write a Bash script that answers the query and this is obviously the complicated part, so this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper is concerned with translating a single query into a batch script.",
                    "label": 0
                },
                {
                    "sent": "That's the purpose.",
                    "label": 0
                },
                {
                    "sent": "So how do we do this?",
                    "label": 0
                },
                {
                    "sent": "We've.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just translate our sparkle free two day to look and why are we doing this?",
                    "label": 0
                },
                {
                    "sent": "We do this because Datalog can handle arbitrary arities, so just not just triples or quadruples, but arbitrary number of columns.",
                    "label": 0
                },
                {
                    "sent": "And this is a pretty standard translation you see, here is the query.",
                    "label": 0
                },
                {
                    "sent": "Select a where Elvis influence plus.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in that relative closure, somebody.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to make it in today to look at.",
                    "label": 0
                },
                {
                    "sent": "Photos were going to print the facts into a fact predicate directly from disk, and then we're going to find the influence predicate recursively.",
                    "label": 0
                },
                {
                    "sent": "Will say, X influences Y if X enters Y or if there is an intermediate and then we have the final predicate that just asked for.",
                    "label": 0
                },
                {
                    "sent": "Give me all people whom analysts influenced.",
                    "label": 0
                },
                {
                    "sent": "In the end, this is the first step.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going to.",
                    "label": 0
                },
                {
                    "sent": "I know we want to be more specific here.",
                    "label": 0
                },
                {
                    "sent": "Our Datalog dialect supports arbitrary Arity, obviously joins the junction selections, projections and unions.",
                    "label": 0
                },
                {
                    "sent": "Recursion, as we're seeing here, an stratified negation.",
                    "label": 0
                },
                {
                    "sent": "Plus we support arbitrary Unix commands that print into a predicate.",
                    "label": 0
                },
                {
                    "sent": "Here we print just the TSV file, which obviously generates a tab separated data stream.",
                    "label": 0
                },
                {
                    "sent": "But you can use any other Unix command that produces a tab separated value file.",
                    "label": 0
                },
                {
                    "sent": "You can also use enterprise files.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second step is to translate this deadlock program into a into a relational algebra tree, and we do this because we can optimize the tree more easily than we can optimize the program.",
                    "label": 0
                },
                {
                    "sent": "So in this example, the tree has three components, one is the recursion start, which basically computes who influenced whom.",
                    "label": 1
                },
                {
                    "sent": "And then we have a recurrence step which tries to add 1 hop and do the transitive closure of this of this procedure and then the blue one says OK and none of this translator.",
                    "label": 0
                },
                {
                    "sent": "Please give me just those people whoever is influenced and you see that this is pretty inefficient calculation because rather than first computing the entire trend of closure and then selecting only the ones with ever you would rather first selectable service and then do the hops and we can do this optimization automatically.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "And enter optimizer that pushes down the selections.",
                    "label": 0
                },
                {
                    "sent": "And you see this here in purple.",
                    "label": 0
                },
                {
                    "sent": "So the purple part selects all facts that go with the subject.",
                    "label": 0
                },
                {
                    "sent": "An object that go with the influence relationship.",
                    "label": 0
                },
                {
                    "sent": "And the green part here starts, bootstraps the recursion directly, only with the facts where the subject is Elvis and the relationship is influenced.",
                    "label": 0
                },
                {
                    "sent": "And this is how we optimize it.",
                    "label": 0
                },
                {
                    "sent": "So just to explain the parts, the green part does the first hop in the in the knowledge base and then comes the purple part which does one up in the influence relationship.",
                    "label": 0
                },
                {
                    "sent": "And then you have the red part, which adds the remaining, which as the transit pump.",
                    "label": 0
                },
                {
                    "sent": "Basically there is one more thing that you can optimize here.",
                    "label": 0
                },
                {
                    "sent": "This purple part here.",
                    "label": 0
                },
                {
                    "sent": "We just select one hop from the from.",
                    "label": 0
                },
                {
                    "sent": "The data is executed every time in every single iteration of the recursion, so that's not efficient.",
                    "label": 0
                },
                {
                    "sent": "So we're going to outsource that, and we're going to put that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into a materialization node, so we're going to compute it once up front, and then we're going to reuse that as an intermediate result in our.",
                    "label": 0
                },
                {
                    "sent": "Recursion and our optimizer does these things automatically.",
                    "label": 0
                },
                {
                    "sent": "Figures out which parts to outsource and to preprocess.",
                    "label": 0
                },
                {
                    "sent": "So this leads us to the last step, which is that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Translation of the Algebra Tree, two Bash and let's start with something simple.",
                    "label": 0
                },
                {
                    "sent": "This part here runs basically through the file and select all lines where the subject is Elvis and the predicate is influence and then it just projects on the third line on 3rd column on the object.",
                    "label": 0
                },
                {
                    "sent": "This works with a simple or command.",
                    "label": 0
                },
                {
                    "sent": "Ark is a small Unix utility.",
                    "label": 0
                },
                {
                    "sent": "That is.",
                    "label": 0
                },
                {
                    "sent": "Fantastic for these types of purposes.",
                    "label": 0
                },
                {
                    "sent": "Now you may say OK, why don't you just program everything in awe kitfox so cool and the reason is that arc works in memory an we will encounter data that doesn't fit in memory, so we cannot just program everything in Ark, but these things where we run linearly through a file that works great in log.",
                    "label": 0
                },
                {
                    "sent": "Same thing here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the right, inside this precomputation of finding the one hop in the data.",
                    "label": 0
                },
                {
                    "sent": "This can be done in AWK.",
                    "label": 0
                },
                {
                    "sent": "And now comes the trick.",
                    "label": 0
                },
                {
                    "sent": "We want to reuse this part that's being done here in the join later, so this is a preprocessing step and we do this by piping.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's basically into a fire and then using that file in our later join here and we want to do this in parallel, so we're going to do is we want to start many processes in parallel and then use the data as it arrives.",
                    "label": 0
                },
                {
                    "sent": "The problem here is that if the joint starts before this preprocessing is done, then the joint will be incomplete.",
                    "label": 0
                },
                {
                    "sent": "So what we do in order to prevent this is we create a log.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is basically a named pipe and then this lock is basically is a Piper.",
                    "label": 0
                },
                {
                    "sent": "There is no data.",
                    "label": 0
                },
                {
                    "sent": "And then before doing the join we read from that lock.",
                    "label": 0
                },
                {
                    "sent": "And so that this cat command just blocks because there's no data in parallel.",
                    "label": 0
                },
                {
                    "sent": "This means in parallel we execute the preprocessing part and then once that's done we free the lock, which is a pain in Unix.",
                    "label": 0
                },
                {
                    "sent": "But this is the way it goes.",
                    "label": 0
                },
                {
                    "sent": "It's these three commands.",
                    "label": 0
                },
                {
                    "sent": "And once that's done, this runs in parallel.",
                    "label": 0
                },
                {
                    "sent": "Then the cat command will see, oh, there is no more data, it quits, and then the joint starts.",
                    "label": 0
                },
                {
                    "sent": "So this is how we launch server process in parallel.",
                    "label": 0
                },
                {
                    "sent": "Each process waits for the respective other ones to finish.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's talk about the recursion.",
                    "label": 0
                },
                {
                    "sent": "We have basically the first recursion step, which is the green part.",
                    "label": 0
                },
                {
                    "sent": "Selecting the people whom Elvis influence directly, and then we're going to have a loop here a while loop and each while loop is just going to add one more hop, so the green part is.",
                    "label": 0
                },
                {
                    "sent": "Whom did Elvis influence then we do in blue one more hop who made their influence again and we have new renew people who were transitively influenced and from these will remove the ones we already had.",
                    "label": 0
                },
                {
                    "sent": "So we compute the Delta, the difference and then we see only if there are really new people.",
                    "label": 0
                },
                {
                    "sent": "Then we continue with the loop and this loop will eventually terminate cause we have only stratified negation.",
                    "label": 0
                },
                {
                    "sent": "Absolutely this works.",
                    "label": 0
                },
                {
                    "sent": "Cool so here.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our our experiments.",
                    "label": 0
                },
                {
                    "sent": "We connect experience with four types of systems, Datalog based systems that deal Visa play, Aria Fox and Big Datalog, Triplestores, Janus startup Virtuoso database management systems wanted to be an Postgres an others RDF slice which is not strictly a triple store and know deep.",
                    "label": 0
                },
                {
                    "sent": "So in all of these experiments we're going to count we're going to measure also the time that these are projects need to load the data, so I'd say that's unfair, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, why do you measure the time, then load the data?",
                    "label": 0
                },
                {
                    "sent": "Because once you noted the data and the subsequent crews will be faster.",
                    "label": 0
                },
                {
                    "sent": "And that's totally true.",
                    "label": 0
                },
                {
                    "sent": "And so remember that our scenario is that we just have a single query.",
                    "label": 0
                },
                {
                    "sent": "If we have a single query, then you need to count the loading time.",
                    "label": 0
                },
                {
                    "sent": "Once you have several queries, just don't use our system, so we are in a case where you just have one single query.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are the numbers you see that some lines are dashed, which means that these systems cannot answer all queries.",
                    "label": 0
                },
                {
                    "sent": "So for example, Postgres doesn't support all types of recursions, and virtuoso does not support the full Sparkle subset that we needed, so they don't answer all queries and then you see this the runtime here and you see that best dialogue is fast.",
                    "label": 0
                },
                {
                    "sent": "It is on this graph the fastest, but we don't actually claim that we are always there.",
                    "label": 0
                },
                {
                    "sent": "Caste system because there could be other systems and maybe there's some people in the audience who knows system that's faster, an that's all.",
                    "label": 0
                },
                {
                    "sent": "Granted our main point here is to say we are competitive with the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Now we are maybe not here in this example the fastest, but we're at least compatible.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah we are competitive with the state of the art.",
                    "label": 0
                },
                {
                    "sent": "That's not everything.",
                    "label": 0
                },
                {
                    "sent": "There's something more the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scaling actually, so our system scales to large datasets.",
                    "label": 0
                },
                {
                    "sent": "So here you have four datasets.",
                    "label": 0
                },
                {
                    "sent": "Live Journal orchid fencer wiki data.",
                    "label": 0
                },
                {
                    "sent": "And you see that RDF box is always the fastest system and this is because RDF box loads the entire data memory and is there super fast and answering curse increase.",
                    "label": 0
                },
                {
                    "sent": "The problem is if the data does not fit into the main memory then are the folks cannot answer any query even if the query is simple it just cannot load the data.",
                    "label": 0
                },
                {
                    "sent": "It doesn't do anything.",
                    "label": 0
                },
                {
                    "sent": "And so are the Xbox runs out of memory.",
                    "label": 0
                },
                {
                    "sent": "Big Data lock run, I mean is already pretty slow anyway and then ran out of space.",
                    "label": 0
                },
                {
                    "sent": "An Stardock was just too slow.",
                    "label": 0
                },
                {
                    "sent": "So we abortive.",
                    "label": 0
                },
                {
                    "sent": "Where is Bash runs pretty decent in terms of minutes.",
                    "label": 0
                },
                {
                    "sent": "Here it takes 4 hours, which is still long here.",
                    "label": 0
                },
                {
                    "sent": "It takes an hour, which is still decent compared to the other approaches, so one of the reasons why we scale so well we believe is that Unix, the Unix actually optimized for running several small processes that are IO intensive in parallel.",
                    "label": 0
                },
                {
                    "sent": "And this is exactly what we were doing, so we're heavily relying on the optimization.",
                    "label": 0
                },
                {
                    "sent": "The operating system actually does for us.",
                    "label": 0
                },
                {
                    "sent": "But this is not even the coolest part, so it's not just as fast as scalable.",
                    "label": 0
                },
                {
                    "sent": "The coolest part.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that you do not need any software, so in order to use our system you just go to that web page and you enter your sparkle query and click convert to Bash script.",
                    "label": 0
                },
                {
                    "sent": "Then you get back script you copy, paste that into a terminal and you trust us a lot and then.",
                    "label": 0
                },
                {
                    "sent": "Then you're going to get the results.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's really the key point of this.",
                    "label": 0
                },
                {
                    "sent": "You can also use this in develop mode, and we have an API that you can use with curve from the command line directly.",
                    "label": 0
                },
                {
                    "sent": "So that can.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In my talk I presented approach that translates deadlock or spark queries directly to bash.",
                    "label": 0
                },
                {
                    "sent": "This is competitive if you have just a single query.",
                    "label": 0
                },
                {
                    "sent": "This is our setting just one single query, then it's competitive in terms of speed with the state of the art, it scales for large datasets better than many of our competitors.",
                    "label": 0
                },
                {
                    "sent": "Plus it doesn't need any installation of software.",
                    "label": 0
                },
                {
                    "sent": "You just need a Unix bash shell and if you want to know how many people were influenced by Elvis on yoga, that's 12 people and the query took six minutes.",
                    "label": 0
                },
                {
                    "sent": "And with this I would like to thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}