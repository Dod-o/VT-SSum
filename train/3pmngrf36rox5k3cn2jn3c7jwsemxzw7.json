{
    "id": "3pmngrf36rox5k3cn2jn3c7jwsemxzw7",
    "title": "Rule-Based Active Sampling for Learning to Rank",
    "info": {
        "produced by": [
            "Data & Web Mining Lab"
        ],
        "author": [
            "Rodrigo Silva, Federal University of Minas Gerais"
        ],
        "published": "Nov. 30, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_silva_rank/",
    "segmentation": [
        [
            "Good morning.",
            "He's a red regal.",
            "We're going to be presenting.",
            "Where is the?",
            "Also just use mine.",
            "So we're going to be presenting a work on.",
            "Model active sampling algorithm for learning to rank which is based on Association rules so."
        ],
        [
            "Start giving him outline.",
            "We're going to talk briefly about.",
            "The reasons for active sampling in this specific realm I'm going to explain how we use a rule based supervised over it.",
            "How we use an Association rule based algorithm.",
            "So actually do learning to rank on a supervised manner using a full training set.",
            "And from that I'm going to extend that algorithm.",
            "Use a simple idea to extend that and.",
            "Be able to use active sampling to select specific instances and reduce my training settings.",
            "Have a smaller smaller training set.",
            "So that it's easier to apply it to real life incident situations.",
            "And finally, I'm going to talk about some results and a small discussion about it."
        ],
        [
            "So learning to rank a as being as we said before, it's used for many things, especially the documents word.",
            "But you can use it for many different in many different applications and as we all know, train sets are always difficult to get an it's very expensive to produce them.",
            "Especially sometimes in learning to rank.",
            "It's even harder because sometimes depending on the kind of lowering use, you have to not only label documents as relevant or not relevant that you were given query, but you can also sometimes have to do listwise ranking of documents.",
            "We can't give you have to annotate or sometimes sometimes has to actually give an order to the results pending on the type of algorithm you're using, so.",
            "It's pretty expensive to do that, and it's really hard to get those training staff.",
            "So can we use very small training sets, or can we produce very small training sets that are very informative?",
            "Very good for that for the learning task.",
            "So can we produce very good results using just a small amount of documents?",
            "So.",
            "If we do that, if we can select very specific examples of documents, there are very informative to the algorithm.",
            "Does that prove maybe even improve your results?",
            "If you're just using?",
            "If you are playing some noise in the training data?",
            "So that's the kind of answers were talking about.",
            "We're trying to get here.",
            "So we are also looking for because there are some previous work on active active sampling, active learning for learning to rank, which usually need an initial labeled set seed set as we call it that is used to train an initial learner and then from that you interactively build new, bring new new new examples into the to the learner and update it.",
            "Can we do that without the seats at?",
            "Because we want to do it in a way that we can lag over it and very very fast without being too actually go there and have some initial trainings.",
            "So this is the motivation."
        ],
        [
            "For this work, and 1st, I'm going to be talking about how you do learning to rank using this Association rules.",
            "Right now I'm talking about supervised regular supervised algorithm, right?",
            "So I do have a training set composed of a query and a document, an relevance level.",
            "The document is composed of feature values which are usually different information about the document or about the.",
            "Where in the document we repair.",
            "Because for learning to rank the usually what you get is what you have is you have a query so your training set has a query and that's this query generates a bunch of.",
            "Retrieve from some some data data set like a.",
            "You retrieve the documents that are relevant using some information retrieval technique, and then you label it so you're training your training set is basically a document.",
            "Features related to a document, but that document is in response to a query right?",
            "So that we have all these different values.",
            "Usually real values associated to the document and then you have relevance levels that could be like in a kind of.",
            "Is a binary binary relevance strange that you have just not relevant, relevant, but you can also have like not relevant to little bit level relevant, more level credit card so you could have.",
            "Several levels of relevance for that specific documents in that query and your test set is composed of the same thing, but you don't have the relevance anyway.",
            "You want to somehow discover that you have to.",
            "You want to rank those documents on the test set.",
            "According to the article then, to learn function in the training set.",
            "So what we use is.",
            "We want to use.",
            "Association rules to derives Association rules from the training set.",
            "Over the course of this form, so we basically looking at features that indicate some relevance.",
            "So we produce rules and you have a confidence level of these rules is better here.",
            "And.",
            "Was from the training set.",
            "You could just generate a huge amount of rules, right?",
            "You could just."
        ],
        [
            "Doing that in offline, you're basically if you're building a ruleset from huge training set, then you could generate possibly millions or billions of holes, so that's not very practical.",
            "One way of avoiding this explosion of rules of Member of rules would be to stab Lish.",
            "Some support for threshold where you say OK, I just I just want rules if they are frequent enough so you stab Lish, a Sigma min value, and you say OK.",
            "If the rule appears only once in for this whole data set, then I don't want it.",
            "I want rules that are appear with some frequency so.",
            "This is 1 possible solution for.",
            "For doing this for solving this explosion of rules problem.",
            "But then again, if you said this too low, you still have too many rules, and if you set it too high, maybe you're going to miss very important rules that would allow you to derive relevance or rank the documents from the same formula test set.",
            "Using this rule set that he created.",
            "So instead of doing that, why not do a lazy approach where you do on-demand rule expression and technically query time.",
            "So we're talking about here is given a query in the test set, I look at the query, I retrieve all the documents.",
            "From the test had related to that query and then for each of those documents I actually create a projected training set.",
            "So I basically eliminate from the training set everything that doesn't have any relation to those options.",
            "That specific document that I'm looking at right now because the rules are only useful if the feature values of those rules.",
            "The appear in that in this document specifically, they're only useful for that specific document.",
            "They appear in the document, it doesn't.",
            "Take me anywhere if I if I'm looking at a feature value.",
            "This doesn't doesn't tell me anything about that document.",
            "So what I do is I project at query time.",
            "I project this training set and eliminate everything that is not useful.",
            "So generate rules for that specific document and then I generate a specific rule set for that document.",
            "In the test app and now I can.",
            "Only produce I guarantee to produce only very useful rules for classifying for ranking that document.",
            "So how do I go?"
        ],
        [
            "About ranking it.",
            "Basically what we do is that we consider that each rule that we extracted from this art that we generate into this RRD sets of rules for that document.",
            "Remember that this is specific for that document query time, so each rules of Bolt to a given relevance level so.",
            "Operating right on a little bit of a problem so.",
            "In each vote has a weight which is the confidence right?",
            "So.",
            "Based.",
            "When I have this rule set now, I can what I can do for that specific document is to specify score that is normalized.",
            "Basically that this data, which is nice, my confidence on that on that rule.",
            "Which is the conditional probability right?",
            "That rules that specific role indicated that relevance level.",
            "I can just sum it up and then divide it by the all the rules in that rule set for that document that have.",
            "This specific.",
            "Relevance level, so I I had this this core and then I normalize the support for all the different.",
            "Different relevance levels and basically my ranking for the final ranking function function, so I'm basically assigning a number to this document saying OK.",
            "This is the ranking value of this document and later on after I do all the documents.",
            "Basically what I want to do is just order those documents by the ranking function ranking value right?",
            "So it's a pointwise ranking function and.",
            "Basically, I do a linear combination of this of this values of this.",
            "This likelihoods the relevance right.",
            "Likelihoods for documents and what I have is a ranking Faneuil pointwise ranking better for that number so."
        ],
        [
            "Let's say this is."
        ],
        [
            "The.",
            "The supervised algorithm.",
            "So here I'm considering that I have a training set and so I get a new document from the query time I filter out by my training set.",
            "I produce rules for that specific document and then I come up with this ranking value for that document in relation to that query so."
        ],
        [
            "What if I want to build?",
            "I want to use this to build a training set.",
            "I don't have a training set.",
            "I have an unlabeled set containing unlabeled documents.",
            "And what I want to do now is to use some things related to this to this.",
            "Supervised algorithm using Association rules to pick out the documents that I want to label.",
            "So I'm going to pick one document at a time and then I'm going to label it and eventually this is going to become my training set.",
            "An is a very small training set and it's, I hope very, very effective.",
            "So how do we do that?",
            "We have this unlabeled set.",
            "And then what I look at is.",
            "Let's say I have.",
            "Some train set.",
            "I have like some 10 or 10 documents in my training set right now, so I'm in the middle of the process of doing this.",
            "So if I'm going to start one new document into the set, I'm going to those rules from the stand documents and I'm going to look into my unlabeled set because I'm I'm taking one one document from the label set and then I'm producing the rules.",
            "And then what is going to happen is that this this UI document that I'm just inserting?",
            "Into the training set, which is the small training set right now.",
            "When I do that, the number of rules that share features with with, so the documents that remain in you the documents in you.",
            "These the number of rules that I can extract from my training set.",
            "Right now they they will increase only for those documents that is still in you that contain that share feature vectors with this document specifically.",
            "And obviously, for the darkness that do not share any values, the number of rules will not change because.",
            "I only produce rules for that app, and if there is a sharing features because I filter out the whole the whole training set before I do that so.",
            "What we're getting at is that the number of rules extracted for a document.",
            "So once I get a document and I look at it and I filter all of my training set, my small training set, the number of rules is an indication of how many documents that are similar to that document that I'm looking at that I already have into my training set.",
            "So if I have a lot of rules, then I have a lot of documents that are similar.",
            "If I have fewer rules than that document is very different from the document that already having the same sense.",
            "So what I'm what I want to do is.",
            "Basically.",
            "I have what we what we wanted, what we think is that.",
            "The diversity of the documents in the training set is essentially if you want to build a very small training set, then you have to have very different documents.",
            "There are very diverse so that those will form a training set.",
            "It is useful to rank.",
            "Test set up very good because they have different characteristics.",
            "They are very bad diverse.",
            "So what we're doing is basically our grading is selecting from you or then label set all the documents that demand the fewer rules from my current training set.",
            "So I do that interacts with interactively, every at every round.",
            "Decide which of the documents in you is the most interesting and I put it into into the into my training set, and then I label it, and then I do it again.",
            "So I I I iterate over that and so I have a training set and."
        ],
        [
            "Basically, the sampling function that I'm getting at here is that.",
            "I'm looking for the document which has this, which produces the smaller the smallest.",
            "Rules out right so.",
            "So of course, initially my my training set is empty.",
            "I can do that once I can generate rules.",
            "I can't generate rules if I don't have any documents in the training set.",
            "So to do that what we do is that the first document that is selected.",
            "So if I have an empty training set, I basically go there and pick the document that shares the most feature values with all the other documents into the unlabeled set.",
            "So basically I'm looking for a very representative document because that's the guy that's going to give me more rules for the following for the next rounds of the algorithm.",
            "So once I select this first document, then I start using this this sampling function where I'm basically looking for the documents that produced the fewer loop rules from my current training set and inserting it."
        ],
        [
            "So.",
            "We tried we.",
            "Ransom experience using the liter data sets that 3.0 and I'm here I'm showing the mean average precision for the supervised algorithm, which is the algorithm using the full training sets.",
            "So this is the size of the training set.",
            "This is the amount of instances of documents that were selected by our.",
            "Algorithm, and this is the percentage of the size of what was selected, and this is the mean average precision and we can see that here that although it fares pretty well in a couple of very specific data sets which are these name pages and home pages at datasets, you can see that goes pretty well in a couple of those.",
            "It's not very good in general, but it's selecting very few very few instances.",
            "So."
        ],
        [
            "How can we improve that?",
            "How can we select more?",
            "We need to?",
            "Because they were in ultimate.",
            "Verges whilst it's Alexa document is already selected, so it basically does this process until it gets a point where it tries to select the document that's already in the training set.",
            "So how do we fill a discover gence we basically?",
            "Partitioning we basically partitioned the unlabeled set, which is.",
            "Composed of several features and we vertically partitioned it.",
            "Separating groups of features.",
            "And the reason why we want to do that is because we want to select partitions based on select documents based on different.",
            "Groups of partitions of features.",
            "And basically we're setting up.",
            "We experimentally defined reached the number of partitions saying that OK 8 to 12 features per partitions is a good balance on 4.",
            "In general, and it's this is valid for all data sets that we we tried, we use, but we only.",
            "So basically, we're working with five partitions for this data set.",
            "I'm going to show the results in a moment.",
            "So what we do is we select the.",
            "We look at the features 1st and then we try to rank the features such that we know reach are the most informative features we want to put informative features into each partition.",
            "Because we want the algorithm to select informative examples from from the different partitions for different reasons.",
            "Because they're using different features.",
            "So we basically using the key squared to evaluate and rank the features in relation to each other.",
            "We are using that to eventually spread the most informative partition features into each of the partitions in such a way that we always have some informative feature."
        ],
        [
            "And we get from that using five partitions for all these datasets, which are which have 64 features.",
            "The lift or 3.0 datasets.",
            "We have basically 12 features per partition and here we are.",
            "We can see that we select a more reasonable amount of the original set, so we're basically using two point 18% of the of this specific data set.",
            "The original training set, which are we are using as the labels have to select from and we are obtaining very good results for basically all those datasets.",
            "This is again the supervised algorithm with the whole training set.",
            "And this is the active sampling algorithm."
        ],
        [
            "So."
        ],
        [
            "Just 4 four.",
            "For reference, we compare those with established baselines, algorithms of their work, published by the Little 3.0 publishers.",
            "So this this is rank boost Anne Frank and regression.",
            "There are like 12 different baselines that are published by the letter of producers, and we're here.",
            "We're just comparing to show that our algorithm using that's very, very small amount of regional training sets."
        ],
        [
            "As you can see here.",
            "So 1.1, two 2.2."
        ],
        [
            "They they fare pretty well and even better than these algorithms which are using the full training center.",
            "These are supervised algorithm algorithms using the."
        ],
        [
            "Incense.",
            "So this work is different from previous work in the sense that there's some active learning frameworks for learning to rank, and most of 'em.",
            "First personal, they depend on using an initial labeled SESAC so you need to have a train and initial training set which would we don't need here because we are producing this set from scratch and.",
            "Also these words.",
            "They usually they use from 11 to 15% of the original sets to obtain similar results.",
            "We're using from one 1%, so it's a percent.",
            "So basically that's it."
        ],
        [
            "Do we have the next speaker?",
            "I don't think so.",
            "There was an announcement."
        ],
        [
            "Decisions stop that.",
            "There were basically no sections one in the system, so probably the last 26.",
            "Sorry for pressing.",
            "That's OK, that's OK. Just do this.",
            "Fighting is alone.",
            "Short any questions.",
            "From, from what I understood, your maker criterion for selecting examples is diversity.",
            "So yeah, my question is OK, sure, intuitively makes sense.",
            "Select the diverse training set, but do you have any, say theoretical reasons or justifications for doing that and question related to this is if you are only looking at diversity.",
            "In principle, this intermediate step of mining Association rules and principles not really necessary, right?",
            "I mean, you could just compare the document descriptions and then also compute the area kind of diversity measures, yeah?",
            "Well, they're there.",
            "There are a couple of words talking about diversity.",
            "Batman diversity in this collections.",
            "There is no theoretical work on how that influences brain.",
            "Not that I'm aware of.",
            "We did not develop a theoretical theoretical framework for that.",
            "To explain why it is their version is good.",
            "It's all.",
            "It's only an intuition and it's somehow.",
            "Experimentally, we see that that is the case and the other words that I know.",
            "Also, talk about experience of experimentally defining that some diversity and.",
            "In the document collection is always good for learning algorithm, Ranger ankle rhythms.",
            "For for how why we do the rule?",
            "The rule is cell that the rule that you could in principle yes just select use a simpler way to determine what is a diverse document based on what you have like you could just look at the features and try to establish that, but the rules are useful way of doing that because we're already using the rules anyways to actually do their ranking.",
            "You can.",
            "To do the actual ranking because it's a two step process here you're selecting your data, set your training set, and then you're actually.",
            "Using it on a test set for one query time, right?",
            "And.",
            "I don't see why rules are not good enough way of doing the same thing which is basically looking at the future then just more natural since we're already using that for Nicholas paying for the ranking itself.",
            "This question so.",
            "Way to do it.",
            "Once you have already sampled and then the pickings document, which is far away and according to the features, for example.",
            "Yeah, that could be another way of foods.",
            "Yeah.",
            "The rule itself is not a very complex approach, right?",
            "And I don't think so, but it's very useful because it shows that it's very simple, easy to understand, and at the same time it's very effective as we can see from the results.",
            "But yeah, you could use different different approaches for that.",
            "I have another question.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning.",
                    "label": 0
                },
                {
                    "sent": "He's a red regal.",
                    "label": 0
                },
                {
                    "sent": "We're going to be presenting.",
                    "label": 0
                },
                {
                    "sent": "Where is the?",
                    "label": 0
                },
                {
                    "sent": "Also just use mine.",
                    "label": 0
                },
                {
                    "sent": "So we're going to be presenting a work on.",
                    "label": 0
                },
                {
                    "sent": "Model active sampling algorithm for learning to rank which is based on Association rules so.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Start giving him outline.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk briefly about.",
                    "label": 0
                },
                {
                    "sent": "The reasons for active sampling in this specific realm I'm going to explain how we use a rule based supervised over it.",
                    "label": 1
                },
                {
                    "sent": "How we use an Association rule based algorithm.",
                    "label": 0
                },
                {
                    "sent": "So actually do learning to rank on a supervised manner using a full training set.",
                    "label": 1
                },
                {
                    "sent": "And from that I'm going to extend that algorithm.",
                    "label": 0
                },
                {
                    "sent": "Use a simple idea to extend that and.",
                    "label": 1
                },
                {
                    "sent": "Be able to use active sampling to select specific instances and reduce my training settings.",
                    "label": 0
                },
                {
                    "sent": "Have a smaller smaller training set.",
                    "label": 0
                },
                {
                    "sent": "So that it's easier to apply it to real life incident situations.",
                    "label": 0
                },
                {
                    "sent": "And finally, I'm going to talk about some results and a small discussion about it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So learning to rank a as being as we said before, it's used for many things, especially the documents word.",
                    "label": 0
                },
                {
                    "sent": "But you can use it for many different in many different applications and as we all know, train sets are always difficult to get an it's very expensive to produce them.",
                    "label": 0
                },
                {
                    "sent": "Especially sometimes in learning to rank.",
                    "label": 1
                },
                {
                    "sent": "It's even harder because sometimes depending on the kind of lowering use, you have to not only label documents as relevant or not relevant that you were given query, but you can also sometimes have to do listwise ranking of documents.",
                    "label": 0
                },
                {
                    "sent": "We can't give you have to annotate or sometimes sometimes has to actually give an order to the results pending on the type of algorithm you're using, so.",
                    "label": 0
                },
                {
                    "sent": "It's pretty expensive to do that, and it's really hard to get those training staff.",
                    "label": 1
                },
                {
                    "sent": "So can we use very small training sets, or can we produce very small training sets that are very informative?",
                    "label": 0
                },
                {
                    "sent": "Very good for that for the learning task.",
                    "label": 0
                },
                {
                    "sent": "So can we produce very good results using just a small amount of documents?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we do that, if we can select very specific examples of documents, there are very informative to the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Does that prove maybe even improve your results?",
                    "label": 0
                },
                {
                    "sent": "If you're just using?",
                    "label": 0
                },
                {
                    "sent": "If you are playing some noise in the training data?",
                    "label": 1
                },
                {
                    "sent": "So that's the kind of answers were talking about.",
                    "label": 0
                },
                {
                    "sent": "We're trying to get here.",
                    "label": 0
                },
                {
                    "sent": "So we are also looking for because there are some previous work on active active sampling, active learning for learning to rank, which usually need an initial labeled set seed set as we call it that is used to train an initial learner and then from that you interactively build new, bring new new new examples into the to the learner and update it.",
                    "label": 1
                },
                {
                    "sent": "Can we do that without the seats at?",
                    "label": 0
                },
                {
                    "sent": "Because we want to do it in a way that we can lag over it and very very fast without being too actually go there and have some initial trainings.",
                    "label": 0
                },
                {
                    "sent": "So this is the motivation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For this work, and 1st, I'm going to be talking about how you do learning to rank using this Association rules.",
                    "label": 1
                },
                {
                    "sent": "Right now I'm talking about supervised regular supervised algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "So I do have a training set composed of a query and a document, an relevance level.",
                    "label": 0
                },
                {
                    "sent": "The document is composed of feature values which are usually different information about the document or about the.",
                    "label": 0
                },
                {
                    "sent": "Where in the document we repair.",
                    "label": 0
                },
                {
                    "sent": "Because for learning to rank the usually what you get is what you have is you have a query so your training set has a query and that's this query generates a bunch of.",
                    "label": 0
                },
                {
                    "sent": "Retrieve from some some data data set like a.",
                    "label": 0
                },
                {
                    "sent": "You retrieve the documents that are relevant using some information retrieval technique, and then you label it so you're training your training set is basically a document.",
                    "label": 0
                },
                {
                    "sent": "Features related to a document, but that document is in response to a query right?",
                    "label": 0
                },
                {
                    "sent": "So that we have all these different values.",
                    "label": 0
                },
                {
                    "sent": "Usually real values associated to the document and then you have relevance levels that could be like in a kind of.",
                    "label": 0
                },
                {
                    "sent": "Is a binary binary relevance strange that you have just not relevant, relevant, but you can also have like not relevant to little bit level relevant, more level credit card so you could have.",
                    "label": 1
                },
                {
                    "sent": "Several levels of relevance for that specific documents in that query and your test set is composed of the same thing, but you don't have the relevance anyway.",
                    "label": 0
                },
                {
                    "sent": "You want to somehow discover that you have to.",
                    "label": 0
                },
                {
                    "sent": "You want to rank those documents on the test set.",
                    "label": 0
                },
                {
                    "sent": "According to the article then, to learn function in the training set.",
                    "label": 0
                },
                {
                    "sent": "So what we use is.",
                    "label": 1
                },
                {
                    "sent": "We want to use.",
                    "label": 0
                },
                {
                    "sent": "Association rules to derives Association rules from the training set.",
                    "label": 0
                },
                {
                    "sent": "Over the course of this form, so we basically looking at features that indicate some relevance.",
                    "label": 0
                },
                {
                    "sent": "So we produce rules and you have a confidence level of these rules is better here.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Was from the training set.",
                    "label": 0
                },
                {
                    "sent": "You could just generate a huge amount of rules, right?",
                    "label": 0
                },
                {
                    "sent": "You could just.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing that in offline, you're basically if you're building a ruleset from huge training set, then you could generate possibly millions or billions of holes, so that's not very practical.",
                    "label": 0
                },
                {
                    "sent": "One way of avoiding this explosion of rules of Member of rules would be to stab Lish.",
                    "label": 0
                },
                {
                    "sent": "Some support for threshold where you say OK, I just I just want rules if they are frequent enough so you stab Lish, a Sigma min value, and you say OK.",
                    "label": 0
                },
                {
                    "sent": "If the rule appears only once in for this whole data set, then I don't want it.",
                    "label": 0
                },
                {
                    "sent": "I want rules that are appear with some frequency so.",
                    "label": 0
                },
                {
                    "sent": "This is 1 possible solution for.",
                    "label": 0
                },
                {
                    "sent": "For doing this for solving this explosion of rules problem.",
                    "label": 0
                },
                {
                    "sent": "But then again, if you said this too low, you still have too many rules, and if you set it too high, maybe you're going to miss very important rules that would allow you to derive relevance or rank the documents from the same formula test set.",
                    "label": 1
                },
                {
                    "sent": "Using this rule set that he created.",
                    "label": 1
                },
                {
                    "sent": "So instead of doing that, why not do a lazy approach where you do on-demand rule expression and technically query time.",
                    "label": 0
                },
                {
                    "sent": "So we're talking about here is given a query in the test set, I look at the query, I retrieve all the documents.",
                    "label": 1
                },
                {
                    "sent": "From the test had related to that query and then for each of those documents I actually create a projected training set.",
                    "label": 1
                },
                {
                    "sent": "So I basically eliminate from the training set everything that doesn't have any relation to those options.",
                    "label": 0
                },
                {
                    "sent": "That specific document that I'm looking at right now because the rules are only useful if the feature values of those rules.",
                    "label": 0
                },
                {
                    "sent": "The appear in that in this document specifically, they're only useful for that specific document.",
                    "label": 0
                },
                {
                    "sent": "They appear in the document, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Take me anywhere if I if I'm looking at a feature value.",
                    "label": 1
                },
                {
                    "sent": "This doesn't doesn't tell me anything about that document.",
                    "label": 0
                },
                {
                    "sent": "So what I do is I project at query time.",
                    "label": 0
                },
                {
                    "sent": "I project this training set and eliminate everything that is not useful.",
                    "label": 0
                },
                {
                    "sent": "So generate rules for that specific document and then I generate a specific rule set for that document.",
                    "label": 0
                },
                {
                    "sent": "In the test app and now I can.",
                    "label": 0
                },
                {
                    "sent": "Only produce I guarantee to produce only very useful rules for classifying for ranking that document.",
                    "label": 0
                },
                {
                    "sent": "So how do I go?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About ranking it.",
                    "label": 0
                },
                {
                    "sent": "Basically what we do is that we consider that each rule that we extracted from this art that we generate into this RRD sets of rules for that document.",
                    "label": 0
                },
                {
                    "sent": "Remember that this is specific for that document query time, so each rules of Bolt to a given relevance level so.",
                    "label": 0
                },
                {
                    "sent": "Operating right on a little bit of a problem so.",
                    "label": 0
                },
                {
                    "sent": "In each vote has a weight which is the confidence right?",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Based.",
                    "label": 0
                },
                {
                    "sent": "When I have this rule set now, I can what I can do for that specific document is to specify score that is normalized.",
                    "label": 0
                },
                {
                    "sent": "Basically that this data, which is nice, my confidence on that on that rule.",
                    "label": 0
                },
                {
                    "sent": "Which is the conditional probability right?",
                    "label": 0
                },
                {
                    "sent": "That rules that specific role indicated that relevance level.",
                    "label": 0
                },
                {
                    "sent": "I can just sum it up and then divide it by the all the rules in that rule set for that document that have.",
                    "label": 0
                },
                {
                    "sent": "This specific.",
                    "label": 1
                },
                {
                    "sent": "Relevance level, so I I had this this core and then I normalize the support for all the different.",
                    "label": 0
                },
                {
                    "sent": "Different relevance levels and basically my ranking for the final ranking function function, so I'm basically assigning a number to this document saying OK.",
                    "label": 0
                },
                {
                    "sent": "This is the ranking value of this document and later on after I do all the documents.",
                    "label": 0
                },
                {
                    "sent": "Basically what I want to do is just order those documents by the ranking function ranking value right?",
                    "label": 0
                },
                {
                    "sent": "So it's a pointwise ranking function and.",
                    "label": 1
                },
                {
                    "sent": "Basically, I do a linear combination of this of this values of this.",
                    "label": 0
                },
                {
                    "sent": "This likelihoods the relevance right.",
                    "label": 0
                },
                {
                    "sent": "Likelihoods for documents and what I have is a ranking Faneuil pointwise ranking better for that number so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say this is.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The supervised algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here I'm considering that I have a training set and so I get a new document from the query time I filter out by my training set.",
                    "label": 0
                },
                {
                    "sent": "I produce rules for that specific document and then I come up with this ranking value for that document in relation to that query so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What if I want to build?",
                    "label": 0
                },
                {
                    "sent": "I want to use this to build a training set.",
                    "label": 0
                },
                {
                    "sent": "I don't have a training set.",
                    "label": 0
                },
                {
                    "sent": "I have an unlabeled set containing unlabeled documents.",
                    "label": 0
                },
                {
                    "sent": "And what I want to do now is to use some things related to this to this.",
                    "label": 0
                },
                {
                    "sent": "Supervised algorithm using Association rules to pick out the documents that I want to label.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to pick one document at a time and then I'm going to label it and eventually this is going to become my training set.",
                    "label": 0
                },
                {
                    "sent": "An is a very small training set and it's, I hope very, very effective.",
                    "label": 0
                },
                {
                    "sent": "So how do we do that?",
                    "label": 0
                },
                {
                    "sent": "We have this unlabeled set.",
                    "label": 0
                },
                {
                    "sent": "And then what I look at is.",
                    "label": 0
                },
                {
                    "sent": "Let's say I have.",
                    "label": 0
                },
                {
                    "sent": "Some train set.",
                    "label": 0
                },
                {
                    "sent": "I have like some 10 or 10 documents in my training set right now, so I'm in the middle of the process of doing this.",
                    "label": 0
                },
                {
                    "sent": "So if I'm going to start one new document into the set, I'm going to those rules from the stand documents and I'm going to look into my unlabeled set because I'm I'm taking one one document from the label set and then I'm producing the rules.",
                    "label": 0
                },
                {
                    "sent": "And then what is going to happen is that this this UI document that I'm just inserting?",
                    "label": 0
                },
                {
                    "sent": "Into the training set, which is the small training set right now.",
                    "label": 0
                },
                {
                    "sent": "When I do that, the number of rules that share features with with, so the documents that remain in you the documents in you.",
                    "label": 1
                },
                {
                    "sent": "These the number of rules that I can extract from my training set.",
                    "label": 0
                },
                {
                    "sent": "Right now they they will increase only for those documents that is still in you that contain that share feature vectors with this document specifically.",
                    "label": 0
                },
                {
                    "sent": "And obviously, for the darkness that do not share any values, the number of rules will not change because.",
                    "label": 1
                },
                {
                    "sent": "I only produce rules for that app, and if there is a sharing features because I filter out the whole the whole training set before I do that so.",
                    "label": 0
                },
                {
                    "sent": "What we're getting at is that the number of rules extracted for a document.",
                    "label": 1
                },
                {
                    "sent": "So once I get a document and I look at it and I filter all of my training set, my small training set, the number of rules is an indication of how many documents that are similar to that document that I'm looking at that I already have into my training set.",
                    "label": 0
                },
                {
                    "sent": "So if I have a lot of rules, then I have a lot of documents that are similar.",
                    "label": 0
                },
                {
                    "sent": "If I have fewer rules than that document is very different from the document that already having the same sense.",
                    "label": 0
                },
                {
                    "sent": "So what I'm what I want to do is.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "I have what we what we wanted, what we think is that.",
                    "label": 0
                },
                {
                    "sent": "The diversity of the documents in the training set is essentially if you want to build a very small training set, then you have to have very different documents.",
                    "label": 0
                },
                {
                    "sent": "There are very diverse so that those will form a training set.",
                    "label": 0
                },
                {
                    "sent": "It is useful to rank.",
                    "label": 1
                },
                {
                    "sent": "Test set up very good because they have different characteristics.",
                    "label": 0
                },
                {
                    "sent": "They are very bad diverse.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing is basically our grading is selecting from you or then label set all the documents that demand the fewer rules from my current training set.",
                    "label": 0
                },
                {
                    "sent": "So I do that interacts with interactively, every at every round.",
                    "label": 0
                },
                {
                    "sent": "Decide which of the documents in you is the most interesting and I put it into into the into my training set, and then I label it, and then I do it again.",
                    "label": 0
                },
                {
                    "sent": "So I I I iterate over that and so I have a training set and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basically, the sampling function that I'm getting at here is that.",
                    "label": 1
                },
                {
                    "sent": "I'm looking for the document which has this, which produces the smaller the smallest.",
                    "label": 1
                },
                {
                    "sent": "Rules out right so.",
                    "label": 0
                },
                {
                    "sent": "So of course, initially my my training set is empty.",
                    "label": 0
                },
                {
                    "sent": "I can do that once I can generate rules.",
                    "label": 0
                },
                {
                    "sent": "I can't generate rules if I don't have any documents in the training set.",
                    "label": 0
                },
                {
                    "sent": "So to do that what we do is that the first document that is selected.",
                    "label": 0
                },
                {
                    "sent": "So if I have an empty training set, I basically go there and pick the document that shares the most feature values with all the other documents into the unlabeled set.",
                    "label": 1
                },
                {
                    "sent": "So basically I'm looking for a very representative document because that's the guy that's going to give me more rules for the following for the next rounds of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So once I select this first document, then I start using this this sampling function where I'm basically looking for the documents that produced the fewer loop rules from my current training set and inserting it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We tried we.",
                    "label": 0
                },
                {
                    "sent": "Ransom experience using the liter data sets that 3.0 and I'm here I'm showing the mean average precision for the supervised algorithm, which is the algorithm using the full training sets.",
                    "label": 0
                },
                {
                    "sent": "So this is the size of the training set.",
                    "label": 0
                },
                {
                    "sent": "This is the amount of instances of documents that were selected by our.",
                    "label": 0
                },
                {
                    "sent": "Algorithm, and this is the percentage of the size of what was selected, and this is the mean average precision and we can see that here that although it fares pretty well in a couple of very specific data sets which are these name pages and home pages at datasets, you can see that goes pretty well in a couple of those.",
                    "label": 0
                },
                {
                    "sent": "It's not very good in general, but it's selecting very few very few instances.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can we improve that?",
                    "label": 0
                },
                {
                    "sent": "How can we select more?",
                    "label": 0
                },
                {
                    "sent": "We need to?",
                    "label": 0
                },
                {
                    "sent": "Because they were in ultimate.",
                    "label": 0
                },
                {
                    "sent": "Verges whilst it's Alexa document is already selected, so it basically does this process until it gets a point where it tries to select the document that's already in the training set.",
                    "label": 0
                },
                {
                    "sent": "So how do we fill a discover gence we basically?",
                    "label": 0
                },
                {
                    "sent": "Partitioning we basically partitioned the unlabeled set, which is.",
                    "label": 0
                },
                {
                    "sent": "Composed of several features and we vertically partitioned it.",
                    "label": 0
                },
                {
                    "sent": "Separating groups of features.",
                    "label": 0
                },
                {
                    "sent": "And the reason why we want to do that is because we want to select partitions based on select documents based on different.",
                    "label": 0
                },
                {
                    "sent": "Groups of partitions of features.",
                    "label": 1
                },
                {
                    "sent": "And basically we're setting up.",
                    "label": 0
                },
                {
                    "sent": "We experimentally defined reached the number of partitions saying that OK 8 to 12 features per partitions is a good balance on 4.",
                    "label": 1
                },
                {
                    "sent": "In general, and it's this is valid for all data sets that we we tried, we use, but we only.",
                    "label": 0
                },
                {
                    "sent": "So basically, we're working with five partitions for this data set.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show the results in a moment.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we select the.",
                    "label": 1
                },
                {
                    "sent": "We look at the features 1st and then we try to rank the features such that we know reach are the most informative features we want to put informative features into each partition.",
                    "label": 0
                },
                {
                    "sent": "Because we want the algorithm to select informative examples from from the different partitions for different reasons.",
                    "label": 1
                },
                {
                    "sent": "Because they're using different features.",
                    "label": 0
                },
                {
                    "sent": "So we basically using the key squared to evaluate and rank the features in relation to each other.",
                    "label": 0
                },
                {
                    "sent": "We are using that to eventually spread the most informative partition features into each of the partitions in such a way that we always have some informative feature.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we get from that using five partitions for all these datasets, which are which have 64 features.",
                    "label": 0
                },
                {
                    "sent": "The lift or 3.0 datasets.",
                    "label": 0
                },
                {
                    "sent": "We have basically 12 features per partition and here we are.",
                    "label": 1
                },
                {
                    "sent": "We can see that we select a more reasonable amount of the original set, so we're basically using two point 18% of the of this specific data set.",
                    "label": 0
                },
                {
                    "sent": "The original training set, which are we are using as the labels have to select from and we are obtaining very good results for basically all those datasets.",
                    "label": 0
                },
                {
                    "sent": "This is again the supervised algorithm with the whole training set.",
                    "label": 1
                },
                {
                    "sent": "And this is the active sampling algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just 4 four.",
                    "label": 0
                },
                {
                    "sent": "For reference, we compare those with established baselines, algorithms of their work, published by the Little 3.0 publishers.",
                    "label": 0
                },
                {
                    "sent": "So this this is rank boost Anne Frank and regression.",
                    "label": 0
                },
                {
                    "sent": "There are like 12 different baselines that are published by the letter of producers, and we're here.",
                    "label": 0
                },
                {
                    "sent": "We're just comparing to show that our algorithm using that's very, very small amount of regional training sets.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you can see here.",
                    "label": 0
                },
                {
                    "sent": "So 1.1, two 2.2.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They they fare pretty well and even better than these algorithms which are using the full training center.",
                    "label": 0
                },
                {
                    "sent": "These are supervised algorithm algorithms using the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Incense.",
                    "label": 0
                },
                {
                    "sent": "So this work is different from previous work in the sense that there's some active learning frameworks for learning to rank, and most of 'em.",
                    "label": 1
                },
                {
                    "sent": "First personal, they depend on using an initial labeled SESAC so you need to have a train and initial training set which would we don't need here because we are producing this set from scratch and.",
                    "label": 0
                },
                {
                    "sent": "Also these words.",
                    "label": 0
                },
                {
                    "sent": "They usually they use from 11 to 15% of the original sets to obtain similar results.",
                    "label": 1
                },
                {
                    "sent": "We're using from one 1%, so it's a percent.",
                    "label": 0
                },
                {
                    "sent": "So basically that's it.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do we have the next speaker?",
                    "label": 0
                },
                {
                    "sent": "I don't think so.",
                    "label": 0
                },
                {
                    "sent": "There was an announcement.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decisions stop that.",
                    "label": 0
                },
                {
                    "sent": "There were basically no sections one in the system, so probably the last 26.",
                    "label": 0
                },
                {
                    "sent": "Sorry for pressing.",
                    "label": 0
                },
                {
                    "sent": "That's OK, that's OK. Just do this.",
                    "label": 0
                },
                {
                    "sent": "Fighting is alone.",
                    "label": 0
                },
                {
                    "sent": "Short any questions.",
                    "label": 0
                },
                {
                    "sent": "From, from what I understood, your maker criterion for selecting examples is diversity.",
                    "label": 0
                },
                {
                    "sent": "So yeah, my question is OK, sure, intuitively makes sense.",
                    "label": 0
                },
                {
                    "sent": "Select the diverse training set, but do you have any, say theoretical reasons or justifications for doing that and question related to this is if you are only looking at diversity.",
                    "label": 0
                },
                {
                    "sent": "In principle, this intermediate step of mining Association rules and principles not really necessary, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, you could just compare the document descriptions and then also compute the area kind of diversity measures, yeah?",
                    "label": 0
                },
                {
                    "sent": "Well, they're there.",
                    "label": 0
                },
                {
                    "sent": "There are a couple of words talking about diversity.",
                    "label": 0
                },
                {
                    "sent": "Batman diversity in this collections.",
                    "label": 0
                },
                {
                    "sent": "There is no theoretical work on how that influences brain.",
                    "label": 0
                },
                {
                    "sent": "Not that I'm aware of.",
                    "label": 0
                },
                {
                    "sent": "We did not develop a theoretical theoretical framework for that.",
                    "label": 0
                },
                {
                    "sent": "To explain why it is their version is good.",
                    "label": 0
                },
                {
                    "sent": "It's all.",
                    "label": 0
                },
                {
                    "sent": "It's only an intuition and it's somehow.",
                    "label": 0
                },
                {
                    "sent": "Experimentally, we see that that is the case and the other words that I know.",
                    "label": 0
                },
                {
                    "sent": "Also, talk about experience of experimentally defining that some diversity and.",
                    "label": 0
                },
                {
                    "sent": "In the document collection is always good for learning algorithm, Ranger ankle rhythms.",
                    "label": 0
                },
                {
                    "sent": "For for how why we do the rule?",
                    "label": 0
                },
                {
                    "sent": "The rule is cell that the rule that you could in principle yes just select use a simpler way to determine what is a diverse document based on what you have like you could just look at the features and try to establish that, but the rules are useful way of doing that because we're already using the rules anyways to actually do their ranking.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "To do the actual ranking because it's a two step process here you're selecting your data, set your training set, and then you're actually.",
                    "label": 0
                },
                {
                    "sent": "Using it on a test set for one query time, right?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I don't see why rules are not good enough way of doing the same thing which is basically looking at the future then just more natural since we're already using that for Nicholas paying for the ranking itself.",
                    "label": 0
                },
                {
                    "sent": "This question so.",
                    "label": 0
                },
                {
                    "sent": "Way to do it.",
                    "label": 0
                },
                {
                    "sent": "Once you have already sampled and then the pickings document, which is far away and according to the features, for example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that could be another way of foods.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The rule itself is not a very complex approach, right?",
                    "label": 0
                },
                {
                    "sent": "And I don't think so, but it's very useful because it shows that it's very simple, easy to understand, and at the same time it's very effective as we can see from the results.",
                    "label": 0
                },
                {
                    "sent": "But yeah, you could use different different approaches for that.",
                    "label": 0
                },
                {
                    "sent": "I have another question.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}