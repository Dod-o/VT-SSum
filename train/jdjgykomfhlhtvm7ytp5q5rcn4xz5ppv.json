{
    "id": "jdjgykomfhlhtvm7ytp5q5rcn4xz5ppv",
    "title": "Redefining Class Definitions using Constraint-Based Clustering: An Application to Remote Sensing of the Earth's Surface",
    "info": {
        "author": [
            "Dan R. Preston, Department of Computer Science, Tufts University"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Machine Learning->Clustering",
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/kdd2010_preston_rcdu/",
    "segmentation": [
        [
            "OK.",
            "This is redefining class definitions using constraint based clustering.",
            "I'm Dan Preston number, Stanford student.",
            "I did this work with Carla Brodley and Roni Cardone at Tufts and this is in conjunction with the geography Department at Boston University."
        ],
        [
            "So let's start with a fundamental question where the classes come from all classes come from categories or concepts that we may find useful.",
            "So for example, if we're trying to diagnose cancer, we may have stomach and lung cancer, and if we only have very basic symptoms, if we only know very basic features about this data, then we may not be able to support them by the features will not be able to print them.",
            "On the other hand, if we cluster to find the classes.",
            "If we have lots of different features, if we have many different ways of measuring the cancer itself, we may find that the lung cancer then Detroit into where where it might be, what the state of the case might be, and this may not be useful to a practitioner.",
            "So there are other problems like we don't know how many different clusters there are, and there may be many different clusterings that are equally good depending on the metric that we used to look at this.",
            "So let's look at a."
        ],
        [
            "Example, this is our data set.",
            "This is the IGP product.",
            "From here we have many labeled instances and the instances are then used to predict the rest of it using boosted decision trees and the classes are agriculture, water and other classes that describe this land cover data.",
            "There are 17 of them and what we find is that.",
            "Some."
        ],
        [
            "Of the areas are very uniform, so this is agriculture.",
            "What we understand is that there may be more to this there maybe we or corn or other subclasses that may be more interesting to understand about the data and we have a better understanding an new instruments to be able to find these features.",
            "So overtime these have been defined since the 1970s, and since then because of this new understanding, we may want to look at these classes again and."
        ],
        [
            "See what we can find.",
            "Another example is when we have many different classes in this one area, mixed forest, deciduous forests that may not really be supported by the features, so maybe these should be put together into one class that has a better."
        ],
        [
            "Class definition"
        ],
        [
            "And so we don't want to throw away any of the work that's been done in the past, and we want to leverage a lot of the expert knowledge so that we don't have to redo the thousands of hours of graduate student work that went into labeling all of these instances.",
            "So how can we use this data use what we already know and come up with a better class definition.",
            "Also, looking at the unsupervised level of this."
        ],
        [
            "So our approach is to use a probabilistic constraint clustering, and we're going to use the original labels as the constraints and then use expert belief as a guide as to how these labels should interact and how.",
            "Sorry as how these classes should interact.",
            "So we're going to have to measure how well this clustering is doing for our experts, and we're going to present a metric for doing this, and this will help us also determine the number of clusters.",
            "A number of classes that should be used to the data.",
            "And finally, we go into more detail about this.",
            "IGP Land cover data set.",
            "And."
        ],
        [
            "Let's start with a brief review.",
            "So originally this was done using instance pairs, so two pairs of instances have some constraint at first with hard constraints, so they must be together that cannot be together in any clustering in this result should match their constraints that was given to us, and this is first time with K means.",
            "There is then extended to EM with Gaussian mixture mixture models.",
            "Very excited to use probabilistic constraints.",
            "An in one paper they use a group in which all of the instances in that group have some probability of appearing together.",
            "This was done with a Bayes net and because we have so many instances and and we have constraints for each one of our classes in each one of our instances, this will get very large and ends up being intractable for our users.",
            "So we found another method, PPC, which does a very good job at approximating this using variational methods, and so we use this.",
            "As part of our framework to build out the rest of the details."
        ],
        [
            "So what are the constraints that we're using in this framework?",
            "The constraints are going to be put together in a compact representation so that we can use so it can be intuitive for expert and also easy to compute."
        ],
        [
            "So when we wanted to find expert belief, we're going to give him a matrix to call this the C matrix this.",
            "Has two different kind of values.",
            "First, if it's not on the diagonal, if we have two different classes A&B, you can specify a value of 1, which means that you want these two classes to merge together in the final product or you have a very strong intention of keeping them together.",
            "If it's negative one, you want to separate them as much as possible.",
            "So if you want to merge two classes, say for example two kinds of forests, you know that should be in the same class.",
            "In the end, you'll want to fight a value of 1.",
            "If you know that they should be separate, say agriculture and water, you want to provide a value of negative.",
            "And if you have no opinion, you put a value of zero, you will then revert to EM by itself, meaning that you'll get the unsupervised learning aspect of it.",
            "The values on the diagonal where you have a single label, a single value for one class.",
            "This value is a slightly different meaning.",
            "If you put a value of 1.",
            "This means that you want this class to stay intact.",
            "You want to make sure you retain as much of the structure as possible, whereas if you set a value of less than one, you'll.",
            "Allow the algorithm to split the class into multiple subclasses, so may, for example, if you have agriculture and you know this could be split into wheat and corn, everybody value of .5 and it will retain much of the structure, but it could allow to split a value of 0 again elected to perform unsupervised clustering on it, and negative one is not really meaningful in that you would try to put each instance into its own cluster which is."
        ],
        [
            "Kind of nonsense so.",
            "One example of this matrix.",
            "This was given to us by our expert, and these define the values.",
            "For the matrix, for each one of the classes.",
            "It's important to note that these specify the preferences of the expert, so this is not something that can be learned.",
            "This is something that allows the experts define what he, what he or she cares about, and what is important to see in the final product of the clustering.",
            "Also, slight variations in these.",
            "These values don't have a serious effect on the final clustering, so we're looking for best guesses an.",
            "Some constraints that are given to us by our expert.",
            "So we're going to take this matrix and incorporate it."
        ],
        [
            "Square algorithm.",
            "The update equations on the bottom are.",
            "Gas and EM equations.",
            "You've seen streams before.",
            "The difference here is that QIK.",
            "Is the prior times the membership probability and then in the in the exponential is what we represent our constraints?",
            "So for this is summed over all of the different all of the instances, and for each instance we pull from the constraint matrix the.",
            "The value in the matrix that represents the original label of QA in the original label of the other instance you're summing over, so we multiply that by the current value times this value, Lambda, which is an overall parameter for the expert to define that defines how much he or she believes in their matrix, and this is a tunable parameter that you can use to find different clusterings.",
            "In the end, this is done iteratively until convergence and.",
            "It only takes about 5 to 10 iterations for this work."
        ],
        [
            "Because we have this compact representation, we actually find that there's a lot of redundant computation that happens if you sum over strictly the instances.",
            "So instead, we can actually reduce this from over and squared, where is number of instances, which in our case is about 50,000 and reduce it from endovenous squared to over and L4L as a number of classes from which we have 17, and we can use this down pretty significantly.",
            "I won't go into the math, but the basic intuition here is that we cash the values for.",
            "Each one of the labels and then we use this in the computation over and over again, and it only has to be calculated once."
        ],
        [
            "So now that we've come up with the clustering, we have our algorithm.",
            "How do we evaluate this?",
            "What is a good clustering in this setting?"
        ],
        [
            "So if you're doing simply unsupervised clustering, normal heuristic for this maybe be ICRA.",
            "I see these fundamentally have two parts to it.",
            "One is a fit term.",
            "How compact are clusters and one is a complexity term.",
            "Making sure we don't have too many clusters, and so we're going to use BICS as the basis for this.",
            "And we're going to add a term for."
        ],
        [
            "Straight and here it's.",
            "And to do this, we're going to create a matrix in the same size as the C matrix and in the same range from from negative one to one.",
            "So if one of the value 4 two labels in the matrix is equal to 1, this means that all instances for those two labels appear in clusters together in the final clustering.",
            "If it's negative one, then they didn't appear together in the final clustering.",
            "This is calculated by doing a normalized count where we add one for each time that two instances with labels A&B appear together and subtract 1 every time they appear in different clusters.",
            "We then normalize this to the to the correct range, negative one to one, and then what we do is we find the difference between this and the original."
        ],
        [
            "Matrix.",
            "Someone together.",
            "Get the sum of the squared difference between these.",
            "And this gives us an aggregated value.",
            "This G value aggregated value to measure how well we're adhering to the constraints overall.",
            "So we're going to use this in our final metric."
        ],
        [
            "So constrained DIC CBSE is first BIC which gives us the fit term in the complexity term and then we add this constraint here instrum.",
            "It is normalized by 4 L squared.",
            "This is the maximum value that this value can take on.",
            "So this is just putting it into the same range as the fit term RSS over these two values, the fit term and the constraint adherence term are then balanced by this Lambda term that we had before, which is the belief that the expert has in their constraint matrix so.",
            "We have these three terms."
        ],
        [
            "The most important thing to remember is that it combines three things, has BICS, which contains complexity and cluster fit.",
            "It also has this aggregated G value, which is how well we can hear constraints, and CBSE is the blending of these three things.",
            "So let's go into an exam."
        ],
        [
            "Well, that kind of ties all of us together.",
            "On the left we have this data set is very simple.",
            "It has four Gaussian clusters.",
            "Two, they were arbitrarily chosen to produce two classes, one red, 1 blue, and if you were to perform them on this, you would expect there to be.",
            "Two clusterings where you would have the closest closest instances together, so this has the best fit.",
            "If we had strong constraints for the original classes with red and blue, and we would hope to produce the clustering on the right where we keep the classes together."
        ],
        [
            "So let's consider different situations where we have different matrices.",
            "In this example, we have very strong constraints an.",
            "The constraints for each class are near one, and so they end up getting put together.",
            "We would hope that.",
            "The number of clusters that the metric tells us is ideal would be too, because we have a strong constraint between these classes."
        ],
        [
            "In another example, we have weak constraints and we revert back to the original M clustering.",
            "And.",
            "Here we would hope that we would have 4.",
            "Because there are actually 4 very clear gas and distributions here, and we hope that K would come out to foreign."
        ],
        [
            "Final metric and so this is what we find with strong constraints.",
            "We have K is equal to 2.",
            "Anne, with the constraints we end up with four.",
            "We're using the criterion.",
            "So with this framework, let's see how it does."
        ],
        [
            "With some real data, the remote sensing data set we saw a little bit before 17 classes.",
            "Things like agriculture.",
            "We gave them two clusterings.",
            "We gave them an EM clustering and a clustering based on our CPC method and we asked them blindly to look at them to look at both of them without asking in advance without telling them in advance which was which.",
            "So we got some."
        ],
        [
            "Using results, this is an area centered around New England, Montreal, and primarily.",
            "It consists of deciduous and mixed forest and what we find is that both CBC and EM end up merging these two classes together because the underlying features didn't support this.",
            "And there's the constraints weren't strong enough to keep them apart, so they ended up merging together.",
            "And this is this actually validated hypothesis that are experts had had before the project started."
        ],
        [
            "In addition, here is an area of agriculture in Iowa.",
            "This is in black and white because it didn't show up in the slides.",
            "What the algorithm found was that you could split this into two classes because the features were pretty well separated and the constraints weren't that strong along the diagonal.",
            "To keep this together.",
            "When our experts examine this, they actually found that the two classes that were split into were primarily corn versus wheat.",
            "And this ended up being a pretty interesting result."
        ],
        [
            "Finally, we hope that EM and CPC don't end up doing the same thing, and this is actually true over much of the map in this instance, this is an area over Mexico in the desert where we have two classes and IGP that aren't very well separated by the features.",
            "For EM it didn't find this structure because it was because it was close together.",
            "Ended up merging these two classes into one, whereas CPC because there was a strong constraint to keep them apart.",
            "Ended up keeping the structure and retaining what we had before, which was desirable."
        ],
        [
            "So in summary, we have this framework to redefine our classes to use the old labels that we had before and not waste a lot of the great work that's gone into labeling these and be able to inject some of the expert preferences and be able to guide these constraints in the right way.",
            "Because of this representation, as a byproduct, we were able to reduce the computation from over and squared over now and.",
            "We later were able to come up with a valuation metric that allowed us to.",
            "Compare clustering results and determine the number of clusters.",
            "And finally we had some promising results in remote sensing that's being continued at both BU and Tufts now, so."
        ],
        [
            "Thank you very much.",
            "This is.",
            "Respect.",
            "Yeah it should.",
            "Sorry the question is has a scale with dimensionality it should scale in the same way that M does its.",
            "It's complexity is generally is is pretty much determined by the number of instances in the number of labels, so the complexity in terms of number of features is not a significant impact on the final result.",
            "OK, so thank you for attending."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This is redefining class definitions using constraint based clustering.",
                    "label": 1
                },
                {
                    "sent": "I'm Dan Preston number, Stanford student.",
                    "label": 0
                },
                {
                    "sent": "I did this work with Carla Brodley and Roni Cardone at Tufts and this is in conjunction with the geography Department at Boston University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's start with a fundamental question where the classes come from all classes come from categories or concepts that we may find useful.",
                    "label": 1
                },
                {
                    "sent": "So for example, if we're trying to diagnose cancer, we may have stomach and lung cancer, and if we only have very basic symptoms, if we only know very basic features about this data, then we may not be able to support them by the features will not be able to print them.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, if we cluster to find the classes.",
                    "label": 0
                },
                {
                    "sent": "If we have lots of different features, if we have many different ways of measuring the cancer itself, we may find that the lung cancer then Detroit into where where it might be, what the state of the case might be, and this may not be useful to a practitioner.",
                    "label": 0
                },
                {
                    "sent": "So there are other problems like we don't know how many different clusters there are, and there may be many different clusterings that are equally good depending on the metric that we used to look at this.",
                    "label": 0
                },
                {
                    "sent": "So let's look at a.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, this is our data set.",
                    "label": 0
                },
                {
                    "sent": "This is the IGP product.",
                    "label": 0
                },
                {
                    "sent": "From here we have many labeled instances and the instances are then used to predict the rest of it using boosted decision trees and the classes are agriculture, water and other classes that describe this land cover data.",
                    "label": 0
                },
                {
                    "sent": "There are 17 of them and what we find is that.",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the areas are very uniform, so this is agriculture.",
                    "label": 0
                },
                {
                    "sent": "What we understand is that there may be more to this there maybe we or corn or other subclasses that may be more interesting to understand about the data and we have a better understanding an new instruments to be able to find these features.",
                    "label": 1
                },
                {
                    "sent": "So overtime these have been defined since the 1970s, and since then because of this new understanding, we may want to look at these classes again and.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See what we can find.",
                    "label": 0
                },
                {
                    "sent": "Another example is when we have many different classes in this one area, mixed forest, deciduous forests that may not really be supported by the features, so maybe these should be put together into one class that has a better.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Class definition",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we don't want to throw away any of the work that's been done in the past, and we want to leverage a lot of the expert knowledge so that we don't have to redo the thousands of hours of graduate student work that went into labeling all of these instances.",
                    "label": 0
                },
                {
                    "sent": "So how can we use this data use what we already know and come up with a better class definition.",
                    "label": 0
                },
                {
                    "sent": "Also, looking at the unsupervised level of this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our approach is to use a probabilistic constraint clustering, and we're going to use the original labels as the constraints and then use expert belief as a guide as to how these labels should interact and how.",
                    "label": 1
                },
                {
                    "sent": "Sorry as how these classes should interact.",
                    "label": 0
                },
                {
                    "sent": "So we're going to have to measure how well this clustering is doing for our experts, and we're going to present a metric for doing this, and this will help us also determine the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "A number of classes that should be used to the data.",
                    "label": 0
                },
                {
                    "sent": "And finally, we go into more detail about this.",
                    "label": 0
                },
                {
                    "sent": "IGP Land cover data set.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's start with a brief review.",
                    "label": 1
                },
                {
                    "sent": "So originally this was done using instance pairs, so two pairs of instances have some constraint at first with hard constraints, so they must be together that cannot be together in any clustering in this result should match their constraints that was given to us, and this is first time with K means.",
                    "label": 0
                },
                {
                    "sent": "There is then extended to EM with Gaussian mixture mixture models.",
                    "label": 0
                },
                {
                    "sent": "Very excited to use probabilistic constraints.",
                    "label": 0
                },
                {
                    "sent": "An in one paper they use a group in which all of the instances in that group have some probability of appearing together.",
                    "label": 0
                },
                {
                    "sent": "This was done with a Bayes net and because we have so many instances and and we have constraints for each one of our classes in each one of our instances, this will get very large and ends up being intractable for our users.",
                    "label": 0
                },
                {
                    "sent": "So we found another method, PPC, which does a very good job at approximating this using variational methods, and so we use this.",
                    "label": 0
                },
                {
                    "sent": "As part of our framework to build out the rest of the details.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what are the constraints that we're using in this framework?",
                    "label": 0
                },
                {
                    "sent": "The constraints are going to be put together in a compact representation so that we can use so it can be intuitive for expert and also easy to compute.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we wanted to find expert belief, we're going to give him a matrix to call this the C matrix this.",
                    "label": 0
                },
                {
                    "sent": "Has two different kind of values.",
                    "label": 0
                },
                {
                    "sent": "First, if it's not on the diagonal, if we have two different classes A&B, you can specify a value of 1, which means that you want these two classes to merge together in the final product or you have a very strong intention of keeping them together.",
                    "label": 0
                },
                {
                    "sent": "If it's negative one, you want to separate them as much as possible.",
                    "label": 0
                },
                {
                    "sent": "So if you want to merge two classes, say for example two kinds of forests, you know that should be in the same class.",
                    "label": 0
                },
                {
                    "sent": "In the end, you'll want to fight a value of 1.",
                    "label": 0
                },
                {
                    "sent": "If you know that they should be separate, say agriculture and water, you want to provide a value of negative.",
                    "label": 0
                },
                {
                    "sent": "And if you have no opinion, you put a value of zero, you will then revert to EM by itself, meaning that you'll get the unsupervised learning aspect of it.",
                    "label": 0
                },
                {
                    "sent": "The values on the diagonal where you have a single label, a single value for one class.",
                    "label": 0
                },
                {
                    "sent": "This value is a slightly different meaning.",
                    "label": 0
                },
                {
                    "sent": "If you put a value of 1.",
                    "label": 0
                },
                {
                    "sent": "This means that you want this class to stay intact.",
                    "label": 0
                },
                {
                    "sent": "You want to make sure you retain as much of the structure as possible, whereas if you set a value of less than one, you'll.",
                    "label": 0
                },
                {
                    "sent": "Allow the algorithm to split the class into multiple subclasses, so may, for example, if you have agriculture and you know this could be split into wheat and corn, everybody value of .5 and it will retain much of the structure, but it could allow to split a value of 0 again elected to perform unsupervised clustering on it, and negative one is not really meaningful in that you would try to put each instance into its own cluster which is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of nonsense so.",
                    "label": 0
                },
                {
                    "sent": "One example of this matrix.",
                    "label": 0
                },
                {
                    "sent": "This was given to us by our expert, and these define the values.",
                    "label": 0
                },
                {
                    "sent": "For the matrix, for each one of the classes.",
                    "label": 0
                },
                {
                    "sent": "It's important to note that these specify the preferences of the expert, so this is not something that can be learned.",
                    "label": 0
                },
                {
                    "sent": "This is something that allows the experts define what he, what he or she cares about, and what is important to see in the final product of the clustering.",
                    "label": 0
                },
                {
                    "sent": "Also, slight variations in these.",
                    "label": 0
                },
                {
                    "sent": "These values don't have a serious effect on the final clustering, so we're looking for best guesses an.",
                    "label": 0
                },
                {
                    "sent": "Some constraints that are given to us by our expert.",
                    "label": 0
                },
                {
                    "sent": "So we're going to take this matrix and incorporate it.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Square algorithm.",
                    "label": 0
                },
                {
                    "sent": "The update equations on the bottom are.",
                    "label": 0
                },
                {
                    "sent": "Gas and EM equations.",
                    "label": 0
                },
                {
                    "sent": "You've seen streams before.",
                    "label": 0
                },
                {
                    "sent": "The difference here is that QIK.",
                    "label": 0
                },
                {
                    "sent": "Is the prior times the membership probability and then in the in the exponential is what we represent our constraints?",
                    "label": 0
                },
                {
                    "sent": "So for this is summed over all of the different all of the instances, and for each instance we pull from the constraint matrix the.",
                    "label": 0
                },
                {
                    "sent": "The value in the matrix that represents the original label of QA in the original label of the other instance you're summing over, so we multiply that by the current value times this value, Lambda, which is an overall parameter for the expert to define that defines how much he or she believes in their matrix, and this is a tunable parameter that you can use to find different clusterings.",
                    "label": 0
                },
                {
                    "sent": "In the end, this is done iteratively until convergence and.",
                    "label": 0
                },
                {
                    "sent": "It only takes about 5 to 10 iterations for this work.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because we have this compact representation, we actually find that there's a lot of redundant computation that happens if you sum over strictly the instances.",
                    "label": 0
                },
                {
                    "sent": "So instead, we can actually reduce this from over and squared, where is number of instances, which in our case is about 50,000 and reduce it from endovenous squared to over and L4L as a number of classes from which we have 17, and we can use this down pretty significantly.",
                    "label": 0
                },
                {
                    "sent": "I won't go into the math, but the basic intuition here is that we cash the values for.",
                    "label": 0
                },
                {
                    "sent": "Each one of the labels and then we use this in the computation over and over again, and it only has to be calculated once.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now that we've come up with the clustering, we have our algorithm.",
                    "label": 0
                },
                {
                    "sent": "How do we evaluate this?",
                    "label": 0
                },
                {
                    "sent": "What is a good clustering in this setting?",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you're doing simply unsupervised clustering, normal heuristic for this maybe be ICRA.",
                    "label": 0
                },
                {
                    "sent": "I see these fundamentally have two parts to it.",
                    "label": 0
                },
                {
                    "sent": "One is a fit term.",
                    "label": 1
                },
                {
                    "sent": "How compact are clusters and one is a complexity term.",
                    "label": 0
                },
                {
                    "sent": "Making sure we don't have too many clusters, and so we're going to use BICS as the basis for this.",
                    "label": 0
                },
                {
                    "sent": "And we're going to add a term for.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Straight and here it's.",
                    "label": 0
                },
                {
                    "sent": "And to do this, we're going to create a matrix in the same size as the C matrix and in the same range from from negative one to one.",
                    "label": 1
                },
                {
                    "sent": "So if one of the value 4 two labels in the matrix is equal to 1, this means that all instances for those two labels appear in clusters together in the final clustering.",
                    "label": 1
                },
                {
                    "sent": "If it's negative one, then they didn't appear together in the final clustering.",
                    "label": 0
                },
                {
                    "sent": "This is calculated by doing a normalized count where we add one for each time that two instances with labels A&B appear together and subtract 1 every time they appear in different clusters.",
                    "label": 1
                },
                {
                    "sent": "We then normalize this to the to the correct range, negative one to one, and then what we do is we find the difference between this and the original.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Matrix.",
                    "label": 0
                },
                {
                    "sent": "Someone together.",
                    "label": 0
                },
                {
                    "sent": "Get the sum of the squared difference between these.",
                    "label": 1
                },
                {
                    "sent": "And this gives us an aggregated value.",
                    "label": 0
                },
                {
                    "sent": "This G value aggregated value to measure how well we're adhering to the constraints overall.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use this in our final metric.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So constrained DIC CBSE is first BIC which gives us the fit term in the complexity term and then we add this constraint here instrum.",
                    "label": 0
                },
                {
                    "sent": "It is normalized by 4 L squared.",
                    "label": 0
                },
                {
                    "sent": "This is the maximum value that this value can take on.",
                    "label": 0
                },
                {
                    "sent": "So this is just putting it into the same range as the fit term RSS over these two values, the fit term and the constraint adherence term are then balanced by this Lambda term that we had before, which is the belief that the expert has in their constraint matrix so.",
                    "label": 1
                },
                {
                    "sent": "We have these three terms.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The most important thing to remember is that it combines three things, has BICS, which contains complexity and cluster fit.",
                    "label": 1
                },
                {
                    "sent": "It also has this aggregated G value, which is how well we can hear constraints, and CBSE is the blending of these three things.",
                    "label": 1
                },
                {
                    "sent": "So let's go into an exam.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, that kind of ties all of us together.",
                    "label": 0
                },
                {
                    "sent": "On the left we have this data set is very simple.",
                    "label": 0
                },
                {
                    "sent": "It has four Gaussian clusters.",
                    "label": 0
                },
                {
                    "sent": "Two, they were arbitrarily chosen to produce two classes, one red, 1 blue, and if you were to perform them on this, you would expect there to be.",
                    "label": 0
                },
                {
                    "sent": "Two clusterings where you would have the closest closest instances together, so this has the best fit.",
                    "label": 0
                },
                {
                    "sent": "If we had strong constraints for the original classes with red and blue, and we would hope to produce the clustering on the right where we keep the classes together.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's consider different situations where we have different matrices.",
                    "label": 0
                },
                {
                    "sent": "In this example, we have very strong constraints an.",
                    "label": 0
                },
                {
                    "sent": "The constraints for each class are near one, and so they end up getting put together.",
                    "label": 0
                },
                {
                    "sent": "We would hope that.",
                    "label": 0
                },
                {
                    "sent": "The number of clusters that the metric tells us is ideal would be too, because we have a strong constraint between these classes.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In another example, we have weak constraints and we revert back to the original M clustering.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Here we would hope that we would have 4.",
                    "label": 0
                },
                {
                    "sent": "Because there are actually 4 very clear gas and distributions here, and we hope that K would come out to foreign.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Final metric and so this is what we find with strong constraints.",
                    "label": 0
                },
                {
                    "sent": "We have K is equal to 2.",
                    "label": 0
                },
                {
                    "sent": "Anne, with the constraints we end up with four.",
                    "label": 0
                },
                {
                    "sent": "We're using the criterion.",
                    "label": 0
                },
                {
                    "sent": "So with this framework, let's see how it does.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With some real data, the remote sensing data set we saw a little bit before 17 classes.",
                    "label": 0
                },
                {
                    "sent": "Things like agriculture.",
                    "label": 0
                },
                {
                    "sent": "We gave them two clusterings.",
                    "label": 0
                },
                {
                    "sent": "We gave them an EM clustering and a clustering based on our CPC method and we asked them blindly to look at them to look at both of them without asking in advance without telling them in advance which was which.",
                    "label": 0
                },
                {
                    "sent": "So we got some.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using results, this is an area centered around New England, Montreal, and primarily.",
                    "label": 1
                },
                {
                    "sent": "It consists of deciduous and mixed forest and what we find is that both CBC and EM end up merging these two classes together because the underlying features didn't support this.",
                    "label": 0
                },
                {
                    "sent": "And there's the constraints weren't strong enough to keep them apart, so they ended up merging together.",
                    "label": 0
                },
                {
                    "sent": "And this is this actually validated hypothesis that are experts had had before the project started.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In addition, here is an area of agriculture in Iowa.",
                    "label": 0
                },
                {
                    "sent": "This is in black and white because it didn't show up in the slides.",
                    "label": 0
                },
                {
                    "sent": "What the algorithm found was that you could split this into two classes because the features were pretty well separated and the constraints weren't that strong along the diagonal.",
                    "label": 0
                },
                {
                    "sent": "To keep this together.",
                    "label": 0
                },
                {
                    "sent": "When our experts examine this, they actually found that the two classes that were split into were primarily corn versus wheat.",
                    "label": 0
                },
                {
                    "sent": "And this ended up being a pretty interesting result.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, we hope that EM and CPC don't end up doing the same thing, and this is actually true over much of the map in this instance, this is an area over Mexico in the desert where we have two classes and IGP that aren't very well separated by the features.",
                    "label": 0
                },
                {
                    "sent": "For EM it didn't find this structure because it was because it was close together.",
                    "label": 0
                },
                {
                    "sent": "Ended up merging these two classes into one, whereas CPC because there was a strong constraint to keep them apart.",
                    "label": 0
                },
                {
                    "sent": "Ended up keeping the structure and retaining what we had before, which was desirable.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, we have this framework to redefine our classes to use the old labels that we had before and not waste a lot of the great work that's gone into labeling these and be able to inject some of the expert preferences and be able to guide these constraints in the right way.",
                    "label": 0
                },
                {
                    "sent": "Because of this representation, as a byproduct, we were able to reduce the computation from over and squared over now and.",
                    "label": 0
                },
                {
                    "sent": "We later were able to come up with a valuation metric that allowed us to.",
                    "label": 0
                },
                {
                    "sent": "Compare clustering results and determine the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "And finally we had some promising results in remote sensing that's being continued at both BU and Tufts now, so.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "Respect.",
                    "label": 0
                },
                {
                    "sent": "Yeah it should.",
                    "label": 0
                },
                {
                    "sent": "Sorry the question is has a scale with dimensionality it should scale in the same way that M does its.",
                    "label": 0
                },
                {
                    "sent": "It's complexity is generally is is pretty much determined by the number of instances in the number of labels, so the complexity in terms of number of features is not a significant impact on the final result.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you for attending.",
                    "label": 0
                }
            ]
        }
    }
}