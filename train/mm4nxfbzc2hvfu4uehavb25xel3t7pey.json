{
    "id": "mm4nxfbzc2hvfu4uehavb25xel3t7pey",
    "title": "An Efficient Algorithm For Weak Hierarchical Lasso",
    "info": {
        "author": [
            "Yashu Liu, The Biodesign Institute, Arizona State University"
        ],
        "published": "Oct. 8, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_liu_direct_optimization/",
    "segmentation": [
        [
            "Hello everyone.",
            "I mean, I'm sure you from Arizona State University and this is joint work with Doctor J One and my advisor Doctor GPU."
        ],
        [
            "In my talk, I will first briefly introduce the regression models with interactions and related related issues and challenges, and then I will briefly talk about weak hierarchical assault, which is an effective approach of modeling nonlinear regression models with interactions.",
            "Since the problem is nonconvex and it is really challenging to solve, we propose an efficient algorithm to directly solve it.",
            "And I will also present some experimental results and I will summarize my talk at the end."
        ],
        [
            "Linear regression is widely used tool in determining areas and the machine learning areas.",
            "So in regression model the outcome Y can be modeled by linear combination of features and a noise term.",
            "Here the outcome Y is scalar, an feature feature X is a vector and the coefficient W is also a vector as noise.",
            "Epsilon is a scalar."
        ],
        [
            "However, regression models with only linear effects may not be sufficient in many applications.",
            "One effective way to capture the non linearity of the data is to include interactions.",
            "In mathematical form we simply as X transpose QX into the model and X is still the feature vector and Q is a square coefficient matrix.",
            "So IGS entry of Q represent the coefficient of interaction between feature ion feature J and we typically call the linear effects as a main facts."
        ],
        [
            "There are two major issues of using interactions for regression models.",
            "The first one is that including interactions will lead to Ultra high dimensionality.",
            "For example, if you have 100 features, there will be 10,000 of interactions, which is, which is a huge increase in terms of dimensionality and 2nd typically hierarchical structure between main effects and interaction effects is very effective to constrain the search space.",
            "And it typically gives very good interpretation and the explanation of the results.",
            "However, the hierarchical structural estimator is very difficult to obtain."
        ],
        [
            "Recently there recently regression models with interactions.",
            "He has received increasing attention and there is a bunch of research work targeting on learning sparse hierarchical structural estimators for such models and one."
        ],
        [
            "Of the most important and effective model is weak hierarchical assault.",
            "Before introducing it, let's first talk about the weak hierarchy.",
            "We Kuroki means that an interaction is selected only if at least one of the main facts is selected.",
            "In math form it is the coefficient of the coefficient of the interaction between feature I.",
            "An feature JQIG is non zero only if the coefficient of coefficient of the ice feature WI is non 0 or the coefficient of the JS feature is not zero.",
            "Let's give an illustration.",
            "Here we are given three individual features, age, gender, and MSE.",
            "They are represented by the red discs, and there are three interaction terms between them.",
            "The interaction between age and gender, the interaction between H and mercy, and the interaction between gender and MSE.",
            "If the features, gender and MSE excluded from the model, then according to the week hierarchical structure, the interaction between gender and MSE will be also removed from the model.",
            "However, their interactions with H may still be in the Model B cause the feature edges selected here OK."
        ],
        [
            "In week hierarchical assault.",
            "So weak hierarchical constraints are proposed to guarantee the week hierarchical structure.",
            "In math form, it is the one norm of the JS column of Q is upper bounded by the absolute value of the JS entry of W. Lasky also give an illustration to explain how this week hierarchical constraints can guarantee the week hierarchical structure between man effects and interactions.",
            "Ox.",
            "Assume that we are given two coefficients, so W is the coefficient vector for individual features.",
            "The main facts and the Q is the coefficient matrix for interactions.",
            "Here we are given 5 features, an 12M5, so W is a 5 dimensional vector and Q is a 505 square matrix.",
            "Let's"
        ],
        [
            "So there when she equals to one, so we consider only the first entry of W and the first column of 1st column of Q on the right, we give the graph structure, assumes the first feature M1 is removed from the model.",
            "Then the first entry of W will be 0.",
            "We use a white block to represent the zero entry.",
            "And according to the weak hierarchical constraints, the first column of Q will be all the rules.",
            "Let's consider when she calls 22.",
            "We consider the second entry of W and the second column of Q assumes this time M2 is selected in the model.",
            "Then the second entry of W will be non 0.",
            "And according to the weak hierarchical constraints, the interactions associated with the second feature M2 may or may not be in the model.",
            "OK, in this case the 2nd, the 4th of 5th interactions are removed and the first and last interactions.",
            "Cluding the model."
        ],
        [
            "OK, let's introduce week hierarchical assault.",
            "Lets the air of QB the loss function for regression models with interaction.",
            "Then we hierarchy colossal formulation has the following form.",
            "Besides, we can't hierarchical constraints in the objective.",
            "We have the loss function and the loss of penalties on W&Q.",
            "However, so weak hierarchical constraints make this problem nonconvex, which is very challenging to solve."
        ],
        [
            "Existing work proposed proposed convex relaxation on this non convex problem to make it convex.",
            "However in theory.",
            "Without any additional assumptions, so weak hierarchical constraints cannot be guaranteed by such formulation."
        ],
        [
            "And in our work we show how we can solve this week hierarchical source, the nonconvex problem directly and efficiently.",
            "First, we propose to use approximate algorithm to solve the nonconvex weak hierarchical assault.",
            "One key steps OK subroutine is to compute compute the proximal operator.",
            "In our work, we show that the proximal operator associated with a non convex, weaker colossal formulation admits closed form solution.",
            "And, however, a straightforward implementation of computing the.",
            "Proximal operator proximal operator subproblem will take quadratic time an by exploiting the special structure of the same problem, we accelerate the corresponding computation from quadratic to linear reasoning and."
        ],
        [
            "Here, let's take some high level ideas of the technical.",
            "Here is a weak hierarchy colossal formulation as mentioned before and here you can derive the proximal operator as the following form."
        ],
        [
            "Instead of directly solved solving the unknown coefficient W&Q, we first factorize the unknown coefficients by its science and magnitudes.",
            "This is actually the key idea to derive the closed form solution of W&Q.",
            "For example, there are no coefficient W as elementwise multiplication of the side variables SW and the magnitude variables W shield and the matrix Q coefficient Q can be written as.",
            "Element wise, multiplication of the sign variables SQ and the magnitude variables Q~"
        ],
        [
            "OK, since the proximal operator can be coupled and by the factorization we can write the subproblem of the proximal operator in the following form.",
            "And we will solve the sign variables and the magnitude variables."
        ],
        [
            "Let's take a look at how we solve the same variables by very simple mathematics.",
            "Only three lines mathematics.",
            "We derive that in order to achieve the minimum, the sign of the unknown coefficient must be the science of vector we and the science of unknown coefficient matrix Q.",
            "Should be the same as the size of matrix U in the proximal operator if you remember.",
            "Oh"
        ],
        [
            "OK then, so some variables has closed form solutions and we can further obtain the magnitude variables by solving the following.",
            "Problem and we show that the magnitude variables in this problem also has closed form solutions."
        ],
        [
            "However, a straightforward implementation to solve the magnitude variables in the subproblem will take quadratic attractive time and which is not desired.",
            "An not scalable to large scale problems, and we exploit the special structure of the subproblem and further develop an efficient algorithm to reduce the corresponding time complexity from quadratic to linear rhythmic.",
            "Since this is highly involved and we skip all the mathematics and you can find the details in our KDD paper."
        ],
        [
            "Or you can also talk with me in my post office session.",
            "And let's see, let's show some experimental results.",
            "We compare our algorithm with the convex week hierarchical ASO.",
            "And the running time of the number of iterations achieving the same objective are shown in this plot.",
            "Figures and the first rule correspond to the running time and the 2nd row correspond to the iterations and both running time and iterations are showing the vertical axis and the penalty amounts actually correspond to different penalty parameters are showing the horizontal axis and different columns correspond to different synthetic datasets.",
            "Where the ground truth sparsity is different.",
            "The blue curves correspond to the performance of Convex Week hierarchical also, and the orange curves correspond to the performance of our algorithm as you.",
            "As we can see, the results show that our algorithm is much faster than the convex week hierarchical assault."
        ],
        [
            "Let's compare the recovery performances.",
            "The sensitivity of recovery, which is actually the accuracy of the recovery.",
            "Non zero entries in the coefficients is shown in the following figure.",
            "So sensitivity is showing the vertical axis the different number of non 0 main facts.",
            "Actually different problem setups are showing the horizontal axis and the results show that the nonconvex with hierarchical Russell has overall better recovery.",
            "Performance."
        ],
        [
            "We also conduct the comparisons on real datasets to any data set and in this task we are trying to use clinical features.",
            "an MRI features to predict different subtypes of MCI MCI patients, and this is actually the classification task and we modify the least square loss to logistic loss.",
            "An so prediction performance showing the table.",
            "And we can see the week, hierarchical, uh, so overall gives better and more balanced performance than other baseline methods such as random forest, SVM and the nonconvex week hierarchical also gives better solutions than the convex with hierarchical us all."
        ],
        [
            "OK, in our in our work we study the week hierarchical also which is popular for modeling nonlinear regression models with interactions.",
            "And this problem is actually non convex and it is hard to solve an hour work.",
            "We propose an algorithm to directly solve the week hierarchical assault and we show the associated proximal operator admits closed form solution an.",
            "We further develop an efficient algorithm to reduce the computation of each subproblem.",
            "Of the proximal operator from quadratic to linear rhythmic, we conduct experiments to demonstrate the effective effectiveness and efficiency of our algorithm."
        ],
        [
            "In the future, we intend to apply this nonconvex week hierarchical also for more challenging applications such as depression study, and we are also going to try to extend our techniques to solve strong hierarchical muscle, which is another very popular approach to modeling the regression models with interactions."
        ],
        [
            "And thank you very much.",
            "Any questions?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm sure you from Arizona State University and this is joint work with Doctor J One and my advisor Doctor GPU.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In my talk, I will first briefly introduce the regression models with interactions and related related issues and challenges, and then I will briefly talk about weak hierarchical assault, which is an effective approach of modeling nonlinear regression models with interactions.",
                    "label": 1
                },
                {
                    "sent": "Since the problem is nonconvex and it is really challenging to solve, we propose an efficient algorithm to directly solve it.",
                    "label": 1
                },
                {
                    "sent": "And I will also present some experimental results and I will summarize my talk at the end.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Linear regression is widely used tool in determining areas and the machine learning areas.",
                    "label": 1
                },
                {
                    "sent": "So in regression model the outcome Y can be modeled by linear combination of features and a noise term.",
                    "label": 0
                },
                {
                    "sent": "Here the outcome Y is scalar, an feature feature X is a vector and the coefficient W is also a vector as noise.",
                    "label": 0
                },
                {
                    "sent": "Epsilon is a scalar.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, regression models with only linear effects may not be sufficient in many applications.",
                    "label": 1
                },
                {
                    "sent": "One effective way to capture the non linearity of the data is to include interactions.",
                    "label": 1
                },
                {
                    "sent": "In mathematical form we simply as X transpose QX into the model and X is still the feature vector and Q is a square coefficient matrix.",
                    "label": 0
                },
                {
                    "sent": "So IGS entry of Q represent the coefficient of interaction between feature ion feature J and we typically call the linear effects as a main facts.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are two major issues of using interactions for regression models.",
                    "label": 0
                },
                {
                    "sent": "The first one is that including interactions will lead to Ultra high dimensionality.",
                    "label": 1
                },
                {
                    "sent": "For example, if you have 100 features, there will be 10,000 of interactions, which is, which is a huge increase in terms of dimensionality and 2nd typically hierarchical structure between main effects and interaction effects is very effective to constrain the search space.",
                    "label": 0
                },
                {
                    "sent": "And it typically gives very good interpretation and the explanation of the results.",
                    "label": 0
                },
                {
                    "sent": "However, the hierarchical structural estimator is very difficult to obtain.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recently there recently regression models with interactions.",
                    "label": 0
                },
                {
                    "sent": "He has received increasing attention and there is a bunch of research work targeting on learning sparse hierarchical structural estimators for such models and one.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the most important and effective model is weak hierarchical assault.",
                    "label": 0
                },
                {
                    "sent": "Before introducing it, let's first talk about the weak hierarchy.",
                    "label": 0
                },
                {
                    "sent": "We Kuroki means that an interaction is selected only if at least one of the main facts is selected.",
                    "label": 1
                },
                {
                    "sent": "In math form it is the coefficient of the coefficient of the interaction between feature I.",
                    "label": 0
                },
                {
                    "sent": "An feature JQIG is non zero only if the coefficient of coefficient of the ice feature WI is non 0 or the coefficient of the JS feature is not zero.",
                    "label": 0
                },
                {
                    "sent": "Let's give an illustration.",
                    "label": 0
                },
                {
                    "sent": "Here we are given three individual features, age, gender, and MSE.",
                    "label": 0
                },
                {
                    "sent": "They are represented by the red discs, and there are three interaction terms between them.",
                    "label": 0
                },
                {
                    "sent": "The interaction between age and gender, the interaction between H and mercy, and the interaction between gender and MSE.",
                    "label": 0
                },
                {
                    "sent": "If the features, gender and MSE excluded from the model, then according to the week hierarchical structure, the interaction between gender and MSE will be also removed from the model.",
                    "label": 0
                },
                {
                    "sent": "However, their interactions with H may still be in the Model B cause the feature edges selected here OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In week hierarchical assault.",
                    "label": 0
                },
                {
                    "sent": "So weak hierarchical constraints are proposed to guarantee the week hierarchical structure.",
                    "label": 1
                },
                {
                    "sent": "In math form, it is the one norm of the JS column of Q is upper bounded by the absolute value of the JS entry of W. Lasky also give an illustration to explain how this week hierarchical constraints can guarantee the week hierarchical structure between man effects and interactions.",
                    "label": 0
                },
                {
                    "sent": "Ox.",
                    "label": 0
                },
                {
                    "sent": "Assume that we are given two coefficients, so W is the coefficient vector for individual features.",
                    "label": 0
                },
                {
                    "sent": "The main facts and the Q is the coefficient matrix for interactions.",
                    "label": 0
                },
                {
                    "sent": "Here we are given 5 features, an 12M5, so W is a 5 dimensional vector and Q is a 505 square matrix.",
                    "label": 0
                },
                {
                    "sent": "Let's",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there when she equals to one, so we consider only the first entry of W and the first column of 1st column of Q on the right, we give the graph structure, assumes the first feature M1 is removed from the model.",
                    "label": 0
                },
                {
                    "sent": "Then the first entry of W will be 0.",
                    "label": 0
                },
                {
                    "sent": "We use a white block to represent the zero entry.",
                    "label": 0
                },
                {
                    "sent": "And according to the weak hierarchical constraints, the first column of Q will be all the rules.",
                    "label": 1
                },
                {
                    "sent": "Let's consider when she calls 22.",
                    "label": 0
                },
                {
                    "sent": "We consider the second entry of W and the second column of Q assumes this time M2 is selected in the model.",
                    "label": 0
                },
                {
                    "sent": "Then the second entry of W will be non 0.",
                    "label": 1
                },
                {
                    "sent": "And according to the weak hierarchical constraints, the interactions associated with the second feature M2 may or may not be in the model.",
                    "label": 0
                },
                {
                    "sent": "OK, in this case the 2nd, the 4th of 5th interactions are removed and the first and last interactions.",
                    "label": 0
                },
                {
                    "sent": "Cluding the model.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's introduce week hierarchical assault.",
                    "label": 0
                },
                {
                    "sent": "Lets the air of QB the loss function for regression models with interaction.",
                    "label": 1
                },
                {
                    "sent": "Then we hierarchy colossal formulation has the following form.",
                    "label": 0
                },
                {
                    "sent": "Besides, we can't hierarchical constraints in the objective.",
                    "label": 0
                },
                {
                    "sent": "We have the loss function and the loss of penalties on W&Q.",
                    "label": 1
                },
                {
                    "sent": "However, so weak hierarchical constraints make this problem nonconvex, which is very challenging to solve.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Existing work proposed proposed convex relaxation on this non convex problem to make it convex.",
                    "label": 0
                },
                {
                    "sent": "However in theory.",
                    "label": 0
                },
                {
                    "sent": "Without any additional assumptions, so weak hierarchical constraints cannot be guaranteed by such formulation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in our work we show how we can solve this week hierarchical source, the nonconvex problem directly and efficiently.",
                    "label": 0
                },
                {
                    "sent": "First, we propose to use approximate algorithm to solve the nonconvex weak hierarchical assault.",
                    "label": 1
                },
                {
                    "sent": "One key steps OK subroutine is to compute compute the proximal operator.",
                    "label": 1
                },
                {
                    "sent": "In our work, we show that the proximal operator associated with a non convex, weaker colossal formulation admits closed form solution.",
                    "label": 0
                },
                {
                    "sent": "And, however, a straightforward implementation of computing the.",
                    "label": 1
                },
                {
                    "sent": "Proximal operator proximal operator subproblem will take quadratic time an by exploiting the special structure of the same problem, we accelerate the corresponding computation from quadratic to linear reasoning and.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, let's take some high level ideas of the technical.",
                    "label": 0
                },
                {
                    "sent": "Here is a weak hierarchy colossal formulation as mentioned before and here you can derive the proximal operator as the following form.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instead of directly solved solving the unknown coefficient W&Q, we first factorize the unknown coefficients by its science and magnitudes.",
                    "label": 1
                },
                {
                    "sent": "This is actually the key idea to derive the closed form solution of W&Q.",
                    "label": 1
                },
                {
                    "sent": "For example, there are no coefficient W as elementwise multiplication of the side variables SW and the magnitude variables W shield and the matrix Q coefficient Q can be written as.",
                    "label": 0
                },
                {
                    "sent": "Element wise, multiplication of the sign variables SQ and the magnitude variables Q~",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, since the proximal operator can be coupled and by the factorization we can write the subproblem of the proximal operator in the following form.",
                    "label": 0
                },
                {
                    "sent": "And we will solve the sign variables and the magnitude variables.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's take a look at how we solve the same variables by very simple mathematics.",
                    "label": 1
                },
                {
                    "sent": "Only three lines mathematics.",
                    "label": 0
                },
                {
                    "sent": "We derive that in order to achieve the minimum, the sign of the unknown coefficient must be the science of vector we and the science of unknown coefficient matrix Q.",
                    "label": 1
                },
                {
                    "sent": "Should be the same as the size of matrix U in the proximal operator if you remember.",
                    "label": 0
                },
                {
                    "sent": "Oh",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK then, so some variables has closed form solutions and we can further obtain the magnitude variables by solving the following.",
                    "label": 0
                },
                {
                    "sent": "Problem and we show that the magnitude variables in this problem also has closed form solutions.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, a straightforward implementation to solve the magnitude variables in the subproblem will take quadratic attractive time and which is not desired.",
                    "label": 1
                },
                {
                    "sent": "An not scalable to large scale problems, and we exploit the special structure of the subproblem and further develop an efficient algorithm to reduce the corresponding time complexity from quadratic to linear rhythmic.",
                    "label": 0
                },
                {
                    "sent": "Since this is highly involved and we skip all the mathematics and you can find the details in our KDD paper.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or you can also talk with me in my post office session.",
                    "label": 0
                },
                {
                    "sent": "And let's see, let's show some experimental results.",
                    "label": 0
                },
                {
                    "sent": "We compare our algorithm with the convex week hierarchical ASO.",
                    "label": 1
                },
                {
                    "sent": "And the running time of the number of iterations achieving the same objective are shown in this plot.",
                    "label": 0
                },
                {
                    "sent": "Figures and the first rule correspond to the running time and the 2nd row correspond to the iterations and both running time and iterations are showing the vertical axis and the penalty amounts actually correspond to different penalty parameters are showing the horizontal axis and different columns correspond to different synthetic datasets.",
                    "label": 0
                },
                {
                    "sent": "Where the ground truth sparsity is different.",
                    "label": 0
                },
                {
                    "sent": "The blue curves correspond to the performance of Convex Week hierarchical also, and the orange curves correspond to the performance of our algorithm as you.",
                    "label": 0
                },
                {
                    "sent": "As we can see, the results show that our algorithm is much faster than the convex week hierarchical assault.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's compare the recovery performances.",
                    "label": 1
                },
                {
                    "sent": "The sensitivity of recovery, which is actually the accuracy of the recovery.",
                    "label": 0
                },
                {
                    "sent": "Non zero entries in the coefficients is shown in the following figure.",
                    "label": 0
                },
                {
                    "sent": "So sensitivity is showing the vertical axis the different number of non 0 main facts.",
                    "label": 0
                },
                {
                    "sent": "Actually different problem setups are showing the horizontal axis and the results show that the nonconvex with hierarchical Russell has overall better recovery.",
                    "label": 0
                },
                {
                    "sent": "Performance.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also conduct the comparisons on real datasets to any data set and in this task we are trying to use clinical features.",
                    "label": 0
                },
                {
                    "sent": "an MRI features to predict different subtypes of MCI MCI patients, and this is actually the classification task and we modify the least square loss to logistic loss.",
                    "label": 0
                },
                {
                    "sent": "An so prediction performance showing the table.",
                    "label": 0
                },
                {
                    "sent": "And we can see the week, hierarchical, uh, so overall gives better and more balanced performance than other baseline methods such as random forest, SVM and the nonconvex week hierarchical also gives better solutions than the convex with hierarchical us all.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, in our in our work we study the week hierarchical also which is popular for modeling nonlinear regression models with interactions.",
                    "label": 1
                },
                {
                    "sent": "And this problem is actually non convex and it is hard to solve an hour work.",
                    "label": 1
                },
                {
                    "sent": "We propose an algorithm to directly solve the week hierarchical assault and we show the associated proximal operator admits closed form solution an.",
                    "label": 1
                },
                {
                    "sent": "We further develop an efficient algorithm to reduce the computation of each subproblem.",
                    "label": 0
                },
                {
                    "sent": "Of the proximal operator from quadratic to linear rhythmic, we conduct experiments to demonstrate the effective effectiveness and efficiency of our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the future, we intend to apply this nonconvex week hierarchical also for more challenging applications such as depression study, and we are also going to try to extend our techniques to solve strong hierarchical muscle, which is another very popular approach to modeling the regression models with interactions.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                }
            ]
        }
    }
}