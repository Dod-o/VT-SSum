{
    "id": "bxuuh4cnp5wii3s2hdclq3zcr2im2uib",
    "title": "Efficient Ontology-Based Data Integration with canonical IRIs",
    "info": {
        "author": [
            "Diego Calvanese, Free University of Bozen-Bolzano"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_calvanese_canonical_IRIs/",
    "segmentation": [
        [
            "Yes, so this is joint work with some people in Balzano who we?",
            "Actually, the only one still involves an American likes used to be important, and he's now in Rakuten in Japan and with some people in Oslo working as start or Doug Martin and also with Dimitri from Athens.",
            "So."
        ],
        [
            "What is the motivation for this work?",
            "It starts from a common problem, which is that of accessing heterogeneous data, which is a challenging problem in large corporations.",
            "In public administrations, in many settings, and I'm showing here an example from Statoil which is the Norwegian oil Company actually changed name.",
            "By the way, it's uncalled starter anymore, but I still you started because it's more known under this name and we work together with them and specifically together with the Department that is responsible for doing exploration.",
            "So they.",
            "Interested in exploring you places where they can dig and so they have to analyze the data from previous Diggins they have done and from previous oil wells they have explored and this is done by geologists and this geologists collect essentially through this.",
            "Through this explorations on huge amounts of data and this data is stored in very large databases which not only large but they also quite literal genius.",
            "So they are composed of.",
            "Thousands of relational tables, large amounts of data and these experts have to access these these databases.",
            "However, they cannot do it themselves, so they don't really know how to formulate the queries over these databases.",
            "So what they do?"
        ],
        [
            "They formulate the queries in natural language and go to data management experts and ask these experts to formulate these queries in SQL and then the queries are executed.",
            "The answers are given to geologists to elaborate them and then the cycle repeats and this causes a huge loss of time and actually huge cost in such companies.",
            "So estimations that 30 to 70% depending on the setting of the time of experts were highly paid, is spent on tasks that are not really their task because these are geologists, they're not data management experts.",
            "So how can one address this issue?"
        ],
        [
            "Now the approach would be proposed, and then we actually realized in Statoil is one that relies on this ontology based data integration padding.",
            "But the idea is to build a system in which the experts are not presented with the data source, but they presented with a concept representation of the data sources in terms of an ontology and these ontologies links to the actual data sources in the declarative way through mappings, and then the idea is that query is posed over the ontology and the results are given to the user in terms that he can understand.",
            "So what we achieve in this way is what is we could call logic transparency in accessing the data so that the user doesn't really know or need to know how the data is organized and stored in the sources but only sees this concept of high level representation in the language that the user understand.",
            "Now to realize this is challenging."
        ],
        [
            "In fact, OK, here's a short example that I want to give a from.",
            "This is a startled domain and it's also running example.",
            "They use through the presentation, so in this example we have two databases.",
            "They recall national incorporated used abbreviations, each storing for simplicity just one table.",
            "So we have a table in Caldwell Bar in the national database and table called drilling OPS in the corporate database, and these tables store related information intuitively so.",
            "The names of the of the wellbores are listed here in blue.",
            "These are the keys of these tables and they listed here or some blue and now you can see that intuitively there should be a relationship between the names.",
            "Here.",
            "There they are written in a different way, but there is a way to map these two.",
            "For example, this wellbore corresponds to this webinar.",
            "National database corresponds to this variable in the drilling operation database and their different information associated to this well, both in the different database.",
            "For example, here we have the wellbore field and the purpose.",
            "The purpose is repeatedly.",
            "Essentially it's called reason here.",
            "Here we have also the date of the of the drilling of the start of the drilling.",
            "For this well bore.",
            "Now in this OBD setting what we do, we specify these mappings that connect these databases to the concept representation of the domain of interest and now in these mappings we have two parts.",
            "We have a part that is a query source query in SQL over the database that refers, for example is the query for this first table.",
            "And this query extracts the information.",
            "In this case it's very simple query just extracts the whole table and the values extracted from the table.",
            "I used to populate facts to create trippers in the data that is shown at the level of the ontologies generated delivery ontology.",
            "For example, the Wellbore Field Direct generates a literal well both field.",
            "Here in these mappings, this is the source part and this is the target part that is specified in terms of RDF triples templates, actually.",
            "Because we use the variables from, the answer varies from the query in these templates.",
            "What is important?",
            "So as an example here, suppose that we have this mapping executed over this database.",
            "This would generate or these two mappings would generate the set of triples that we find here.",
            "For example, the first query would generate, among others, these two.",
            "These two triples here, you see that it populates the two triples with predicate in field and with predicate purpose.",
            "And what is important to note also is that in these mappings in the source part.",
            "So in the target part we have not only directly developers, but also what are called IRI template.",
            "So we construct from the values retrieved from the database iris of the objects that populate the ontology.",
            "So these are the templates have a pattern that makes use of the variables retrieved from the source.",
            "For example in this case this is IRA template to generate the for the first app from this table.",
            "I have just depicted the answer for the first Apple generate these two papers in which you see and I recreated through this template, Iris created using the value retrieved here in this position from the table.",
            "OK, so that's the idea of these mappings.",
            "They create an RDF graph.",
            "This RDF graph is not really materialized, it's it's typically kept."
        ],
        [
            "Airport, so the idea of this approach is not to materialize the graph because in general this would be too huge.",
            "It's unmanageable if you have terabytes of data you can.",
            "It's difficult to manage this, or you don't want to do it because of freshness and keeping up to date.",
            "So the idea is different.",
            "The idea is that the query that the user poses of the ontology is transformed through various steps.",
            "First rewriting step take into account the ontology a second so called unfolding step take into account the mappings.",
            "Is transformed into an SQL query.",
            "This SQL query is evaluated over the data sources and the relational answers we get is then further transformed using the the the templates.",
            "The Irishman Place in the mappings to transform to obtain the RDF triples that the the answer to the query that is then shipped to the user.",
            "So this is the idea of the of how these obedient OBD systems on target based data integration and data access systems work by rewriting queries."
        ],
        [
            "Now what are the issues in the integration setting that we're looking at?",
            "The point is that the information about a single real world entity might be distributed as we have seen an example over various tables.",
            "So how do we deal with it?",
            "So we need to do what is called anterior solution.",
            "So we need to actually understand which are the records in the various tables that match with each other in correspond to each other.",
            "Now in this paper we do not address this specific problem, so we assume that this information is somehow available and we'll see how this can be made available, but we're not really concerned with addressing this problem.",
            "This is per share whole area of research in the context of data integrations, how to measure entities?",
            "The second aspect is then how to.",
            "Once we have even match the the entities, how to do integrated querying over the various data sources.",
            "Take into account the correspondences between the entities.",
            "So the idea is that we answer to queries.",
            "Need to integrate the entities, and this is actually what we are concerned with in this paper."
        ],
        [
            "So let's see the example that we had before.",
            "So this is just repeating what we had there and internally as we have seen since the information about these two one well boy stored in these two tables.",
            "If we answer if you ask a sparkle query that tries to do a join over these two so that somehow tries to access both the infeed information and the drilling started information which was retrieved through the mappings.",
            "Now if we use the same variable here and try to do a join will get no answer because the infield information is retrieved from this first.",
            "Table the drilling start information is retrieved from the second table, but the identifies a different, so actually we cannot really join this verbal so intuitively would like to have this answer here.",
            "For example this answer where we choose for the variable W the identifying the second table and we obtain the field and drilling starting date.",
            "But in fact we do not get this answer because this joint is not really performed.",
            "So that's what we want to add this.",
            "We want to address an efficient way of getting this kind of."
        ],
        [
            "This is now So what we need to do is we need mechanisms to merge the data.",
            "So the first thing that one could think of is to physically merge the data like it is done in extractor.",
            "For Mindy TL approaches where the data is extracted and actually integrated.",
            "For example in a data warehouse.",
            "But this is not really a practical approach in many scenarios because we might not have control over the data sources.",
            "We might not even be able to do this and also this creates issues of freshness, privacy and legal aspects related to the data.",
            "So it's not always possible to pursue this approach.",
            "The other approaches to do actually to follow up on this virtual approach of OH BDA and virtually merge the data.",
            "For example, using the standard approach in the semantic web, which is declare different iris to be equal through same as which is the standard way of doing it in owl.",
            "So now what is the problem there?",
            "The problem is that same as using just same as.",
            "Might cause an issue due to a large explosion of the number of answers.",
            "Consider query that returns an N tuple of answer variables and each of the elements of dissent.",
            "Apple.",
            "We have two possibilities because because we have declared the two values to be equivalent.",
            "Then if we choose all the possible combinations where each of the components we choose, either one or the other value, we get an exponential number.",
            "If we have North and Arity and query, we get 2 to the end just from this.",
            "Single tap are we get 2 to the end.",
            "Different answers and this is actually a practical problem so that's what we would like to avoid.",
            "Also because not only because we get a lot of redundant answers but also this redundant answers are difficult to interpret and so this approach is in many practical cases not really feasible as well and that's where we come in with the approach that we propose in this work here, namely to substitute this same as."
        ],
        [
            "Is based approach by somehow I simple approach into the simple approach which is that of using Canonical iris for the objects extracted from the database.",
            "So instead of retrieving all the possibilities and declaring them to be equal what we do is we use for each type of information a Canonical way of representing the information at the level of the ontology through an IRI.",
            "And so we have a single Canonical representation and this allows to break the symmetry which causes this exponential blowup and get.",
            "A more compact answer that can also be computed more efficiently.",
            "So what we do is, we assume that the a box.",
            "So the level of data retreated level deontology, augmented with a set of Canonical area assertions using a property can only can I re of that somehow replaces the same as but declaring instead of 1 two irizar declared to be the same.",
            "We declare camera off saying which is the Canonical IRI, for another one.",
            "For example we might choose here.",
            "To represent to use the Canonical area for this object created at the level of the ontology.",
            "To represent it.",
            "In fact through these different identifiers, this different IRI.",
            "And this might be the area also for this other object in another database.",
            "Now what we do as an assumption which is practical which is needed for our techniques to work, but is also reasonable, is that each IRI has at most one Canonical iris, so we don't use different Canonical areas for the same object, which is actually exactly the purpose of having Canonical Iris.",
            "So formally we can say that this property can I re office inverse functional in the in the box that we generate?"
        ],
        [
            "Now what we can do is once we have defined set up this setting of Canonical areas what we can.",
            "Define can define a function that associates to each individual economical IRI and the way we do it is if there is an assertion about an individual.",
            "All of this form Canonical IRI of C. Oh, by the way, just on the slides are used interchangeably.",
            "Both the triple notation and the fact notation.",
            "Usually I use the triple notation examples and they use the fact notation in the more formal presentation just for easiness of reading.",
            "So if we have here economically.",
            "The assertion foreign object and sees the quality of oh then thank you.",
            "Then we say that sees the Chronicle is what is returned by this function.",
            "If there is no assertion of this form for an object or the object is itself the Canonical IRI.",
            "For example.",
            "In this case, since for the two objects here we have discounted Larry assertions, then these are the Canonical Diaries.",
            "For this object.",
            "There is no Canonical area search, and so the object itself is its own Canonical library.",
            "And once we have defined this, we can define what we call the Canonical graph, which is actually the representation of the whole data at the level of knowledge of the a box by replacing each IRI with its Canonical IRI.",
            "So in each fact we just use the Canonical eyeballs in.",
            "Class assertions and in property assertions."
        ],
        [
            "Now just as small.",
            "As a small aside, regarding payment regimes, so since we're interested in reasoning with respect to the ontology, we have to deal with sparkle entailment regimes and ingenious parking L entailment entailment regimes, specify how to obtain from an RDF graph and entail graph which is enriched by the consequences of the entailments and we call e.g.",
            "Of E is the entailment redeemed entail graph from G using the Interment regime.",
            "Notice that in general, this graph is an ontology that consider $80.00 and in a box and then that's just the notation that I use to know the answer to sparkle query over graph and then under the entailment regime.",
            "This is how we did.",
            "Note the answer to this park query, so QG is the answer to sparkle query Q under the entailment Ragini and how is it defined is just defined as the answer to the regular query with no entailment regime over the Intel graph so that's.",
            "How sparkle works?",
            "Notice that entailment regimes, by definition, the internal teams only modifies the valuations of basic graph patterns, not that of the other sparkle of operators.",
            "Once we've defined how do how to extend the basic graph patterns, the rest is just obtained by applying the users parcial operators and what we have defined.",
            "Now, in our setting is what we call the Canonical IRI entailment regime and which is an extension of any entailment regime.",
            "So if we have an intelligent regime East, then.",
            "The Canonical Irene Tellement regime E Plus can we define it as the one that is obtained by computing the Canonical graph that we have seen before on this slide and then just applying the entailment regime East over the Canonical graph together with the tee box?",
            "That's how we define this extended entailment regime.",
            "Notice that this internal Jim is defined in a layered way, so somehow.",
            "We first compute the economic graph and then on top of it we apply the entailment regime."
        ],
        [
            "So how this Canonical ireann?",
            "Same as intelligent related to each other?",
            "So we have to say when they are related.",
            "So we have this notion of compliance and essentially the North of compliance tell us tells us that if we have an economically I reassertion between.",
            "So if you say that one is the canal diary of O2 then one or two should be in the same as relation.",
            "And similarly if we have that one and two are in the same as relation, considering also it's transitive, reflexive.",
            "Symmetric closure because same as has these properties.",
            "Then the Canonical object the Canonical IRA for one or two should be the same.",
            "Then these two are compatible and we call this compliant.",
            "We say that.",
            "I said AC of Congress version is compatible, is compliant with a set of same as assertions.",
            "For example, here you see an example of compliant same as and Canonical area assertions.",
            "Notice that in this example we have introduced knew Canonical Iris for some given Iris, so we're not forced to use existing iris as the Canonical ones.",
            "We can introduce.",
            "Also, new ones are talk somehow."
        ],
        [
            "Now so once if we have a set of same as assertions, a set of Canonical area assertions that are that are compliant with each other, then what we have is that the same as entailment regime and the Canonical Irene payment version correspond to each other intuitively stated here.",
            "Intuitively, because the exact formulation is a bit more complicated, don't want to.",
            "Give the details now.",
            "Actually this is even a simplified form than the one that is actually needed, so look at look it up in the paper."
        ],
        [
            "OK, now how do we want to handle this?",
            "Canonical iris semantics.",
            "The idea is we want to exploit essentially the same approach that we exploit in ontology based data integration and access, namely, an approach based on virtualization.",
            "So we want to deal with it by rewriting queries and so the objective is to rewrite a sparkle query and the E plus can entailment regime to a new sparkle query are like all this ad because it stands for the rewriting.",
            "In such a way that the rewriting evaluated on the standard entailment regime gives me the same answers as the original query evaluated and the entailment regime extended with the Canonical IRI intended entailment regime.",
            "Now, in order to obtain this, the first observation is that we need to be a bit careful first, 'cause this Canonical error entailment regime is not monotonic in the sense that if we take basic craft pattern, then under the Canonical area semantics this doesn't behave monotonically.",
            "Thank you.",
            "And why is this the case?",
            "Simply be cause if we obtain an answer to a query before having a Canonical area searching for this query.",
            "And then we add economically.",
            "So sorry before having a Canonical area searching for an individual, then we might obtain this individual as an answer to a query even to a basic graph pattern.",
            "If we then add economically assertion for this individual that, for example, tells us that season allow the Canonical area of this individual A, then will not obtain a anymore as an answer because we buy the semantics of coronavirus should obtain C as an answer, so it's not anymore an answer after having added something to our.",
            "Our knowledge in this sense this entailment regime is not monotonic, so this means that we will not be able to rewrite a basic graph pattern as a basic graph pattern because basic graph patterns are monotonic, so we need in the rewriting.",
            "This tells us that we need to have some nonatomic mechanism, which means some form of negation in the query that we produce."
        ],
        [
            "And in fact, what we have shown is how to introduce this form of medication so that it does the job.",
            "This is just a simple query that one can define and you see the definition here that returns the Canonical IRI for certain object.",
            "So if we ask this query then it will give us for each individual X the Canonical IRI for that individual X and this query just implements the definition that we have seen on the previous slide.",
            "Nothing special, sorry.",
            "This is not meant to be shown.",
            "So what we have is that this query in fact behaves correctly.",
            "So if a pair is in the answer this query, then despair is such that the first element is the Canonical IRI of the second element."
        ],
        [
            "Now given this query as a component, we can actually compute the Canonical I rewriting of sparkle query and here you see how this is done.",
            "Essentially what you have to do is replace each triple pattern in the query intuitively by a joint with this query that returns the Canonical library.",
            "That's the intuition I don't want to go into the detail, this is how it is done.",
            "It's quite natural.",
            "That's what we would naturally need to do, and this is just the formalization of how it is done, and this is what you do.",
            "What you would do in the example that in an example query that we've seen before, the one that was doing the join between the infield and the drilling, started.",
            "And essentially you see that it implements this joint by returning the Canonical IRI for the various variables.",
            "So this transformation deals with each triple pattern singularly and joins it with this query, turning the Canonical area.",
            "That's the intuition."
        ],
        [
            "Now this is the correct way of computing the Canonical iris and to returning the answers under Canonical iris semantics.",
            "But although the size of the written query is linear in the size of the original query, this approach is actually not really feasible and why?",
            "Because the number of variables that we introduced in the not exists clauses.",
            "Sorry, I forgot to say that."
        ],
        [
            "This query that implements the computation of the Canonical reuses does not exist, which is precisely the negation that we needed to overcome the monotonicity.",
            "So the number of variables that appear in these clauses is linear and.",
            "However, for each such variable essentially one needs to scan the whole database, so this is not really feasible in practice.",
            "So which means the query execution time would grow exponentially in the number of variables in the original query.",
            "That's why we have been looking."
        ],
        [
            "Sing for a different approach, namely one that is based on using the mappings that are present in each of the scenario.",
            "So the idea is that we have mappings that I used to feed this Canonical area assertions, and this is a common assumption.",
            "For example, in many organization one has so called master tables which exactly those that somehow relates the information in different parts of the information system of the organization.",
            "And this master tables.",
            "Can be used to populate this Canonical Iris.",
            "Notice that, however, this approach that we suggest does not really rely on the presence of such master table.",
            "It would also work if you have other types of queries that retrieve somehow the Canonical error information at the level of the box is an example installing there we had this master tables and then we can write the queries that just populate this Canonical area.",
            "Assertions from this master tables."
        ],
        [
            "So what we do is, our approach is a proposal that thank you that is based on extending the mappings that we have.",
            "So the regular mapping so that we have in a OBD I integration scenario and embedded in this mapping the information coming from the mappings that compute the Canonical Diaries.",
            "So this is an approach that is actually inspired by similar approach that is used for optimizing query answering.",
            "In ontology based data access that is so called mapping saturation algorithms that are implemented in OBD systems and in order to do So what we need to do is we need to ensure that this property we're assuming before, namely that Canonical IRES inverse functional is actually satisfied and we can do so in this mapping based approach by putting condition on the mappings, namely that."
        ],
        [
            "One that looks at the IRI templates in the mapping assertions and.",
            "The idea is that for each IRA templates that we have in the regular mappings we have at most one mapping assertion in the mappings populating the Canonical iris, that is, that creates a Canonical IRI for that.",
            "I written plate in this way.",
            "If this assumption is satisfied, we also guarantee the inverse functionality was that we need notice.",
            "However, these are strong.",
            "This assumption is actually stronger, but it's actually quite reasonable assumption in practice, so it's not a limitation in practical settings.",
            "And now what we can do is if this assumption is satisfied, we can define a rewriting on the of the mappings and this rewriting is actually implementing by changing the standard mapping assertions, taking into account information coming from the Canonical libraries.",
            "And again here you see how this is done, we need to process each mapping assertion in the regular mapping by taking into account the assertions regarding the Canonical Iris."
        ],
        [
            "And this is what this rewriting approach would give us on our example.",
            "So what you see here is essentially that this rewriting algorithms implements join with the master tables.",
            "In the mappings that you have, so the mappings are enriched with suitable joint operations over the master table.",
            "That's the intuition that you get from this rewriting."
        ],
        [
            "One can show that this is correct, that it gives us so that the query evaluated under the enriched mappings.",
            "Under the enrich mappings which we apply, the rewriting algorithm evaluated over the ebox obtaining this way gives us the same results as the original query over under the Canonical IRA entailment regime."
        ],
        [
            "That's what we want to do obtain now.",
            "We have implemented this approach in.",
            "The system will be a system that we are working on in boards on which is the on top system that you can download."
        ],
        [
            "And we have carried out two kinds of experimentations.",
            "You can find the details in the paper, one on the real world data of Statoil where we have used real world queries coming from the information requests of geologists, and we're seeing that we obtain a significant improvement in performance with respect to the approach based on same As for dealing with multiple tables.",
            "And then we have also carried out systematic experimentation on synthetic data where we have explored.",
            "This approach on synthetic generated data with different kinds of queries."
        ],
        [
            "Sorry.",
            "I'm done.",
            "This is the last slide.",
            "So the approach that we have proposed allows for simple implementation of this Canonical isml."
        ],
        [
            "Fix by embedding the information in the mappings.",
            "What this means is that we have however shifted some effort from the rewriting to the actual design of these Canonical IRI assertions of the mapping assertions, because we need to.",
            "Essentially implement transit tivity and leave the burden of choosing the Canonical IRI to users, but this is something that in many contexts is already done and so we believe that this approach is one that is actually feasible and useful in practical scenarios."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so this is joint work with some people in Balzano who we?",
                    "label": 0
                },
                {
                    "sent": "Actually, the only one still involves an American likes used to be important, and he's now in Rakuten in Japan and with some people in Oslo working as start or Doug Martin and also with Dimitri from Athens.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is the motivation for this work?",
                    "label": 0
                },
                {
                    "sent": "It starts from a common problem, which is that of accessing heterogeneous data, which is a challenging problem in large corporations.",
                    "label": 1
                },
                {
                    "sent": "In public administrations, in many settings, and I'm showing here an example from Statoil which is the Norwegian oil Company actually changed name.",
                    "label": 0
                },
                {
                    "sent": "By the way, it's uncalled starter anymore, but I still you started because it's more known under this name and we work together with them and specifically together with the Department that is responsible for doing exploration.",
                    "label": 0
                },
                {
                    "sent": "So they.",
                    "label": 0
                },
                {
                    "sent": "Interested in exploring you places where they can dig and so they have to analyze the data from previous Diggins they have done and from previous oil wells they have explored and this is done by geologists and this geologists collect essentially through this.",
                    "label": 0
                },
                {
                    "sent": "Through this explorations on huge amounts of data and this data is stored in very large databases which not only large but they also quite literal genius.",
                    "label": 0
                },
                {
                    "sent": "So they are composed of.",
                    "label": 0
                },
                {
                    "sent": "Thousands of relational tables, large amounts of data and these experts have to access these these databases.",
                    "label": 1
                },
                {
                    "sent": "However, they cannot do it themselves, so they don't really know how to formulate the queries over these databases.",
                    "label": 0
                },
                {
                    "sent": "So what they do?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They formulate the queries in natural language and go to data management experts and ask these experts to formulate these queries in SQL and then the queries are executed.",
                    "label": 0
                },
                {
                    "sent": "The answers are given to geologists to elaborate them and then the cycle repeats and this causes a huge loss of time and actually huge cost in such companies.",
                    "label": 0
                },
                {
                    "sent": "So estimations that 30 to 70% depending on the setting of the time of experts were highly paid, is spent on tasks that are not really their task because these are geologists, they're not data management experts.",
                    "label": 0
                },
                {
                    "sent": "So how can one address this issue?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the approach would be proposed, and then we actually realized in Statoil is one that relies on this ontology based data integration padding.",
                    "label": 0
                },
                {
                    "sent": "But the idea is to build a system in which the experts are not presented with the data source, but they presented with a concept representation of the data sources in terms of an ontology and these ontologies links to the actual data sources in the declarative way through mappings, and then the idea is that query is posed over the ontology and the results are given to the user in terms that he can understand.",
                    "label": 1
                },
                {
                    "sent": "So what we achieve in this way is what is we could call logic transparency in accessing the data so that the user doesn't really know or need to know how the data is organized and stored in the sources but only sees this concept of high level representation in the language that the user understand.",
                    "label": 0
                },
                {
                    "sent": "Now to realize this is challenging.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, OK, here's a short example that I want to give a from.",
                    "label": 0
                },
                {
                    "sent": "This is a startled domain and it's also running example.",
                    "label": 0
                },
                {
                    "sent": "They use through the presentation, so in this example we have two databases.",
                    "label": 1
                },
                {
                    "sent": "They recall national incorporated used abbreviations, each storing for simplicity just one table.",
                    "label": 0
                },
                {
                    "sent": "So we have a table in Caldwell Bar in the national database and table called drilling OPS in the corporate database, and these tables store related information intuitively so.",
                    "label": 0
                },
                {
                    "sent": "The names of the of the wellbores are listed here in blue.",
                    "label": 1
                },
                {
                    "sent": "These are the keys of these tables and they listed here or some blue and now you can see that intuitively there should be a relationship between the names.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "There they are written in a different way, but there is a way to map these two.",
                    "label": 0
                },
                {
                    "sent": "For example, this wellbore corresponds to this webinar.",
                    "label": 0
                },
                {
                    "sent": "National database corresponds to this variable in the drilling operation database and their different information associated to this well, both in the different database.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have the wellbore field and the purpose.",
                    "label": 0
                },
                {
                    "sent": "The purpose is repeatedly.",
                    "label": 0
                },
                {
                    "sent": "Essentially it's called reason here.",
                    "label": 0
                },
                {
                    "sent": "Here we have also the date of the of the drilling of the start of the drilling.",
                    "label": 0
                },
                {
                    "sent": "For this well bore.",
                    "label": 0
                },
                {
                    "sent": "Now in this OBD setting what we do, we specify these mappings that connect these databases to the concept representation of the domain of interest and now in these mappings we have two parts.",
                    "label": 0
                },
                {
                    "sent": "We have a part that is a query source query in SQL over the database that refers, for example is the query for this first table.",
                    "label": 0
                },
                {
                    "sent": "And this query extracts the information.",
                    "label": 0
                },
                {
                    "sent": "In this case it's very simple query just extracts the whole table and the values extracted from the table.",
                    "label": 0
                },
                {
                    "sent": "I used to populate facts to create trippers in the data that is shown at the level of the ontologies generated delivery ontology.",
                    "label": 0
                },
                {
                    "sent": "For example, the Wellbore Field Direct generates a literal well both field.",
                    "label": 0
                },
                {
                    "sent": "Here in these mappings, this is the source part and this is the target part that is specified in terms of RDF triples templates, actually.",
                    "label": 0
                },
                {
                    "sent": "Because we use the variables from, the answer varies from the query in these templates.",
                    "label": 0
                },
                {
                    "sent": "What is important?",
                    "label": 0
                },
                {
                    "sent": "So as an example here, suppose that we have this mapping executed over this database.",
                    "label": 0
                },
                {
                    "sent": "This would generate or these two mappings would generate the set of triples that we find here.",
                    "label": 1
                },
                {
                    "sent": "For example, the first query would generate, among others, these two.",
                    "label": 0
                },
                {
                    "sent": "These two triples here, you see that it populates the two triples with predicate in field and with predicate purpose.",
                    "label": 1
                },
                {
                    "sent": "And what is important to note also is that in these mappings in the source part.",
                    "label": 0
                },
                {
                    "sent": "So in the target part we have not only directly developers, but also what are called IRI template.",
                    "label": 0
                },
                {
                    "sent": "So we construct from the values retrieved from the database iris of the objects that populate the ontology.",
                    "label": 0
                },
                {
                    "sent": "So these are the templates have a pattern that makes use of the variables retrieved from the source.",
                    "label": 0
                },
                {
                    "sent": "For example in this case this is IRA template to generate the for the first app from this table.",
                    "label": 0
                },
                {
                    "sent": "I have just depicted the answer for the first Apple generate these two papers in which you see and I recreated through this template, Iris created using the value retrieved here in this position from the table.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the idea of these mappings.",
                    "label": 0
                },
                {
                    "sent": "They create an RDF graph.",
                    "label": 0
                },
                {
                    "sent": "This RDF graph is not really materialized, it's it's typically kept.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Airport, so the idea of this approach is not to materialize the graph because in general this would be too huge.",
                    "label": 0
                },
                {
                    "sent": "It's unmanageable if you have terabytes of data you can.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to manage this, or you don't want to do it because of freshness and keeping up to date.",
                    "label": 0
                },
                {
                    "sent": "So the idea is different.",
                    "label": 0
                },
                {
                    "sent": "The idea is that the query that the user poses of the ontology is transformed through various steps.",
                    "label": 0
                },
                {
                    "sent": "First rewriting step take into account the ontology a second so called unfolding step take into account the mappings.",
                    "label": 0
                },
                {
                    "sent": "Is transformed into an SQL query.",
                    "label": 0
                },
                {
                    "sent": "This SQL query is evaluated over the data sources and the relational answers we get is then further transformed using the the the templates.",
                    "label": 1
                },
                {
                    "sent": "The Irishman Place in the mappings to transform to obtain the RDF triples that the the answer to the query that is then shipped to the user.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea of the of how these obedient OBD systems on target based data integration and data access systems work by rewriting queries.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what are the issues in the integration setting that we're looking at?",
                    "label": 0
                },
                {
                    "sent": "The point is that the information about a single real world entity might be distributed as we have seen an example over various tables.",
                    "label": 1
                },
                {
                    "sent": "So how do we deal with it?",
                    "label": 0
                },
                {
                    "sent": "So we need to do what is called anterior solution.",
                    "label": 0
                },
                {
                    "sent": "So we need to actually understand which are the records in the various tables that match with each other in correspond to each other.",
                    "label": 0
                },
                {
                    "sent": "Now in this paper we do not address this specific problem, so we assume that this information is somehow available and we'll see how this can be made available, but we're not really concerned with addressing this problem.",
                    "label": 1
                },
                {
                    "sent": "This is per share whole area of research in the context of data integrations, how to measure entities?",
                    "label": 1
                },
                {
                    "sent": "The second aspect is then how to.",
                    "label": 0
                },
                {
                    "sent": "Once we have even match the the entities, how to do integrated querying over the various data sources.",
                    "label": 0
                },
                {
                    "sent": "Take into account the correspondences between the entities.",
                    "label": 1
                },
                {
                    "sent": "So the idea is that we answer to queries.",
                    "label": 0
                },
                {
                    "sent": "Need to integrate the entities, and this is actually what we are concerned with in this paper.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see the example that we had before.",
                    "label": 0
                },
                {
                    "sent": "So this is just repeating what we had there and internally as we have seen since the information about these two one well boy stored in these two tables.",
                    "label": 0
                },
                {
                    "sent": "If we answer if you ask a sparkle query that tries to do a join over these two so that somehow tries to access both the infeed information and the drilling started information which was retrieved through the mappings.",
                    "label": 0
                },
                {
                    "sent": "Now if we use the same variable here and try to do a join will get no answer because the infield information is retrieved from this first.",
                    "label": 0
                },
                {
                    "sent": "Table the drilling start information is retrieved from the second table, but the identifies a different, so actually we cannot really join this verbal so intuitively would like to have this answer here.",
                    "label": 0
                },
                {
                    "sent": "For example this answer where we choose for the variable W the identifying the second table and we obtain the field and drilling starting date.",
                    "label": 0
                },
                {
                    "sent": "But in fact we do not get this answer because this joint is not really performed.",
                    "label": 0
                },
                {
                    "sent": "So that's what we want to add this.",
                    "label": 0
                },
                {
                    "sent": "We want to address an efficient way of getting this kind of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is now So what we need to do is we need mechanisms to merge the data.",
                    "label": 0
                },
                {
                    "sent": "So the first thing that one could think of is to physically merge the data like it is done in extractor.",
                    "label": 1
                },
                {
                    "sent": "For Mindy TL approaches where the data is extracted and actually integrated.",
                    "label": 0
                },
                {
                    "sent": "For example in a data warehouse.",
                    "label": 1
                },
                {
                    "sent": "But this is not really a practical approach in many scenarios because we might not have control over the data sources.",
                    "label": 1
                },
                {
                    "sent": "We might not even be able to do this and also this creates issues of freshness, privacy and legal aspects related to the data.",
                    "label": 1
                },
                {
                    "sent": "So it's not always possible to pursue this approach.",
                    "label": 1
                },
                {
                    "sent": "The other approaches to do actually to follow up on this virtual approach of OH BDA and virtually merge the data.",
                    "label": 1
                },
                {
                    "sent": "For example, using the standard approach in the semantic web, which is declare different iris to be equal through same as which is the standard way of doing it in owl.",
                    "label": 0
                },
                {
                    "sent": "So now what is the problem there?",
                    "label": 0
                },
                {
                    "sent": "The problem is that same as using just same as.",
                    "label": 0
                },
                {
                    "sent": "Might cause an issue due to a large explosion of the number of answers.",
                    "label": 0
                },
                {
                    "sent": "Consider query that returns an N tuple of answer variables and each of the elements of dissent.",
                    "label": 0
                },
                {
                    "sent": "Apple.",
                    "label": 0
                },
                {
                    "sent": "We have two possibilities because because we have declared the two values to be equivalent.",
                    "label": 0
                },
                {
                    "sent": "Then if we choose all the possible combinations where each of the components we choose, either one or the other value, we get an exponential number.",
                    "label": 0
                },
                {
                    "sent": "If we have North and Arity and query, we get 2 to the end just from this.",
                    "label": 0
                },
                {
                    "sent": "Single tap are we get 2 to the end.",
                    "label": 0
                },
                {
                    "sent": "Different answers and this is actually a practical problem so that's what we would like to avoid.",
                    "label": 0
                },
                {
                    "sent": "Also because not only because we get a lot of redundant answers but also this redundant answers are difficult to interpret and so this approach is in many practical cases not really feasible as well and that's where we come in with the approach that we propose in this work here, namely to substitute this same as.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is based approach by somehow I simple approach into the simple approach which is that of using Canonical iris for the objects extracted from the database.",
                    "label": 0
                },
                {
                    "sent": "So instead of retrieving all the possibilities and declaring them to be equal what we do is we use for each type of information a Canonical way of representing the information at the level of the ontology through an IRI.",
                    "label": 0
                },
                {
                    "sent": "And so we have a single Canonical representation and this allows to break the symmetry which causes this exponential blowup and get.",
                    "label": 0
                },
                {
                    "sent": "A more compact answer that can also be computed more efficiently.",
                    "label": 0
                },
                {
                    "sent": "So what we do is, we assume that the a box.",
                    "label": 0
                },
                {
                    "sent": "So the level of data retreated level deontology, augmented with a set of Canonical area assertions using a property can only can I re of that somehow replaces the same as but declaring instead of 1 two irizar declared to be the same.",
                    "label": 0
                },
                {
                    "sent": "We declare camera off saying which is the Canonical IRI, for another one.",
                    "label": 0
                },
                {
                    "sent": "For example we might choose here.",
                    "label": 0
                },
                {
                    "sent": "To represent to use the Canonical area for this object created at the level of the ontology.",
                    "label": 0
                },
                {
                    "sent": "To represent it.",
                    "label": 0
                },
                {
                    "sent": "In fact through these different identifiers, this different IRI.",
                    "label": 0
                },
                {
                    "sent": "And this might be the area also for this other object in another database.",
                    "label": 0
                },
                {
                    "sent": "Now what we do as an assumption which is practical which is needed for our techniques to work, but is also reasonable, is that each IRI has at most one Canonical iris, so we don't use different Canonical areas for the same object, which is actually exactly the purpose of having Canonical Iris.",
                    "label": 1
                },
                {
                    "sent": "So formally we can say that this property can I re office inverse functional in the in the box that we generate?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what we can do is once we have defined set up this setting of Canonical areas what we can.",
                    "label": 0
                },
                {
                    "sent": "Define can define a function that associates to each individual economical IRI and the way we do it is if there is an assertion about an individual.",
                    "label": 0
                },
                {
                    "sent": "All of this form Canonical IRI of C. Oh, by the way, just on the slides are used interchangeably.",
                    "label": 0
                },
                {
                    "sent": "Both the triple notation and the fact notation.",
                    "label": 0
                },
                {
                    "sent": "Usually I use the triple notation examples and they use the fact notation in the more formal presentation just for easiness of reading.",
                    "label": 0
                },
                {
                    "sent": "So if we have here economically.",
                    "label": 0
                },
                {
                    "sent": "The assertion foreign object and sees the quality of oh then thank you.",
                    "label": 0
                },
                {
                    "sent": "Then we say that sees the Chronicle is what is returned by this function.",
                    "label": 0
                },
                {
                    "sent": "If there is no assertion of this form for an object or the object is itself the Canonical IRI.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "In this case, since for the two objects here we have discounted Larry assertions, then these are the Canonical Diaries.",
                    "label": 0
                },
                {
                    "sent": "For this object.",
                    "label": 0
                },
                {
                    "sent": "There is no Canonical area search, and so the object itself is its own Canonical library.",
                    "label": 0
                },
                {
                    "sent": "And once we have defined this, we can define what we call the Canonical graph, which is actually the representation of the whole data at the level of knowledge of the a box by replacing each IRI with its Canonical IRI.",
                    "label": 0
                },
                {
                    "sent": "So in each fact we just use the Canonical eyeballs in.",
                    "label": 0
                },
                {
                    "sent": "Class assertions and in property assertions.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now just as small.",
                    "label": 0
                },
                {
                    "sent": "As a small aside, regarding payment regimes, so since we're interested in reasoning with respect to the ontology, we have to deal with sparkle entailment regimes and ingenious parking L entailment entailment regimes, specify how to obtain from an RDF graph and entail graph which is enriched by the consequences of the entailments and we call e.g.",
                    "label": 1
                },
                {
                    "sent": "Of E is the entailment redeemed entail graph from G using the Interment regime.",
                    "label": 0
                },
                {
                    "sent": "Notice that in general, this graph is an ontology that consider $80.00 and in a box and then that's just the notation that I use to know the answer to sparkle query over graph and then under the entailment regime.",
                    "label": 0
                },
                {
                    "sent": "This is how we did.",
                    "label": 1
                },
                {
                    "sent": "Note the answer to this park query, so QG is the answer to sparkle query Q under the entailment Ragini and how is it defined is just defined as the answer to the regular query with no entailment regime over the Intel graph so that's.",
                    "label": 1
                },
                {
                    "sent": "How sparkle works?",
                    "label": 0
                },
                {
                    "sent": "Notice that entailment regimes, by definition, the internal teams only modifies the valuations of basic graph patterns, not that of the other sparkle of operators.",
                    "label": 0
                },
                {
                    "sent": "Once we've defined how do how to extend the basic graph patterns, the rest is just obtained by applying the users parcial operators and what we have defined.",
                    "label": 1
                },
                {
                    "sent": "Now, in our setting is what we call the Canonical IRI entailment regime and which is an extension of any entailment regime.",
                    "label": 0
                },
                {
                    "sent": "So if we have an intelligent regime East, then.",
                    "label": 1
                },
                {
                    "sent": "The Canonical Irene Tellement regime E Plus can we define it as the one that is obtained by computing the Canonical graph that we have seen before on this slide and then just applying the entailment regime East over the Canonical graph together with the tee box?",
                    "label": 0
                },
                {
                    "sent": "That's how we define this extended entailment regime.",
                    "label": 0
                },
                {
                    "sent": "Notice that this internal Jim is defined in a layered way, so somehow.",
                    "label": 0
                },
                {
                    "sent": "We first compute the economic graph and then on top of it we apply the entailment regime.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how this Canonical ireann?",
                    "label": 0
                },
                {
                    "sent": "Same as intelligent related to each other?",
                    "label": 0
                },
                {
                    "sent": "So we have to say when they are related.",
                    "label": 0
                },
                {
                    "sent": "So we have this notion of compliance and essentially the North of compliance tell us tells us that if we have an economically I reassertion between.",
                    "label": 0
                },
                {
                    "sent": "So if you say that one is the canal diary of O2 then one or two should be in the same as relation.",
                    "label": 0
                },
                {
                    "sent": "And similarly if we have that one and two are in the same as relation, considering also it's transitive, reflexive.",
                    "label": 0
                },
                {
                    "sent": "Symmetric closure because same as has these properties.",
                    "label": 0
                },
                {
                    "sent": "Then the Canonical object the Canonical IRA for one or two should be the same.",
                    "label": 0
                },
                {
                    "sent": "Then these two are compatible and we call this compliant.",
                    "label": 0
                },
                {
                    "sent": "We say that.",
                    "label": 0
                },
                {
                    "sent": "I said AC of Congress version is compatible, is compliant with a set of same as assertions.",
                    "label": 0
                },
                {
                    "sent": "For example, here you see an example of compliant same as and Canonical area assertions.",
                    "label": 0
                },
                {
                    "sent": "Notice that in this example we have introduced knew Canonical Iris for some given Iris, so we're not forced to use existing iris as the Canonical ones.",
                    "label": 1
                },
                {
                    "sent": "We can introduce.",
                    "label": 0
                },
                {
                    "sent": "Also, new ones are talk somehow.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now so once if we have a set of same as assertions, a set of Canonical area assertions that are that are compliant with each other, then what we have is that the same as entailment regime and the Canonical Irene payment version correspond to each other intuitively stated here.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, because the exact formulation is a bit more complicated, don't want to.",
                    "label": 0
                },
                {
                    "sent": "Give the details now.",
                    "label": 0
                },
                {
                    "sent": "Actually this is even a simplified form than the one that is actually needed, so look at look it up in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now how do we want to handle this?",
                    "label": 0
                },
                {
                    "sent": "Canonical iris semantics.",
                    "label": 0
                },
                {
                    "sent": "The idea is we want to exploit essentially the same approach that we exploit in ontology based data integration and access, namely, an approach based on virtualization.",
                    "label": 0
                },
                {
                    "sent": "So we want to deal with it by rewriting queries and so the objective is to rewrite a sparkle query and the E plus can entailment regime to a new sparkle query are like all this ad because it stands for the rewriting.",
                    "label": 1
                },
                {
                    "sent": "In such a way that the rewriting evaluated on the standard entailment regime gives me the same answers as the original query evaluated and the entailment regime extended with the Canonical IRI intended entailment regime.",
                    "label": 1
                },
                {
                    "sent": "Now, in order to obtain this, the first observation is that we need to be a bit careful first, 'cause this Canonical error entailment regime is not monotonic in the sense that if we take basic craft pattern, then under the Canonical area semantics this doesn't behave monotonically.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "And why is this the case?",
                    "label": 0
                },
                {
                    "sent": "Simply be cause if we obtain an answer to a query before having a Canonical area searching for this query.",
                    "label": 0
                },
                {
                    "sent": "And then we add economically.",
                    "label": 0
                },
                {
                    "sent": "So sorry before having a Canonical area searching for an individual, then we might obtain this individual as an answer to a query even to a basic graph pattern.",
                    "label": 0
                },
                {
                    "sent": "If we then add economically assertion for this individual that, for example, tells us that season allow the Canonical area of this individual A, then will not obtain a anymore as an answer because we buy the semantics of coronavirus should obtain C as an answer, so it's not anymore an answer after having added something to our.",
                    "label": 0
                },
                {
                    "sent": "Our knowledge in this sense this entailment regime is not monotonic, so this means that we will not be able to rewrite a basic graph pattern as a basic graph pattern because basic graph patterns are monotonic, so we need in the rewriting.",
                    "label": 0
                },
                {
                    "sent": "This tells us that we need to have some nonatomic mechanism, which means some form of negation in the query that we produce.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in fact, what we have shown is how to introduce this form of medication so that it does the job.",
                    "label": 0
                },
                {
                    "sent": "This is just a simple query that one can define and you see the definition here that returns the Canonical IRI for certain object.",
                    "label": 0
                },
                {
                    "sent": "So if we ask this query then it will give us for each individual X the Canonical IRI for that individual X and this query just implements the definition that we have seen on the previous slide.",
                    "label": 1
                },
                {
                    "sent": "Nothing special, sorry.",
                    "label": 0
                },
                {
                    "sent": "This is not meant to be shown.",
                    "label": 0
                },
                {
                    "sent": "So what we have is that this query in fact behaves correctly.",
                    "label": 0
                },
                {
                    "sent": "So if a pair is in the answer this query, then despair is such that the first element is the Canonical IRI of the second element.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now given this query as a component, we can actually compute the Canonical I rewriting of sparkle query and here you see how this is done.",
                    "label": 0
                },
                {
                    "sent": "Essentially what you have to do is replace each triple pattern in the query intuitively by a joint with this query that returns the Canonical library.",
                    "label": 0
                },
                {
                    "sent": "That's the intuition I don't want to go into the detail, this is how it is done.",
                    "label": 0
                },
                {
                    "sent": "It's quite natural.",
                    "label": 0
                },
                {
                    "sent": "That's what we would naturally need to do, and this is just the formalization of how it is done, and this is what you do.",
                    "label": 0
                },
                {
                    "sent": "What you would do in the example that in an example query that we've seen before, the one that was doing the join between the infield and the drilling, started.",
                    "label": 0
                },
                {
                    "sent": "And essentially you see that it implements this joint by returning the Canonical IRI for the various variables.",
                    "label": 0
                },
                {
                    "sent": "So this transformation deals with each triple pattern singularly and joins it with this query, turning the Canonical area.",
                    "label": 0
                },
                {
                    "sent": "That's the intuition.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this is the correct way of computing the Canonical iris and to returning the answers under Canonical iris semantics.",
                    "label": 0
                },
                {
                    "sent": "But although the size of the written query is linear in the size of the original query, this approach is actually not really feasible and why?",
                    "label": 1
                },
                {
                    "sent": "Because the number of variables that we introduced in the not exists clauses.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I forgot to say that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This query that implements the computation of the Canonical reuses does not exist, which is precisely the negation that we needed to overcome the monotonicity.",
                    "label": 0
                },
                {
                    "sent": "So the number of variables that appear in these clauses is linear and.",
                    "label": 0
                },
                {
                    "sent": "However, for each such variable essentially one needs to scan the whole database, so this is not really feasible in practice.",
                    "label": 0
                },
                {
                    "sent": "So which means the query execution time would grow exponentially in the number of variables in the original query.",
                    "label": 0
                },
                {
                    "sent": "That's why we have been looking.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sing for a different approach, namely one that is based on using the mappings that are present in each of the scenario.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we have mappings that I used to feed this Canonical area assertions, and this is a common assumption.",
                    "label": 0
                },
                {
                    "sent": "For example, in many organization one has so called master tables which exactly those that somehow relates the information in different parts of the information system of the organization.",
                    "label": 0
                },
                {
                    "sent": "And this master tables.",
                    "label": 0
                },
                {
                    "sent": "Can be used to populate this Canonical Iris.",
                    "label": 1
                },
                {
                    "sent": "Notice that, however, this approach that we suggest does not really rely on the presence of such master table.",
                    "label": 1
                },
                {
                    "sent": "It would also work if you have other types of queries that retrieve somehow the Canonical error information at the level of the box is an example installing there we had this master tables and then we can write the queries that just populate this Canonical area.",
                    "label": 0
                },
                {
                    "sent": "Assertions from this master tables.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we do is, our approach is a proposal that thank you that is based on extending the mappings that we have.",
                    "label": 1
                },
                {
                    "sent": "So the regular mapping so that we have in a OBD I integration scenario and embedded in this mapping the information coming from the mappings that compute the Canonical Diaries.",
                    "label": 0
                },
                {
                    "sent": "So this is an approach that is actually inspired by similar approach that is used for optimizing query answering.",
                    "label": 1
                },
                {
                    "sent": "In ontology based data access that is so called mapping saturation algorithms that are implemented in OBD systems and in order to do So what we need to do is we need to ensure that this property we're assuming before, namely that Canonical IRES inverse functional is actually satisfied and we can do so in this mapping based approach by putting condition on the mappings, namely that.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One that looks at the IRI templates in the mapping assertions and.",
                    "label": 1
                },
                {
                    "sent": "The idea is that for each IRA templates that we have in the regular mappings we have at most one mapping assertion in the mappings populating the Canonical iris, that is, that creates a Canonical IRI for that.",
                    "label": 1
                },
                {
                    "sent": "I written plate in this way.",
                    "label": 0
                },
                {
                    "sent": "If this assumption is satisfied, we also guarantee the inverse functionality was that we need notice.",
                    "label": 0
                },
                {
                    "sent": "However, these are strong.",
                    "label": 0
                },
                {
                    "sent": "This assumption is actually stronger, but it's actually quite reasonable assumption in practice, so it's not a limitation in practical settings.",
                    "label": 0
                },
                {
                    "sent": "And now what we can do is if this assumption is satisfied, we can define a rewriting on the of the mappings and this rewriting is actually implementing by changing the standard mapping assertions, taking into account information coming from the Canonical libraries.",
                    "label": 0
                },
                {
                    "sent": "And again here you see how this is done, we need to process each mapping assertion in the regular mapping by taking into account the assertions regarding the Canonical Iris.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what this rewriting approach would give us on our example.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is essentially that this rewriting algorithms implements join with the master tables.",
                    "label": 0
                },
                {
                    "sent": "In the mappings that you have, so the mappings are enriched with suitable joint operations over the master table.",
                    "label": 0
                },
                {
                    "sent": "That's the intuition that you get from this rewriting.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One can show that this is correct, that it gives us so that the query evaluated under the enriched mappings.",
                    "label": 0
                },
                {
                    "sent": "Under the enrich mappings which we apply, the rewriting algorithm evaluated over the ebox obtaining this way gives us the same results as the original query over under the Canonical IRA entailment regime.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's what we want to do obtain now.",
                    "label": 0
                },
                {
                    "sent": "We have implemented this approach in.",
                    "label": 0
                },
                {
                    "sent": "The system will be a system that we are working on in boards on which is the on top system that you can download.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have carried out two kinds of experimentations.",
                    "label": 1
                },
                {
                    "sent": "You can find the details in the paper, one on the real world data of Statoil where we have used real world queries coming from the information requests of geologists, and we're seeing that we obtain a significant improvement in performance with respect to the approach based on same As for dealing with multiple tables.",
                    "label": 1
                },
                {
                    "sent": "And then we have also carried out systematic experimentation on synthetic data where we have explored.",
                    "label": 0
                },
                {
                    "sent": "This approach on synthetic generated data with different kinds of queries.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "I'm done.",
                    "label": 0
                },
                {
                    "sent": "This is the last slide.",
                    "label": 0
                },
                {
                    "sent": "So the approach that we have proposed allows for simple implementation of this Canonical isml.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fix by embedding the information in the mappings.",
                    "label": 1
                },
                {
                    "sent": "What this means is that we have however shifted some effort from the rewriting to the actual design of these Canonical IRI assertions of the mapping assertions, because we need to.",
                    "label": 1
                },
                {
                    "sent": "Essentially implement transit tivity and leave the burden of choosing the Canonical IRI to users, but this is something that in many contexts is already done and so we believe that this approach is one that is actually feasible and useful in practical scenarios.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}