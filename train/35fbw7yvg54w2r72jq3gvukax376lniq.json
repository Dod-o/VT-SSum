{
    "id": "35fbw7yvg54w2r72jq3gvukax376lniq",
    "title": "Machine Learning",
    "info": {
        "author": [
            "Doina Precup, School of Computer Science, McGill University"
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_precup_machine_learning/",
    "segmentation": [
        [
            "So what I would like to do this morning is to do a brief introduction to machine learning.",
            "If you're taking a machine learning course before, this will just be very gentle refresher, but I hope it serves to put us all on the same page.",
            "Also in terms of notation and some terminology that we."
        ],
        [
            "Going to be using, so I'll talk a little bit about different kinds of machine learning problems, and then I'll do some very basic stuff on linear approximation, objective functions, bias variance tradeoff, and a little bit of abbasian view on learning which may come back further in later lectures in the week so in."
        ],
        [
            "Of machine learning is a very broad field.",
            "There's, broadly speaking, three major types of learning problems, supervised learning, reinforcement learning, and unsupervised learning."
        ],
        [
            "And they differ in terms of the kind of feedback and the strength of the feedback that's provided to the learner.",
            "Supervised learning is probably what you think of 1st when you think of machine learning.",
            "It's sort of the classical setting where you have a data set.",
            "There's some inputs that are denoted X.",
            "There's some target that you're trying to predict, which is called why that might be a discrete target or continuous target, and what you're trying to do is to learn a mapping from the inputs to the outputs.",
            "So in this case you have a teacher, you have some sort of system that's provided you with the right labels, or kind of the right labels for this data set, and so your goal is basically to mimic these labels correctly, and so in order to do this, we typically set up an error or loss function objective that we're going to try to optimize, and ideally would like to minimize this error over all the instances.",
            "And the trick what we're going to talk about is how do you do this when you know that you don't have access to the entire possible data set, but only to a small subset of this?"
        ],
        [
            "So this is a typical example of a supervised learning problem which you may have encountered a lot of times before.",
            "It's an image where somebody has labeled faces, and so we might want to know is there a face or not in the image.",
            "How many faces are there in the image and where they are located?",
            "So actually the sizes of these bounding boxes.",
            "Re"
        ],
        [
            "Enforcement learning, which are going to hear a lot more about next week, is a weaker supervision.",
            "Kind of a setup where you have an agent that's just interacting with an environment and occasionally gets a numerical reward signal.",
            "So for example, if you have to have a trading agent that's acting in a market, it's trading stock whenever it's trading, it might have a win or loss.",
            "That's the kind of feedback that it gets, but it never actually knows what was the right thing to do, so it has to learn from this sort of weak form of supervision.",
            "What is an optimal strategy?"
        ],
        [
            "And typical example for this is games.",
            "This is a classical example, many of you might have heard of Alphago, which was a very recent success of reinforcement learning.",
            "This is sort of where it all came from.",
            "This is TD Gammon done back in the 90s by Jerry Tesauro at IBM is a system that became world champion at playing backgammon using a mixture of neural networks and reinforcement learning.",
            "The basic idea here is that the learner sees the state of the board.",
            "It can choose what piece to move where based on on the set of legal moves, and the only feedback that's provided is at the end of the game where the learner wins or loses, and so it can get a plus one or minus one, so there's no label on every single move as you would have in supervised learning.",
            "There's only one label at the end of the game, and the interesting thing is that when you have this kind of weak supervision.",
            "The system is in some sense free to experiment and figure out ways of playing that may not be apparent to people.",
            "Again, this has happened with TD.",
            "Gammon has happened with Alphago and we have a lot of other evidence of that."
        ],
        [
            "And then finally, there's unsupervised learning, which is perhaps the most challenging and also quite interesting form of machine learning where you just have a heap of data and you're trying to figure out what's interesting in this data set.",
            "Oftentimes you think of this as clustering or dimension."
        ],
        [
            "Allati reduction or finding some other kinds of structure.",
            "This is 1 again fairly old example of an oncology data set.",
            "These are cancer patients for which gene activity was recorded, and so if you do something like cluster analysis, you can figure out that there are actually subtypes of patients that react differently to medication and in this particular case they actually found two sort of subtypes that were known before and one that was not OK, so you can find things.",
            "That you may not know about, there's no teacher right teacher to tell you about about the structure in the data.",
            "So you're going to hear about all of these kinds of learning during the week.",
            "Today I'm going to Maine."
        ],
        [
            "We focus on supervised learning, which is sort of the bread and butter.",
            "Here we have just an example data set again to sort of firm up the terminology a little bit.",
            "So again, this is sort of a cancer data set.",
            "You have cell samples that were taken from from tumors and.",
            "The patients are then followed up and what we would like to figure out is based on characteristics from these images.",
            "Will the cancer recur or not?",
            "That's a binary outcome that we would like to predict and if there is a recurrence, how long will it take until the cancer?"
        ],
        [
            "Recurs, and So what we have is a table of data like this, where each of the rows represents a patient.",
            "Each of the columns represents a measurement that was done, and then the two outcomes that we would like to predict, and in this case it's a.",
            "It's a very clean data set.",
            "OK, it's a happy case where all of the variables are measured for all of the patients, or it's a complete data set and.",
            "We have two prediction tasks, CR1 which we're going to call classification.",
            "In fact, it's binary classification and the other one where we're trying to predict this real value.",
            "We're going to call that regression.",
            "OK."
        ],
        [
            "So we have some input variables or features or attributes in this part of the table.",
            "Here we have some targets or output variables and we have training examples or instances here.",
            "Each training example is 1 patient we would like to figure out this prediction task."
        ],
        [
            "So we're going to formalize this a little bit.",
            "We're going to use matrix notation just because that's very convenient.",
            "So bold X denotes the matrix of inputs, bold, Y denotes the output column vector.",
            "And we're going to."
        ],
        [
            "Try and learn a mapping from the input space to the output space, so that's the supervised learning problem.",
            "We want to learn a hypothesis, which is a good predictor for the output variables.",
            "So we're going to call H or hypothesis and typically these ages come from some class of functions or some hypothesis class.",
            "So I'm going to talk this morning mainly about regression and classification in general.",
            "The output space could be quite complex, could be something like a graph or a tree or some other kind of structured object.",
            "Then in that case you have structured prediction and I believe Hugo is going to talk more later about structured prediction and other kinds of variations that are quite interesting on on these types of machine learning tasks.",
            "But we're going to focus on the two simple cases."
        ],
        [
            "This morning so how are we going to go about solving this problem?",
            "First of all, we have to kind of decide what the input and output pairs are.",
            "In this case the data was provided to us, but in general that's a choice that you have to make.",
            "So do you work?",
            "For example with the raw image and extract some kind of visual features out of the image?",
            "Do you have somebody actually labeling certain things on the image measurements and so forth?",
            "That's a choice that you have.",
            "Sometimes you need to do some kind of filtering or preprocessing on the data in order to ensure its quality.",
            "You need to figure out how to encode the inputs and the outputs.",
            "OK. For example, you might want to take the continuous variables and normalize them, or discretize them, and then we have to choose a class of hypothesis or representation.",
            "So that's where we're going."
        ],
        [
            "Look at now.",
            "OK, so here is a simple data set, much simpler than the one before you have just one input variable, one output variable, so real valued variable OK and we have some points here.",
            "What kind of hypothesis class should we pick?",
            "How should we model this data?",
            "With a line OK line is the simplest thing.",
            "OK, so we could take a line and we could sort of look what's the best line that fits these points.",
            "OK so."
        ],
        [
            "That's called linear regression.",
            "OK, so we're going to consider linear hypothesis classes.",
            "That means you take the inputs and you form a linear function with these W's here called parameters or weights, and our job is to find these weights.",
            "OK, we're going to simplify notation a tiny bit and just always assume that there's an input that's always set to one.",
            "OK, that way we don't have to worry about this sort of bias or intercept term.",
            "It's just going to be 1 weight vector that's multiplied with an input vector.",
            "So whatever inputs you have, you just add a column of ones to them.",
            "OK, so now we're going to have to figure out a way of picking a good."
        ],
        [
            "W OK and in order to do this, we need to posit an error function or cost function that we want to optimize."
        ],
        [
            "And of course, one way to do this, which is kind of intuitive and we're going to see in a minute actually quite principled is to optimize in this case the sum of squares or the mean squared error.",
            "So we take the difference between the output value that was provided and the value provided by our hypothesis.",
            "We square these differences.",
            "OK, we have 1/2 here just for convenience, 'cause we're going to take a derivative in a minute, and this is the objective function, so we're going to try and find.",
            "The weight vector W that optimizes this objective function.",
            "I."
        ],
        [
            "So if you remember your calculus right, one way to optimize when you have an objective function is actually partial derivative.",
            "So if I have some objective that depends on some parameters and we want to compute the Max or min you take the gradient of the subjective OK, which is the vector of partial derivatives, and wherever the gradient is equal to 0, that's where you have an extremum point.",
            "Or you might have a saddle point and we can use the second derivative in order to tell us."
        ],
        [
            "What that is?",
            "So in our case, we have a smooth, objective function, right?",
            "Because it's a quadratic.",
            "We have a nice hypothesis.",
            "We can take these derivatives.",
            "Algebra here is not so important, you can.",
            "It's just there for the reference you take these derivatives.",
            "You can set them to zero OK, and what you obtain is a linear system of equations where you think of your weight vector as the unknowns OK."
        ],
        [
            "Data is providing the coefficients and so we can actually solve this in closed form.",
            "So you should enjoy this moment because it's pretty much the last time that we're actually going to be able to solve things in closed form.",
            "OK, there's a very nice formula over there that gives you the best weight vector that fits best the training data that we have OK. And of course this is like one line of code in your favorite programming language.",
            "OK, you can.",
            "You can compute this.",
            "Assuming, of course, that this input matrix is not too big OK, and that you can actually take this inverse over here, so we're going to see in a minute while we're going to do if those are actually not feasible."
        ],
        [
            "So here's an example.",
            "This is some data the best."
        ],
        [
            "Your hypothesis fit OK.",
            "It's a very high."
        ],
        [
            "The case now what happens if the data is more complicated, which is almost always the case.",
            "Well, we may actually not want to have a linear hypothesis because maybe it doesn't really fit the data well.",
            "OK, and as a result we're going to look for nonlinear hypothesis.",
            "Now, the easiest way to get a non linear hypothesis is actually to take your data and feed it through some kind of nonlinear function and then put the weight vector on top.",
            "OK, so you can take your inputs X and feed them through some set of functions 5X.",
            "We'll call these basis functions.",
            "Let's assume for now that these are fixed.",
            "OK, so they're not parameterized.",
            "I give them to you.",
            "Maybe their Gaussians, maybe their sigmoids or something else OK. And then we still can fit this parameter vector W that's on top.",
            "And of course we still have the same sort of closed form solution, except that now instead of having the matrix of inputs X, we have this matrix Phi which contains 5X, so it's just.",
            "It's just a very small change.",
            "Compared to the linear regression case, but it allows you to put in nonlinearities that you think might be good OK."
        ],
        [
            "So in general we have linear models, by which we mean a function that is linear in the parameter vector OK.",
            "It doesn't mean that it's linear in the inputs.",
            "OK, for example, if I use basis functions that are polynomial, I going to obtain something that's called polynomial regression where the dependences linear on the parameter vector but not on the inputs.",
            "Um?",
            "And we very often of course, are going to still have a bias term.",
            "At this point, we're assuming the basis functions are fixed, and again, Hugo is going to tell you a little bit later about what you do if you actually want to adjust these basis functions."
        ],
        [
            "So this is a very typical case of what we call a parametric model.",
            "What does that mean?",
            "It means that we've chosen a priority with the complexity of the hypothesis.",
            "We have a fixed number of parameters that length of the W vector is fixed OK, and we're just looking for a good weight vector.",
            "OK, this is in contrast with nonparametric models.",
            "Things like nearest neighbor methods, for example where.",
            "The complexity of the hypothesis class is allowed to grow with the size of the data.",
            "So we're going to hear a lot about deep learning this week about deep Nets.",
            "We typically think of deep Nets as very large parametric models, although the sort of the understanding of what deep Nets do is still in some sense, evolving.",
            "OK, are there any questions so far?",
            "OK.",
            "So we want to fit the data OK. We have an objective function and we figured out the best way of fitting that data OK, and so now I'm going to show you some pictures that are examples of doing fits of this data where we take take the input and we feed it through a set of basis functions that are polynomial OK. Why?",
            "Because we don't think that align will quite do.",
            "There's some nonlinear trend in the data and so we want to have the possibility of using some nonlinear basis."
        ],
        [
            "So here is some data.",
            "These blue crosses are the data.",
            "OK, we're doing an order to fit.",
            "That means we put X&X squared as inputs as well as the bus term, and then we fit the best parameter vector.",
            "OK and you can see that this actually looks pretty good.",
            "So in order to fit to the data, of course we could do something else.",
            "We could do an order 3 fit to the data."
        ],
        [
            "Here it is.",
            "And we could do in order for."
        ],
        [
            "Fit to the data."
        ],
        [
            "5."
        ],
        [
            "And so on."
        ],
        [
            "Which of these do you prefer?",
            "What's the better fit to the data?"
        ],
        [
            "The first one, but why?",
            "Let me show you one that's really good."
        ],
        [
            "Only this one.",
            "So no, denying fit to the data, it's perfect.",
            "Right, it just goes through the points.",
            "There is 0 error.",
            "Why is this not good?",
            "It doesn't generalize, so somebody OK.",
            "So this is an illustration of a very typical example of overfitting OK, and overfitting is a very very, very important problem in machine learning, which you always have to remember.",
            "It basically means that your algorithm is really good on the data that it's seen, but does not generalize well on data that it has not seen OK."
        ],
        [
            "And you see it over here, right?",
            "These high order fits OK, what happens here?",
            "You have some data.",
            "You have a hypothesis class that's growing as I put the order of the polynomial higher and higher.",
            "Essentially, I allow my hypothesis class to have more and more parameters, so it has more ways of simply memorizing the data.",
            "OK, compared to."
        ],
        [
            "Here OK where I just don't have enough parameters to exactly memorize the data.",
            "Now you notice that the training error does not notice that this might be a better hypothesis, right?",
            "The training here in fact really is very good for these higher order fits where we're memorizing the data perfectly, and so this is something that we have to guard against.",
            "OK, this is basically telling you that the training error is not a good objective function.",
            "OK, and that we have to."
        ],
        [
            "Find a way to measure the true generalization of our hypothesis class."
        ],
        [
            "So these are these are some examples from Chris Bishop's book on Machine Learning, showing different ways.",
            "OK, that that hypothesis can actually fail.",
            "OK, so here we have a true function, which is this green function.",
            "We have some data which is these blue circles, the way that they were generated was by drawing on input uniformly at random, then computing the output and perturbing it with some Gaussian noise.",
            "OK, and we're doing fits to this data using different.",
            "Orders of polynomials and what you can see is you have some cases like for example here.",
            "OK, we have a polynomial of order zero.",
            "That means we just fit the average of the data.",
            "That's not very good, right?",
            "Because it doesn't capture the complexity of the data.",
            "You have on the other panel a linear fit that also doesn't capture the data very well because the data actually has nonlinear structure, so we're losing that.",
            "So the two top cases are what's called under fitting.",
            "Your hypothesis class is too small, too simple, and therefore cannot capture stuff that's actually useful in the data.",
            "Over here and the bottom corner you have the overfitting case, so there you have a polynomial very high degree.",
            "In this case it matches the number of points.",
            "Therefore I can fit the points exactly training Area 0, but again we don't generalize well.",
            "You can see there are certain places right where this polynomial is quite wild compared to the true function, and then we have some happy medium over here where you're fitting the data.",
            "Of course not perfectly OK, but pretty well.",
            "So we're going to talk a lot about avoiding overfitting, because a lot of the time we have these function approximators that have lots and lots of parameters.",
            "But you have to also bear in mind that underfitting may be a problem.",
            "OK, Underfitting gives you systematic errors that you cannot avoid.",
            "OK, overfitting gives you errors due to the fact that it's very sensitive to the exact locations of the point, so if I draw a chance another subset of points of the same size, I'm going to get a hypothesis that's going to be very different.",
            "Right, and that's a symptom of poor."
        ],
        [
            "Generalization.",
            "So more formally, we're going to assume typically that the data is drawn from some fixed probability distribution of the environment, which we don't know, but it exists, and there is some kind of best expected error which we're calling jstar.",
            "OK, so if I had access to the entire data distribution, and I ran my hypothesis on all the examples, I would have this sort of number that tells me what's the best that I can achieve.",
            "But because we don't have all the data, we only have a limited sample of the data.",
            "OK, essentially what we do is we do a Monte Carlo estimate of this error based on the sample that we have OK, and so now if we compare it to hypothesis on a training set which is of a limited size, one of them might appear to be better.",
            "OK by luck of the draw of how we chose that data set.",
            "But maybe it actually has worse sort of true air.",
            "OK, so this is sort of the definition.",
            "Of over fitting.",
            "And of course, one way to avoid this since we're doing Monte Carlo estimation of these errors is just to get more data.",
            "OK, but if you can't get more data, then we basically need to have some way of guarding against this phenomenon, which we're going to."
        ],
        [
            "Discuss now.",
            "So this is a plot that shows you one method for avoiding overfitting.",
            "OK, which is to use a separate set of data called the test set or validation set in order to verify that your hypothesis is.",
            "Really the best one.",
            "So here we have again this example with the polynomial fit M is the degree of the polynomial, so the complexity as M increases the complexity of the hypothesis class increases.",
            "The blue curve is the training error, which goes down OK and the red curve is the error measured on an independent set of data which is called the test set.",
            "And over there you see that for some while the error improves OK.",
            "This is the place where we are eliminating underfitting.",
            "We're sort of finding hypothesis that are good enough, complex enough to capture the structure of the data, but then afterwards they are really shoots up OK, and this part where here shoots up is really the overfitting part.",
            "So this is very much sort of a standard thing that you must absolutely always do when you try out learning algorithms, which is cross validation.",
            "You train on subset of data you test on an independent set of data.",
            "OK, now everybody says, oh, I know, I know how to do this when I say an independent set of data, I mean that data should not be touched in any way during the training process.",
            "That means you don't fit.",
            "Any kinds of parameters of the learning algorithm on that data, you don't sort of figure out how to do the preprocessing using that data.",
            "It absolutely has to be fresh data, otherwise you don't get a correct idea of what your hypothesis class should be."
        ],
        [
            "So we're going to have this sort of general procedure where whatever data set we have, we're going to split it at the beginning into a part that we're going to use to sort of tunare approximator, and then the part that we're going to use to test.",
            "Very often this part that's used to tune the approximator is going to be used for two purposes.",
            "One is to find the order of the hypothesis class, and the other one is to find the actual parameters.",
            "So very often there's going to be a further split of.",
            "The training into training of parameters and a validation set that's used to validate the order of the hypothesis, and then we test this on the test set.",
            "And also typically we're going to repeat this process several times.",
            "So for example, if we're doing 5 fold cross validation, we'll take our data will chop it up into five disjoint pieces, and will repeatedly take four of them.",
            "Train, take the fifth one and test, and it's really, really important in order to make sure that your results are actually real."
        ],
        [
            "Viable now I would like to take a little bit of time to discuss sort of more in depth what is overfitting and underfitting and how do we think of them from a statistical perspective, OK?",
            "So let's assume that you have some example OK. Access the input wise the output and this example comes from some true function F. That I don't know anything about plus some noise OK and epsilon is the noise variable that's drawn from some distribution.",
            "I'm going to make for the moment an assumption that this is a Gaussian distribution of mean zero and some variance.",
            "OK.",
            "So we don't know the variance, but we're going to assume that it's the same for all of the examples.",
            "In other words, it's independent of the input.",
            "So now what did we do so far?",
            "Well, we took the data and we measured squared error on the data and we found an approximator that minimizes the squared error.",
            "Now, because of simply the hypothesis class that we chose, we're going to make some systematic errors OK, and then there's going to be some errors that are made due to the variability from the draw OK of the data and then."
        ],
        [
            "Noise that comes with it.",
            "So one can sort of take this problem and kind of think about the errors that we're making and try to figure out what are the different causes of these errors.",
            "That's called sort of bias variance analysis.",
            "So we're going to take the expected prediction error.",
            "OK, we're assuming that the data is drawn ID independently identically distributed.",
            "That means I asked the environment.",
            "It gives me an input and an output, and then I ask again, and these things are not correlated OK, they just come ID from the same distribution.",
            "This assumption is going to be lifted later on this week when you talk about time series data for example, where the inputs might very much be correlated with each other.",
            "But let's assume for a moment that we have an an IID data set.",
            "And we would like to compute the expected error at any given point.",
            "OK, so the expected value of this Y -- H of X squared and.",
            "We are going to decompose this OK."
        ],
        [
            "Into some components.",
            "This is just some sort of quick reminder of statistics.",
            "If you have a random variable you have it's mean and you have its variance, and there's this very useful variants lemma that expresses the variance as the expectation of X squared minus the mean squared.",
            "So we're going to use this in order to do them."
        ],
        [
            "After this decomposition.",
            "So we take the error OK and we can sort of add and subtract some things and rearrange the terms.",
            "I'm not going to go through the math in detail, but the result is somewhat interesting.",
            "OK, so we're going to end up.",
            "With one term which is.",
            "This expectation of Y squared given X OK."
        ],
        [
            "Sorry, let's do it here so we have one term which is expectation of H of X -- H bar of X.",
            "We have a square term that's F -- H bar and then expected value of y -- F ^2.",
            "OK and let's let's look at these terms just a little bit.",
            "OK so what's H bar H bar is the average hypothesis that I could get at that point.",
            "H is the hypothesis that I happened to get at this point based on the data that I had.",
            "OK, an F is the true value.",
            "So the first time that we're going to look at which is kind of the easiest one, is this expected value of Y -- F of X squared?",
            "OK, what is this?",
            "Well, this is basically the noise because we said why is F plus some noise variable?",
            "OK, so this term here is noise that I can't do anything about it.",
            "It's a characteristic of the problem.",
            "If my assumption was that I have Gaussian noise of mean zero, then essentially this is kind of a benign sort of term.",
            "It's got some variance that is unknown, but the variance is the same for all of the examples.",
            "So this is something that we're.",
            "Going to simply ignore.",
            "What's this H of X -- H bar of X squared?",
            "Well, this basically is telling me what's the variance in the hypothesis class?",
            "In other words, if I were to take a data set and then take another data set and do these fits, how much variability do I have between the different hypothesis?",
            "And so this is essentially what's causing overfitting.",
            "If I have very high variance, OK, maybe because the hypothesis class is very rich or I don't have enough data for that particular hypothesis class, then this term is going to be high.",
            "On the other hand, I have here F of X -- H bar of X squared.",
            "OK, what is this?",
            "Well, this is basically expressing a systematic error.",
            "If my hypothesis class is very small, I may not be able to actually capture F at all of the points OK, and so certain points are going to be badly captured all the time, and this is going to be high.",
            "So this term here is the squared bias OK?",
            "And typically, we're going to have a tradeoff where if the variance increases, the bias decreases and vice versa, OK?"
        ],
        [
            "And so this is.",
            "This is the picture here OK, there's an error decomposition that we have here.",
            "We have the test error, which is this black curve, and we're showing the different components of the error over here.",
            "This was a small data set, so we can actually compute things analytically.",
            "OK, so the pink curve down here that mimics the shape of the test.",
            "There is actually computed.",
            "Using the expectation analytically OK over the data distribution, you can see that it mimics the test error in terms of shape very well, although it's not quite of the same magnitude, but it's got these two components, the bias squared, which is the blue curve and the variance, which is the red curve.",
            "And as you increase the size of your hypothesis space, basically you obtain more variance and less bias.",
            "OK, this kind of U shaped curve for the test error.",
            "As well As for the sort of true expected error of a hypothesis is very very typical.",
            "OK doesn't always come out as cleanly, because in practice you have messier data sets, but you typically still see this kind of U shaped curve in test errors, and So what you want is to find the hypothesis class that's at the bottom of that you shape.",
            "That would be sort of the best thing.",
            "Questions.",
            "Bar.",
            "So."
        ],
        [
            "So here you can compute, you can compute H bar essentially by repeatedly taking a sample of the same size of number of points and fitting H and then taking the average of all of those.",
            "Other questions.",
            "Yeah."
        ],
        [
            "So what we do here basically is we add and we subtract an F. OK, so we started with this formula that has y -- H we add and subtract F and we rearrange the terms and here we've used the sort of product rule for the expectations because what happens is the noise in the output is independent of the noise that I might have in the hypothesis and then the rest of it is simply manipulating these terms and using the definition of Y.",
            "Other questions.",
            "OK.",
            "So almost all learning algorithms have this bias variance tradeoff that you have to be mindful of.",
            "OK, bias is typically telling you that you don't have good hypothesis in your hypothesis class.",
            "OK, and it generates systematic errors that you cannot eliminate because your hypothesis classes somewhere else than the true function variance."
        ],
        [
            "Results from having too many hypothesis in your hypothesis class.",
            "OK, so if your hypothesis class is very rich compared to the size of the data set that you are using OK, then various becomes an issue.",
            "And so we're going to talk in a minute about maximum likelihood estimation versus Bayesian estimation.",
            "This is one way in which you can sort of tweak the bias variance tradeoff.",
            "But typically this is a choice that you have to make OK and you make it based on the amount of data that."
        ],
        [
            "You have OK, so here's an example.",
            "OK, we have two datasets, one with 15 points, one with 100 points.",
            "OK, they are from the same distribution and having the same target function.",
            "But what you see is that if you have more points, you can actually search for polynomials that have higher degrees and you'll still do well right?",
            "Your approximate the data very well, why?",
            "Because really it's not about the number of parameters, it's about how much data you have.",
            "Compared to the number of parameters, then parameter vector has has to be supported by enough data.",
            "Alot of the successes that we've seen for deep learning in recent years have been in these cases where you have very massive function approximators, but you also have very very massive datasets OK, and so we're in a situation that we haven't had in the past in some sense where there's millions of images there is billions of pages of text and so on that one can mine, and so of course, then you can support very big.",
            "Approximators."
        ],
        [
            "OK, so mean squared error.",
            "We've talked a little bit about this.",
            "OK, it's got some nice math.",
            "It's got actually a very nice geometric interpretation in terms of projections.",
            "I'm not really going to tell you about that, but we're going to talk a little bit about this probabilistic assumption behind the mean squared error, because this is again a choice that we kind of made arbitrarily at the beginning, and it's useful for us for other problems to think a little bit about how we make these choices.",
            "So remember I told?"
        ],
        [
            "You that we're going to be in the setting where you have a target.",
            "OK, and we're thinking of this target coming from some function plus some Gaussian noise.",
            "So for a minute, I'm going to assume that really this function is in my hypothesis class.",
            "OK, so there is some hypothesis with some parameter vectors.",
            "I have access to and the examples actually have their targets generated from this hypothesis plus Gaussian noise that's drawn IID from.",
            "Means zero Gaussian distribution.",
            "OK, so let's assume that this is the data.",
            "This is my model for generating the data.",
            "Now how should I choose a good parameter vector?"
        ],
        [
            "And so one way that we we sort of do things in a principled fashion is to leverage based theorem.",
            "OK, based here and basically tells us that each hypothesis has a probability given the data set that we have, and ideally we would find a hypothesis that has high probability.",
            "Excuse me, given the data and so what's the probability of a hypothesis given the data?",
            "Well, I can just write down Bayes rule OK?",
            "So it's PFD given H times pH divided by PFD.",
            "OK, now this is kind of an interesting thing to ponder.",
            "It's sort of a trivial thing to write down, but the meaning of these terms is actually kind of nice.",
            "OK, so what's pH?",
            "pH is a proper prior probability of the hypothesis age OK?",
            "And PFD given age.",
            "Says given the hypothesis I have some probability for the data set.",
            "OK, so it's the likelihood of the data.",
            "PFD really, we don't care about.",
            "It's a normalization term.",
            "OK, there's just there to make sure that you get a probability distribution out, and in fact we're going to ignore this.",
            "OK, because if all we're looking for is a very good hypothesis, one that maximizes this BFH.",
            "Given D, we have these just the constant, OK, and it doesn't really matter."
        ],
        [
            "So what we can do is find the Max a posteriori hypothesis.",
            "That means that hypothesis that maximizes pH given D and again in this case we don't really care about the PFD and we end up with a maximum in the hypothesis space of PFH times PFD given H. So this would be sort of the bashen answer for how to choose hypothesis and notice that it lets you put in some prior idea about what your hypothesis class ought to be OK. For example, I can put the prior that says simpler hypothesis are better, OK, or I can put the prior that says linear hypothesis are more likely than polynomial hypothesis of a higher degree and so on.",
            "OK, so it's a device that lets you put in also prior knowledge that you might have, especially in structured prediction.",
            "About what kinds of hypothesis you would be looking for in the data and this other term PFD, given edge is something that we can just compute OK."
        ],
        [
            "Out of the data.",
            "Now, if we were to assume that all hypothesis are equally likely OK, then what we end up with is what called a maximum likelihood hypothesis.",
            "That's the hypothesis that just maximizes the likelihood of the data, and if we are assuming that the examples are ID, we can further simplify this, because PFD given edge is just going to be a product of the probabilities of each example, so this further simplifies here."
        ],
        [
            "And of course we can apply the lectric you have.",
            "We have a product but we don't really like to work with products.",
            "We take the log of that.",
            "That gives us some OK and then the sum.",
            "We have the log of the likelihood of the hypothesis and we have two terms.",
            "One has to do with the probability of the inputs slog PF XI and the other one is log P of Y given X and a hypothesis.",
            "Second thing, we don't really know, right?",
            "This is the stuff that's the probability of these examples being generated by the environment.",
            "But we don't really care about it either.",
            "Again, because it doesn't depend on the hypothesis class, it just depends on the environment.",
            "So if all we're trying to do is to maximize with respect to H, this thing is just a constant OK, and we're going to ignore it, and we're going to focus on this first term, which is PFY given X and the hypothesis."
        ],
        [
            "And this is the point.",
            "So everything that we've done."
        ],
        [
            "So far is fully general.",
            "It applies to all hypothesis classes.",
            "It's just general principles of applying Bayes theorem for learning.",
            "Now is the time if I want to talk about this probability of the output given the hypothesis class where I'm going to use the assumptions that are making about how the data."
        ],
        [
            "It's actually generated specifically.",
            "Now I have my Gaussian assumption OK, and so if we adopt this Gaussian assumption that the outputs Y really are the value of the hypothesis plus some Gaussian noise, then the likelihood has a nice form.",
            "OK, because we have gaussian's here."
        ],
        [
            "We can take the log OK. And maximizing the log likelihood becomes the same as optimizing the squared error.",
            "OK.",
            "So that's very nice.",
            "OK, why is it nice?",
            "Well, for one thing, it gives us a reason in hindsight as to why we're using the squared error while using the squared error, because we're maximizing the likelihood.",
            "And we have this assumption of Gaussian noise.",
            "That is, ID end up the same variance.",
            "The other interesting thing about about this formula is that it also shows you exactly what assumptions you are making when you choose to optimize the squared error.",
            "Again, this is quite important because in fact this is a pretty strong assumption.",
            "OK, we have uniform prior over the hypothesis space.",
            "We're assuming IID data, and we're assuming this Gaussian noise of fixed variance over all the input space.",
            "OK, now if this assumption does not hold, for example, if the variance over the input space actually depends on the inputs.",
            "OK, then you in fact should not be optimizing this quarter.",
            "You should be optimizing something else.",
            "If you have outputs that are not continuous, outputs OK, but maybe they are counts.",
            "OK, maybe there are possible or whatever, depending on what you assume about that distribution of the output.",
            "You may need to choose a different objective function.",
            "So this is an exercise that essentially helps you uncover what exactly are the assumptions that you're making, and these assumptions are going to have to be different depending on the type of problem that you're faced with and the sort of class of thing that you're trying to solve.",
            "So for example, the minute we're going to talk about classification there, we're not going to make an assumption of Gaussian noise because that's not appropriate.",
            "KR Noise is going to be different, and so therefore we're going to have.",
            "A different objective function.",
            "Any questions about this?",
            "Yeah.",
            "About various decree.",
            "Yes.",
            "At least inconsistent.",
            "And what's the effect of device value straight off?",
            "So.",
            "So consistent estimator basically means that in the limit the bias goes to zero.",
            "OK, that's a very happy case, which we usually don't have in fact, and so most of the time we.",
            "So this is sort of one of the differences between statisticians and machine learning.",
            "People is statisticians talk about estimators, where the bias actually goes to zero in the limit, whereas we are often concerned we know we pick a hypothesis class, we don't make any assumptions about the data and therefore.",
            "We kind of always end up with some bias and the variance squishing down.",
            "And then it's just a question of finding an estimator that's less biased in some sense."
        ],
        [
            "OK.",
            "So we've uncovered, sort of.",
            "What are the assumptions behind using the?"
        ],
        [
            "Squared error Now I just want to show you one other picture of how we think about this whole process.",
            "OK and this is a little cartoon of much more general class of models called the graphical model.",
            "It's a cartoon made for this particular situation.",
            "OK, so here you have a graph where you have random variables at the notes.",
            "OK and these arcs essentially are telling you influences and at every one of these nodes we have a probability distribution of that variable.",
            "Conditioned on its parents.",
            "So this cartoon here is basically showing you.",
            "The process of data generation OK. And of that we can also use for fitting in the case of our regression problem.",
            "So we have some data X that's drawn from some unknown probability distribution of the environment OK. We have a noise process which is the sort of normal Gaussian distributed noise.",
            "OK in our case and we have the W vector.",
            "Now the W vector.",
            "We often think of it as searching, but actually we could think of it as a random variable that has its own prior distribution.",
            "OK, so we're going to talk in a minute about the Bayesian approach to regression.",
            "In that case, W actually has a prior distribution, and so the outputs we think of the outputs as being obtained.",
            "Through this hypothesis that depends on W applied on the inputs X plus some noise, and so this actually is a deterministic node.",
            "In our case, OK, and so the sort of the regression process for us is essentially a search over this W that gives us good likelihood for the data.",
            "But of course if we had basean view OK, if we put a prior on W then we could in fact look for a Max a posteriori hypothesis.",
            "And we would in fact do inference in order to figure out what a good W might be.",
            "And I believe you're going to talk about more later on in the week about things related to graphical models.",
            "So what we would like is actually to sort of leverage this here a little bit in order to find ways during the training process to encourage the hypothesis class to have a good bias variance tradeoff."
        ],
        [
            "OK, now how do we do this?",
            "Well, typically we do this through what's called regularization OK and regularization is sort of a tweak to the optimization criterion, but we're going to see in a minute it's actually sort of very principled from this point of view of map fitting.",
            "OK, so regularization basically says we have our usual objective, which is to fit the data.",
            "This is this term JD FW measures error on the data and we're going to.",
            "Add to this a penalty OK and this penalty function essentially is going to encourage simple hypothesis and there's a constant Lambda here that kind of tradeoff between these two things.",
            "It's also called the regularization coefficient.",
            "And this form of the penalty is something also that we choose.",
            "So in statistics this is called shrinkage.",
            "In machine learning we call it regularization."
        ],
        [
            "And now we can think of what might be good ways to encourage simple hypothesis.",
            "So one way we can sort of formalize simplicity is to say, well, we would like the weights to be close to 0.",
            "Ideally.",
            "In fact, what we would like is for some of the ways to be exactly 0.",
            "That means some of the inputs don't really matter and we keep the size of the hypothesis space in check by essentially ignoring some of the inputs.",
            "But if you want to do that, I'm going to show you that in a minute as well.",
            "It's a little bit harder to optimize and so sort of a good compromise is to just say well.",
            "Actually, let's just encourage the weights to be close to zero.",
            "OK, we can do that by adding a penalty term on the L2 norm of the weight vector.",
            "OK, so the second term here half of W, transpose W, is basically a penalty on the magnitude of the weights.",
            "And sometimes this is called L2 regularization in neural net literature.",
            "Sometimes you see this is called weight decay.",
            "You notice that if I do this, the complexity of the problem of optimizing is exactly the same.",
            "OK, in fact, we can still solve things in closed form, and you get a closed form solution here for the weight vector, which is like we had before 5 transpose 5, but we apply a Lambda identity matrix OK to that.",
            "So essentially the diagonal of that gets boosted.",
            "Notice that this has the side effect of actually improving the conditioning of this matrix.",
            "OK, so it's more likely that this matrix in fact is going to be invertible.",
            "Can we won't run into numerical issues if we do this?",
            "Now of course, what happens if I make Lambda very, very big here?",
            "What am I going to do?",
            "One person.",
            "It's going to ignore the data completely, right?",
            "If I flunk that goes to Infinity.",
            "In fact, it's going to just return a vector that's very very close to zero, OK?",
            "And of course, if I said Lambda to 0, then there is no regularization penalty, right?",
            "I'm just fitting the labels, so you see that now you have a nob.",
            "Actually, that you can use to make your hypothesis space more or less expressive.",
            "OK, it's a bias variance variance tradeoff nob, OK?",
            "So if I make Lambda very big, obtain a hypothesis class, which is very, very simple, very biased, OK, very low variance, I'll always get a zero no matter what the data is.",
            "I'll always get a zero.",
            "It's very low variance.",
            "Very useful, OK."
        ],
        [
            "So this particular thing is also called Ridge regression.",
            "It's a special case of Tikhonov regularization, in fact.",
            "And it can be viewed from sort of many different perspective."
        ],
        [
            "Tips and interest of time.",
            "I'm going to sort of skip this, but I'll show you sort of one way that we can visualize this, OK?",
            "So imagine that I show you the error function.",
            "OK, so the error function is a quadratic.",
            "The bowl here we have two parameters, so you have your error function which is a bowl.",
            "It's the error of the data OK, and I'm looking at it from above.",
            "This is the circles over here.",
            "OK, now what does this L2 penalty say?",
            "the Celtic penalty basically says.",
            "Well, actually I would like my weights to be close to zero.",
            "OK, so in fact I would like my weights to be somewhere in a circle around zero OK, and the radius of the circle is controlled by the regularization parameter Lambda.",
            "So more precisely, it's like one over Lambda.",
            "So if Lambda is very big, the circle really shrinks and I actually really want my weights to be close to 0.",
            "So what we're going to do if we have no regularization is to optimize for this quadratic, which means we descend the ball and we're going to find the blue point here.",
            "However, if we add this quadratic penalty, what happens is we would like to optimize this subject to a constraint, this constraint being that the weights are somewhere within this yellow circle.",
            "OK, and the size of the yellow circle is controlled by Lambda.",
            "So what we find essentially is we find a point that's on the edge of the Circle K and it's as close as possible to the center of the blue circle.",
            "That's the solution.",
            "So regularization you can interpret it as a constraint optimization problem that we're going to solve instead of an unconstrained optimization problem which we had before.",
            "And the constraint is controlled by this regularization constant Lambda."
        ],
        [
            "So now people sometimes think of regularization as something to helps you sort of avoid overfitting.",
            "So then the question comes, does this mean that we have to not do cross validation anymore?",
            "For my point of view, the answer is no.",
            "You always, always, always have to do cross validation OK Huawei, because in fact you actually don't quite know what the magnitude of this regularization penalty ought to be, right?",
            "You can kind of think of it as being given, but oftentimes you in fact will want to optimize it somehow.",
            "And then you're going to use a validation set in order to optimize that.",
            "As well.",
            "Now what will happen with this kind of penalty is that the weights are going to shrink OK, but if you have irrelevant input styles still probably have non 0 weight small."
        ],
        [
            "But but still not quite the same as sort of eliminating those inputs.",
            "So there's a different way of doing the penalization, called L1 regularization, which you may have heard of very popular in the statistics community.",
            "Which basically says instead of constraining the L2 norm of the weights, let's constrain the L1 norm of the weights.",
            "OK, and so the picture for that is that we're going to have a little diamond shape around the origin and we would like the weights to be somewhere inside of this time.",
            "So we say this by imposing these sort of absolute value constraint, sum of absolute values on the weights being smaller than some regularization constant.",
            "This yields an algorithm called lasso and all that sort of friends in this.",
            "That are used in the statistics community.",
            "This kind of looks ugly because you have these constraints here with absolute values in them.",
            "But what happens is you can actually read."
        ],
        [
            "Write these constraints by expanding the absolute values OK, and they turn into linear constraints.",
            "You just have to put the constraint for all of the cases of all the combinations of different signs to the weights, so of course this is going to be expensive, right?",
            "Because if you have many whites, there's many combinations of these signs, right?",
            "So the number of constraints kind of explodes, but you still have a problem that is fairly easy to solve up to a certain size."
        ],
        [
            "So the good thing about that one regularization is that it gives you sparse solutions.",
            "So certain variables that are irrelevant for the target will just get 0 white and essentially can eliminate them from the datasets.",
            "One reason why it's popular in the statistics community, because if you have, for example, biostats tasks, you actually want to know what are the variables that matter for your target and just keep those and eliminate everything else.",
            "But the optimization tends to be much more expensive than using L2, and so when we have deep Nets almost always were in fact going to use L2 and not L1 regularization."
        ],
        [
            "OK, this is showing you sort of the effect of the weights.",
            "OK so this is starting with a number of features.",
            "OK, in the task that we had at the beginning of this class and increasing the amount of regularization.",
            "So of course as you increase the amount of regularization encouraged the ways to go to zero.",
            "But you see that in the case of L2 all the way, it's kind of all shrinks zero together, whereas in the case of L1, certain variables just kind of start and then go to zero, OK, and then their weight stays at zero and some other variables goes to 0.",
            "Is at zero OK, so at any point in time only and limited number of variables actually have any non zero weights.",
            "So that's kind of the distinction between these two."
        ],
        [
            "Now how do we think of this from a probabilistic perspective?",
            "What do these L1 and L2 penalties do?",
            "Well, in fact what they do is they impose specific prior assumptions on the weight vector.",
            "OK. And.",
            "So in the case of L2, for example, we're going to put an assumption on the weight vector, which is a Gaussian assumption.",
            "We assume that the weights come drawn initially from a Gaussian of mean zero.",
            "And so, with this prior distribution, then we can optimize for posterior OK and we obtain L2 regularization and so essentially we obtain the map hypothesis is the one that you obtained by doing the L2 regularization.",
            "Now what does the Lambda parameter do?",
            "Well, the Lambda parameter essentially tells me how much confidence do I have in my prior.",
            "OK, so it's sort of the if you have a very high Lambda it will take more data in order to wash out that prior.",
            "Similarly, for L1 regularization, this kind of double exponential prior.",
            "This was also shown formally by Taxi, Ronnie.",
            "That corresponds to this weight vector and in general we can impose other priors on the weight vector, and we can sort of translate that into different forms of regularization tradeoffs always from the sort of computational POV involve how easy is that?",
            "The resulting optimization problem so very often we make an assumption.",
            "Not necessarily because it's the best assumption for that particular data set, but because it leads to an optimization that we can actually solve through efficient means even when the function approximator becomes very big.",
            "Now, of course, if you come to this conclusion that you could have priors on the hypothesis space, you could actually take this to a more extreme setting where we do.",
            "In fact, Bayesian optimization over the hypothesis space rather than doing just the fitting of 1 hypothesis, which is the most likely hypothesis."
        ],
        [
            "So this is the picture over here again from taken from the Bishop book, which gives you a beige and view OK of regularization, but sort of more fully Bayesian.",
            "So what do we do here?",
            "Let's assume that we have a Gaussian round prior over the weight space.",
            "OK, so this is the picture on top here with the circles that's the prior over the weights.",
            "OK, So what does this mean?",
            "This means that we could draw weights from this prior and every weight vector corresponds to a hypothesis.",
            "So really, every white vector actually gives me a line OK, and so these are the lines over here.",
            "These red lines there all hypothesis that are drawn from this prior.",
            "Now some data comes in.",
            "OK, one data point comes in chicken very barely.",
            "See here.",
            "It's a blue point.",
            "So what does this mean?",
            "Now we want to fit the data.",
            "OK, so we want to maximize the likelihood of this data.",
            "But we also have the prior information, so the likelihood of the data is this sort of square here with the line that basically says we like all kinds of lines, but they have to go through this point.",
            "OK, they have to be anchored somewhere close to this point.",
            "Now we can combine this with the prior on the weights and we get a posterior.",
            "This is this sort of Ellen gated Gaussian here.",
            "OK, what does this mean?",
            "What this means that now we can draw weight vectors OK and see what they do?",
            "What they do is they give us line that all go through the data point that I have.",
            "OK, we still don't know very much about these lines.",
            "There's still great variability, right?",
            "So it's the case of high variance because we have very little data to support our choice and so a lot of the these lines are in fact sort of driven by the prior, but they're all anchored at this point.",
            "Now, what happens if we get a second point?",
            "OK, so here we're getting a second point, sort of at the bottom.",
            "Over here and so now we have another likelihood term coming from the second point.",
            "We're going to take this and combine it with the first term, and so we get a Gaussian here, still Gaussian, but it's much tighter, because now we have more data and so the distribution of the weights has become much tighter and so now again we can draw from this distribution.",
            "We still have some variability.",
            "So there are many different hypothesis that we could have, but they all kind of go in the vicinity of these two points because that's what the likelihood terms are making us do an, so we can continue this process.",
            "OK, we can add more points.",
            "These points bring in terms to the likelihood.",
            "OK, the more points we have, the more the likelihood becomes important, OK, and So what you see is, these Gaussian blobs are getting tighter and tighter.",
            "OK, the weight vectors become more and more similar to each other.",
            "Because they are forced by the likelihood terms to fit the data OK.",
            "But still if you look at this picture, the very last picture, there's still a bunch of lines in there, not just one line.",
            "OK, so this is the distinction between sort of maximum likelihood or map fitting versus sort of the pure beige and view in the Bayesian view.",
            "Never have one hypothesis, so you always have a distribution of our hypothesis and you kind of carried that distribution around.",
            "You might sample from it, OK?",
            "You have some hypothesis that you return or some subset of hypothesis to return, but you always keep in mind that there's this distribution over hypothesis."
        ],
        [
            "Now, why is this interesting?",
            "OK, here's an example.",
            "This is sort of the same data set with one point and two points.",
            "There's some true function, which is this green function, and you can see a whole bunch of hypothesis that are these polynomials that have been drawn, and what you can see is that they are all very wild, but they all kind of fit the data OK, so actually we can map where we are certain about the values and where these hypothesis have a lot of uncertainty.",
            "OK, so in this particular case around where the data is, uncertainty gets reduced.",
            "Why?",
            "Because the hypothesis are forced to fit the data points and so they have to go in some small business entity around the data points very far away from the data.",
            "There's a lot of uncertainty because we have no information there, and so all that we have acting there is the prior in the prior.",
            "In this case is a very vanilla prior.",
            "So this is useful because it gives you some information about the uncertainty in your prediction as opposed to just returning you one."
        ],
        [
            "Hypothesis.",
            "And this is sort of further illustration of this.",
            "As you get more and more data OK. Of course the uncertainty decreases OK and you end up with something that is around the true function.",
            "And of course you see this when you draw from the posterior.",
            "You draw this your draw these hypothesis.",
            "They're all kind of clustered together.",
            "Now.",
            "This approach is conceptually nice.",
            "It's useful when you are in situations where in fact you don't have very much data, and it's very important for you to know where the where the uncertainty is and where your predictor is actually reliable.",
            "It's not feasible to do this in very large hypothesis spaces, at least not at the moment, because you know, keeping these distributions cannot be done in closed form always.",
            "This is sort of a happy case where we're doing things in closed form, but most of the time you need to do this.",
            "We are sampling and that becomes quite expensive."
        ],
        [
            "But I just wanted to sort of bring this to your attention because it's actually kind of interesting now.",
            "The other thing that I wanted to say is that the sort of in the limit, the Bashan and the maximum likelihood view, converge to the same thing in the limit of infinite amount of data.",
            "But in the short term they will not give you the same answer, and in particular the Bayesian approach is biased by the prior.",
            "OK now is biased good or bad.",
            "Well, that depends, OK?",
            "If you have a good prior nearby stores the prior then it's great.",
            "OK if you're just using a vanilla priority, don't have a good prior, then it can actually hurt you.",
            "So how will this approach works is really dependent on how good your priors.",
            "Um?",
            "The other interesting thing is that these uncertainty estimates can be used for other purposes.",
            "So for example, there is a setup called active learning in which the learner is allowed to ask questions.",
            "So it's not just that you get a data set and you do whatever you want with that particular data set, but actually the learner is allowed to go back and ask for labels for specific input examples.",
            "OK, so if I have a patient, I have a classifier classifier, doesn't know the label for this patient, can go back to the doctor and ask for label for this patient.",
            "So how do you do this kind of thing?",
            "Where very often the uncertainty estimates is what drives this right?",
            "Specifically, we're going to go and ask questions about examples that were very uncertain, right?",
            "Just like a student before an exam goes and ask the teacher about questions they don't think that they know the answer to and so you can use these uncertainty estimates.",
            "In the case of active learning and other methods like this in order to shape the strategy of the learner.",
            "Any questions or comments about this so far?",
            "Yep.",
            "Yes, that's correct.",
            "So the Lambda inverse is the variance of the Gaussian basically.",
            "Yes.",
            "So so in general, LP spaces can also be linked to priors.",
            "OK, just about.",
            "So if you think of the term at the sort of the regularization objective, right which has the data portion, and then you have plus Lambda in this other penalty, right?",
            "If you think of this as you take it to an exponential OK, then you can tell that you have this kind of exponential family flavor to things, right so?",
            "Regularization of many different kinds, in fact can be thought of as having one of these exponential family priors now, which kind of regularization you do.",
            "Again, you know, should you do LP, for example?",
            "Well, that depends on the complexity and sort of the amount of data that you have in the complexity of the hypothesis space.",
            "In the case where, for example, so LO, nobody does LO OK, even though in some sense it's exactly what we would like to do.",
            "But solving that optimization problem is very complicated.",
            "Some of the LP Regularization's are quite feasable and so so people will will do that.",
            "And then there's also different kinds of combinations.",
            "So for example, there's tricks like combining L1 and L2 or Huber eyes losses where you have an L1 component in just a dash of L2 at the bottom to make things differentiable, and so on.",
            "Yeah.",
            "So if you think of our formula right, we have PFD given H which is the data set right?",
            "And then pH and so pH is 1.",
            "So if I take the log of that pH gives me one term and PFD.",
            "Given H is actually a sum of terms in the ID assumption, one term for every data point.",
            "And so if I take the amount of data and take it to Infinity, the number of terms in that sums and that some goes to Infinity OK, and so essentially those terms are going to dominate the objective.",
            "And if I can optimize those terms, I will be very good.",
            "Now how do I make sure that that doesn't happen too fast, but that's by basically making the prior stronger and supporting for example a higher regularization constant is going to make sure that the prior doesn't.",
            "Wash off too quick.",
            "Yeah.",
            "What's your view?",
            "Anyone?",
            "Position for feature selection.",
            "So that's an interesting question, so I'm not I'm not a statistician, so perhaps not the best qualified to to discuss that.",
            "But my understanding is that one has been very successful at doing sort of feature selection and many contexts, perhaps not in its more vanilla form, but in more evolved forms, right?",
            "So there is, for example, group lasso style algorithms where you sort of select the subgroup of features and then you do.",
            "Further regularization within that many of these things seem to have worked quite well for various sort of biomedical tasks.",
            "For example genetic tasks and so on.",
            "My experience has been that anything that I need to do I can do with L2, and so I usually don't use a one very much just because the size of approximators that I need a one would not necessarily be be feasable.",
            "But my understanding is that it's actually pretty good at doing feature selection.",
            "The exception is for specific classes of problems, for example where submodularity holds you can actually have better feature selection.",
            "Approaches that leverage combinatorial optimization, but that requires further assumptions on the feature space.",
            "Yep.",
            "Can you set up?",
            "We don't necessarily encode that weight should be close to 0 right.",
            "L2 and L1 have this kind of prior, right?",
            "One has a sparsity prior, just the number of non zero weights should be small.",
            "L2 has this prior of what's going to 0, but in general in the Bashan view you can put the prior of any kind you want and it does not.",
            "It's often a simplicity prior, like why it's going to 0, but it doesn't have to be.",
            "It can be something else that's informed by the problem at hand.",
            "OK, and so for example if you know.",
            "That certain features are important for your problem and that they should be part of the approximator that you want to obtain at the end.",
            "Then you can put the prior that says the weights of these features should be high.",
            "There's nothing sort of preventing you from doing that in this field.",
            "Yeah.",
            "Is good.",
            "What?",
            "Yeah, so so that uninformative priors have sort of two points.",
            "One is sometimes you just don't know uninformative prior but you still want to express this sort of a regularization towards something right?",
            "And so then you know you can put in a very simple prior.",
            "The other thing is that sometimes this sort of prior is used to better condition the optimization objective.",
            "This is not apparent in the simple cases that we're talking about here, but in the case.",
            "Of neural Nets, for example, where you have nonconvex optimization and so the error landscape is very irregular, you may want to do things in such a way that you kind of smooth out the optimization objective and so that you know you can use the regularization terms to help you do that, and you'll hear more about that later.",
            "OK, so."
        ],
        [
            "There's one last thing that I want to talk about today, which is the classification tasks OK and the counterpart of linear regression regression for classification problems is logistic regression.",
            "So in logistic regression, we have a hypothesis that's represented as a logistic function.",
            "OK, so logistic function, we have a linear combination of inputs with weights or of inputs fed through some feature vector combined with the weights.",
            "And you put this through a nonlinearity which is this 1 / 1 plus yeast.",
            "Essentially, what this gives you is a soft threshold.",
            "OK, so instead of having a threshold that goes up like this, you have sort of a curve that is close to zero, close to one and has a soft threshold in between and the weight vector essentially controls the curvature and the position of that threshold.",
            "So this is sort of the linear OK version of a decision surface.",
            "Now why do I say that?",
            "Well, let's look for a minute at some particular example X. OK, let's assume that this is our hypothesis class with the weight vector, and we have here the log odds ratio.",
            "So the probability of Y being one versus the probability of why being OK.",
            "So we had, we take the log of that.",
            "What is this?",
            "Well, this is actually a linear surface.",
            "W transpose X OK.",
            "So what does this mean?",
            "It means that if W transpose X is positive, I'm going to answer that.",
            "The label of this example is 1, and otherwise I'm going to answer that.",
            "The label of this example is zero.",
            "That's the most likely sort of label for this example.",
            "OK, so essentially, if you're thinking of these examples as points, OK, given by the inputs, what we're doing is we're drawing a decision boundary, which is a linear decision boundary that separates.",
            "The positive and the negative examples.",
            "OK, so in this case we are essentially doing linear classification using this sort of logistic regression mechanism.",
            "And the best weights are going to optimize the conditional likelihood of the output given the input now.",
            "Here again, we have a hypothesis which is smooth in the weight vector.",
            "OK, and we'd like to find the best weight vector."
        ],
        [
            "OK, now how do we do that?",
            "Well, we're going to optimize some objective.",
            "OK, now what's our objective?",
            "In this case we have binary outputs.",
            "OK, so having sort of a Gaussian noise model is no longer a good idea, and so therefore we're not going to use square there.",
            "But we still would like to optimize log likelihood.",
            "OK, that's sort of the easiest and the best thing that we can do.",
            "So what's the log likelihood of a hypothesis?",
            "Well, if the output is 1, then it's given by log H of XI.",
            "And if an example has labeled zero, it's log of 1 -- H of XI.",
            "So we can take these terms and put them under 1 formula.",
            "OK, using this trick you know noticing that Y is either one or zero.",
            "So in that case 1 -- y is 1 and so we can take this sort of bracket and put it all together using Y and 1 -- y and so we get one objective function which gives us the log likelihood and we can optimize.",
            "This is also called the cross entropy error function.",
            "OK, and because this depends on H which is smooth.",
            "OK, we can take gradients and you know think of setting those gradients to zero in order to find.",
            "The optimum.",
            "So classification has a different objective function from linear regression.",
            "However, the principle is the same.",
            "We're trying to optimize log likelihood."
        ],
        [
            "So here's a picture of the error surface for this logistic function.",
            "OK, you can see that it's very nice.",
            "Very well behaved OK, looks like it's got an optimum, but actually we can't really solve this optimization and closed form.",
            "And if you take the gradients you're going to see this very easily right?",
            "You have some exponentials here.",
            "Going to take derivatives of exponentials, you want to set to zero.",
            "You can't really set to zero.",
            "OK, can solve that in closed form, even though this is a convex optimization problem, so it has a unique optimum.",
            "So as I told you, linear regression is your one moment of joy where you can actually have closed form solutions.",
            "Now we can no longer do that, but we can still do something really good."
        ],
        [
            "Which is called gradient descent.",
            "So gradient descent basically says we have some objective function.",
            "We're just going to step down in the direction of the gradient in order to get to an optimum solution.",
            "The first picture here is a convex optimization problem.",
            "There's a unique optimum, and so you can just do this with a step size and get to the optimum.",
            "The second picture here is what you typically have in deep Nets.",
            "It's a non convex optimization problem and so you start somewhere.",
            "You go down, you'll end up in one of these wells you don't know which one.",
            "OK, so we're just going to try and do our best to end up in a good well, but it's going to end up with a locally optimal solution as opposed to a globally optimal solution."
        ],
        [
            "So this is again the sort of non convex optimization picture.",
            "You can start in different places.",
            "You can run the optimization and ends up with a locally optimal solution.",
            "OK, there may be many locally optimal solutions and So what we're going to do is probably do this several times with different initial weight vector parameters to make sure that we kind of cover the space of possible optimal solutions."
        ],
        [
            "So this is just a little picture of what the gradient descent algorithm looks like.",
            "In general.",
            "You have some objective function J.",
            "We're going to assume that the gradient of this objective function can be computed easily, and So what we're going to do is take an initial guess of the parameter vector that's called WO, and then we're going to Step 2 and you guess for the parameter vector.",
            "So from a guest WI will go to a guest WI plus one.",
            "How do we do this well?",
            "We step in the direction of the gradient OK, because that's the direction of steepest descent.",
            "The minus here says we're stepping down in the direction of the gradient because we're doing a minimization problem OK, and then we have this parameter here Alpha, which is called the step size or learning rate for this particular iteration.",
            "It's something between zero and one, usually pretty small, and it's telling us in some sense how much we want to step down in the direction of the gradient, how sort of how confident are we?",
            "That this is a good direction."
        ],
        [
            "And so we can exactly do this in the case of logistic regression.",
            "OK, we can take the log of the likelihood.",
            "We can take the gradient of that.",
            "We can optimize.",
            "And actually we get a formula which is quite nice.",
            "OK, once you do all the calculations, calculations are not so important now which basically says we're going to use the inputs OK and then Y minus.",
            "Why hat is the error?",
            "OK, so we're just going to sort of optimize these weights in such a way as to improve on the error of our estimates, and we're just going to run this algorithm for many steps because it's a convex optimization problem, there's one.",
            "Solution we're going to obtain that.",
            "There's one little tricky thing here, which is that we have this learning rate or stepsize parameter, and that's going to influence the quality of the solution that we get OK and so."
        ],
        [
            "There's a way actually to get around that problem, which is to remember from sort of calculus classes that one could in fact use a sort of what we call a second order method.",
            "OK, so in our case we're trying to find the point where the gradient is zero, OK, and so if you want to try to find the zeros of some function.",
            "OK, the way you do that is, you approximate by the tangent and then you solve this linear equation.",
            "OK, that's called nute."
        ],
        [
            "This method, and so we can just apply that with our function being the gradient.",
            "OK, 'cause we're trying to find the zero of the gradient.",
            "This is written here in sort of the form where you have one variable, but you can do this with many variables, so it's called a second order method because we rely on the 2nd order derivative in order to do this opt."
        ],
        [
            "Station and if you have a weight vector, OK, the equivalent of having a second order derivative is to have a Hessian matrix.",
            "Social matrix has the 2nd order partial derivatives of the objective function, and in some sense this gives you the optimal learning rates.",
            "So this is great.",
            "OK, you don't have to figure out anymore of learning rates.",
            "OK, you do need to have this matrix, which may or may not be feasable.",
            "OK, now why is that?",
            "Well, the matrix is square in the number of parameters.",
            "OK, so if now I have actually a lot of parameters because I have a deep net and it's got a million weights, that's a very big matrix.",
            "And not only do I have to have it and invert it.",
            "But actually I have to estimate these entries right?",
            "These are second order relatives and so these entries need to be supported by data.",
            "So I need to have data in order to."
        ],
        [
            "You to do this kind of estimation.",
            "So what's the better method?",
            "Well, that kind of depends.",
            "OK, Newtons method typically requires far fewer iterations, right?",
            "Because he was in some sense go at exactly the right speed.",
            "But computing the Hessian might be a problem.",
            "The inversion actually turns out you don't really need to do.",
            "There's a nice trick that allows you to compute the product of a Hessian with a vector in linear time.",
            "That very often people actually leverage.",
            "It's a nice paper.",
            "We don't really have time to talk about it, but."
        ],
        [
            "I encourage you to look at that and so we can write this all up as Newton raphson for logistic regression, and we can sort of right now the update of this weight vector without even thinking about any kind of step sizes at all.",
            "And."
        ],
        [
            "How do we do regularization for logistic regression?",
            "Well, we can do regularization in similar way.",
            "For example, we can impose a quadratic penalty on the weight vector right, which encourages the weights to be small.",
            "This is the case over here.",
            "We can still take derivatives.",
            "Of course in this case, and we're going to end up with sort of very similar.",
            "Kind of optimization.",
            "Again, this imposes you know so conceptually, what does this do?",
            "It says well, I have a Gaussian prior on the weights right, and then I also want to optimize the likelihood of the data.",
            "Notice that doing something beige and here is going to become very tricky.",
            "However.",
            "OK, why?",
            "Because sort of Gaussian prior on the weights would go with the Gaussian posterior, but this likelihood term here is based on cross entropy and it's no longer.",
            "Conjugate to the prior OK. And so doing basean stuff becomes."
        ],
        [
            "Slightly more involved in this case, where you no longer have sort of conjugacy.",
            "I."
        ],
        [
            "So I'm going to stop there just a few key points that I want you to remember.",
            "You need to make choices of your hypothesis, space, error function and optimization procedure.",
            "OK, so we've discussed here linear and logistic regressions as choices of the function with discussed squared error versus cross entropy's choices of the optimization objective with discussed sort of solving things in closed form versus doing gradient descent as the optimization procedure.",
            "Most of the time we're going to try and find a good sort of computationally efficient way of doing the optimization, and a lot of the literature is about that.",
            "And all of the algorithms are affected by this very bias variance tradeoff, and so you need to guard against that and Bashan.",
            "Stuff might help you with that.",
            "There's other ways to do that, just always always do cross validation, so I'll stop there.",
            "And if there are any further questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I would like to do this morning is to do a brief introduction to machine learning.",
                    "label": 1
                },
                {
                    "sent": "If you're taking a machine learning course before, this will just be very gentle refresher, but I hope it serves to put us all on the same page.",
                    "label": 0
                },
                {
                    "sent": "Also in terms of notation and some terminology that we.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to be using, so I'll talk a little bit about different kinds of machine learning problems, and then I'll do some very basic stuff on linear approximation, objective functions, bias variance tradeoff, and a little bit of abbasian view on learning which may come back further in later lectures in the week so in.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of machine learning is a very broad field.",
                    "label": 0
                },
                {
                    "sent": "There's, broadly speaking, three major types of learning problems, supervised learning, reinforcement learning, and unsupervised learning.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And they differ in terms of the kind of feedback and the strength of the feedback that's provided to the learner.",
                    "label": 0
                },
                {
                    "sent": "Supervised learning is probably what you think of 1st when you think of machine learning.",
                    "label": 1
                },
                {
                    "sent": "It's sort of the classical setting where you have a data set.",
                    "label": 0
                },
                {
                    "sent": "There's some inputs that are denoted X.",
                    "label": 0
                },
                {
                    "sent": "There's some target that you're trying to predict, which is called why that might be a discrete target or continuous target, and what you're trying to do is to learn a mapping from the inputs to the outputs.",
                    "label": 0
                },
                {
                    "sent": "So in this case you have a teacher, you have some sort of system that's provided you with the right labels, or kind of the right labels for this data set, and so your goal is basically to mimic these labels correctly, and so in order to do this, we typically set up an error or loss function objective that we're going to try to optimize, and ideally would like to minimize this error over all the instances.",
                    "label": 1
                },
                {
                    "sent": "And the trick what we're going to talk about is how do you do this when you know that you don't have access to the entire possible data set, but only to a small subset of this?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a typical example of a supervised learning problem which you may have encountered a lot of times before.",
                    "label": 0
                },
                {
                    "sent": "It's an image where somebody has labeled faces, and so we might want to know is there a face or not in the image.",
                    "label": 0
                },
                {
                    "sent": "How many faces are there in the image and where they are located?",
                    "label": 0
                },
                {
                    "sent": "So actually the sizes of these bounding boxes.",
                    "label": 0
                },
                {
                    "sent": "Re",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Enforcement learning, which are going to hear a lot more about next week, is a weaker supervision.",
                    "label": 0
                },
                {
                    "sent": "Kind of a setup where you have an agent that's just interacting with an environment and occasionally gets a numerical reward signal.",
                    "label": 1
                },
                {
                    "sent": "So for example, if you have to have a trading agent that's acting in a market, it's trading stock whenever it's trading, it might have a win or loss.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of feedback that it gets, but it never actually knows what was the right thing to do, so it has to learn from this sort of weak form of supervision.",
                    "label": 0
                },
                {
                    "sent": "What is an optimal strategy?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And typical example for this is games.",
                    "label": 0
                },
                {
                    "sent": "This is a classical example, many of you might have heard of Alphago, which was a very recent success of reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "This is sort of where it all came from.",
                    "label": 0
                },
                {
                    "sent": "This is TD Gammon done back in the 90s by Jerry Tesauro at IBM is a system that became world champion at playing backgammon using a mixture of neural networks and reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "The basic idea here is that the learner sees the state of the board.",
                    "label": 0
                },
                {
                    "sent": "It can choose what piece to move where based on on the set of legal moves, and the only feedback that's provided is at the end of the game where the learner wins or loses, and so it can get a plus one or minus one, so there's no label on every single move as you would have in supervised learning.",
                    "label": 0
                },
                {
                    "sent": "There's only one label at the end of the game, and the interesting thing is that when you have this kind of weak supervision.",
                    "label": 0
                },
                {
                    "sent": "The system is in some sense free to experiment and figure out ways of playing that may not be apparent to people.",
                    "label": 0
                },
                {
                    "sent": "Again, this has happened with TD.",
                    "label": 0
                },
                {
                    "sent": "Gammon has happened with Alphago and we have a lot of other evidence of that.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then finally, there's unsupervised learning, which is perhaps the most challenging and also quite interesting form of machine learning where you just have a heap of data and you're trying to figure out what's interesting in this data set.",
                    "label": 0
                },
                {
                    "sent": "Oftentimes you think of this as clustering or dimension.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Allati reduction or finding some other kinds of structure.",
                    "label": 0
                },
                {
                    "sent": "This is 1 again fairly old example of an oncology data set.",
                    "label": 0
                },
                {
                    "sent": "These are cancer patients for which gene activity was recorded, and so if you do something like cluster analysis, you can figure out that there are actually subtypes of patients that react differently to medication and in this particular case they actually found two sort of subtypes that were known before and one that was not OK, so you can find things.",
                    "label": 1
                },
                {
                    "sent": "That you may not know about, there's no teacher right teacher to tell you about about the structure in the data.",
                    "label": 0
                },
                {
                    "sent": "So you're going to hear about all of these kinds of learning during the week.",
                    "label": 0
                },
                {
                    "sent": "Today I'm going to Maine.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We focus on supervised learning, which is sort of the bread and butter.",
                    "label": 0
                },
                {
                    "sent": "Here we have just an example data set again to sort of firm up the terminology a little bit.",
                    "label": 0
                },
                {
                    "sent": "So again, this is sort of a cancer data set.",
                    "label": 1
                },
                {
                    "sent": "You have cell samples that were taken from from tumors and.",
                    "label": 1
                },
                {
                    "sent": "The patients are then followed up and what we would like to figure out is based on characteristics from these images.",
                    "label": 1
                },
                {
                    "sent": "Will the cancer recur or not?",
                    "label": 0
                },
                {
                    "sent": "That's a binary outcome that we would like to predict and if there is a recurrence, how long will it take until the cancer?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recurs, and So what we have is a table of data like this, where each of the rows represents a patient.",
                    "label": 0
                },
                {
                    "sent": "Each of the columns represents a measurement that was done, and then the two outcomes that we would like to predict, and in this case it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a very clean data set.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a happy case where all of the variables are measured for all of the patients, or it's a complete data set and.",
                    "label": 0
                },
                {
                    "sent": "We have two prediction tasks, CR1 which we're going to call classification.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's binary classification and the other one where we're trying to predict this real value.",
                    "label": 0
                },
                {
                    "sent": "We're going to call that regression.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have some input variables or features or attributes in this part of the table.",
                    "label": 1
                },
                {
                    "sent": "Here we have some targets or output variables and we have training examples or instances here.",
                    "label": 1
                },
                {
                    "sent": "Each training example is 1 patient we would like to figure out this prediction task.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to formalize this a little bit.",
                    "label": 0
                },
                {
                    "sent": "We're going to use matrix notation just because that's very convenient.",
                    "label": 0
                },
                {
                    "sent": "So bold X denotes the matrix of inputs, bold, Y denotes the output column vector.",
                    "label": 0
                },
                {
                    "sent": "And we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try and learn a mapping from the input space to the output space, so that's the supervised learning problem.",
                    "label": 1
                },
                {
                    "sent": "We want to learn a hypothesis, which is a good predictor for the output variables.",
                    "label": 1
                },
                {
                    "sent": "So we're going to call H or hypothesis and typically these ages come from some class of functions or some hypothesis class.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to talk this morning mainly about regression and classification in general.",
                    "label": 0
                },
                {
                    "sent": "The output space could be quite complex, could be something like a graph or a tree or some other kind of structured object.",
                    "label": 0
                },
                {
                    "sent": "Then in that case you have structured prediction and I believe Hugo is going to talk more later about structured prediction and other kinds of variations that are quite interesting on on these types of machine learning tasks.",
                    "label": 0
                },
                {
                    "sent": "But we're going to focus on the two simple cases.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This morning so how are we going to go about solving this problem?",
                    "label": 0
                },
                {
                    "sent": "First of all, we have to kind of decide what the input and output pairs are.",
                    "label": 1
                },
                {
                    "sent": "In this case the data was provided to us, but in general that's a choice that you have to make.",
                    "label": 0
                },
                {
                    "sent": "So do you work?",
                    "label": 0
                },
                {
                    "sent": "For example with the raw image and extract some kind of visual features out of the image?",
                    "label": 0
                },
                {
                    "sent": "Do you have somebody actually labeling certain things on the image measurements and so forth?",
                    "label": 0
                },
                {
                    "sent": "That's a choice that you have.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you need to do some kind of filtering or preprocessing on the data in order to ensure its quality.",
                    "label": 1
                },
                {
                    "sent": "You need to figure out how to encode the inputs and the outputs.",
                    "label": 1
                },
                {
                    "sent": "OK. For example, you might want to take the continuous variables and normalize them, or discretize them, and then we have to choose a class of hypothesis or representation.",
                    "label": 0
                },
                {
                    "sent": "So that's where we're going.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at now.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is a simple data set, much simpler than the one before you have just one input variable, one output variable, so real valued variable OK and we have some points here.",
                    "label": 0
                },
                {
                    "sent": "What kind of hypothesis class should we pick?",
                    "label": 1
                },
                {
                    "sent": "How should we model this data?",
                    "label": 0
                },
                {
                    "sent": "With a line OK line is the simplest thing.",
                    "label": 0
                },
                {
                    "sent": "OK, so we could take a line and we could sort of look what's the best line that fits these points.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's called linear regression.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to consider linear hypothesis classes.",
                    "label": 1
                },
                {
                    "sent": "That means you take the inputs and you form a linear function with these W's here called parameters or weights, and our job is to find these weights.",
                    "label": 1
                },
                {
                    "sent": "OK, we're going to simplify notation a tiny bit and just always assume that there's an input that's always set to one.",
                    "label": 1
                },
                {
                    "sent": "OK, that way we don't have to worry about this sort of bias or intercept term.",
                    "label": 0
                },
                {
                    "sent": "It's just going to be 1 weight vector that's multiplied with an input vector.",
                    "label": 0
                },
                {
                    "sent": "So whatever inputs you have, you just add a column of ones to them.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're going to have to figure out a way of picking a good.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "W OK and in order to do this, we need to posit an error function or cost function that we want to optimize.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course, one way to do this, which is kind of intuitive and we're going to see in a minute actually quite principled is to optimize in this case the sum of squares or the mean squared error.",
                    "label": 0
                },
                {
                    "sent": "So we take the difference between the output value that was provided and the value provided by our hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We square these differences.",
                    "label": 0
                },
                {
                    "sent": "OK, we have 1/2 here just for convenience, 'cause we're going to take a derivative in a minute, and this is the objective function, so we're going to try and find.",
                    "label": 0
                },
                {
                    "sent": "The weight vector W that optimizes this objective function.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you remember your calculus right, one way to optimize when you have an objective function is actually partial derivative.",
                    "label": 1
                },
                {
                    "sent": "So if I have some objective that depends on some parameters and we want to compute the Max or min you take the gradient of the subjective OK, which is the vector of partial derivatives, and wherever the gradient is equal to 0, that's where you have an extremum point.",
                    "label": 1
                },
                {
                    "sent": "Or you might have a saddle point and we can use the second derivative in order to tell us.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What that is?",
                    "label": 0
                },
                {
                    "sent": "So in our case, we have a smooth, objective function, right?",
                    "label": 0
                },
                {
                    "sent": "Because it's a quadratic.",
                    "label": 0
                },
                {
                    "sent": "We have a nice hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We can take these derivatives.",
                    "label": 0
                },
                {
                    "sent": "Algebra here is not so important, you can.",
                    "label": 0
                },
                {
                    "sent": "It's just there for the reference you take these derivatives.",
                    "label": 0
                },
                {
                    "sent": "You can set them to zero OK, and what you obtain is a linear system of equations where you think of your weight vector as the unknowns OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data is providing the coefficients and so we can actually solve this in closed form.",
                    "label": 0
                },
                {
                    "sent": "So you should enjoy this moment because it's pretty much the last time that we're actually going to be able to solve things in closed form.",
                    "label": 0
                },
                {
                    "sent": "OK, there's a very nice formula over there that gives you the best weight vector that fits best the training data that we have OK. And of course this is like one line of code in your favorite programming language.",
                    "label": 0
                },
                {
                    "sent": "OK, you can.",
                    "label": 0
                },
                {
                    "sent": "You can compute this.",
                    "label": 0
                },
                {
                    "sent": "Assuming, of course, that this input matrix is not too big OK, and that you can actually take this inverse over here, so we're going to see in a minute while we're going to do if those are actually not feasible.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "This is some data the best.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your hypothesis fit OK.",
                    "label": 0
                },
                {
                    "sent": "It's a very high.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The case now what happens if the data is more complicated, which is almost always the case.",
                    "label": 0
                },
                {
                    "sent": "Well, we may actually not want to have a linear hypothesis because maybe it doesn't really fit the data well.",
                    "label": 0
                },
                {
                    "sent": "OK, and as a result we're going to look for nonlinear hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Now, the easiest way to get a non linear hypothesis is actually to take your data and feed it through some kind of nonlinear function and then put the weight vector on top.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can take your inputs X and feed them through some set of functions 5X.",
                    "label": 0
                },
                {
                    "sent": "We'll call these basis functions.",
                    "label": 0
                },
                {
                    "sent": "Let's assume for now that these are fixed.",
                    "label": 0
                },
                {
                    "sent": "OK, so they're not parameterized.",
                    "label": 0
                },
                {
                    "sent": "I give them to you.",
                    "label": 0
                },
                {
                    "sent": "Maybe their Gaussians, maybe their sigmoids or something else OK. And then we still can fit this parameter vector W that's on top.",
                    "label": 0
                },
                {
                    "sent": "And of course we still have the same sort of closed form solution, except that now instead of having the matrix of inputs X, we have this matrix Phi which contains 5X, so it's just.",
                    "label": 0
                },
                {
                    "sent": "It's just a very small change.",
                    "label": 0
                },
                {
                    "sent": "Compared to the linear regression case, but it allows you to put in nonlinearities that you think might be good OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in general we have linear models, by which we mean a function that is linear in the parameter vector OK.",
                    "label": 1
                },
                {
                    "sent": "It doesn't mean that it's linear in the inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, for example, if I use basis functions that are polynomial, I going to obtain something that's called polynomial regression where the dependences linear on the parameter vector but not on the inputs.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "And we very often of course, are going to still have a bias term.",
                    "label": 0
                },
                {
                    "sent": "At this point, we're assuming the basis functions are fixed, and again, Hugo is going to tell you a little bit later about what you do if you actually want to adjust these basis functions.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a very typical case of what we call a parametric model.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "It means that we've chosen a priority with the complexity of the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "We have a fixed number of parameters that length of the W vector is fixed OK, and we're just looking for a good weight vector.",
                    "label": 0
                },
                {
                    "sent": "OK, this is in contrast with nonparametric models.",
                    "label": 0
                },
                {
                    "sent": "Things like nearest neighbor methods, for example where.",
                    "label": 0
                },
                {
                    "sent": "The complexity of the hypothesis class is allowed to grow with the size of the data.",
                    "label": 1
                },
                {
                    "sent": "So we're going to hear a lot about deep learning this week about deep Nets.",
                    "label": 1
                },
                {
                    "sent": "We typically think of deep Nets as very large parametric models, although the sort of the understanding of what deep Nets do is still in some sense, evolving.",
                    "label": 0
                },
                {
                    "sent": "OK, are there any questions so far?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we want to fit the data OK. We have an objective function and we figured out the best way of fitting that data OK, and so now I'm going to show you some pictures that are examples of doing fits of this data where we take take the input and we feed it through a set of basis functions that are polynomial OK. Why?",
                    "label": 0
                },
                {
                    "sent": "Because we don't think that align will quite do.",
                    "label": 0
                },
                {
                    "sent": "There's some nonlinear trend in the data and so we want to have the possibility of using some nonlinear basis.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is some data.",
                    "label": 0
                },
                {
                    "sent": "These blue crosses are the data.",
                    "label": 0
                },
                {
                    "sent": "OK, we're doing an order to fit.",
                    "label": 0
                },
                {
                    "sent": "That means we put X&X squared as inputs as well as the bus term, and then we fit the best parameter vector.",
                    "label": 0
                },
                {
                    "sent": "OK and you can see that this actually looks pretty good.",
                    "label": 0
                },
                {
                    "sent": "So in order to fit to the data, of course we could do something else.",
                    "label": 0
                },
                {
                    "sent": "We could do an order 3 fit to the data.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here it is.",
                    "label": 0
                },
                {
                    "sent": "And we could do in order for.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fit to the data.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "5.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so on.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which of these do you prefer?",
                    "label": 0
                },
                {
                    "sent": "What's the better fit to the data?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first one, but why?",
                    "label": 0
                },
                {
                    "sent": "Let me show you one that's really good.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only this one.",
                    "label": 0
                },
                {
                    "sent": "So no, denying fit to the data, it's perfect.",
                    "label": 1
                },
                {
                    "sent": "Right, it just goes through the points.",
                    "label": 0
                },
                {
                    "sent": "There is 0 error.",
                    "label": 1
                },
                {
                    "sent": "Why is this not good?",
                    "label": 0
                },
                {
                    "sent": "It doesn't generalize, so somebody OK.",
                    "label": 0
                },
                {
                    "sent": "So this is an illustration of a very typical example of overfitting OK, and overfitting is a very very, very important problem in machine learning, which you always have to remember.",
                    "label": 0
                },
                {
                    "sent": "It basically means that your algorithm is really good on the data that it's seen, but does not generalize well on data that it has not seen OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you see it over here, right?",
                    "label": 0
                },
                {
                    "sent": "These high order fits OK, what happens here?",
                    "label": 0
                },
                {
                    "sent": "You have some data.",
                    "label": 0
                },
                {
                    "sent": "You have a hypothesis class that's growing as I put the order of the polynomial higher and higher.",
                    "label": 0
                },
                {
                    "sent": "Essentially, I allow my hypothesis class to have more and more parameters, so it has more ways of simply memorizing the data.",
                    "label": 1
                },
                {
                    "sent": "OK, compared to.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here OK where I just don't have enough parameters to exactly memorize the data.",
                    "label": 1
                },
                {
                    "sent": "Now you notice that the training error does not notice that this might be a better hypothesis, right?",
                    "label": 0
                },
                {
                    "sent": "The training here in fact really is very good for these higher order fits where we're memorizing the data perfectly, and so this is something that we have to guard against.",
                    "label": 0
                },
                {
                    "sent": "OK, this is basically telling you that the training error is not a good objective function.",
                    "label": 0
                },
                {
                    "sent": "OK, and that we have to.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find a way to measure the true generalization of our hypothesis class.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are these are some examples from Chris Bishop's book on Machine Learning, showing different ways.",
                    "label": 0
                },
                {
                    "sent": "OK, that that hypothesis can actually fail.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we have a true function, which is this green function.",
                    "label": 0
                },
                {
                    "sent": "We have some data which is these blue circles, the way that they were generated was by drawing on input uniformly at random, then computing the output and perturbing it with some Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "OK, and we're doing fits to this data using different.",
                    "label": 0
                },
                {
                    "sent": "Orders of polynomials and what you can see is you have some cases like for example here.",
                    "label": 0
                },
                {
                    "sent": "OK, we have a polynomial of order zero.",
                    "label": 0
                },
                {
                    "sent": "That means we just fit the average of the data.",
                    "label": 0
                },
                {
                    "sent": "That's not very good, right?",
                    "label": 0
                },
                {
                    "sent": "Because it doesn't capture the complexity of the data.",
                    "label": 0
                },
                {
                    "sent": "You have on the other panel a linear fit that also doesn't capture the data very well because the data actually has nonlinear structure, so we're losing that.",
                    "label": 0
                },
                {
                    "sent": "So the two top cases are what's called under fitting.",
                    "label": 0
                },
                {
                    "sent": "Your hypothesis class is too small, too simple, and therefore cannot capture stuff that's actually useful in the data.",
                    "label": 0
                },
                {
                    "sent": "Over here and the bottom corner you have the overfitting case, so there you have a polynomial very high degree.",
                    "label": 0
                },
                {
                    "sent": "In this case it matches the number of points.",
                    "label": 0
                },
                {
                    "sent": "Therefore I can fit the points exactly training Area 0, but again we don't generalize well.",
                    "label": 0
                },
                {
                    "sent": "You can see there are certain places right where this polynomial is quite wild compared to the true function, and then we have some happy medium over here where you're fitting the data.",
                    "label": 0
                },
                {
                    "sent": "Of course not perfectly OK, but pretty well.",
                    "label": 0
                },
                {
                    "sent": "So we're going to talk a lot about avoiding overfitting, because a lot of the time we have these function approximators that have lots and lots of parameters.",
                    "label": 0
                },
                {
                    "sent": "But you have to also bear in mind that underfitting may be a problem.",
                    "label": 0
                },
                {
                    "sent": "OK, Underfitting gives you systematic errors that you cannot avoid.",
                    "label": 0
                },
                {
                    "sent": "OK, overfitting gives you errors due to the fact that it's very sensitive to the exact locations of the point, so if I draw a chance another subset of points of the same size, I'm going to get a hypothesis that's going to be very different.",
                    "label": 0
                },
                {
                    "sent": "Right, and that's a symptom of poor.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Generalization.",
                    "label": 0
                },
                {
                    "sent": "So more formally, we're going to assume typically that the data is drawn from some fixed probability distribution of the environment, which we don't know, but it exists, and there is some kind of best expected error which we're calling jstar.",
                    "label": 1
                },
                {
                    "sent": "OK, so if I had access to the entire data distribution, and I ran my hypothesis on all the examples, I would have this sort of number that tells me what's the best that I can achieve.",
                    "label": 1
                },
                {
                    "sent": "But because we don't have all the data, we only have a limited sample of the data.",
                    "label": 0
                },
                {
                    "sent": "OK, essentially what we do is we do a Monte Carlo estimate of this error based on the sample that we have OK, and so now if we compare it to hypothesis on a training set which is of a limited size, one of them might appear to be better.",
                    "label": 0
                },
                {
                    "sent": "OK by luck of the draw of how we chose that data set.",
                    "label": 0
                },
                {
                    "sent": "But maybe it actually has worse sort of true air.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is sort of the definition.",
                    "label": 0
                },
                {
                    "sent": "Of over fitting.",
                    "label": 0
                },
                {
                    "sent": "And of course, one way to avoid this since we're doing Monte Carlo estimation of these errors is just to get more data.",
                    "label": 0
                },
                {
                    "sent": "OK, but if you can't get more data, then we basically need to have some way of guarding against this phenomenon, which we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Discuss now.",
                    "label": 0
                },
                {
                    "sent": "So this is a plot that shows you one method for avoiding overfitting.",
                    "label": 0
                },
                {
                    "sent": "OK, which is to use a separate set of data called the test set or validation set in order to verify that your hypothesis is.",
                    "label": 0
                },
                {
                    "sent": "Really the best one.",
                    "label": 0
                },
                {
                    "sent": "So here we have again this example with the polynomial fit M is the degree of the polynomial, so the complexity as M increases the complexity of the hypothesis class increases.",
                    "label": 1
                },
                {
                    "sent": "The blue curve is the training error, which goes down OK and the red curve is the error measured on an independent set of data which is called the test set.",
                    "label": 0
                },
                {
                    "sent": "And over there you see that for some while the error improves OK.",
                    "label": 0
                },
                {
                    "sent": "This is the place where we are eliminating underfitting.",
                    "label": 0
                },
                {
                    "sent": "We're sort of finding hypothesis that are good enough, complex enough to capture the structure of the data, but then afterwards they are really shoots up OK, and this part where here shoots up is really the overfitting part.",
                    "label": 0
                },
                {
                    "sent": "So this is very much sort of a standard thing that you must absolutely always do when you try out learning algorithms, which is cross validation.",
                    "label": 0
                },
                {
                    "sent": "You train on subset of data you test on an independent set of data.",
                    "label": 0
                },
                {
                    "sent": "OK, now everybody says, oh, I know, I know how to do this when I say an independent set of data, I mean that data should not be touched in any way during the training process.",
                    "label": 0
                },
                {
                    "sent": "That means you don't fit.",
                    "label": 0
                },
                {
                    "sent": "Any kinds of parameters of the learning algorithm on that data, you don't sort of figure out how to do the preprocessing using that data.",
                    "label": 0
                },
                {
                    "sent": "It absolutely has to be fresh data, otherwise you don't get a correct idea of what your hypothesis class should be.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're going to have this sort of general procedure where whatever data set we have, we're going to split it at the beginning into a part that we're going to use to sort of tunare approximator, and then the part that we're going to use to test.",
                    "label": 0
                },
                {
                    "sent": "Very often this part that's used to tune the approximator is going to be used for two purposes.",
                    "label": 0
                },
                {
                    "sent": "One is to find the order of the hypothesis class, and the other one is to find the actual parameters.",
                    "label": 1
                },
                {
                    "sent": "So very often there's going to be a further split of.",
                    "label": 1
                },
                {
                    "sent": "The training into training of parameters and a validation set that's used to validate the order of the hypothesis, and then we test this on the test set.",
                    "label": 0
                },
                {
                    "sent": "And also typically we're going to repeat this process several times.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we're doing 5 fold cross validation, we'll take our data will chop it up into five disjoint pieces, and will repeatedly take four of them.",
                    "label": 0
                },
                {
                    "sent": "Train, take the fifth one and test, and it's really, really important in order to make sure that your results are actually real.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Viable now I would like to take a little bit of time to discuss sort of more in depth what is overfitting and underfitting and how do we think of them from a statistical perspective, OK?",
                    "label": 0
                },
                {
                    "sent": "So let's assume that you have some example OK. Access the input wise the output and this example comes from some true function F. That I don't know anything about plus some noise OK and epsilon is the noise variable that's drawn from some distribution.",
                    "label": 0
                },
                {
                    "sent": "I'm going to make for the moment an assumption that this is a Gaussian distribution of mean zero and some variance.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we don't know the variance, but we're going to assume that it's the same for all of the examples.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's independent of the input.",
                    "label": 1
                },
                {
                    "sent": "So now what did we do so far?",
                    "label": 0
                },
                {
                    "sent": "Well, we took the data and we measured squared error on the data and we found an approximator that minimizes the squared error.",
                    "label": 0
                },
                {
                    "sent": "Now, because of simply the hypothesis class that we chose, we're going to make some systematic errors OK, and then there's going to be some errors that are made due to the variability from the draw OK of the data and then.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Noise that comes with it.",
                    "label": 0
                },
                {
                    "sent": "So one can sort of take this problem and kind of think about the errors that we're making and try to figure out what are the different causes of these errors.",
                    "label": 0
                },
                {
                    "sent": "That's called sort of bias variance analysis.",
                    "label": 0
                },
                {
                    "sent": "So we're going to take the expected prediction error.",
                    "label": 1
                },
                {
                    "sent": "OK, we're assuming that the data is drawn ID independently identically distributed.",
                    "label": 0
                },
                {
                    "sent": "That means I asked the environment.",
                    "label": 0
                },
                {
                    "sent": "It gives me an input and an output, and then I ask again, and these things are not correlated OK, they just come ID from the same distribution.",
                    "label": 0
                },
                {
                    "sent": "This assumption is going to be lifted later on this week when you talk about time series data for example, where the inputs might very much be correlated with each other.",
                    "label": 1
                },
                {
                    "sent": "But let's assume for a moment that we have an an IID data set.",
                    "label": 0
                },
                {
                    "sent": "And we would like to compute the expected error at any given point.",
                    "label": 1
                },
                {
                    "sent": "OK, so the expected value of this Y -- H of X squared and.",
                    "label": 0
                },
                {
                    "sent": "We are going to decompose this OK.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Into some components.",
                    "label": 0
                },
                {
                    "sent": "This is just some sort of quick reminder of statistics.",
                    "label": 0
                },
                {
                    "sent": "If you have a random variable you have it's mean and you have its variance, and there's this very useful variants lemma that expresses the variance as the expectation of X squared minus the mean squared.",
                    "label": 1
                },
                {
                    "sent": "So we're going to use this in order to do them.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After this decomposition.",
                    "label": 0
                },
                {
                    "sent": "So we take the error OK and we can sort of add and subtract some things and rearrange the terms.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go through the math in detail, but the result is somewhat interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to end up.",
                    "label": 0
                },
                {
                    "sent": "With one term which is.",
                    "label": 0
                },
                {
                    "sent": "This expectation of Y squared given X OK.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry, let's do it here so we have one term which is expectation of H of X -- H bar of X.",
                    "label": 0
                },
                {
                    "sent": "We have a square term that's F -- H bar and then expected value of y -- F ^2.",
                    "label": 1
                },
                {
                    "sent": "OK and let's let's look at these terms just a little bit.",
                    "label": 0
                },
                {
                    "sent": "OK so what's H bar H bar is the average hypothesis that I could get at that point.",
                    "label": 0
                },
                {
                    "sent": "H is the hypothesis that I happened to get at this point based on the data that I had.",
                    "label": 0
                },
                {
                    "sent": "OK, an F is the true value.",
                    "label": 0
                },
                {
                    "sent": "So the first time that we're going to look at which is kind of the easiest one, is this expected value of Y -- F of X squared?",
                    "label": 0
                },
                {
                    "sent": "OK, what is this?",
                    "label": 0
                },
                {
                    "sent": "Well, this is basically the noise because we said why is F plus some noise variable?",
                    "label": 0
                },
                {
                    "sent": "OK, so this term here is noise that I can't do anything about it.",
                    "label": 0
                },
                {
                    "sent": "It's a characteristic of the problem.",
                    "label": 0
                },
                {
                    "sent": "If my assumption was that I have Gaussian noise of mean zero, then essentially this is kind of a benign sort of term.",
                    "label": 0
                },
                {
                    "sent": "It's got some variance that is unknown, but the variance is the same for all of the examples.",
                    "label": 1
                },
                {
                    "sent": "So this is something that we're.",
                    "label": 0
                },
                {
                    "sent": "Going to simply ignore.",
                    "label": 0
                },
                {
                    "sent": "What's this H of X -- H bar of X squared?",
                    "label": 0
                },
                {
                    "sent": "Well, this basically is telling me what's the variance in the hypothesis class?",
                    "label": 1
                },
                {
                    "sent": "In other words, if I were to take a data set and then take another data set and do these fits, how much variability do I have between the different hypothesis?",
                    "label": 0
                },
                {
                    "sent": "And so this is essentially what's causing overfitting.",
                    "label": 0
                },
                {
                    "sent": "If I have very high variance, OK, maybe because the hypothesis class is very rich or I don't have enough data for that particular hypothesis class, then this term is going to be high.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, I have here F of X -- H bar of X squared.",
                    "label": 0
                },
                {
                    "sent": "OK, what is this?",
                    "label": 0
                },
                {
                    "sent": "Well, this is basically expressing a systematic error.",
                    "label": 0
                },
                {
                    "sent": "If my hypothesis class is very small, I may not be able to actually capture F at all of the points OK, and so certain points are going to be badly captured all the time, and this is going to be high.",
                    "label": 0
                },
                {
                    "sent": "So this term here is the squared bias OK?",
                    "label": 0
                },
                {
                    "sent": "And typically, we're going to have a tradeoff where if the variance increases, the bias decreases and vice versa, OK?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the picture here OK, there's an error decomposition that we have here.",
                    "label": 1
                },
                {
                    "sent": "We have the test error, which is this black curve, and we're showing the different components of the error over here.",
                    "label": 0
                },
                {
                    "sent": "This was a small data set, so we can actually compute things analytically.",
                    "label": 0
                },
                {
                    "sent": "OK, so the pink curve down here that mimics the shape of the test.",
                    "label": 0
                },
                {
                    "sent": "There is actually computed.",
                    "label": 0
                },
                {
                    "sent": "Using the expectation analytically OK over the data distribution, you can see that it mimics the test error in terms of shape very well, although it's not quite of the same magnitude, but it's got these two components, the bias squared, which is the blue curve and the variance, which is the red curve.",
                    "label": 1
                },
                {
                    "sent": "And as you increase the size of your hypothesis space, basically you obtain more variance and less bias.",
                    "label": 0
                },
                {
                    "sent": "OK, this kind of U shaped curve for the test error.",
                    "label": 0
                },
                {
                    "sent": "As well As for the sort of true expected error of a hypothesis is very very typical.",
                    "label": 0
                },
                {
                    "sent": "OK doesn't always come out as cleanly, because in practice you have messier data sets, but you typically still see this kind of U shaped curve in test errors, and So what you want is to find the hypothesis class that's at the bottom of that you shape.",
                    "label": 0
                },
                {
                    "sent": "That would be sort of the best thing.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Bar.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here you can compute, you can compute H bar essentially by repeatedly taking a sample of the same size of number of points and fitting H and then taking the average of all of those.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do here basically is we add and we subtract an F. OK, so we started with this formula that has y -- H we add and subtract F and we rearrange the terms and here we've used the sort of product rule for the expectations because what happens is the noise in the output is independent of the noise that I might have in the hypothesis and then the rest of it is simply manipulating these terms and using the definition of Y.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So almost all learning algorithms have this bias variance tradeoff that you have to be mindful of.",
                    "label": 0
                },
                {
                    "sent": "OK, bias is typically telling you that you don't have good hypothesis in your hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "OK, and it generates systematic errors that you cannot eliminate because your hypothesis classes somewhere else than the true function variance.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results from having too many hypothesis in your hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "OK, so if your hypothesis class is very rich compared to the size of the data set that you are using OK, then various becomes an issue.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to talk in a minute about maximum likelihood estimation versus Bayesian estimation.",
                    "label": 0
                },
                {
                    "sent": "This is one way in which you can sort of tweak the bias variance tradeoff.",
                    "label": 0
                },
                {
                    "sent": "But typically this is a choice that you have to make OK and you make it based on the amount of data that.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have OK, so here's an example.",
                    "label": 0
                },
                {
                    "sent": "OK, we have two datasets, one with 15 points, one with 100 points.",
                    "label": 0
                },
                {
                    "sent": "OK, they are from the same distribution and having the same target function.",
                    "label": 0
                },
                {
                    "sent": "But what you see is that if you have more points, you can actually search for polynomials that have higher degrees and you'll still do well right?",
                    "label": 0
                },
                {
                    "sent": "Your approximate the data very well, why?",
                    "label": 0
                },
                {
                    "sent": "Because really it's not about the number of parameters, it's about how much data you have.",
                    "label": 0
                },
                {
                    "sent": "Compared to the number of parameters, then parameter vector has has to be supported by enough data.",
                    "label": 0
                },
                {
                    "sent": "Alot of the successes that we've seen for deep learning in recent years have been in these cases where you have very massive function approximators, but you also have very very massive datasets OK, and so we're in a situation that we haven't had in the past in some sense where there's millions of images there is billions of pages of text and so on that one can mine, and so of course, then you can support very big.",
                    "label": 0
                },
                {
                    "sent": "Approximators.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so mean squared error.",
                    "label": 0
                },
                {
                    "sent": "We've talked a little bit about this.",
                    "label": 0
                },
                {
                    "sent": "OK, it's got some nice math.",
                    "label": 0
                },
                {
                    "sent": "It's got actually a very nice geometric interpretation in terms of projections.",
                    "label": 0
                },
                {
                    "sent": "I'm not really going to tell you about that, but we're going to talk a little bit about this probabilistic assumption behind the mean squared error, because this is again a choice that we kind of made arbitrarily at the beginning, and it's useful for us for other problems to think a little bit about how we make these choices.",
                    "label": 0
                },
                {
                    "sent": "So remember I told?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You that we're going to be in the setting where you have a target.",
                    "label": 0
                },
                {
                    "sent": "OK, and we're thinking of this target coming from some function plus some Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "So for a minute, I'm going to assume that really this function is in my hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "OK, so there is some hypothesis with some parameter vectors.",
                    "label": 0
                },
                {
                    "sent": "I have access to and the examples actually have their targets generated from this hypothesis plus Gaussian noise that's drawn IID from.",
                    "label": 0
                },
                {
                    "sent": "Means zero Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's assume that this is the data.",
                    "label": 0
                },
                {
                    "sent": "This is my model for generating the data.",
                    "label": 0
                },
                {
                    "sent": "Now how should I choose a good parameter vector?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so one way that we we sort of do things in a principled fashion is to leverage based theorem.",
                    "label": 0
                },
                {
                    "sent": "OK, based here and basically tells us that each hypothesis has a probability given the data set that we have, and ideally we would find a hypothesis that has high probability.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, given the data and so what's the probability of a hypothesis given the data?",
                    "label": 0
                },
                {
                    "sent": "Well, I can just write down Bayes rule OK?",
                    "label": 0
                },
                {
                    "sent": "So it's PFD given H times pH divided by PFD.",
                    "label": 0
                },
                {
                    "sent": "OK, now this is kind of an interesting thing to ponder.",
                    "label": 0
                },
                {
                    "sent": "It's sort of a trivial thing to write down, but the meaning of these terms is actually kind of nice.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's pH?",
                    "label": 0
                },
                {
                    "sent": "pH is a proper prior probability of the hypothesis age OK?",
                    "label": 0
                },
                {
                    "sent": "And PFD given age.",
                    "label": 0
                },
                {
                    "sent": "Says given the hypothesis I have some probability for the data set.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "PFD really, we don't care about.",
                    "label": 0
                },
                {
                    "sent": "It's a normalization term.",
                    "label": 0
                },
                {
                    "sent": "OK, there's just there to make sure that you get a probability distribution out, and in fact we're going to ignore this.",
                    "label": 0
                },
                {
                    "sent": "OK, because if all we're looking for is a very good hypothesis, one that maximizes this BFH.",
                    "label": 0
                },
                {
                    "sent": "Given D, we have these just the constant, OK, and it doesn't really matter.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we can do is find the Max a posteriori hypothesis.",
                    "label": 0
                },
                {
                    "sent": "That means that hypothesis that maximizes pH given D and again in this case we don't really care about the PFD and we end up with a maximum in the hypothesis space of PFH times PFD given H. So this would be sort of the bashen answer for how to choose hypothesis and notice that it lets you put in some prior idea about what your hypothesis class ought to be OK. For example, I can put the prior that says simpler hypothesis are better, OK, or I can put the prior that says linear hypothesis are more likely than polynomial hypothesis of a higher degree and so on.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's a device that lets you put in also prior knowledge that you might have, especially in structured prediction.",
                    "label": 0
                },
                {
                    "sent": "About what kinds of hypothesis you would be looking for in the data and this other term PFD, given edge is something that we can just compute OK.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out of the data.",
                    "label": 0
                },
                {
                    "sent": "Now, if we were to assume that all hypothesis are equally likely OK, then what we end up with is what called a maximum likelihood hypothesis.",
                    "label": 0
                },
                {
                    "sent": "That's the hypothesis that just maximizes the likelihood of the data, and if we are assuming that the examples are ID, we can further simplify this, because PFD given edge is just going to be a product of the probabilities of each example, so this further simplifies here.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course we can apply the lectric you have.",
                    "label": 0
                },
                {
                    "sent": "We have a product but we don't really like to work with products.",
                    "label": 0
                },
                {
                    "sent": "We take the log of that.",
                    "label": 0
                },
                {
                    "sent": "That gives us some OK and then the sum.",
                    "label": 0
                },
                {
                    "sent": "We have the log of the likelihood of the hypothesis and we have two terms.",
                    "label": 0
                },
                {
                    "sent": "One has to do with the probability of the inputs slog PF XI and the other one is log P of Y given X and a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Second thing, we don't really know, right?",
                    "label": 0
                },
                {
                    "sent": "This is the stuff that's the probability of these examples being generated by the environment.",
                    "label": 0
                },
                {
                    "sent": "But we don't really care about it either.",
                    "label": 0
                },
                {
                    "sent": "Again, because it doesn't depend on the hypothesis class, it just depends on the environment.",
                    "label": 0
                },
                {
                    "sent": "So if all we're trying to do is to maximize with respect to H, this thing is just a constant OK, and we're going to ignore it, and we're going to focus on this first term, which is PFY given X and the hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the point.",
                    "label": 0
                },
                {
                    "sent": "So everything that we've done.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far is fully general.",
                    "label": 0
                },
                {
                    "sent": "It applies to all hypothesis classes.",
                    "label": 0
                },
                {
                    "sent": "It's just general principles of applying Bayes theorem for learning.",
                    "label": 0
                },
                {
                    "sent": "Now is the time if I want to talk about this probability of the output given the hypothesis class where I'm going to use the assumptions that are making about how the data.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's actually generated specifically.",
                    "label": 0
                },
                {
                    "sent": "Now I have my Gaussian assumption OK, and so if we adopt this Gaussian assumption that the outputs Y really are the value of the hypothesis plus some Gaussian noise, then the likelihood has a nice form.",
                    "label": 0
                },
                {
                    "sent": "OK, because we have gaussian's here.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can take the log OK. And maximizing the log likelihood becomes the same as optimizing the squared error.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's very nice.",
                    "label": 0
                },
                {
                    "sent": "OK, why is it nice?",
                    "label": 0
                },
                {
                    "sent": "Well, for one thing, it gives us a reason in hindsight as to why we're using the squared error while using the squared error, because we're maximizing the likelihood.",
                    "label": 0
                },
                {
                    "sent": "And we have this assumption of Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "That is, ID end up the same variance.",
                    "label": 0
                },
                {
                    "sent": "The other interesting thing about about this formula is that it also shows you exactly what assumptions you are making when you choose to optimize the squared error.",
                    "label": 0
                },
                {
                    "sent": "Again, this is quite important because in fact this is a pretty strong assumption.",
                    "label": 0
                },
                {
                    "sent": "OK, we have uniform prior over the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "We're assuming IID data, and we're assuming this Gaussian noise of fixed variance over all the input space.",
                    "label": 0
                },
                {
                    "sent": "OK, now if this assumption does not hold, for example, if the variance over the input space actually depends on the inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, then you in fact should not be optimizing this quarter.",
                    "label": 0
                },
                {
                    "sent": "You should be optimizing something else.",
                    "label": 0
                },
                {
                    "sent": "If you have outputs that are not continuous, outputs OK, but maybe they are counts.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe there are possible or whatever, depending on what you assume about that distribution of the output.",
                    "label": 0
                },
                {
                    "sent": "You may need to choose a different objective function.",
                    "label": 0
                },
                {
                    "sent": "So this is an exercise that essentially helps you uncover what exactly are the assumptions that you're making, and these assumptions are going to have to be different depending on the type of problem that you're faced with and the sort of class of thing that you're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "So for example, the minute we're going to talk about classification there, we're not going to make an assumption of Gaussian noise because that's not appropriate.",
                    "label": 0
                },
                {
                    "sent": "KR Noise is going to be different, and so therefore we're going to have.",
                    "label": 0
                },
                {
                    "sent": "A different objective function.",
                    "label": 0
                },
                {
                    "sent": "Any questions about this?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "About various decree.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "At least inconsistent.",
                    "label": 0
                },
                {
                    "sent": "And what's the effect of device value straight off?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So consistent estimator basically means that in the limit the bias goes to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a very happy case, which we usually don't have in fact, and so most of the time we.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of one of the differences between statisticians and machine learning.",
                    "label": 0
                },
                {
                    "sent": "People is statisticians talk about estimators, where the bias actually goes to zero in the limit, whereas we are often concerned we know we pick a hypothesis class, we don't make any assumptions about the data and therefore.",
                    "label": 0
                },
                {
                    "sent": "We kind of always end up with some bias and the variance squishing down.",
                    "label": 0
                },
                {
                    "sent": "And then it's just a question of finding an estimator that's less biased in some sense.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we've uncovered, sort of.",
                    "label": 0
                },
                {
                    "sent": "What are the assumptions behind using the?",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Squared error Now I just want to show you one other picture of how we think about this whole process.",
                    "label": 1
                },
                {
                    "sent": "OK and this is a little cartoon of much more general class of models called the graphical model.",
                    "label": 0
                },
                {
                    "sent": "It's a cartoon made for this particular situation.",
                    "label": 0
                },
                {
                    "sent": "OK, so here you have a graph where you have random variables at the notes.",
                    "label": 0
                },
                {
                    "sent": "OK and these arcs essentially are telling you influences and at every one of these nodes we have a probability distribution of that variable.",
                    "label": 0
                },
                {
                    "sent": "Conditioned on its parents.",
                    "label": 0
                },
                {
                    "sent": "So this cartoon here is basically showing you.",
                    "label": 0
                },
                {
                    "sent": "The process of data generation OK. And of that we can also use for fitting in the case of our regression problem.",
                    "label": 0
                },
                {
                    "sent": "So we have some data X that's drawn from some unknown probability distribution of the environment OK. We have a noise process which is the sort of normal Gaussian distributed noise.",
                    "label": 0
                },
                {
                    "sent": "OK in our case and we have the W vector.",
                    "label": 1
                },
                {
                    "sent": "Now the W vector.",
                    "label": 0
                },
                {
                    "sent": "We often think of it as searching, but actually we could think of it as a random variable that has its own prior distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to talk in a minute about the Bayesian approach to regression.",
                    "label": 0
                },
                {
                    "sent": "In that case, W actually has a prior distribution, and so the outputs we think of the outputs as being obtained.",
                    "label": 0
                },
                {
                    "sent": "Through this hypothesis that depends on W applied on the inputs X plus some noise, and so this actually is a deterministic node.",
                    "label": 0
                },
                {
                    "sent": "In our case, OK, and so the sort of the regression process for us is essentially a search over this W that gives us good likelihood for the data.",
                    "label": 0
                },
                {
                    "sent": "But of course if we had basean view OK, if we put a prior on W then we could in fact look for a Max a posteriori hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And we would in fact do inference in order to figure out what a good W might be.",
                    "label": 0
                },
                {
                    "sent": "And I believe you're going to talk about more later on in the week about things related to graphical models.",
                    "label": 0
                },
                {
                    "sent": "So what we would like is actually to sort of leverage this here a little bit in order to find ways during the training process to encourage the hypothesis class to have a good bias variance tradeoff.",
                    "label": 1
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now how do we do this?",
                    "label": 0
                },
                {
                    "sent": "Well, typically we do this through what's called regularization OK and regularization is sort of a tweak to the optimization criterion, but we're going to see in a minute it's actually sort of very principled from this point of view of map fitting.",
                    "label": 0
                },
                {
                    "sent": "OK, so regularization basically says we have our usual objective, which is to fit the data.",
                    "label": 0
                },
                {
                    "sent": "This is this term JD FW measures error on the data and we're going to.",
                    "label": 0
                },
                {
                    "sent": "Add to this a penalty OK and this penalty function essentially is going to encourage simple hypothesis and there's a constant Lambda here that kind of tradeoff between these two things.",
                    "label": 0
                },
                {
                    "sent": "It's also called the regularization coefficient.",
                    "label": 0
                },
                {
                    "sent": "And this form of the penalty is something also that we choose.",
                    "label": 0
                },
                {
                    "sent": "So in statistics this is called shrinkage.",
                    "label": 0
                },
                {
                    "sent": "In machine learning we call it regularization.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now we can think of what might be good ways to encourage simple hypothesis.",
                    "label": 1
                },
                {
                    "sent": "So one way we can sort of formalize simplicity is to say, well, we would like the weights to be close to 0.",
                    "label": 0
                },
                {
                    "sent": "Ideally.",
                    "label": 0
                },
                {
                    "sent": "In fact, what we would like is for some of the ways to be exactly 0.",
                    "label": 0
                },
                {
                    "sent": "That means some of the inputs don't really matter and we keep the size of the hypothesis space in check by essentially ignoring some of the inputs.",
                    "label": 0
                },
                {
                    "sent": "But if you want to do that, I'm going to show you that in a minute as well.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit harder to optimize and so sort of a good compromise is to just say well.",
                    "label": 0
                },
                {
                    "sent": "Actually, let's just encourage the weights to be close to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, we can do that by adding a penalty term on the L2 norm of the weight vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so the second term here half of W, transpose W, is basically a penalty on the magnitude of the weights.",
                    "label": 0
                },
                {
                    "sent": "And sometimes this is called L2 regularization in neural net literature.",
                    "label": 1
                },
                {
                    "sent": "Sometimes you see this is called weight decay.",
                    "label": 0
                },
                {
                    "sent": "You notice that if I do this, the complexity of the problem of optimizing is exactly the same.",
                    "label": 0
                },
                {
                    "sent": "OK, in fact, we can still solve things in closed form, and you get a closed form solution here for the weight vector, which is like we had before 5 transpose 5, but we apply a Lambda identity matrix OK to that.",
                    "label": 0
                },
                {
                    "sent": "So essentially the diagonal of that gets boosted.",
                    "label": 0
                },
                {
                    "sent": "Notice that this has the side effect of actually improving the conditioning of this matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's more likely that this matrix in fact is going to be invertible.",
                    "label": 0
                },
                {
                    "sent": "Can we won't run into numerical issues if we do this?",
                    "label": 0
                },
                {
                    "sent": "Now of course, what happens if I make Lambda very, very big here?",
                    "label": 0
                },
                {
                    "sent": "What am I going to do?",
                    "label": 1
                },
                {
                    "sent": "One person.",
                    "label": 0
                },
                {
                    "sent": "It's going to ignore the data completely, right?",
                    "label": 0
                },
                {
                    "sent": "If I flunk that goes to Infinity.",
                    "label": 1
                },
                {
                    "sent": "In fact, it's going to just return a vector that's very very close to zero, OK?",
                    "label": 0
                },
                {
                    "sent": "And of course, if I said Lambda to 0, then there is no regularization penalty, right?",
                    "label": 0
                },
                {
                    "sent": "I'm just fitting the labels, so you see that now you have a nob.",
                    "label": 0
                },
                {
                    "sent": "Actually, that you can use to make your hypothesis space more or less expressive.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a bias variance variance tradeoff nob, OK?",
                    "label": 0
                },
                {
                    "sent": "So if I make Lambda very big, obtain a hypothesis class, which is very, very simple, very biased, OK, very low variance, I'll always get a zero no matter what the data is.",
                    "label": 0
                },
                {
                    "sent": "I'll always get a zero.",
                    "label": 0
                },
                {
                    "sent": "It's very low variance.",
                    "label": 0
                },
                {
                    "sent": "Very useful, OK.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this particular thing is also called Ridge regression.",
                    "label": 0
                },
                {
                    "sent": "It's a special case of Tikhonov regularization, in fact.",
                    "label": 0
                },
                {
                    "sent": "And it can be viewed from sort of many different perspective.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tips and interest of time.",
                    "label": 0
                },
                {
                    "sent": "I'm going to sort of skip this, but I'll show you sort of one way that we can visualize this, OK?",
                    "label": 0
                },
                {
                    "sent": "So imagine that I show you the error function.",
                    "label": 0
                },
                {
                    "sent": "OK, so the error function is a quadratic.",
                    "label": 1
                },
                {
                    "sent": "The bowl here we have two parameters, so you have your error function which is a bowl.",
                    "label": 0
                },
                {
                    "sent": "It's the error of the data OK, and I'm looking at it from above.",
                    "label": 0
                },
                {
                    "sent": "This is the circles over here.",
                    "label": 1
                },
                {
                    "sent": "OK, now what does this L2 penalty say?",
                    "label": 0
                },
                {
                    "sent": "the Celtic penalty basically says.",
                    "label": 0
                },
                {
                    "sent": "Well, actually I would like my weights to be close to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so in fact I would like my weights to be somewhere in a circle around zero OK, and the radius of the circle is controlled by the regularization parameter Lambda.",
                    "label": 1
                },
                {
                    "sent": "So more precisely, it's like one over Lambda.",
                    "label": 1
                },
                {
                    "sent": "So if Lambda is very big, the circle really shrinks and I actually really want my weights to be close to 0.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do if we have no regularization is to optimize for this quadratic, which means we descend the ball and we're going to find the blue point here.",
                    "label": 0
                },
                {
                    "sent": "However, if we add this quadratic penalty, what happens is we would like to optimize this subject to a constraint, this constraint being that the weights are somewhere within this yellow circle.",
                    "label": 0
                },
                {
                    "sent": "OK, and the size of the yellow circle is controlled by Lambda.",
                    "label": 0
                },
                {
                    "sent": "So what we find essentially is we find a point that's on the edge of the Circle K and it's as close as possible to the center of the blue circle.",
                    "label": 0
                },
                {
                    "sent": "That's the solution.",
                    "label": 0
                },
                {
                    "sent": "So regularization you can interpret it as a constraint optimization problem that we're going to solve instead of an unconstrained optimization problem which we had before.",
                    "label": 0
                },
                {
                    "sent": "And the constraint is controlled by this regularization constant Lambda.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now people sometimes think of regularization as something to helps you sort of avoid overfitting.",
                    "label": 0
                },
                {
                    "sent": "So then the question comes, does this mean that we have to not do cross validation anymore?",
                    "label": 0
                },
                {
                    "sent": "For my point of view, the answer is no.",
                    "label": 0
                },
                {
                    "sent": "You always, always, always have to do cross validation OK Huawei, because in fact you actually don't quite know what the magnitude of this regularization penalty ought to be, right?",
                    "label": 0
                },
                {
                    "sent": "You can kind of think of it as being given, but oftentimes you in fact will want to optimize it somehow.",
                    "label": 0
                },
                {
                    "sent": "And then you're going to use a validation set in order to optimize that.",
                    "label": 0
                },
                {
                    "sent": "As well.",
                    "label": 0
                },
                {
                    "sent": "Now what will happen with this kind of penalty is that the weights are going to shrink OK, but if you have irrelevant input styles still probably have non 0 weight small.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But but still not quite the same as sort of eliminating those inputs.",
                    "label": 0
                },
                {
                    "sent": "So there's a different way of doing the penalization, called L1 regularization, which you may have heard of very popular in the statistics community.",
                    "label": 0
                },
                {
                    "sent": "Which basically says instead of constraining the L2 norm of the weights, let's constrain the L1 norm of the weights.",
                    "label": 0
                },
                {
                    "sent": "OK, and so the picture for that is that we're going to have a little diamond shape around the origin and we would like the weights to be somewhere inside of this time.",
                    "label": 0
                },
                {
                    "sent": "So we say this by imposing these sort of absolute value constraint, sum of absolute values on the weights being smaller than some regularization constant.",
                    "label": 0
                },
                {
                    "sent": "This yields an algorithm called lasso and all that sort of friends in this.",
                    "label": 0
                },
                {
                    "sent": "That are used in the statistics community.",
                    "label": 0
                },
                {
                    "sent": "This kind of looks ugly because you have these constraints here with absolute values in them.",
                    "label": 0
                },
                {
                    "sent": "But what happens is you can actually read.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write these constraints by expanding the absolute values OK, and they turn into linear constraints.",
                    "label": 0
                },
                {
                    "sent": "You just have to put the constraint for all of the cases of all the combinations of different signs to the weights, so of course this is going to be expensive, right?",
                    "label": 0
                },
                {
                    "sent": "Because if you have many whites, there's many combinations of these signs, right?",
                    "label": 0
                },
                {
                    "sent": "So the number of constraints kind of explodes, but you still have a problem that is fairly easy to solve up to a certain size.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the good thing about that one regularization is that it gives you sparse solutions.",
                    "label": 0
                },
                {
                    "sent": "So certain variables that are irrelevant for the target will just get 0 white and essentially can eliminate them from the datasets.",
                    "label": 0
                },
                {
                    "sent": "One reason why it's popular in the statistics community, because if you have, for example, biostats tasks, you actually want to know what are the variables that matter for your target and just keep those and eliminate everything else.",
                    "label": 0
                },
                {
                    "sent": "But the optimization tends to be much more expensive than using L2, and so when we have deep Nets almost always were in fact going to use L2 and not L1 regularization.",
                    "label": 1
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, this is showing you sort of the effect of the weights.",
                    "label": 0
                },
                {
                    "sent": "OK so this is starting with a number of features.",
                    "label": 0
                },
                {
                    "sent": "OK, in the task that we had at the beginning of this class and increasing the amount of regularization.",
                    "label": 0
                },
                {
                    "sent": "So of course as you increase the amount of regularization encouraged the ways to go to zero.",
                    "label": 0
                },
                {
                    "sent": "But you see that in the case of L2 all the way, it's kind of all shrinks zero together, whereas in the case of L1, certain variables just kind of start and then go to zero, OK, and then their weight stays at zero and some other variables goes to 0.",
                    "label": 0
                },
                {
                    "sent": "Is at zero OK, so at any point in time only and limited number of variables actually have any non zero weights.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of the distinction between these two.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now how do we think of this from a probabilistic perspective?",
                    "label": 0
                },
                {
                    "sent": "What do these L1 and L2 penalties do?",
                    "label": 0
                },
                {
                    "sent": "Well, in fact what they do is they impose specific prior assumptions on the weight vector.",
                    "label": 0
                },
                {
                    "sent": "OK. And.",
                    "label": 0
                },
                {
                    "sent": "So in the case of L2, for example, we're going to put an assumption on the weight vector, which is a Gaussian assumption.",
                    "label": 0
                },
                {
                    "sent": "We assume that the weights come drawn initially from a Gaussian of mean zero.",
                    "label": 0
                },
                {
                    "sent": "And so, with this prior distribution, then we can optimize for posterior OK and we obtain L2 regularization and so essentially we obtain the map hypothesis is the one that you obtained by doing the L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "Now what does the Lambda parameter do?",
                    "label": 0
                },
                {
                    "sent": "Well, the Lambda parameter essentially tells me how much confidence do I have in my prior.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's sort of the if you have a very high Lambda it will take more data in order to wash out that prior.",
                    "label": 0
                },
                {
                    "sent": "Similarly, for L1 regularization, this kind of double exponential prior.",
                    "label": 0
                },
                {
                    "sent": "This was also shown formally by Taxi, Ronnie.",
                    "label": 0
                },
                {
                    "sent": "That corresponds to this weight vector and in general we can impose other priors on the weight vector, and we can sort of translate that into different forms of regularization tradeoffs always from the sort of computational POV involve how easy is that?",
                    "label": 0
                },
                {
                    "sent": "The resulting optimization problem so very often we make an assumption.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily because it's the best assumption for that particular data set, but because it leads to an optimization that we can actually solve through efficient means even when the function approximator becomes very big.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, if you come to this conclusion that you could have priors on the hypothesis space, you could actually take this to a more extreme setting where we do.",
                    "label": 0
                },
                {
                    "sent": "In fact, Bayesian optimization over the hypothesis space rather than doing just the fitting of 1 hypothesis, which is the most likely hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the picture over here again from taken from the Bishop book, which gives you a beige and view OK of regularization, but sort of more fully Bayesian.",
                    "label": 0
                },
                {
                    "sent": "So what do we do here?",
                    "label": 0
                },
                {
                    "sent": "Let's assume that we have a Gaussian round prior over the weight space.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the picture on top here with the circles that's the prior over the weights.",
                    "label": 0
                },
                {
                    "sent": "OK, So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "This means that we could draw weights from this prior and every weight vector corresponds to a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So really, every white vector actually gives me a line OK, and so these are the lines over here.",
                    "label": 0
                },
                {
                    "sent": "These red lines there all hypothesis that are drawn from this prior.",
                    "label": 0
                },
                {
                    "sent": "Now some data comes in.",
                    "label": 1
                },
                {
                    "sent": "OK, one data point comes in chicken very barely.",
                    "label": 0
                },
                {
                    "sent": "See here.",
                    "label": 0
                },
                {
                    "sent": "It's a blue point.",
                    "label": 0
                },
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "Now we want to fit the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so we want to maximize the likelihood of this data.",
                    "label": 0
                },
                {
                    "sent": "But we also have the prior information, so the likelihood of the data is this sort of square here with the line that basically says we like all kinds of lines, but they have to go through this point.",
                    "label": 1
                },
                {
                    "sent": "OK, they have to be anchored somewhere close to this point.",
                    "label": 1
                },
                {
                    "sent": "Now we can combine this with the prior on the weights and we get a posterior.",
                    "label": 0
                },
                {
                    "sent": "This is this sort of Ellen gated Gaussian here.",
                    "label": 0
                },
                {
                    "sent": "OK, what does this mean?",
                    "label": 0
                },
                {
                    "sent": "What this means that now we can draw weight vectors OK and see what they do?",
                    "label": 0
                },
                {
                    "sent": "What they do is they give us line that all go through the data point that I have.",
                    "label": 0
                },
                {
                    "sent": "OK, we still don't know very much about these lines.",
                    "label": 0
                },
                {
                    "sent": "There's still great variability, right?",
                    "label": 0
                },
                {
                    "sent": "So it's the case of high variance because we have very little data to support our choice and so a lot of the these lines are in fact sort of driven by the prior, but they're all anchored at this point.",
                    "label": 0
                },
                {
                    "sent": "Now, what happens if we get a second point?",
                    "label": 0
                },
                {
                    "sent": "OK, so here we're getting a second point, sort of at the bottom.",
                    "label": 0
                },
                {
                    "sent": "Over here and so now we have another likelihood term coming from the second point.",
                    "label": 0
                },
                {
                    "sent": "We're going to take this and combine it with the first term, and so we get a Gaussian here, still Gaussian, but it's much tighter, because now we have more data and so the distribution of the weights has become much tighter and so now again we can draw from this distribution.",
                    "label": 0
                },
                {
                    "sent": "We still have some variability.",
                    "label": 0
                },
                {
                    "sent": "So there are many different hypothesis that we could have, but they all kind of go in the vicinity of these two points because that's what the likelihood terms are making us do an, so we can continue this process.",
                    "label": 0
                },
                {
                    "sent": "OK, we can add more points.",
                    "label": 0
                },
                {
                    "sent": "These points bring in terms to the likelihood.",
                    "label": 0
                },
                {
                    "sent": "OK, the more points we have, the more the likelihood becomes important, OK, and So what you see is, these Gaussian blobs are getting tighter and tighter.",
                    "label": 0
                },
                {
                    "sent": "OK, the weight vectors become more and more similar to each other.",
                    "label": 1
                },
                {
                    "sent": "Because they are forced by the likelihood terms to fit the data OK.",
                    "label": 0
                },
                {
                    "sent": "But still if you look at this picture, the very last picture, there's still a bunch of lines in there, not just one line.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the distinction between sort of maximum likelihood or map fitting versus sort of the pure beige and view in the Bayesian view.",
                    "label": 0
                },
                {
                    "sent": "Never have one hypothesis, so you always have a distribution of our hypothesis and you kind of carried that distribution around.",
                    "label": 0
                },
                {
                    "sent": "You might sample from it, OK?",
                    "label": 0
                },
                {
                    "sent": "You have some hypothesis that you return or some subset of hypothesis to return, but you always keep in mind that there's this distribution over hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, why is this interesting?",
                    "label": 0
                },
                {
                    "sent": "OK, here's an example.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the same data set with one point and two points.",
                    "label": 0
                },
                {
                    "sent": "There's some true function, which is this green function, and you can see a whole bunch of hypothesis that are these polynomials that have been drawn, and what you can see is that they are all very wild, but they all kind of fit the data OK, so actually we can map where we are certain about the values and where these hypothesis have a lot of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this particular case around where the data is, uncertainty gets reduced.",
                    "label": 1
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because the hypothesis are forced to fit the data points and so they have to go in some small business entity around the data points very far away from the data.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of uncertainty because we have no information there, and so all that we have acting there is the prior in the prior.",
                    "label": 0
                },
                {
                    "sent": "In this case is a very vanilla prior.",
                    "label": 0
                },
                {
                    "sent": "So this is useful because it gives you some information about the uncertainty in your prediction as opposed to just returning you one.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And this is sort of further illustration of this.",
                    "label": 0
                },
                {
                    "sent": "As you get more and more data OK. Of course the uncertainty decreases OK and you end up with something that is around the true function.",
                    "label": 1
                },
                {
                    "sent": "And of course you see this when you draw from the posterior.",
                    "label": 1
                },
                {
                    "sent": "You draw this your draw these hypothesis.",
                    "label": 0
                },
                {
                    "sent": "They're all kind of clustered together.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This approach is conceptually nice.",
                    "label": 0
                },
                {
                    "sent": "It's useful when you are in situations where in fact you don't have very much data, and it's very important for you to know where the where the uncertainty is and where your predictor is actually reliable.",
                    "label": 0
                },
                {
                    "sent": "It's not feasible to do this in very large hypothesis spaces, at least not at the moment, because you know, keeping these distributions cannot be done in closed form always.",
                    "label": 0
                },
                {
                    "sent": "This is sort of a happy case where we're doing things in closed form, but most of the time you need to do this.",
                    "label": 0
                },
                {
                    "sent": "We are sampling and that becomes quite expensive.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But I just wanted to sort of bring this to your attention because it's actually kind of interesting now.",
                    "label": 0
                },
                {
                    "sent": "The other thing that I wanted to say is that the sort of in the limit, the Bashan and the maximum likelihood view, converge to the same thing in the limit of infinite amount of data.",
                    "label": 0
                },
                {
                    "sent": "But in the short term they will not give you the same answer, and in particular the Bayesian approach is biased by the prior.",
                    "label": 1
                },
                {
                    "sent": "OK now is biased good or bad.",
                    "label": 0
                },
                {
                    "sent": "Well, that depends, OK?",
                    "label": 0
                },
                {
                    "sent": "If you have a good prior nearby stores the prior then it's great.",
                    "label": 0
                },
                {
                    "sent": "OK if you're just using a vanilla priority, don't have a good prior, then it can actually hurt you.",
                    "label": 0
                },
                {
                    "sent": "So how will this approach works is really dependent on how good your priors.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The other interesting thing is that these uncertainty estimates can be used for other purposes.",
                    "label": 0
                },
                {
                    "sent": "So for example, there is a setup called active learning in which the learner is allowed to ask questions.",
                    "label": 0
                },
                {
                    "sent": "So it's not just that you get a data set and you do whatever you want with that particular data set, but actually the learner is allowed to go back and ask for labels for specific input examples.",
                    "label": 0
                },
                {
                    "sent": "OK, so if I have a patient, I have a classifier classifier, doesn't know the label for this patient, can go back to the doctor and ask for label for this patient.",
                    "label": 0
                },
                {
                    "sent": "So how do you do this kind of thing?",
                    "label": 0
                },
                {
                    "sent": "Where very often the uncertainty estimates is what drives this right?",
                    "label": 0
                },
                {
                    "sent": "Specifically, we're going to go and ask questions about examples that were very uncertain, right?",
                    "label": 0
                },
                {
                    "sent": "Just like a student before an exam goes and ask the teacher about questions they don't think that they know the answer to and so you can use these uncertainty estimates.",
                    "label": 0
                },
                {
                    "sent": "In the case of active learning and other methods like this in order to shape the strategy of the learner.",
                    "label": 0
                },
                {
                    "sent": "Any questions or comments about this so far?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's correct.",
                    "label": 0
                },
                {
                    "sent": "So the Lambda inverse is the variance of the Gaussian basically.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So so in general, LP spaces can also be linked to priors.",
                    "label": 0
                },
                {
                    "sent": "OK, just about.",
                    "label": 0
                },
                {
                    "sent": "So if you think of the term at the sort of the regularization objective, right which has the data portion, and then you have plus Lambda in this other penalty, right?",
                    "label": 0
                },
                {
                    "sent": "If you think of this as you take it to an exponential OK, then you can tell that you have this kind of exponential family flavor to things, right so?",
                    "label": 0
                },
                {
                    "sent": "Regularization of many different kinds, in fact can be thought of as having one of these exponential family priors now, which kind of regularization you do.",
                    "label": 0
                },
                {
                    "sent": "Again, you know, should you do LP, for example?",
                    "label": 0
                },
                {
                    "sent": "Well, that depends on the complexity and sort of the amount of data that you have in the complexity of the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "In the case where, for example, so LO, nobody does LO OK, even though in some sense it's exactly what we would like to do.",
                    "label": 0
                },
                {
                    "sent": "But solving that optimization problem is very complicated.",
                    "label": 0
                },
                {
                    "sent": "Some of the LP Regularization's are quite feasable and so so people will will do that.",
                    "label": 0
                },
                {
                    "sent": "And then there's also different kinds of combinations.",
                    "label": 0
                },
                {
                    "sent": "So for example, there's tricks like combining L1 and L2 or Huber eyes losses where you have an L1 component in just a dash of L2 at the bottom to make things differentiable, and so on.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So if you think of our formula right, we have PFD given H which is the data set right?",
                    "label": 0
                },
                {
                    "sent": "And then pH and so pH is 1.",
                    "label": 0
                },
                {
                    "sent": "So if I take the log of that pH gives me one term and PFD.",
                    "label": 0
                },
                {
                    "sent": "Given H is actually a sum of terms in the ID assumption, one term for every data point.",
                    "label": 0
                },
                {
                    "sent": "And so if I take the amount of data and take it to Infinity, the number of terms in that sums and that some goes to Infinity OK, and so essentially those terms are going to dominate the objective.",
                    "label": 0
                },
                {
                    "sent": "And if I can optimize those terms, I will be very good.",
                    "label": 1
                },
                {
                    "sent": "Now how do I make sure that that doesn't happen too fast, but that's by basically making the prior stronger and supporting for example a higher regularization constant is going to make sure that the prior doesn't.",
                    "label": 0
                },
                {
                    "sent": "Wash off too quick.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "What's your view?",
                    "label": 0
                },
                {
                    "sent": "Anyone?",
                    "label": 0
                },
                {
                    "sent": "Position for feature selection.",
                    "label": 0
                },
                {
                    "sent": "So that's an interesting question, so I'm not I'm not a statistician, so perhaps not the best qualified to to discuss that.",
                    "label": 0
                },
                {
                    "sent": "But my understanding is that one has been very successful at doing sort of feature selection and many contexts, perhaps not in its more vanilla form, but in more evolved forms, right?",
                    "label": 0
                },
                {
                    "sent": "So there is, for example, group lasso style algorithms where you sort of select the subgroup of features and then you do.",
                    "label": 0
                },
                {
                    "sent": "Further regularization within that many of these things seem to have worked quite well for various sort of biomedical tasks.",
                    "label": 0
                },
                {
                    "sent": "For example genetic tasks and so on.",
                    "label": 0
                },
                {
                    "sent": "My experience has been that anything that I need to do I can do with L2, and so I usually don't use a one very much just because the size of approximators that I need a one would not necessarily be be feasable.",
                    "label": 0
                },
                {
                    "sent": "But my understanding is that it's actually pretty good at doing feature selection.",
                    "label": 0
                },
                {
                    "sent": "The exception is for specific classes of problems, for example where submodularity holds you can actually have better feature selection.",
                    "label": 0
                },
                {
                    "sent": "Approaches that leverage combinatorial optimization, but that requires further assumptions on the feature space.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Can you set up?",
                    "label": 0
                },
                {
                    "sent": "We don't necessarily encode that weight should be close to 0 right.",
                    "label": 0
                },
                {
                    "sent": "L2 and L1 have this kind of prior, right?",
                    "label": 0
                },
                {
                    "sent": "One has a sparsity prior, just the number of non zero weights should be small.",
                    "label": 0
                },
                {
                    "sent": "L2 has this prior of what's going to 0, but in general in the Bashan view you can put the prior of any kind you want and it does not.",
                    "label": 0
                },
                {
                    "sent": "It's often a simplicity prior, like why it's going to 0, but it doesn't have to be.",
                    "label": 1
                },
                {
                    "sent": "It can be something else that's informed by the problem at hand.",
                    "label": 0
                },
                {
                    "sent": "OK, and so for example if you know.",
                    "label": 0
                },
                {
                    "sent": "That certain features are important for your problem and that they should be part of the approximator that you want to obtain at the end.",
                    "label": 0
                },
                {
                    "sent": "Then you can put the prior that says the weights of these features should be high.",
                    "label": 0
                },
                {
                    "sent": "There's nothing sort of preventing you from doing that in this field.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Is good.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so that uninformative priors have sort of two points.",
                    "label": 0
                },
                {
                    "sent": "One is sometimes you just don't know uninformative prior but you still want to express this sort of a regularization towards something right?",
                    "label": 0
                },
                {
                    "sent": "And so then you know you can put in a very simple prior.",
                    "label": 0
                },
                {
                    "sent": "The other thing is that sometimes this sort of prior is used to better condition the optimization objective.",
                    "label": 0
                },
                {
                    "sent": "This is not apparent in the simple cases that we're talking about here, but in the case.",
                    "label": 0
                },
                {
                    "sent": "Of neural Nets, for example, where you have nonconvex optimization and so the error landscape is very irregular, you may want to do things in such a way that you kind of smooth out the optimization objective and so that you know you can use the regularization terms to help you do that, and you'll hear more about that later.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's one last thing that I want to talk about today, which is the classification tasks OK and the counterpart of linear regression regression for classification problems is logistic regression.",
                    "label": 0
                },
                {
                    "sent": "So in logistic regression, we have a hypothesis that's represented as a logistic function.",
                    "label": 0
                },
                {
                    "sent": "OK, so logistic function, we have a linear combination of inputs with weights or of inputs fed through some feature vector combined with the weights.",
                    "label": 0
                },
                {
                    "sent": "And you put this through a nonlinearity which is this 1 / 1 plus yeast.",
                    "label": 0
                },
                {
                    "sent": "Essentially, what this gives you is a soft threshold.",
                    "label": 0
                },
                {
                    "sent": "OK, so instead of having a threshold that goes up like this, you have sort of a curve that is close to zero, close to one and has a soft threshold in between and the weight vector essentially controls the curvature and the position of that threshold.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the linear OK version of a decision surface.",
                    "label": 1
                },
                {
                    "sent": "Now why do I say that?",
                    "label": 0
                },
                {
                    "sent": "Well, let's look for a minute at some particular example X. OK, let's assume that this is our hypothesis class with the weight vector, and we have here the log odds ratio.",
                    "label": 0
                },
                {
                    "sent": "So the probability of Y being one versus the probability of why being OK.",
                    "label": 0
                },
                {
                    "sent": "So we had, we take the log of that.",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "Well, this is actually a linear surface.",
                    "label": 0
                },
                {
                    "sent": "W transpose X OK.",
                    "label": 0
                },
                {
                    "sent": "So what does this mean?",
                    "label": 1
                },
                {
                    "sent": "It means that if W transpose X is positive, I'm going to answer that.",
                    "label": 0
                },
                {
                    "sent": "The label of this example is 1, and otherwise I'm going to answer that.",
                    "label": 0
                },
                {
                    "sent": "The label of this example is zero.",
                    "label": 1
                },
                {
                    "sent": "That's the most likely sort of label for this example.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially, if you're thinking of these examples as points, OK, given by the inputs, what we're doing is we're drawing a decision boundary, which is a linear decision boundary that separates.",
                    "label": 1
                },
                {
                    "sent": "The positive and the negative examples.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case we are essentially doing linear classification using this sort of logistic regression mechanism.",
                    "label": 1
                },
                {
                    "sent": "And the best weights are going to optimize the conditional likelihood of the output given the input now.",
                    "label": 0
                },
                {
                    "sent": "Here again, we have a hypothesis which is smooth in the weight vector.",
                    "label": 0
                },
                {
                    "sent": "OK, and we'd like to find the best weight vector.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now how do we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, we're going to optimize some objective.",
                    "label": 0
                },
                {
                    "sent": "OK, now what's our objective?",
                    "label": 0
                },
                {
                    "sent": "In this case we have binary outputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so having sort of a Gaussian noise model is no longer a good idea, and so therefore we're not going to use square there.",
                    "label": 0
                },
                {
                    "sent": "But we still would like to optimize log likelihood.",
                    "label": 0
                },
                {
                    "sent": "OK, that's sort of the easiest and the best thing that we can do.",
                    "label": 0
                },
                {
                    "sent": "So what's the log likelihood of a hypothesis?",
                    "label": 1
                },
                {
                    "sent": "Well, if the output is 1, then it's given by log H of XI.",
                    "label": 0
                },
                {
                    "sent": "And if an example has labeled zero, it's log of 1 -- H of XI.",
                    "label": 0
                },
                {
                    "sent": "So we can take these terms and put them under 1 formula.",
                    "label": 0
                },
                {
                    "sent": "OK, using this trick you know noticing that Y is either one or zero.",
                    "label": 0
                },
                {
                    "sent": "So in that case 1 -- y is 1 and so we can take this sort of bracket and put it all together using Y and 1 -- y and so we get one objective function which gives us the log likelihood and we can optimize.",
                    "label": 1
                },
                {
                    "sent": "This is also called the cross entropy error function.",
                    "label": 0
                },
                {
                    "sent": "OK, and because this depends on H which is smooth.",
                    "label": 0
                },
                {
                    "sent": "OK, we can take gradients and you know think of setting those gradients to zero in order to find.",
                    "label": 0
                },
                {
                    "sent": "The optimum.",
                    "label": 0
                },
                {
                    "sent": "So classification has a different objective function from linear regression.",
                    "label": 0
                },
                {
                    "sent": "However, the principle is the same.",
                    "label": 0
                },
                {
                    "sent": "We're trying to optimize log likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a picture of the error surface for this logistic function.",
                    "label": 0
                },
                {
                    "sent": "OK, you can see that it's very nice.",
                    "label": 0
                },
                {
                    "sent": "Very well behaved OK, looks like it's got an optimum, but actually we can't really solve this optimization and closed form.",
                    "label": 0
                },
                {
                    "sent": "And if you take the gradients you're going to see this very easily right?",
                    "label": 0
                },
                {
                    "sent": "You have some exponentials here.",
                    "label": 0
                },
                {
                    "sent": "Going to take derivatives of exponentials, you want to set to zero.",
                    "label": 0
                },
                {
                    "sent": "You can't really set to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, can solve that in closed form, even though this is a convex optimization problem, so it has a unique optimum.",
                    "label": 0
                },
                {
                    "sent": "So as I told you, linear regression is your one moment of joy where you can actually have closed form solutions.",
                    "label": 0
                },
                {
                    "sent": "Now we can no longer do that, but we can still do something really good.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is called gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So gradient descent basically says we have some objective function.",
                    "label": 0
                },
                {
                    "sent": "We're just going to step down in the direction of the gradient in order to get to an optimum solution.",
                    "label": 0
                },
                {
                    "sent": "The first picture here is a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "There's a unique optimum, and so you can just do this with a step size and get to the optimum.",
                    "label": 0
                },
                {
                    "sent": "The second picture here is what you typically have in deep Nets.",
                    "label": 0
                },
                {
                    "sent": "It's a non convex optimization problem and so you start somewhere.",
                    "label": 0
                },
                {
                    "sent": "You go down, you'll end up in one of these wells you don't know which one.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're just going to try and do our best to end up in a good well, but it's going to end up with a locally optimal solution as opposed to a globally optimal solution.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is again the sort of non convex optimization picture.",
                    "label": 0
                },
                {
                    "sent": "You can start in different places.",
                    "label": 0
                },
                {
                    "sent": "You can run the optimization and ends up with a locally optimal solution.",
                    "label": 0
                },
                {
                    "sent": "OK, there may be many locally optimal solutions and So what we're going to do is probably do this several times with different initial weight vector parameters to make sure that we kind of cover the space of possible optimal solutions.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is just a little picture of what the gradient descent algorithm looks like.",
                    "label": 0
                },
                {
                    "sent": "In general.",
                    "label": 0
                },
                {
                    "sent": "You have some objective function J.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume that the gradient of this objective function can be computed easily, and So what we're going to do is take an initial guess of the parameter vector that's called WO, and then we're going to Step 2 and you guess for the parameter vector.",
                    "label": 0
                },
                {
                    "sent": "So from a guest WI will go to a guest WI plus one.",
                    "label": 0
                },
                {
                    "sent": "How do we do this well?",
                    "label": 0
                },
                {
                    "sent": "We step in the direction of the gradient OK, because that's the direction of steepest descent.",
                    "label": 0
                },
                {
                    "sent": "The minus here says we're stepping down in the direction of the gradient because we're doing a minimization problem OK, and then we have this parameter here Alpha, which is called the step size or learning rate for this particular iteration.",
                    "label": 0
                },
                {
                    "sent": "It's something between zero and one, usually pretty small, and it's telling us in some sense how much we want to step down in the direction of the gradient, how sort of how confident are we?",
                    "label": 0
                },
                {
                    "sent": "That this is a good direction.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we can exactly do this in the case of logistic regression.",
                    "label": 0
                },
                {
                    "sent": "OK, we can take the log of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "We can take the gradient of that.",
                    "label": 0
                },
                {
                    "sent": "We can optimize.",
                    "label": 0
                },
                {
                    "sent": "And actually we get a formula which is quite nice.",
                    "label": 0
                },
                {
                    "sent": "OK, once you do all the calculations, calculations are not so important now which basically says we're going to use the inputs OK and then Y minus.",
                    "label": 0
                },
                {
                    "sent": "Why hat is the error?",
                    "label": 0
                },
                {
                    "sent": "OK, so we're just going to sort of optimize these weights in such a way as to improve on the error of our estimates, and we're just going to run this algorithm for many steps because it's a convex optimization problem, there's one.",
                    "label": 0
                },
                {
                    "sent": "Solution we're going to obtain that.",
                    "label": 0
                },
                {
                    "sent": "There's one little tricky thing here, which is that we have this learning rate or stepsize parameter, and that's going to influence the quality of the solution that we get OK and so.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a way actually to get around that problem, which is to remember from sort of calculus classes that one could in fact use a sort of what we call a second order method.",
                    "label": 0
                },
                {
                    "sent": "OK, so in our case we're trying to find the point where the gradient is zero, OK, and so if you want to try to find the zeros of some function.",
                    "label": 0
                },
                {
                    "sent": "OK, the way you do that is, you approximate by the tangent and then you solve this linear equation.",
                    "label": 0
                },
                {
                    "sent": "OK, that's called nute.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This method, and so we can just apply that with our function being the gradient.",
                    "label": 0
                },
                {
                    "sent": "OK, 'cause we're trying to find the zero of the gradient.",
                    "label": 1
                },
                {
                    "sent": "This is written here in sort of the form where you have one variable, but you can do this with many variables, so it's called a second order method because we rely on the 2nd order derivative in order to do this opt.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station and if you have a weight vector, OK, the equivalent of having a second order derivative is to have a Hessian matrix.",
                    "label": 0
                },
                {
                    "sent": "Social matrix has the 2nd order partial derivatives of the objective function, and in some sense this gives you the optimal learning rates.",
                    "label": 0
                },
                {
                    "sent": "So this is great.",
                    "label": 0
                },
                {
                    "sent": "OK, you don't have to figure out anymore of learning rates.",
                    "label": 0
                },
                {
                    "sent": "OK, you do need to have this matrix, which may or may not be feasable.",
                    "label": 0
                },
                {
                    "sent": "OK, now why is that?",
                    "label": 0
                },
                {
                    "sent": "Well, the matrix is square in the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so if now I have actually a lot of parameters because I have a deep net and it's got a million weights, that's a very big matrix.",
                    "label": 0
                },
                {
                    "sent": "And not only do I have to have it and invert it.",
                    "label": 0
                },
                {
                    "sent": "But actually I have to estimate these entries right?",
                    "label": 0
                },
                {
                    "sent": "These are second order relatives and so these entries need to be supported by data.",
                    "label": 0
                },
                {
                    "sent": "So I need to have data in order to.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You to do this kind of estimation.",
                    "label": 0
                },
                {
                    "sent": "So what's the better method?",
                    "label": 0
                },
                {
                    "sent": "Well, that kind of depends.",
                    "label": 0
                },
                {
                    "sent": "OK, Newtons method typically requires far fewer iterations, right?",
                    "label": 0
                },
                {
                    "sent": "Because he was in some sense go at exactly the right speed.",
                    "label": 0
                },
                {
                    "sent": "But computing the Hessian might be a problem.",
                    "label": 0
                },
                {
                    "sent": "The inversion actually turns out you don't really need to do.",
                    "label": 0
                },
                {
                    "sent": "There's a nice trick that allows you to compute the product of a Hessian with a vector in linear time.",
                    "label": 0
                },
                {
                    "sent": "That very often people actually leverage.",
                    "label": 0
                },
                {
                    "sent": "It's a nice paper.",
                    "label": 0
                },
                {
                    "sent": "We don't really have time to talk about it, but.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I encourage you to look at that and so we can write this all up as Newton raphson for logistic regression, and we can sort of right now the update of this weight vector without even thinking about any kind of step sizes at all.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we do regularization for logistic regression?",
                    "label": 1
                },
                {
                    "sent": "Well, we can do regularization in similar way.",
                    "label": 1
                },
                {
                    "sent": "For example, we can impose a quadratic penalty on the weight vector right, which encourages the weights to be small.",
                    "label": 0
                },
                {
                    "sent": "This is the case over here.",
                    "label": 1
                },
                {
                    "sent": "We can still take derivatives.",
                    "label": 0
                },
                {
                    "sent": "Of course in this case, and we're going to end up with sort of very similar.",
                    "label": 0
                },
                {
                    "sent": "Kind of optimization.",
                    "label": 0
                },
                {
                    "sent": "Again, this imposes you know so conceptually, what does this do?",
                    "label": 0
                },
                {
                    "sent": "It says well, I have a Gaussian prior on the weights right, and then I also want to optimize the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "Notice that doing something beige and here is going to become very tricky.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "OK, why?",
                    "label": 0
                },
                {
                    "sent": "Because sort of Gaussian prior on the weights would go with the Gaussian posterior, but this likelihood term here is based on cross entropy and it's no longer.",
                    "label": 0
                },
                {
                    "sent": "Conjugate to the prior OK. And so doing basean stuff becomes.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slightly more involved in this case, where you no longer have sort of conjugacy.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to stop there just a few key points that I want you to remember.",
                    "label": 0
                },
                {
                    "sent": "You need to make choices of your hypothesis, space, error function and optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "OK, so we've discussed here linear and logistic regressions as choices of the function with discussed squared error versus cross entropy's choices of the optimization objective with discussed sort of solving things in closed form versus doing gradient descent as the optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "Most of the time we're going to try and find a good sort of computationally efficient way of doing the optimization, and a lot of the literature is about that.",
                    "label": 0
                },
                {
                    "sent": "And all of the algorithms are affected by this very bias variance tradeoff, and so you need to guard against that and Bashan.",
                    "label": 0
                },
                {
                    "sent": "Stuff might help you with that.",
                    "label": 0
                },
                {
                    "sent": "There's other ways to do that, just always always do cross validation, so I'll stop there.",
                    "label": 0
                },
                {
                    "sent": "And if there are any further questions.",
                    "label": 0
                }
            ]
        }
    }
}