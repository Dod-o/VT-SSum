{
    "id": "nmrntldjn7rvyfhdntm4q5abkagkxum4",
    "title": "On the Consistency of Output Code Based Learning Algorithms for Multiclass Learning Problems",
    "info": {
        "author": [
            "Harish G. Ramaswamy, Indian Institute of Science Bangalore"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory"
        ]
    },
    "url": "http://videolectures.net/colt2014_ramaswamy_problems/",
    "segmentation": [
        [
            "As many of you might know, output code based methods are very popular class of methods for solving multiclass learning problems and consistency is very useful and powerful notion for analyzing learning algorithms.",
            "But surprisingly, however, there's been very little results on analyzing the consistency of general output code based methods for general evaluation metrics.",
            "ABI partially fill this gap by giving conditions under which general output code based method is consistent.",
            "For a general multiclass problem."
        ],
        [
            "Our objective is to design A multiclass algorithm which takes a multiclass data set having one of N possible labels and returns a classifier which takes an instance as an input and gives one of K possible predictions as an output.",
            "So the set of classes in a set of predictions K or often same in a lot of example of problems, but that may not always be the case, I'll give an example later on so."
        ],
        [
            "11 very well studied class of algorithms are the binary learning algorithms which take a data set with positive and negative labels and give a real valued function over the instance spaces output.",
            "These are very well studied classical rhythms and.",
            "\u201c"
        ],
        [
            "Windows are exactly those multiclass methods which take these binary learners as a subroutine and try to solve and try to drive a multiclass algorithm.",
            "So now the code base method simply takes a multiclass data set and derives, say D separate binary datasets order.",
            "It's done then why I say be functions M1M2 CMP.",
            "If MJ of Y equals can take other values plus 1 -- 1 or 0 indicating that instances with class Y become either positive examples or negative examples or are ignored in the binary data set.",
            "So, given these D binary datasets now they can be solved by binary learners to get D separate functions or the real valued functions within space.",
            "And these functions are combined to get a single classifier using a decoder.",
            "So it can be seen that the output code based method has three components, the output coder, the binary learner and the decoder.",
            "So."
        ],
        [
            "This is a very popular class of methods, but the question we ask is one of the properties that these three components of the output code method must satisfy that will guarantee consistency of the overall method, so I'll briefly describe what the components the three components are and what consistency is so."
        ],
        [
            "The first component is the output coder, so the open code is defined by AD D + -- 1 value functions which can be compactly expressed as a coding matrix decoding matrix for two popular output code base methods.",
            "That is, the almost result in all password is given here, so the one who's all output coding method or it does is it reduces our in class problem into North binary subproblems.",
            "In subproblem J, Class J becomes a positive example.",
            "In every other classes become negative examples.",
            "So we have B = N. Here the alpicella precoding method reduces N class problem into N choose.",
            "Two binaries are problems.",
            "So in each subproblem indexed by a pair of glasses, say inj class, I becomes positive class, J becomes negative and every other classes ignored.",
            "So we have D = N. Choose two here."
        ],
        [
            "So the binary learner is there a whole variety of minors out there from mission tree methods to neural networks and so on, but we focus on a particular class of binary learners.",
            "Are the target minimizing methods, so this includes all popular methods like crazy and the logistic regression, the Least Quest classification, Adaboost, and so on.",
            "So the minor is defined by two positive functions.",
            "The binary circuit, 515 minus one.",
            "So given a binary data set, what the minor does, is it?",
            "Returns the minimizer of the empirical surrogate risk over an appropriate function class, so we assume standard universality conditions will be satisfied with the function class.",
            "So we just assume the binary learners defined completely by just a circuit 5 one 5 -- 1."
        ],
        [
            "So through the through, the talk will be interested in a particular class of virus targets, known as strictly proper composite losses.",
            "So they are essentially conditional probability estimation surrogates.",
            "So they satisfy this condition.",
            "That is, there exists a link function Lambda that is such that this condition holds.",
            "So this condition simply says that you should the conditional probability should be uniquely designed from the minimizer of the conditional expectation of the surrogate risk.",
            "So.",
            "Many, many popular targets, like the largest expansion and the least quest satisfy this property.",
            "OK."
        ],
        [
            "So we want to decode.",
            "The decoder is simply a function which takes D real values and outputs of K possible predictions.",
            "For example, the popular decoder used to the one with the salt water is simply the argmax another popular decoder used with the alpass coding method.",
            "Is the wind Max decoder, which simply decodes as the class which has the most wins in pairwise matches value.",
            "Interpret your ID element UI J as the probability that.",
            "Class I beats class T. OK, so.",
            "So that completes the description.",
            "The three companies are recording method so, but we have the algorithm.",
            "But what is the objective of the algorithm to be so one?"
        ],
        [
            "The most reliable applications come with an evaluation metric which penalizes single predictions for a given proof.",
            "For example, popular evaluation metric used in multiclass classification is the 01 loss which has the set of predictions to be the same as a set of classes, and you incur a loss of 1 if the prediction differs from the truth and incur a loss of 0 if it agrees with the truth.",
            "I."
        ],
        [
            "The more complicated evaluation metric considered the DCG, last used in label ranking with a fixed set of our labels.",
            "The classes here are score vectors on these are labels, so we have to power our classes.",
            "If you have.",
            "We assume binary score vectors.",
            "The predictions how, however, are permutations on these are labels and hence number R factorial.",
            "So this is an example of the case where the set of classes etc predictions are different."
        ],
        [
            "So in general, there could be some in classes and K predictions and evaluation metric is given by a loss matrix L, where LIJ indicates the loss incurred on predicting J when the true class is fine.",
            "It is simple to extend this valuation metric for single predictions to an evaluation metric.",
            "For full classifiers, simply take the expected loss incurred by the classifier."
        ],
        [
            "So the objective algorithm is now all is clear.",
            "So given a training sample drawn from a distribution D, the algorithm must find a classifier hatch that minimizes the expected loss incurred by the classifier.",
            "So as."
        ],
        [
            "Algorithm gets more and more training samples.",
            "We expect the classifier returned to get better and better, and the limit of infinite data.",
            "We would like the classifier returned by the algorithm to actually have the lowest possible expected loss, and that is exactly the notion of consistency.",
            "The objective of the whole paper is to get a handle on consistent output coding algorithms.",
            "The first Keith."
        ],
        [
            "We do we do for that is we realized that the output coding method is equivalent to a multiclass surrogate minimizing method.",
            "It's simply a function convex function, but typically on the second variable defined over the class of the set of classes and the continuous space ARD and the multiclass Senate minimizing method.",
            "Given that it simply returns the minimizer of the empirical surrogate risk.",
            "So these class of methods have been there have been very many tools developed for analyzing consistency of these classes methods, and we use these tools for getting the output code so we."
        ],
        [
            "Make an observation that output coding method given by the code matrix M and binary circuits 505 -- 1 simply corresponds to a surrogate given by this equation.",
            "So that's our first step in making the connection to consistency."
        ],
        [
            "So now we want our results now.",
            "So considering the one must output coding method, we show that the Windows output coding method with a strictly proper opposite binary surrogate is actually consistent with respect to the 01 loss you had.",
            "The decoder used is simply the standard argmax decoder composed with the inverse link function of the binary cycle.",
            "We also really have a previous results which show that if you use the Internet was a hinge loss, then the resulting algorithm is not consistent with respect to the 01 loss for any decoder.",
            "OK, so."
        ],
        [
            "I'm not going to the all pairs of recording method.",
            "We show a similar result for all passes.",
            "We show that if your binary set is strictly proper composite then the all partial coding method is also consistent with respect to the 01 loss.",
            "For better, the decoder again is the Standard Oil Patch decoder composed with the inverse link function.",
            "Over here, even with the hinge loss, is the binary circuit.",
            "We can show that the old password coding algorithm is actually consistent, so this is very different.",
            "So how do these are standard coding methods and the standard 01 loss?",
            "How do we generalize beyond to other other output coding methods and other evaluation metrics the key?"
        ],
        [
            "Step in doing so is what we call the column space condition which characterizes what are the good code matrices.",
            "So we say that a code matrix M satisfies the column space condition with respect to the last matrix L. If simply the span of the code matrix concatenated with the all ones column vector is actually a super set of the span of the last matrix.",
            "So if you have, we say that if.",
            "If a code matrix satisfies this condition, we say we call it a good code.",
            "Metrics say so can see that simply that if the rank of the last matrix is D, you need at least D -- 1 columns in the code matrix to achieve this condition.",
            "However, this might be significantly higher because we are restricting the code matrix M to take only entries plus 1 -- 1.",
            "Note that the one is all code matrix actually satisfies this condition for any loss metrics because it's pretty much a translation of the identity matrix.",
            "However, if in the case that the last matrix actually spans a lesser dimensional subspace, you could do significantly better.",
            "That is, you might be able to satisfy satisfy this condition with much lesser number of columns.",
            "That translates to a much lesser number of binary subproblems.",
            "OK, so we."
        ],
        [
            "Are you simply show that if your code matrix M satisfies the column space condition with respect to the last matrix L and you're buying that is strictly proper composite, then the resulting output coding algorithm is actually consistent with respect to the last matrix L. We don't show the decoder here, but the decoder now depends on the code matrix.",
            "The last Matrix, as well as the link function associated with the binary cycle.",
            "OK, so this is a general result that applies for general loss matrices, but one major returned with this result is the code metrics restriction to take only values plus one and minus one.",
            "If we could somehow generalize that other code matrices, we can always guarantee that rank Delos matrix requires only B columns, so we should.",
            "I think that so can we do that?",
            "Yes we can, but that would require us to generalize the output coding method itself to what we call US probabilistic corporate coding method."
        ],
        [
            "So how is the probability of recording with a different?",
            "It uses a more powerful learner than the standard simple binary learner.",
            "It uses what we call a binary class probability weighted learner, which takes input.",
            "Instances along with 01 value not just plus 1 -- 1 but real valued labels and returns a real valued function over the instant space."
        ],
        [
            "The problem.",
            "Yeah, so the given the binary static binary class probability weighted learner is also defined by a surrogate and given a sample given appropriate training set, it returns the minimizer of this function, which can be viewed as binary class probability weighted empirical target risk."
        ],
        [
            "So OK, so the probabilistic input coding method is simply the standard open coding method with just 01 valued output coder and binary class probability weighted learners instead of standard simple binary learners."
        ],
        [
            "Be sure very similar is that if your code matrix Now, which is which now takes values in 01.",
            "The increased exclusion zone instead of just plus or minus one if the code matrix M Now satisfies the column space condition with respect to the last matrix L and your binary circuit is strictly proper composite, then the resulting output coding algorithm is consistent with respect to the last matrix.",
            "This produces exactly the same result just now your code matrix is more powerful and this this you can ensure that for a rank be loss matrix can satisfy the column space condition with just the columns.",
            "For."
        ],
        [
            "I've been saving up later as well to the DCG loss for our labels as we saw earlier, can clearly see that the DCG loss for label ranking with our labels has rank at most are plus one.",
            "We can show that using a probabilistic corporate coding method it requires just are binary tasks to be solved.",
            "In other words you can satisfy the column space condition with just our columns.",
            "However if you use the ones or output coding method which is also consistent, you could require a 2 hour column matrix.",
            "Just you'll have to start over.",
            "The tasks, so we just make a huge savings.",
            "And."
        ],
        [
            "And that just about that concludes my talk.",
            "I'll just give a summary in case you missed anything.",
            "We give general conditions for coding methods with the windows on all paths to be consistent with respect to 01 loss.",
            "We gave a column space condition on the code matrix for consistency with respect to General Medical classes.",
            "And we introduced what we call is the probabilistic corporate coding method, which can require fewer binary problems to achieve consistency with respect to general multiclass.",
            "But yeah, that's."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As many of you might know, output code based methods are very popular class of methods for solving multiclass learning problems and consistency is very useful and powerful notion for analyzing learning algorithms.",
                    "label": 1
                },
                {
                    "sent": "But surprisingly, however, there's been very little results on analyzing the consistency of general output code based methods for general evaluation metrics.",
                    "label": 0
                },
                {
                    "sent": "ABI partially fill this gap by giving conditions under which general output code based method is consistent.",
                    "label": 1
                },
                {
                    "sent": "For a general multiclass problem.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our objective is to design A multiclass algorithm which takes a multiclass data set having one of N possible labels and returns a classifier which takes an instance as an input and gives one of K possible predictions as an output.",
                    "label": 0
                },
                {
                    "sent": "So the set of classes in a set of predictions K or often same in a lot of example of problems, but that may not always be the case, I'll give an example later on so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "11 very well studied class of algorithms are the binary learning algorithms which take a data set with positive and negative labels and give a real valued function over the instance spaces output.",
                    "label": 0
                },
                {
                    "sent": "These are very well studied classical rhythms and.",
                    "label": 0
                },
                {
                    "sent": "\u201c",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Windows are exactly those multiclass methods which take these binary learners as a subroutine and try to solve and try to drive a multiclass algorithm.",
                    "label": 0
                },
                {
                    "sent": "So now the code base method simply takes a multiclass data set and derives, say D separate binary datasets order.",
                    "label": 0
                },
                {
                    "sent": "It's done then why I say be functions M1M2 CMP.",
                    "label": 0
                },
                {
                    "sent": "If MJ of Y equals can take other values plus 1 -- 1 or 0 indicating that instances with class Y become either positive examples or negative examples or are ignored in the binary data set.",
                    "label": 0
                },
                {
                    "sent": "So, given these D binary datasets now they can be solved by binary learners to get D separate functions or the real valued functions within space.",
                    "label": 0
                },
                {
                    "sent": "And these functions are combined to get a single classifier using a decoder.",
                    "label": 0
                },
                {
                    "sent": "So it can be seen that the output code based method has three components, the output coder, the binary learner and the decoder.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a very popular class of methods, but the question we ask is one of the properties that these three components of the output code method must satisfy that will guarantee consistency of the overall method, so I'll briefly describe what the components the three components are and what consistency is so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first component is the output coder, so the open code is defined by AD D + -- 1 value functions which can be compactly expressed as a coding matrix decoding matrix for two popular output code base methods.",
                    "label": 0
                },
                {
                    "sent": "That is, the almost result in all password is given here, so the one who's all output coding method or it does is it reduces our in class problem into North binary subproblems.",
                    "label": 0
                },
                {
                    "sent": "In subproblem J, Class J becomes a positive example.",
                    "label": 0
                },
                {
                    "sent": "In every other classes become negative examples.",
                    "label": 0
                },
                {
                    "sent": "So we have B = N. Here the alpicella precoding method reduces N class problem into N choose.",
                    "label": 0
                },
                {
                    "sent": "Two binaries are problems.",
                    "label": 0
                },
                {
                    "sent": "So in each subproblem indexed by a pair of glasses, say inj class, I becomes positive class, J becomes negative and every other classes ignored.",
                    "label": 0
                },
                {
                    "sent": "So we have D = N. Choose two here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the binary learner is there a whole variety of minors out there from mission tree methods to neural networks and so on, but we focus on a particular class of binary learners.",
                    "label": 0
                },
                {
                    "sent": "Are the target minimizing methods, so this includes all popular methods like crazy and the logistic regression, the Least Quest classification, Adaboost, and so on.",
                    "label": 0
                },
                {
                    "sent": "So the minor is defined by two positive functions.",
                    "label": 0
                },
                {
                    "sent": "The binary circuit, 515 minus one.",
                    "label": 1
                },
                {
                    "sent": "So given a binary data set, what the minor does, is it?",
                    "label": 0
                },
                {
                    "sent": "Returns the minimizer of the empirical surrogate risk over an appropriate function class, so we assume standard universality conditions will be satisfied with the function class.",
                    "label": 0
                },
                {
                    "sent": "So we just assume the binary learners defined completely by just a circuit 5 one 5 -- 1.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So through the through, the talk will be interested in a particular class of virus targets, known as strictly proper composite losses.",
                    "label": 1
                },
                {
                    "sent": "So they are essentially conditional probability estimation surrogates.",
                    "label": 0
                },
                {
                    "sent": "So they satisfy this condition.",
                    "label": 0
                },
                {
                    "sent": "That is, there exists a link function Lambda that is such that this condition holds.",
                    "label": 1
                },
                {
                    "sent": "So this condition simply says that you should the conditional probability should be uniquely designed from the minimizer of the conditional expectation of the surrogate risk.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Many, many popular targets, like the largest expansion and the least quest satisfy this property.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want to decode.",
                    "label": 0
                },
                {
                    "sent": "The decoder is simply a function which takes D real values and outputs of K possible predictions.",
                    "label": 0
                },
                {
                    "sent": "For example, the popular decoder used to the one with the salt water is simply the argmax another popular decoder used with the alpass coding method.",
                    "label": 0
                },
                {
                    "sent": "Is the wind Max decoder, which simply decodes as the class which has the most wins in pairwise matches value.",
                    "label": 0
                },
                {
                    "sent": "Interpret your ID element UI J as the probability that.",
                    "label": 0
                },
                {
                    "sent": "Class I beats class T. OK, so.",
                    "label": 0
                },
                {
                    "sent": "So that completes the description.",
                    "label": 0
                },
                {
                    "sent": "The three companies are recording method so, but we have the algorithm.",
                    "label": 0
                },
                {
                    "sent": "But what is the objective of the algorithm to be so one?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The most reliable applications come with an evaluation metric which penalizes single predictions for a given proof.",
                    "label": 0
                },
                {
                    "sent": "For example, popular evaluation metric used in multiclass classification is the 01 loss which has the set of predictions to be the same as a set of classes, and you incur a loss of 1 if the prediction differs from the truth and incur a loss of 0 if it agrees with the truth.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The more complicated evaluation metric considered the DCG, last used in label ranking with a fixed set of our labels.",
                    "label": 0
                },
                {
                    "sent": "The classes here are score vectors on these are labels, so we have to power our classes.",
                    "label": 0
                },
                {
                    "sent": "If you have.",
                    "label": 0
                },
                {
                    "sent": "We assume binary score vectors.",
                    "label": 0
                },
                {
                    "sent": "The predictions how, however, are permutations on these are labels and hence number R factorial.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of the case where the set of classes etc predictions are different.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in general, there could be some in classes and K predictions and evaluation metric is given by a loss matrix L, where LIJ indicates the loss incurred on predicting J when the true class is fine.",
                    "label": 0
                },
                {
                    "sent": "It is simple to extend this valuation metric for single predictions to an evaluation metric.",
                    "label": 0
                },
                {
                    "sent": "For full classifiers, simply take the expected loss incurred by the classifier.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the objective algorithm is now all is clear.",
                    "label": 0
                },
                {
                    "sent": "So given a training sample drawn from a distribution D, the algorithm must find a classifier hatch that minimizes the expected loss incurred by the classifier.",
                    "label": 0
                },
                {
                    "sent": "So as.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithm gets more and more training samples.",
                    "label": 0
                },
                {
                    "sent": "We expect the classifier returned to get better and better, and the limit of infinite data.",
                    "label": 0
                },
                {
                    "sent": "We would like the classifier returned by the algorithm to actually have the lowest possible expected loss, and that is exactly the notion of consistency.",
                    "label": 0
                },
                {
                    "sent": "The objective of the whole paper is to get a handle on consistent output coding algorithms.",
                    "label": 0
                },
                {
                    "sent": "The first Keith.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do we do for that is we realized that the output coding method is equivalent to a multiclass surrogate minimizing method.",
                    "label": 1
                },
                {
                    "sent": "It's simply a function convex function, but typically on the second variable defined over the class of the set of classes and the continuous space ARD and the multiclass Senate minimizing method.",
                    "label": 0
                },
                {
                    "sent": "Given that it simply returns the minimizer of the empirical surrogate risk.",
                    "label": 0
                },
                {
                    "sent": "So these class of methods have been there have been very many tools developed for analyzing consistency of these classes methods, and we use these tools for getting the output code so we.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Make an observation that output coding method given by the code matrix M and binary circuits 505 -- 1 simply corresponds to a surrogate given by this equation.",
                    "label": 0
                },
                {
                    "sent": "So that's our first step in making the connection to consistency.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we want our results now.",
                    "label": 0
                },
                {
                    "sent": "So considering the one must output coding method, we show that the Windows output coding method with a strictly proper opposite binary surrogate is actually consistent with respect to the 01 loss you had.",
                    "label": 1
                },
                {
                    "sent": "The decoder used is simply the standard argmax decoder composed with the inverse link function of the binary cycle.",
                    "label": 0
                },
                {
                    "sent": "We also really have a previous results which show that if you use the Internet was a hinge loss, then the resulting algorithm is not consistent with respect to the 01 loss for any decoder.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm not going to the all pairs of recording method.",
                    "label": 1
                },
                {
                    "sent": "We show a similar result for all passes.",
                    "label": 0
                },
                {
                    "sent": "We show that if your binary set is strictly proper composite then the all partial coding method is also consistent with respect to the 01 loss.",
                    "label": 1
                },
                {
                    "sent": "For better, the decoder again is the Standard Oil Patch decoder composed with the inverse link function.",
                    "label": 0
                },
                {
                    "sent": "Over here, even with the hinge loss, is the binary circuit.",
                    "label": 1
                },
                {
                    "sent": "We can show that the old password coding algorithm is actually consistent, so this is very different.",
                    "label": 0
                },
                {
                    "sent": "So how do these are standard coding methods and the standard 01 loss?",
                    "label": 0
                },
                {
                    "sent": "How do we generalize beyond to other other output coding methods and other evaluation metrics the key?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Step in doing so is what we call the column space condition which characterizes what are the good code matrices.",
                    "label": 0
                },
                {
                    "sent": "So we say that a code matrix M satisfies the column space condition with respect to the last matrix L. If simply the span of the code matrix concatenated with the all ones column vector is actually a super set of the span of the last matrix.",
                    "label": 1
                },
                {
                    "sent": "So if you have, we say that if.",
                    "label": 0
                },
                {
                    "sent": "If a code matrix satisfies this condition, we say we call it a good code.",
                    "label": 0
                },
                {
                    "sent": "Metrics say so can see that simply that if the rank of the last matrix is D, you need at least D -- 1 columns in the code matrix to achieve this condition.",
                    "label": 0
                },
                {
                    "sent": "However, this might be significantly higher because we are restricting the code matrix M to take only entries plus 1 -- 1.",
                    "label": 0
                },
                {
                    "sent": "Note that the one is all code matrix actually satisfies this condition for any loss metrics because it's pretty much a translation of the identity matrix.",
                    "label": 0
                },
                {
                    "sent": "However, if in the case that the last matrix actually spans a lesser dimensional subspace, you could do significantly better.",
                    "label": 0
                },
                {
                    "sent": "That is, you might be able to satisfy satisfy this condition with much lesser number of columns.",
                    "label": 0
                },
                {
                    "sent": "That translates to a much lesser number of binary subproblems.",
                    "label": 0
                },
                {
                    "sent": "OK, so we.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are you simply show that if your code matrix M satisfies the column space condition with respect to the last matrix L and you're buying that is strictly proper composite, then the resulting output coding algorithm is actually consistent with respect to the last matrix L. We don't show the decoder here, but the decoder now depends on the code matrix.",
                    "label": 1
                },
                {
                    "sent": "The last Matrix, as well as the link function associated with the binary cycle.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a general result that applies for general loss matrices, but one major returned with this result is the code metrics restriction to take only values plus one and minus one.",
                    "label": 0
                },
                {
                    "sent": "If we could somehow generalize that other code matrices, we can always guarantee that rank Delos matrix requires only B columns, so we should.",
                    "label": 0
                },
                {
                    "sent": "I think that so can we do that?",
                    "label": 0
                },
                {
                    "sent": "Yes we can, but that would require us to generalize the output coding method itself to what we call US probabilistic corporate coding method.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how is the probability of recording with a different?",
                    "label": 0
                },
                {
                    "sent": "It uses a more powerful learner than the standard simple binary learner.",
                    "label": 0
                },
                {
                    "sent": "It uses what we call a binary class probability weighted learner, which takes input.",
                    "label": 1
                },
                {
                    "sent": "Instances along with 01 value not just plus 1 -- 1 but real valued labels and returns a real valued function over the instant space.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the given the binary static binary class probability weighted learner is also defined by a surrogate and given a sample given appropriate training set, it returns the minimizer of this function, which can be viewed as binary class probability weighted empirical target risk.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so the probabilistic input coding method is simply the standard open coding method with just 01 valued output coder and binary class probability weighted learners instead of standard simple binary learners.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be sure very similar is that if your code matrix Now, which is which now takes values in 01.",
                    "label": 0
                },
                {
                    "sent": "The increased exclusion zone instead of just plus or minus one if the code matrix M Now satisfies the column space condition with respect to the last matrix L and your binary circuit is strictly proper composite, then the resulting output coding algorithm is consistent with respect to the last matrix.",
                    "label": 1
                },
                {
                    "sent": "This produces exactly the same result just now your code matrix is more powerful and this this you can ensure that for a rank be loss matrix can satisfy the column space condition with just the columns.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've been saving up later as well to the DCG loss for our labels as we saw earlier, can clearly see that the DCG loss for label ranking with our labels has rank at most are plus one.",
                    "label": 0
                },
                {
                    "sent": "We can show that using a probabilistic corporate coding method it requires just are binary tasks to be solved.",
                    "label": 1
                },
                {
                    "sent": "In other words you can satisfy the column space condition with just our columns.",
                    "label": 1
                },
                {
                    "sent": "However if you use the ones or output coding method which is also consistent, you could require a 2 hour column matrix.",
                    "label": 0
                },
                {
                    "sent": "Just you'll have to start over.",
                    "label": 0
                },
                {
                    "sent": "The tasks, so we just make a huge savings.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that just about that concludes my talk.",
                    "label": 0
                },
                {
                    "sent": "I'll just give a summary in case you missed anything.",
                    "label": 0
                },
                {
                    "sent": "We give general conditions for coding methods with the windows on all paths to be consistent with respect to 01 loss.",
                    "label": 1
                },
                {
                    "sent": "We gave a column space condition on the code matrix for consistency with respect to General Medical classes.",
                    "label": 1
                },
                {
                    "sent": "And we introduced what we call is the probabilistic corporate coding method, which can require fewer binary problems to achieve consistency with respect to general multiclass.",
                    "label": 0
                },
                {
                    "sent": "But yeah, that's.",
                    "label": 0
                }
            ]
        }
    }
}