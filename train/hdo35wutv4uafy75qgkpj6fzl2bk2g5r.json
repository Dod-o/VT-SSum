{
    "id": "hdo35wutv4uafy75qgkpj6fzl2bk2g5r",
    "title": "Semi-supervised Feature Selection for Graph Classification",
    "info": {
        "author": [
            "Xiangnan Kong, Department of Computer Science, Worcester Polytechnic Institute"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2010_kong_ssfs/",
    "segmentation": [
        [
            "So we have four papers in this section.",
            "The 1st paper is on semi supervised feature selection for graph for graph classification and will be presented by Zhang LAN comb.",
            "Yeah please.",
            "OK, good morning, thank you all for coming today.",
            "I'm going to talk about Semi supervised feature selection for graph classification and this is a joint work with my supervisor Philip U and we are from University of Illinois, Sasha."
        ],
        [
            "Cargo so let's first talk about what is graph classification problem and why should we care about this problem.",
            "So as we all know that in conventional data mining and machine learning approaches it is assumed that the data are represented as feature vectors.",
            "However, in many real world applications the data are usually not directly represented as feature vector, but as graphs with some complex structures.",
            "For example the chemical compounds.",
            "Can be represented as graphs and program flows, XML documents and what we would like to do is we want to perform classification on this graph objects and in other words, in conventional classification problem the instance each instance is a feature vector by in graph classification problem.",
            "Each instance is a graph.",
            "So let's."
        ],
        [
            "First, take a look.",
            "Look at real world example.",
            "So this is a drug activity prediction problem.",
            "So we are first given a set of graph objects or chemical compounds and we want to test whether this chemical compound can be used to cure a certain type of disease and if if this compound can be used as a drug to cure some disease, we can say this is a positive graph.",
            "Otherwise we will say this is a negative graph.",
            "And what we want to do is we want to predict whether a new unlabeled graph can cure a certain kind of kind of disease and whether it's a positive graph or a negative graph.",
            "So this problem is very important for the people who want to discover new drugs for a certain type of disease.",
            "And also it is very important for people who want to predict whether a program flow has certain type of error or they want to.",
            "Classified XML documents into some categories.",
            "So in all these applications the problem is a graph classification problem and we want to classify the graph."
        ],
        [
            "So there are many graph classification methods have been proposed an in this paper we focused on this sub graph based graph classification.",
            "So the general idea of this type of approach is like this.",
            "We are first given a set of graph object and since we cannot directly perform classification on this graph object.",
            "So the first step we need to do is we want to convert each of the graph object into a feature vector an.",
            "Using a set of subgraph patterns.",
            "So suppose we are given a set of subpatterns, G1G2, and G3.",
            "We can now use them to convert the graph objects into feature vectors like this.",
            "If the graph object has this subpattern, we can put in one into its feature vector.",
            "Otherwise, we can put in zero, so using this way we can use a set of software pattern to convert all the graph objects into feature vectors, so the rest task will be very simple.",
            "We just can use any classification model on these feature vectors to perform graph classification.",
            "So now we see that the central problem for the graph classification is.",
            "How can we find this set of sub graph feature in order to perform the graph classification as effective as possible or as efficient as possible.",
            "So there are many methods have been proposed to this."
        ],
        [
            "Problem an all this method.",
            "Has two components to solve different problems.",
            "Different challenges in this problem.",
            "So the first part is evaluation part.",
            "They they want to tell which whether the subpattern is useful to the classification task or not, and we know that there are many subgraph patterns in a graph data set, and most of them are not directly useful for the classification tasks, so we just want to select the useful ones from them and the 2nd.",
            "And intuitively, the first part can make the model more effective to the classification task, and the second part is the search space pruning.",
            "Because in real graph data set usually there are a lot of subpatterns.",
            "The number of the subgraph pattern can be exponential to the size of the graph, so usually it is impossible to enumerate all the subgraph pattern in order to find the best one.",
            "So what they do is they find a way to prove this search space without searching all the subgraph patterns and also find the best subgraph features so.",
            "So the second part can make the method more more efficient."
        ],
        [
            "And all this conventional methods are focused on the supervised settings, which means that they require a lot.",
            "A lot of labeled graph in order to work well.",
            "However, in real world problems usually labeling a graph is very hard.",
            "Take take example for the chemical compounds, if we want to label a chemical, usually we need to take animal test, clinical trial, use a lot of money, a lot of time and.",
            "Effort of the experts.",
            "So in real case it is impossible to get a large set of labeled graph in order to perform graph classification."
        ],
        [
            "So because the two components of the conventional method will all fail because the lack of label information."
        ],
        [
            "So what can we do?",
            "In this paper we proposed to use a semi proposal framework for semi supervised feature selection for graph classification.",
            "The general idea is.",
            "Though in real world problems we cannot get too many labeled graphs, but usually we can get a lot of unlabeled graph very easily.",
            "So why not?",
            "We use both labeled graph and unlabeled graph together to find the most useful subgraph patterns.",
            "So the problem we want to solve is how can we use the labeled graph, an unlabeled graph to find the useful patterns for the graph classification."
        ],
        [
            "So in order to solve this problem, we need to attack two questions which is similar to the conventional conventional method.",
            "The first one is the evaluation part.",
            "How can we say a sub graph is useful to the classification task when we have both labeled and unlabeled graph and 2nd part is how can we prune the search space using both labeled and unlabeled graph?",
            "So let's first focus on the first question.",
            "So the question is, what is a good feature?",
            "We have both labeled and and."
        ],
        [
            "Prograf so we we proposed.",
            "This three quite hearing all three properties, which we say a good feature should have all these three properties.",
            "The first one is cannot link, which means that using that subgraph feature the graphs in different classes should be separated far away from each other and the second one is must.",
            "Link means if the graph in the same class should be close together using that subgraph feature, and the third one is separability, which means that the unlabeled graph should be able to be separated from each other using that.",
            "Subgraph feature, so let's explain this using an example.",
            "Suppose we have some labeled graphs and a lot of large number of unlabeled graphs.",
            "So now we have a several pattern one, and this pattern is can be represented as a partition in the graph database because one.",
            "One part of the graph will have this pattern, while the other part do not have that one.",
            "So let's look at the first 2 properties.",
            "We want to find in the subpattern.",
            "Actually, according to according to this property, this subpattern is not a good pattern, because we can see that this pattern actually separates the graphs in the same class far away from each other.",
            "Well, make the graph in different classes close to each other, so this is not what we want.",
            "So this is not a good pattern.",
            "Let's look at the second sub pattern.",
            "So if we only look at the labeled graphs, actually this is a very good pattern because it can make the graph in the same class close together while the different class far away.",
            "So actually this is what we want.",
            "However, if we also look at the third property, which means if we consider the unlabeled graphs will find there will be a problem with this several feature is that if.",
            "If we use this feature on this graph, data set, actually, no matter what classifier you use, all the unlabeled graph will be classified into the same class, and usually this is not what we want.",
            "So when we so when we consider all the three properties, usually the third graph feature is what we want to find.",
            "They can both satisfy the three, the three properties.",
            "So when we compare the these two separate patterns, we will find how the unlabeled graph can help us to select better Sagra patterns.",
            "So."
        ],
        [
            "Oh we formulate the sub graph feature selection problem as the optimization problem and we want to select a subset from other subgraph features and using trying to maximize the evaluation function, the evaluation function is is composed by three terms and each of these terms corresponds to one property.",
            "We want to find in the subgraph features, so we also put two parameters to control the.",
            "Weights on different type of properties to to emphasize on."
        ],
        [
            "In parts so.",
            "When we convert this evaluation function into matrix form, finally we find that the evaluation value can be calculated by a sum over all the selected feature using this formula.",
            "Now we define this formula as evaluation criteria for a subgraph feature.",
            "Here the FK means represent the case several feature, while the L matrix has the information from both labeled an unlabeled graphs.",
            "And we just need to calculate all the GCM score on each of the circular pattern and select the best one.",
            "So now we have to find a way to evaluate the subgraph patterns using both label and label graph so."
        ],
        [
            "How good our our evaluation method works.",
            "We perform experiments on five real world data set about chemical compounds, activities and we use different number of labeled graphs in each settings.",
            "Let's focus on one of the fish."
        ],
        [
            "Years so.",
            "In this figure way compared to baseline, one is supervised using information going to select several features.",
            "The second one is unsupervised, which just select the most frequent subgraph patterns, and we see that when we select different number of feature set, actually our method can outperform outperform all the other two baselines and this can be explained that our method can use both labeled and unlabeled graph.",
            "Well, the supervised method only.",
            "Make use of the small set of labeled information an the frequent and supervise method.",
            "Do not use the label information so they cannot work better than the baseline.",
            "Then our method."
        ],
        [
            "So.",
            "Here we go to the second part.",
            "We need to solve is how can we prove the search space using both labeled and unlabeled graphs?"
        ],
        [
            "So actually the question is of is like because we have a large number of subgraph patterns in a graph data set.",
            "However, we only want to find the most useful ones among them, so it's like finding a needle in a haystack.",
            "So in order to do this, we need to use frequent subgraph subgraph mining method called G span an.",
            "It is very efficient algorithm to enumerate other frequent subgraph patterns in a graph data set.",
            "So the basic idea is they can put all the frequent subgraph pattern, organize all the frequent several patterns in the pattern search tree, which they call DFS code tree, and each of these nodes in the tree represent a subgraph pattern and.",
            "As we perform depth, first search in the in the pattern search tree.",
            "Initially we will have a very small subgraph pattern and we keep adding new edges to that pattern and get larger larger subgraphs until the pattern becomes infrequent.",
            "So we know that among all the nodes in this tree, we have some useful patterns according to the GSM score, and we want to find these patterns among other nodes and the bad news is usually this tree is very large.",
            "We cannot afford to search all the nodes in this tree in order to get the best ones from them.",
            "So how can we do that?",
            "The basic idea is we want to use the branch and bound to prune the search space an."
        ],
        [
            "Take take an example like this.",
            "Suppose we have a current best subgraph feature an.",
            "This is just me score an now we have the current node.",
            "When we search the pattern search tree and it's and it's score is like this.",
            "If the current nodes Geesaman score is better than the best one we seen before, we can just replace the best one with our current node.",
            "However, if the current node is not better than the best sub graph, we also need to decide whether we need to search.",
            "To the children node and subtree of from the current node.",
            "So we calculate an upper bound.",
            "The meaning of this upper bound is that if we if we consider all the sub graph in the subtree and actually they will not get any better value than this upper bound.",
            "So this upper bound means that this is the best they can get so.",
            "If the current best value is better than this upper bound, we can simply cut this subtree without searching any node, and it's guaranteed that we will not miss any better subgraph features."
        ],
        [
            "So how good our sub?",
            "How could our pruning method works?",
            "So this is a running time when we compare after pruning and without planning.",
            "So consider the running time is in exponential scale so our pruning method can.",
            "Significantly decrease the running time."
        ],
        [
            "Anne.",
            "Also, we study the number of subgraphs explored during this feature mining process.",
            "We find that our upper bound can prove a lot of large number of subgraph patterns, so this process can make the our model very efficient."
        ],
        [
            "So to conclude.",
            "This is the first first method to study the problem of semi supervised feature selection for graph classification and in order to do that we first propose evaluation method to to evaluate the subgraph features using both label and label graphs and then we propose a branch branch and bound pruning method to make make this process even faster.",
            "So thank you for your attention.",
            "Time for a few questions.",
            "First question is your result is slightly better than 50%.",
            "I'm wondering the usability of the research and the other question.",
            "Did you compare with some kernel approach for graph classification?",
            "OK, so the first question is.",
            "The evaluation result is just, the accuracy is just a little bit better than 50% right?",
            "OK, so maybe because this is a very hard classification problem so and also we only have a little number of the label graph, so maybe this is the best they can do, and we and we only show that using both labeled an unlabeled graph can get the performance improved then the.",
            "The supervised methods so so did I compared with the kernel based graph classification method.",
            "Well, in this paper we only focus on the sub graph based methods, so we did not compare with the kernel based method.",
            "So yeah, maybe it's an interesting topic we we can try to study that them later, yeah?",
            "I actually my question is related to his question and the and the first one I did notice that your accuracy is slightly over 50% for the binary classes classification, and I understand that that particular data set is very hard one.",
            "So have you test your method on some some other classification graph classification data set where the typical accuracy would be like 7080% to see how much improvement you can get or.",
            "That when you show it was the only set data set you you have tested, we performed experiment on five real world data set first three NCI data set the the second last two PC data set and that is what graph classification papers always use.",
            "So we just use this file.",
            "Yeah, that's the accuracy.",
            "Always stay at a little about 50% or is accuracy better for some other data set?",
            "That's my question.",
            "The the accuracy you have five data set right?",
            "You show us one of the five OK and how about the other four?",
            "I just wonder about the accuracy."
        ],
        [
            "So, so this is all the experiment an actually.",
            "Yeah, most of them are just a little bit higher than 50%, but the good news is in all these cases our method can improve the performance.",
            "Then there's only the supervised method in terms of the supervised method.",
            "There are more than one of those, and which one did you compare?",
            "We compare using the information gain to select the feature.",
            "And it is just used also used in other papers to compare with their paper.",
            "So it is like a benchmark method, yeah?",
            "Well the I I'm I'm aware of there's other more recent ones, and then I would suggest you look at them and.",
            "Well, you have to be out by capitalizing more and more discussion.",
            "Yeah, thank you.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have four papers in this section.",
                    "label": 0
                },
                {
                    "sent": "The 1st paper is on semi supervised feature selection for graph for graph classification and will be presented by Zhang LAN comb.",
                    "label": 0
                },
                {
                    "sent": "Yeah please.",
                    "label": 0
                },
                {
                    "sent": "OK, good morning, thank you all for coming today.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about Semi supervised feature selection for graph classification and this is a joint work with my supervisor Philip U and we are from University of Illinois, Sasha.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cargo so let's first talk about what is graph classification problem and why should we care about this problem.",
                    "label": 0
                },
                {
                    "sent": "So as we all know that in conventional data mining and machine learning approaches it is assumed that the data are represented as feature vectors.",
                    "label": 1
                },
                {
                    "sent": "However, in many real world applications the data are usually not directly represented as feature vector, but as graphs with some complex structures.",
                    "label": 0
                },
                {
                    "sent": "For example the chemical compounds.",
                    "label": 0
                },
                {
                    "sent": "Can be represented as graphs and program flows, XML documents and what we would like to do is we want to perform classification on this graph objects and in other words, in conventional classification problem the instance each instance is a feature vector by in graph classification problem.",
                    "label": 0
                },
                {
                    "sent": "Each instance is a graph.",
                    "label": 0
                },
                {
                    "sent": "So let's.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, take a look.",
                    "label": 0
                },
                {
                    "sent": "Look at real world example.",
                    "label": 0
                },
                {
                    "sent": "So this is a drug activity prediction problem.",
                    "label": 1
                },
                {
                    "sent": "So we are first given a set of graph objects or chemical compounds and we want to test whether this chemical compound can be used to cure a certain type of disease and if if this compound can be used as a drug to cure some disease, we can say this is a positive graph.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we will say this is a negative graph.",
                    "label": 0
                },
                {
                    "sent": "And what we want to do is we want to predict whether a new unlabeled graph can cure a certain kind of kind of disease and whether it's a positive graph or a negative graph.",
                    "label": 0
                },
                {
                    "sent": "So this problem is very important for the people who want to discover new drugs for a certain type of disease.",
                    "label": 0
                },
                {
                    "sent": "And also it is very important for people who want to predict whether a program flow has certain type of error or they want to.",
                    "label": 0
                },
                {
                    "sent": "Classified XML documents into some categories.",
                    "label": 0
                },
                {
                    "sent": "So in all these applications the problem is a graph classification problem and we want to classify the graph.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are many graph classification methods have been proposed an in this paper we focused on this sub graph based graph classification.",
                    "label": 0
                },
                {
                    "sent": "So the general idea of this type of approach is like this.",
                    "label": 0
                },
                {
                    "sent": "We are first given a set of graph object and since we cannot directly perform classification on this graph object.",
                    "label": 0
                },
                {
                    "sent": "So the first step we need to do is we want to convert each of the graph object into a feature vector an.",
                    "label": 0
                },
                {
                    "sent": "Using a set of subgraph patterns.",
                    "label": 1
                },
                {
                    "sent": "So suppose we are given a set of subpatterns, G1G2, and G3.",
                    "label": 1
                },
                {
                    "sent": "We can now use them to convert the graph objects into feature vectors like this.",
                    "label": 0
                },
                {
                    "sent": "If the graph object has this subpattern, we can put in one into its feature vector.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, we can put in zero, so using this way we can use a set of software pattern to convert all the graph objects into feature vectors, so the rest task will be very simple.",
                    "label": 1
                },
                {
                    "sent": "We just can use any classification model on these feature vectors to perform graph classification.",
                    "label": 0
                },
                {
                    "sent": "So now we see that the central problem for the graph classification is.",
                    "label": 0
                },
                {
                    "sent": "How can we find this set of sub graph feature in order to perform the graph classification as effective as possible or as efficient as possible.",
                    "label": 0
                },
                {
                    "sent": "So there are many methods have been proposed to this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem an all this method.",
                    "label": 0
                },
                {
                    "sent": "Has two components to solve different problems.",
                    "label": 1
                },
                {
                    "sent": "Different challenges in this problem.",
                    "label": 0
                },
                {
                    "sent": "So the first part is evaluation part.",
                    "label": 0
                },
                {
                    "sent": "They they want to tell which whether the subpattern is useful to the classification task or not, and we know that there are many subgraph patterns in a graph data set, and most of them are not directly useful for the classification tasks, so we just want to select the useful ones from them and the 2nd.",
                    "label": 0
                },
                {
                    "sent": "And intuitively, the first part can make the model more effective to the classification task, and the second part is the search space pruning.",
                    "label": 1
                },
                {
                    "sent": "Because in real graph data set usually there are a lot of subpatterns.",
                    "label": 1
                },
                {
                    "sent": "The number of the subgraph pattern can be exponential to the size of the graph, so usually it is impossible to enumerate all the subgraph pattern in order to find the best one.",
                    "label": 0
                },
                {
                    "sent": "So what they do is they find a way to prove this search space without searching all the subgraph patterns and also find the best subgraph features so.",
                    "label": 0
                },
                {
                    "sent": "So the second part can make the method more more efficient.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And all this conventional methods are focused on the supervised settings, which means that they require a lot.",
                    "label": 1
                },
                {
                    "sent": "A lot of labeled graph in order to work well.",
                    "label": 0
                },
                {
                    "sent": "However, in real world problems usually labeling a graph is very hard.",
                    "label": 1
                },
                {
                    "sent": "Take take example for the chemical compounds, if we want to label a chemical, usually we need to take animal test, clinical trial, use a lot of money, a lot of time and.",
                    "label": 0
                },
                {
                    "sent": "Effort of the experts.",
                    "label": 0
                },
                {
                    "sent": "So in real case it is impossible to get a large set of labeled graph in order to perform graph classification.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So because the two components of the conventional method will all fail because the lack of label information.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what can we do?",
                    "label": 0
                },
                {
                    "sent": "In this paper we proposed to use a semi proposal framework for semi supervised feature selection for graph classification.",
                    "label": 0
                },
                {
                    "sent": "The general idea is.",
                    "label": 0
                },
                {
                    "sent": "Though in real world problems we cannot get too many labeled graphs, but usually we can get a lot of unlabeled graph very easily.",
                    "label": 0
                },
                {
                    "sent": "So why not?",
                    "label": 0
                },
                {
                    "sent": "We use both labeled graph and unlabeled graph together to find the most useful subgraph patterns.",
                    "label": 1
                },
                {
                    "sent": "So the problem we want to solve is how can we use the labeled graph, an unlabeled graph to find the useful patterns for the graph classification.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to solve this problem, we need to attack two questions which is similar to the conventional conventional method.",
                    "label": 0
                },
                {
                    "sent": "The first one is the evaluation part.",
                    "label": 0
                },
                {
                    "sent": "How can we say a sub graph is useful to the classification task when we have both labeled and unlabeled graph and 2nd part is how can we prune the search space using both labeled and unlabeled graph?",
                    "label": 1
                },
                {
                    "sent": "So let's first focus on the first question.",
                    "label": 0
                },
                {
                    "sent": "So the question is, what is a good feature?",
                    "label": 0
                },
                {
                    "sent": "We have both labeled and and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prograf so we we proposed.",
                    "label": 0
                },
                {
                    "sent": "This three quite hearing all three properties, which we say a good feature should have all these three properties.",
                    "label": 0
                },
                {
                    "sent": "The first one is cannot link, which means that using that subgraph feature the graphs in different classes should be separated far away from each other and the second one is must.",
                    "label": 0
                },
                {
                    "sent": "Link means if the graph in the same class should be close together using that subgraph feature, and the third one is separability, which means that the unlabeled graph should be able to be separated from each other using that.",
                    "label": 1
                },
                {
                    "sent": "Subgraph feature, so let's explain this using an example.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have some labeled graphs and a lot of large number of unlabeled graphs.",
                    "label": 0
                },
                {
                    "sent": "So now we have a several pattern one, and this pattern is can be represented as a partition in the graph database because one.",
                    "label": 0
                },
                {
                    "sent": "One part of the graph will have this pattern, while the other part do not have that one.",
                    "label": 0
                },
                {
                    "sent": "So let's look at the first 2 properties.",
                    "label": 0
                },
                {
                    "sent": "We want to find in the subpattern.",
                    "label": 0
                },
                {
                    "sent": "Actually, according to according to this property, this subpattern is not a good pattern, because we can see that this pattern actually separates the graphs in the same class far away from each other.",
                    "label": 0
                },
                {
                    "sent": "Well, make the graph in different classes close to each other, so this is not what we want.",
                    "label": 0
                },
                {
                    "sent": "So this is not a good pattern.",
                    "label": 0
                },
                {
                    "sent": "Let's look at the second sub pattern.",
                    "label": 0
                },
                {
                    "sent": "So if we only look at the labeled graphs, actually this is a very good pattern because it can make the graph in the same class close together while the different class far away.",
                    "label": 0
                },
                {
                    "sent": "So actually this is what we want.",
                    "label": 0
                },
                {
                    "sent": "However, if we also look at the third property, which means if we consider the unlabeled graphs will find there will be a problem with this several feature is that if.",
                    "label": 0
                },
                {
                    "sent": "If we use this feature on this graph, data set, actually, no matter what classifier you use, all the unlabeled graph will be classified into the same class, and usually this is not what we want.",
                    "label": 0
                },
                {
                    "sent": "So when we so when we consider all the three properties, usually the third graph feature is what we want to find.",
                    "label": 0
                },
                {
                    "sent": "They can both satisfy the three, the three properties.",
                    "label": 0
                },
                {
                    "sent": "So when we compare the these two separate patterns, we will find how the unlabeled graph can help us to select better Sagra patterns.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh we formulate the sub graph feature selection problem as the optimization problem and we want to select a subset from other subgraph features and using trying to maximize the evaluation function, the evaluation function is is composed by three terms and each of these terms corresponds to one property.",
                    "label": 0
                },
                {
                    "sent": "We want to find in the subgraph features, so we also put two parameters to control the.",
                    "label": 0
                },
                {
                    "sent": "Weights on different type of properties to to emphasize on.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In parts so.",
                    "label": 0
                },
                {
                    "sent": "When we convert this evaluation function into matrix form, finally we find that the evaluation value can be calculated by a sum over all the selected feature using this formula.",
                    "label": 1
                },
                {
                    "sent": "Now we define this formula as evaluation criteria for a subgraph feature.",
                    "label": 0
                },
                {
                    "sent": "Here the FK means represent the case several feature, while the L matrix has the information from both labeled an unlabeled graphs.",
                    "label": 0
                },
                {
                    "sent": "And we just need to calculate all the GCM score on each of the circular pattern and select the best one.",
                    "label": 0
                },
                {
                    "sent": "So now we have to find a way to evaluate the subgraph patterns using both label and label graph so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How good our our evaluation method works.",
                    "label": 0
                },
                {
                    "sent": "We perform experiments on five real world data set about chemical compounds, activities and we use different number of labeled graphs in each settings.",
                    "label": 0
                },
                {
                    "sent": "Let's focus on one of the fish.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Years so.",
                    "label": 0
                },
                {
                    "sent": "In this figure way compared to baseline, one is supervised using information going to select several features.",
                    "label": 0
                },
                {
                    "sent": "The second one is unsupervised, which just select the most frequent subgraph patterns, and we see that when we select different number of feature set, actually our method can outperform outperform all the other two baselines and this can be explained that our method can use both labeled and unlabeled graph.",
                    "label": 0
                },
                {
                    "sent": "Well, the supervised method only.",
                    "label": 0
                },
                {
                    "sent": "Make use of the small set of labeled information an the frequent and supervise method.",
                    "label": 0
                },
                {
                    "sent": "Do not use the label information so they cannot work better than the baseline.",
                    "label": 0
                },
                {
                    "sent": "Then our method.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here we go to the second part.",
                    "label": 0
                },
                {
                    "sent": "We need to solve is how can we prove the search space using both labeled and unlabeled graphs?",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So actually the question is of is like because we have a large number of subgraph patterns in a graph data set.",
                    "label": 0
                },
                {
                    "sent": "However, we only want to find the most useful ones among them, so it's like finding a needle in a haystack.",
                    "label": 1
                },
                {
                    "sent": "So in order to do this, we need to use frequent subgraph subgraph mining method called G span an.",
                    "label": 0
                },
                {
                    "sent": "It is very efficient algorithm to enumerate other frequent subgraph patterns in a graph data set.",
                    "label": 1
                },
                {
                    "sent": "So the basic idea is they can put all the frequent subgraph pattern, organize all the frequent several patterns in the pattern search tree, which they call DFS code tree, and each of these nodes in the tree represent a subgraph pattern and.",
                    "label": 0
                },
                {
                    "sent": "As we perform depth, first search in the in the pattern search tree.",
                    "label": 0
                },
                {
                    "sent": "Initially we will have a very small subgraph pattern and we keep adding new edges to that pattern and get larger larger subgraphs until the pattern becomes infrequent.",
                    "label": 0
                },
                {
                    "sent": "So we know that among all the nodes in this tree, we have some useful patterns according to the GSM score, and we want to find these patterns among other nodes and the bad news is usually this tree is very large.",
                    "label": 0
                },
                {
                    "sent": "We cannot afford to search all the nodes in this tree in order to get the best ones from them.",
                    "label": 1
                },
                {
                    "sent": "So how can we do that?",
                    "label": 0
                },
                {
                    "sent": "The basic idea is we want to use the branch and bound to prune the search space an.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Take take an example like this.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a current best subgraph feature an.",
                    "label": 1
                },
                {
                    "sent": "This is just me score an now we have the current node.",
                    "label": 0
                },
                {
                    "sent": "When we search the pattern search tree and it's and it's score is like this.",
                    "label": 1
                },
                {
                    "sent": "If the current nodes Geesaman score is better than the best one we seen before, we can just replace the best one with our current node.",
                    "label": 1
                },
                {
                    "sent": "However, if the current node is not better than the best sub graph, we also need to decide whether we need to search.",
                    "label": 0
                },
                {
                    "sent": "To the children node and subtree of from the current node.",
                    "label": 1
                },
                {
                    "sent": "So we calculate an upper bound.",
                    "label": 0
                },
                {
                    "sent": "The meaning of this upper bound is that if we if we consider all the sub graph in the subtree and actually they will not get any better value than this upper bound.",
                    "label": 0
                },
                {
                    "sent": "So this upper bound means that this is the best they can get so.",
                    "label": 0
                },
                {
                    "sent": "If the current best value is better than this upper bound, we can simply cut this subtree without searching any node, and it's guaranteed that we will not miss any better subgraph features.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how good our sub?",
                    "label": 0
                },
                {
                    "sent": "How could our pruning method works?",
                    "label": 0
                },
                {
                    "sent": "So this is a running time when we compare after pruning and without planning.",
                    "label": 1
                },
                {
                    "sent": "So consider the running time is in exponential scale so our pruning method can.",
                    "label": 0
                },
                {
                    "sent": "Significantly decrease the running time.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Also, we study the number of subgraphs explored during this feature mining process.",
                    "label": 1
                },
                {
                    "sent": "We find that our upper bound can prove a lot of large number of subgraph patterns, so this process can make the our model very efficient.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude.",
                    "label": 0
                },
                {
                    "sent": "This is the first first method to study the problem of semi supervised feature selection for graph classification and in order to do that we first propose evaluation method to to evaluate the subgraph features using both label and label graphs and then we propose a branch branch and bound pruning method to make make this process even faster.",
                    "label": 1
                },
                {
                    "sent": "So thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Time for a few questions.",
                    "label": 0
                },
                {
                    "sent": "First question is your result is slightly better than 50%.",
                    "label": 0
                },
                {
                    "sent": "I'm wondering the usability of the research and the other question.",
                    "label": 0
                },
                {
                    "sent": "Did you compare with some kernel approach for graph classification?",
                    "label": 0
                },
                {
                    "sent": "OK, so the first question is.",
                    "label": 0
                },
                {
                    "sent": "The evaluation result is just, the accuracy is just a little bit better than 50% right?",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe because this is a very hard classification problem so and also we only have a little number of the label graph, so maybe this is the best they can do, and we and we only show that using both labeled an unlabeled graph can get the performance improved then the.",
                    "label": 0
                },
                {
                    "sent": "The supervised methods so so did I compared with the kernel based graph classification method.",
                    "label": 0
                },
                {
                    "sent": "Well, in this paper we only focus on the sub graph based methods, so we did not compare with the kernel based method.",
                    "label": 0
                },
                {
                    "sent": "So yeah, maybe it's an interesting topic we we can try to study that them later, yeah?",
                    "label": 0
                },
                {
                    "sent": "I actually my question is related to his question and the and the first one I did notice that your accuracy is slightly over 50% for the binary classes classification, and I understand that that particular data set is very hard one.",
                    "label": 0
                },
                {
                    "sent": "So have you test your method on some some other classification graph classification data set where the typical accuracy would be like 7080% to see how much improvement you can get or.",
                    "label": 0
                },
                {
                    "sent": "That when you show it was the only set data set you you have tested, we performed experiment on five real world data set first three NCI data set the the second last two PC data set and that is what graph classification papers always use.",
                    "label": 0
                },
                {
                    "sent": "So we just use this file.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's the accuracy.",
                    "label": 0
                },
                {
                    "sent": "Always stay at a little about 50% or is accuracy better for some other data set?",
                    "label": 0
                },
                {
                    "sent": "That's my question.",
                    "label": 0
                },
                {
                    "sent": "The the accuracy you have five data set right?",
                    "label": 0
                },
                {
                    "sent": "You show us one of the five OK and how about the other four?",
                    "label": 0
                },
                {
                    "sent": "I just wonder about the accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so this is all the experiment an actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah, most of them are just a little bit higher than 50%, but the good news is in all these cases our method can improve the performance.",
                    "label": 0
                },
                {
                    "sent": "Then there's only the supervised method in terms of the supervised method.",
                    "label": 0
                },
                {
                    "sent": "There are more than one of those, and which one did you compare?",
                    "label": 0
                },
                {
                    "sent": "We compare using the information gain to select the feature.",
                    "label": 0
                },
                {
                    "sent": "And it is just used also used in other papers to compare with their paper.",
                    "label": 0
                },
                {
                    "sent": "So it is like a benchmark method, yeah?",
                    "label": 0
                },
                {
                    "sent": "Well the I I'm I'm aware of there's other more recent ones, and then I would suggest you look at them and.",
                    "label": 0
                },
                {
                    "sent": "Well, you have to be out by capitalizing more and more discussion.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}