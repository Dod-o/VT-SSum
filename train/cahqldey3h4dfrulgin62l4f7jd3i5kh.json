{
    "id": "cahqldey3h4dfrulgin62l4f7jd3i5kh",
    "title": "Knowing a Good HOG Filter When You See It: Efficient Selection of Filters for Detection",
    "info": {
        "author": [
            "Ejaz Ahmed, Institute for Advanced Computer Studies, University of Maryland"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2014_ahmed_efficient_selection/",
    "segmentation": [
        [
            "Good morning everyone.",
            "Thank you for the introduction.",
            "I did this work when I was an intern entity as Chicago.",
            "This is joint work with Greg Tech Knowledge answer on Jumanji and I get to present this work because it's my birthday today."
        ],
        [
            "So a common way to represent visual category is to represent it as a collection of models.",
            "These models can be part based such as IMPOSERS or DPM, or can be defined globally.",
            "Such an example assumes the way these components are defined and discovered varies across methods.",
            "In this work, our focus is on a common architecture which has two major steps, candidate generation step and candidate selection step."
        ],
        [
            "Candidate generation step involves generating a large pool of filters or classifiers, giving a category.",
            "These filters are generated from positives and negative examples.",
            "So given positive and negative examples, you train classifiers.",
            "Typically linear classifiers, for instance linear, SVM, LDA, or more recently convolution neural networks.",
            "This step, the candidate generation step is modestly expensive."
        ],
        [
            "It is impractical to use all the generated filters in a detection setting on test set, so to give it to give you an idea pose late model generates initially generates thousand pose, let filters and then it is.",
            "As you can imagine it is impractical to evaluate all those thousand filters on the test image.",
            "So usually these architectures select a subset of filters from a large pool of filters.",
            "There are two sources of inefficiency.",
            "One is redundancy.",
            "You don't want to select similar looking filter more than once.",
            "You want to have complementary filters.",
            "And second source of inefficiency is noise, so you want to select filters which are good which are discriminative.",
            "So on the on the left hand side on the right hand side we have a bad filter which will fire all over the image.",
            "It's not if it won't fire at unique location while on the left hand side there is a good filter which will fire on unique locations."
        ],
        [
            "So typically candidate selection step is done in the following way, so you are given a pool of filters.",
            "You well with each of these filters filter on a testing on a training set and then you evaluate the performance of each of these filters and then you select filters according to their performance on the training set.",
            "And you can imagine that this process is very slow because you need to evaluate each filter on a training data in a sliding window fashion.",
            "So you need to evaluate thousands of sub windows you want to classify thousands of Windows.",
            "So this step is very slow in and is often the bottleneck for such architectures."
        ],
        [
            "So we propose to bypass this expensive evaluation step, so our goal is that given a given a bunch of filters, large pool of filters, we will select a small cooler filter, small filter, small set of filters.",
            "But we won't do this with with expensive valuation and the properties of the selected filters should be that they should be discriminative and they should be complementary to each other.",
            "This is what we propose to do."
        ],
        [
            "So, given, uh, so for training we have bunch of categories we select, we get, we generate some filters from them and we evaluate the filters on using expensive method and then we learn a model which ranks these filters.",
            "So during training we do the expensive elevation to get some information about what a good filter is and then we train a model and when we are when we want to do selection for a new category we basically generate the filters and do selection by applying our model.",
            "Applier learn model on the on the generated filters for test category.",
            "Notice that the test category the filters which are used for training category are they do not have any filter from the test category.",
            "So in that sense this is a category independent way of selecting filters.",
            "So we can rank filters as accurately as a as direct evaluation on thousands of examples examples."
        ],
        [
            "V in this work we have shown results on two architecture postlets.",
            "An example seems both less are semantically aligned discriminative patterns that capture parts of object patches are patches are far visually but they are closed semantically."
        ],
        [
            "So the candidate generation step of posted architecture has the following thing, so they randomly sample windows in an in an object and then this cluster those clusters of windows to form different concept.",
            "For instance head, leg, torso etc.",
            "And then it rain linear schemes for on them and then the candidate selection step involves expensive elevation on a held out set and then selecting filters according to coverage.",
            "It takes 20 hours on a single machine to train post, let architecture, and 24% of the time is spending candidate generation and 3, four 3/4 of the time is spent in candidate selection."
        ],
        [
            "Example, assume is another architecture which generates large pool of filters and evaluate.",
            "So basically for each training example there is, it learns a spam classifier an all those SVM filters are then applied on a test image and then the results are accumulated.",
            "There is, as you can imagine, there is a lot of redundancy because various examples are very similar.",
            "So we can say significantly in training time if we can quickly select small subset of relevant.",
            "Examplars so let's pause for a second.",
            "So our problem is, given a bunch of filters, we want to select a small subset of filters with the property that the small subset should be discriminate if they should be complemented to each other, and we want to do this without expensive explicit evaluation in order to do so, we need to understand what is a good filter and what is a bad filter."
        ],
        [
            "On the left hand side I have shown some some good filters and on the right hand side I have shown some bad filters.",
            "So the property of good filter is that the gradients are less cluttered and the gradients are correlated.",
            "So if we zoom in into a good filter and if you look at one particular cell of a good filter we see that the gradient gradients are active simultaneously and if you look at nearby gradient orientation bins are tend to coincide, forming line segments.",
            "They tend to differ by an angle forming curves or corners.",
            "We exploit this."
        ],
        [
            "These properties to come up with some features based on the.",
            "Based on these properties.",
            "So the first feature we consider is just simple norm of the of the filter, so a higher norm implies that it is consistent with high degree of alignment.",
            "We make it invariant filter dimension.",
            "Here are some filters which are sorted according to the decreasing value of norm on the left hand side.",
            "There are good filters on the right hand side.",
            "There are some bad filters and you can see that even this naive filter is a feature is also able to discriminate between a good filter and a bad filter.",
            "Then we have some other other features such as cell covariance which capture which captures the property that within a cell gradient orientations are active simultaneously, and then we also consider cell cross covariance which says that gradient orientation bins in nearby cells they tend to coincide, forming line segments and curves.",
            "We consider four neighborhoods horizontal, vertical and the two diagonals."
        ],
        [
            "So we concatenate all the features and we have a feature representation of a filter and our goal is to model A ranking score by a linear function and during training we have a bunch of filters.",
            "We extract features from them and we also have their estimated quality which we obtained by evaluating them on a on a held out set.",
            "So we we train, uh, we minimize the following objective function and I'm not going to go into the details of the objective function.",
            "The details are in the paper.",
            "You can look over that or we can talk about it more in the Post recession.",
            "But this is basically a slack rescaled hinge loss."
        ],
        [
            "So as I said earlier, the selected filters should be discriminative but as well as they should be diverse.",
            "So by diverse diversity, that means that they should be complementary to each other.",
            "And the way we do with the way we induce this diversity term is as follows.",
            "First, we select a filter which has the maximum predicted score from a rancor and then suppose we have selected the filter.",
            "So far we select the next filter using the following function and the overall intuition about this function is as follows.",
            "Suppose we have filters on the left hand side, which of which we have already selected and then we have three filters on the right hand side from which we have to select one filter.",
            "Let's assume for simplicity that the rank rank are gave equal quality for all of these three filters, so we will select that filter which has the minimum similarity with from the selected filters, so that filter is selected."
        ],
        [
            "So so far we have a we have speeded up the selection procedure by learning a model, but we haven't touched the candidate generation process candidate generation process typically is training, linear SVM, zinar bootstrapping them so hard negative mining so it is modestly expensive.",
            "So we instead of training linear experience, we trade linear discriminant analysis so they can be the property of LDA filters is that they can be computed really fast because you need to estimate Sigma and mu negative.",
            "Only once, father for all the categories.",
            "And another property of the elephant is that individual performance of a filter is not that good, but it is correlated with SPM filter.",
            "So for instance, a good idea filter is also a good SPM filter, so we exploit their property.",
            "We generate initial set of LDA filters, large bunch of LDA filters.",
            "We apply a model and select a small subset of LDA filters and then we only train expensive SPM filters with hard negative mining on this small subset too.",
            "And the performance of this subset is better.",
            "As compared to a small subset of LDA filters."
        ],
        [
            "So.",
            "We did not expect we evaluated our filter selection procedure on post, let architecture.",
            "So if we want to do selection filter selection for say for instance bicycle, all the remaining categories were used to generate filters and user training used to train our model.",
            "So our our goal is that for each category we have 800 filters and our goal is to select hundred filters out of those 800 filters.",
            "We evaluate our experiments as two tasks, ranking task and detection."
        ],
        [
            "So we evaluate the ranking task by predicted ranking by our algorithm versus the true ranking as per the expensive evaluation of AP scores.",
            "First method we compare is by just sorting according to the norm of SPM filters.",
            "And then we also consider structured Norm which was presented at ACC 2012 by Garvey tell structure.",
            "Norm Ranking performs better than norm ranking and then we rank the filters according to the user ranking model to rank filters according to the LDA filters and this.",
            "This ranking performs better than structured Norman Norm.",
            "And if we do ranking on the SVM filters, it performs better than all three ranking methods."
        ],
        [
            "For detection, we construct opposed detector using the selected filters on this axis I'm showing performance detection performance in increasing order and on this axis I have speed up with respect to the Oracle.",
            "So Oracle is basically the expensive evaluation procedure when you when you select filters by expensively evaluating each of the filters on the training set.",
            "So first we selected 100 filters from 800 filters by random sampling, and as you can imagine.",
            "The performance is really bad, but the speedup is 8 times cause there is no selection going on there.",
            "Then we selected 100 filters by evaluating 800 filters on on 10% of the training data and the performance is better than random, but the speedup goes down to 2.4 times.",
            "We selected filters by sort sorting them according to their rank.",
            "The performance is bad, but if we add the diversity term to it, the performance increases and this results with a 3 times speedup.",
            "Similarly, structured Norm performs better than Norm and the diversity version of the structure known performs better than Norm plus diversity and it results again in three times speedup rank ranking using a ranking model machine filters it performs somewhere in middle of this whole spectrum, but it results in a three times speed up.",
            "If you had the diversity term it outperforms Oracle method and it again results in a three times speed up.",
            "Now we did.",
            "We evaluated we selected filters based on the ranking based on the LDA filters and we ranked according to the LDA filters and.",
            "Since you can imagine that this LDA ranking method based on this LDA filters is, it also speeds up selection procedure as well as the candidate generation process because we don't have to do hard negative mining for for for generating their spam filters.",
            "So the performance is not that good but it results in eight times speedup and because of this LDA acceleration we are we can select from not only from 100 filters but we can select from a larger set of filters.",
            "So we did that experiment and we selected.",
            "100 filters from a 16 form from a set of from a pool of 1600 filters and.",
            "The performance is better than rank extreme plus diversity and Oracle which is expensive valuation and it results in.",
            "Order of magnitude speedup of eight times.",
            "So to summarize these results.",
            "Basically we are able to obtain an order of magnitude speedup with an improved performance over the expensive evaluation process."
        ],
        [
            "We also have some results on example SVM where we can select a subset of good examples which are which are which are basically diverse and frequent and discriminative.",
            "The details are in the papers, but over there also we obtain similar trends."
        ],
        [
            "To conclude, we have presented an automatic mechanism for selecting a diverse set of discriminative filters, which results in an order of magnitude improvement in training time.",
            "Approach is applicable to any discriminative architecture that uses collection of filters.",
            "It gives us insight into what makes a good filter for object detection.",
            "And this can be used as an attention mechanism during test time.",
            "Also.",
            "For instance, you can.",
            "We can reduce number of convolutions or hashing look up based on these properties of filters.",
            "So.",
            "Overall summary of the work or the OR the thing which was of, which was very interesting to me, is the fact that one can tell whether a filter is useful for a category without knowing what that category is by just looking at the filter.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the introduction.",
                    "label": 0
                },
                {
                    "sent": "I did this work when I was an intern entity as Chicago.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Greg Tech Knowledge answer on Jumanji and I get to present this work because it's my birthday today.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a common way to represent visual category is to represent it as a collection of models.",
                    "label": 1
                },
                {
                    "sent": "These models can be part based such as IMPOSERS or DPM, or can be defined globally.",
                    "label": 0
                },
                {
                    "sent": "Such an example assumes the way these components are defined and discovered varies across methods.",
                    "label": 0
                },
                {
                    "sent": "In this work, our focus is on a common architecture which has two major steps, candidate generation step and candidate selection step.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Candidate generation step involves generating a large pool of filters or classifiers, giving a category.",
                    "label": 1
                },
                {
                    "sent": "These filters are generated from positives and negative examples.",
                    "label": 0
                },
                {
                    "sent": "So given positive and negative examples, you train classifiers.",
                    "label": 0
                },
                {
                    "sent": "Typically linear classifiers, for instance linear, SVM, LDA, or more recently convolution neural networks.",
                    "label": 0
                },
                {
                    "sent": "This step, the candidate generation step is modestly expensive.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is impractical to use all the generated filters in a detection setting on test set, so to give it to give you an idea pose late model generates initially generates thousand pose, let filters and then it is.",
                    "label": 0
                },
                {
                    "sent": "As you can imagine it is impractical to evaluate all those thousand filters on the test image.",
                    "label": 0
                },
                {
                    "sent": "So usually these architectures select a subset of filters from a large pool of filters.",
                    "label": 1
                },
                {
                    "sent": "There are two sources of inefficiency.",
                    "label": 1
                },
                {
                    "sent": "One is redundancy.",
                    "label": 0
                },
                {
                    "sent": "You don't want to select similar looking filter more than once.",
                    "label": 0
                },
                {
                    "sent": "You want to have complementary filters.",
                    "label": 0
                },
                {
                    "sent": "And second source of inefficiency is noise, so you want to select filters which are good which are discriminative.",
                    "label": 0
                },
                {
                    "sent": "So on the on the left hand side on the right hand side we have a bad filter which will fire all over the image.",
                    "label": 0
                },
                {
                    "sent": "It's not if it won't fire at unique location while on the left hand side there is a good filter which will fire on unique locations.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So typically candidate selection step is done in the following way, so you are given a pool of filters.",
                    "label": 1
                },
                {
                    "sent": "You well with each of these filters filter on a testing on a training set and then you evaluate the performance of each of these filters and then you select filters according to their performance on the training set.",
                    "label": 0
                },
                {
                    "sent": "And you can imagine that this process is very slow because you need to evaluate each filter on a training data in a sliding window fashion.",
                    "label": 0
                },
                {
                    "sent": "So you need to evaluate thousands of sub windows you want to classify thousands of Windows.",
                    "label": 0
                },
                {
                    "sent": "So this step is very slow in and is often the bottleneck for such architectures.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we propose to bypass this expensive evaluation step, so our goal is that given a given a bunch of filters, large pool of filters, we will select a small cooler filter, small filter, small set of filters.",
                    "label": 1
                },
                {
                    "sent": "But we won't do this with with expensive valuation and the properties of the selected filters should be that they should be discriminative and they should be complementary to each other.",
                    "label": 1
                },
                {
                    "sent": "This is what we propose to do.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, given, uh, so for training we have bunch of categories we select, we get, we generate some filters from them and we evaluate the filters on using expensive method and then we learn a model which ranks these filters.",
                    "label": 0
                },
                {
                    "sent": "So during training we do the expensive elevation to get some information about what a good filter is and then we train a model and when we are when we want to do selection for a new category we basically generate the filters and do selection by applying our model.",
                    "label": 0
                },
                {
                    "sent": "Applier learn model on the on the generated filters for test category.",
                    "label": 0
                },
                {
                    "sent": "Notice that the test category the filters which are used for training category are they do not have any filter from the test category.",
                    "label": 0
                },
                {
                    "sent": "So in that sense this is a category independent way of selecting filters.",
                    "label": 0
                },
                {
                    "sent": "So we can rank filters as accurately as a as direct evaluation on thousands of examples examples.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "V in this work we have shown results on two architecture postlets.",
                    "label": 0
                },
                {
                    "sent": "An example seems both less are semantically aligned discriminative patterns that capture parts of object patches are patches are far visually but they are closed semantically.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the candidate generation step of posted architecture has the following thing, so they randomly sample windows in an in an object and then this cluster those clusters of windows to form different concept.",
                    "label": 0
                },
                {
                    "sent": "For instance head, leg, torso etc.",
                    "label": 0
                },
                {
                    "sent": "And then it rain linear schemes for on them and then the candidate selection step involves expensive elevation on a held out set and then selecting filters according to coverage.",
                    "label": 0
                },
                {
                    "sent": "It takes 20 hours on a single machine to train post, let architecture, and 24% of the time is spending candidate generation and 3, four 3/4 of the time is spent in candidate selection.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example, assume is another architecture which generates large pool of filters and evaluate.",
                    "label": 0
                },
                {
                    "sent": "So basically for each training example there is, it learns a spam classifier an all those SVM filters are then applied on a test image and then the results are accumulated.",
                    "label": 0
                },
                {
                    "sent": "There is, as you can imagine, there is a lot of redundancy because various examples are very similar.",
                    "label": 0
                },
                {
                    "sent": "So we can say significantly in training time if we can quickly select small subset of relevant.",
                    "label": 1
                },
                {
                    "sent": "Examplars so let's pause for a second.",
                    "label": 0
                },
                {
                    "sent": "So our problem is, given a bunch of filters, we want to select a small subset of filters with the property that the small subset should be discriminate if they should be complemented to each other, and we want to do this without expensive explicit evaluation in order to do so, we need to understand what is a good filter and what is a bad filter.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the left hand side I have shown some some good filters and on the right hand side I have shown some bad filters.",
                    "label": 1
                },
                {
                    "sent": "So the property of good filter is that the gradients are less cluttered and the gradients are correlated.",
                    "label": 0
                },
                {
                    "sent": "So if we zoom in into a good filter and if you look at one particular cell of a good filter we see that the gradient gradients are active simultaneously and if you look at nearby gradient orientation bins are tend to coincide, forming line segments.",
                    "label": 0
                },
                {
                    "sent": "They tend to differ by an angle forming curves or corners.",
                    "label": 0
                },
                {
                    "sent": "We exploit this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These properties to come up with some features based on the.",
                    "label": 0
                },
                {
                    "sent": "Based on these properties.",
                    "label": 0
                },
                {
                    "sent": "So the first feature we consider is just simple norm of the of the filter, so a higher norm implies that it is consistent with high degree of alignment.",
                    "label": 1
                },
                {
                    "sent": "We make it invariant filter dimension.",
                    "label": 0
                },
                {
                    "sent": "Here are some filters which are sorted according to the decreasing value of norm on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "There are good filters on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "There are some bad filters and you can see that even this naive filter is a feature is also able to discriminate between a good filter and a bad filter.",
                    "label": 0
                },
                {
                    "sent": "Then we have some other other features such as cell covariance which capture which captures the property that within a cell gradient orientations are active simultaneously, and then we also consider cell cross covariance which says that gradient orientation bins in nearby cells they tend to coincide, forming line segments and curves.",
                    "label": 1
                },
                {
                    "sent": "We consider four neighborhoods horizontal, vertical and the two diagonals.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we concatenate all the features and we have a feature representation of a filter and our goal is to model A ranking score by a linear function and during training we have a bunch of filters.",
                    "label": 1
                },
                {
                    "sent": "We extract features from them and we also have their estimated quality which we obtained by evaluating them on a on a held out set.",
                    "label": 0
                },
                {
                    "sent": "So we we train, uh, we minimize the following objective function and I'm not going to go into the details of the objective function.",
                    "label": 0
                },
                {
                    "sent": "The details are in the paper.",
                    "label": 0
                },
                {
                    "sent": "You can look over that or we can talk about it more in the Post recession.",
                    "label": 1
                },
                {
                    "sent": "But this is basically a slack rescaled hinge loss.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I said earlier, the selected filters should be discriminative but as well as they should be diverse.",
                    "label": 0
                },
                {
                    "sent": "So by diverse diversity, that means that they should be complementary to each other.",
                    "label": 0
                },
                {
                    "sent": "And the way we do with the way we induce this diversity term is as follows.",
                    "label": 0
                },
                {
                    "sent": "First, we select a filter which has the maximum predicted score from a rancor and then suppose we have selected the filter.",
                    "label": 0
                },
                {
                    "sent": "So far we select the next filter using the following function and the overall intuition about this function is as follows.",
                    "label": 1
                },
                {
                    "sent": "Suppose we have filters on the left hand side, which of which we have already selected and then we have three filters on the right hand side from which we have to select one filter.",
                    "label": 0
                },
                {
                    "sent": "Let's assume for simplicity that the rank rank are gave equal quality for all of these three filters, so we will select that filter which has the minimum similarity with from the selected filters, so that filter is selected.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so far we have a we have speeded up the selection procedure by learning a model, but we haven't touched the candidate generation process candidate generation process typically is training, linear SVM, zinar bootstrapping them so hard negative mining so it is modestly expensive.",
                    "label": 1
                },
                {
                    "sent": "So we instead of training linear experience, we trade linear discriminant analysis so they can be the property of LDA filters is that they can be computed really fast because you need to estimate Sigma and mu negative.",
                    "label": 0
                },
                {
                    "sent": "Only once, father for all the categories.",
                    "label": 0
                },
                {
                    "sent": "And another property of the elephant is that individual performance of a filter is not that good, but it is correlated with SPM filter.",
                    "label": 0
                },
                {
                    "sent": "So for instance, a good idea filter is also a good SPM filter, so we exploit their property.",
                    "label": 0
                },
                {
                    "sent": "We generate initial set of LDA filters, large bunch of LDA filters.",
                    "label": 0
                },
                {
                    "sent": "We apply a model and select a small subset of LDA filters and then we only train expensive SPM filters with hard negative mining on this small subset too.",
                    "label": 0
                },
                {
                    "sent": "And the performance of this subset is better.",
                    "label": 1
                },
                {
                    "sent": "As compared to a small subset of LDA filters.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We did not expect we evaluated our filter selection procedure on post, let architecture.",
                    "label": 0
                },
                {
                    "sent": "So if we want to do selection filter selection for say for instance bicycle, all the remaining categories were used to generate filters and user training used to train our model.",
                    "label": 0
                },
                {
                    "sent": "So our our goal is that for each category we have 800 filters and our goal is to select hundred filters out of those 800 filters.",
                    "label": 1
                },
                {
                    "sent": "We evaluate our experiments as two tasks, ranking task and detection.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we evaluate the ranking task by predicted ranking by our algorithm versus the true ranking as per the expensive evaluation of AP scores.",
                    "label": 1
                },
                {
                    "sent": "First method we compare is by just sorting according to the norm of SPM filters.",
                    "label": 0
                },
                {
                    "sent": "And then we also consider structured Norm which was presented at ACC 2012 by Garvey tell structure.",
                    "label": 0
                },
                {
                    "sent": "Norm Ranking performs better than norm ranking and then we rank the filters according to the user ranking model to rank filters according to the LDA filters and this.",
                    "label": 0
                },
                {
                    "sent": "This ranking performs better than structured Norman Norm.",
                    "label": 0
                },
                {
                    "sent": "And if we do ranking on the SVM filters, it performs better than all three ranking methods.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For detection, we construct opposed detector using the selected filters on this axis I'm showing performance detection performance in increasing order and on this axis I have speed up with respect to the Oracle.",
                    "label": 1
                },
                {
                    "sent": "So Oracle is basically the expensive evaluation procedure when you when you select filters by expensively evaluating each of the filters on the training set.",
                    "label": 0
                },
                {
                    "sent": "So first we selected 100 filters from 800 filters by random sampling, and as you can imagine.",
                    "label": 0
                },
                {
                    "sent": "The performance is really bad, but the speedup is 8 times cause there is no selection going on there.",
                    "label": 0
                },
                {
                    "sent": "Then we selected 100 filters by evaluating 800 filters on on 10% of the training data and the performance is better than random, but the speedup goes down to 2.4 times.",
                    "label": 0
                },
                {
                    "sent": "We selected filters by sort sorting them according to their rank.",
                    "label": 0
                },
                {
                    "sent": "The performance is bad, but if we add the diversity term to it, the performance increases and this results with a 3 times speedup.",
                    "label": 0
                },
                {
                    "sent": "Similarly, structured Norm performs better than Norm and the diversity version of the structure known performs better than Norm plus diversity and it results again in three times speedup rank ranking using a ranking model machine filters it performs somewhere in middle of this whole spectrum, but it results in a three times speed up.",
                    "label": 0
                },
                {
                    "sent": "If you had the diversity term it outperforms Oracle method and it again results in a three times speed up.",
                    "label": 0
                },
                {
                    "sent": "Now we did.",
                    "label": 0
                },
                {
                    "sent": "We evaluated we selected filters based on the ranking based on the LDA filters and we ranked according to the LDA filters and.",
                    "label": 0
                },
                {
                    "sent": "Since you can imagine that this LDA ranking method based on this LDA filters is, it also speeds up selection procedure as well as the candidate generation process because we don't have to do hard negative mining for for for generating their spam filters.",
                    "label": 0
                },
                {
                    "sent": "So the performance is not that good but it results in eight times speedup and because of this LDA acceleration we are we can select from not only from 100 filters but we can select from a larger set of filters.",
                    "label": 0
                },
                {
                    "sent": "So we did that experiment and we selected.",
                    "label": 0
                },
                {
                    "sent": "100 filters from a 16 form from a set of from a pool of 1600 filters and.",
                    "label": 0
                },
                {
                    "sent": "The performance is better than rank extreme plus diversity and Oracle which is expensive valuation and it results in.",
                    "label": 0
                },
                {
                    "sent": "Order of magnitude speedup of eight times.",
                    "label": 0
                },
                {
                    "sent": "So to summarize these results.",
                    "label": 0
                },
                {
                    "sent": "Basically we are able to obtain an order of magnitude speedup with an improved performance over the expensive evaluation process.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also have some results on example SVM where we can select a subset of good examples which are which are which are basically diverse and frequent and discriminative.",
                    "label": 0
                },
                {
                    "sent": "The details are in the papers, but over there also we obtain similar trends.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To conclude, we have presented an automatic mechanism for selecting a diverse set of discriminative filters, which results in an order of magnitude improvement in training time.",
                    "label": 1
                },
                {
                    "sent": "Approach is applicable to any discriminative architecture that uses collection of filters.",
                    "label": 1
                },
                {
                    "sent": "It gives us insight into what makes a good filter for object detection.",
                    "label": 0
                },
                {
                    "sent": "And this can be used as an attention mechanism during test time.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can.",
                    "label": 0
                },
                {
                    "sent": "We can reduce number of convolutions or hashing look up based on these properties of filters.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "Overall summary of the work or the OR the thing which was of, which was very interesting to me, is the fact that one can tell whether a filter is useful for a category without knowing what that category is by just looking at the filter.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}