{
    "id": "r2zywllvuz4bhfpekdgerqdihjl6fxqp",
    "title": "Compact and Understandable Descriptions of Mixtures of Bernoulli Distributions",
    "info": {
        "author": [
            "Jaakko Hollm\u00e9n, Helsinki Institute for Information Technology"
        ],
        "published": "Oct. 5, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/ida07_hollmen_cud/",
    "segmentation": [
        [
            "OK, thanks for the introduction.",
            "So it's nice to be one of the early speakers in the conference, because regardless of the contents of the talks, then people tend to be awake.",
            "And so my talk is basically divided in three parts.",
            "So first I will talk about the problem we have in cancer genetics.",
            "Little, but a little bit about their data and their conception of the language used to describe their data.",
            "Then the middle part about our modeling efforts with the finite mixture models of multivariate Bernoulli distributions and then in the end I will.",
            "I will show how to make this probabilistic models compact.",
            "And understandable for for our collaborators to use in their their work."
        ],
        [
            "Little bit background on the problem first so so I should acknowledge the collaboration with Zachary Crudele and someone will look on us at the University of Helsinki.",
            "They are cancer genetests and they are interested in that DNA copy number amplification.",
            "Or Simply put put mutations in the DNA structures and that has like a known role in the development of cancer and that's that's why they're interested to investigate that.",
            "And they actually made a huge.",
            "Complete compilation of literature covering 808 hundred Journal articles covering the duration of 10 years and they actually read through these articles by hand, so no text mining involved and then compiled a database of these chromosomal mutations that has about 4500 cancer patients."
        ],
        [
            "Recorded so this would be a typical example that they go through text and using their professional knowledge they pick up some parts.",
            "These actually like the notations used used in the literature to denote chromosomal area.",
            "So physical locations in the general.",
            "There's also background article about the data set and and the collection of it.",
            "And if somebody is interested to work with this data set time, I'm willing to share it with you."
        ],
        [
            "So a little bit about the naming scheme used used in this context, so there's a standardized naming scheme or nomenklatura to address like areas in the general like one picture is on the right side, there's chromosome one that we will use as an as an example.",
            "Throughout this talk there are PR, man, QR, miracle moment.",
            "Then they are divided into like regions and subregions.",
            "In in some hierarchical and irregular manner, for instance, if we have the area one, P, 36.2, then it would mean from us on one arm, P, region 36, and sub region 2, and then we can say see some kind of like a range is also also with a similar kind of notation.",
            "But for our purposes."
        ],
        [
            "So we took this this database and we transform it to a 01 database.",
            "So we have.",
            "The rows are now now cancer patients.",
            "So one row describes the data of 1 cancer patients and then we have the spatial coordinates here on the X axis.",
            "So they denote like some course chromosomal areas and then we record either zeros or ones whether there is a mutation or is not a mutation in that particular location.",
            "So this is the modeling problem.",
            "So can we identify some kind of structure in this data?",
            "And then."
        ],
        [
            "We set out to solve this problem by realizing that cancer is actually like a collection of disease, so it's not not one particular disease or well defined disease.",
            "It's like a heterogeneous mass of different kinds of diseases, so then we opted to go with a model that would have some kind of like a clustering capability and we chose to work in the probabilistic context an used finite mixture.",
            "Models of multivariate kernel distributions.",
            "So in the left part of the equation there's a.",
            "Are the standard formulation for, or finite mixture models in general, so we are interested in modeling a probability distribution PX and we model it in terms of J component distributions, parametrised by by some theater JS and then we wait them together or mix them together, gather, perform the probability distribution and then on the right side there's like with the specific choice of like 01 data.",
            "Then we need a multivariate bernouilli distribution as as the component distribution and there the para meters to be estimated.",
            "Our Theater, J eyes and Jays now index the component distributions.",
            "An eyes index the data dimension, so it's like an array or matrix of para meters in that sense.",
            "And what this para meters tell is the probability of some random variable taking the value one.",
            "So we can readily estimate this model in the framework of maximum likelihood using the email gharib them.",
            "This is more or less textbook."
        ],
        [
            "Soft so I'm not going to touch it here.",
            "But what is a central problem in in this context?",
            "Is the model selection, So what kind of resolution do we need in the model?",
            "So more specifically, how many components do we need in this mixture model?",
            "And we use the like a data resampling approach.",
            "We used five fold cross validation approach.",
            "To train different models and then we repeated this exercise 10 times.",
            "So we have 50 trainings.",
            "Of models and then we can estimate the training likelihood seen as the upper curve for different models of different complexity and then validation.",
            "Likelihood and then as some kind of like hopefully like good approximation of the generalization abilities, we picked the.",
            "The model with the maximum validation likelihood.",
            "And so we have the choice of J is equal to six.",
            "In this example chromosome one."
        ],
        [
            "So here's the model.",
            "We then, then we have fixed fixed the model complexity.",
            "Then we take all of the data and this is our final model.",
            "So this should somehow summarize the mutation patterns or DNA copy number amplification patterns will come as one.",
            "And we have provided visualization of the parimeter so large.",
            "Para meters are noted in dark.",
            "So now we have the six mixture components as rows of this matrix.",
            "So we can see that there are like very strong spatial dependencies as these mutations are likely to happen over like many many regions in our resolution.",
            "Resolution and we'll see that the cluster data data in the next slide.",
            "But now it's important to realize that this model is summarized by a large array of probability values.",
            "So we have about 200 para meters like probability values, and this is our model."
        ],
        [
            "And then we can use this this model in like a clustering mode so we can associate data into the clusters by through the like Bayes rule or by associating with posterior probabilities.",
            "And now we have taken the original data that we saw earlier than we have partitioned the data into six clusters or clusters are separated by grey horizontal lines in this figure, so it's just the row permutation of the data data earlier and this.",
            "Like gives kinda like a nice picture so that maybe maybe we have identified relevant structure so there are different types of mutation patterns found in each of the clusters.",
            "Clusters, and so we have like.",
            "We rely on the model.",
            "I think we have done.",
            "Good job."
        ],
        [
            "But then then kind of like a paradox in this work is that the solution created this problem, so the model is very nice, but we created some kind of like communications problems because we would be very unfriendly to our collaborators if we just sent like a stack of 200 para meters and wish them a nice rest of the day.",
            "We cannot do that.",
            "The models would be like really useless.",
            "So now we come to the effort.",
            "So we should make the model somehow understandable to the console.",
            "Experts and it would be very nice if they could like refer.",
            "They could report it and their colleagues could refer to the results.",
            "So we should come up with some kind of names just like we have names."
        ],
        [
            "OK, so now we revisit the title so the compact and understable standable descriptions.",
            "And by understand ability, we mean that we should somehow like turn the results into the language that the cancer genetests are using.",
            "And we had the standard nomenclatural, so that's a natural choice and also compact.",
            "They should be somehow not like a page long listing, but but somehow like a like a short name for some phenomenon, some mutation phenomenon that this happened, and we have basically two ways of doing that.",
            "First, like a direct approach through describing the parameters of the model.",
            "There's two ways I will describe from the next slide, or then we can use the clustering capability cluster the data 1st and then describe like the marginal distributions of the data in the clusters.",
            "But first."
        ],
        [
            "Let's see how we can do with the model parameters.",
            "So one like very, very compact way of summarizing one of these component distributions in a mixture model is to give the mode of the component distribution.",
            "So that's the most probable chromosomal area to have a mutation that's just one one area, but in some cases it gives a biased view view of the whole component distribution as.",
            "As we will see in the results.",
            "The other way actually borrowed from back there.",
            "Aladji is so-called hypothetical mean Organism where we do like quantization of the para meters.",
            "So wherever a para meters above 1/2, then we give a one, and when it's below 1/2 then we give a 0.",
            "Then the."
        ],
        [
            "Second approach is to cluster the data 1st and then described the marginal distributions of the clusters.",
            "Of course you can do this in many many ways, and now we have chosen to use frequent itemsets in this, and more specifically maximal frequent itemsets and then you have.",
            "You could ask that why maximal OK?",
            "Actually.",
            "Secondly, and more importantly extracting frequent itemsets are not feasible, since they are very like long areas or ones, so that there would be so many many of them.",
            "It's not just not computationally feasible.",
            "But we want to describe the largest representative commonalities in the data and we are not really interested in all the millions of subsets of those.",
            "And then we once we have this frequent item representation, then we can."
        ],
        [
            "Express these as some kind of like ranges of documentations.",
            "So this is the result table from the paper, so we have the hypothetical mean Organism on the left for all of their six component distribution in the middle.",
            "The mode we actually don't want to give the mode where it gives a biased view for component distributions with very low probabilities or with very large areas of constant probabilities and on the right column there is this description based on the item sets and there we give them.",
            "Ranges.",
            "Then we also tried as a reference.",
            "We tried to extract frequent itemsets from the day, the globally and there we have only like a couple of results, and they're a little bit like spirits.",
            "Curious, they don't actually relate to the real findings, but they're like sums, sums of different mechanisms found found in this situation.",
            "Patterns also like shadowing that big things like cover small things under them.",
            "Since we are analyzing the margins of.",
            "The."
        ],
        [
            "Whole data set.",
            "So this is actually the summary of our work, so we actually now I present this.",
            "This area of the red box, and so the chromosome one.",
            "In the talk, but also we worked with all the other chromosomes 1 to 22 + X.",
            "Why was omitted?",
            "Because there was no data and then, like with this proposed approach now on the right side, there are around 100 like mutation patterns that we're about publish publish an since they are like expressed in this language, they can be like nicely used as.",
            "In the work of cancer genetics."
        ],
        [
            "It's.",
            "Then to summarize, so we were interested in analyzing the DNA copy number caitians for mutations in cancer, and we showed how our collaborators had compiled a database of these mutations actually by hand, not using any of the text mining fancy stuff, and then we transform this database into a 01 database, did some mixture modeling, and then realized that they are really hard to.",
            "Get across so we had to do some kind of model summarization and we propose two ways taking the parimeter, summarizing them or using the model as a clustering model and then describing the cluster data instead.",
            "And there we used maximum frequent itemsets, although you could use many many methods for that.",
            "And as a like a net result, I think this collection of DNA copy number applications can be can be seen or forms of new basis for cancer classification.",
            "And that's like from this copy number amplification pointed here.",
            "So this concludes my talk.",
            "I'm certain.",
            "That you're doing it for my question is doing it.",
            "Are you considering the variances within classes to inconvenience in their Class 2?",
            "Is window an attribute?",
            "Well, when we extract the frequent itemsets, then then they actually like they are like summarization of the spatially strongly dependent components.",
            "So in a way, yes, yes there's no like.",
            "Full variance here, but spatially dependent areas or other summaries basically.",
            "Recipes for, but they don't give you in general cases the full information which is available even for your scale you have available.",
            "Is a specific kind of measuring if they show up on the right side and it's pod or write code there showing up there some dependencies between evidently in, but you could get a little more together inside a person might be found in interest for the assignment is.",
            "Yeah of course yeah, but of course summaries should not contain all the information, rather we should regard disregard some information.",
            "Maybe I missed that, how do you normalize that?",
            "They can do 01.",
            "So according to the database entries, one area of the chromosome in one patient either has a mutation or does not have an imitation, so it's a natural 01 distinction, so it's like presence or absence of imitation.",
            "Yeah, there are you there or.",
            "So yeah, it's going to.",
            "You mentioned that at the end there were 100 different types of mutation.",
            "This was essentially independent women in Italy for the different chromosomes.",
            "Yeah, yeah, yeah.",
            "So actually like to back up this.",
            "This choice of modeling one chromosome at a time.",
            "We actually took a look like whether they will be like Co mutation between the chromosome and there was so little in this particular database so that we basically ignored.",
            "Chose to ignore the problem.",
            "Is there?",
            "Did you look to see if the.",
            "Things that you'd found by the posturing match some known cancer types.",
            "Or was there?",
            "Yeah, yeah, actually this is also what I like ignored in this talk.",
            "Time constraints, but you could argue that are these rubbish or do they have a meaning and we have one external data set so called fragile sites that are like like known areas of the general that are likely to break, like easier breakpoints.",
            "And then we map these into the.",
            "Our descriptions and then we do some hypothesis testing and it was like seeing it significantly more likely that the endpoint would break than than any other point, or like like inside of the pattern.",
            "Yeah, so we had like external data set and we reflected like that.",
            "Cancel those breakpoints.",
            "Yeah yeah.",
            "OK in like the full paper like we're doing Journal paper.",
            "Of course we made it like huge listing of different patterns that we identified and then types of 8080 or 9090 cancer.",
            "So it's like a huge compilation.",
            "One more question.",
            "Probably assume that their locations on chromosome are independent.",
            "This is true.",
            "That is 1 location.",
            "There's one little little independence and explication.",
            "No mutations are likely to occur over ranges of this this.",
            "Location.",
            "Mutations can be large, so with regard to mutations, our like data resolution is quite nice, so they're like small small chunks within the patient.",
            "Anymore questions.",
            "Great Netflix.",
            "Thanks speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thanks for the introduction.",
                    "label": 0
                },
                {
                    "sent": "So it's nice to be one of the early speakers in the conference, because regardless of the contents of the talks, then people tend to be awake.",
                    "label": 0
                },
                {
                    "sent": "And so my talk is basically divided in three parts.",
                    "label": 0
                },
                {
                    "sent": "So first I will talk about the problem we have in cancer genetics.",
                    "label": 0
                },
                {
                    "sent": "Little, but a little bit about their data and their conception of the language used to describe their data.",
                    "label": 0
                },
                {
                    "sent": "Then the middle part about our modeling efforts with the finite mixture models of multivariate Bernoulli distributions and then in the end I will.",
                    "label": 0
                },
                {
                    "sent": "I will show how to make this probabilistic models compact.",
                    "label": 1
                },
                {
                    "sent": "And understandable for for our collaborators to use in their their work.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Little bit background on the problem first so so I should acknowledge the collaboration with Zachary Crudele and someone will look on us at the University of Helsinki.",
                    "label": 0
                },
                {
                    "sent": "They are cancer genetests and they are interested in that DNA copy number amplification.",
                    "label": 0
                },
                {
                    "sent": "Or Simply put put mutations in the DNA structures and that has like a known role in the development of cancer and that's that's why they're interested to investigate that.",
                    "label": 0
                },
                {
                    "sent": "And they actually made a huge.",
                    "label": 0
                },
                {
                    "sent": "Complete compilation of literature covering 808 hundred Journal articles covering the duration of 10 years and they actually read through these articles by hand, so no text mining involved and then compiled a database of these chromosomal mutations that has about 4500 cancer patients.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recorded so this would be a typical example that they go through text and using their professional knowledge they pick up some parts.",
                    "label": 0
                },
                {
                    "sent": "These actually like the notations used used in the literature to denote chromosomal area.",
                    "label": 0
                },
                {
                    "sent": "So physical locations in the general.",
                    "label": 0
                },
                {
                    "sent": "There's also background article about the data set and and the collection of it.",
                    "label": 0
                },
                {
                    "sent": "And if somebody is interested to work with this data set time, I'm willing to share it with you.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a little bit about the naming scheme used used in this context, so there's a standardized naming scheme or nomenklatura to address like areas in the general like one picture is on the right side, there's chromosome one that we will use as an as an example.",
                    "label": 0
                },
                {
                    "sent": "Throughout this talk there are PR, man, QR, miracle moment.",
                    "label": 0
                },
                {
                    "sent": "Then they are divided into like regions and subregions.",
                    "label": 0
                },
                {
                    "sent": "In in some hierarchical and irregular manner, for instance, if we have the area one, P, 36.2, then it would mean from us on one arm, P, region 36, and sub region 2, and then we can say see some kind of like a range is also also with a similar kind of notation.",
                    "label": 0
                },
                {
                    "sent": "But for our purposes.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we took this this database and we transform it to a 01 database.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "The rows are now now cancer patients.",
                    "label": 0
                },
                {
                    "sent": "So one row describes the data of 1 cancer patients and then we have the spatial coordinates here on the X axis.",
                    "label": 0
                },
                {
                    "sent": "So they denote like some course chromosomal areas and then we record either zeros or ones whether there is a mutation or is not a mutation in that particular location.",
                    "label": 0
                },
                {
                    "sent": "So this is the modeling problem.",
                    "label": 0
                },
                {
                    "sent": "So can we identify some kind of structure in this data?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We set out to solve this problem by realizing that cancer is actually like a collection of disease, so it's not not one particular disease or well defined disease.",
                    "label": 0
                },
                {
                    "sent": "It's like a heterogeneous mass of different kinds of diseases, so then we opted to go with a model that would have some kind of like a clustering capability and we chose to work in the probabilistic context an used finite mixture.",
                    "label": 0
                },
                {
                    "sent": "Models of multivariate kernel distributions.",
                    "label": 0
                },
                {
                    "sent": "So in the left part of the equation there's a.",
                    "label": 0
                },
                {
                    "sent": "Are the standard formulation for, or finite mixture models in general, so we are interested in modeling a probability distribution PX and we model it in terms of J component distributions, parametrised by by some theater JS and then we wait them together or mix them together, gather, perform the probability distribution and then on the right side there's like with the specific choice of like 01 data.",
                    "label": 0
                },
                {
                    "sent": "Then we need a multivariate bernouilli distribution as as the component distribution and there the para meters to be estimated.",
                    "label": 0
                },
                {
                    "sent": "Our Theater, J eyes and Jays now index the component distributions.",
                    "label": 0
                },
                {
                    "sent": "An eyes index the data dimension, so it's like an array or matrix of para meters in that sense.",
                    "label": 0
                },
                {
                    "sent": "And what this para meters tell is the probability of some random variable taking the value one.",
                    "label": 0
                },
                {
                    "sent": "So we can readily estimate this model in the framework of maximum likelihood using the email gharib them.",
                    "label": 0
                },
                {
                    "sent": "This is more or less textbook.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Soft so I'm not going to touch it here.",
                    "label": 0
                },
                {
                    "sent": "But what is a central problem in in this context?",
                    "label": 0
                },
                {
                    "sent": "Is the model selection, So what kind of resolution do we need in the model?",
                    "label": 0
                },
                {
                    "sent": "So more specifically, how many components do we need in this mixture model?",
                    "label": 0
                },
                {
                    "sent": "And we use the like a data resampling approach.",
                    "label": 0
                },
                {
                    "sent": "We used five fold cross validation approach.",
                    "label": 0
                },
                {
                    "sent": "To train different models and then we repeated this exercise 10 times.",
                    "label": 0
                },
                {
                    "sent": "So we have 50 trainings.",
                    "label": 0
                },
                {
                    "sent": "Of models and then we can estimate the training likelihood seen as the upper curve for different models of different complexity and then validation.",
                    "label": 0
                },
                {
                    "sent": "Likelihood and then as some kind of like hopefully like good approximation of the generalization abilities, we picked the.",
                    "label": 0
                },
                {
                    "sent": "The model with the maximum validation likelihood.",
                    "label": 1
                },
                {
                    "sent": "And so we have the choice of J is equal to six.",
                    "label": 0
                },
                {
                    "sent": "In this example chromosome one.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the model.",
                    "label": 0
                },
                {
                    "sent": "We then, then we have fixed fixed the model complexity.",
                    "label": 0
                },
                {
                    "sent": "Then we take all of the data and this is our final model.",
                    "label": 0
                },
                {
                    "sent": "So this should somehow summarize the mutation patterns or DNA copy number amplification patterns will come as one.",
                    "label": 0
                },
                {
                    "sent": "And we have provided visualization of the parimeter so large.",
                    "label": 0
                },
                {
                    "sent": "Para meters are noted in dark.",
                    "label": 0
                },
                {
                    "sent": "So now we have the six mixture components as rows of this matrix.",
                    "label": 0
                },
                {
                    "sent": "So we can see that there are like very strong spatial dependencies as these mutations are likely to happen over like many many regions in our resolution.",
                    "label": 0
                },
                {
                    "sent": "Resolution and we'll see that the cluster data data in the next slide.",
                    "label": 0
                },
                {
                    "sent": "But now it's important to realize that this model is summarized by a large array of probability values.",
                    "label": 0
                },
                {
                    "sent": "So we have about 200 para meters like probability values, and this is our model.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can use this this model in like a clustering mode so we can associate data into the clusters by through the like Bayes rule or by associating with posterior probabilities.",
                    "label": 0
                },
                {
                    "sent": "And now we have taken the original data that we saw earlier than we have partitioned the data into six clusters or clusters are separated by grey horizontal lines in this figure, so it's just the row permutation of the data data earlier and this.",
                    "label": 0
                },
                {
                    "sent": "Like gives kinda like a nice picture so that maybe maybe we have identified relevant structure so there are different types of mutation patterns found in each of the clusters.",
                    "label": 0
                },
                {
                    "sent": "Clusters, and so we have like.",
                    "label": 0
                },
                {
                    "sent": "We rely on the model.",
                    "label": 0
                },
                {
                    "sent": "I think we have done.",
                    "label": 0
                },
                {
                    "sent": "Good job.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then then kind of like a paradox in this work is that the solution created this problem, so the model is very nice, but we created some kind of like communications problems because we would be very unfriendly to our collaborators if we just sent like a stack of 200 para meters and wish them a nice rest of the day.",
                    "label": 0
                },
                {
                    "sent": "We cannot do that.",
                    "label": 0
                },
                {
                    "sent": "The models would be like really useless.",
                    "label": 0
                },
                {
                    "sent": "So now we come to the effort.",
                    "label": 0
                },
                {
                    "sent": "So we should make the model somehow understandable to the console.",
                    "label": 0
                },
                {
                    "sent": "Experts and it would be very nice if they could like refer.",
                    "label": 0
                },
                {
                    "sent": "They could report it and their colleagues could refer to the results.",
                    "label": 0
                },
                {
                    "sent": "So we should come up with some kind of names just like we have names.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we revisit the title so the compact and understable standable descriptions.",
                    "label": 1
                },
                {
                    "sent": "And by understand ability, we mean that we should somehow like turn the results into the language that the cancer genetests are using.",
                    "label": 0
                },
                {
                    "sent": "And we had the standard nomenclatural, so that's a natural choice and also compact.",
                    "label": 0
                },
                {
                    "sent": "They should be somehow not like a page long listing, but but somehow like a like a short name for some phenomenon, some mutation phenomenon that this happened, and we have basically two ways of doing that.",
                    "label": 0
                },
                {
                    "sent": "First, like a direct approach through describing the parameters of the model.",
                    "label": 0
                },
                {
                    "sent": "There's two ways I will describe from the next slide, or then we can use the clustering capability cluster the data 1st and then describe like the marginal distributions of the data in the clusters.",
                    "label": 0
                },
                {
                    "sent": "But first.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see how we can do with the model parameters.",
                    "label": 1
                },
                {
                    "sent": "So one like very, very compact way of summarizing one of these component distributions in a mixture model is to give the mode of the component distribution.",
                    "label": 0
                },
                {
                    "sent": "So that's the most probable chromosomal area to have a mutation that's just one one area, but in some cases it gives a biased view view of the whole component distribution as.",
                    "label": 0
                },
                {
                    "sent": "As we will see in the results.",
                    "label": 1
                },
                {
                    "sent": "The other way actually borrowed from back there.",
                    "label": 0
                },
                {
                    "sent": "Aladji is so-called hypothetical mean Organism where we do like quantization of the para meters.",
                    "label": 0
                },
                {
                    "sent": "So wherever a para meters above 1/2, then we give a one, and when it's below 1/2 then we give a 0.",
                    "label": 0
                },
                {
                    "sent": "Then the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second approach is to cluster the data 1st and then described the marginal distributions of the clusters.",
                    "label": 1
                },
                {
                    "sent": "Of course you can do this in many many ways, and now we have chosen to use frequent itemsets in this, and more specifically maximal frequent itemsets and then you have.",
                    "label": 0
                },
                {
                    "sent": "You could ask that why maximal OK?",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "Secondly, and more importantly extracting frequent itemsets are not feasible, since they are very like long areas or ones, so that there would be so many many of them.",
                    "label": 0
                },
                {
                    "sent": "It's not just not computationally feasible.",
                    "label": 1
                },
                {
                    "sent": "But we want to describe the largest representative commonalities in the data and we are not really interested in all the millions of subsets of those.",
                    "label": 0
                },
                {
                    "sent": "And then we once we have this frequent item representation, then we can.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Express these as some kind of like ranges of documentations.",
                    "label": 1
                },
                {
                    "sent": "So this is the result table from the paper, so we have the hypothetical mean Organism on the left for all of their six component distribution in the middle.",
                    "label": 0
                },
                {
                    "sent": "The mode we actually don't want to give the mode where it gives a biased view for component distributions with very low probabilities or with very large areas of constant probabilities and on the right column there is this description based on the item sets and there we give them.",
                    "label": 0
                },
                {
                    "sent": "Ranges.",
                    "label": 0
                },
                {
                    "sent": "Then we also tried as a reference.",
                    "label": 0
                },
                {
                    "sent": "We tried to extract frequent itemsets from the day, the globally and there we have only like a couple of results, and they're a little bit like spirits.",
                    "label": 0
                },
                {
                    "sent": "Curious, they don't actually relate to the real findings, but they're like sums, sums of different mechanisms found found in this situation.",
                    "label": 0
                },
                {
                    "sent": "Patterns also like shadowing that big things like cover small things under them.",
                    "label": 0
                },
                {
                    "sent": "Since we are analyzing the margins of.",
                    "label": 1
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whole data set.",
                    "label": 0
                },
                {
                    "sent": "So this is actually the summary of our work, so we actually now I present this.",
                    "label": 0
                },
                {
                    "sent": "This area of the red box, and so the chromosome one.",
                    "label": 0
                },
                {
                    "sent": "In the talk, but also we worked with all the other chromosomes 1 to 22 + X.",
                    "label": 0
                },
                {
                    "sent": "Why was omitted?",
                    "label": 0
                },
                {
                    "sent": "Because there was no data and then, like with this proposed approach now on the right side, there are around 100 like mutation patterns that we're about publish publish an since they are like expressed in this language, they can be like nicely used as.",
                    "label": 0
                },
                {
                    "sent": "In the work of cancer genetics.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "Then to summarize, so we were interested in analyzing the DNA copy number caitians for mutations in cancer, and we showed how our collaborators had compiled a database of these mutations actually by hand, not using any of the text mining fancy stuff, and then we transform this database into a 01 database, did some mixture modeling, and then realized that they are really hard to.",
                    "label": 0
                },
                {
                    "sent": "Get across so we had to do some kind of model summarization and we propose two ways taking the parimeter, summarizing them or using the model as a clustering model and then describing the cluster data instead.",
                    "label": 0
                },
                {
                    "sent": "And there we used maximum frequent itemsets, although you could use many many methods for that.",
                    "label": 0
                },
                {
                    "sent": "And as a like a net result, I think this collection of DNA copy number applications can be can be seen or forms of new basis for cancer classification.",
                    "label": 0
                },
                {
                    "sent": "And that's like from this copy number amplification pointed here.",
                    "label": 0
                },
                {
                    "sent": "So this concludes my talk.",
                    "label": 0
                },
                {
                    "sent": "I'm certain.",
                    "label": 0
                },
                {
                    "sent": "That you're doing it for my question is doing it.",
                    "label": 0
                },
                {
                    "sent": "Are you considering the variances within classes to inconvenience in their Class 2?",
                    "label": 0
                },
                {
                    "sent": "Is window an attribute?",
                    "label": 0
                },
                {
                    "sent": "Well, when we extract the frequent itemsets, then then they actually like they are like summarization of the spatially strongly dependent components.",
                    "label": 0
                },
                {
                    "sent": "So in a way, yes, yes there's no like.",
                    "label": 0
                },
                {
                    "sent": "Full variance here, but spatially dependent areas or other summaries basically.",
                    "label": 0
                },
                {
                    "sent": "Recipes for, but they don't give you in general cases the full information which is available even for your scale you have available.",
                    "label": 0
                },
                {
                    "sent": "Is a specific kind of measuring if they show up on the right side and it's pod or write code there showing up there some dependencies between evidently in, but you could get a little more together inside a person might be found in interest for the assignment is.",
                    "label": 0
                },
                {
                    "sent": "Yeah of course yeah, but of course summaries should not contain all the information, rather we should regard disregard some information.",
                    "label": 0
                },
                {
                    "sent": "Maybe I missed that, how do you normalize that?",
                    "label": 0
                },
                {
                    "sent": "They can do 01.",
                    "label": 0
                },
                {
                    "sent": "So according to the database entries, one area of the chromosome in one patient either has a mutation or does not have an imitation, so it's a natural 01 distinction, so it's like presence or absence of imitation.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there are you there or.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it's going to.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that at the end there were 100 different types of mutation.",
                    "label": 0
                },
                {
                    "sent": "This was essentially independent women in Italy for the different chromosomes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So actually like to back up this.",
                    "label": 0
                },
                {
                    "sent": "This choice of modeling one chromosome at a time.",
                    "label": 0
                },
                {
                    "sent": "We actually took a look like whether they will be like Co mutation between the chromosome and there was so little in this particular database so that we basically ignored.",
                    "label": 0
                },
                {
                    "sent": "Chose to ignore the problem.",
                    "label": 0
                },
                {
                    "sent": "Is there?",
                    "label": 0
                },
                {
                    "sent": "Did you look to see if the.",
                    "label": 0
                },
                {
                    "sent": "Things that you'd found by the posturing match some known cancer types.",
                    "label": 0
                },
                {
                    "sent": "Or was there?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, actually this is also what I like ignored in this talk.",
                    "label": 0
                },
                {
                    "sent": "Time constraints, but you could argue that are these rubbish or do they have a meaning and we have one external data set so called fragile sites that are like like known areas of the general that are likely to break, like easier breakpoints.",
                    "label": 0
                },
                {
                    "sent": "And then we map these into the.",
                    "label": 0
                },
                {
                    "sent": "Our descriptions and then we do some hypothesis testing and it was like seeing it significantly more likely that the endpoint would break than than any other point, or like like inside of the pattern.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we had like external data set and we reflected like that.",
                    "label": 0
                },
                {
                    "sent": "Cancel those breakpoints.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "OK in like the full paper like we're doing Journal paper.",
                    "label": 0
                },
                {
                    "sent": "Of course we made it like huge listing of different patterns that we identified and then types of 8080 or 9090 cancer.",
                    "label": 0
                },
                {
                    "sent": "So it's like a huge compilation.",
                    "label": 0
                },
                {
                    "sent": "One more question.",
                    "label": 0
                },
                {
                    "sent": "Probably assume that their locations on chromosome are independent.",
                    "label": 0
                },
                {
                    "sent": "This is true.",
                    "label": 0
                },
                {
                    "sent": "That is 1 location.",
                    "label": 0
                },
                {
                    "sent": "There's one little little independence and explication.",
                    "label": 0
                },
                {
                    "sent": "No mutations are likely to occur over ranges of this this.",
                    "label": 0
                },
                {
                    "sent": "Location.",
                    "label": 0
                },
                {
                    "sent": "Mutations can be large, so with regard to mutations, our like data resolution is quite nice, so they're like small small chunks within the patient.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "Great Netflix.",
                    "label": 0
                },
                {
                    "sent": "Thanks speaker again.",
                    "label": 0
                }
            ]
        }
    }
}