{
    "id": "6jvcphcvttuuyrjztraqy5l7rgrgse5k",
    "title": "PAC-Bayesian Learning of Linear Classifiers",
    "info": {
        "author": [
            "Mario Marchand, D\u00e9partement d'informatique et de g\u00e9nie logiciel, Universit\u00e9 Laval"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Linear Models",
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_marchand_pbll/",
    "segmentation": [
        [
            "OK, so thank you so this is joint work with Pascal, Chame, Alexander cows, Francois Laviolette, all from Laval University.",
            "So it's a talk about the famous classification problem, and for the classification problem task of the learner."
        ],
        [
            "To find a classifier with the smallest possible risk, so the risk of a classifier is just sometimes called the generalization error.",
            "It's the probability to make a mistake on a randomly drawn example.",
            "So the problem is that we cannot find this because basically we don't know what is the data."
        ],
        [
            "Generating distribution, so all we we."
        ],
        [
            "Obvious access to some training data where each example is generated according to that."
        ],
        [
            "Distribution D. So basically the fundamental question is what a learning algorithm should optimize on the training data in order to obtain a classifier with the smallest possible risk."
        ],
        [
            "Several objective function to minimize on the training data have been proposed somewhat in an adult matter.",
            "The soft margin, SVM, Adaboost, Ridge regression, logistic regression and so on.",
            "So several optimizing object sufficient to optimize."
        ],
        [
            "As had been proposed, but the rigorous guarantee always comes a posteriori viewer risk bound, so risk bound is something that its name says that it's uniformly bounced.",
            "The risk of our classifier in some class."
        ],
        [
            "So why not try then to optimize the guarantee?",
            "If this is the accepted guarantee for everybody, so why not directly optimize the guarantee?",
            "So let's try to design efficient algorithm to minimize tight risk bound an this talk is going to be about minimizing the PAC Bayes bound which are known to be quite tight and you will see we have obtained quite tight bound results here.",
            "So the plan of the talk is basically to."
        ],
        [
            "I sent a simple and general theorem from which we can derive all known pacbase bound."
        ],
        [
            "Quite simply, we will specialize to linear classifier for to compare to state of the art algorithm basically so we will perform gradient descent learning out."
        ],
        [
            "That minimizes the PAC Bayes bounds, so this is our going to minimize the pack."
        ],
        [
            "Just bounce and we're going to present extensive numerical result where we compare these bound minimizing algorithm to Adaboost ND SVM.",
            "So this is basically the plan of the talk, so let's start with some simplified backbase Pack Bayesian theory, so recall."
        ],
        [
            "But you know the true risk of the classifier is just the probability that it makes a mistake on a randomly drawn example.",
            "So we don't have access to that.",
            "In fact, we want to find bounds for these quantities based on what we can measure on the training data, and this is what we can measure on the training data.",
            "It's the empirical risk.",
            "So here I'm going to talk."
        ],
        [
            "About learning algorithms that does not return a single classifier, but basically a distribution on the space of classifier that I will call the posterior distribution.",
            "Because you can examine the data to find the posterior distribution that Secutor post an our predictor is going to be a weighted majority vote on this posterior, so this will be our predictor, but the PAC Bayes bound does not does not provide about."
        ],
        [
            "Under risk of the majority vote directly provides abound via stochastic classifier that we call the Gibbs classifier and the Gibbs classifier is just basically the following.",
            "So if you want to predict the label of an example X with with the Gibbs classifier basically just draw classifier according to Q and then predict the label of X with this with this pick classifier with this chosen classifier.",
            "So it follows that."
        ],
        [
            "Basically, the risk of the Gibbs classifier, which is what the PAC Bayes bound is going to bound.",
            "So the risk of the Gibbs classifier is just the expected risk of single classifier expectation performance.",
            "Of course, according to the distribution Q and the same thing for the empirical risk.",
            "So there is OK, so we're going basically the bound on."
        ],
        [
            "The risk of the Gibbs classifier will also provide indirectly abound on the base classifier, and this is the usual factor of two ruled that that basically relates both risk.",
            "Basically, the risk of the majority to classifier is almost twice the risk of the gifts class classifier, so providing an upper bound on this also provides an upper bound on our predictor.",
            "So why is this?",
            "Well, basically the worst case.",
            "Since when all the distribution is concentrated on the single example, so whenever the majority vote makes an error on that single example, this means that at least half of the classifiers are making an error on that example, and it could be, let's say 1/2 plus epsilon that are making an error.",
            "In that case, the risk of the Gibbs risk of the majority vote is 1, but the risk of the Gibbs classifier is just one half plus epsilon.",
            "Hence the factor of two data that is presented about so."
        ],
        [
            "The PAC Bayes bound basically needs a prior distribution on H, so we're going to the learning algorithm output the posterior distribution, but the bound really depend on how close is the posterior from a prior distribution that needs to be provided before observing the data, and basically the bounce provide the bounds depends on the trip back library divergance between the posterior and the prior.",
            "We're also going to make use of the Cal Dive."
        ],
        [
            "Distance between two Bernoulli distribution, one with probability of success P and the other with probability."
        ],
        [
            "Success Q and it turns out that it's just the binary cross entropy function."
        ],
        [
            "So OK, so this is our simplified, let's say general.",
            "Mother bound for all pacbase bound.",
            "Basically it is stated in terms of a general convex function that you can use to measure the descriptor discrepancy between the true risk and the empirical risk.",
            "So it's measured via this arbitrary convex function D and with high probability this distance between the empirical risk and the true risk is bounded by this quantity.",
            "So you need to perform this expectation in order to get the bound an we usually cannot perform this expectation if the expectation is.",
            "If the prior is dependent on S, this is very difficult to perform because we never know what is.",
            "What is the true risk OK, given an empirical risk so we can perform this expectation if the prior is is S independent, so you can switch these expectation and then you can perform the expectation over the sample before, because once the classifier's fix the true risk is fixed and then we know what is the distribution of training error.",
            "So this is how you get basically all other PAC Bayes bound.",
            "You choose a function D and you perform this expectation.",
            "So if you choose the binary cross entropy for the function D you can image."
        ],
        [
            "We performed this expectation.",
            "You can switch these expectation if P is independent of this and you find out this formula which is something in big Pete of square root of.",
            "So this gives you in the bound a big Tito Squ."
        ],
        [
            "Root or famine, you just change the bike.",
            "The smaller the binary cross entropy.",
            "So this is about that has been found by the first one that has been found is is magical cigar in his famous JMLR 2002 paper.",
            "It was later also used by Langford and it's quite a tight tight bound but you can OK so there's a graphic illustration of this bound.",
            "So suppose that the empirical risk is.",
            "10% and let's say this is kind of small.",
            "Let's say that the right hand side term."
        ],
        [
            "Is 6% so the bound is saying that well, if this is the empirical risk, well, the true risk will lie with probability 1 minus Delta between this upper bound in the lower bound.",
            "So this is basically how it works if you."
        ],
        [
            "Choose another function, let's say and if you're looking for a function with which depends linearly on the empirical risk an you don't know what this will be.",
            "Well, you just can plug."
        ],
        [
            "This into the expectation and you find abound that apparently was found in dependently before us by Catonian 2007.",
            "So without you respect we will call it the catoni bound.",
            "So this is what you find is it is so you see you have you have an undefined parameter.",
            "The bound is valid for any see, but it does not all uniformly for all see.",
            "So for any see the risk of the Gibbs classifier is.",
            "Bounded by this expression and what's nice about this bound is that, well, if you're looking for the Gibbs classifier that minimize the bound, all you need to minimize this simple expression inside the argument.",
            "So basically this gives this optimization, well, huge."
        ],
        [
            "Just minimize the sum of the empirical risk and some regularizer, let's call it the pack Bayesian regularizer.",
            "Without this, is always that we find so basic."
        ],
        [
            "Really, the only thing is that the bound depends on this constant C well, which is plays the same role as the CNS VM.",
            "And so it has an iPod you have and hyperparameter to tune basically."
        ],
        [
            "So this is in contrast with the Langford Seeger bound, where basically you know you have no parimeter things, so we will make use of these two bounds because most of the time, in fact it's the Langford Seeger bound, the one with the binary cross entropy entropy, which is tighter.",
            "But sometimes the Tony bound can be tighter because basically you don't have the Sigma of em function, just have one there so the cattle need bound.",
            "Sometimes can be, it can be tighter and it gives a simple optimization problem, so this is quite interesting.",
            "So we of course tried to optimize this.",
            "Why not try to find Gibbs classifier that minimizes this, so we apply."
        ],
        [
            "This 2 two linear classifier.",
            "So each example is mapped into a feature space, A set of features which can be give."
        ],
        [
            "Implicitly we are Mr.",
            "Colonel, so this is the usual.",
            "So basically this is the output given by."
        ],
        [
            "Linear classifier V with linear with weight vector V an.",
            "As I told you, we're going to construct posterior."
        ],
        [
            "On this set of classifiers and we're going to discuss here isotropic Gaussian posterior.",
            "So basically all our posterior are going to be like that, so these are isotropic, Gaussian centered on some weight vector W. OK, so basically our task is then to find to find a waiter W that will minimize the pack baseband.",
            "So we're so this where we are.",
            "So basically this is the task of the learner to find the weight vector W that minimizes the PAC Bayes bound.",
            "So 11 nice property of these isotropic Gaussian is that by symmetry, basically the output of the weighted majority vote."
        ],
        [
            "Which is, our predictor is basically the same as the output of the linear classifier with weight vector W. They are basically the same, the same classifier.",
            "So basically the pacbase bound will also upper upper bound this."
        ],
        [
            "Die here, the risk of this of this guy here so.",
            "OK, so so OK, so we want to compute the PAC Bayes bound on the training data and minimize it.",
            "So you need to compute the KL divergences between the posterior and the prior.",
            "So what will we choose?"
        ],
        [
            "Who's for the prior?",
            "Well, we're going to choose the prior in the same set that we're going to use the posterior, but it must be defined apriori.",
            "So basically the prior is also an easy topic Gaussian but centered somewhere else, some some weight vector WP, and so by performing Gaussians integral you find you find this.",
            "So we need so the, uh."
        ],
        [
            "Everything we need to compute it.",
            "It's Gibson pickle risk.",
            "We need to compute this guys because this is the other quantity that enters the bound.",
            "So we need to compute gives empirical risk on the single example, so we need to perform this Gaussian integral, which is just the probability of making a mistake.",
            "So basically we're still using the 01 loss as.",
            "As mentioned here by this indicator function, but it is the average of 01 loss, so this will give you some sort of a function which will not be the 01 loss in terms of W, so this will induce an effective loss for W."
        ],
        [
            "Basically.",
            "So it's just a matter of doing this Gaussian integral an you find basically that it is a cumulative Gaussian of the normalized margins.",
            "So if this is.",
            "Weight vector W and this is my example."
        ],
        [
            "Wife hired ex.",
            "So basically it depends on the cosine of that angle times the Euclidean norm.",
            "So you multiply that by the actions in normal W. So basically so this function as the following form in terms of the normalized margin.",
            "So and it's easy to understand that just put your Gaussian, try your posterior here.",
            "So basically I'll do this as positive margin.",
            "It is classified correctly.",
            "This example is classified correctly by this linear classifier, but as it's.",
            "Fluctuated as the probability of making a misclassification error, so you will have a curve like that when they are both orthogonal.",
            "Basically the probability is 1/2.",
            "So all curves pass to these to this place here and so on an as the norm of W increases very large very largely, so remember that the Valiants here is fixed to one.",
            "Basically the standard deviation is 1.",
            "So as you increase your weight vector.",
            "It becomes more your classifier becomes more and more deterministic and so you converge to this 01 last step function OK, so these are the 2 two quantities that enter into the bound.",
            "So the Langford Seeger bound."
        ],
        [
            "Is this so you need to solve so that?"
        ],
        [
            "Maximum value of epsilon is realized equality.",
            "Basically this gives You Tube solution, an upper bound and lower bound.",
            "So to find the upper bound you need to solve this equation, so OK."
        ],
        [
            "So for the Catoni bound, the situation is simpler.",
            "This is just about you need to minimize the bond.",
            "You need to minimize this expression, and so this expression is.",
            "So we just computed these guys and these guys.",
            "So what you just fill in the express?"
        ],
        [
            "So it's nice to compare this with the objective function that the SVM is minimizing, so this is an SVM.",
            "It minimizes this.",
            "This is the regularizer DL2 norm plus the engine loss we find exactly the same thing when our prior is noninformative.",
            "So if you put zero here you see you have the same expression except that the convex injure lost here is replaced by the nonconvex sigmoid loss so.",
            "Basically, at the SVM is just a convex relaxation of what you should do of what PAC Bayes is tells you that what."
        ],
        [
            "We should do OK, so this is an alternative explanation of the SVM.",
            "So we have performed gradient descent.",
            "So the nice thing about gradient descent is that you only need to know the gradient.",
            "So this is the gradient of the Langford."
        ],
        [
            "Seeger, bound.",
            "You can compute it explicitly."
        ],
        [
            "This is the gradient of the catoni bound."
        ],
        [
            "And so basically we're performing."
        ],
        [
            "Gradient descent so OK so."
        ],
        [
            "There is this question is why does we use?",
            "Do we use simple gradient descent?",
            "After all, the probit loss is not a convex function, but it's cause I can't."
        ],
        [
            "Fix, but the problem is that we don't have a single."
        ],
        [
            "Of course I can fix to minimize we have a sum.",
            "Of course, I confessed to minimizing quasiconvex.",
            "Stated is not additive.",
            "I mean if you sum quasiconvex function, the summation is not guaranteed to be quasiconvex an in fact.",
            "So this means that Gibbs empirical risk is not quasiconvex, it has local."
        ],
        [
            "Minimal and it can have several local minima anwen in the cartoony bouncy is large.",
            "We do see a lot of local minima so this."
        ],
        [
            "The problem of the."
        ],
        [
            "So this means that we need to supply it with some Ristic.",
            "Here we have just use random starting random start myristic so."
        ],
        [
            "OK, so the proposed algorithm are used both in the primal an individual so to go to the jewel you just performed.",
            "This expense, linear expansion in terms of the example."
        ],
        [
            "We have used this agent stamps to compare to Adaboost for primal version version an for that."
        ],
        [
            "Full version basically we use kernels, the RBF cur."
        ],
        [
            "And so we provide tree algo hits.",
            "So PAC Bayes gradient descent one just minimizes the lengths."
        ],
        [
            "Seeger, bound with an uninformative prior, so that is easy to do this gradient descent tree does the same thing, but with the catoni bound for different values of C that have been chosen by cross validation.",
            "So you cheat.",
            "Here you say these are the quantities that I should use, but the right proportion I'm going to settle for cross validation instead of using bound values, because it would more let's do the same thing here."
        ],
        [
            "So PAC Bayes gradient descent, two basically, so this is a true bound minimizing algorithm.",
            "This is not quite this one is."
        ],
        [
            "Also, a true about minimizing algorithm where basically you use part of your data to learn a good prior.",
            "So basically we minimize the catoni bound by fixing some arbitrary values of C. This gives us several posterior that we use as priors too.",
            "To learn the second half of the data so this."
        ],
        [
            "Suspect based gradient descent 2.",
            "OK, so let us come."
        ],
        [
            "Go straight ahead to the result in the.",
            "In the in the primal version, basically we see that perhaps not clearly.",
            "But yeah, the bowl."
        ],
        [
            "I'm not quite clear, but the overall winner is packed based gradient descent tree, so so the true bound minimizing algorithm turns out to be not as good as as the one where you choose.",
            "See by cross validation, but back based gradient descent two improves or improves over pack based gradient descent.",
            "One meaning that yes, it is often advantages to learn the prior tree.",
            "An Adaboost are quite competitive, the overall winner seems to be.",
            "To be PGD 3 but Abu scissor close."
        ],
        [
            "So these are the result in basically for individual.",
            "So where we compare to SVM the RBF kernel.",
            "So again PBG tree is quite competitive with VM, but the difference is turns out to be non non significant but most of the time it is slightly better than the SVM.",
            "This one is slightly inferior."
        ],
        [
            "So basically the bottom line that yes, using F of the."
        ],
        [
            "So basically, to learn a prior helps because the second version of the bound minimizing algorithm is better."
        ],
        [
            "And the first one.",
            "But it is still better to find the right proportion of empirical risk.",
            "An regularizer by cross validation, PGD trees a bit better than PGD."
        ],
        [
            "So the bound is not quantitatively as good as we would like to be.",
            "The two have so basically PGD tree is a good contender with Adaboost and SV."
        ],
        [
            "And it seems to be a slight better, but it is much slow."
        ],
        [
            "Or because we have to do all this random restarts.",
            "So if you do care about."
        ],
        [
            "About obtaining a good guarantee.",
            "Basically PGD 2 is the best one because we did obtain good pound value.",
            "I didn't show you, but sometimes the bound is let's say or like on the 1% scale.",
            "So OK, thank you for attention."
        ],
        [
            "Yes.",
            "Yep, Yep.",
            "Yeah, VR union bond argument for instance.",
            "It gives the same result as just minimizing the Langford Seeger bound if you do it for several C. Basically it's just like minimizing the other bound.",
            "Well, experimentally that.",
            "So that's yeah.",
            "An you can show basically that finding the optimal value of C4 bound.",
            "If you get rid of the Sigma of em gives you the KL divergent.",
            "Yes, you try to to find the the the the minimum place the we did it and it's it gives you the KL meaning that some somehow the binary cross entropy is.",
            "An ideal choice for the.",
            "It seems like the.",
            "It's a computation.",
            "They give good results, but it takes time.",
            "So have you thought about trying starts?",
            "Online versions of the algorithm would be much faster if you could optimize this online.",
            "Maybe that was it.",
            "I have not talked about online.",
            "I tried to find something better than gradient descent.",
            "I was not really able to find something better.",
            "Our first thing that we wanted to do is to see if it looks promising.",
            "It looks promising, so perhaps it's worthwhile to invest more effort, but there.",
            "With several local minima, I think it's, but it's a good suggestion to look for an online version, yes?",
            "There's a very.",
            "My mother.",
            "How?",
            "But we didn't make any.",
            "That's all."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so thank you so this is joint work with Pascal, Chame, Alexander cows, Francois Laviolette, all from Laval University.",
                    "label": 0
                },
                {
                    "sent": "So it's a talk about the famous classification problem, and for the classification problem task of the learner.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To find a classifier with the smallest possible risk, so the risk of a classifier is just sometimes called the generalization error.",
                    "label": 1
                },
                {
                    "sent": "It's the probability to make a mistake on a randomly drawn example.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that we cannot find this because basically we don't know what is the data.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generating distribution, so all we we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obvious access to some training data where each example is generated according to that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution D. So basically the fundamental question is what a learning algorithm should optimize on the training data in order to obtain a classifier with the smallest possible risk.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Several objective function to minimize on the training data have been proposed somewhat in an adult matter.",
                    "label": 1
                },
                {
                    "sent": "The soft margin, SVM, Adaboost, Ridge regression, logistic regression and so on.",
                    "label": 0
                },
                {
                    "sent": "So several optimizing object sufficient to optimize.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As had been proposed, but the rigorous guarantee always comes a posteriori viewer risk bound, so risk bound is something that its name says that it's uniformly bounced.",
                    "label": 0
                },
                {
                    "sent": "The risk of our classifier in some class.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why not try then to optimize the guarantee?",
                    "label": 0
                },
                {
                    "sent": "If this is the accepted guarantee for everybody, so why not directly optimize the guarantee?",
                    "label": 1
                },
                {
                    "sent": "So let's try to design efficient algorithm to minimize tight risk bound an this talk is going to be about minimizing the PAC Bayes bound which are known to be quite tight and you will see we have obtained quite tight bound results here.",
                    "label": 1
                },
                {
                    "sent": "So the plan of the talk is basically to.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I sent a simple and general theorem from which we can derive all known pacbase bound.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite simply, we will specialize to linear classifier for to compare to state of the art algorithm basically so we will perform gradient descent learning out.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That minimizes the PAC Bayes bounds, so this is our going to minimize the pack.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just bounce and we're going to present extensive numerical result where we compare these bound minimizing algorithm to Adaboost ND SVM.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the plan of the talk, so let's start with some simplified backbase Pack Bayesian theory, so recall.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But you know the true risk of the classifier is just the probability that it makes a mistake on a randomly drawn example.",
                    "label": 1
                },
                {
                    "sent": "So we don't have access to that.",
                    "label": 1
                },
                {
                    "sent": "In fact, we want to find bounds for these quantities based on what we can measure on the training data, and this is what we can measure on the training data.",
                    "label": 0
                },
                {
                    "sent": "It's the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "So here I'm going to talk.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About learning algorithms that does not return a single classifier, but basically a distribution on the space of classifier that I will call the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Because you can examine the data to find the posterior distribution that Secutor post an our predictor is going to be a weighted majority vote on this posterior, so this will be our predictor, but the PAC Bayes bound does not does not provide about.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under risk of the majority vote directly provides abound via stochastic classifier that we call the Gibbs classifier and the Gibbs classifier is just basically the following.",
                    "label": 1
                },
                {
                    "sent": "So if you want to predict the label of an example X with with the Gibbs classifier basically just draw classifier according to Q and then predict the label of X with this with this pick classifier with this chosen classifier.",
                    "label": 1
                },
                {
                    "sent": "So it follows that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basically, the risk of the Gibbs classifier, which is what the PAC Bayes bound is going to bound.",
                    "label": 1
                },
                {
                    "sent": "So the risk of the Gibbs classifier is just the expected risk of single classifier expectation performance.",
                    "label": 1
                },
                {
                    "sent": "Of course, according to the distribution Q and the same thing for the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "So there is OK, so we're going basically the bound on.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The risk of the Gibbs classifier will also provide indirectly abound on the base classifier, and this is the usual factor of two ruled that that basically relates both risk.",
                    "label": 0
                },
                {
                    "sent": "Basically, the risk of the majority to classifier is almost twice the risk of the gifts class classifier, so providing an upper bound on this also provides an upper bound on our predictor.",
                    "label": 1
                },
                {
                    "sent": "So why is this?",
                    "label": 0
                },
                {
                    "sent": "Well, basically the worst case.",
                    "label": 1
                },
                {
                    "sent": "Since when all the distribution is concentrated on the single example, so whenever the majority vote makes an error on that single example, this means that at least half of the classifiers are making an error on that example, and it could be, let's say 1/2 plus epsilon that are making an error.",
                    "label": 0
                },
                {
                    "sent": "In that case, the risk of the Gibbs risk of the majority vote is 1, but the risk of the Gibbs classifier is just one half plus epsilon.",
                    "label": 0
                },
                {
                    "sent": "Hence the factor of two data that is presented about so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The PAC Bayes bound basically needs a prior distribution on H, so we're going to the learning algorithm output the posterior distribution, but the bound really depend on how close is the posterior from a prior distribution that needs to be provided before observing the data, and basically the bounce provide the bounds depends on the trip back library divergance between the posterior and the prior.",
                    "label": 0
                },
                {
                    "sent": "We're also going to make use of the Cal Dive.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distance between two Bernoulli distribution, one with probability of success P and the other with probability.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Success Q and it turns out that it's just the binary cross entropy function.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so this is our simplified, let's say general.",
                    "label": 0
                },
                {
                    "sent": "Mother bound for all pacbase bound.",
                    "label": 0
                },
                {
                    "sent": "Basically it is stated in terms of a general convex function that you can use to measure the descriptor discrepancy between the true risk and the empirical risk.",
                    "label": 0
                },
                {
                    "sent": "So it's measured via this arbitrary convex function D and with high probability this distance between the empirical risk and the true risk is bounded by this quantity.",
                    "label": 0
                },
                {
                    "sent": "So you need to perform this expectation in order to get the bound an we usually cannot perform this expectation if the expectation is.",
                    "label": 0
                },
                {
                    "sent": "If the prior is dependent on S, this is very difficult to perform because we never know what is.",
                    "label": 0
                },
                {
                    "sent": "What is the true risk OK, given an empirical risk so we can perform this expectation if the prior is is S independent, so you can switch these expectation and then you can perform the expectation over the sample before, because once the classifier's fix the true risk is fixed and then we know what is the distribution of training error.",
                    "label": 0
                },
                {
                    "sent": "So this is how you get basically all other PAC Bayes bound.",
                    "label": 0
                },
                {
                    "sent": "You choose a function D and you perform this expectation.",
                    "label": 0
                },
                {
                    "sent": "So if you choose the binary cross entropy for the function D you can image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We performed this expectation.",
                    "label": 0
                },
                {
                    "sent": "You can switch these expectation if P is independent of this and you find out this formula which is something in big Pete of square root of.",
                    "label": 0
                },
                {
                    "sent": "So this gives you in the bound a big Tito Squ.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Root or famine, you just change the bike.",
                    "label": 0
                },
                {
                    "sent": "The smaller the binary cross entropy.",
                    "label": 0
                },
                {
                    "sent": "So this is about that has been found by the first one that has been found is is magical cigar in his famous JMLR 2002 paper.",
                    "label": 0
                },
                {
                    "sent": "It was later also used by Langford and it's quite a tight tight bound but you can OK so there's a graphic illustration of this bound.",
                    "label": 0
                },
                {
                    "sent": "So suppose that the empirical risk is.",
                    "label": 0
                },
                {
                    "sent": "10% and let's say this is kind of small.",
                    "label": 0
                },
                {
                    "sent": "Let's say that the right hand side term.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is 6% so the bound is saying that well, if this is the empirical risk, well, the true risk will lie with probability 1 minus Delta between this upper bound in the lower bound.",
                    "label": 0
                },
                {
                    "sent": "So this is basically how it works if you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Choose another function, let's say and if you're looking for a function with which depends linearly on the empirical risk an you don't know what this will be.",
                    "label": 0
                },
                {
                    "sent": "Well, you just can plug.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This into the expectation and you find abound that apparently was found in dependently before us by Catonian 2007.",
                    "label": 0
                },
                {
                    "sent": "So without you respect we will call it the catoni bound.",
                    "label": 1
                },
                {
                    "sent": "So this is what you find is it is so you see you have you have an undefined parameter.",
                    "label": 1
                },
                {
                    "sent": "The bound is valid for any see, but it does not all uniformly for all see.",
                    "label": 0
                },
                {
                    "sent": "So for any see the risk of the Gibbs classifier is.",
                    "label": 0
                },
                {
                    "sent": "Bounded by this expression and what's nice about this bound is that, well, if you're looking for the Gibbs classifier that minimize the bound, all you need to minimize this simple expression inside the argument.",
                    "label": 0
                },
                {
                    "sent": "So basically this gives this optimization, well, huge.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just minimize the sum of the empirical risk and some regularizer, let's call it the pack Bayesian regularizer.",
                    "label": 0
                },
                {
                    "sent": "Without this, is always that we find so basic.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really, the only thing is that the bound depends on this constant C well, which is plays the same role as the CNS VM.",
                    "label": 0
                },
                {
                    "sent": "And so it has an iPod you have and hyperparameter to tune basically.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is in contrast with the Langford Seeger bound, where basically you know you have no parimeter things, so we will make use of these two bounds because most of the time, in fact it's the Langford Seeger bound, the one with the binary cross entropy entropy, which is tighter.",
                    "label": 1
                },
                {
                    "sent": "But sometimes the Tony bound can be tighter because basically you don't have the Sigma of em function, just have one there so the cattle need bound.",
                    "label": 1
                },
                {
                    "sent": "Sometimes can be, it can be tighter and it gives a simple optimization problem, so this is quite interesting.",
                    "label": 0
                },
                {
                    "sent": "So we of course tried to optimize this.",
                    "label": 0
                },
                {
                    "sent": "Why not try to find Gibbs classifier that minimizes this, so we apply.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This 2 two linear classifier.",
                    "label": 0
                },
                {
                    "sent": "So each example is mapped into a feature space, A set of features which can be give.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Implicitly we are Mr.",
                    "label": 0
                },
                {
                    "sent": "Colonel, so this is the usual.",
                    "label": 0
                },
                {
                    "sent": "So basically this is the output given by.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Linear classifier V with linear with weight vector V an.",
                    "label": 0
                },
                {
                    "sent": "As I told you, we're going to construct posterior.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On this set of classifiers and we're going to discuss here isotropic Gaussian posterior.",
                    "label": 0
                },
                {
                    "sent": "So basically all our posterior are going to be like that, so these are isotropic, Gaussian centered on some weight vector W. OK, so basically our task is then to find to find a waiter W that will minimize the pack baseband.",
                    "label": 1
                },
                {
                    "sent": "So we're so this where we are.",
                    "label": 0
                },
                {
                    "sent": "So basically this is the task of the learner to find the weight vector W that minimizes the PAC Bayes bound.",
                    "label": 0
                },
                {
                    "sent": "So 11 nice property of these isotropic Gaussian is that by symmetry, basically the output of the weighted majority vote.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is, our predictor is basically the same as the output of the linear classifier with weight vector W. They are basically the same, the same classifier.",
                    "label": 0
                },
                {
                    "sent": "So basically the pacbase bound will also upper upper bound this.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Die here, the risk of this of this guy here so.",
                    "label": 0
                },
                {
                    "sent": "OK, so so OK, so we want to compute the PAC Bayes bound on the training data and minimize it.",
                    "label": 0
                },
                {
                    "sent": "So you need to compute the KL divergences between the posterior and the prior.",
                    "label": 0
                },
                {
                    "sent": "So what will we choose?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who's for the prior?",
                    "label": 0
                },
                {
                    "sent": "Well, we're going to choose the prior in the same set that we're going to use the posterior, but it must be defined apriori.",
                    "label": 1
                },
                {
                    "sent": "So basically the prior is also an easy topic Gaussian but centered somewhere else, some some weight vector WP, and so by performing Gaussians integral you find you find this.",
                    "label": 1
                },
                {
                    "sent": "So we need so the, uh.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Everything we need to compute it.",
                    "label": 0
                },
                {
                    "sent": "It's Gibson pickle risk.",
                    "label": 0
                },
                {
                    "sent": "We need to compute this guys because this is the other quantity that enters the bound.",
                    "label": 0
                },
                {
                    "sent": "So we need to compute gives empirical risk on the single example, so we need to perform this Gaussian integral, which is just the probability of making a mistake.",
                    "label": 1
                },
                {
                    "sent": "So basically we're still using the 01 loss as.",
                    "label": 0
                },
                {
                    "sent": "As mentioned here by this indicator function, but it is the average of 01 loss, so this will give you some sort of a function which will not be the 01 loss in terms of W, so this will induce an effective loss for W.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "So it's just a matter of doing this Gaussian integral an you find basically that it is a cumulative Gaussian of the normalized margins.",
                    "label": 0
                },
                {
                    "sent": "So if this is.",
                    "label": 0
                },
                {
                    "sent": "Weight vector W and this is my example.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wife hired ex.",
                    "label": 0
                },
                {
                    "sent": "So basically it depends on the cosine of that angle times the Euclidean norm.",
                    "label": 0
                },
                {
                    "sent": "So you multiply that by the actions in normal W. So basically so this function as the following form in terms of the normalized margin.",
                    "label": 0
                },
                {
                    "sent": "So and it's easy to understand that just put your Gaussian, try your posterior here.",
                    "label": 0
                },
                {
                    "sent": "So basically I'll do this as positive margin.",
                    "label": 0
                },
                {
                    "sent": "It is classified correctly.",
                    "label": 0
                },
                {
                    "sent": "This example is classified correctly by this linear classifier, but as it's.",
                    "label": 0
                },
                {
                    "sent": "Fluctuated as the probability of making a misclassification error, so you will have a curve like that when they are both orthogonal.",
                    "label": 0
                },
                {
                    "sent": "Basically the probability is 1/2.",
                    "label": 0
                },
                {
                    "sent": "So all curves pass to these to this place here and so on an as the norm of W increases very large very largely, so remember that the Valiants here is fixed to one.",
                    "label": 0
                },
                {
                    "sent": "Basically the standard deviation is 1.",
                    "label": 0
                },
                {
                    "sent": "So as you increase your weight vector.",
                    "label": 0
                },
                {
                    "sent": "It becomes more your classifier becomes more and more deterministic and so you converge to this 01 last step function OK, so these are the 2 two quantities that enter into the bound.",
                    "label": 0
                },
                {
                    "sent": "So the Langford Seeger bound.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is this so you need to solve so that?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maximum value of epsilon is realized equality.",
                    "label": 0
                },
                {
                    "sent": "Basically this gives You Tube solution, an upper bound and lower bound.",
                    "label": 0
                },
                {
                    "sent": "So to find the upper bound you need to solve this equation, so OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the Catoni bound, the situation is simpler.",
                    "label": 0
                },
                {
                    "sent": "This is just about you need to minimize the bond.",
                    "label": 0
                },
                {
                    "sent": "You need to minimize this expression, and so this expression is.",
                    "label": 0
                },
                {
                    "sent": "So we just computed these guys and these guys.",
                    "label": 0
                },
                {
                    "sent": "So what you just fill in the express?",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's nice to compare this with the objective function that the SVM is minimizing, so this is an SVM.",
                    "label": 1
                },
                {
                    "sent": "It minimizes this.",
                    "label": 0
                },
                {
                    "sent": "This is the regularizer DL2 norm plus the engine loss we find exactly the same thing when our prior is noninformative.",
                    "label": 0
                },
                {
                    "sent": "So if you put zero here you see you have the same expression except that the convex injure lost here is replaced by the nonconvex sigmoid loss so.",
                    "label": 1
                },
                {
                    "sent": "Basically, at the SVM is just a convex relaxation of what you should do of what PAC Bayes is tells you that what.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We should do OK, so this is an alternative explanation of the SVM.",
                    "label": 1
                },
                {
                    "sent": "So we have performed gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So the nice thing about gradient descent is that you only need to know the gradient.",
                    "label": 1
                },
                {
                    "sent": "So this is the gradient of the Langford.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seeger, bound.",
                    "label": 0
                },
                {
                    "sent": "You can compute it explicitly.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the gradient of the catoni bound.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so basically we're performing.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gradient descent so OK so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is this question is why does we use?",
                    "label": 0
                },
                {
                    "sent": "Do we use simple gradient descent?",
                    "label": 0
                },
                {
                    "sent": "After all, the probit loss is not a convex function, but it's cause I can't.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fix, but the problem is that we don't have a single.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course I can fix to minimize we have a sum.",
                    "label": 0
                },
                {
                    "sent": "Of course, I confessed to minimizing quasiconvex.",
                    "label": 0
                },
                {
                    "sent": "Stated is not additive.",
                    "label": 0
                },
                {
                    "sent": "I mean if you sum quasiconvex function, the summation is not guaranteed to be quasiconvex an in fact.",
                    "label": 0
                },
                {
                    "sent": "So this means that Gibbs empirical risk is not quasiconvex, it has local.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Minimal and it can have several local minima anwen in the cartoony bouncy is large.",
                    "label": 0
                },
                {
                    "sent": "We do see a lot of local minima so this.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem of the.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this means that we need to supply it with some Ristic.",
                    "label": 0
                },
                {
                    "sent": "Here we have just use random starting random start myristic so.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the proposed algorithm are used both in the primal an individual so to go to the jewel you just performed.",
                    "label": 0
                },
                {
                    "sent": "This expense, linear expansion in terms of the example.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have used this agent stamps to compare to Adaboost for primal version version an for that.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Full version basically we use kernels, the RBF cur.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we provide tree algo hits.",
                    "label": 0
                },
                {
                    "sent": "So PAC Bayes gradient descent one just minimizes the lengths.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seeger, bound with an uninformative prior, so that is easy to do this gradient descent tree does the same thing, but with the catoni bound for different values of C that have been chosen by cross validation.",
                    "label": 0
                },
                {
                    "sent": "So you cheat.",
                    "label": 0
                },
                {
                    "sent": "Here you say these are the quantities that I should use, but the right proportion I'm going to settle for cross validation instead of using bound values, because it would more let's do the same thing here.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So PAC Bayes gradient descent, two basically, so this is a true bound minimizing algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is not quite this one is.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, a true about minimizing algorithm where basically you use part of your data to learn a good prior.",
                    "label": 1
                },
                {
                    "sent": "So basically we minimize the catoni bound by fixing some arbitrary values of C. This gives us several posterior that we use as priors too.",
                    "label": 1
                },
                {
                    "sent": "To learn the second half of the data so this.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suspect based gradient descent 2.",
                    "label": 0
                },
                {
                    "sent": "OK, so let us come.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go straight ahead to the result in the.",
                    "label": 0
                },
                {
                    "sent": "In the in the primal version, basically we see that perhaps not clearly.",
                    "label": 0
                },
                {
                    "sent": "But yeah, the bowl.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm not quite clear, but the overall winner is packed based gradient descent tree, so so the true bound minimizing algorithm turns out to be not as good as as the one where you choose.",
                    "label": 0
                },
                {
                    "sent": "See by cross validation, but back based gradient descent two improves or improves over pack based gradient descent.",
                    "label": 0
                },
                {
                    "sent": "One meaning that yes, it is often advantages to learn the prior tree.",
                    "label": 0
                },
                {
                    "sent": "An Adaboost are quite competitive, the overall winner seems to be.",
                    "label": 0
                },
                {
                    "sent": "To be PGD 3 but Abu scissor close.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the result in basically for individual.",
                    "label": 0
                },
                {
                    "sent": "So where we compare to SVM the RBF kernel.",
                    "label": 0
                },
                {
                    "sent": "So again PBG tree is quite competitive with VM, but the difference is turns out to be non non significant but most of the time it is slightly better than the SVM.",
                    "label": 0
                },
                {
                    "sent": "This one is slightly inferior.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically the bottom line that yes, using F of the.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically, to learn a prior helps because the second version of the bound minimizing algorithm is better.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the first one.",
                    "label": 0
                },
                {
                    "sent": "But it is still better to find the right proportion of empirical risk.",
                    "label": 1
                },
                {
                    "sent": "An regularizer by cross validation, PGD trees a bit better than PGD.",
                    "label": 1
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the bound is not quantitatively as good as we would like to be.",
                    "label": 0
                },
                {
                    "sent": "The two have so basically PGD tree is a good contender with Adaboost and SV.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it seems to be a slight better, but it is much slow.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or because we have to do all this random restarts.",
                    "label": 0
                },
                {
                    "sent": "So if you do care about.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About obtaining a good guarantee.",
                    "label": 1
                },
                {
                    "sent": "Basically PGD 2 is the best one because we did obtain good pound value.",
                    "label": 1
                },
                {
                    "sent": "I didn't show you, but sometimes the bound is let's say or like on the 1% scale.",
                    "label": 0
                },
                {
                    "sent": "So OK, thank you for attention.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yep, Yep.",
                    "label": 0
                },
                {
                    "sent": "Yeah, VR union bond argument for instance.",
                    "label": 0
                },
                {
                    "sent": "It gives the same result as just minimizing the Langford Seeger bound if you do it for several C. Basically it's just like minimizing the other bound.",
                    "label": 0
                },
                {
                    "sent": "Well, experimentally that.",
                    "label": 0
                },
                {
                    "sent": "So that's yeah.",
                    "label": 0
                },
                {
                    "sent": "An you can show basically that finding the optimal value of C4 bound.",
                    "label": 0
                },
                {
                    "sent": "If you get rid of the Sigma of em gives you the KL divergent.",
                    "label": 0
                },
                {
                    "sent": "Yes, you try to to find the the the the minimum place the we did it and it's it gives you the KL meaning that some somehow the binary cross entropy is.",
                    "label": 0
                },
                {
                    "sent": "An ideal choice for the.",
                    "label": 0
                },
                {
                    "sent": "It seems like the.",
                    "label": 0
                },
                {
                    "sent": "It's a computation.",
                    "label": 0
                },
                {
                    "sent": "They give good results, but it takes time.",
                    "label": 0
                },
                {
                    "sent": "So have you thought about trying starts?",
                    "label": 0
                },
                {
                    "sent": "Online versions of the algorithm would be much faster if you could optimize this online.",
                    "label": 0
                },
                {
                    "sent": "Maybe that was it.",
                    "label": 0
                },
                {
                    "sent": "I have not talked about online.",
                    "label": 0
                },
                {
                    "sent": "I tried to find something better than gradient descent.",
                    "label": 0
                },
                {
                    "sent": "I was not really able to find something better.",
                    "label": 0
                },
                {
                    "sent": "Our first thing that we wanted to do is to see if it looks promising.",
                    "label": 0
                },
                {
                    "sent": "It looks promising, so perhaps it's worthwhile to invest more effort, but there.",
                    "label": 0
                },
                {
                    "sent": "With several local minima, I think it's, but it's a good suggestion to look for an online version, yes?",
                    "label": 0
                },
                {
                    "sent": "There's a very.",
                    "label": 0
                },
                {
                    "sent": "My mother.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "But we didn't make any.",
                    "label": 0
                },
                {
                    "sent": "That's all.",
                    "label": 0
                }
            ]
        }
    }
}