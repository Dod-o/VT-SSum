{
    "id": "c3srxqrdmk7bcaq7em4zjlujrijy2o5h",
    "title": "Recurrent Neural Networks",
    "info": {
        "author": [
            "Yoshua Bengio, Department of Computer Science and Operations Research, University of Montreal"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_bengio_neural_networks/",
    "segmentation": [
        [
            "So recurrent neural Nets you might not know, but was one of my first loves.",
            "During my PhD I worked on recurrent Nets and I worked on sequences and I got very excited about them and then as I played more with recurrent Nets, I realized there was something wrong that I was trying to learn some things and they didn't want to learn them and I was frustrated and I tried to figure out why.",
            "And that's how I came to publish this work that I'll tell you about regarding the difficulty for recurrent Nets too long, long term dependencies and.",
            "An everything we've learned about how information propagates through recurrent Nets.",
            "Some of it applies also to the difficulty of training deep Nets in general, so hopefully you'll come out of this lecture with more understanding of recurrent Nets, but also of some issues that apply to other kinds of deep learning."
        ],
        [
            "So.",
            "People draw pictures for recurrent Nets in two different ways.",
            "So what you see on the left is the way the kind of drawing that people used to draw in the 80s and 90s where people were thinking about circuits and neurons.",
            "So the little black square here means that there is a delay in the connection from the state at some time to its next value.",
            "In other words, the units are connected to each other, but through a deley.",
            "And So what we can do to better understand what is going on?",
            "What is the computation that's happening and also to implement back propping these things is to draw the kind of pictures on the right side where we say we are unfolding the network.",
            "So we're considering the state of the network at every discrete time step.",
            "And now we see that the state at time T depends on two things.",
            "It depends on the current inputs AXT and the previous state S T -- 1.",
            "So we can write an equation like the one above that says the state of time T is at parameterized function.",
            "So F Theta here is parameterized function.",
            "We want to learn those parameters that combines information coming from the previous state and the current input.",
            "And of course this kind of equation is very common when you study dynamical systems, whether it's for machine learning or other purposes.",
            "Now, one thing you have to realize is that you can also think about unfolding in an algebraic sense.",
            "So at the top we have sort of the equivalent of the left hand picture, where we're thinking about you know how a state is updated at each time step in the bottom equation, where oh test equals GT of all the past sequence in.",
            "We're kind of thinking about the unfolded computation, where this GT is just the function obtained by composing F over and over again.",
            "And so we see that the state at particular time is a function of all the pasts.",
            "But if this is interesting from machine learning point of view, because if you wanted to learn G directly.",
            "In other words, if you parameterise the learning system in terms of some imagine G is some machine learning system that tries to predict the next state.",
            "The problem with this would be that you would need a different G for every length right for every position you have a different G because it has a different number of inputs and.",
            "It would be hard to generalize to new lengths.",
            "Of course, with a recurrent net, an parameterized dynamical system like on the top, you don't have this problem.",
            "You will naturally generalize to new lengths and within even the same sequence because we're sharing parameters across time.",
            "Things you learn at a particular time, sort of.",
            "Our combined with things you learn at other times through the shared parameters.",
            "So you basically have a very compact representation.",
            "Now when you do that, of course you're making some assumptions.",
            "You're assuming the same kind of computation can be applied at every time step an.",
            "You may imagine cases where you really depending on the value of T you would like to have a different computation.",
            "However, the good news is that if your state is rich enough, then you can always sort of emulate that kind of thing.",
            "So imagine that one of the components of the state is T, so you know you have, say, a unit that just increments by one at every time step, and so you're going to have T as as.",
            "Implicit argument basically, and you can.",
            "You can, if you have enough capacity in this F data, you can basically emulate any GT."
        ],
        [
            "Alright, so of course.",
            "Once we regard the computation through this unfolded graph, it's very easy to apply all the things we've heard about regarding backdrop.",
            "It's just like a very special kind of architecture where instead of having inputs coming just on one side, they coming one piece at a time and influencing the intermediate states.",
            "In the example here, notice that we have an input sequence, an output sequence, and both the input sequence and output sequence have the same length.",
            "So this is one of those special cases that people have applied recurrent Nets for.",
            "This is, for example when I was doing my thesis and I was doing phoneme recognition.",
            "While you have acoustic frames, as the ex is and the others were phoneme classes or things like that."
        ],
        [
            "Now there is another kind of recurrent net architecture which is very important to understand and very commonly used these days.",
            "It's the kind in which the.",
            "Outputs also feedback as extra inputs.",
            "And Furthermore, we can make it probabilistic interpretation of what is being computed as a directed graphical model that is fully connected in some sense and fully observable.",
            "So what do I mean here?",
            "So now think about the owes.",
            "Is the output at each time step is representing a probability distribution, for example the probabilities for each of the symbols that X can take.",
            "At each time step, and then what we're going to be doing is we're going to be.",
            "Able to use a recurrent net to generate a sequence so the dotted arrows here in this figure mean that we're going to sample when we use the recurrent net in its generative mode is going to be just free running.",
            "It's going to produce its own inputs, so at time T is going to produce a probability distribution over the random variable X T + 1 given all the previous ones, and we're going to be able to draw samples.",
            "For example, pick egg the next character.",
            "Given the distribution represented by OT, so you can imagine OT being a softmax over all the symbol values, and we draw particular symbol and now that becomes the next input.",
            "Now I talked about symbols, but those could be vectors, real vectors.",
            "It could be any kind of random variables.",
            "So what are we doing here when we train this with maximum likelihood is we're saying were given a sequence X one to XT Ann?",
            "Would like that our network gives a high probability to that sequence.",
            "We can decompose the joint probability of the sequence X one to XT as a product of conditionals, so that's what you see on the on the right hand side of the equation on the top.",
            "Each conditional is of the form P of the next symbol or the next observation.",
            "It doesn't have to be symbol.",
            "Given all the previous ones and of course we multiply all these probabilities and you know that's just standard decomposition of a joint into a product of conditionals, where the order here is the temporal order, that is usually a natural thing to consider for sequential data.",
            "So the training objective will just be the minus the log of the thing on the top, which means that it's the sum of negative log probabilities for these conditionals.",
            "So we're trying to predict the actually observed next symbol given all the previous symbols.",
            "And we maximize the probability of getting that thing right.",
            "So it's just like a classification problem.",
            "At each time step.",
            "And of course, replace classification by regression if it's real valued or any other kind of types of random variable.",
            "So that's the sense in which a recurrent Nets can be thought about as a generative model.",
            "And if you think about it now in terms of graphical models, for those of you know bit about that we have thinking what you see is that there are no latent variables, or at least no stochastic LinkedIn variables that you can think of the S as very special kinds of latent variables.",
            "But there are deterministic functions of everything else, so the essays are deterministic functions of the previous.",
            "As of the previous access through the equation, we."
        ],
        [
            "Saw in the previous slides, right?",
            "So the St here is a completely deterministic function of all the previous axes."
        ],
        [
            "And so you can actually think of this as a in different ways from a graphical model point of view.",
            "But if we ignore the S as latent variables because they are kind of deterministic, then it's a fully observed model where.",
            "Which means that we can just apply maximum likelihood in very simple ways and compute the tractable gradient, and everything is easy and simple, and we can model the joint distribution.",
            "You can also think of the SSS latent variables, but as I said, there are deterministic and the role they play is to make the graphical model both statistically and computationally more tractable.",
            "So what you notice is that through this through this equation that defines S in terms of the previous X is.",
            "You actually have a full dependency of all the previous axes conditioning the next one, so it's not a graphical model where we have removed any of the arcs.",
            "It's a fully connected directed graphical model, right?",
            "So there's no assumption, no conditional independence assumption.",
            "You can model any distribution.",
            "However, in general, for graphical model you think that if you had this fully connected thing, it would be very expensive.",
            "The number of parameters could blow up, and the computation could blow up in terms of the length of the sequence.",
            "But because we have introduced these intermediate quantities, the S is.",
            "States actually the parametrization is compact, it's just the status for each time step as well as the computation is cheap, right?",
            "The computation doesn't grow at each time step in terms of the length of the sequence is always the same cost, so this is a very kind of efficient parametrization parametrization of a joint distribution."
        ],
        [
            "Alright, we can play all kinds of games with these recurrent Nets and the first of all.",
            "Of course we can think of mapping different kinds of objects to different kinds of objects, like for example we can on the top right here.",
            "What we see is a recurrent net that reads a sequence and then outputs evector.",
            "So you can go Mapa sequence to a vector and sometimes you have applications where this is what you want.",
            "We've already seen the case of mapping a sequence to sequence with the two sequences are aligned.",
            "This was one of the earlier pictures and I guess that's the one on the right.",
            "The second one on the right, the third example, which I'm assuming that I don't know.",
            "The third example is vector to sequence, so here we can generate a sequence so it's the same picture as we had just in the previous slide where we can produce a sequence in a stochastic sense where we could sample from that sequence.",
            "We and.",
            "And but, however, we're going to condition all of the transitions on some vector, right?",
            "So that's the if you see the my pointer here, there's another pointer.",
            "No 2.",
            "Anyways, the thing on the left hand side here would be a conditioning variable that's going to influence every one of the transition.",
            "So now you're basically modeling P of an output sequence.",
            "Given an input vector and then the one in the bottom is a sequence to sequence case where the two sequences don't have to be the same length.",
            "They could be even of different types, and for example this is a model that's being used early on for machine translation.",
            "Where you have an input sequence and an output sequence, and So what happens here is that you have two parts to this you have reading the input sequence that creates a representation through a summary of the whole input sequence in the state, and then then we're going to generate an output sequence using the same generative model, but it's now conditioned on the state that we got as a result of summarizing the input sequence.",
            "Any question about these things.",
            "Alright, good now."
        ],
        [
            "I told you that we can train these recurrent Nets by maximum likelihood.",
            "This is also called teacher forcing.",
            "This name came before people thought that we were actually doing maximum likelihood.",
            "And there's a good reason for this name, so let's try to figure that's trying to see what's happening when we train in the maximum likelihood way you can think of it like this.",
            "There are two kinds of computations that need to be considered when we train in this way.",
            "There is the the kind of computation we're doing when we train, and the kind of computation that we do when we use the model to generate a sequence.",
            "Alright, so whether it's conditional or not doesn't really matter.",
            "So what you see in the picture with the?",
            "So there are two kinds of dotted.",
            "There's the dashed and dotted right, so the.",
            "The dash is the what happens during training.",
            "So in other words, during training we have targets for the outputs.",
            "Otherwise we know what the ground truth next output next observation should be.",
            "So given the past ground truth, we are trying to predict the next element of the ground truth sequence and so the thing that we're going to be feeding in as input for the next time step is that you know observed Whitey.",
            "Coming from the data.",
            "On the other hand, at Test time we're going to be.",
            "Of course, we don't have any ground throws at Test time.",
            "We're going to use the output of the model.",
            "The sample from the conditional distribution of the Y given the current state.",
            "So we have these two kinds of loops now they could coincide, but they could also be different and you could easily imagine a situation where there would be different when the kinds of sequences that the model has learned to generate isn't quite like the kinds of sequences in your training set.",
            "In fact, in general this is going to be the case.",
            "We never have a perfect model, right?",
            "So if it was a perfect model, it would only generate sequences like those in the training set, but it's not going to be the case in practice, so there's going to be discrepancy.",
            "Between the kinds of of data that's fed in as input.",
            "In other words, what the recurrent net sees as the conditioning input when it's training versus when it's being used to generate symbols, and that discrepancy is kind of mismatch, which means that it could be that the network is essentially doing something completely weird and wrong when it's being used.",
            "So this let me give you.",
            "A sort of analogy to understand how badly could be so.",
            "Imagine that what the network is doing is learning to drive a car, which is today a very you know.",
            "Important application of deep learning.",
            "So let's say that the way we train our network to drive a car is we have a human driver car and then we just wait till the network to predict what's the next.",
            "You know position of the driving direction.",
            "Given the observations and the past driving directions, and you know if the network train learns to perfectly imitate the moves of the human, it might be fine.",
            "But let's say that it makes small mistakes and at some point it actually gets the car slightly off of the center of the road, and it's now, you know, at a place where humans have never been, because humans know that they shouldn't.",
            "You shouldn't be so close to the border, and now the car is seeing a kind of input that it has never seen.",
            "And you know, maybe you're lucky and it generalizes well and goes back towards the middle.",
            "Or maybe you're not lucky.",
            "And it goes even more to the right, and it goes out of the road, right?",
            "So the problem is that it's going to see input configurations when it's generating, when it's acting on itself.",
            "That may be very different from the one that's on during training, because the human driver of course doesn't visit these bad states that you might see when the model is actually running by itself."
        ],
        [
            "So the this is a history of machine learning approaches to try to deal with this and a lot of it is inspired from issues.",
            "Similar issues happening in reinforcement learning.",
            "An I'm not going to go in detail into these, but one of the recent ideas that is having some success is called scheduled sampling and it bears relation to earlier work, hold Cernan, Dagger and the idea is we're going to be sort of trying to make the network see the kinds of inputs that it would generate itself during training, so that knows to kind of go back to the right.",
            "You know the middle of the road.",
            "The kinds of things that the human would do.",
            "The teacher would do so.",
            "In other words, the idea is that.",
            "Instead of of of picking the ground truth as inputs while we train with some probability, we're going to pick the ground truth and with some probability we're going to pick the sample coming from the output of the model, and it turns out that it's actually wrong to do that from a. Sining point of view that this procedure doesn't actually learn the right thing, but it's reasonable to believe, and I don't have any proof of that, but it seems reasonable that if we, if we make that probability of choosing one or the other, gradually decrease towards 0, not in the sense that it ends up just listening to the ground truth, then, then you'd be OK, and it would have some kind of exposure to the kinds of things that kinds of situations that it would see when it drives by itself.",
            "Right, so one interesting question.",
            "There's something wrong in this and you take some time to go.",
            "And really understand it.",
            "But one way to think about it is imagined that we run the network in its training using the ground truth, and then we let it run by itself for a few steps, right?",
            "So it's what we call open loop, so it just takes it output and feeds it as input an it might go in a strange place, and in particular the place where it goes might not the right answer for the state where it ends up might not be the one that you have in your ground through sequence, so if you.",
            "Go back to the driving example.",
            "Maybe the driver was staying straight in the middle and.",
            "If if the car decided to go a bit to the right, now the right action would be to go back to the middle.",
            "But maybe because the ground truth was staying in the middle, it says you know you stay in the middle or even go a bit to the right because he was gone a bit to the left and so so these could be inconsistent targets that were giving to this network.",
            "So so you know the question is really, how should we train this?",
            "And one idea I had when I wrote those slides was that, well, we don't actually want to match the.",
            "The ground truth target a few steps later what we want to do is to match the ground truth in distribution, and so maybe something like again, which you will hear about and you've heard a little bit already about yesterday.",
            "Might be a good way to deal with this problem."
        ],
        [
            "OK, so let me talk more about some architecture variations.",
            "So up to now, I haven't really looked into how we structure the architecture of the neural net, but what you see on the left here is sort of the vanilla architecture that we've been talking about.",
            "We could we could think of in several researchers and papers of proposed different ways of making this kind of architecture deeper for each time step, so you can do that in various ways.",
            "So one of the first ways that was proposed, believed by Alex Graves, is the one on the bottom left, called stacking.",
            "Where essentially we're going to decompose the state into different levels.",
            "So here we call one level they choose and the other the Zeds.",
            "But you could imagine having many more levels and typically people will have like even 10 levels like in normal deep Nets, so not what happens is that for a given input XT there will be like a deep network of feed forward.",
            "If you want recurrent net going up to all the layers of the recurrent net, but.",
            "At each of these layers, like the HD for example, it not only depends on the current input, but the previous layer, but also on the previous value of that levels state.",
            "OK, so that's the stacking version.",
            "Another way that you could increase depth is to think about making the transition from one state to the next day deeper instead of having a single affine followed by non linearity for going from ST2ST plus one you could get insert like an MLP for example like in the picture in the middle.",
            "And similarly, the mapping between state and outputs could be deeper, right?",
            "So you could again insert one or more hidden layers.",
            "Now there is a problem with this that I should have put the.",
            "Oh yeah, there's I clear 2004.",
            "So we had a paper about this.",
            "There's an issue when you insert the.",
            "When you insert an extra layer from T to T + 1 is that it somehow makes training more difficult because the length of the sequences to be considered is not like doubled.",
            "And so we inserted the little skip connection.",
            "Here that goes directly from T -- 1 two T as well as the.",
            "You know, in addition to the extraordinarily extra layer in between.",
            "That's connected to the problem of long-term dependencies, which I'll come to."
        ],
        [
            "In a few minutes.",
            "And also sort of think out of the box and.",
            "Expand The kinds of architectures from recurrent Nets to other kinds of structures that are not really corresponding to a chain, right?",
            "So?",
            "So in the case of the recurrent net, you basically have the extended.",
            "The unfolded graph is basically a chain, but you could imagine other kinds of things.",
            "For example, you could have a tree, and these are called recursive networks, and they've been studied in the 90s and more recently by Richard Socher and a bunch of papers where he applied them to both the natural language and images.",
            "Another a kind of architecture, is the bidirectional recurrent net, so this is the one on the top right where you have two recurrent Nets, one going from the past to the future and one going from the future of the past.",
            "And then you think of the concatenation of the state at each time step as a representation for the whole sequence, right?",
            "Because?",
            "If you think about it, the state in the say left going.",
            "RNN summarizes everything from the future.",
            "At a particular point and the state in the right, going RN at the same time point.",
            "Summarizes everything from the past, so now if I concatenate these two states, I have a representation which contains information about the whole sequence, and this is true at every time step.",
            "So now what we have, if we take those two concatenated States and we do something with them like we compute a new representation is we have a representation.",
            "We have a feature extraction which depends on the whole sequence at every time step.",
            "So we're extracting features at every time step which.",
            "Basically, we'll focus more on what's happening in the neighborhood of times that, but could be influenced by everything.",
            "So in other words, you can think of it like.",
            "It's a context dependent feature extraction like the normal feature extraction.",
            "We look at one time step or a fixed size window and we get some features.",
            "But now we have features that of course will tend to tell you more about what's happening in the particular place, but they will be sort of influenced by potentially everything.",
            "The whole sequence.",
            "Now of course one problem with this is we lost the causality.",
            "In other words, we can't.",
            "For example, we can't use this to generate the inputs, because we would be using the future to generate itself, which doesn't make any sense.",
            "But we could use this as a preprocessing to extract information from a sequence.",
            "So when, for example we are mapping a sequence to sequence.",
            "Or sequence to anything else.",
            "This kind of architecture is very useful.",
            "It has become even a standard for many applications.",
            "There's another kind of expansion extension of recurrent Nets, which is interesting, maybe less used as the binder.",
            "I would say the bidirectional Nets are the most commonly used these days, But another interesting direction is basically everything that works for 1D can be extended to 2D or 3D pretty naturally, right?",
            "So instead of having a chain that goes left to right, you can imagine that you have, say, a 2D plane.",
            "And that's really useful for images, and we've done things with that.",
            "Where at each position you now have a state.",
            "So at each idea position you have a state and that state depends on the state at.",
            "You know the one on the left, the state on the left.",
            "So at my I -- 1 J and the one above.",
            "So that's I J -- 1.",
            "So that creates kind of grid where you can actually compute any state by traversing the grid in some reasonable order like diagonals or something.",
            "And of course, you can then backdrop and do everything that you want, so you can generalize this chain idea to 2D or 3D structures."
        ],
        [
            "Um?",
            "Yeah you can.",
            "You can play with the parameterization, so one of the things we've done recently is instead of having the state being in the find function of the previous state and input, we can introduce some gating or multiplicative interactions.",
            "So this this dot with a circle is just elementwise multiplication.",
            "Or some more general form where you now introduce more multiplicative interactions and somehow this can actually help to learn some things without increasing the number of parameters.",
            "So these these these gating or multiplicative types of computations being useful in many instances you'll see this week and this is just one example."
        ],
        [
            "OK, so now let me go to probably the most important part of my presentation, which is about the issue with training recurrent Nets and why in particular learning about long-term dependencies is difficult is fundamentally difficult.",
            "So this is a summarizing paper that came out in 90 four and I started working on this around 1990.",
            "And I'm going to tell you more about this so."
        ],
        [
            "In 91 when I was at MIT I I was trying to understand why my recurrent Nets that I had used for speech recognition weren't learning those long term dependencies.",
            "I really didn't have that concept.",
            "Clearly in my mind, but I was trying to understand what.",
            "Why is it that sometimes it doesn't learn and so I tried to reduce the problem to very simple case which is a single neuron.",
            "OK Anna single neuron trying to learn to store 1 bit of information.",
            "I think you can't have simpler than that.",
            "And I found that even that really stupid simple task.",
            "The network would fail to learn it if it had to remember that piece of information for a long time.",
            "And then it didn't tell it that it had to learn it until the end of the sequence.",
            "So so the input would be something like this.",
            "So either.",
            "The first input was large or the 1st three inputs were large, or they were small, so it's a binary information.",
            "Then there was noise and then only at the end of the sequence I would tell the recurrent net what the right answer should be, which is basically output A1 if the initial input was large and output a zero if the initial input was low, and if I trained this with a target coming soon after.",
            "So for short sequence like say 5 or 10.",
            "Time steps it would work fine, but if I went to like 2030 and you know like 50 now the probability of successfully learning a task went down to like 5% or something.",
            "It basically didn't work most of the time and I was very surprised because this should be very easy task.",
            "So what was going on?"
        ],
        [
            "So to understand what was going on.",
            "It's good to go back to basic notions about dynamical systems, because if you think about that little situation, what we have is we have this dynamical system.",
            "We started in a particular place, so either with the input being large or the input being high, and so we want to keep that information we want to remember in the state that the initial state was either in some region, so we started in the region corresponding to.",
            "To a high value or we start in the region corresponding to.",
            "Sorry, low value or corresponding to a high value and then we follow the dynamics.",
            "So in the state space here I imagine this is a 2D state space.",
            "Actually in my example it's a 1D space space.",
            "What happens is that the network will follow the dynamics we like.",
            "Follow some errors so you can imagine that every position you have arrows and these arrows will tend to bring the system towards some regions.",
            "We call these regions attractors.",
            "And in particular, you could imagine the simple case where it's a fixed point attractor.",
            "So there's one place where it wants to go from anywhere you start, and the regions in which the dynamics would lead into the attractor, or called the basins of attractions of these tractors.",
            "And so there is a boundary between those basins of attraction.",
            "If you start on one side that boundary, you will tend to go to the this attractor.",
            "If you start on the other side, you will tend to go to that attractor.",
            "Right so.",
            "There are a few interesting things here.",
            "First of all, from the point of view of the size of the gradients, there's something really funny happening around the boundary region, because if I move by epsilon going from one side of the boundary to the other side of the boundary, the result at the end of the sequence will be very, very different.",
            "So the derivative of the state at the end of the sequence with respect to the state at the beginning of the sequence will blow up, right?",
            "In other words, a small change at the beginning becomes a huge change at the end.",
            "And of course there are other cases we have things like this with fractal dynamics and so on.",
            "But even in the simple case like this, you see that you might end up with very large derivatives, so these gradient explosion might happen in this case.",
            "There's another thing.",
            "Which is.",
            "That this is a property of of these basins of attraction is that inside the basin of attraction, and in particular near the attractor the derivatives of the dynamics function.",
            "The function that Maps states to next state.",
            "Have particular property that essentially the derivatives are less than one, so there is less than one means that we see the map is contractive, meaning it takes 2 nearby points to two points that are even closer.",
            "So the map is either contractive or it's expanding, right?",
            "So if it's expanding means it means it takes 2 points and Maps them slightly even further from each other and actually in different directions.",
            "The answer might be different.",
            "Right, and that corresponds to the.",
            "The eigenvalues of the map.",
            "So if you have the Jacobian of the map.",
            "So if you think about that transformation from T + 1 as a function, it has a Jacobian matrix.",
            "And Jacobian matrix has single values or eigenvalues.",
            "Either way, the important question to ask about those eigenvalues is in magnitude.",
            "Are they less than one or greater than one?",
            "If there are less than one, then somehow the dynamics will tend to be converging towards someplace if it's greater than one, then it's pushing you.",
            "Away.",
            "So why is that in?"
        ],
        [
            "Portant because.",
            "In the region where the derivatives are less than one, then you are in a place where you're contracting and noise will be cancelled.",
            "So if you are in such a region an you have a bit of noise being added to your state, the system will be robust to that noise and you will still be able to converge to the fixed point.",
            "If you're in the expanding region then a bit of noise will be blown up and eventually you can go out of the extractor and forget the bit right so?",
            "As for getting here means going from the base and corresponding to say one bit to another one.",
            "Basically you've lost that information.",
            "So the thing that really matters here is the weather.",
            "Those derivatives are less than one or greater than one."
        ],
        [
            "And if we want to store information reliably.",
            "In other words, we don't want to be kicked out by a little bit of noise.",
            "From that information we stored like the one or the zero that I had in my example.",
            "Then we want to make sure that the dynamics stays in the regions where the derivatives are less than one.",
            "So why is that a problem?",
            "It's a problem because if you look at the gradients that we would use for example, for backdrop they involve asking the question how does state at time T influence the final loss.",
            "So you can think of the final loss as a function of all the previous States and each state depends on the previous state and so on.",
            "And because of these decomposition we have a composition of functions and by the chain rule we can write the gradient as a product.",
            "Of these jacobian's, at each timestep times, one final gradient vector for the relationship between the state at the end of the sequence and the loss.",
            "So we what we have here is a product of matrices and vector.",
            "So now each of these matrices if they have eigenvalues.",
            "In of the Jacobian, there are less than one.",
            "What does it mean?",
            "It means we're basically multiplying a bunch of numbers that are less than one together.",
            "And if you multiply many numbers of less than one together, what you get is vanishing gradients."
        ],
        [
            "So this actually was independently discovered by set Horse Rider, and he wrote about it in his thesis in 9091 in German, so I didn't really know about it until a few years later.",
            "And he he.",
            "This is actually interesting.",
            "I learned this recently.",
            "Not only he discovered this this issue, that the sort of.",
            "The derivatives of the states in the past versus the future you know are obtained as a product of the Jacobian.",
            "If this jacobian's are small, then you have vanishing, but this also actually led him to come up with the STM, which I'll tell you about later and he started thinking about LSD M in his in his 1991 thesis.",
            "The actual SDM paper only came up in 97.",
            "I'll tell you more about."
        ],
        [
            "OK, so why is it that having these derivatives?",
            "Converge to zero as we consider longer sequences.",
            "Why is that a problem?",
            "Because it's going to.",
            "It's going to mess up our parameter gradient so.",
            "The equation I'm showing here is not the way that the gradient is computed by backdrop, but you can rewrite the gradient equations in this way to understand.",
            "How it's composed an you can you can rewrite the gradient of the costs at some time in the future, like the end of the sequence with respect to parameters as a sum over all the previous time steps.",
            "So we have the final time steps T an.",
            "Now we consider the sum over all the previous time steps Taw.",
            "Where we're going to consider that the way that we can, that the parameters influence the cost at T at the end of the sequence is that the parameters are going to influence the state at all some intermediate time.",
            "Then the state or is going to influence the state at T much later, and then the state of T influences the costs alright.",
            "And now we have a problem with this middle quantity.",
            "Here D state at and D state at some intermediate points.",
            "And the problem is that if we want to be in the region.",
            "Of the state space and the parameter space that allows to store bits of information reliably.",
            "We need those derivatives to be less than one.",
            "We need those eigenvalues to be have we need the spectral radius to be less than one, we need all the eigenvalues to be less than one, because this is the condition that will allow to store information reliably, but at the same time this condition makes it so that this this derivative this matrix, which is a product of all the intermediate Jacobian matrices, converges to zero exponentially fast in terms of the length of the sequence.",
            "So why is that a problem?",
            "Because now we have this sum.",
            "Some of the terms will be very small because there are exponentially smaller than the other ones, so the terms that regard long term dependencies.",
            "So in other words, how the state in the remote past some far in the past all influences the current T. Those terms will be very small compared to the terms in that some corresponding to what's happening when tall is really, really close to 2 T. Right, so what's happening is that the total gradient is a sum of terms, some of which will be much smaller, and we know what happens numerically when you add a large number in a small number.",
            "Basically, the small number loses.",
            "You lose that information.",
            "I mean, if you if you an, especially if you think about stochastic gradient descent, there's kind of noise happening in this gradient, and So what we're going to have is.",
            "Essentially that the long term dependencies are going to dominate.",
            "It's going to be easy for the network to learn their short-term dependencies, but it's going to take forever for the network to learn the long term dependencies.",
            "An forever could be really bad in some cases.",
            "Alright, so this is this is really, really important.",
            "I want to make a pause here to allow you to ask questions.",
            "Yes, this might be really crazy.",
            "Not just rescaled.",
            "I tried it.",
            "Didn't work.",
            "But the problem with rescaling is that.",
            "Then you don't have any guarantee that is the correct gradient anymore.",
            "So if you're lucky, maybe all of those terms have the same sign, for example, and then it would be fine.",
            "But let's say some are positive, some are negative.",
            "You change the weighting of each of them, and now you might go in the wrong direction.",
            "Yeah.",
            "The problem because you have a fine time scale, but they don't have sort.",
            "Of course I tried to log into office.",
            "Yes, I'll come to.",
            "That is one of the directions to try to solve this problem, but note that it won't solve it completely.",
            "It would make it easier because we're trying to reach between 8:00 on 80 through some steps that are somehow less nonlinear and have less Jacobian is closer to 1 basically.",
            "But that's a very important direction of investigation.",
            "Forever, forever forever be clumped independently.",
            "So are you saying that in the limit of infinite I'm growing tree learning I think so yeah.",
            "I don't have any like math to support this thing, but but intuitively it's just a matter that the total gradient is.",
            "Now, you know, has important terms from from a statistical point of view, but the numerically these terms are very, very small right?",
            "So in principle you would first kill off the the you would learn the short term dependencies and then those terms would be small and then eventually you should be able to learn the long term ones.",
            "But in practice, because you also have noise in the gradient coming from the fact that you're doing SGD.",
            "And you know all kinds of imperfections, or even numerical precision issues.",
            "It becomes harder and harder.",
            "Yes, how cold cases dynamics in terms of Canada tractor be measuring on zero like sure?",
            "So that's a very complicated yeah, but really here, the argument I made doesn't really care about the shape of the attractor.",
            "It only depends on the fact that we for it to be an attractor.",
            "The eigen values need to be less than one around it.",
            "So you can get close.",
            "Nobody, I don't care where I'm on their tractor.",
            "Yes yes.",
            "So in general when you store many bits.",
            "This is your exactly going to be in the situation where the attractor isn't a point, right.",
            "Otherwise you would need like one attractor for each value that you want to store.",
            "It's much more efficient to have kind of a distributed representation where the tractor is actually a multi dimensional object and now you can store many bits, sort of in a componential way.",
            "But anyways doesn't matter.",
            "The point is to store information reliably.",
            "You need these contractive mappings.",
            "But contractive mappings equals.",
            "Hard to learn.",
            "The longer term dependencies.",
            "Yeah.",
            "Is there another problem with where you start?",
            "The initial condition will be the point on the boundaries of the yes, that could be a problem to an.",
            "In practice when we train recurrent Nets, we see this happening so rarely.",
            "No, it's not necessarily.",
            "I mean, that would be one instance, but simply the fact that you go in those places where the eigenvalues in some regions the eigenvalues are larger than one.",
            "And if you spend time there, you're going to receive some very large gradients, and that can simply throw off your learning.",
            "In fact, that's one of the common problems with training RNN, but the good news is that we have a trick to fix that, which I'm going to explain in a couple of minutes, yes.",
            "In order approaches, so yes, I tried that too.",
            "Yeah, and we had some hope for a time that it could solve the problem, but it.",
            "It's not it.",
            "It could help in some cases, but it doesn't seem to be general cure.",
            "Yes, so just before that the reason why we thought this could work and this is really ideas coming from yes Cover and James Martens.",
            "Is that if we're lucky?",
            "When the first derivatives, when the components of the first derivatives.",
            "So these are components of the gradients.",
            "So you can think about components also of the second derivatives.",
            "So if we're lucky, the components of the second derivatives also scale in the same way.",
            "And then when you multiply by the inverse Hessian, that kind of cancels this issue.",
            "So there's hope, but you know, it doesn't always work, and I don't really understand why.",
            "Alright, I should probably move on to get a chance to see the rest of the material last quite less question.",
            "Problem, what networks I didn't hear.",
            "Work kind of sold well.",
            "What residual networks are feedforward networks?",
            "An you can think of residual.",
            "It's the other way around.",
            "Visiting networks work because they do like Gru, zorel stems or higher highway networks.",
            "They they have a Jacobian close to 1.",
            "Because they have this.",
            "Next state equals previous state plus something if something is reasonably small, then the dominant term in the Jacobian is this identity.",
            "Alright, I should move on."
        ],
        [
            "OK so um.",
            "Yeah, it's interesting to point out though, that.",
            "The situation in the feedforward case is not quite the same.",
            "Although there are some really important parallels and lessons to be.",
            "Considered so, this is a recurrent case and I've kind of drawn here.",
            "I put it upside down and I've put in read the fact that the weights now are different at each layer.",
            "So in the recurrent case we have inputs coming at each time step, but that's not the main thing.",
            "The main thing is that the weights are different at each time step, and so that makes a huge difference because basically.",
            "Especially the target only comes at the end.",
            "Now in principle you could.",
            "You could do the re weighting.",
            "I forgot who proposed.",
            "We should do a reweighting.",
            "Well here you can do a reweighting because there are you know you're not adding up these things.",
            "Now forget about the sum.",
            "They all go to a different layer right?",
            "So you have a different set of ways for each time step for each layer.",
            "So now you can re wait an.",
            "In fact it's a good thing to do it.",
            "And I think the adaptive learning rate methods do something like this.",
            "Unfortunately, we waiting the layers in a deep net, although it can help.",
            "Doesn't necessarily completely solve the problems of learning deep Nets, but it's something to keep in mind.",
            "Alright."
        ],
        [
            "So I guess I said all these things."
        ],
        [
            "Let me probably."
        ],
        [
            "This let me tell you about the clipping.",
            "So.",
            "So there's a very simple recipe to get rid of the problem of the large eigenvalue.",
            "So when the gradients become very large because you multiply numbers that are greater than one together, you get a kind of explosion, and the recipe is basically when the gradients is large.",
            "Don't trust it.",
            "Very simple right?",
            "Because if you were to take your current parameter values and add this huge gradient.",
            "It would just throw you off very far from where you should be.",
            "One thing to keep in mind and why this makes sense is that the gradient descent algorithms make sense when you make small steps.",
            "If you have a huge gradient and you add that with your current learning rate and you make a big step, you could go anywhere.",
            "It's just going to be, you know it's likely to be wrong.",
            "So in particular, you have to think about the most important information about the gradient is the direction it tells you to go, but the magnitude could be completely wrong, right?",
            "So what we did is we take the gradient on the parameters and we check if it's norm is greater than threshold.",
            "We change the norm so that it's equal to the threshold.",
            "So it's very easy.",
            "It's a one line to change in your code and it prevents the issues you have with gradient explosion.",
            "Now let me tell you about the picture in the back.",
            "In the bottom, people used to think that the main optimization sort of landscape to keep in mind when we train neural Nets or other kinds of problems actually is that there's a conditioning problem and there is a conditioning problem, meaning that.",
            "So this is supposed to be the error.",
            "The cost with respect to the parameter space on the plane.",
            "Meaning that you have directions where the second derivatives of the costs are very large and directions where the second derivatives costs are very small and you know this is slowing down training and so on.",
            "But in recurrent Nets actually you might see things like this, so this is actually the case where the single neuron with the feedback and you have these ridges.",
            "So instead of things being these values being symmetric, you have very high derivatives on one side, but not necessarily high derivatives on the other side.",
            "And here you have a nice slope going down in this direction, so you actually would like to go down in this direction.",
            "The problem is, as you do, that you approach this region which is close to probably a boundary of basic attraction.",
            "This is in parameter space, so it makes it makes it possible to approach those boundaries that have very large gradients and near those boundaries the gradient become huge and they kick you off and throw off the learning.",
            "So by simply rescaling the gradient or sometimes just ignoring it and doing a random move, you just go not too far away and then continue.",
            "And that really solves a lot of these problems, it doesn't solve the long term dependencies problem, but it solves the problem coming from the large gradients.",
            "So this is called gradient clipping and it's very very efficient and you should all have it in your own code."
        ],
        [
            "Alright.",
            "So now I'm going to tell you about approaches to try to deal with this problem.",
            "Have long term dependencies, so in the.",
            "In the 93 paper that we wrote about the long term dependencies.",
            "So this was an early version of the Journal Paper 94.",
            "We proposed something that has the flavor of LVM is not the same thing, but the idea was that again we have this memory cell that at each state gets updated by just copying itself, and we have some kind of decision that gates that that you know whether we copy.",
            "Or we don't.",
            "And then we use some kind of touristic to decide how to propagate gradients.",
            "But this idea that you should have this kind of self loop to keep information for a long time was there, and it was also in 91 in separate writers thesis."
        ],
        [
            "So.",
            "Yeah, actually."
        ],
        [
            "You tell you about LST em right now.",
            "So.",
            "There are different variants of the LSD, but basically all of them.",
            "The central idea is.",
            "There is this state variable.",
            "Has a self loop with itself in other words.",
            "They called the code the cell in the LCM.",
            "The new state will be equal to the old state plus some kind of update.",
            "An we can control with a gate whether we actually copy the old state into the new state.",
            "An whether we actually have an update coming, so the important one is the forget gate here, which which multiplies the self loop path and so it could kill off the self loop path and the reason you want to do that is that if you didn't have that then it would just keep adding and adding in the state would keep growing and growing.",
            "And yeah this might prevent you from forgetting things.",
            "Sometimes you actually want to forget things because you have limited memory.",
            "And in the case of LTM, there are also extra gates which control whether we actually add something into the state.",
            "So there is the input.",
            "But there's also a gate which multiplies this or it can kill off the thing that will be added.",
            "And they also have an output gate, which I think is useless, but controls whether something is going to be sent to the outside world and the Gru, gated recurrent unit has a.",
            "Slightly simpler architecture, so it's, but it has the same self loop and it works basically the same and it's a bit cheaper to compute, so several papers are using it.",
            "It is kind of the same principle."
        ],
        [
            "So that was 97 LS TM in 95.",
            "In 95 we.",
            "There's another paper that's missing I should have.",
            "We proposed in NIPS 95 we proposed to use temporal hierarchy, so this is answering Join's suggestion that maybe we could use multiple levels of timescales in order to bypass this problem of having you know the multiplication by many jacobian's.",
            "So what I mean here is here in the bottom you have a regular recurrent net, but at the next layer you have a recurrent net that's updated less often somehow.",
            "And then another one even less often.",
            "So here I double the period.",
            "So what happens is that even though the path through the the fine time scale recurrent net may just make it impossible to learn long-term dependencies, you could learn long-term dependencies.",
            "By having gradients propagate through the shorter path that goes through the slow time scale.",
            "So this is the general idea.",
            "And the devil is in the details.",
            "Like how do we define when those upper ones should be updated?",
            "And so on.",
            "You don't even have to have discrete updates.",
            "You could have slowly changing units higher up rather than.",
            "You know I update every 10 time steps.",
            "I just update by copying my old value a little bit and adding a little bit of the new value.",
            "Another idea which came at about the same time from Lee Giles in the top right.",
            "What you see is you can have recurrent Nets.",
            "We skip connections overtime.",
            "So again, what you are doing is now you create those paths in the graph which allowed to go sort of faster from the past or the future with less nonlinearities in between.",
            "And that also works.",
            "So an example of these hierarchies in recent work we did with Julian Serban an others here at Mila involves.",
            "Two level hierarchy where there is one level of recurrent Nets that is reading.",
            "Words in a sentence, but you could also imagine some characters in a word and another level which is working at the level here of sentences, and you can have more levels if you wanted, but you could imagine many ways that you can implement these ideas of a hierarchy."
        ],
        [
            "And now if we go to something very recent with which I think brings fresh ideas to this question of long-term dependencies, memory networks, which you will hear more about.",
            "You can think of memory networks as some kind of recurrent network where the state part of the state is now stored in a big memory big outside memory.",
            "I'm going to."
        ],
        [
            "See you next picture 'cause it's kind of easier to understand so so you have a set of memory cells and at each time step what happens is that those memory cells either get copied from the previous time step or somebody writes something into a cell and somebody is a neural net right recurrent that, and when you write something into a cell, of course you are going to be for getting old values, but most of the time if you have a big memory Ann, you're only writing at one place at a time, basically.",
            "You're just copying and so information gets propagated for a very long time.",
            "In other words, if you have like a memory like a memory of a Turing machine, when you store things in there, it robustly stays for a long time, right?",
            "And so that kind of sidesteps the problem of long-term dependencies.",
            "Or at least it reduces it considerably."
        ],
        [
            "So there's a nice recent paper.",
            "From Mila, an also involving Toronto people where we try to think of.",
            "How to characterize these recurrent net architectures and we came up with three.",
            "Interesting measures to help us understand an architecture, so one of them is the.",
            "A feed forward depth, so that's like the yellow path.",
            "So remember if we stack and recurrent net.",
            "So how long does it take to go from input to output through different layers?",
            "That's basically like going in the feed forward direction.",
            "Then you have the recurrent depth which tells us what's the longest path from a particular time.",
            "Step 2 later in the future, potentially going through all the complications of the architecture, and in this particular architecture you see that you can.",
            "You can pack two nonlinearities for each time step, because you can go through this layer, then then the one above, and then at the same time step.",
            "And then go to the next time step at the same level and so this red path here actually.",
            "Packs twice as much depth per timestep, then a standard architecture, and then the third quantity.",
            "That's interesting to consider is the skip coefficient.",
            "Which tells us about the blue arrows.",
            "That tells us not about the longest path.",
            "From beginning to the end, but the shortest path and is also useful, right?",
            "You want to have these short paths in order to long-term dependencies."
        ],
        [
            "So there are experiments that I don't have to tell you about showing how all of these things, all of these things can matter."
        ],
        [
            "Briefly, there's been a bunch of work exploring how we can play with the weight matrix in order to make it easier to learn long term dependencies.",
            "So, for example, you could initialize it to be orthogonal.",
            "Or you can actually constrain it to be a unitary matrix which has all the eigenvalues equal to 1.",
            "Or you can play a game similar to what you have in stock and resonates where sometimes the Jacobian is just the identity because you just copy the previous data, the next date, and you can randomly do that and this is called zone out in recent paper, also from Mila.",
            "OK."
        ],
        [
            "Now earlier I said that in a.",
            "Standard recurrent net.",
            "We can interpret the computation and the model as a directed graphical model without any latent variables.",
            "And what that means is that all of the randomness that is injected when we generate something is happening at the level of the observations of the visible variables at the data level, right?",
            "So if we're working on pixels, it's like the way that we generated images that we randomly picked the next pixel, and then the next pixel given the previous pixels.",
            "But it would make a lot of sense if instead.",
            "The randomness was about taking decisions regarding not the low level, not the pixels, but the high level in the hierarchy.",
            "Like what is this picture going to be about?",
            "What is this text going to be about?",
            "What is this music going to be built?",
            "You'd like to take these high level decisions and then condition on these high level decisions.",
            "You might want to put in the details at the low level.",
            "So for this you need to introduce latent actual latent variables, not just the deterministic ones we have in a regular recurrent net.",
            "We need to introduce the exact variables at sort of a high level of the hierarchy corresponding to high level abstractions.",
            "So it's like you decide on the high level structure, and then given that you may decide low level structure.",
            "So we the last nips, we had a paper about combining ideas from what's called variational autoencoders, which hopefully will be also covered later this week in recurrent Nets.",
            "Since you haven't seen these things yet, I'm not going to go in much detail and I don't have much time, but basically you can combine the ideas in some of these modern latent variable models in recurrent Nets, and you can stick in high level random decisions in the computational graph in the model."
        ],
        [
            "So the model I showed you earlier which has two levels of recurrent Nets like one working on words, the other working on sentence is you can also have random variables at each time step which control sort of high level decisions about.",
            "You know, maybe what topic we're going to be talking about in the next sentence, given everything that we've said before, and then given that we can generate the next sentence.",
            "And so that's also been work of Julian Serban."
        ],
        [
            "So there are other fully observed neural Nets that are directed graphical models that are not really recurrent Nets, but or maybe different from recurrent Nets, and it's worth talking about now.",
            "Anne."
        ],
        [
            "And they belong to a larger family which uses the same decomposition.",
            "I told you at the beginning.",
            "Remember, I told you that we can take a joint distribution P of X1 to XY and we can write it as a product of conditional.",
            "So that's the way one of the basic.",
            "You know things you should know about probability distributions and so in general we get a graphical model like the one on the right where you see each variable like X3 being conditioned on all the previous ones.",
            "So these kinds of decompositions had been used before.",
            "The 90s in particular Brendan Frey, in whose Toronto in his thesis in 97, proposed a model that essentially has a logistic regression of each bit in a vector given the previous bits according to some order.",
            "So you were now not talking about sequences, so there's no natural order, but we can still pick an order and then say we're going to model the conditional distribution of the Earth.",
            "Variable given the ones from I from 1 to I -- 1 and we can just do a linear regression or logistic regression to obtain those conditional probabilities in 99 with my brother Sammy.",
            "We sort of extended this to annual net.",
            "Where we said, OK, so those conditional probabilities instead of being computed by a linear model, we're going to be using a neural net, but instead of having a different neural net for each conditional probability.",
            "Now because we have these hidden units we can share.",
            "The representations that we've learned for other earlier predictions in coming up with the next prediction.",
            "So this is very different from a normal recurrent net because in the normal recurrent net there is this kind of translation in variance.",
            "In other words, we're assuming that what's the parameters that are good to predict the next.",
            "A time step are also good to predict the one after and the one after this.",
            "It doesn't matter.",
            "We can take the data and then translate it and the properties of those conditional distributions remain the same, but here the pixels could be, you know.",
            "I mean the X one X2 X could be anything like any random variable.",
            "There's no, there's no equivalent of.",
            "I can translate and keep the semantics, so the parameters of the conditionals for predicting the third one would be different from the ones for predicting the 4th one.",
            "Now here we have the same thing, but we can share because when we make say the prediction for X3 given X1 and X2, we extract some intermediate features that are hidden units.",
            "And we could use these to predict X4.",
            "Well there should be an arrow here.",
            "Again, going from H22P of X4.",
            "So."
        ],
        [
            "A little bit later in 2011, Hugo, whom you've heard on Monday, came up with a variation on this idea, which makes the computation.",
            "Very efficient and also.",
            "The statistical representation more efficient, so there's less parameters because and by introducing a form of sharing that we didn't have, so the idea here is that.",
            "The weights that go from X1 to a first group of hidden units will be the same as those that go from X1 to another group of units at corresponding to the prediction you want to make in the future, and so in this way you have less parameters and you can also organize computations so that it's actually more efficient by reusing the computation that you've already made for the earlier time steps, and you just have to add the new terms when you consider the next prediction.",
            "Say I now consider X3 as an extra input.",
            "I don't need to redo the additions corresponding to the previous ones.",
            "I just consider the new input an add an extra term to the sum so computation can be very efficient now very efficient compared to previous models, But it's still very inefficient on like a GPU because there's still very very sequential for each for each input and reach output we have to do a little bit of computation, so it's kind of harder to parallelize, but these kinds of models actually quite we're quite well an recently people have."
        ],
        [
            "Using this style of modeling images.",
            "And they're called pixel RNS.",
            "And basically these works surprisingly well, so it's kind of disappointing for people like me.",
            "We've been working on generative models with latent variables that these graphical models without any latent variables.",
            "So it's just like a big recurrent net, essentially with a particular structure, can generate the next pixel given the previously generated pixels.",
            "So you can organize what's previously generated in various ways.",
            "For example, on the top left you see you just traverse all the rows, and then you predict the next pixel given.",
            "Everything you've seen before.",
            "Or maybe you can organize computation using this kind of triangle where you use only information from the top or like the one on the right.",
            "I mean there are various architectures that you could use, but the point is we define a sequence.",
            "And we have a little recurrent net which summarizes information you've seen in the past of the sequence and is used to predict next pixel, and it's very slow because you have to go through all the pixels one at a time, which is very sequential in order to generate an.",
            "Also when you train, but it does.",
            "It gives pretty nice images when you generate.",
            "It tends to get the local details very good, much better than the kind of.",
            "Deep generative models that have been there before and you will hear about more later.",
            "So it gets things to get texture quite well and you can get pretty sharp and realistic images, at least on the scale it's been done up to now.",
            "Do you think the resource they grow a structure is captured correctly has to do with long term memory, or is it just that there's not enough information to in the data set to learn the global structure?",
            "So I think there is enough information.",
            "I think.",
            "You can interpret the fact that it's not getting global structure as well as other models.",
            "By thinking of.",
            "Anne.",
            "The issue is one of long-term dependencies, but you can also think of it like it would be so much more convenient if you first decide like.",
            "What kind of object is going to be in the image?",
            "And then your global structure would be decided, and then you fill out the details.",
            "So ideally you want to have the two things you want to have.",
            "The ability to decide on the global structure in a kind of heartical way.",
            "But you also need to fill out the details so that the local texture an local parents is well preserved.",
            "Other questions.",
            "OK."
        ],
        [
            "Now.",
            "And let me tell you about the last subject which.",
            "Is a very old subject, which I think is coming back.",
            "There is.",
            "There's an issue with backpropagation through time.",
            "Actually, there are several issues.",
            "Um?",
            "For for those people who care to think about how brains might implement some machine learning algorithms, one issue with backdrop through time is that it requires a form of computation that seems a bit crazy.",
            "You have to go through the whole history.",
            "And you know, in worst case that means you have to go through your whole life.",
            "And then store everything every state of your brain.",
            "Somewhere and then replay it backwards.",
            "And fix things using gradient steps.",
            "And then we live your life better.",
            "OK, I may be exaggerating.",
            "Maybe you could get away with only learning about the dependencies across a single day, but then you know you think that something is missing and maybe maybe at night we're replaying backwards.",
            "The things that are happening during the day, some.",
            "There's some clues suggesting something like this may be happening, but it seems a bit crazy.",
            "And also there's the issue of having to store the full sequence of states.",
            "Because you need to store that somewhere so it's like you have your main state, but you have a memory which isn't part of your state which is used as a control part of the control algorithm where you would store these things.",
            "It's not inconceivable for brains, but again, it's seems a bit of a stretch.",
            "So it would be nice if there were other options.",
            "Also, from a purely AI machine learning point of view, when we start playing with very long sequences and large recurrent Nets, the memory becomes a real bottleneck.",
            "So for example, we've been playing with.",
            "Acoustic signals where say you have 16,000 seven acoustic samples per second per second, yes.",
            "And so the number of time steps grows very fast.",
            "So if you want to do 10 seconds of audio, that's a lot of time steps and you have to store the state of recurrent net for every one of those time steps, so that just not going to fit on your GPU.",
            "For now at least.",
            "So, so that raises the question, are there any other ways to train recurrent Nets besides backdrop through time?",
            "And the answer to this has already been given to some extent in 1989 paper from William Williams and Sipser.",
            "In fact, the idea is much older, and people doing automatic differentiation much before that have already had already solved the problem.",
            "Anne.",
            "And so the idea is that we can compute the gradient.",
            "In a forward way, rather than the backward way, and to see why this is possible, let me use a blackboard.",
            "It also will help to understand why.",
            "For now we don't have a good, efficient way of doing it.",
            "So remember, I told you that the total gradient.",
            "If you consider a sequence like.",
            "Where only at the end we get a loss an we've got now a Jacobian for the first time, step Jacobian for the second time step, Jacobian for the third time step, and so on.",
            "And then we have D LDS.",
            "This is a 0 S 1 S 2 S 3 S 4 so we've got DLD S4 which is a vector right?",
            "So.",
            "If we want to compute, say, the gradients with respect to.",
            "Those weights, what we need is is multiply DL DS4 by DS4DS three times DS3DS2 and so on.",
            "The as 1D S 0 so we have a product of these matrices and we have a vector on one end.",
            "OK, so.",
            "If you think about the computation that is being performed by back prop.",
            "What it does here is you start from the end.",
            "Which is gives you the gradient on the state at the last time step and then you.",
            "Multiply that vector.",
            "By the matrix corresponding to the Jacobian that goes from relates S3 to S4.",
            "So we do a vector times matrix multiplication and then we get a vector and the cost of that operation is a size of that matrix.",
            "So it's let's see if we have N dimension.",
            "This is N ^2.",
            "So we do this N squared vector matrix operation T times.",
            "But we have to do it backwards in time.",
            "But we could get the same result by going forward in time.",
            "By starting from this matrix.",
            "And then by the way, here is this DS0DW.",
            "'cause this is the W we care about.",
            "So we could start with this matrix and then multiplied by this matrix.",
            "This matrix.",
            "This matrix, this matrix and then this vector.",
            "How much would it cost?",
            "Well, now we've got a bunch of matrix multiplications.",
            "How much does it cost to multiply 2 matrices of N squared?",
            "It costs N cube.",
            "So instead of doing N squared computation for each time step, Now we need to do N cube computation for each time step.",
            "In fact, it's worse than that.",
            "Because that matrix here is not N squared, it's end times the number of weights which is itself N ^2.",
            "So this is a.",
            "This is a North by N squared matrix and when we multiply by this N by N matrix.",
            "We get an N. The result of this is going to be an N by N squared again.",
            "And how many computations are we going to do?",
            "We're actually going to be doing N. To the four computation right?",
            "Because for each of the elements here, we're going to have to look at all and here so.",
            "The amount of computation we need here for this is order of N 4, whereas previously we had order of N ^2.",
            "OK, that's really bad.",
            "But we could do it.",
            "In other words, we can compute the gradients by moving forward in time rather than backwards in time we don't have.",
            "We can do this.",
            "Even before we know what the right answer will be.",
            "An anytime we get a right answer.",
            "I mean time we get a loss then we can, we can use it to update the weights.",
            "I'm not doing the full decomposition here.",
            "I'm considering a very simple case where the losses only at the end.",
            "But you can generalize it to the case where the losses at anytime step.",
            "But the point is is like multiplying matrices from right to left versus left or right.",
            "It gets you the same answer, but it's going to be a lot more expensive, yes?",
            "Exactly that.",
            "That's what I said earlier that you know with my differentiation.",
            "People have discovered it well before and so these guys realized without knowing about automatic differentiation, you could do that and you could.",
            "You could thus compute gradients online.",
            "In recurrent net it means as we are considering the next example, if we have kept a memory.",
            "Of where is if we've kept in memory of DSTDW, we can just update this.",
            "An multiplied by at anytime by the loss AT with respect to St. An that will give us the component of the gradient due to the loss at T, and we can make an update.",
            "In other words that will tell us this product will tell us how.",
            "All the past states, the influence of the weights on all the past states.",
            "He's leading us to this particular loss and how we should change the weights so that for this particular loss we make less of an error.",
            "And so we could just go forward online as they called it.",
            "The problem is that it's just too expensive and it's not even biologically plausible, because storing this means storing.",
            "This matrix this is a huge, it's a tensor, right?",
            "So for each neuron you have to consider all the possible weights, not just the weights entering that neuron.",
            "But all the weights.",
            "Right, that's the thing that's not, that's crazy.",
            "Now there is some good news recently.",
            "Jan Olivier in France and his collaborators have come up with a method to approximate that matrix.",
            "These state D parameters.",
            "So this is a huge thing you don't even want to store it, so they have a low rank representation of that made of that tensor which has the property that in expectation.",
            "So it's a stochastic estimator of that matrix.",
            "It's a low rank stochastic estimator, meaning that in expectation it is the right value.",
            "And they have a random way of choosing things so that in average over these randomness they get the right tensor, and it's never represented directly is represented as a product of 2 low rank matrices, right?",
            "So.",
            "This this idea that we might be able to actually do online learning in recurrent net is really is coming back and might be something to watch for in the future.",
            "Alright I need to stop here and take any more questions you have."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So recurrent neural Nets you might not know, but was one of my first loves.",
                    "label": 0
                },
                {
                    "sent": "During my PhD I worked on recurrent Nets and I worked on sequences and I got very excited about them and then as I played more with recurrent Nets, I realized there was something wrong that I was trying to learn some things and they didn't want to learn them and I was frustrated and I tried to figure out why.",
                    "label": 0
                },
                {
                    "sent": "And that's how I came to publish this work that I'll tell you about regarding the difficulty for recurrent Nets too long, long term dependencies and.",
                    "label": 0
                },
                {
                    "sent": "An everything we've learned about how information propagates through recurrent Nets.",
                    "label": 0
                },
                {
                    "sent": "Some of it applies also to the difficulty of training deep Nets in general, so hopefully you'll come out of this lecture with more understanding of recurrent Nets, but also of some issues that apply to other kinds of deep learning.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "People draw pictures for recurrent Nets in two different ways.",
                    "label": 0
                },
                {
                    "sent": "So what you see on the left is the way the kind of drawing that people used to draw in the 80s and 90s where people were thinking about circuits and neurons.",
                    "label": 0
                },
                {
                    "sent": "So the little black square here means that there is a delay in the connection from the state at some time to its next value.",
                    "label": 0
                },
                {
                    "sent": "In other words, the units are connected to each other, but through a deley.",
                    "label": 0
                },
                {
                    "sent": "And So what we can do to better understand what is going on?",
                    "label": 0
                },
                {
                    "sent": "What is the computation that's happening and also to implement back propping these things is to draw the kind of pictures on the right side where we say we are unfolding the network.",
                    "label": 0
                },
                {
                    "sent": "So we're considering the state of the network at every discrete time step.",
                    "label": 0
                },
                {
                    "sent": "And now we see that the state at time T depends on two things.",
                    "label": 0
                },
                {
                    "sent": "It depends on the current inputs AXT and the previous state S T -- 1.",
                    "label": 0
                },
                {
                    "sent": "So we can write an equation like the one above that says the state of time T is at parameterized function.",
                    "label": 0
                },
                {
                    "sent": "So F Theta here is parameterized function.",
                    "label": 0
                },
                {
                    "sent": "We want to learn those parameters that combines information coming from the previous state and the current input.",
                    "label": 0
                },
                {
                    "sent": "And of course this kind of equation is very common when you study dynamical systems, whether it's for machine learning or other purposes.",
                    "label": 0
                },
                {
                    "sent": "Now, one thing you have to realize is that you can also think about unfolding in an algebraic sense.",
                    "label": 0
                },
                {
                    "sent": "So at the top we have sort of the equivalent of the left hand picture, where we're thinking about you know how a state is updated at each time step in the bottom equation, where oh test equals GT of all the past sequence in.",
                    "label": 0
                },
                {
                    "sent": "We're kind of thinking about the unfolded computation, where this GT is just the function obtained by composing F over and over again.",
                    "label": 0
                },
                {
                    "sent": "And so we see that the state at particular time is a function of all the pasts.",
                    "label": 0
                },
                {
                    "sent": "But if this is interesting from machine learning point of view, because if you wanted to learn G directly.",
                    "label": 0
                },
                {
                    "sent": "In other words, if you parameterise the learning system in terms of some imagine G is some machine learning system that tries to predict the next state.",
                    "label": 0
                },
                {
                    "sent": "The problem with this would be that you would need a different G for every length right for every position you have a different G because it has a different number of inputs and.",
                    "label": 0
                },
                {
                    "sent": "It would be hard to generalize to new lengths.",
                    "label": 0
                },
                {
                    "sent": "Of course, with a recurrent net, an parameterized dynamical system like on the top, you don't have this problem.",
                    "label": 0
                },
                {
                    "sent": "You will naturally generalize to new lengths and within even the same sequence because we're sharing parameters across time.",
                    "label": 0
                },
                {
                    "sent": "Things you learn at a particular time, sort of.",
                    "label": 0
                },
                {
                    "sent": "Our combined with things you learn at other times through the shared parameters.",
                    "label": 0
                },
                {
                    "sent": "So you basically have a very compact representation.",
                    "label": 0
                },
                {
                    "sent": "Now when you do that, of course you're making some assumptions.",
                    "label": 0
                },
                {
                    "sent": "You're assuming the same kind of computation can be applied at every time step an.",
                    "label": 0
                },
                {
                    "sent": "You may imagine cases where you really depending on the value of T you would like to have a different computation.",
                    "label": 0
                },
                {
                    "sent": "However, the good news is that if your state is rich enough, then you can always sort of emulate that kind of thing.",
                    "label": 0
                },
                {
                    "sent": "So imagine that one of the components of the state is T, so you know you have, say, a unit that just increments by one at every time step, and so you're going to have T as as.",
                    "label": 0
                },
                {
                    "sent": "Implicit argument basically, and you can.",
                    "label": 0
                },
                {
                    "sent": "You can, if you have enough capacity in this F data, you can basically emulate any GT.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so of course.",
                    "label": 0
                },
                {
                    "sent": "Once we regard the computation through this unfolded graph, it's very easy to apply all the things we've heard about regarding backdrop.",
                    "label": 0
                },
                {
                    "sent": "It's just like a very special kind of architecture where instead of having inputs coming just on one side, they coming one piece at a time and influencing the intermediate states.",
                    "label": 0
                },
                {
                    "sent": "In the example here, notice that we have an input sequence, an output sequence, and both the input sequence and output sequence have the same length.",
                    "label": 0
                },
                {
                    "sent": "So this is one of those special cases that people have applied recurrent Nets for.",
                    "label": 0
                },
                {
                    "sent": "This is, for example when I was doing my thesis and I was doing phoneme recognition.",
                    "label": 0
                },
                {
                    "sent": "While you have acoustic frames, as the ex is and the others were phoneme classes or things like that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there is another kind of recurrent net architecture which is very important to understand and very commonly used these days.",
                    "label": 0
                },
                {
                    "sent": "It's the kind in which the.",
                    "label": 0
                },
                {
                    "sent": "Outputs also feedback as extra inputs.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, we can make it probabilistic interpretation of what is being computed as a directed graphical model that is fully connected in some sense and fully observable.",
                    "label": 0
                },
                {
                    "sent": "So what do I mean here?",
                    "label": 0
                },
                {
                    "sent": "So now think about the owes.",
                    "label": 0
                },
                {
                    "sent": "Is the output at each time step is representing a probability distribution, for example the probabilities for each of the symbols that X can take.",
                    "label": 0
                },
                {
                    "sent": "At each time step, and then what we're going to be doing is we're going to be.",
                    "label": 0
                },
                {
                    "sent": "Able to use a recurrent net to generate a sequence so the dotted arrows here in this figure mean that we're going to sample when we use the recurrent net in its generative mode is going to be just free running.",
                    "label": 0
                },
                {
                    "sent": "It's going to produce its own inputs, so at time T is going to produce a probability distribution over the random variable X T + 1 given all the previous ones, and we're going to be able to draw samples.",
                    "label": 0
                },
                {
                    "sent": "For example, pick egg the next character.",
                    "label": 0
                },
                {
                    "sent": "Given the distribution represented by OT, so you can imagine OT being a softmax over all the symbol values, and we draw particular symbol and now that becomes the next input.",
                    "label": 0
                },
                {
                    "sent": "Now I talked about symbols, but those could be vectors, real vectors.",
                    "label": 0
                },
                {
                    "sent": "It could be any kind of random variables.",
                    "label": 0
                },
                {
                    "sent": "So what are we doing here when we train this with maximum likelihood is we're saying were given a sequence X one to XT Ann?",
                    "label": 0
                },
                {
                    "sent": "Would like that our network gives a high probability to that sequence.",
                    "label": 0
                },
                {
                    "sent": "We can decompose the joint probability of the sequence X one to XT as a product of conditionals, so that's what you see on the on the right hand side of the equation on the top.",
                    "label": 0
                },
                {
                    "sent": "Each conditional is of the form P of the next symbol or the next observation.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to be symbol.",
                    "label": 0
                },
                {
                    "sent": "Given all the previous ones and of course we multiply all these probabilities and you know that's just standard decomposition of a joint into a product of conditionals, where the order here is the temporal order, that is usually a natural thing to consider for sequential data.",
                    "label": 0
                },
                {
                    "sent": "So the training objective will just be the minus the log of the thing on the top, which means that it's the sum of negative log probabilities for these conditionals.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to predict the actually observed next symbol given all the previous symbols.",
                    "label": 0
                },
                {
                    "sent": "And we maximize the probability of getting that thing right.",
                    "label": 0
                },
                {
                    "sent": "So it's just like a classification problem.",
                    "label": 0
                },
                {
                    "sent": "At each time step.",
                    "label": 0
                },
                {
                    "sent": "And of course, replace classification by regression if it's real valued or any other kind of types of random variable.",
                    "label": 0
                },
                {
                    "sent": "So that's the sense in which a recurrent Nets can be thought about as a generative model.",
                    "label": 0
                },
                {
                    "sent": "And if you think about it now in terms of graphical models, for those of you know bit about that we have thinking what you see is that there are no latent variables, or at least no stochastic LinkedIn variables that you can think of the S as very special kinds of latent variables.",
                    "label": 0
                },
                {
                    "sent": "But there are deterministic functions of everything else, so the essays are deterministic functions of the previous.",
                    "label": 0
                },
                {
                    "sent": "As of the previous access through the equation, we.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Saw in the previous slides, right?",
                    "label": 0
                },
                {
                    "sent": "So the St here is a completely deterministic function of all the previous axes.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you can actually think of this as a in different ways from a graphical model point of view.",
                    "label": 0
                },
                {
                    "sent": "But if we ignore the S as latent variables because they are kind of deterministic, then it's a fully observed model where.",
                    "label": 0
                },
                {
                    "sent": "Which means that we can just apply maximum likelihood in very simple ways and compute the tractable gradient, and everything is easy and simple, and we can model the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "You can also think of the SSS latent variables, but as I said, there are deterministic and the role they play is to make the graphical model both statistically and computationally more tractable.",
                    "label": 0
                },
                {
                    "sent": "So what you notice is that through this through this equation that defines S in terms of the previous X is.",
                    "label": 0
                },
                {
                    "sent": "You actually have a full dependency of all the previous axes conditioning the next one, so it's not a graphical model where we have removed any of the arcs.",
                    "label": 0
                },
                {
                    "sent": "It's a fully connected directed graphical model, right?",
                    "label": 0
                },
                {
                    "sent": "So there's no assumption, no conditional independence assumption.",
                    "label": 0
                },
                {
                    "sent": "You can model any distribution.",
                    "label": 0
                },
                {
                    "sent": "However, in general, for graphical model you think that if you had this fully connected thing, it would be very expensive.",
                    "label": 0
                },
                {
                    "sent": "The number of parameters could blow up, and the computation could blow up in terms of the length of the sequence.",
                    "label": 0
                },
                {
                    "sent": "But because we have introduced these intermediate quantities, the S is.",
                    "label": 0
                },
                {
                    "sent": "States actually the parametrization is compact, it's just the status for each time step as well as the computation is cheap, right?",
                    "label": 0
                },
                {
                    "sent": "The computation doesn't grow at each time step in terms of the length of the sequence is always the same cost, so this is a very kind of efficient parametrization parametrization of a joint distribution.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, we can play all kinds of games with these recurrent Nets and the first of all.",
                    "label": 0
                },
                {
                    "sent": "Of course we can think of mapping different kinds of objects to different kinds of objects, like for example we can on the top right here.",
                    "label": 0
                },
                {
                    "sent": "What we see is a recurrent net that reads a sequence and then outputs evector.",
                    "label": 0
                },
                {
                    "sent": "So you can go Mapa sequence to a vector and sometimes you have applications where this is what you want.",
                    "label": 0
                },
                {
                    "sent": "We've already seen the case of mapping a sequence to sequence with the two sequences are aligned.",
                    "label": 0
                },
                {
                    "sent": "This was one of the earlier pictures and I guess that's the one on the right.",
                    "label": 0
                },
                {
                    "sent": "The second one on the right, the third example, which I'm assuming that I don't know.",
                    "label": 0
                },
                {
                    "sent": "The third example is vector to sequence, so here we can generate a sequence so it's the same picture as we had just in the previous slide where we can produce a sequence in a stochastic sense where we could sample from that sequence.",
                    "label": 0
                },
                {
                    "sent": "We and.",
                    "label": 0
                },
                {
                    "sent": "And but, however, we're going to condition all of the transitions on some vector, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the if you see the my pointer here, there's another pointer.",
                    "label": 0
                },
                {
                    "sent": "No 2.",
                    "label": 0
                },
                {
                    "sent": "Anyways, the thing on the left hand side here would be a conditioning variable that's going to influence every one of the transition.",
                    "label": 0
                },
                {
                    "sent": "So now you're basically modeling P of an output sequence.",
                    "label": 0
                },
                {
                    "sent": "Given an input vector and then the one in the bottom is a sequence to sequence case where the two sequences don't have to be the same length.",
                    "label": 0
                },
                {
                    "sent": "They could be even of different types, and for example this is a model that's being used early on for machine translation.",
                    "label": 0
                },
                {
                    "sent": "Where you have an input sequence and an output sequence, and So what happens here is that you have two parts to this you have reading the input sequence that creates a representation through a summary of the whole input sequence in the state, and then then we're going to generate an output sequence using the same generative model, but it's now conditioned on the state that we got as a result of summarizing the input sequence.",
                    "label": 0
                },
                {
                    "sent": "Any question about these things.",
                    "label": 0
                },
                {
                    "sent": "Alright, good now.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I told you that we can train these recurrent Nets by maximum likelihood.",
                    "label": 1
                },
                {
                    "sent": "This is also called teacher forcing.",
                    "label": 1
                },
                {
                    "sent": "This name came before people thought that we were actually doing maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "And there's a good reason for this name, so let's try to figure that's trying to see what's happening when we train in the maximum likelihood way you can think of it like this.",
                    "label": 0
                },
                {
                    "sent": "There are two kinds of computations that need to be considered when we train in this way.",
                    "label": 0
                },
                {
                    "sent": "There is the the kind of computation we're doing when we train, and the kind of computation that we do when we use the model to generate a sequence.",
                    "label": 0
                },
                {
                    "sent": "Alright, so whether it's conditional or not doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "So what you see in the picture with the?",
                    "label": 0
                },
                {
                    "sent": "So there are two kinds of dotted.",
                    "label": 0
                },
                {
                    "sent": "There's the dashed and dotted right, so the.",
                    "label": 0
                },
                {
                    "sent": "The dash is the what happens during training.",
                    "label": 0
                },
                {
                    "sent": "So in other words, during training we have targets for the outputs.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we know what the ground truth next output next observation should be.",
                    "label": 0
                },
                {
                    "sent": "So given the past ground truth, we are trying to predict the next element of the ground truth sequence and so the thing that we're going to be feeding in as input for the next time step is that you know observed Whitey.",
                    "label": 0
                },
                {
                    "sent": "Coming from the data.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, at Test time we're going to be.",
                    "label": 0
                },
                {
                    "sent": "Of course, we don't have any ground throws at Test time.",
                    "label": 0
                },
                {
                    "sent": "We're going to use the output of the model.",
                    "label": 0
                },
                {
                    "sent": "The sample from the conditional distribution of the Y given the current state.",
                    "label": 0
                },
                {
                    "sent": "So we have these two kinds of loops now they could coincide, but they could also be different and you could easily imagine a situation where there would be different when the kinds of sequences that the model has learned to generate isn't quite like the kinds of sequences in your training set.",
                    "label": 0
                },
                {
                    "sent": "In fact, in general this is going to be the case.",
                    "label": 0
                },
                {
                    "sent": "We never have a perfect model, right?",
                    "label": 0
                },
                {
                    "sent": "So if it was a perfect model, it would only generate sequences like those in the training set, but it's not going to be the case in practice, so there's going to be discrepancy.",
                    "label": 0
                },
                {
                    "sent": "Between the kinds of of data that's fed in as input.",
                    "label": 0
                },
                {
                    "sent": "In other words, what the recurrent net sees as the conditioning input when it's training versus when it's being used to generate symbols, and that discrepancy is kind of mismatch, which means that it could be that the network is essentially doing something completely weird and wrong when it's being used.",
                    "label": 0
                },
                {
                    "sent": "So this let me give you.",
                    "label": 0
                },
                {
                    "sent": "A sort of analogy to understand how badly could be so.",
                    "label": 0
                },
                {
                    "sent": "Imagine that what the network is doing is learning to drive a car, which is today a very you know.",
                    "label": 0
                },
                {
                    "sent": "Important application of deep learning.",
                    "label": 0
                },
                {
                    "sent": "So let's say that the way we train our network to drive a car is we have a human driver car and then we just wait till the network to predict what's the next.",
                    "label": 0
                },
                {
                    "sent": "You know position of the driving direction.",
                    "label": 0
                },
                {
                    "sent": "Given the observations and the past driving directions, and you know if the network train learns to perfectly imitate the moves of the human, it might be fine.",
                    "label": 0
                },
                {
                    "sent": "But let's say that it makes small mistakes and at some point it actually gets the car slightly off of the center of the road, and it's now, you know, at a place where humans have never been, because humans know that they shouldn't.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't be so close to the border, and now the car is seeing a kind of input that it has never seen.",
                    "label": 0
                },
                {
                    "sent": "And you know, maybe you're lucky and it generalizes well and goes back towards the middle.",
                    "label": 0
                },
                {
                    "sent": "Or maybe you're not lucky.",
                    "label": 0
                },
                {
                    "sent": "And it goes even more to the right, and it goes out of the road, right?",
                    "label": 0
                },
                {
                    "sent": "So the problem is that it's going to see input configurations when it's generating, when it's acting on itself.",
                    "label": 0
                },
                {
                    "sent": "That may be very different from the one that's on during training, because the human driver of course doesn't visit these bad states that you might see when the model is actually running by itself.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the this is a history of machine learning approaches to try to deal with this and a lot of it is inspired from issues.",
                    "label": 0
                },
                {
                    "sent": "Similar issues happening in reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "An I'm not going to go in detail into these, but one of the recent ideas that is having some success is called scheduled sampling and it bears relation to earlier work, hold Cernan, Dagger and the idea is we're going to be sort of trying to make the network see the kinds of inputs that it would generate itself during training, so that knows to kind of go back to the right.",
                    "label": 0
                },
                {
                    "sent": "You know the middle of the road.",
                    "label": 0
                },
                {
                    "sent": "The kinds of things that the human would do.",
                    "label": 0
                },
                {
                    "sent": "The teacher would do so.",
                    "label": 0
                },
                {
                    "sent": "In other words, the idea is that.",
                    "label": 0
                },
                {
                    "sent": "Instead of of of picking the ground truth as inputs while we train with some probability, we're going to pick the ground truth and with some probability we're going to pick the sample coming from the output of the model, and it turns out that it's actually wrong to do that from a. Sining point of view that this procedure doesn't actually learn the right thing, but it's reasonable to believe, and I don't have any proof of that, but it seems reasonable that if we, if we make that probability of choosing one or the other, gradually decrease towards 0, not in the sense that it ends up just listening to the ground truth, then, then you'd be OK, and it would have some kind of exposure to the kinds of things that kinds of situations that it would see when it drives by itself.",
                    "label": 0
                },
                {
                    "sent": "Right, so one interesting question.",
                    "label": 0
                },
                {
                    "sent": "There's something wrong in this and you take some time to go.",
                    "label": 0
                },
                {
                    "sent": "And really understand it.",
                    "label": 0
                },
                {
                    "sent": "But one way to think about it is imagined that we run the network in its training using the ground truth, and then we let it run by itself for a few steps, right?",
                    "label": 0
                },
                {
                    "sent": "So it's what we call open loop, so it just takes it output and feeds it as input an it might go in a strange place, and in particular the place where it goes might not the right answer for the state where it ends up might not be the one that you have in your ground through sequence, so if you.",
                    "label": 0
                },
                {
                    "sent": "Go back to the driving example.",
                    "label": 0
                },
                {
                    "sent": "Maybe the driver was staying straight in the middle and.",
                    "label": 0
                },
                {
                    "sent": "If if the car decided to go a bit to the right, now the right action would be to go back to the middle.",
                    "label": 0
                },
                {
                    "sent": "But maybe because the ground truth was staying in the middle, it says you know you stay in the middle or even go a bit to the right because he was gone a bit to the left and so so these could be inconsistent targets that were giving to this network.",
                    "label": 0
                },
                {
                    "sent": "So so you know the question is really, how should we train this?",
                    "label": 0
                },
                {
                    "sent": "And one idea I had when I wrote those slides was that, well, we don't actually want to match the.",
                    "label": 0
                },
                {
                    "sent": "The ground truth target a few steps later what we want to do is to match the ground truth in distribution, and so maybe something like again, which you will hear about and you've heard a little bit already about yesterday.",
                    "label": 0
                },
                {
                    "sent": "Might be a good way to deal with this problem.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me talk more about some architecture variations.",
                    "label": 0
                },
                {
                    "sent": "So up to now, I haven't really looked into how we structure the architecture of the neural net, but what you see on the left here is sort of the vanilla architecture that we've been talking about.",
                    "label": 0
                },
                {
                    "sent": "We could we could think of in several researchers and papers of proposed different ways of making this kind of architecture deeper for each time step, so you can do that in various ways.",
                    "label": 0
                },
                {
                    "sent": "So one of the first ways that was proposed, believed by Alex Graves, is the one on the bottom left, called stacking.",
                    "label": 0
                },
                {
                    "sent": "Where essentially we're going to decompose the state into different levels.",
                    "label": 0
                },
                {
                    "sent": "So here we call one level they choose and the other the Zeds.",
                    "label": 0
                },
                {
                    "sent": "But you could imagine having many more levels and typically people will have like even 10 levels like in normal deep Nets, so not what happens is that for a given input XT there will be like a deep network of feed forward.",
                    "label": 0
                },
                {
                    "sent": "If you want recurrent net going up to all the layers of the recurrent net, but.",
                    "label": 0
                },
                {
                    "sent": "At each of these layers, like the HD for example, it not only depends on the current input, but the previous layer, but also on the previous value of that levels state.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the stacking version.",
                    "label": 0
                },
                {
                    "sent": "Another way that you could increase depth is to think about making the transition from one state to the next day deeper instead of having a single affine followed by non linearity for going from ST2ST plus one you could get insert like an MLP for example like in the picture in the middle.",
                    "label": 0
                },
                {
                    "sent": "And similarly, the mapping between state and outputs could be deeper, right?",
                    "label": 0
                },
                {
                    "sent": "So you could again insert one or more hidden layers.",
                    "label": 0
                },
                {
                    "sent": "Now there is a problem with this that I should have put the.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, there's I clear 2004.",
                    "label": 0
                },
                {
                    "sent": "So we had a paper about this.",
                    "label": 0
                },
                {
                    "sent": "There's an issue when you insert the.",
                    "label": 0
                },
                {
                    "sent": "When you insert an extra layer from T to T + 1 is that it somehow makes training more difficult because the length of the sequences to be considered is not like doubled.",
                    "label": 0
                },
                {
                    "sent": "And so we inserted the little skip connection.",
                    "label": 0
                },
                {
                    "sent": "Here that goes directly from T -- 1 two T as well as the.",
                    "label": 0
                },
                {
                    "sent": "You know, in addition to the extraordinarily extra layer in between.",
                    "label": 0
                },
                {
                    "sent": "That's connected to the problem of long-term dependencies, which I'll come to.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a few minutes.",
                    "label": 0
                },
                {
                    "sent": "And also sort of think out of the box and.",
                    "label": 0
                },
                {
                    "sent": "Expand The kinds of architectures from recurrent Nets to other kinds of structures that are not really corresponding to a chain, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "So in the case of the recurrent net, you basically have the extended.",
                    "label": 0
                },
                {
                    "sent": "The unfolded graph is basically a chain, but you could imagine other kinds of things.",
                    "label": 0
                },
                {
                    "sent": "For example, you could have a tree, and these are called recursive networks, and they've been studied in the 90s and more recently by Richard Socher and a bunch of papers where he applied them to both the natural language and images.",
                    "label": 0
                },
                {
                    "sent": "Another a kind of architecture, is the bidirectional recurrent net, so this is the one on the top right where you have two recurrent Nets, one going from the past to the future and one going from the future of the past.",
                    "label": 0
                },
                {
                    "sent": "And then you think of the concatenation of the state at each time step as a representation for the whole sequence, right?",
                    "label": 0
                },
                {
                    "sent": "Because?",
                    "label": 0
                },
                {
                    "sent": "If you think about it, the state in the say left going.",
                    "label": 0
                },
                {
                    "sent": "RNN summarizes everything from the future.",
                    "label": 0
                },
                {
                    "sent": "At a particular point and the state in the right, going RN at the same time point.",
                    "label": 0
                },
                {
                    "sent": "Summarizes everything from the past, so now if I concatenate these two states, I have a representation which contains information about the whole sequence, and this is true at every time step.",
                    "label": 0
                },
                {
                    "sent": "So now what we have, if we take those two concatenated States and we do something with them like we compute a new representation is we have a representation.",
                    "label": 0
                },
                {
                    "sent": "We have a feature extraction which depends on the whole sequence at every time step.",
                    "label": 0
                },
                {
                    "sent": "So we're extracting features at every time step which.",
                    "label": 0
                },
                {
                    "sent": "Basically, we'll focus more on what's happening in the neighborhood of times that, but could be influenced by everything.",
                    "label": 0
                },
                {
                    "sent": "So in other words, you can think of it like.",
                    "label": 0
                },
                {
                    "sent": "It's a context dependent feature extraction like the normal feature extraction.",
                    "label": 0
                },
                {
                    "sent": "We look at one time step or a fixed size window and we get some features.",
                    "label": 0
                },
                {
                    "sent": "But now we have features that of course will tend to tell you more about what's happening in the particular place, but they will be sort of influenced by potentially everything.",
                    "label": 0
                },
                {
                    "sent": "The whole sequence.",
                    "label": 0
                },
                {
                    "sent": "Now of course one problem with this is we lost the causality.",
                    "label": 0
                },
                {
                    "sent": "In other words, we can't.",
                    "label": 0
                },
                {
                    "sent": "For example, we can't use this to generate the inputs, because we would be using the future to generate itself, which doesn't make any sense.",
                    "label": 0
                },
                {
                    "sent": "But we could use this as a preprocessing to extract information from a sequence.",
                    "label": 0
                },
                {
                    "sent": "So when, for example we are mapping a sequence to sequence.",
                    "label": 0
                },
                {
                    "sent": "Or sequence to anything else.",
                    "label": 0
                },
                {
                    "sent": "This kind of architecture is very useful.",
                    "label": 0
                },
                {
                    "sent": "It has become even a standard for many applications.",
                    "label": 0
                },
                {
                    "sent": "There's another kind of expansion extension of recurrent Nets, which is interesting, maybe less used as the binder.",
                    "label": 0
                },
                {
                    "sent": "I would say the bidirectional Nets are the most commonly used these days, But another interesting direction is basically everything that works for 1D can be extended to 2D or 3D pretty naturally, right?",
                    "label": 0
                },
                {
                    "sent": "So instead of having a chain that goes left to right, you can imagine that you have, say, a 2D plane.",
                    "label": 0
                },
                {
                    "sent": "And that's really useful for images, and we've done things with that.",
                    "label": 0
                },
                {
                    "sent": "Where at each position you now have a state.",
                    "label": 0
                },
                {
                    "sent": "So at each idea position you have a state and that state depends on the state at.",
                    "label": 0
                },
                {
                    "sent": "You know the one on the left, the state on the left.",
                    "label": 0
                },
                {
                    "sent": "So at my I -- 1 J and the one above.",
                    "label": 0
                },
                {
                    "sent": "So that's I J -- 1.",
                    "label": 0
                },
                {
                    "sent": "So that creates kind of grid where you can actually compute any state by traversing the grid in some reasonable order like diagonals or something.",
                    "label": 0
                },
                {
                    "sent": "And of course, you can then backdrop and do everything that you want, so you can generalize this chain idea to 2D or 3D structures.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah you can.",
                    "label": 0
                },
                {
                    "sent": "You can play with the parameterization, so one of the things we've done recently is instead of having the state being in the find function of the previous state and input, we can introduce some gating or multiplicative interactions.",
                    "label": 0
                },
                {
                    "sent": "So this this dot with a circle is just elementwise multiplication.",
                    "label": 0
                },
                {
                    "sent": "Or some more general form where you now introduce more multiplicative interactions and somehow this can actually help to learn some things without increasing the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "So these these these gating or multiplicative types of computations being useful in many instances you'll see this week and this is just one example.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now let me go to probably the most important part of my presentation, which is about the issue with training recurrent Nets and why in particular learning about long-term dependencies is difficult is fundamentally difficult.",
                    "label": 1
                },
                {
                    "sent": "So this is a summarizing paper that came out in 90 four and I started working on this around 1990.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to tell you more about this so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In 91 when I was at MIT I I was trying to understand why my recurrent Nets that I had used for speech recognition weren't learning those long term dependencies.",
                    "label": 1
                },
                {
                    "sent": "I really didn't have that concept.",
                    "label": 0
                },
                {
                    "sent": "Clearly in my mind, but I was trying to understand what.",
                    "label": 0
                },
                {
                    "sent": "Why is it that sometimes it doesn't learn and so I tried to reduce the problem to very simple case which is a single neuron.",
                    "label": 0
                },
                {
                    "sent": "OK Anna single neuron trying to learn to store 1 bit of information.",
                    "label": 0
                },
                {
                    "sent": "I think you can't have simpler than that.",
                    "label": 0
                },
                {
                    "sent": "And I found that even that really stupid simple task.",
                    "label": 0
                },
                {
                    "sent": "The network would fail to learn it if it had to remember that piece of information for a long time.",
                    "label": 0
                },
                {
                    "sent": "And then it didn't tell it that it had to learn it until the end of the sequence.",
                    "label": 0
                },
                {
                    "sent": "So so the input would be something like this.",
                    "label": 0
                },
                {
                    "sent": "So either.",
                    "label": 0
                },
                {
                    "sent": "The first input was large or the 1st three inputs were large, or they were small, so it's a binary information.",
                    "label": 0
                },
                {
                    "sent": "Then there was noise and then only at the end of the sequence I would tell the recurrent net what the right answer should be, which is basically output A1 if the initial input was large and output a zero if the initial input was low, and if I trained this with a target coming soon after.",
                    "label": 0
                },
                {
                    "sent": "So for short sequence like say 5 or 10.",
                    "label": 0
                },
                {
                    "sent": "Time steps it would work fine, but if I went to like 2030 and you know like 50 now the probability of successfully learning a task went down to like 5% or something.",
                    "label": 0
                },
                {
                    "sent": "It basically didn't work most of the time and I was very surprised because this should be very easy task.",
                    "label": 0
                },
                {
                    "sent": "So what was going on?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to understand what was going on.",
                    "label": 0
                },
                {
                    "sent": "It's good to go back to basic notions about dynamical systems, because if you think about that little situation, what we have is we have this dynamical system.",
                    "label": 0
                },
                {
                    "sent": "We started in a particular place, so either with the input being large or the input being high, and so we want to keep that information we want to remember in the state that the initial state was either in some region, so we started in the region corresponding to.",
                    "label": 0
                },
                {
                    "sent": "To a high value or we start in the region corresponding to.",
                    "label": 0
                },
                {
                    "sent": "Sorry, low value or corresponding to a high value and then we follow the dynamics.",
                    "label": 0
                },
                {
                    "sent": "So in the state space here I imagine this is a 2D state space.",
                    "label": 0
                },
                {
                    "sent": "Actually in my example it's a 1D space space.",
                    "label": 0
                },
                {
                    "sent": "What happens is that the network will follow the dynamics we like.",
                    "label": 0
                },
                {
                    "sent": "Follow some errors so you can imagine that every position you have arrows and these arrows will tend to bring the system towards some regions.",
                    "label": 0
                },
                {
                    "sent": "We call these regions attractors.",
                    "label": 0
                },
                {
                    "sent": "And in particular, you could imagine the simple case where it's a fixed point attractor.",
                    "label": 0
                },
                {
                    "sent": "So there's one place where it wants to go from anywhere you start, and the regions in which the dynamics would lead into the attractor, or called the basins of attractions of these tractors.",
                    "label": 0
                },
                {
                    "sent": "And so there is a boundary between those basins of attraction.",
                    "label": 1
                },
                {
                    "sent": "If you start on one side that boundary, you will tend to go to the this attractor.",
                    "label": 0
                },
                {
                    "sent": "If you start on the other side, you will tend to go to that attractor.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "There are a few interesting things here.",
                    "label": 0
                },
                {
                    "sent": "First of all, from the point of view of the size of the gradients, there's something really funny happening around the boundary region, because if I move by epsilon going from one side of the boundary to the other side of the boundary, the result at the end of the sequence will be very, very different.",
                    "label": 0
                },
                {
                    "sent": "So the derivative of the state at the end of the sequence with respect to the state at the beginning of the sequence will blow up, right?",
                    "label": 0
                },
                {
                    "sent": "In other words, a small change at the beginning becomes a huge change at the end.",
                    "label": 0
                },
                {
                    "sent": "And of course there are other cases we have things like this with fractal dynamics and so on.",
                    "label": 0
                },
                {
                    "sent": "But even in the simple case like this, you see that you might end up with very large derivatives, so these gradient explosion might happen in this case.",
                    "label": 0
                },
                {
                    "sent": "There's another thing.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "That this is a property of of these basins of attraction is that inside the basin of attraction, and in particular near the attractor the derivatives of the dynamics function.",
                    "label": 0
                },
                {
                    "sent": "The function that Maps states to next state.",
                    "label": 0
                },
                {
                    "sent": "Have particular property that essentially the derivatives are less than one, so there is less than one means that we see the map is contractive, meaning it takes 2 nearby points to two points that are even closer.",
                    "label": 0
                },
                {
                    "sent": "So the map is either contractive or it's expanding, right?",
                    "label": 0
                },
                {
                    "sent": "So if it's expanding means it means it takes 2 points and Maps them slightly even further from each other and actually in different directions.",
                    "label": 0
                },
                {
                    "sent": "The answer might be different.",
                    "label": 0
                },
                {
                    "sent": "Right, and that corresponds to the.",
                    "label": 0
                },
                {
                    "sent": "The eigenvalues of the map.",
                    "label": 0
                },
                {
                    "sent": "So if you have the Jacobian of the map.",
                    "label": 0
                },
                {
                    "sent": "So if you think about that transformation from T + 1 as a function, it has a Jacobian matrix.",
                    "label": 0
                },
                {
                    "sent": "And Jacobian matrix has single values or eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Either way, the important question to ask about those eigenvalues is in magnitude.",
                    "label": 0
                },
                {
                    "sent": "Are they less than one or greater than one?",
                    "label": 0
                },
                {
                    "sent": "If there are less than one, then somehow the dynamics will tend to be converging towards someplace if it's greater than one, then it's pushing you.",
                    "label": 0
                },
                {
                    "sent": "Away.",
                    "label": 0
                },
                {
                    "sent": "So why is that in?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Portant because.",
                    "label": 0
                },
                {
                    "sent": "In the region where the derivatives are less than one, then you are in a place where you're contracting and noise will be cancelled.",
                    "label": 0
                },
                {
                    "sent": "So if you are in such a region an you have a bit of noise being added to your state, the system will be robust to that noise and you will still be able to converge to the fixed point.",
                    "label": 0
                },
                {
                    "sent": "If you're in the expanding region then a bit of noise will be blown up and eventually you can go out of the extractor and forget the bit right so?",
                    "label": 0
                },
                {
                    "sent": "As for getting here means going from the base and corresponding to say one bit to another one.",
                    "label": 0
                },
                {
                    "sent": "Basically you've lost that information.",
                    "label": 0
                },
                {
                    "sent": "So the thing that really matters here is the weather.",
                    "label": 0
                },
                {
                    "sent": "Those derivatives are less than one or greater than one.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we want to store information reliably.",
                    "label": 0
                },
                {
                    "sent": "In other words, we don't want to be kicked out by a little bit of noise.",
                    "label": 0
                },
                {
                    "sent": "From that information we stored like the one or the zero that I had in my example.",
                    "label": 0
                },
                {
                    "sent": "Then we want to make sure that the dynamics stays in the regions where the derivatives are less than one.",
                    "label": 0
                },
                {
                    "sent": "So why is that a problem?",
                    "label": 0
                },
                {
                    "sent": "It's a problem because if you look at the gradients that we would use for example, for backdrop they involve asking the question how does state at time T influence the final loss.",
                    "label": 0
                },
                {
                    "sent": "So you can think of the final loss as a function of all the previous States and each state depends on the previous state and so on.",
                    "label": 0
                },
                {
                    "sent": "And because of these decomposition we have a composition of functions and by the chain rule we can write the gradient as a product.",
                    "label": 0
                },
                {
                    "sent": "Of these jacobian's, at each timestep times, one final gradient vector for the relationship between the state at the end of the sequence and the loss.",
                    "label": 0
                },
                {
                    "sent": "So we what we have here is a product of matrices and vector.",
                    "label": 0
                },
                {
                    "sent": "So now each of these matrices if they have eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "In of the Jacobian, there are less than one.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "It means we're basically multiplying a bunch of numbers that are less than one together.",
                    "label": 0
                },
                {
                    "sent": "And if you multiply many numbers of less than one together, what you get is vanishing gradients.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this actually was independently discovered by set Horse Rider, and he wrote about it in his thesis in 9091 in German, so I didn't really know about it until a few years later.",
                    "label": 0
                },
                {
                    "sent": "And he he.",
                    "label": 0
                },
                {
                    "sent": "This is actually interesting.",
                    "label": 0
                },
                {
                    "sent": "I learned this recently.",
                    "label": 0
                },
                {
                    "sent": "Not only he discovered this this issue, that the sort of.",
                    "label": 0
                },
                {
                    "sent": "The derivatives of the states in the past versus the future you know are obtained as a product of the Jacobian.",
                    "label": 0
                },
                {
                    "sent": "If this jacobian's are small, then you have vanishing, but this also actually led him to come up with the STM, which I'll tell you about later and he started thinking about LSD M in his in his 1991 thesis.",
                    "label": 0
                },
                {
                    "sent": "The actual SDM paper only came up in 97.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you more about.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so why is it that having these derivatives?",
                    "label": 0
                },
                {
                    "sent": "Converge to zero as we consider longer sequences.",
                    "label": 0
                },
                {
                    "sent": "Why is that a problem?",
                    "label": 0
                },
                {
                    "sent": "Because it's going to.",
                    "label": 0
                },
                {
                    "sent": "It's going to mess up our parameter gradient so.",
                    "label": 0
                },
                {
                    "sent": "The equation I'm showing here is not the way that the gradient is computed by backdrop, but you can rewrite the gradient equations in this way to understand.",
                    "label": 0
                },
                {
                    "sent": "How it's composed an you can you can rewrite the gradient of the costs at some time in the future, like the end of the sequence with respect to parameters as a sum over all the previous time steps.",
                    "label": 0
                },
                {
                    "sent": "So we have the final time steps T an.",
                    "label": 0
                },
                {
                    "sent": "Now we consider the sum over all the previous time steps Taw.",
                    "label": 0
                },
                {
                    "sent": "Where we're going to consider that the way that we can, that the parameters influence the cost at T at the end of the sequence is that the parameters are going to influence the state at all some intermediate time.",
                    "label": 0
                },
                {
                    "sent": "Then the state or is going to influence the state at T much later, and then the state of T influences the costs alright.",
                    "label": 0
                },
                {
                    "sent": "And now we have a problem with this middle quantity.",
                    "label": 0
                },
                {
                    "sent": "Here D state at and D state at some intermediate points.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that if we want to be in the region.",
                    "label": 0
                },
                {
                    "sent": "Of the state space and the parameter space that allows to store bits of information reliably.",
                    "label": 0
                },
                {
                    "sent": "We need those derivatives to be less than one.",
                    "label": 0
                },
                {
                    "sent": "We need those eigenvalues to be have we need the spectral radius to be less than one, we need all the eigenvalues to be less than one, because this is the condition that will allow to store information reliably, but at the same time this condition makes it so that this this derivative this matrix, which is a product of all the intermediate Jacobian matrices, converges to zero exponentially fast in terms of the length of the sequence.",
                    "label": 0
                },
                {
                    "sent": "So why is that a problem?",
                    "label": 0
                },
                {
                    "sent": "Because now we have this sum.",
                    "label": 0
                },
                {
                    "sent": "Some of the terms will be very small because there are exponentially smaller than the other ones, so the terms that regard long term dependencies.",
                    "label": 0
                },
                {
                    "sent": "So in other words, how the state in the remote past some far in the past all influences the current T. Those terms will be very small compared to the terms in that some corresponding to what's happening when tall is really, really close to 2 T. Right, so what's happening is that the total gradient is a sum of terms, some of which will be much smaller, and we know what happens numerically when you add a large number in a small number.",
                    "label": 0
                },
                {
                    "sent": "Basically, the small number loses.",
                    "label": 0
                },
                {
                    "sent": "You lose that information.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you if you an, especially if you think about stochastic gradient descent, there's kind of noise happening in this gradient, and So what we're going to have is.",
                    "label": 0
                },
                {
                    "sent": "Essentially that the long term dependencies are going to dominate.",
                    "label": 0
                },
                {
                    "sent": "It's going to be easy for the network to learn their short-term dependencies, but it's going to take forever for the network to learn the long term dependencies.",
                    "label": 0
                },
                {
                    "sent": "An forever could be really bad in some cases.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is this is really, really important.",
                    "label": 0
                },
                {
                    "sent": "I want to make a pause here to allow you to ask questions.",
                    "label": 0
                },
                {
                    "sent": "Yes, this might be really crazy.",
                    "label": 0
                },
                {
                    "sent": "Not just rescaled.",
                    "label": 0
                },
                {
                    "sent": "I tried it.",
                    "label": 0
                },
                {
                    "sent": "Didn't work.",
                    "label": 0
                },
                {
                    "sent": "But the problem with rescaling is that.",
                    "label": 0
                },
                {
                    "sent": "Then you don't have any guarantee that is the correct gradient anymore.",
                    "label": 0
                },
                {
                    "sent": "So if you're lucky, maybe all of those terms have the same sign, for example, and then it would be fine.",
                    "label": 0
                },
                {
                    "sent": "But let's say some are positive, some are negative.",
                    "label": 0
                },
                {
                    "sent": "You change the weighting of each of them, and now you might go in the wrong direction.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The problem because you have a fine time scale, but they don't have sort.",
                    "label": 0
                },
                {
                    "sent": "Of course I tried to log into office.",
                    "label": 0
                },
                {
                    "sent": "Yes, I'll come to.",
                    "label": 0
                },
                {
                    "sent": "That is one of the directions to try to solve this problem, but note that it won't solve it completely.",
                    "label": 0
                },
                {
                    "sent": "It would make it easier because we're trying to reach between 8:00 on 80 through some steps that are somehow less nonlinear and have less Jacobian is closer to 1 basically.",
                    "label": 0
                },
                {
                    "sent": "But that's a very important direction of investigation.",
                    "label": 0
                },
                {
                    "sent": "Forever, forever forever be clumped independently.",
                    "label": 0
                },
                {
                    "sent": "So are you saying that in the limit of infinite I'm growing tree learning I think so yeah.",
                    "label": 0
                },
                {
                    "sent": "I don't have any like math to support this thing, but but intuitively it's just a matter that the total gradient is.",
                    "label": 0
                },
                {
                    "sent": "Now, you know, has important terms from from a statistical point of view, but the numerically these terms are very, very small right?",
                    "label": 0
                },
                {
                    "sent": "So in principle you would first kill off the the you would learn the short term dependencies and then those terms would be small and then eventually you should be able to learn the long term ones.",
                    "label": 0
                },
                {
                    "sent": "But in practice, because you also have noise in the gradient coming from the fact that you're doing SGD.",
                    "label": 0
                },
                {
                    "sent": "And you know all kinds of imperfections, or even numerical precision issues.",
                    "label": 0
                },
                {
                    "sent": "It becomes harder and harder.",
                    "label": 0
                },
                {
                    "sent": "Yes, how cold cases dynamics in terms of Canada tractor be measuring on zero like sure?",
                    "label": 0
                },
                {
                    "sent": "So that's a very complicated yeah, but really here, the argument I made doesn't really care about the shape of the attractor.",
                    "label": 0
                },
                {
                    "sent": "It only depends on the fact that we for it to be an attractor.",
                    "label": 0
                },
                {
                    "sent": "The eigen values need to be less than one around it.",
                    "label": 0
                },
                {
                    "sent": "So you can get close.",
                    "label": 0
                },
                {
                    "sent": "Nobody, I don't care where I'm on their tractor.",
                    "label": 0
                },
                {
                    "sent": "Yes yes.",
                    "label": 0
                },
                {
                    "sent": "So in general when you store many bits.",
                    "label": 0
                },
                {
                    "sent": "This is your exactly going to be in the situation where the attractor isn't a point, right.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you would need like one attractor for each value that you want to store.",
                    "label": 0
                },
                {
                    "sent": "It's much more efficient to have kind of a distributed representation where the tractor is actually a multi dimensional object and now you can store many bits, sort of in a componential way.",
                    "label": 0
                },
                {
                    "sent": "But anyways doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "The point is to store information reliably.",
                    "label": 0
                },
                {
                    "sent": "You need these contractive mappings.",
                    "label": 0
                },
                {
                    "sent": "But contractive mappings equals.",
                    "label": 0
                },
                {
                    "sent": "Hard to learn.",
                    "label": 0
                },
                {
                    "sent": "The longer term dependencies.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Is there another problem with where you start?",
                    "label": 0
                },
                {
                    "sent": "The initial condition will be the point on the boundaries of the yes, that could be a problem to an.",
                    "label": 0
                },
                {
                    "sent": "In practice when we train recurrent Nets, we see this happening so rarely.",
                    "label": 0
                },
                {
                    "sent": "No, it's not necessarily.",
                    "label": 0
                },
                {
                    "sent": "I mean, that would be one instance, but simply the fact that you go in those places where the eigenvalues in some regions the eigenvalues are larger than one.",
                    "label": 0
                },
                {
                    "sent": "And if you spend time there, you're going to receive some very large gradients, and that can simply throw off your learning.",
                    "label": 0
                },
                {
                    "sent": "In fact, that's one of the common problems with training RNN, but the good news is that we have a trick to fix that, which I'm going to explain in a couple of minutes, yes.",
                    "label": 0
                },
                {
                    "sent": "In order approaches, so yes, I tried that too.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and we had some hope for a time that it could solve the problem, but it.",
                    "label": 0
                },
                {
                    "sent": "It's not it.",
                    "label": 0
                },
                {
                    "sent": "It could help in some cases, but it doesn't seem to be general cure.",
                    "label": 0
                },
                {
                    "sent": "Yes, so just before that the reason why we thought this could work and this is really ideas coming from yes Cover and James Martens.",
                    "label": 0
                },
                {
                    "sent": "Is that if we're lucky?",
                    "label": 0
                },
                {
                    "sent": "When the first derivatives, when the components of the first derivatives.",
                    "label": 0
                },
                {
                    "sent": "So these are components of the gradients.",
                    "label": 0
                },
                {
                    "sent": "So you can think about components also of the second derivatives.",
                    "label": 0
                },
                {
                    "sent": "So if we're lucky, the components of the second derivatives also scale in the same way.",
                    "label": 0
                },
                {
                    "sent": "And then when you multiply by the inverse Hessian, that kind of cancels this issue.",
                    "label": 0
                },
                {
                    "sent": "So there's hope, but you know, it doesn't always work, and I don't really understand why.",
                    "label": 0
                },
                {
                    "sent": "Alright, I should probably move on to get a chance to see the rest of the material last quite less question.",
                    "label": 0
                },
                {
                    "sent": "Problem, what networks I didn't hear.",
                    "label": 0
                },
                {
                    "sent": "Work kind of sold well.",
                    "label": 0
                },
                {
                    "sent": "What residual networks are feedforward networks?",
                    "label": 0
                },
                {
                    "sent": "An you can think of residual.",
                    "label": 0
                },
                {
                    "sent": "It's the other way around.",
                    "label": 0
                },
                {
                    "sent": "Visiting networks work because they do like Gru, zorel stems or higher highway networks.",
                    "label": 0
                },
                {
                    "sent": "They they have a Jacobian close to 1.",
                    "label": 0
                },
                {
                    "sent": "Because they have this.",
                    "label": 0
                },
                {
                    "sent": "Next state equals previous state plus something if something is reasonably small, then the dominant term in the Jacobian is this identity.",
                    "label": 0
                },
                {
                    "sent": "Alright, I should move on.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so um.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's interesting to point out though, that.",
                    "label": 0
                },
                {
                    "sent": "The situation in the feedforward case is not quite the same.",
                    "label": 0
                },
                {
                    "sent": "Although there are some really important parallels and lessons to be.",
                    "label": 0
                },
                {
                    "sent": "Considered so, this is a recurrent case and I've kind of drawn here.",
                    "label": 0
                },
                {
                    "sent": "I put it upside down and I've put in read the fact that the weights now are different at each layer.",
                    "label": 0
                },
                {
                    "sent": "So in the recurrent case we have inputs coming at each time step, but that's not the main thing.",
                    "label": 0
                },
                {
                    "sent": "The main thing is that the weights are different at each time step, and so that makes a huge difference because basically.",
                    "label": 0
                },
                {
                    "sent": "Especially the target only comes at the end.",
                    "label": 0
                },
                {
                    "sent": "Now in principle you could.",
                    "label": 0
                },
                {
                    "sent": "You could do the re weighting.",
                    "label": 0
                },
                {
                    "sent": "I forgot who proposed.",
                    "label": 0
                },
                {
                    "sent": "We should do a reweighting.",
                    "label": 0
                },
                {
                    "sent": "Well here you can do a reweighting because there are you know you're not adding up these things.",
                    "label": 0
                },
                {
                    "sent": "Now forget about the sum.",
                    "label": 0
                },
                {
                    "sent": "They all go to a different layer right?",
                    "label": 0
                },
                {
                    "sent": "So you have a different set of ways for each time step for each layer.",
                    "label": 0
                },
                {
                    "sent": "So now you can re wait an.",
                    "label": 0
                },
                {
                    "sent": "In fact it's a good thing to do it.",
                    "label": 0
                },
                {
                    "sent": "And I think the adaptive learning rate methods do something like this.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, we waiting the layers in a deep net, although it can help.",
                    "label": 0
                },
                {
                    "sent": "Doesn't necessarily completely solve the problems of learning deep Nets, but it's something to keep in mind.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I guess I said all these things.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me probably.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This let me tell you about the clipping.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So there's a very simple recipe to get rid of the problem of the large eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So when the gradients become very large because you multiply numbers that are greater than one together, you get a kind of explosion, and the recipe is basically when the gradients is large.",
                    "label": 0
                },
                {
                    "sent": "Don't trust it.",
                    "label": 0
                },
                {
                    "sent": "Very simple right?",
                    "label": 0
                },
                {
                    "sent": "Because if you were to take your current parameter values and add this huge gradient.",
                    "label": 0
                },
                {
                    "sent": "It would just throw you off very far from where you should be.",
                    "label": 0
                },
                {
                    "sent": "One thing to keep in mind and why this makes sense is that the gradient descent algorithms make sense when you make small steps.",
                    "label": 0
                },
                {
                    "sent": "If you have a huge gradient and you add that with your current learning rate and you make a big step, you could go anywhere.",
                    "label": 0
                },
                {
                    "sent": "It's just going to be, you know it's likely to be wrong.",
                    "label": 0
                },
                {
                    "sent": "So in particular, you have to think about the most important information about the gradient is the direction it tells you to go, but the magnitude could be completely wrong, right?",
                    "label": 0
                },
                {
                    "sent": "So what we did is we take the gradient on the parameters and we check if it's norm is greater than threshold.",
                    "label": 0
                },
                {
                    "sent": "We change the norm so that it's equal to the threshold.",
                    "label": 0
                },
                {
                    "sent": "So it's very easy.",
                    "label": 0
                },
                {
                    "sent": "It's a one line to change in your code and it prevents the issues you have with gradient explosion.",
                    "label": 1
                },
                {
                    "sent": "Now let me tell you about the picture in the back.",
                    "label": 0
                },
                {
                    "sent": "In the bottom, people used to think that the main optimization sort of landscape to keep in mind when we train neural Nets or other kinds of problems actually is that there's a conditioning problem and there is a conditioning problem, meaning that.",
                    "label": 0
                },
                {
                    "sent": "So this is supposed to be the error.",
                    "label": 0
                },
                {
                    "sent": "The cost with respect to the parameter space on the plane.",
                    "label": 0
                },
                {
                    "sent": "Meaning that you have directions where the second derivatives of the costs are very large and directions where the second derivatives costs are very small and you know this is slowing down training and so on.",
                    "label": 0
                },
                {
                    "sent": "But in recurrent Nets actually you might see things like this, so this is actually the case where the single neuron with the feedback and you have these ridges.",
                    "label": 0
                },
                {
                    "sent": "So instead of things being these values being symmetric, you have very high derivatives on one side, but not necessarily high derivatives on the other side.",
                    "label": 0
                },
                {
                    "sent": "And here you have a nice slope going down in this direction, so you actually would like to go down in this direction.",
                    "label": 0
                },
                {
                    "sent": "The problem is, as you do, that you approach this region which is close to probably a boundary of basic attraction.",
                    "label": 0
                },
                {
                    "sent": "This is in parameter space, so it makes it makes it possible to approach those boundaries that have very large gradients and near those boundaries the gradient become huge and they kick you off and throw off the learning.",
                    "label": 0
                },
                {
                    "sent": "So by simply rescaling the gradient or sometimes just ignoring it and doing a random move, you just go not too far away and then continue.",
                    "label": 0
                },
                {
                    "sent": "And that really solves a lot of these problems, it doesn't solve the long term dependencies problem, but it solves the problem coming from the large gradients.",
                    "label": 0
                },
                {
                    "sent": "So this is called gradient clipping and it's very very efficient and you should all have it in your own code.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to tell you about approaches to try to deal with this problem.",
                    "label": 0
                },
                {
                    "sent": "Have long term dependencies, so in the.",
                    "label": 0
                },
                {
                    "sent": "In the 93 paper that we wrote about the long term dependencies.",
                    "label": 0
                },
                {
                    "sent": "So this was an early version of the Journal Paper 94.",
                    "label": 1
                },
                {
                    "sent": "We proposed something that has the flavor of LVM is not the same thing, but the idea was that again we have this memory cell that at each state gets updated by just copying itself, and we have some kind of decision that gates that that you know whether we copy.",
                    "label": 0
                },
                {
                    "sent": "Or we don't.",
                    "label": 0
                },
                {
                    "sent": "And then we use some kind of touristic to decide how to propagate gradients.",
                    "label": 0
                },
                {
                    "sent": "But this idea that you should have this kind of self loop to keep information for a long time was there, and it was also in 91 in separate writers thesis.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, actually.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You tell you about LST em right now.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There are different variants of the LSD, but basically all of them.",
                    "label": 0
                },
                {
                    "sent": "The central idea is.",
                    "label": 0
                },
                {
                    "sent": "There is this state variable.",
                    "label": 0
                },
                {
                    "sent": "Has a self loop with itself in other words.",
                    "label": 0
                },
                {
                    "sent": "They called the code the cell in the LCM.",
                    "label": 0
                },
                {
                    "sent": "The new state will be equal to the old state plus some kind of update.",
                    "label": 1
                },
                {
                    "sent": "An we can control with a gate whether we actually copy the old state into the new state.",
                    "label": 0
                },
                {
                    "sent": "An whether we actually have an update coming, so the important one is the forget gate here, which which multiplies the self loop path and so it could kill off the self loop path and the reason you want to do that is that if you didn't have that then it would just keep adding and adding in the state would keep growing and growing.",
                    "label": 0
                },
                {
                    "sent": "And yeah this might prevent you from forgetting things.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you actually want to forget things because you have limited memory.",
                    "label": 0
                },
                {
                    "sent": "And in the case of LTM, there are also extra gates which control whether we actually add something into the state.",
                    "label": 0
                },
                {
                    "sent": "So there is the input.",
                    "label": 0
                },
                {
                    "sent": "But there's also a gate which multiplies this or it can kill off the thing that will be added.",
                    "label": 0
                },
                {
                    "sent": "And they also have an output gate, which I think is useless, but controls whether something is going to be sent to the outside world and the Gru, gated recurrent unit has a.",
                    "label": 0
                },
                {
                    "sent": "Slightly simpler architecture, so it's, but it has the same self loop and it works basically the same and it's a bit cheaper to compute, so several papers are using it.",
                    "label": 0
                },
                {
                    "sent": "It is kind of the same principle.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was 97 LS TM in 95.",
                    "label": 0
                },
                {
                    "sent": "In 95 we.",
                    "label": 0
                },
                {
                    "sent": "There's another paper that's missing I should have.",
                    "label": 0
                },
                {
                    "sent": "We proposed in NIPS 95 we proposed to use temporal hierarchy, so this is answering Join's suggestion that maybe we could use multiple levels of timescales in order to bypass this problem of having you know the multiplication by many jacobian's.",
                    "label": 0
                },
                {
                    "sent": "So what I mean here is here in the bottom you have a regular recurrent net, but at the next layer you have a recurrent net that's updated less often somehow.",
                    "label": 0
                },
                {
                    "sent": "And then another one even less often.",
                    "label": 0
                },
                {
                    "sent": "So here I double the period.",
                    "label": 0
                },
                {
                    "sent": "So what happens is that even though the path through the the fine time scale recurrent net may just make it impossible to learn long-term dependencies, you could learn long-term dependencies.",
                    "label": 0
                },
                {
                    "sent": "By having gradients propagate through the shorter path that goes through the slow time scale.",
                    "label": 0
                },
                {
                    "sent": "So this is the general idea.",
                    "label": 0
                },
                {
                    "sent": "And the devil is in the details.",
                    "label": 0
                },
                {
                    "sent": "Like how do we define when those upper ones should be updated?",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "You don't even have to have discrete updates.",
                    "label": 0
                },
                {
                    "sent": "You could have slowly changing units higher up rather than.",
                    "label": 0
                },
                {
                    "sent": "You know I update every 10 time steps.",
                    "label": 0
                },
                {
                    "sent": "I just update by copying my old value a little bit and adding a little bit of the new value.",
                    "label": 0
                },
                {
                    "sent": "Another idea which came at about the same time from Lee Giles in the top right.",
                    "label": 0
                },
                {
                    "sent": "What you see is you can have recurrent Nets.",
                    "label": 0
                },
                {
                    "sent": "We skip connections overtime.",
                    "label": 0
                },
                {
                    "sent": "So again, what you are doing is now you create those paths in the graph which allowed to go sort of faster from the past or the future with less nonlinearities in between.",
                    "label": 0
                },
                {
                    "sent": "And that also works.",
                    "label": 0
                },
                {
                    "sent": "So an example of these hierarchies in recent work we did with Julian Serban an others here at Mila involves.",
                    "label": 0
                },
                {
                    "sent": "Two level hierarchy where there is one level of recurrent Nets that is reading.",
                    "label": 0
                },
                {
                    "sent": "Words in a sentence, but you could also imagine some characters in a word and another level which is working at the level here of sentences, and you can have more levels if you wanted, but you could imagine many ways that you can implement these ideas of a hierarchy.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now if we go to something very recent with which I think brings fresh ideas to this question of long-term dependencies, memory networks, which you will hear more about.",
                    "label": 0
                },
                {
                    "sent": "You can think of memory networks as some kind of recurrent network where the state part of the state is now stored in a big memory big outside memory.",
                    "label": 0
                },
                {
                    "sent": "I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See you next picture 'cause it's kind of easier to understand so so you have a set of memory cells and at each time step what happens is that those memory cells either get copied from the previous time step or somebody writes something into a cell and somebody is a neural net right recurrent that, and when you write something into a cell, of course you are going to be for getting old values, but most of the time if you have a big memory Ann, you're only writing at one place at a time, basically.",
                    "label": 0
                },
                {
                    "sent": "You're just copying and so information gets propagated for a very long time.",
                    "label": 0
                },
                {
                    "sent": "In other words, if you have like a memory like a memory of a Turing machine, when you store things in there, it robustly stays for a long time, right?",
                    "label": 0
                },
                {
                    "sent": "And so that kind of sidesteps the problem of long-term dependencies.",
                    "label": 1
                },
                {
                    "sent": "Or at least it reduces it considerably.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a nice recent paper.",
                    "label": 0
                },
                {
                    "sent": "From Mila, an also involving Toronto people where we try to think of.",
                    "label": 0
                },
                {
                    "sent": "How to characterize these recurrent net architectures and we came up with three.",
                    "label": 0
                },
                {
                    "sent": "Interesting measures to help us understand an architecture, so one of them is the.",
                    "label": 0
                },
                {
                    "sent": "A feed forward depth, so that's like the yellow path.",
                    "label": 0
                },
                {
                    "sent": "So remember if we stack and recurrent net.",
                    "label": 0
                },
                {
                    "sent": "So how long does it take to go from input to output through different layers?",
                    "label": 0
                },
                {
                    "sent": "That's basically like going in the feed forward direction.",
                    "label": 0
                },
                {
                    "sent": "Then you have the recurrent depth which tells us what's the longest path from a particular time.",
                    "label": 0
                },
                {
                    "sent": "Step 2 later in the future, potentially going through all the complications of the architecture, and in this particular architecture you see that you can.",
                    "label": 0
                },
                {
                    "sent": "You can pack two nonlinearities for each time step, because you can go through this layer, then then the one above, and then at the same time step.",
                    "label": 0
                },
                {
                    "sent": "And then go to the next time step at the same level and so this red path here actually.",
                    "label": 0
                },
                {
                    "sent": "Packs twice as much depth per timestep, then a standard architecture, and then the third quantity.",
                    "label": 0
                },
                {
                    "sent": "That's interesting to consider is the skip coefficient.",
                    "label": 0
                },
                {
                    "sent": "Which tells us about the blue arrows.",
                    "label": 0
                },
                {
                    "sent": "That tells us not about the longest path.",
                    "label": 0
                },
                {
                    "sent": "From beginning to the end, but the shortest path and is also useful, right?",
                    "label": 0
                },
                {
                    "sent": "You want to have these short paths in order to long-term dependencies.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are experiments that I don't have to tell you about showing how all of these things, all of these things can matter.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Briefly, there's been a bunch of work exploring how we can play with the weight matrix in order to make it easier to learn long term dependencies.",
                    "label": 0
                },
                {
                    "sent": "So, for example, you could initialize it to be orthogonal.",
                    "label": 0
                },
                {
                    "sent": "Or you can actually constrain it to be a unitary matrix which has all the eigenvalues equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Or you can play a game similar to what you have in stock and resonates where sometimes the Jacobian is just the identity because you just copy the previous data, the next date, and you can randomly do that and this is called zone out in recent paper, also from Mila.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now earlier I said that in a.",
                    "label": 0
                },
                {
                    "sent": "Standard recurrent net.",
                    "label": 0
                },
                {
                    "sent": "We can interpret the computation and the model as a directed graphical model without any latent variables.",
                    "label": 0
                },
                {
                    "sent": "And what that means is that all of the randomness that is injected when we generate something is happening at the level of the observations of the visible variables at the data level, right?",
                    "label": 0
                },
                {
                    "sent": "So if we're working on pixels, it's like the way that we generated images that we randomly picked the next pixel, and then the next pixel given the previous pixels.",
                    "label": 0
                },
                {
                    "sent": "But it would make a lot of sense if instead.",
                    "label": 0
                },
                {
                    "sent": "The randomness was about taking decisions regarding not the low level, not the pixels, but the high level in the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Like what is this picture going to be about?",
                    "label": 0
                },
                {
                    "sent": "What is this text going to be about?",
                    "label": 0
                },
                {
                    "sent": "What is this music going to be built?",
                    "label": 0
                },
                {
                    "sent": "You'd like to take these high level decisions and then condition on these high level decisions.",
                    "label": 0
                },
                {
                    "sent": "You might want to put in the details at the low level.",
                    "label": 0
                },
                {
                    "sent": "So for this you need to introduce latent actual latent variables, not just the deterministic ones we have in a regular recurrent net.",
                    "label": 0
                },
                {
                    "sent": "We need to introduce the exact variables at sort of a high level of the hierarchy corresponding to high level abstractions.",
                    "label": 0
                },
                {
                    "sent": "So it's like you decide on the high level structure, and then given that you may decide low level structure.",
                    "label": 0
                },
                {
                    "sent": "So we the last nips, we had a paper about combining ideas from what's called variational autoencoders, which hopefully will be also covered later this week in recurrent Nets.",
                    "label": 0
                },
                {
                    "sent": "Since you haven't seen these things yet, I'm not going to go in much detail and I don't have much time, but basically you can combine the ideas in some of these modern latent variable models in recurrent Nets, and you can stick in high level random decisions in the computational graph in the model.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the model I showed you earlier which has two levels of recurrent Nets like one working on words, the other working on sentence is you can also have random variables at each time step which control sort of high level decisions about.",
                    "label": 0
                },
                {
                    "sent": "You know, maybe what topic we're going to be talking about in the next sentence, given everything that we've said before, and then given that we can generate the next sentence.",
                    "label": 0
                },
                {
                    "sent": "And so that's also been work of Julian Serban.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are other fully observed neural Nets that are directed graphical models that are not really recurrent Nets, but or maybe different from recurrent Nets, and it's worth talking about now.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they belong to a larger family which uses the same decomposition.",
                    "label": 0
                },
                {
                    "sent": "I told you at the beginning.",
                    "label": 0
                },
                {
                    "sent": "Remember, I told you that we can take a joint distribution P of X1 to XY and we can write it as a product of conditional.",
                    "label": 0
                },
                {
                    "sent": "So that's the way one of the basic.",
                    "label": 0
                },
                {
                    "sent": "You know things you should know about probability distributions and so in general we get a graphical model like the one on the right where you see each variable like X3 being conditioned on all the previous ones.",
                    "label": 0
                },
                {
                    "sent": "So these kinds of decompositions had been used before.",
                    "label": 0
                },
                {
                    "sent": "The 90s in particular Brendan Frey, in whose Toronto in his thesis in 97, proposed a model that essentially has a logistic regression of each bit in a vector given the previous bits according to some order.",
                    "label": 0
                },
                {
                    "sent": "So you were now not talking about sequences, so there's no natural order, but we can still pick an order and then say we're going to model the conditional distribution of the Earth.",
                    "label": 0
                },
                {
                    "sent": "Variable given the ones from I from 1 to I -- 1 and we can just do a linear regression or logistic regression to obtain those conditional probabilities in 99 with my brother Sammy.",
                    "label": 0
                },
                {
                    "sent": "We sort of extended this to annual net.",
                    "label": 0
                },
                {
                    "sent": "Where we said, OK, so those conditional probabilities instead of being computed by a linear model, we're going to be using a neural net, but instead of having a different neural net for each conditional probability.",
                    "label": 0
                },
                {
                    "sent": "Now because we have these hidden units we can share.",
                    "label": 0
                },
                {
                    "sent": "The representations that we've learned for other earlier predictions in coming up with the next prediction.",
                    "label": 0
                },
                {
                    "sent": "So this is very different from a normal recurrent net because in the normal recurrent net there is this kind of translation in variance.",
                    "label": 0
                },
                {
                    "sent": "In other words, we're assuming that what's the parameters that are good to predict the next.",
                    "label": 0
                },
                {
                    "sent": "A time step are also good to predict the one after and the one after this.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "We can take the data and then translate it and the properties of those conditional distributions remain the same, but here the pixels could be, you know.",
                    "label": 0
                },
                {
                    "sent": "I mean the X one X2 X could be anything like any random variable.",
                    "label": 0
                },
                {
                    "sent": "There's no, there's no equivalent of.",
                    "label": 0
                },
                {
                    "sent": "I can translate and keep the semantics, so the parameters of the conditionals for predicting the third one would be different from the ones for predicting the 4th one.",
                    "label": 0
                },
                {
                    "sent": "Now here we have the same thing, but we can share because when we make say the prediction for X3 given X1 and X2, we extract some intermediate features that are hidden units.",
                    "label": 0
                },
                {
                    "sent": "And we could use these to predict X4.",
                    "label": 0
                },
                {
                    "sent": "Well there should be an arrow here.",
                    "label": 0
                },
                {
                    "sent": "Again, going from H22P of X4.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little bit later in 2011, Hugo, whom you've heard on Monday, came up with a variation on this idea, which makes the computation.",
                    "label": 0
                },
                {
                    "sent": "Very efficient and also.",
                    "label": 0
                },
                {
                    "sent": "The statistical representation more efficient, so there's less parameters because and by introducing a form of sharing that we didn't have, so the idea here is that.",
                    "label": 0
                },
                {
                    "sent": "The weights that go from X1 to a first group of hidden units will be the same as those that go from X1 to another group of units at corresponding to the prediction you want to make in the future, and so in this way you have less parameters and you can also organize computations so that it's actually more efficient by reusing the computation that you've already made for the earlier time steps, and you just have to add the new terms when you consider the next prediction.",
                    "label": 0
                },
                {
                    "sent": "Say I now consider X3 as an extra input.",
                    "label": 0
                },
                {
                    "sent": "I don't need to redo the additions corresponding to the previous ones.",
                    "label": 0
                },
                {
                    "sent": "I just consider the new input an add an extra term to the sum so computation can be very efficient now very efficient compared to previous models, But it's still very inefficient on like a GPU because there's still very very sequential for each for each input and reach output we have to do a little bit of computation, so it's kind of harder to parallelize, but these kinds of models actually quite we're quite well an recently people have.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using this style of modeling images.",
                    "label": 0
                },
                {
                    "sent": "And they're called pixel RNS.",
                    "label": 0
                },
                {
                    "sent": "And basically these works surprisingly well, so it's kind of disappointing for people like me.",
                    "label": 0
                },
                {
                    "sent": "We've been working on generative models with latent variables that these graphical models without any latent variables.",
                    "label": 1
                },
                {
                    "sent": "So it's just like a big recurrent net, essentially with a particular structure, can generate the next pixel given the previously generated pixels.",
                    "label": 1
                },
                {
                    "sent": "So you can organize what's previously generated in various ways.",
                    "label": 0
                },
                {
                    "sent": "For example, on the top left you see you just traverse all the rows, and then you predict the next pixel given.",
                    "label": 0
                },
                {
                    "sent": "Everything you've seen before.",
                    "label": 0
                },
                {
                    "sent": "Or maybe you can organize computation using this kind of triangle where you use only information from the top or like the one on the right.",
                    "label": 0
                },
                {
                    "sent": "I mean there are various architectures that you could use, but the point is we define a sequence.",
                    "label": 0
                },
                {
                    "sent": "And we have a little recurrent net which summarizes information you've seen in the past of the sequence and is used to predict next pixel, and it's very slow because you have to go through all the pixels one at a time, which is very sequential in order to generate an.",
                    "label": 1
                },
                {
                    "sent": "Also when you train, but it does.",
                    "label": 0
                },
                {
                    "sent": "It gives pretty nice images when you generate.",
                    "label": 0
                },
                {
                    "sent": "It tends to get the local details very good, much better than the kind of.",
                    "label": 0
                },
                {
                    "sent": "Deep generative models that have been there before and you will hear about more later.",
                    "label": 0
                },
                {
                    "sent": "So it gets things to get texture quite well and you can get pretty sharp and realistic images, at least on the scale it's been done up to now.",
                    "label": 0
                },
                {
                    "sent": "Do you think the resource they grow a structure is captured correctly has to do with long term memory, or is it just that there's not enough information to in the data set to learn the global structure?",
                    "label": 0
                },
                {
                    "sent": "So I think there is enough information.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "You can interpret the fact that it's not getting global structure as well as other models.",
                    "label": 0
                },
                {
                    "sent": "By thinking of.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "The issue is one of long-term dependencies, but you can also think of it like it would be so much more convenient if you first decide like.",
                    "label": 1
                },
                {
                    "sent": "What kind of object is going to be in the image?",
                    "label": 0
                },
                {
                    "sent": "And then your global structure would be decided, and then you fill out the details.",
                    "label": 0
                },
                {
                    "sent": "So ideally you want to have the two things you want to have.",
                    "label": 0
                },
                {
                    "sent": "The ability to decide on the global structure in a kind of heartical way.",
                    "label": 0
                },
                {
                    "sent": "But you also need to fill out the details so that the local texture an local parents is well preserved.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "And let me tell you about the last subject which.",
                    "label": 0
                },
                {
                    "sent": "Is a very old subject, which I think is coming back.",
                    "label": 0
                },
                {
                    "sent": "There is.",
                    "label": 0
                },
                {
                    "sent": "There's an issue with backpropagation through time.",
                    "label": 0
                },
                {
                    "sent": "Actually, there are several issues.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "For for those people who care to think about how brains might implement some machine learning algorithms, one issue with backdrop through time is that it requires a form of computation that seems a bit crazy.",
                    "label": 0
                },
                {
                    "sent": "You have to go through the whole history.",
                    "label": 0
                },
                {
                    "sent": "And you know, in worst case that means you have to go through your whole life.",
                    "label": 0
                },
                {
                    "sent": "And then store everything every state of your brain.",
                    "label": 0
                },
                {
                    "sent": "Somewhere and then replay it backwards.",
                    "label": 0
                },
                {
                    "sent": "And fix things using gradient steps.",
                    "label": 0
                },
                {
                    "sent": "And then we live your life better.",
                    "label": 0
                },
                {
                    "sent": "OK, I may be exaggerating.",
                    "label": 0
                },
                {
                    "sent": "Maybe you could get away with only learning about the dependencies across a single day, but then you know you think that something is missing and maybe maybe at night we're replaying backwards.",
                    "label": 0
                },
                {
                    "sent": "The things that are happening during the day, some.",
                    "label": 0
                },
                {
                    "sent": "There's some clues suggesting something like this may be happening, but it seems a bit crazy.",
                    "label": 0
                },
                {
                    "sent": "And also there's the issue of having to store the full sequence of states.",
                    "label": 0
                },
                {
                    "sent": "Because you need to store that somewhere so it's like you have your main state, but you have a memory which isn't part of your state which is used as a control part of the control algorithm where you would store these things.",
                    "label": 0
                },
                {
                    "sent": "It's not inconceivable for brains, but again, it's seems a bit of a stretch.",
                    "label": 0
                },
                {
                    "sent": "So it would be nice if there were other options.",
                    "label": 0
                },
                {
                    "sent": "Also, from a purely AI machine learning point of view, when we start playing with very long sequences and large recurrent Nets, the memory becomes a real bottleneck.",
                    "label": 0
                },
                {
                    "sent": "So for example, we've been playing with.",
                    "label": 0
                },
                {
                    "sent": "Acoustic signals where say you have 16,000 seven acoustic samples per second per second, yes.",
                    "label": 0
                },
                {
                    "sent": "And so the number of time steps grows very fast.",
                    "label": 0
                },
                {
                    "sent": "So if you want to do 10 seconds of audio, that's a lot of time steps and you have to store the state of recurrent net for every one of those time steps, so that just not going to fit on your GPU.",
                    "label": 0
                },
                {
                    "sent": "For now at least.",
                    "label": 0
                },
                {
                    "sent": "So, so that raises the question, are there any other ways to train recurrent Nets besides backdrop through time?",
                    "label": 0
                },
                {
                    "sent": "And the answer to this has already been given to some extent in 1989 paper from William Williams and Sipser.",
                    "label": 0
                },
                {
                    "sent": "In fact, the idea is much older, and people doing automatic differentiation much before that have already had already solved the problem.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And so the idea is that we can compute the gradient.",
                    "label": 0
                },
                {
                    "sent": "In a forward way, rather than the backward way, and to see why this is possible, let me use a blackboard.",
                    "label": 0
                },
                {
                    "sent": "It also will help to understand why.",
                    "label": 0
                },
                {
                    "sent": "For now we don't have a good, efficient way of doing it.",
                    "label": 0
                },
                {
                    "sent": "So remember, I told you that the total gradient.",
                    "label": 0
                },
                {
                    "sent": "If you consider a sequence like.",
                    "label": 0
                },
                {
                    "sent": "Where only at the end we get a loss an we've got now a Jacobian for the first time, step Jacobian for the second time step, Jacobian for the third time step, and so on.",
                    "label": 0
                },
                {
                    "sent": "And then we have D LDS.",
                    "label": 0
                },
                {
                    "sent": "This is a 0 S 1 S 2 S 3 S 4 so we've got DLD S4 which is a vector right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we want to compute, say, the gradients with respect to.",
                    "label": 0
                },
                {
                    "sent": "Those weights, what we need is is multiply DL DS4 by DS4DS three times DS3DS2 and so on.",
                    "label": 0
                },
                {
                    "sent": "The as 1D S 0 so we have a product of these matrices and we have a vector on one end.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "If you think about the computation that is being performed by back prop.",
                    "label": 0
                },
                {
                    "sent": "What it does here is you start from the end.",
                    "label": 0
                },
                {
                    "sent": "Which is gives you the gradient on the state at the last time step and then you.",
                    "label": 0
                },
                {
                    "sent": "Multiply that vector.",
                    "label": 0
                },
                {
                    "sent": "By the matrix corresponding to the Jacobian that goes from relates S3 to S4.",
                    "label": 0
                },
                {
                    "sent": "So we do a vector times matrix multiplication and then we get a vector and the cost of that operation is a size of that matrix.",
                    "label": 0
                },
                {
                    "sent": "So it's let's see if we have N dimension.",
                    "label": 0
                },
                {
                    "sent": "This is N ^2.",
                    "label": 0
                },
                {
                    "sent": "So we do this N squared vector matrix operation T times.",
                    "label": 0
                },
                {
                    "sent": "But we have to do it backwards in time.",
                    "label": 0
                },
                {
                    "sent": "But we could get the same result by going forward in time.",
                    "label": 0
                },
                {
                    "sent": "By starting from this matrix.",
                    "label": 0
                },
                {
                    "sent": "And then by the way, here is this DS0DW.",
                    "label": 0
                },
                {
                    "sent": "'cause this is the W we care about.",
                    "label": 0
                },
                {
                    "sent": "So we could start with this matrix and then multiplied by this matrix.",
                    "label": 0
                },
                {
                    "sent": "This matrix.",
                    "label": 0
                },
                {
                    "sent": "This matrix, this matrix and then this vector.",
                    "label": 0
                },
                {
                    "sent": "How much would it cost?",
                    "label": 0
                },
                {
                    "sent": "Well, now we've got a bunch of matrix multiplications.",
                    "label": 0
                },
                {
                    "sent": "How much does it cost to multiply 2 matrices of N squared?",
                    "label": 0
                },
                {
                    "sent": "It costs N cube.",
                    "label": 0
                },
                {
                    "sent": "So instead of doing N squared computation for each time step, Now we need to do N cube computation for each time step.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's worse than that.",
                    "label": 0
                },
                {
                    "sent": "Because that matrix here is not N squared, it's end times the number of weights which is itself N ^2.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a North by N squared matrix and when we multiply by this N by N matrix.",
                    "label": 0
                },
                {
                    "sent": "We get an N. The result of this is going to be an N by N squared again.",
                    "label": 0
                },
                {
                    "sent": "And how many computations are we going to do?",
                    "label": 0
                },
                {
                    "sent": "We're actually going to be doing N. To the four computation right?",
                    "label": 0
                },
                {
                    "sent": "Because for each of the elements here, we're going to have to look at all and here so.",
                    "label": 0
                },
                {
                    "sent": "The amount of computation we need here for this is order of N 4, whereas previously we had order of N ^2.",
                    "label": 0
                },
                {
                    "sent": "OK, that's really bad.",
                    "label": 0
                },
                {
                    "sent": "But we could do it.",
                    "label": 0
                },
                {
                    "sent": "In other words, we can compute the gradients by moving forward in time rather than backwards in time we don't have.",
                    "label": 0
                },
                {
                    "sent": "We can do this.",
                    "label": 0
                },
                {
                    "sent": "Even before we know what the right answer will be.",
                    "label": 0
                },
                {
                    "sent": "An anytime we get a right answer.",
                    "label": 0
                },
                {
                    "sent": "I mean time we get a loss then we can, we can use it to update the weights.",
                    "label": 0
                },
                {
                    "sent": "I'm not doing the full decomposition here.",
                    "label": 0
                },
                {
                    "sent": "I'm considering a very simple case where the losses only at the end.",
                    "label": 0
                },
                {
                    "sent": "But you can generalize it to the case where the losses at anytime step.",
                    "label": 0
                },
                {
                    "sent": "But the point is is like multiplying matrices from right to left versus left or right.",
                    "label": 0
                },
                {
                    "sent": "It gets you the same answer, but it's going to be a lot more expensive, yes?",
                    "label": 0
                },
                {
                    "sent": "Exactly that.",
                    "label": 0
                },
                {
                    "sent": "That's what I said earlier that you know with my differentiation.",
                    "label": 0
                },
                {
                    "sent": "People have discovered it well before and so these guys realized without knowing about automatic differentiation, you could do that and you could.",
                    "label": 0
                },
                {
                    "sent": "You could thus compute gradients online.",
                    "label": 0
                },
                {
                    "sent": "In recurrent net it means as we are considering the next example, if we have kept a memory.",
                    "label": 0
                },
                {
                    "sent": "Of where is if we've kept in memory of DSTDW, we can just update this.",
                    "label": 0
                },
                {
                    "sent": "An multiplied by at anytime by the loss AT with respect to St. An that will give us the component of the gradient due to the loss at T, and we can make an update.",
                    "label": 1
                },
                {
                    "sent": "In other words that will tell us this product will tell us how.",
                    "label": 0
                },
                {
                    "sent": "All the past states, the influence of the weights on all the past states.",
                    "label": 0
                },
                {
                    "sent": "He's leading us to this particular loss and how we should change the weights so that for this particular loss we make less of an error.",
                    "label": 0
                },
                {
                    "sent": "And so we could just go forward online as they called it.",
                    "label": 0
                },
                {
                    "sent": "The problem is that it's just too expensive and it's not even biologically plausible, because storing this means storing.",
                    "label": 0
                },
                {
                    "sent": "This matrix this is a huge, it's a tensor, right?",
                    "label": 0
                },
                {
                    "sent": "So for each neuron you have to consider all the possible weights, not just the weights entering that neuron.",
                    "label": 0
                },
                {
                    "sent": "But all the weights.",
                    "label": 0
                },
                {
                    "sent": "Right, that's the thing that's not, that's crazy.",
                    "label": 0
                },
                {
                    "sent": "Now there is some good news recently.",
                    "label": 0
                },
                {
                    "sent": "Jan Olivier in France and his collaborators have come up with a method to approximate that matrix.",
                    "label": 0
                },
                {
                    "sent": "These state D parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is a huge thing you don't even want to store it, so they have a low rank representation of that made of that tensor which has the property that in expectation.",
                    "label": 0
                },
                {
                    "sent": "So it's a stochastic estimator of that matrix.",
                    "label": 0
                },
                {
                    "sent": "It's a low rank stochastic estimator, meaning that in expectation it is the right value.",
                    "label": 0
                },
                {
                    "sent": "And they have a random way of choosing things so that in average over these randomness they get the right tensor, and it's never represented directly is represented as a product of 2 low rank matrices, right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This this idea that we might be able to actually do online learning in recurrent net is really is coming back and might be something to watch for in the future.",
                    "label": 0
                },
                {
                    "sent": "Alright I need to stop here and take any more questions you have.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}