{
    "id": "t4io2hcwv4q7pg5v7x7f73vyk6cokqmo",
    "title": "Random k-Labelsets: An Ensemble Method for Multilabel Classification",
    "info": {
        "author": [
            "Grigorios Tsoumakas, Aristotle University of Thessaloniki"
        ],
        "published": "Jan. 29, 2008",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Ensemble Methods"
        ]
    },
    "url": "http://videolectures.net/ecml07_tsoumakas_em/",
    "segmentation": [
        [
            "OK, hello everyone, I'm happy to be here to present your work on the problem of multi label classification using a new and so."
        ],
        [
            "L'approche so you are all familiar with the traditional single label classification where we hear examples are associated with just a single label Lambda from a set of label cell.",
            "If the size of the of the set of labels is 2, then we have the known problem of binary classification or information retrieval.",
            "It's also called filtering if the number of labels is larger than two.",
            "Then this is called the multi class classification problem.",
            "Now in their multi label classification problem, examples can be associated with a set of labels which is a subset of the original set."
        ],
        [
            "Later.",
            "And this is an important problem that arises in many domains.",
            "Traditionally we can find examples of multi label data in text."
        ],
        [
            "Location.",
            "For example, this paper, if we want to train a classifier to assign conference papers to areas, then we could categorize this paper to the areas of ensemble methods and perhaps also to produce."
        ],
        [
            "Of complex structures in medical diagnosis apace and can be suffering from more than one diseases."
        ],
        [
            "Same time.",
            "And some."
        ],
        [
            "Applications like protein function classification where protein families."
        ],
        [
            "May overlap.",
            "Music categorization, where a song can belong to more than one different terms."
        ],
        [
            "And the final to semantic scene analysis, where we can annotate images with different labels.",
            "For example, this image in the lower part we could based on the lower part, we could annotate it as an area Sandy area of bits, and from the top part of the image we could annotate it as an urban area."
        ],
        [
            "And the same with this second payments withdrawn from based on the lower part.",
            "We could annotate it as a filter based on the two parties."
        ],
        [
            "We can.",
            "There has been a lot of work towards dealing with this problem.",
            "We can categorize the different methods in two groups, problem transformation methods which transform them with the multi label classification problem into one or more single label classification or even regression or label ranking problems.",
            "And this category of methods are algorithm independent.",
            "The second category.",
            "Are the algorithm adaptation methods that adapt specific learning algorithms to directly deal with multiple labels, and there has also been significant work.",
            "Here are extensions of support vector machine algorithms, decision tree algorithms, probabilistic algorithms."
        ],
        [
            "So we in this work with we focused on the first group of methods which we consider is more interesting because it's more general and we can use any known Al Gore."
        ],
        [
            "Thundermist one of the most popular methods that exist in this category, is the binary relevance method, which trains.",
            "A single label classifier, binary classifier, one for its different label.",
            "So it independently treats the labels.",
            "And that's basically the same solution used to deal with a multiclass problem using a binary classifier.",
            "Now this method is criticized for for the fact that it doesn't consider the correlation that exists that may be existing."
        ],
        [
            "The multiple labels less known problem transformation method is what we call the label Powerset method, and this method considers its different subset of the set of labels as a single label.",
            "So in essence, what is what it is doing is language classifier that Maps the instances to the power set of the set of labels.",
            "Now the criticism of this method is that a large number of different labels may arise due to the power of the set of the size of the set of labels, and many of these labels will include few if any, examples.",
            "But we can partly alleviate this problem by considering only the distinct subsets that exist in the training set, and this is typically impractical.",
            "Applications, much less than two to the power of the.",
            "Size of the set of labels."
        ],
        [
            "So the algorithm that we proposed the random care labels at the algorithm what it does in a mess up in a nutshell, is that it cost racks and assemble of Labor power set classifier classifier and it show aims to take into account label correlations because the label Powerset plus five considers correlation.",
            "But it will train it's LP classifier using only a small.",
            "Random subset of the set of labels with this attention to avoid.",
            "The criticism of label partial classifiers that I explained early assembly combination is achieved by thresholding the average 01 decision for it's different label by its model.",
            "We will explain this steps later on.",
            "With more detail, first let me introduce some notation.",
            "What is a K label set?",
            "Caleb, Caleb and that is simply a subset of the set of labels with K elements, which K labels and we also will be using the notation.",
            "The superscript notation LK to denote the set of all distinct K label sets on L. Now let."
        ],
        [
            "See, there are several production phase with more detail.",
            "First we have to choose the size of the label set to the K value of K and then at iteration there again algorithms will randomly select such such a keg label set from the set of all distinct K label sets and it learns from this subset label partial classifier OK.",
            "So the parameters here in this phase as I said, we have first decide on their size of the label set, which can range from one to the size of set of labels, but the meaningful values, let's say, are between 2:00 and the size of the set of labels minus one.",
            "'cause if we use if we think of just the one label sets and we set the number of models to the number of labels, then we get the binary relevance method.",
            "While if we set gay to the number of labels, and consequently we can get only one model, then this is again the label Powerset method.",
            "So we can also think that Raquel is somewhere in between these two methods.",
            "We can.",
            "We have also to decide on the number of iterations them which can range from one to the size of the set of distinct gay label sets.",
            "Now they said."
        ],
        [
            "Combination phase, so given a new instance X it's LP model from their models that we have trained provides binary decision for its label that exists in the corresponding label set.",
            "So if they help classifier decide for one label that it must be predicted, then the output is 1, otherwise it is 0.",
            "Then Raquel averages the decision for its label.",
            "Based on these predictions and the final decision is based from this average.",
            "If it exceeds a certain threshold T. So in this case we have introduced in additional parameter which is the threshold T which can range from."
        ],
        [
            "Zero to 1.",
            "OK, few words about the computational complexity of the method.",
            "If we if we consider that sees the set of classes or labels.",
            "This set of examples and take the set of the attributes.",
            "And then we can say that the single label classification algorithm used by the LP by the Labour Party plus five has a complexity in the order that is given by function Z.",
            "Based on these three values, then the computational complexity of Raquel will be this one, which is linear with respect to the number of models.",
            "As with most sensible methods.",
            "But we have to be careful.",
            "About the number of classes which can be high because it's two 2 to the power of K. If you remember based on because we're using underneath the label parser classifier.",
            "But as we said, we will try to use small values for K to restrict this dimension.",
            "And also as I mentioned in the criticism for the label partial classifier.",
            "The larger the value of K, the smaller the distinct subset that we find in the training set, so again, it is not going to be.",
            "2 to the power of 2."
        ],
        [
            "Now in the paper we also provide the categorization of the various evaluation measures that appeared in the literature.",
            "We can group them into categories, example based evaluation measures for multiple for multi label classification problems.",
            "These measures calculated difference between the actual set of labels that exist in the example and the predicted set of labels, and then we have had this result.",
            "Overall examples in the test set the label based measures calculated binary evaluation measure for its label and then we can perform micro or macro averaging operation across all labels.",
            "As for the precision and recall measures by in the information retrieval community."
        ],
        [
            "So.",
            "Here are some of the example based measures that exist in the literature.",
            "I don't want to stay a lot in this slide.",
            "The most popular one is the hand gloss, which is based on the symmetric difference between the set of predicted that actual labels.",
            "And we have rats.",
            "As I said, all these measures across."
        ],
        [
            "Test examples.",
            "In the label based measures we can use any known binary valuation measure, and here is an example of how micro and macro operations are performed.",
            "On the top we can see a binary measure M that is calculated based on the true positives.",
            "False positive false positives, negatives and false negatives for its label Lambda and we first compute this measured parets label and then others the results one in the micro averaging we sum up the statistics and we then compare."
        ],
        [
            "Their measure.",
            "OK, now to the experiment.",
            "We did some experimental work to evaluate our algorithm.",
            "We use three data sets from three different domains.",
            "The same data set from the semantic indexing of still since.",
            "That EMC 2007 data set is a data set from the text mining competition of the same data Mining Government Conference in 2007.",
            "It concerns documents about aviation safety.",
            "As you can see in the table, this is a high dimensional data set consisting of about 49,000 attributes.",
            "To reduce the complexity, we did some feature selection and we selected the five counter features based on the maximum squared rack overall labels.",
            "So even feature selection needs.",
            "A particular approach to the because the data set is multi label, so we take the maximum we can take the maximum or the average.",
            "There are several approach and the well known list data set which is used in many papers on multi label classification.",
            "Which has to do with protein function classification and in the in the table apart from the classical single label statistiques, you can also see some multi label statistics like the number of differently label set that as I told you is much smaller in the training set.",
            "So you can see for example that we have six labels but the distinct subsets are only 15 less than two to the power of 6 and so.",
            "And the same for the other datasets, and we can also see the label cardinality, which is the mean number of labels, for example, and the normalized version of it, which we divide this number.",
            "By the way, the number of labels which we call label disc."
        ],
        [
            "The methods that we comparing the experiments apart from.",
            "Raquel algorithm, which we we experiment with 10 different thresholds from zero, 1209 and we run it with different number of models and the label says we also compare against the binary relevance of the label Powerset method underneath.",
            "For all algorithms we use a support vector machine algorithm and the valuation methodologies that we use the original training and test splits provided within the source of the data sets.",
            "And for the measures we calculate the Hamming loss in the Microverse with measures which are the most popular ones for this kind of tasks."
        ],
        [
            "OK, so let's see the results for the same data set.",
            "In this graph, the horizontal axis is the number of models.",
            "The vertical axis we see the Hamming loss, they lower the camera close, the better the performance.",
            "We can see that the LP classifier is actually better than their most popular binary relevance classifier.",
            "And we see also that the performance of Raquel for a threshold of 0.5 at default threshold that we used with all meaningful meaningful values of the K parameter.",
            "Antall meaningful values for the number of models.",
            "And what I want to say about this graph is that we see that Raquel can achieve.",
            "Good performance for awhile.",
            "Range of parameters.",
            "The same applies for the graph concerning."
        ],
        [
            "I've measured.",
            "Again, we see 4K equal to three and K equal to four and the reasonable number of models to.",
            "Jump to the performance to becoming better than the LP classifier."
        ],
        [
            "And then we also.",
            "Here, so in this graph, the performance of the algorithm when we vary the threshold from zero one to 09.",
            "And we take the optimal value for K for the K and 10 parameters.",
            "So what we notice here is that.",
            "Actually, for a greater fiscal around 0.6 and 0.7 we can see boot performance for a label sets from 2 to."
        ],
        [
            "4.",
            "And.",
            "From for that measure, on the other hand, we see that lower threshold values leads to better performance, so we see that thresholds around 0.3 and 0.4.",
            "Give the best results.",
            "Now of course, this graph cannot be used to directly compare the Raquel algorithm with the binary relevance in the label Powerset method, because I.",
            "We are.",
            "Using the parameters directly directly on the test set and so our results are probably opt."
        ],
        [
            "Mistake so we did also across validation on the training set to decide first on the parameters and then run with these parameters right along the test set.",
            "We did 2 two approaches.",
            "First, we select the first row shows the parameter selected through cross validation with the best result on the training set and the second line Civitan is based on the 10 best results and then we have Reds.",
            "We get the average parameters from this 10 best results.",
            "Of course the result on the Hamming loss was not very big, was not different at all from among these two approaches we see that the results of course is worse than the optimal.",
            "Result on the test set which is given in the third line, but still is better than the best of the other two."
        ],
        [
            "Methods.",
            "And the same more or less applies to their measure.",
            "We can see that we are approximating quite well the values of threshold and the value of K for the size of the label set.",
            "We're not doing quite well on the number of models.",
            "And this time using cross validation using simply cross validation.",
            "Actually the results are worse than the best approach with LP, but using the Civitan approach we managed to get better results than LP.",
            "Still, we are of course worse than the optimal."
        ],
        [
            "Is out on the test set.",
            "OK, we proceed with the same set of results for the use data set so.",
            "Here again, this graph concerts coming last we experimented.",
            "With the value of labels is from 2:00 to 7:00.",
            "We use the small values for K. And they all the corresponding meaningful values of their number of models.",
            "Here we don't even see the best results from the other methods.",
            "Of course, the size where in the vertical axis is a bit narrow.",
            "Anne.",
            "We see that after the 1st 20 models.",
            "All the executions of Raquel better are better than LP and the."
        ],
        [
            "BR.",
            "Here is the graph for left measure.",
            "Again we see that apart from using a two label set which is the.",
            "Lowest line.",
            "For all the rest of the size of label sets, we become better than the best approach, which is LP for the F measure.",
            "OK, an interesting thing to notice is that."
        ],
        [
            "Here actually for the.",
            "For this data set, binary relevance is better than the label Powerset classifier for Hamming loss."
        ],
        [
            "But in that measure, is the other way around.",
            "If they'll be that Beats beer.",
            "And we also notice that the larger the number of labels at the higher the value for K, the better the result."
        ],
        [
            "The graphs that show the performance of the algorithm with the different thresholds.",
            "Again, we see that the higher values of threshold favor the performance of coming in."
        ],
        [
            "I'm English.",
            "And smaller values of Rascal favor the performance on the VF measure."
        ],
        [
            "And the results after the cross validation.",
            "Again, we notice that we are doing pretty well on to.",
            "Guessing the optimal parameters on the test set and we obtained better results than BR, which is the best in this case?"
        ],
        [
            "And their F measure.",
            "We do even better.",
            "We exactly match the threshold and the K value.",
            "And they also the results are better than the best method which is LP concerning F measure."
        ],
        [
            "For the TMC 2007 data set, we only experiment with two values of K due to the high complexity five and seven.",
            "Anti up to 50 models.",
            "The LP was not.",
            "the LP classifier was not computed due to high complexity and we see here that after the first.",
            "15 models the performance of Raquel."
        ],
        [
            "Is better.",
            "Then we are in the same we notice for the."
        ],
        [
            "Measure.",
            "Something different that we notice in the graphs concerning the thresholds is that at this time in incoming loss we saw better performance if we use lower values of rescaled, especially 0.1."
        ],
        [
            "The lowest.",
            "In the same behavior as busy as before we saw."
        ],
        [
            "We see for the F major.",
            "The results after cross validation.",
            "Is that we match?",
            "The size of the label said we don't match the threshold.",
            "We're a bit away.",
            "We're quite away from it.",
            "And but the resulting coming losses are bad."
        ],
        [
            "Then we are at the specially for F Ford F measure.",
            "We're doing a bit better.",
            "We are capturing the threshold better.",
            "We are near to it and we also have much better performance than the beer classifier."
        ],
        [
            "So.",
            "To recap.",
            "We proposed Raquel, which is a new ensemble method for multi label classification.",
            "It constructs and assemble of label partial classifiers.",
            "It's based on a different subset of the set of labels.",
            "It is independent of the actual learning.",
            "Paradigm because it's a problem transformation method.",
            "And the results exhibit improved performance compared to the to some popular popular problem transformation methods.",
            "Now you could argue that perhaps performance is not increased that much, or you may have objections to the LP classifiers underneath.",
            "But I think that the main takeaway from this from this paper is that to consider that the idea of using different subsets of the label, this means that we can perform and assemble to that we can do and assemble approach by considering by manipulating the set of the labels.",
            "I think that this has not been directly addressed in the past.",
            "We here performed to random selection of the subspaces of a fixed size K using LP's, the multi label classifier.",
            "But you could.",
            "Try other approaches.",
            "For example, perform some heuristic selection of the label set instead of random, perhaps based on the correlation of the labels.",
            "And then also we could mix models of different size of subset of subspaces and we and you could use a different multi label classifier instead of the label parser Class 5, but it has to consider to be a classifier that consider."
        ],
        [
            "Label correlations just some resources for those interested in this problem, there is an open source Java software that we develop that includes the BRL P and Raquel algorithms and some other problems that were made through methods.",
            "It computes example in label based evaluation measures and multi label statistiques is built on top of the popular worker library so you can use all existing algorithms that are there.",
            "We have a collection of multi level classification data sets in the format in the AIFF format that is required by this library.",
            "The three ones that were presented in this paper and three more and we have an active bibliography on this is."
        ],
        [
            "So I would like to thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, hello everyone, I'm happy to be here to present your work on the problem of multi label classification using a new and so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "L'approche so you are all familiar with the traditional single label classification where we hear examples are associated with just a single label Lambda from a set of label cell.",
                    "label": 1
                },
                {
                    "sent": "If the size of the of the set of labels is 2, then we have the known problem of binary classification or information retrieval.",
                    "label": 0
                },
                {
                    "sent": "It's also called filtering if the number of labels is larger than two.",
                    "label": 0
                },
                {
                    "sent": "Then this is called the multi class classification problem.",
                    "label": 1
                },
                {
                    "sent": "Now in their multi label classification problem, examples can be associated with a set of labels which is a subset of the original set.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Later.",
                    "label": 0
                },
                {
                    "sent": "And this is an important problem that arises in many domains.",
                    "label": 0
                },
                {
                    "sent": "Traditionally we can find examples of multi label data in text.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location.",
                    "label": 0
                },
                {
                    "sent": "For example, this paper, if we want to train a classifier to assign conference papers to areas, then we could categorize this paper to the areas of ensemble methods and perhaps also to produce.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of complex structures in medical diagnosis apace and can be suffering from more than one diseases.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same time.",
                    "label": 0
                },
                {
                    "sent": "And some.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applications like protein function classification where protein families.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "May overlap.",
                    "label": 0
                },
                {
                    "sent": "Music categorization, where a song can belong to more than one different terms.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the final to semantic scene analysis, where we can annotate images with different labels.",
                    "label": 0
                },
                {
                    "sent": "For example, this image in the lower part we could based on the lower part, we could annotate it as an area Sandy area of bits, and from the top part of the image we could annotate it as an urban area.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the same with this second payments withdrawn from based on the lower part.",
                    "label": 0
                },
                {
                    "sent": "We could annotate it as a filter based on the two parties.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "There has been a lot of work towards dealing with this problem.",
                    "label": 0
                },
                {
                    "sent": "We can categorize the different methods in two groups, problem transformation methods which transform them with the multi label classification problem into one or more single label classification or even regression or label ranking problems.",
                    "label": 1
                },
                {
                    "sent": "And this category of methods are algorithm independent.",
                    "label": 0
                },
                {
                    "sent": "The second category.",
                    "label": 1
                },
                {
                    "sent": "Are the algorithm adaptation methods that adapt specific learning algorithms to directly deal with multiple labels, and there has also been significant work.",
                    "label": 1
                },
                {
                    "sent": "Here are extensions of support vector machine algorithms, decision tree algorithms, probabilistic algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we in this work with we focused on the first group of methods which we consider is more interesting because it's more general and we can use any known Al Gore.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thundermist one of the most popular methods that exist in this category, is the binary relevance method, which trains.",
                    "label": 1
                },
                {
                    "sent": "A single label classifier, binary classifier, one for its different label.",
                    "label": 1
                },
                {
                    "sent": "So it independently treats the labels.",
                    "label": 0
                },
                {
                    "sent": "And that's basically the same solution used to deal with a multiclass problem using a binary classifier.",
                    "label": 0
                },
                {
                    "sent": "Now this method is criticized for for the fact that it doesn't consider the correlation that exists that may be existing.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The multiple labels less known problem transformation method is what we call the label Powerset method, and this method considers its different subset of the set of labels as a single label.",
                    "label": 1
                },
                {
                    "sent": "So in essence, what is what it is doing is language classifier that Maps the instances to the power set of the set of labels.",
                    "label": 1
                },
                {
                    "sent": "Now the criticism of this method is that a large number of different labels may arise due to the power of the set of the size of the set of labels, and many of these labels will include few if any, examples.",
                    "label": 0
                },
                {
                    "sent": "But we can partly alleviate this problem by considering only the distinct subsets that exist in the training set, and this is typically impractical.",
                    "label": 0
                },
                {
                    "sent": "Applications, much less than two to the power of the.",
                    "label": 0
                },
                {
                    "sent": "Size of the set of labels.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the algorithm that we proposed the random care labels at the algorithm what it does in a mess up in a nutshell, is that it cost racks and assemble of Labor power set classifier classifier and it show aims to take into account label correlations because the label Powerset plus five considers correlation.",
                    "label": 1
                },
                {
                    "sent": "But it will train it's LP classifier using only a small.",
                    "label": 1
                },
                {
                    "sent": "Random subset of the set of labels with this attention to avoid.",
                    "label": 0
                },
                {
                    "sent": "The criticism of label partial classifiers that I explained early assembly combination is achieved by thresholding the average 01 decision for it's different label by its model.",
                    "label": 0
                },
                {
                    "sent": "We will explain this steps later on.",
                    "label": 0
                },
                {
                    "sent": "With more detail, first let me introduce some notation.",
                    "label": 1
                },
                {
                    "sent": "What is a K label set?",
                    "label": 0
                },
                {
                    "sent": "Caleb, Caleb and that is simply a subset of the set of labels with K elements, which K labels and we also will be using the notation.",
                    "label": 0
                },
                {
                    "sent": "The superscript notation LK to denote the set of all distinct K label sets on L. Now let.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See, there are several production phase with more detail.",
                    "label": 0
                },
                {
                    "sent": "First we have to choose the size of the label set to the K value of K and then at iteration there again algorithms will randomly select such such a keg label set from the set of all distinct K label sets and it learns from this subset label partial classifier OK.",
                    "label": 0
                },
                {
                    "sent": "So the parameters here in this phase as I said, we have first decide on their size of the label set, which can range from one to the size of set of labels, but the meaningful values, let's say, are between 2:00 and the size of the set of labels minus one.",
                    "label": 0
                },
                {
                    "sent": "'cause if we use if we think of just the one label sets and we set the number of models to the number of labels, then we get the binary relevance method.",
                    "label": 1
                },
                {
                    "sent": "While if we set gay to the number of labels, and consequently we can get only one model, then this is again the label Powerset method.",
                    "label": 0
                },
                {
                    "sent": "So we can also think that Raquel is somewhere in between these two methods.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "We have also to decide on the number of iterations them which can range from one to the size of the set of distinct gay label sets.",
                    "label": 1
                },
                {
                    "sent": "Now they said.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Combination phase, so given a new instance X it's LP model from their models that we have trained provides binary decision for its label that exists in the corresponding label set.",
                    "label": 1
                },
                {
                    "sent": "So if they help classifier decide for one label that it must be predicted, then the output is 1, otherwise it is 0.",
                    "label": 0
                },
                {
                    "sent": "Then Raquel averages the decision for its label.",
                    "label": 0
                },
                {
                    "sent": "Based on these predictions and the final decision is based from this average.",
                    "label": 0
                },
                {
                    "sent": "If it exceeds a certain threshold T. So in this case we have introduced in additional parameter which is the threshold T which can range from.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Zero to 1.",
                    "label": 0
                },
                {
                    "sent": "OK, few words about the computational complexity of the method.",
                    "label": 0
                },
                {
                    "sent": "If we if we consider that sees the set of classes or labels.",
                    "label": 0
                },
                {
                    "sent": "This set of examples and take the set of the attributes.",
                    "label": 0
                },
                {
                    "sent": "And then we can say that the single label classification algorithm used by the LP by the Labour Party plus five has a complexity in the order that is given by function Z.",
                    "label": 0
                },
                {
                    "sent": "Based on these three values, then the computational complexity of Raquel will be this one, which is linear with respect to the number of models.",
                    "label": 1
                },
                {
                    "sent": "As with most sensible methods.",
                    "label": 0
                },
                {
                    "sent": "But we have to be careful.",
                    "label": 0
                },
                {
                    "sent": "About the number of classes which can be high because it's two 2 to the power of K. If you remember based on because we're using underneath the label parser classifier.",
                    "label": 1
                },
                {
                    "sent": "But as we said, we will try to use small values for K to restrict this dimension.",
                    "label": 0
                },
                {
                    "sent": "And also as I mentioned in the criticism for the label partial classifier.",
                    "label": 0
                },
                {
                    "sent": "The larger the value of K, the smaller the distinct subset that we find in the training set, so again, it is not going to be.",
                    "label": 1
                },
                {
                    "sent": "2 to the power of 2.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now in the paper we also provide the categorization of the various evaluation measures that appeared in the literature.",
                    "label": 1
                },
                {
                    "sent": "We can group them into categories, example based evaluation measures for multiple for multi label classification problems.",
                    "label": 0
                },
                {
                    "sent": "These measures calculated difference between the actual set of labels that exist in the example and the predicted set of labels, and then we have had this result.",
                    "label": 0
                },
                {
                    "sent": "Overall examples in the test set the label based measures calculated binary evaluation measure for its label and then we can perform micro or macro averaging operation across all labels.",
                    "label": 1
                },
                {
                    "sent": "As for the precision and recall measures by in the information retrieval community.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here are some of the example based measures that exist in the literature.",
                    "label": 0
                },
                {
                    "sent": "I don't want to stay a lot in this slide.",
                    "label": 0
                },
                {
                    "sent": "The most popular one is the hand gloss, which is based on the symmetric difference between the set of predicted that actual labels.",
                    "label": 1
                },
                {
                    "sent": "And we have rats.",
                    "label": 0
                },
                {
                    "sent": "As I said, all these measures across.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Test examples.",
                    "label": 0
                },
                {
                    "sent": "In the label based measures we can use any known binary valuation measure, and here is an example of how micro and macro operations are performed.",
                    "label": 0
                },
                {
                    "sent": "On the top we can see a binary measure M that is calculated based on the true positives.",
                    "label": 0
                },
                {
                    "sent": "False positive false positives, negatives and false negatives for its label Lambda and we first compute this measured parets label and then others the results one in the micro averaging we sum up the statistics and we then compare.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Their measure.",
                    "label": 0
                },
                {
                    "sent": "OK, now to the experiment.",
                    "label": 0
                },
                {
                    "sent": "We did some experimental work to evaluate our algorithm.",
                    "label": 0
                },
                {
                    "sent": "We use three data sets from three different domains.",
                    "label": 0
                },
                {
                    "sent": "The same data set from the semantic indexing of still since.",
                    "label": 1
                },
                {
                    "sent": "That EMC 2007 data set is a data set from the text mining competition of the same data Mining Government Conference in 2007.",
                    "label": 1
                },
                {
                    "sent": "It concerns documents about aviation safety.",
                    "label": 0
                },
                {
                    "sent": "As you can see in the table, this is a high dimensional data set consisting of about 49,000 attributes.",
                    "label": 0
                },
                {
                    "sent": "To reduce the complexity, we did some feature selection and we selected the five counter features based on the maximum squared rack overall labels.",
                    "label": 0
                },
                {
                    "sent": "So even feature selection needs.",
                    "label": 0
                },
                {
                    "sent": "A particular approach to the because the data set is multi label, so we take the maximum we can take the maximum or the average.",
                    "label": 0
                },
                {
                    "sent": "There are several approach and the well known list data set which is used in many papers on multi label classification.",
                    "label": 1
                },
                {
                    "sent": "Which has to do with protein function classification and in the in the table apart from the classical single label statistiques, you can also see some multi label statistics like the number of differently label set that as I told you is much smaller in the training set.",
                    "label": 0
                },
                {
                    "sent": "So you can see for example that we have six labels but the distinct subsets are only 15 less than two to the power of 6 and so.",
                    "label": 0
                },
                {
                    "sent": "And the same for the other datasets, and we can also see the label cardinality, which is the mean number of labels, for example, and the normalized version of it, which we divide this number.",
                    "label": 1
                },
                {
                    "sent": "By the way, the number of labels which we call label disc.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The methods that we comparing the experiments apart from.",
                    "label": 0
                },
                {
                    "sent": "Raquel algorithm, which we we experiment with 10 different thresholds from zero, 1209 and we run it with different number of models and the label says we also compare against the binary relevance of the label Powerset method underneath.",
                    "label": 1
                },
                {
                    "sent": "For all algorithms we use a support vector machine algorithm and the valuation methodologies that we use the original training and test splits provided within the source of the data sets.",
                    "label": 1
                },
                {
                    "sent": "And for the measures we calculate the Hamming loss in the Microverse with measures which are the most popular ones for this kind of tasks.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's see the results for the same data set.",
                    "label": 1
                },
                {
                    "sent": "In this graph, the horizontal axis is the number of models.",
                    "label": 1
                },
                {
                    "sent": "The vertical axis we see the Hamming loss, they lower the camera close, the better the performance.",
                    "label": 0
                },
                {
                    "sent": "We can see that the LP classifier is actually better than their most popular binary relevance classifier.",
                    "label": 0
                },
                {
                    "sent": "And we see also that the performance of Raquel for a threshold of 0.5 at default threshold that we used with all meaningful meaningful values of the K parameter.",
                    "label": 0
                },
                {
                    "sent": "Antall meaningful values for the number of models.",
                    "label": 1
                },
                {
                    "sent": "And what I want to say about this graph is that we see that Raquel can achieve.",
                    "label": 0
                },
                {
                    "sent": "Good performance for awhile.",
                    "label": 0
                },
                {
                    "sent": "Range of parameters.",
                    "label": 0
                },
                {
                    "sent": "The same applies for the graph concerning.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've measured.",
                    "label": 0
                },
                {
                    "sent": "Again, we see 4K equal to three and K equal to four and the reasonable number of models to.",
                    "label": 0
                },
                {
                    "sent": "Jump to the performance to becoming better than the LP classifier.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we also.",
                    "label": 0
                },
                {
                    "sent": "Here, so in this graph, the performance of the algorithm when we vary the threshold from zero one to 09.",
                    "label": 0
                },
                {
                    "sent": "And we take the optimal value for K for the K and 10 parameters.",
                    "label": 0
                },
                {
                    "sent": "So what we notice here is that.",
                    "label": 0
                },
                {
                    "sent": "Actually, for a greater fiscal around 0.6 and 0.7 we can see boot performance for a label sets from 2 to.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "4.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "From for that measure, on the other hand, we see that lower threshold values leads to better performance, so we see that thresholds around 0.3 and 0.4.",
                    "label": 0
                },
                {
                    "sent": "Give the best results.",
                    "label": 0
                },
                {
                    "sent": "Now of course, this graph cannot be used to directly compare the Raquel algorithm with the binary relevance in the label Powerset method, because I.",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "Using the parameters directly directly on the test set and so our results are probably opt.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mistake so we did also across validation on the training set to decide first on the parameters and then run with these parameters right along the test set.",
                    "label": 0
                },
                {
                    "sent": "We did 2 two approaches.",
                    "label": 0
                },
                {
                    "sent": "First, we select the first row shows the parameter selected through cross validation with the best result on the training set and the second line Civitan is based on the 10 best results and then we have Reds.",
                    "label": 1
                },
                {
                    "sent": "We get the average parameters from this 10 best results.",
                    "label": 0
                },
                {
                    "sent": "Of course the result on the Hamming loss was not very big, was not different at all from among these two approaches we see that the results of course is worse than the optimal.",
                    "label": 0
                },
                {
                    "sent": "Result on the test set which is given in the third line, but still is better than the best of the other two.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods.",
                    "label": 0
                },
                {
                    "sent": "And the same more or less applies to their measure.",
                    "label": 0
                },
                {
                    "sent": "We can see that we are approximating quite well the values of threshold and the value of K for the size of the label set.",
                    "label": 0
                },
                {
                    "sent": "We're not doing quite well on the number of models.",
                    "label": 0
                },
                {
                    "sent": "And this time using cross validation using simply cross validation.",
                    "label": 0
                },
                {
                    "sent": "Actually the results are worse than the best approach with LP, but using the Civitan approach we managed to get better results than LP.",
                    "label": 0
                },
                {
                    "sent": "Still, we are of course worse than the optimal.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is out on the test set.",
                    "label": 0
                },
                {
                    "sent": "OK, we proceed with the same set of results for the use data set so.",
                    "label": 1
                },
                {
                    "sent": "Here again, this graph concerts coming last we experimented.",
                    "label": 1
                },
                {
                    "sent": "With the value of labels is from 2:00 to 7:00.",
                    "label": 1
                },
                {
                    "sent": "We use the small values for K. And they all the corresponding meaningful values of their number of models.",
                    "label": 0
                },
                {
                    "sent": "Here we don't even see the best results from the other methods.",
                    "label": 0
                },
                {
                    "sent": "Of course, the size where in the vertical axis is a bit narrow.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "We see that after the 1st 20 models.",
                    "label": 0
                },
                {
                    "sent": "All the executions of Raquel better are better than LP and the.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "BR.",
                    "label": 0
                },
                {
                    "sent": "Here is the graph for left measure.",
                    "label": 0
                },
                {
                    "sent": "Again we see that apart from using a two label set which is the.",
                    "label": 0
                },
                {
                    "sent": "Lowest line.",
                    "label": 0
                },
                {
                    "sent": "For all the rest of the size of label sets, we become better than the best approach, which is LP for the F measure.",
                    "label": 0
                },
                {
                    "sent": "OK, an interesting thing to notice is that.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here actually for the.",
                    "label": 0
                },
                {
                    "sent": "For this data set, binary relevance is better than the label Powerset classifier for Hamming loss.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But in that measure, is the other way around.",
                    "label": 0
                },
                {
                    "sent": "If they'll be that Beats beer.",
                    "label": 0
                },
                {
                    "sent": "And we also notice that the larger the number of labels at the higher the value for K, the better the result.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The graphs that show the performance of the algorithm with the different thresholds.",
                    "label": 0
                },
                {
                    "sent": "Again, we see that the higher values of threshold favor the performance of coming in.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm English.",
                    "label": 0
                },
                {
                    "sent": "And smaller values of Rascal favor the performance on the VF measure.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the results after the cross validation.",
                    "label": 1
                },
                {
                    "sent": "Again, we notice that we are doing pretty well on to.",
                    "label": 0
                },
                {
                    "sent": "Guessing the optimal parameters on the test set and we obtained better results than BR, which is the best in this case?",
                    "label": 1
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And their F measure.",
                    "label": 0
                },
                {
                    "sent": "We do even better.",
                    "label": 0
                },
                {
                    "sent": "We exactly match the threshold and the K value.",
                    "label": 0
                },
                {
                    "sent": "And they also the results are better than the best method which is LP concerning F measure.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the TMC 2007 data set, we only experiment with two values of K due to the high complexity five and seven.",
                    "label": 0
                },
                {
                    "sent": "Anti up to 50 models.",
                    "label": 0
                },
                {
                    "sent": "The LP was not.",
                    "label": 0
                },
                {
                    "sent": "the LP classifier was not computed due to high complexity and we see here that after the first.",
                    "label": 0
                },
                {
                    "sent": "15 models the performance of Raquel.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is better.",
                    "label": 0
                },
                {
                    "sent": "Then we are in the same we notice for the.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measure.",
                    "label": 0
                },
                {
                    "sent": "Something different that we notice in the graphs concerning the thresholds is that at this time in incoming loss we saw better performance if we use lower values of rescaled, especially 0.1.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The lowest.",
                    "label": 0
                },
                {
                    "sent": "In the same behavior as busy as before we saw.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We see for the F major.",
                    "label": 0
                },
                {
                    "sent": "The results after cross validation.",
                    "label": 0
                },
                {
                    "sent": "Is that we match?",
                    "label": 0
                },
                {
                    "sent": "The size of the label said we don't match the threshold.",
                    "label": 0
                },
                {
                    "sent": "We're a bit away.",
                    "label": 0
                },
                {
                    "sent": "We're quite away from it.",
                    "label": 0
                },
                {
                    "sent": "And but the resulting coming losses are bad.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we are at the specially for F Ford F measure.",
                    "label": 0
                },
                {
                    "sent": "We're doing a bit better.",
                    "label": 0
                },
                {
                    "sent": "We are capturing the threshold better.",
                    "label": 0
                },
                {
                    "sent": "We are near to it and we also have much better performance than the beer classifier.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To recap.",
                    "label": 0
                },
                {
                    "sent": "We proposed Raquel, which is a new ensemble method for multi label classification.",
                    "label": 1
                },
                {
                    "sent": "It constructs and assemble of label partial classifiers.",
                    "label": 0
                },
                {
                    "sent": "It's based on a different subset of the set of labels.",
                    "label": 1
                },
                {
                    "sent": "It is independent of the actual learning.",
                    "label": 1
                },
                {
                    "sent": "Paradigm because it's a problem transformation method.",
                    "label": 0
                },
                {
                    "sent": "And the results exhibit improved performance compared to the to some popular popular problem transformation methods.",
                    "label": 0
                },
                {
                    "sent": "Now you could argue that perhaps performance is not increased that much, or you may have objections to the LP classifiers underneath.",
                    "label": 0
                },
                {
                    "sent": "But I think that the main takeaway from this from this paper is that to consider that the idea of using different subsets of the label, this means that we can perform and assemble to that we can do and assemble approach by considering by manipulating the set of the labels.",
                    "label": 0
                },
                {
                    "sent": "I think that this has not been directly addressed in the past.",
                    "label": 0
                },
                {
                    "sent": "We here performed to random selection of the subspaces of a fixed size K using LP's, the multi label classifier.",
                    "label": 1
                },
                {
                    "sent": "But you could.",
                    "label": 0
                },
                {
                    "sent": "Try other approaches.",
                    "label": 0
                },
                {
                    "sent": "For example, perform some heuristic selection of the label set instead of random, perhaps based on the correlation of the labels.",
                    "label": 0
                },
                {
                    "sent": "And then also we could mix models of different size of subset of subspaces and we and you could use a different multi label classifier instead of the label parser Class 5, but it has to consider to be a classifier that consider.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Label correlations just some resources for those interested in this problem, there is an open source Java software that we develop that includes the BRL P and Raquel algorithms and some other problems that were made through methods.",
                    "label": 1
                },
                {
                    "sent": "It computes example in label based evaluation measures and multi label statistiques is built on top of the popular worker library so you can use all existing algorithms that are there.",
                    "label": 0
                },
                {
                    "sent": "We have a collection of multi level classification data sets in the format in the AIFF format that is required by this library.",
                    "label": 0
                },
                {
                    "sent": "The three ones that were presented in this paper and three more and we have an active bibliography on this is.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I would like to thank you.",
                    "label": 0
                }
            ]
        }
    }
}