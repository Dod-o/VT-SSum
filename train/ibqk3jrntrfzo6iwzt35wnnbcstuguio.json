{
    "id": "ibqk3jrntrfzo6iwzt35wnnbcstuguio",
    "title": "Combining Referring Expression Generation and Surface Realization",
    "info": {
        "author": [
            "Sina Zarrie\u00df, Institute for Natural Language Processing, University of Stuttgart"
        ],
        "published": "Oct. 2, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Computational Linguistics"
        ]
    },
    "url": "http://videolectures.net/acl2013_zarriesa_realization/",
    "segmentation": [
        [
            "So very."
        ],
        [
            "Are we speaking in this talk on this work?",
            "We wanted to design a system that is able to generate coherent text from an abstract representation of a content or message.",
            "So in our data these abstract representation look like these trees that have certain relations.",
            "So there's somebody who's on trial and we have this attack relation and we have reference.",
            "So we have a robber and victim perpetrator, and depending on the choices.",
            "That our generator makes for realizing this reference in these relations with surface raises the output of our system is more or less natural."
        ],
        [
            "So we work in the paradigm of corpus based generation, so we want to learn to make these choices by observing them in corpus data.",
            "So if you want to learn about the rope relation or robbery events, we look at text that describe crimes.",
            "And we annotate these texts so that we know which phrases actually realize our reference in our relations.",
            "And maybe we also annotate if there's certain implicit reference, maybe, and on the basis of these annotations we can learn a model that actually describes these configurations.",
            "That we want to learn.",
            "So do we have a passive with a pronominal victim and an implicit purpose?",
            "Or do we have an active with an indefinite victim into relative pronoun things like that?"
        ],
        [
            "So how do we use this model then for generation?",
            "So we have this abstract tree as our unseen input.",
            "And or generator produces several service candidates for this tree.",
            "And then we can actually use our model to rank these configurations that generator produces.",
            "And if we've good model, the output will correspond or the top ranked sentence will be a natural output.",
            "OK."
        ],
        [
            "So after this very general background on corpus based generation, I will first provide some more motivation on the definition of our generation task.",
            "Then I will describe our data set in our generation components and finally come to expect."
        ],
        [
            "It's.",
            "So there has recently been a lot of interest in this statistical corpus based generation medicine methods and there are two well studied paradigms basically.",
            "So one is surface realization where people, for instance in the shared task take existing treebank annotations and try to predict word order, syntactic realization.",
            "And there's referring expression generation where people try to predict, for instance, formalizations on text with entity annotations.",
            "But the limitation is that.",
            "Attask are often addressed as separated isolated problems.",
            "But"
        ],
        [
            "Of course, when you look at data, these choices are not isolated or separate at all.",
            "So in a standard setup office, surface realization tasks people actually look at trees where you have referring expressions where with the reference expressions are given from the original corpus sentence.",
            "So and this actually.",
            "Leads to a situation where these referring expressions already reflect a lot of the syntactic choices.",
            "So if you have, if you know that attack has two arguments and the agent is phenomenal, it's really likely that it will be finite, whereas if you only have one argument for attack, it's really likely that it will be a normalization or passive, for instance."
        ],
        [
            "OK, so we propose this combined generation task where you actually have to do surface realization and referring expression generation.",
            "And the challenge is that the generator now has to really model the interaction between these two.",
            "2 between these two levels of choices."
        ],
        [
            "OK. And this is actually these multi level generation problems have actually been a big issue in all of generation research.",
            "So if you look at the classic literature, the standard approach is this pipeline that you find all over the place.",
            "So you first do this discourse level, task, document planning, send and spelling and then you do surface realization.",
            "But there are a lot of well known problems with this pipeline.",
            "So first of all you get this error propagation that you always get in pipeline architectures.",
            "And then there's this conceptual problem that it's pretty well known that discourse level decisions cannot actually be isolated from sentence level decisions, so this is also known as the generation gap problem.",
            "And the place of referring expression generation in the pipeline has been notorious problem.",
            "So if you look at 5 different generate applied generation systems, you are likely to find 5 different solutions for placing Origi in the pipeline."
        ],
        [
            "So we propose a corpus based framework to actually address this problem in investigate generation architectures in a data driven way, and we do this by integrating existing annotation standards, and we add some more types of implicit reference to really capture this nice interactions."
        ],
        [
            "So we had to create a data set to to address this task.",
            "And our generator is based on three trainable modules, so we have a synthetic module said basically produces these syntactic realizations.",
            "We have a referring expression module that inserts these referring expression candidates and linearizer and you can investigate a number of changes.",
            "Number of experimental parameters in this setting.",
            "In this talk I will focus on the order of the modules."
        ],
        [
            "So our data set is created on German text 200, text 2030 sentences, and we actually collected newspaper articles that describe robberies and we didn't selected this text type because of.",
            "This is a text that typically mentions two reference in a lot of sentences.",
            "So we have long entity chains for victims and perpetrators, but and we have in this new.",
            "Newspaper Corp is unrestricted syntax and because we're dealing with German, it's free word order."
        ],
        [
            "OK, so how do we create our annotations?",
            "This is a short example.",
            "And we first create two layers of an annotations.",
            "So on the one hand we manually annotate our reference so we annotate all mentions of victims and perpetrators, and we also annotate when there's an implicit mention.",
            "And on the other hand we apply a dependency parser on our data set so that we can get a syntactic representation.",
            "And then we combine these two layers by marking the constituents of the spans and the dependency trees that are actually annotated as referenced by our annotators."
        ],
        [
            "So and then we create something what we call shallow dependencies with referring expression slots.",
            "So in our dependency trees we replace the surface referring expressions by our simple placeholders for our reference.",
            "So we only know whether there's a victim or perpetrator as a subject.",
            "But we keep the original referring expressions in a separate list, and this will actually be the candidates for our generation module."
        ],
        [
            "So then we go one step further and actually map these shallow dependencies with referring expressions.",
            "Lots too deep dependencies.",
            "So this is really similar to this surface realization tasks from 2011.",
            "So we apply a number of rule based transformations that mainly address passives and normalizations.",
            "So we remove auxiliary as we generalize syntactic functions so that we get a uniform.",
            "Dependencies deep dependency representations for these relations.",
            "And then.",
            "By looking at the alignments of the deep and shallow dependencies, we can actually extract candidates for these relations.",
            "So we for such webnode in the deep dependency tree, we will extract a number of shallow candidates, so which has an auxiliary or normalization.",
            "OK."
        ],
        [
            "So then there's a list of our generation modules and the setup of the referring expression and the syntax module is pretty similar.",
            "So the referring expression module.",
            "Actually has in its input candidate list, so which contains the possible referring expressions for a given slot in the tree in independency tree.",
            "And we represent this by feature vectors and rank them SVM rank.",
            "And the syntax module.",
            "Actually has to produce a surface with realization for a verb Nodena deep dependency trees and it has a list of these shallow candidates and also ranks them, and for linear linearisation we use this state of the art linearizer implemented by brunette I and train it on a German corpus.",
            "On another"
        ],
        [
            "Corpus so now we have several options for ordering our generation modules.",
            "So we start from a deep dependency tree with referring expression slots.",
            "And then we have the choice of either applying first refering expressions, generating a deep tree with surface with referring expressions and then applying syntax.",
            "Or the other way around.",
            "And depending on where we apply the modules in the pipeline they were actually have slightly different feature models.",
            "So for instance, when we apply the referring expression generation first, this module doesn't have access to surface syntax, so it only knows whether the slot is for instance in Agent slot."
        ],
        [
            "The rest in the shadow of when it's applied after the syntax module, it knows whether it's a subject or object."
        ],
        [
            "So the same holds for the syntax if it's applied before the referring expressions.",
            "It often doesn't know how its arguments will be realized, so it only knows whether there's a victim or perpetrator.",
            "But if it's applied after refering expression, the syntax module knows whether there will be pronouns in its argument or definite descriptions."
        ],
        [
            "OK, so let's come to our first evaluation.",
            "We did 10 fold cross validation on 200 text.",
            "Our senses are lemmatized, and in this talk I will focus on this remelt measures, so we looked at the blue score.",
            "We have a accuracy measure for the syntax module, which is basically the exact string match and an accuracy for the referring expressions, which is also the proportion of exactly matching referring expressions."
        ],
        [
            "So when we first look at the Bleu score.",
            "For the two pipelines, they really perform very similarly, so we don't observe a big difference."
        ],
        [
            "Now, so why is this the case?",
            "So when we look at the accuracy of the syntactic module, we see that it actually suffers from the errors made by the referring expression model, so it's.",
            "Performance is worse when it's applied second module in a pipeline, and it's better when it's applied as a first module."
        ],
        [
            "And.",
            "The reverse thing is true for the referring expression generation, so it also suffers from the errors made by the syntax module, so it is better to apply it first in the pipeline and it makes more errors when it's applied as a second module."
        ],
        [
            "So then we look at some lower and upper bounds, so we have a robust baseline, which has a very low blue score, and if we apply linearisation on our original dependency trees we get get a much higher blue score.",
            "So this shows that the generator.",
            "So that these task of referring expression and syntax realization introduce a lot of uncertainty into the into the generation problem, but the pipelines almost do the same thing."
        ],
        [
            "So how can we address this typical effect of error propagation?",
            "So."
        ],
        [
            "A very simple way.",
            "All would be to simply take the independent predictions by the two modules.",
            "So to simply take these best predictions and combine them in a representation."
        ],
        [
            "But when we do this, we see that the blue score also only very marginally improves over the pipelines.",
            "OK. And in a way, it's not really surprising, because the system also doesn't really address interactions and really makes simply makes the predictions independent."
        ],
        [
            "So then we experimented with another architecture, which we call revision based architecture here.",
            "And the main idea is that we can also vary the position of the linearisation in the pipeline and what we do is we apply an intermediate linearization step after the syntactic module, then apply referring expressions with a feature model that has some additional positional features, and then we apply the linearizer again and this is more divided by a lot of theoretical research that shows interactions between referring expressions and linearizations.",
            "And these revision based architecture have been proposed in the literature before as.",
            "Approximations of integrated architectures, actually."
        ],
        [
            "OK, so.",
            "Let's evaluate our revision based architecture."
        ],
        [
            "So.",
            "We now see that this architecture clearly improves over the over the pipelines in the parallel system, so we get a nice improvement in blue.",
            "And we see that the the referring expression Model now performs much better when it's applied on these intermediate linearizations of the of the shallow dependencies.",
            "So there we don't have an error propagation of the referring expression model anymore, but it performs better as compared to when we apply it simply on deep dependencies.",
            "OK."
        ],
        [
            "So now our Blues Blue score is simply measuring engram overlap.",
            "So if we improve the accuracy of our referring expressions, it's kind of expected that we improve the blue score because we will have more overlapping engrams, so.",
            "Is this improvement of the revision based system only due to this lexical overlap?",
            "So we define another blue score or another measure for assessing this a little bit.",
            "So what we do is we replace all the referring expressions in the gold and the predicted sentence by a placeholder and then we measure blue and what we get is a blue score that basically factors out the lexical overlap for the reference."
        ],
        [
            "And when we do this.",
            "We actually also see a nice improvement of this modified Bleu score between the parallel and the reversion based architecture, so this indicates that we do not only improve the reference, but we also get better sentence quality, better linearisation."
        ],
        [
            "OK.",
            "So here are my conclusions.",
            "I think in this talk we should we showed that there's a straight forward way of integrating existing annotation standards for referring expression and surface realization.",
            "And that this can be useful for doing data driven studies of generation architectures.",
            "So our results point to shortcomings of the standard pipeline setup, and we showed that.",
            "These data driven generation system really need to capture interactions and we proposed this revision based method for doing this.",
            "Thanks.",
            "Thank you.",
            "I'm sorry, but I cannot resist pointing out.",
            "That we had a publication in 2005 to machine again myself.",
            "We did an integrated approach using integer linear programming, showing exact your Third Point here.",
            "Yeah yeah, OK, yeah, this was nine generation modules.",
            "Yeah, integrated with idle P. OK yeah, and we showed these shortcomings.",
            "That's also Nina deadlifts PhD thesis, which is which is unpublished and there must be some publication by her doing exactly the same thing.",
            "Yeah, so I actually cited you in in our article and pointed out some differences.",
            "Wrong with our first, but with our first results.",
            "There's, I think there's nothing wrong with your first results, I think, like in your work.",
            "So you have a different data set, which is also, so my impression was from reading your article that.",
            "You have a little bit less variation, so in."
        ],
        [
            "In our in our architecture.",
            "Like for instance, is this linear?",
            "Is this linearisation problem we couldn't?",
            "We couldn't address it by a simple classifier.",
            "So in your work, you're basically combining several classifier in a in an LP framework and.",
            "In our data we have so many variations that we cannot label each decision by a label for a classifier.",
            "So we have a pretty complex range and This is why your business provides new insights.",
            "I think This is why you, why your results of the 1st results.",
            "No, I don't want to say that this is the 1st result ever.",
            "On on generation architectures or pipelines, it's my first results that I presented in this talk.",
            "Sorry I misunderstood your question.",
            "Hello so to me your results are very interesting, is more about the users that VM rank.",
            "Have you considered just pulling a human to do the task?",
            "So you give this information?"
        ],
        [
            "And you ask the human to write the things cause with the machine learning.",
            "You are also evaluating how well SVM rank behaves with that type of information.",
            "So that's a big component of your results.",
            "In a sense, SVM rank is better given that data, but if you can shield from that, you can just give that type of data to a human and see how well they can write the text and also get some feedback out of whether this is way to constrain or or yeah.",
            "Make no sense.",
            "So you want to say that I should do some human evaluation at some point or so.",
            "I'm not saying you should, but maybe you you can consider.",
            "Yeah, I definitely agree that these completely automatic methods do not provide full insight on whether we actually generate coherent text swinging or no.",
            "I'm not saying about doing human evaluation, I'm doing doing human execution.",
            "So you take these type of things, you say well.",
            "Your task is, given these, write a sentence and then people will say oh, this is a horrible task.",
            "Yeah, you're putting me in a really complex situation and then that could be an interesting conclusion to say.",
            "Well, so I think Anya belts did this in referring expression generation paper.",
            "So they really asked humans to do this exactly this task.",
            "And of course they found a lot of disagreement.",
            "So it's actually surprising how.",
            "How little humans agree on where to realize pronouns or definite descriptions in a text.",
            "So there's also a certain upper bound that we would get from the human agreement I think, or from human generated.",
            "I want to find could ask your question when you showed your two pipelines you talked about how the information available at each stage was different.",
            "Yeah, could you show that slide again actually?"
        ],
        [
            "Right, so I just wonder on the right hand one so they're referring expression generation has access to the shallow tree, the shallow labels?",
            "Yeah, does it have access to the deep ones as well?",
            "Yeah, yeah yeah, OK?",
            "And I guess another question I had was.",
            "You've done this on a relatively small example.",
            "Yeah, it's a nice neat one where you can get good data.",
            "Yeah, have you thought about?",
            "Is there any way you could do this on a larger scale somehow?",
            "Yeah, I mean.",
            "It's actually pretty easy to get these syntactic representations, so we already did this in the semi automatic or automatic way, so I think there are like it would be possible maybe to use different corpora that are annotated with all sorts of entities.",
            "I think it would be possible to do this for for other types of data, but you have to get these entities represent or you have to know about this reference.",
            "Price lot of deepish semantics there yes yes yeah.",
            "Very nice thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So very.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are we speaking in this talk on this work?",
                    "label": 0
                },
                {
                    "sent": "We wanted to design a system that is able to generate coherent text from an abstract representation of a content or message.",
                    "label": 1
                },
                {
                    "sent": "So in our data these abstract representation look like these trees that have certain relations.",
                    "label": 0
                },
                {
                    "sent": "So there's somebody who's on trial and we have this attack relation and we have reference.",
                    "label": 1
                },
                {
                    "sent": "So we have a robber and victim perpetrator, and depending on the choices.",
                    "label": 0
                },
                {
                    "sent": "That our generator makes for realizing this reference in these relations with surface raises the output of our system is more or less natural.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we work in the paradigm of corpus based generation, so we want to learn to make these choices by observing them in corpus data.",
                    "label": 0
                },
                {
                    "sent": "So if you want to learn about the rope relation or robbery events, we look at text that describe crimes.",
                    "label": 0
                },
                {
                    "sent": "And we annotate these texts so that we know which phrases actually realize our reference in our relations.",
                    "label": 0
                },
                {
                    "sent": "And maybe we also annotate if there's certain implicit reference, maybe, and on the basis of these annotations we can learn a model that actually describes these configurations.",
                    "label": 0
                },
                {
                    "sent": "That we want to learn.",
                    "label": 0
                },
                {
                    "sent": "So do we have a passive with a pronominal victim and an implicit purpose?",
                    "label": 0
                },
                {
                    "sent": "Or do we have an active with an indefinite victim into relative pronoun things like that?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we use this model then for generation?",
                    "label": 0
                },
                {
                    "sent": "So we have this abstract tree as our unseen input.",
                    "label": 0
                },
                {
                    "sent": "And or generator produces several service candidates for this tree.",
                    "label": 0
                },
                {
                    "sent": "And then we can actually use our model to rank these configurations that generator produces.",
                    "label": 0
                },
                {
                    "sent": "And if we've good model, the output will correspond or the top ranked sentence will be a natural output.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So after this very general background on corpus based generation, I will first provide some more motivation on the definition of our generation task.",
                    "label": 0
                },
                {
                    "sent": "Then I will describe our data set in our generation components and finally come to expect.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "So there has recently been a lot of interest in this statistical corpus based generation medicine methods and there are two well studied paradigms basically.",
                    "label": 0
                },
                {
                    "sent": "So one is surface realization where people, for instance in the shared task take existing treebank annotations and try to predict word order, syntactic realization.",
                    "label": 1
                },
                {
                    "sent": "And there's referring expression generation where people try to predict, for instance, formalizations on text with entity annotations.",
                    "label": 1
                },
                {
                    "sent": "But the limitation is that.",
                    "label": 0
                },
                {
                    "sent": "Attask are often addressed as separated isolated problems.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course, when you look at data, these choices are not isolated or separate at all.",
                    "label": 0
                },
                {
                    "sent": "So in a standard setup office, surface realization tasks people actually look at trees where you have referring expressions where with the reference expressions are given from the original corpus sentence.",
                    "label": 1
                },
                {
                    "sent": "So and this actually.",
                    "label": 1
                },
                {
                    "sent": "Leads to a situation where these referring expressions already reflect a lot of the syntactic choices.",
                    "label": 0
                },
                {
                    "sent": "So if you have, if you know that attack has two arguments and the agent is phenomenal, it's really likely that it will be finite, whereas if you only have one argument for attack, it's really likely that it will be a normalization or passive, for instance.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we propose this combined generation task where you actually have to do surface realization and referring expression generation.",
                    "label": 1
                },
                {
                    "sent": "And the challenge is that the generator now has to really model the interaction between these two.",
                    "label": 0
                },
                {
                    "sent": "2 between these two levels of choices.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And this is actually these multi level generation problems have actually been a big issue in all of generation research.",
                    "label": 1
                },
                {
                    "sent": "So if you look at the classic literature, the standard approach is this pipeline that you find all over the place.",
                    "label": 0
                },
                {
                    "sent": "So you first do this discourse level, task, document planning, send and spelling and then you do surface realization.",
                    "label": 1
                },
                {
                    "sent": "But there are a lot of well known problems with this pipeline.",
                    "label": 0
                },
                {
                    "sent": "So first of all you get this error propagation that you always get in pipeline architectures.",
                    "label": 0
                },
                {
                    "sent": "And then there's this conceptual problem that it's pretty well known that discourse level decisions cannot actually be isolated from sentence level decisions, so this is also known as the generation gap problem.",
                    "label": 0
                },
                {
                    "sent": "And the place of referring expression generation in the pipeline has been notorious problem.",
                    "label": 1
                },
                {
                    "sent": "So if you look at 5 different generate applied generation systems, you are likely to find 5 different solutions for placing Origi in the pipeline.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we propose a corpus based framework to actually address this problem in investigate generation architectures in a data driven way, and we do this by integrating existing annotation standards, and we add some more types of implicit reference to really capture this nice interactions.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we had to create a data set to to address this task.",
                    "label": 0
                },
                {
                    "sent": "And our generator is based on three trainable modules, so we have a synthetic module said basically produces these syntactic realizations.",
                    "label": 1
                },
                {
                    "sent": "We have a referring expression module that inserts these referring expression candidates and linearizer and you can investigate a number of changes.",
                    "label": 1
                },
                {
                    "sent": "Number of experimental parameters in this setting.",
                    "label": 0
                },
                {
                    "sent": "In this talk I will focus on the order of the modules.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our data set is created on German text 200, text 2030 sentences, and we actually collected newspaper articles that describe robberies and we didn't selected this text type because of.",
                    "label": 1
                },
                {
                    "sent": "This is a text that typically mentions two reference in a lot of sentences.",
                    "label": 0
                },
                {
                    "sent": "So we have long entity chains for victims and perpetrators, but and we have in this new.",
                    "label": 1
                },
                {
                    "sent": "Newspaper Corp is unrestricted syntax and because we're dealing with German, it's free word order.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how do we create our annotations?",
                    "label": 0
                },
                {
                    "sent": "This is a short example.",
                    "label": 0
                },
                {
                    "sent": "And we first create two layers of an annotations.",
                    "label": 0
                },
                {
                    "sent": "So on the one hand we manually annotate our reference so we annotate all mentions of victims and perpetrators, and we also annotate when there's an implicit mention.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand we apply a dependency parser on our data set so that we can get a syntactic representation.",
                    "label": 0
                },
                {
                    "sent": "And then we combine these two layers by marking the constituents of the spans and the dependency trees that are actually annotated as referenced by our annotators.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and then we create something what we call shallow dependencies with referring expression slots.",
                    "label": 0
                },
                {
                    "sent": "So in our dependency trees we replace the surface referring expressions by our simple placeholders for our reference.",
                    "label": 0
                },
                {
                    "sent": "So we only know whether there's a victim or perpetrator as a subject.",
                    "label": 0
                },
                {
                    "sent": "But we keep the original referring expressions in a separate list, and this will actually be the candidates for our generation module.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we go one step further and actually map these shallow dependencies with referring expressions.",
                    "label": 0
                },
                {
                    "sent": "Lots too deep dependencies.",
                    "label": 0
                },
                {
                    "sent": "So this is really similar to this surface realization tasks from 2011.",
                    "label": 0
                },
                {
                    "sent": "So we apply a number of rule based transformations that mainly address passives and normalizations.",
                    "label": 0
                },
                {
                    "sent": "So we remove auxiliary as we generalize syntactic functions so that we get a uniform.",
                    "label": 0
                },
                {
                    "sent": "Dependencies deep dependency representations for these relations.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "By looking at the alignments of the deep and shallow dependencies, we can actually extract candidates for these relations.",
                    "label": 0
                },
                {
                    "sent": "So we for such webnode in the deep dependency tree, we will extract a number of shallow candidates, so which has an auxiliary or normalization.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then there's a list of our generation modules and the setup of the referring expression and the syntax module is pretty similar.",
                    "label": 1
                },
                {
                    "sent": "So the referring expression module.",
                    "label": 0
                },
                {
                    "sent": "Actually has in its input candidate list, so which contains the possible referring expressions for a given slot in the tree in independency tree.",
                    "label": 1
                },
                {
                    "sent": "And we represent this by feature vectors and rank them SVM rank.",
                    "label": 0
                },
                {
                    "sent": "And the syntax module.",
                    "label": 1
                },
                {
                    "sent": "Actually has to produce a surface with realization for a verb Nodena deep dependency trees and it has a list of these shallow candidates and also ranks them, and for linear linearisation we use this state of the art linearizer implemented by brunette I and train it on a German corpus.",
                    "label": 0
                },
                {
                    "sent": "On another",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Corpus so now we have several options for ordering our generation modules.",
                    "label": 0
                },
                {
                    "sent": "So we start from a deep dependency tree with referring expression slots.",
                    "label": 0
                },
                {
                    "sent": "And then we have the choice of either applying first refering expressions, generating a deep tree with surface with referring expressions and then applying syntax.",
                    "label": 0
                },
                {
                    "sent": "Or the other way around.",
                    "label": 0
                },
                {
                    "sent": "And depending on where we apply the modules in the pipeline they were actually have slightly different feature models.",
                    "label": 0
                },
                {
                    "sent": "So for instance, when we apply the referring expression generation first, this module doesn't have access to surface syntax, so it only knows whether the slot is for instance in Agent slot.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The rest in the shadow of when it's applied after the syntax module, it knows whether it's a subject or object.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the same holds for the syntax if it's applied before the referring expressions.",
                    "label": 0
                },
                {
                    "sent": "It often doesn't know how its arguments will be realized, so it only knows whether there's a victim or perpetrator.",
                    "label": 0
                },
                {
                    "sent": "But if it's applied after refering expression, the syntax module knows whether there will be pronouns in its argument or definite descriptions.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's come to our first evaluation.",
                    "label": 0
                },
                {
                    "sent": "We did 10 fold cross validation on 200 text.",
                    "label": 1
                },
                {
                    "sent": "Our senses are lemmatized, and in this talk I will focus on this remelt measures, so we looked at the blue score.",
                    "label": 0
                },
                {
                    "sent": "We have a accuracy measure for the syntax module, which is basically the exact string match and an accuracy for the referring expressions, which is also the proportion of exactly matching referring expressions.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we first look at the Bleu score.",
                    "label": 0
                },
                {
                    "sent": "For the two pipelines, they really perform very similarly, so we don't observe a big difference.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, so why is this the case?",
                    "label": 0
                },
                {
                    "sent": "So when we look at the accuracy of the syntactic module, we see that it actually suffers from the errors made by the referring expression model, so it's.",
                    "label": 0
                },
                {
                    "sent": "Performance is worse when it's applied second module in a pipeline, and it's better when it's applied as a first module.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The reverse thing is true for the referring expression generation, so it also suffers from the errors made by the syntax module, so it is better to apply it first in the pipeline and it makes more errors when it's applied as a second module.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we look at some lower and upper bounds, so we have a robust baseline, which has a very low blue score, and if we apply linearisation on our original dependency trees we get get a much higher blue score.",
                    "label": 0
                },
                {
                    "sent": "So this shows that the generator.",
                    "label": 0
                },
                {
                    "sent": "So that these task of referring expression and syntax realization introduce a lot of uncertainty into the into the generation problem, but the pipelines almost do the same thing.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how can we address this typical effect of error propagation?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A very simple way.",
                    "label": 0
                },
                {
                    "sent": "All would be to simply take the independent predictions by the two modules.",
                    "label": 0
                },
                {
                    "sent": "So to simply take these best predictions and combine them in a representation.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But when we do this, we see that the blue score also only very marginally improves over the pipelines.",
                    "label": 0
                },
                {
                    "sent": "OK. And in a way, it's not really surprising, because the system also doesn't really address interactions and really makes simply makes the predictions independent.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then we experimented with another architecture, which we call revision based architecture here.",
                    "label": 0
                },
                {
                    "sent": "And the main idea is that we can also vary the position of the linearisation in the pipeline and what we do is we apply an intermediate linearization step after the syntactic module, then apply referring expressions with a feature model that has some additional positional features, and then we apply the linearizer again and this is more divided by a lot of theoretical research that shows interactions between referring expressions and linearizations.",
                    "label": 1
                },
                {
                    "sent": "And these revision based architecture have been proposed in the literature before as.",
                    "label": 0
                },
                {
                    "sent": "Approximations of integrated architectures, actually.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's evaluate our revision based architecture.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We now see that this architecture clearly improves over the over the pipelines in the parallel system, so we get a nice improvement in blue.",
                    "label": 0
                },
                {
                    "sent": "And we see that the the referring expression Model now performs much better when it's applied on these intermediate linearizations of the of the shallow dependencies.",
                    "label": 0
                },
                {
                    "sent": "So there we don't have an error propagation of the referring expression model anymore, but it performs better as compared to when we apply it simply on deep dependencies.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now our Blues Blue score is simply measuring engram overlap.",
                    "label": 0
                },
                {
                    "sent": "So if we improve the accuracy of our referring expressions, it's kind of expected that we improve the blue score because we will have more overlapping engrams, so.",
                    "label": 0
                },
                {
                    "sent": "Is this improvement of the revision based system only due to this lexical overlap?",
                    "label": 1
                },
                {
                    "sent": "So we define another blue score or another measure for assessing this a little bit.",
                    "label": 1
                },
                {
                    "sent": "So what we do is we replace all the referring expressions in the gold and the predicted sentence by a placeholder and then we measure blue and what we get is a blue score that basically factors out the lexical overlap for the reference.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when we do this.",
                    "label": 0
                },
                {
                    "sent": "We actually also see a nice improvement of this modified Bleu score between the parallel and the reversion based architecture, so this indicates that we do not only improve the reference, but we also get better sentence quality, better linearisation.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here are my conclusions.",
                    "label": 0
                },
                {
                    "sent": "I think in this talk we should we showed that there's a straight forward way of integrating existing annotation standards for referring expression and surface realization.",
                    "label": 0
                },
                {
                    "sent": "And that this can be useful for doing data driven studies of generation architectures.",
                    "label": 1
                },
                {
                    "sent": "So our results point to shortcomings of the standard pipeline setup, and we showed that.",
                    "label": 1
                },
                {
                    "sent": "These data driven generation system really need to capture interactions and we proposed this revision based method for doing this.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, but I cannot resist pointing out.",
                    "label": 0
                },
                {
                    "sent": "That we had a publication in 2005 to machine again myself.",
                    "label": 0
                },
                {
                    "sent": "We did an integrated approach using integer linear programming, showing exact your Third Point here.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, OK, yeah, this was nine generation modules.",
                    "label": 0
                },
                {
                    "sent": "Yeah, integrated with idle P. OK yeah, and we showed these shortcomings.",
                    "label": 0
                },
                {
                    "sent": "That's also Nina deadlifts PhD thesis, which is which is unpublished and there must be some publication by her doing exactly the same thing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I actually cited you in in our article and pointed out some differences.",
                    "label": 0
                },
                {
                    "sent": "Wrong with our first, but with our first results.",
                    "label": 0
                },
                {
                    "sent": "There's, I think there's nothing wrong with your first results, I think, like in your work.",
                    "label": 0
                },
                {
                    "sent": "So you have a different data set, which is also, so my impression was from reading your article that.",
                    "label": 0
                },
                {
                    "sent": "You have a little bit less variation, so in.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our in our architecture.",
                    "label": 0
                },
                {
                    "sent": "Like for instance, is this linear?",
                    "label": 0
                },
                {
                    "sent": "Is this linearisation problem we couldn't?",
                    "label": 0
                },
                {
                    "sent": "We couldn't address it by a simple classifier.",
                    "label": 0
                },
                {
                    "sent": "So in your work, you're basically combining several classifier in a in an LP framework and.",
                    "label": 0
                },
                {
                    "sent": "In our data we have so many variations that we cannot label each decision by a label for a classifier.",
                    "label": 0
                },
                {
                    "sent": "So we have a pretty complex range and This is why your business provides new insights.",
                    "label": 0
                },
                {
                    "sent": "I think This is why you, why your results of the 1st results.",
                    "label": 0
                },
                {
                    "sent": "No, I don't want to say that this is the 1st result ever.",
                    "label": 0
                },
                {
                    "sent": "On on generation architectures or pipelines, it's my first results that I presented in this talk.",
                    "label": 0
                },
                {
                    "sent": "Sorry I misunderstood your question.",
                    "label": 0
                },
                {
                    "sent": "Hello so to me your results are very interesting, is more about the users that VM rank.",
                    "label": 0
                },
                {
                    "sent": "Have you considered just pulling a human to do the task?",
                    "label": 0
                },
                {
                    "sent": "So you give this information?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you ask the human to write the things cause with the machine learning.",
                    "label": 0
                },
                {
                    "sent": "You are also evaluating how well SVM rank behaves with that type of information.",
                    "label": 0
                },
                {
                    "sent": "So that's a big component of your results.",
                    "label": 0
                },
                {
                    "sent": "In a sense, SVM rank is better given that data, but if you can shield from that, you can just give that type of data to a human and see how well they can write the text and also get some feedback out of whether this is way to constrain or or yeah.",
                    "label": 0
                },
                {
                    "sent": "Make no sense.",
                    "label": 0
                },
                {
                    "sent": "So you want to say that I should do some human evaluation at some point or so.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying you should, but maybe you you can consider.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I definitely agree that these completely automatic methods do not provide full insight on whether we actually generate coherent text swinging or no.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying about doing human evaluation, I'm doing doing human execution.",
                    "label": 0
                },
                {
                    "sent": "So you take these type of things, you say well.",
                    "label": 0
                },
                {
                    "sent": "Your task is, given these, write a sentence and then people will say oh, this is a horrible task.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're putting me in a really complex situation and then that could be an interesting conclusion to say.",
                    "label": 0
                },
                {
                    "sent": "Well, so I think Anya belts did this in referring expression generation paper.",
                    "label": 0
                },
                {
                    "sent": "So they really asked humans to do this exactly this task.",
                    "label": 0
                },
                {
                    "sent": "And of course they found a lot of disagreement.",
                    "label": 0
                },
                {
                    "sent": "So it's actually surprising how.",
                    "label": 0
                },
                {
                    "sent": "How little humans agree on where to realize pronouns or definite descriptions in a text.",
                    "label": 0
                },
                {
                    "sent": "So there's also a certain upper bound that we would get from the human agreement I think, or from human generated.",
                    "label": 0
                },
                {
                    "sent": "I want to find could ask your question when you showed your two pipelines you talked about how the information available at each stage was different.",
                    "label": 0
                },
                {
                    "sent": "Yeah, could you show that slide again actually?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so I just wonder on the right hand one so they're referring expression generation has access to the shallow tree, the shallow labels?",
                    "label": 0
                },
                {
                    "sent": "Yeah, does it have access to the deep ones as well?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah yeah, OK?",
                    "label": 0
                },
                {
                    "sent": "And I guess another question I had was.",
                    "label": 0
                },
                {
                    "sent": "You've done this on a relatively small example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's a nice neat one where you can get good data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, have you thought about?",
                    "label": 0
                },
                {
                    "sent": "Is there any way you could do this on a larger scale somehow?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean.",
                    "label": 0
                },
                {
                    "sent": "It's actually pretty easy to get these syntactic representations, so we already did this in the semi automatic or automatic way, so I think there are like it would be possible maybe to use different corpora that are annotated with all sorts of entities.",
                    "label": 0
                },
                {
                    "sent": "I think it would be possible to do this for for other types of data, but you have to get these entities represent or you have to know about this reference.",
                    "label": 0
                },
                {
                    "sent": "Price lot of deepish semantics there yes yes yeah.",
                    "label": 0
                },
                {
                    "sent": "Very nice thank you.",
                    "label": 0
                }
            ]
        }
    }
}