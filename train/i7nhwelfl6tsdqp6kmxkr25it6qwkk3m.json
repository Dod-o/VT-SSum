{
    "id": "i7nhwelfl6tsdqp6kmxkr25it6qwkk3m",
    "title": "Bounding the Gaussian Process Information Gain: Applications to PAC-Bayes and GP Bandit Optimization",
    "info": {
        "author": [
            "Matthias W. Seeger, Laboratory for Probabilistic Machine Learning, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne"
        ],
        "published": "April 14, 2010",
        "recorded": "March 2010",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/pacbayesian_seeger_gpig/",
    "segmentation": [
        [
            "So let me start by thanking a few people there all here so I can thank them.",
            "So first of all, David right for coming up with all this stuff and I really think that we shouldn't call this.",
            "We should call this mcalister's bound and then XY.",
            "Zed applied some large deviation inequality, plugged it in because what matters is really the idea, right?",
            "So it's kind of a bound generation idea.",
            "And then John, I don't know.",
            "It's not only for inviting me, I don't know if you remember that you were actually the person who who pointed.",
            "Metepec Basin thing in the 1st place.",
            "So was this workshop in Germany and I gave this really poor talking and afterwards everybody was staring at me and I asked John.",
            "So what do you think about this?",
            "And he said maybe you should look at the pack Bayesian theory.",
            "So and then month it up because I visited him in Essen and I gave a talk to and I only afterwards I realized how simple these things can really be.",
            "If you put convexity in there.",
            "So let's see what this talk is about.",
            "So very briefly, because we've already did a really good job here, so let's notation.",
            "So input points, output points, latent functions, F in my talk, not age, the price."
        ],
        [
            "LP empirical error generalization error.",
            "So people pointed out the pack basis really simple.",
            "I would say it's even simpler than that."
        ],
        [
            "See, this is how I explained it in my thesis.",
            "So you start with a large deviation inequality and you can pick anything you want as long as it works, and then you turn that into something.",
            "I would call a Peck on for dumb classifier so the large deviation inequality tells you something for a fixed function.",
            "For example, this is something you can do with a with a Bernoulli.",
            "This is kind of the KL for the Bernoulli.",
            "You get something like that.",
            "If you fix F, so then you do a dump classify.",
            "You just average over F. It's still true right?",
            "And it's really dumb becausw.",
            "The way in which you average over your function space doesn't depend on the training data.",
            "You just do the same thing all the time, so that's not very useful, but now."
        ],
        [
            "Goal is really to convert that into something that's useful in kind of, lifted to something that makes a statement about a smart classifier that would be Q.",
            "And it's smart because it kind of looks at the data and does something sensible with it, and the only question you have to answer is what does that cost me in order to lift it from the dumb to the smart one?",
            "What do I have to pay for it and amount you have to pay if you use PAC, Bayes is exactly the relative entropy divided by N versus if you would use union bonds you would have to pay more usually here.",
            "Something like lock of hypothesis space over and or something if it's infinite and I don't know then you have to do we see and how does it work.",
            "It really works because there's this one amazing inequality which people college andreoff Angelo variation or whatever."
        ],
        [
            "So this is this one here.",
            "Comes from later on duality.",
            "I don't know about you, but I think this is the most influential inequality that I know so it.",
            "Maybe Manfred has the right name for it.",
            "It comes from statistical physics, so this is the inequality.",
            "It says like this is the thing.",
            "So this is the lock partition function up here and it's lower bounded by the what people call the energy is sort of free energy or minus that I don't know.",
            "And then you have the entropy of the negative entropy.",
            "Here it is the KL diversion.",
            "So it comes from statistical physics.",
            "People used it a lot in variational inference.",
            "For example all the mean field methods use it, or the structured mean field method.",
            "They just use this inequality and optimize over Q.",
            "And also if you think about it a little bit, the EM algorithm.",
            "That's really what the EM algorithm is doing is to use this bound, at least if you want to show.",
            "It converges, and now if you do Peg base, this is also used in learning theory, so this is really nice.",
            "I mean, it's really nice.",
            "In my thesis I said well, it kind of comes full circle because you use it in order to get these methods can also use it to analyze these methods the same idea.",
            "So that's the."
        ],
        [
            "McAllister bound and somebody plugged in the large deviation inequality here, so this how it works, right?",
            "So this thing is convex, so you can pull out the expectation.",
            "This is always true, so you get this.",
            "Then you plug in.",
            "This is here, this side you plug in the right hand side.",
            "Also always true and now we have this thing and now we apply the equality inequality for the dumb classifier in order to bound this and that is the only point where you have to do something with probability and then you get back Bayesian result here.",
            "So, so we've had some people saying So what they think the pack Bayesian bounds are so he."
        ],
        [
            "Is another idea what they are.",
            "They are tired there, certainly tighter than other bounds, and I think the reason why they are tide.",
            "The main reason is that they depend on things so they are non uniform bound.",
            "So they depend on things and if you happen to be some people say lucky other people say you try to make a good guess.",
            "That's what you always do in statistics.",
            "If you made a good guess in your prior and your model assumptions then these bonds give you a good small number so they are dependent on the problem.",
            "And that's usually A plus would come to that, but they're also depending on the data, because the right hand side depends."
        ],
        [
            "No data, so it fluctuates with the sample."
        ],
        [
            "So I guess I don't know if all of you agree, but I would say problem depends is always A plus.",
            "I mean you have to be a really serious pessimist.",
            "If you disagree here I think.",
            "Um?"
        ],
        [
            "But data dependence is not so clear, right?",
            "So data dependence is not always A plus.",
            "I mean, there are two reasons why not.",
            "Maybe you want to do optimized active sampling and then certainly this is a problem for you.",
            "But it also sort of kind of.",
            "I guess people can point out that you've just been lazy because they will ask you how big is this term.",
            "I mean it fluctuates with the sample.",
            "So how big is it?",
            "For the model of the problem that you look at, so certainly you could say if you have a data dependent result, then there's actually more work to be done.",
            "You have to say how big can this term be and this will get much clearer later on when I show you some some applications where the data depends then really a problem.",
            "Well, let's let's just look at."
        ],
        [
            "What how can we analyze this right hand side in the pack Bayesian theorem so this is now Gaussian process regression with Gaussian noise?",
            "And I guess some people point out.",
            "So he starts with classification.",
            "Now he talks about regression, I think.",
            "So this is just a simple case.",
            "I think it also holds for classification.",
            "We can maybe discuss this offline.",
            "So for Gaussian process classification with Gaussian noise, this is the prior you sample your sample path from the zero mean Gaussian process with kernel K and then you sample your data from that function with some Gaussian noise Sigma Square."
        ],
        [
            "And then the posterior that you would call P of F given given the data Y.",
            "Or you could also call it Q in the pack Bayesian bound that would then be also a Gaussian process because this was a Gaussian process and then you multiply in this Gaussian likelihood.",
            "And then it stays a Gaussian process, and importantly, this likelihood only depends on the process evaluated at a few points, it's kind of shifts to measure on this crew points, and that also means that for the whole remaining analysis you can only concentrate on this viewpoint.",
            "So this vector F up here.",
            "So whenever this is powered, I really only mean the function ever."
        ],
        [
            "So that these endpoints.",
            "And that's nice, because now it all becomes linear algebra.",
            "You only have to define a few matrices and you only have to think about what are the main distributions that we're talking about.",
            "Now this is the prior zero mean, and it has the kernel matrix is the covariance.",
            "Then you have the data distribution, which is the distribution of the marginal likelihood of the data and that also has zero mean because the noise didn't have any.",
            "Also had zero mean and covariance is different.",
            "It's not K anymore, but you have to add this this noise covariance there and then you also have to posterior which you can write like that so that it does this mean in this covariance?",
            "So the mean I explicitly wrote it in this Alpha annotation because SVM people like to call of this sister.",
            "They like to think about this is the dual vector.",
            "And then you multiply it with the column matrix.",
            "You get the posterior mean.",
            "And the covariance matrix.",
            "You can kind of write as this.",
            "This product of K and the inverse of the Sigma.",
            "This doesn't look like symmetric matrix, but it's actually one.",
            "So that's the really neat thing about this model is you can write all this down and you can analyze it and you can say how big it is and you can say which is the dominating term and let's just try to do that."
        ],
        [
            "And this this guy is going to come out as the one that dominates it.",
            "So this is the mutual information between the process and the data, so it's kind of the information gain.",
            "So before you sampled that function you knew about as much as the prior about it.",
            "Entropy of the prior or you didn't know about as much as the prior, so that the entropy and then you sample it at end points and then you know more about the function.",
            "So you take this difference.",
            "So this is kind of expected posterior entropy.",
            "That's a positive number here, at least for this model, and that tells you how much information do you gain when you sample this thing at end points.",
            "And it certainly depends on where you sample them, and this is the quantity.",
            "If you write it down, so that's a lock determinant identity the kernel matrix.",
            "Something you can compute and you can look at.",
            "You can also because this is kind of symmetric.",
            "You can also write it like that, so entropy of the data before and after you've looked at F. Um?",
            "And this is kind of almost this, so this term it came up like all the time and I really in stepwise I figured out you know, where does this come up and how found it.",
            "And this is, I guess all this talk is going to be about about this term and what it does and where it comes up and how to bound it."
        ],
        [
            "So the first thing this is really well known is that if you take the right hand side in the pack Bayesian theorem for the Gaussian process case, and you take then the average value over the data distribution, then you get this information gain.",
            "That's that's true.",
            "That's actually true for any statistical model.",
            "If all these things are done exactly here.",
            "So this is just I mean, some people simply say that this is the.",
            "This is the information gain because they always do the expectation over the over the data."
        ],
        [
            "And this is very easy to see, so you just take this thing.",
            "You write it out, then you get one term.",
            "That is this one.",
            "Just write it down and then you get another term that is the expectation over the posterior Q and I just plugged it into BP of F. Given Y of the negative log of the prior and then you have to expectation outside over why.",
            "Now you pull these two things together.",
            "You get the expectation over the joint.",
            "And then you realize that there's no way in here.",
            "So you just integrate it out you."
        ],
        [
            "The entropy of the prior and then you plug it together and you see that."
        ],
        [
            "That's in fact true, and I mean, as Manfred pointed out, there's nothing like Gaussian.",
            "I used here.",
            "This is all true for any distribution, so expected value of this KL is the information gain.",
            "Be careful here because it's not the expected value over the data or whatever, it's just the expected value over very specific distribution.",
            "And of course this thing still depends on the input points.",
            "Yes, this is.",
            "This is maybe also the main reason why it's interesting.",
            "So what about the rest?",
            "So that's fine.",
            "So you sort of know what it's doing and expectation.",
            "What about the rest?",
            "Again, you can just this was on John Slide yesterday, so you can write it down what it is and you can also actually say what these terms are.",
            "So the first one is."
        ],
        [
            "So if you think about it for a second, it's the square dark iges norm of the mean function.",
            "So if you think about fitting your GP to some data which the underlying data is function of bounded arcade Jess Norm, then this term is going to go towards that.",
            "Given that you know that it's consistent, it's going to go towards that number, and it's not going to be larger than this number somehow, so it's going to be actually compared to this term.",
            "It's going to be subdominant, the second part is."
        ],
        [
            "Coming from the posterior variance.",
            "So if you look up here that was the posterior covariance matrix and here's just a trace of it.",
            "So it's the sum of the posterior variances, and again you can fairly easily show that this term has to be even.",
            "Order smaller than the other term by so the idea is that you just look at these two functions.",
            "We can plot them and you can see that the one is always quite a bit bigger.",
            "I mean, they're they're the same asymptotically when you go to zero, but sort of the day they give you.",
            "I mean, this is really then at least kind of.",
            "This is smaller than that term, so you can in the end what I want to say here is that you can focus on this term if you want to know how big this thing can be.",
            "Some way the norm term is sort of what was there so so that is it is kind of where your assumption goes in that.",
            "So you are fitting this to a function which has a bounded complexity.",
            "Maybe I'm brushing this a little bit under the carpet, but you have to make some assumptions.",
            "Suppose you fit your model to a target function.",
            "If that function is arbitrarily complicated and you are not going to get any good behavior here, but usually you would assume that you do.",
            "You know your target function, so this is a bit fluffier.",
            "How did you say yesterday?",
            "It's kind of.",
            "Loosely, but but I would say that in most applications, if you know that your target function is not too complicated, then this thing is going to be small in the end.",
            "Even a small yeah.",
            "So I mean in this case I just want to motivate why it's actually important.",
            "I mean I have a few other reasons why it's important to understand how big distincion be, which may be more convincing than what I'm talking about now.",
            "But in for the moment I just want to tell you that if you want to know about this term, then you know that this one is in there, and then you know that a few other things are in there which you can argue that they are usually smaller than the others.",
            "Set the target function came from the prior then if well then everything goes away here right?",
            "Because then you have to access.",
            "So I'm trying to assess what month it tries to say it's OK if everything comes from the data distribution from the model then this thing is not there anyway.",
            "So you directly.",
            "Actually there's a paper by you and where you?",
            "Is this is our cages North so if if the mean approaches the true target function with increasing amount of data then this would actually grow.",
            "Yeah, but there's this negative.",
            "I mean, if you take the expectation look this, this only depends on why right, and this doesn't depend on why, so the expectation over Y of this term is exactly that one, and that's why it cancels out.",
            "And so if you take the expectation over why from the data, then you're only left with this term, but I'm just so this is the kind of the non agnostic case.",
            "If you get your data from somewhere, but you know that it's not infinitely complicated.",
            "Tennis engross this thing is going to dominate."
        ],
        [
            "So let's let's switch topic now away from the pack base, but another case where it comes up.",
            "So this sequential prediction Alok loss.",
            "So the game is that you always predict the next target given the input that you get and the previous data that you got, so X one you predict why one is in some said Y and then 4X2.",
            "You have to predict Y two given the previous and so on and so on, and the game goes like you predict the distribution for the next label.",
            "And then you actually incur a loss, which is the negative log of that distribution.",
            "Where the nature plugs in the true value or something and then you add up the cumulative lock loss and that is what you want to minimize with a strategy which always.",
            "Pulls out these distributions for in every new timestep, and now if you fix the likelihood here."
        ],
        [
            "Well, you could say the loss function, but in this case it's really a likelihood that underlies the loss function.",
            "Fix the function space.",
            "So how could you play this game so one of the things that you could play it in the Bayesian way?",
            "You could always use the predictive Bayesian distribution in order to make that next decision, and that looks like that here and then.",
            "Funny the lock loss kind of adds up with the chain rule, and so on, and you just get the marginal likelihood here.",
            "The negative local marginal likelihood, which is your cumulative log loss."
        ],
        [
            "And you can compare that against an expert strategy.",
            "So so this is an expert, so he really knows what he's doing, so it's not going to bother about.",
            "Data is always going to say the same thing, but that might be really dumb, but maybe the best expert in this class is going to be one that is really good and you want to compare your strategy against all of them.",
            "So here for the expert, the cumulative log loss is just adding up all these negative locks here, and you can write it in this form here, so you always get used the same function for predicting and then you get the loss."
        ],
        [
            "So there's this notion of information consistency, which kind of is a quality associated with a prediction rule.",
            "So you'd say Rs information consistent of our space of competitors with respect to some input distribution if for every competitor you are in this KL divergent, not not much worse than this competitor, no matter what it was, so not much worse means that KL divergences between the tool.",
            "A predictive distributions here this you can also write.",
            "This is a Cicero average.",
            "If you just sum it used to chain rules here, but you can also write it like that.",
            "Expectation over the input distribution outside it has to grow less fast and then and then."
        ],
        [
            "Into the Bayesian sequential prediction is that you can write this KL divergent's exactly as the expected value over the data distribution of these two losses.",
            "Of these two strategies that are head up.",
            "So that means that if you."
        ],
        [
            "So for any why an you can control this thing here with a uniform regret bound uniform, not over expert over Y.",
            "That implies certainly that it's information consistent.",
            "Well, if this bound is small enough, smaller than N or goes divided by N goes to 0, then you have information consistency.",
            "And now we have this so this."
        ],
        [
            "Regret bound.",
            "And So what is this?",
            "This is the cumulative log log loss of the Bayesian.",
            "This is the.",
            "The same thing for any expert, and then you have.",
            "Then you have this squared kitces norm of the expert here, which basically just means that if the expert is very complicated then it might really do a very good job.",
            "So you would really expect this term to be there.",
            "And then you have this player again, right?",
            "So the information gain is in here again.",
            "We call this a regret term in the paper, but it's really the information gain.",
            "And Archeage snom that comes from the arcade chest.",
            "It's defined by the kernel and what's the sea?",
            "The sea is basically something that if this was done with regression to see would be a Sigma square inverse, but in general it simply bounced II curvature of the negative of the loss function if you want.",
            "OK, so this works for classification and see what we want over for it also works, it doesn't.",
            "It doesn't work for 01, obviously, so there's a step so you have infinite curvature, but it works for all these loss functions F bounded curvature.",
            "Definitely, oh, because there's all minus here.",
            "So in the in the PAC Bayes explanation I had this plus and then you know what I mean.",
            "Was there were different sign between the cage Norman?",
            "The log of the.",
            "Determinant.",
            "'cause they were canceling each other at some point in the.",
            "But maybe that's not.",
            "Maybe I missed up, maybe maybe a mixed up some signs somewhere, but this is certainly true.",
            "I have this in my head, maybe it was wrong.",
            "What I did earlier.",
            "What so there's no correct function here.",
            "The point is that so this is a uniform bound, so it holds for any X&NEY it doesn't.",
            "There's no correct trying.",
            "This is actually a bit different, and then from then generalization error bounds.",
            "So this is kind of this.",
            "You know this regret type setting where you compare yourself against others, and you do this for any data.",
            "It doesn't matter.",
            "And then usually there's some condition on where the X comes from.",
            "I come to that, but the why can be anything?",
            "So I hope this is correct.",
            "Maybe there was a sign mix up earlier on.",
            "So what does that mean?",
            "That means that this GP prediction rule is information consistent."
        ],
        [
            "To compare against any function, you are cages that holds for any input distribution and it holds for any stationary kernel as long as it's basically not infinite at 0.",
            "So this is kind of almost all the cons people use, and unless there may be non stationary and the other really nice thing about this because we can somehow say something about this term and then we can also get."
        ],
        [
            "The size, information, consistency rates and they are what I would call problem dependent because they depend on the kernel and they depend on what you kind of can assume about the input distribution, and they're controlled exactly by this term.",
            "It's left over here by the expected information gain expectation is over the input distribution now divided by N. So now I have to sort of show you."
        ],
        [
            "A little bit how this works, because otherwise you don't believe me that this is pacbase, so it's kind of peg based because it uses the variational inequality again.",
            "So you start with assuming that this is coming from the span.",
            "So from this so it's a kernel expansion and then you use immediately this inequality.",
            "So this is.",
            "That if we energies or this kind of minus of the thing that I had earlier, this is the energy.",
            "This is the entropy, and this holds for any distribution.",
            "And now I'm."
        ],
        [
            "Doing a trick like in John and John's paper, I'm now.",
            "Here's no distribution here.",
            "There's only a competitor.",
            "There's only a function, so I'm going to construct a GP that does the right thing, and I'm doing it by constructing the GP Q so that its main function is the function I want to compare against and that its covariance function is not exactly the kernel, but it's this kind of this covariance function that I get by adding a noise term to the kernel.",
            "And when I do that and I get this result.",
            "So this is for any function that is a kernel expansion on the day to get this inequality.",
            "And this is actually an equality if The thing is regression.",
            "So for regression all our results are actually equalities, not inequalities.",
            "And then the rest thing is to represent us."
        ],
        [
            "So you just say, well, if this is true for any expansion, and because this only holds this term only depends on what the function does on the data, then it has to hold for everything in the dark Ages."
        ],
        [
            "So now OK so.",
            "It's really important to know how big this information gain is.",
            "So how can we do that so we can look at the empirical spectrum and we can relate it to the operator spectrum of the kernel with respect to the input distribution.",
            "So this empirical spectrum of K / N and that is the information.",
            "Again, if you write it in the spectrum now that's the problem is that this all depends on the data.",
            "That's what you don't want.",
            "So you go to the limit of that and that doesn't depend on the data.",
            "It depends only on the distribution center data comes from.",
            "And then you can look at."
        ],
        [
            "Is Tom and you can.",
            "This is always not going to same tricks, so you split it into parts you sum up to I not, and then you summon the rest.",
            "First part you say OK, if I sum up to IN then it can be only as big as I know times log N and the rest you can say, well log 1 + X smaller equal to X.",
            "So this is just tail some.",
            "And."
        ],
        [
            "You use again something that John and Chris Williams did, which is a really funny property of these tail sums.",
            "Because the expected value of the empirical tail sums, at least if they, if everything is stationary.",
            "So they all sum up to the same value.",
            "They're actually.",
            "Inequality is here, so the expected value of detail.",
            "Some of the empirical is actually cannot be larger than the tail.",
            "Some of the process eigenvalues.",
            "Let's just call it BI, not so this is the step where we go from the data dependent to the data independent property that we can maybe say more about."
        ],
        [
            "And well, then you get information consistency, but just saying that OK, we use this bound.",
            "So the first term is speaker stat.",
            "The second term is his biggest be I not, and because this has to sum up.",
            "Alright then this thing is to go to 0, so it's information consistent no matter what the input distribution was.",
            "So Engelstein word pointed that out to me.",
            "We had all these results for by not, but he said well, looked at implies that it's anyway information consistent because this thing has to go to 0.",
            "Even nicer you can."
        ],
        [
            "Also say how quick it goes to 0, because you actually might be able to say how fast this term the case just by you know using results that people have got on these kernel operator Spectra.",
            "So for example for the Gaussian kernel or the RBF kernel in the Gaussian input distribution you can.",
            "This is known how it looks like it's in this paper by through Williams and others, and if you then do this trick with the split some and do some mathematics then you get this one.",
            "And this is really small.",
            "I mean, I was really surprised when I got that.",
            "Maybe I don't know too much about these things, but but this is really small.",
            "If you divide it by N, it's decaying extremely fast.",
            "While if you do it for the maternal kernel, which includes some really rough kernels, then this is way way slower.",
            "So if you do the same trick and you use some results from some mathematician, then you get things like that.",
            "So here you have a term that depends on end not only on log N and if you get to something like this is the degree of freedom.",
            "If you set that to 1/2 year on sent one back kernel which is really rough then you get something that's just about.",
            "Smaller than an.",
            "So you get information consistency, but the rate is quite slow, while for the Gaussian is extremely fast, you can compare this to the linear where you basically would have something like that in the dimension here.",
            "So this is almost like the linear case."
        ],
        [
            "So some comments on this work actually really nice.",
            "Some some real mathematicians picked this up so so there's a paper coming up who basically said, OK, they did this and we can, you know, we can do this better.",
            "I can do that better.",
            "So first of all, actually we cause it's Gaussian processes.",
            "You can do many things in a much nicer way than what we did, and I still have to understand it.",
            "So first of all, you can relax the assumption that the competitor has to be in the arcade.",
            "Yes, it seems to be that they can actually do this for any continuous function.",
            "Um?",
            "Then you can don't even have to talk about information consistency, but you can talk about this stronger property here.",
            "And you can also do something else then on bounding disk information gain.",
            "But"
        ],
        [
            "I have some questions that they are still out on this term, so one of the things is that we looked at the expected value, but what about concentration topic?",
            "Can it be?",
            "It's still not done?",
            "I only say what's the expected value so that could be useful this paper, but we also get to that and then things like what about heavy tailed distributions that don't have bounded support?",
            "Then this theorem wouldn't work that I use for our non stationary kernel.",
            "Again there are some ideas in this paper but I still have to understand it.",
            "You again, that's the input distribution where the X is come from and then they are IID drawn from the X from the distribution.",
            "So for example, one of one of the things that is a bit unpleasant is that these bounds always depend on what the input distribution should be, while the information consistency didn't depend on it.",
            "So one would expect that I can bound this only depending on the kernel, and this is something that these guys say that this is possible by using entropy numbers, and I just don't understand it right now, but it's so they say that eigenvalues are with not the right way of analyzing these terms, but you need to use other concepts, but I guess it's the eigenvalues.",
            "Once you have them, you can make a good statement.",
            "So now another thing, another topic, that's what I really wanted to."
        ],
        [
            "Tell you about here, because this is where the information gain really comes in and you can't avoid it anymore.",
            "This stochastic optimization so, so what's that?",
            "So optimization is hard enough, but what if you don't even know what you want to minimize, right?",
            "That sounds really hard, but unfortunately it's hard.",
            "But it also is important in practice.",
            "So for example, you want to, you know if you're working at Yahoo, you want to choose advertisements and you want to maximize the clickthrough profit.",
            "But you certainly don't know what the users really want if you do clinical trials, you want to minimize patient loss if you do.",
            "Adaptive routing you don't know how the network really looks like, but you still have to minimize these delays and this is."
        ],
        [
            "So it looks like a formally, so you have this unknown function F~ It has some maximum somewhere, and then you play this sampling game.",
            "So you sample the function and you observe the function where you sampled it with some noise and you also get a loss or regret, and that loss is basically telling you how much worse than the best possible sample you have been.",
            "So if you knew where the where the optimum is, then you would always sample it and you would never get any loss.",
            "But as long as you don't and you get some loss.",
            "And then you sum up the loss or the cumulative regret, and that you want to minimize that thing.",
            "And especially interesting, is it again to say when is this thing growing much slower than N?",
            "So when when am I not doing a regret after some initial time when I'm really getting down to the optimum?",
            "Um?"
        ],
        [
            "This is a very interesting problem because it's not the same problem as what people usually wear.",
            "At least what I thought for a long time.",
            "People usually do in statistics because there's this explore exploit tradeoff.",
            "I come to that because it's very nice to illustrate it here, but just for the moment it means that you have to learn just enough about that function so that you can maximize it.",
            "You must not learn anything more about it, because that would be wasted effort.",
            "Well, that's true.",
            "I don't know this regret.",
            "I didn't say this.",
            "The only thing I get I don't even get a reward I get nothing.",
            "I only get the observation this is something that somebody stores and in the end tells me oh, you've done it this good I never observe what that regret was it would be a very strong information of course, but I never get this.",
            "Nobody ever tells me how good I do.",
            "Until the end I guess, but I mean this is actually Infinite Horizon.",
            "This is not so.",
            "We're not going to contest this setting if you know that you can only sample 1000 times, it's a different game.",
            "But this is like you can stop at anytime and you want to be as good as possible at any point in time.",
            "Kate.",
            "Oh yeah, yeah.",
            "I assume that I know Sigma Square.",
            "Actually in our theory might come to that.",
            "We have to assume more than that.",
            "Actually, there was this questions of what about if Sigma Square Zero?",
            "I think you can also do it, but we didn't do it so this I think you could do it because doesn't seem like a problem, but in the end we know Sigma and it's not 0.",
            "So then I guess that's obvious, so that."
        ],
        [
            "Also implies convergence rates because the maximum is kind of closer to the truth than the average."
        ],
        [
            "And funny enough, this is called multi arm Bandit problem with dependent Arms because it sort of comes from from this idea where every arm would be a possible value of X.",
            "Now here you have a continuum.",
            "That's a bit weird this this octopus would have to have a continuous number of arms, but but usually it comes from the fact where you have finite arms and you have to pull them in the right kind of frequency in order to minimize this regret.",
            "So it sort of comes from this, but it's getting a little bit weird too.",
            "It's it's coming from people that looked at these multi unbanded problems.",
            "OK, so."
        ],
        [
            "So here's explore exploit and it's really nice to demonstrate.",
            "So this is how we do it.",
            "We say, OK, we do this with GPS, so we represent the knowledge about the function with a cheap posterior, so that has a GP prior.",
            "And we always look at the mean function in the variance function.",
            "And now how do I sample this thing if I only want to minimize my cumulative regret?",
            "So here are a few ideas.",
            "So one of the things I could do is I could simply always maximize the variance function order square root of it, and that is what experiment design would do.",
            "So you would decrease the uncertainty globally and then you would say, well, if I really know that function everywhere then I can also optimize it, right?",
            "But that is not so good because you actually waste effort exploring that function at even at places where you wouldn't want to explore it, because the maximum cannot be there.",
            "So this is not such a good idea."
        ],
        [
            "So you can use another idea which, which means you simply always maximize the average mean function that you have right now.",
            "So the average expected reward.",
            "That is also not such a good idea, because we actually exploit it very much too soon.",
            "You are very greedy, you exploit whatever you know right now and you usually get stuck in a local optimum.",
            "You never find the point where you really make the best gain or the smallest loss.",
            "So what you can do then is simply taken every."
        ],
        [
            "Much of that so you can use this rule, which people called the upper confidence bound idea.",
            "So you take basically some of these two things.",
            "You waited in the right way, and that's what you maximize.",
            "OK, and that is actually way better than these both strategies, because you can actually realize the optimal explore exploit tradeoff that way.",
            "And then if you do this with GPU, could call this the GP upper confidence bound algorithm.",
            "And we we've done an analysis of this well."
        ],
        [
            "Let me just show you how this looks like.",
            "So the idea is that you model the unknown function by a GP and then you always in every step you maximize the upper confidence level.",
            "So here, for example, is an example, so you have to meet function.",
            "And you assembled already at these points, and that is the upper confidence level.",
            "So so many people would.",
            "So where should I sample now, right?",
            "So probably most people would say well, somewhere here, but the algorithm actually samples here because the upper confidence level is higher here than it would be here.",
            "Which simply means that if I sample here, I already know the function.",
            "But here it might.",
            "There might be actually a maximum here that I missed, so it's samples here."
        ],
        [
            "So it wasn't here so little bit up here, but it wasn't quite here and now the next sample would be there because now the upper can.",
            "I mean, here's maybe another candidate, but this is still a little bit higher here, OK?",
            "So now we we."
        ],
        [
            "Analyze this algorithm and this is kind of again, this is the one quantity that's important in this analysis, and this is this time is the information gain, but now you maximize it.",
            "So you do the sampling in a way that maximizes the information gain.",
            "And then you have this bound here, which basically says that if T is compact, you have to choose the beta that way.",
            "And now the main assump."
        ],
        [
            "And isn't this is only part of the theorem that we have is that you draw the unknown function from the GP that you actually also use to have the prior for your model, so you draw a sample path from the GP from the zero mean with kernel K, and then you try to find its optimum while you only allowed to sample this function and we also need a technical condition which is kind of something like a Lipschitz property with high probability, and I'd tell you when that holds and then when you assume all that then you get this regret bound and it just says the.",
            "This is uniform over all N regret is smaller equal then the square root thing here.",
            "But notice that the information gain so this is N times the maximum information gain due to sampling which is controlling the rate of this algorithm."
        ],
        [
            "So what does that mean?",
            "That means that the rate of this algorithm is dependent on the maximum is controlled by the maximum inform."
        ],
        [
            "Action game come back to this point, but just a few comments.",
            "We have a similar result if the F~ is not from the prior that we assume, but it can be any RKG as function, but I don't get this is more messy so they don't discuss it the technical."
        ],
        [
            "Condition, which is something I'm a bit annoyed about, but it's still there so it holds if the kernel is 4 times differentiable.",
            "So for example for the Gaussian or the maternal kernel when the UFC is larger than two, but it doesn't hold for the instant wound vac, so we still don't know.",
            "I mean certainly our theorem falls apart in that case, and all this is not required if the D is finite.",
            "Of course, then you can use any kernel you want.",
            "You can use any Gaussian prior you want.",
            "And note that this implies that actually there's many algorithm."
        ],
        [
            "GP, UCB algorithm with many or most stationary kernels people use in practice.",
            "We have this no regret statement in probability."
        ],
        [
            "So.",
            "So let me emphasis what this means so.",
            "We have a few different rules for sampling this function right as the experiment design rule, greedy approximation of the maximum information gain.",
            "Why is that?",
            "Because you can easily show that if you always maximize the predicted variance in every step, that is exactly the same as if you maximize the information gain by adding one more point.",
            "That is very.",
            "That's kind of the lock of that somehow.",
            "That's kind of easy.",
            "So what that means is that there is a rule which chooses the points.",
            "So to maximize the disk, up there to approximate it in a greedy way.",
            "And let's just call this election by A and so that's the one that the greedy rule would get you if you ran it."
        ],
        [
            "But that is not a good way of doing things.",
            "I mean, you can do way better than that by basically concentrating your sampling to using this upper confidence idea to actually not just globally explore the function, but to sample it where it really matters here.",
            "And I mean, you would certainly appreciate what I'm saying by just thinking about the fact that the Ed rule it doesn't even depend on the samples that you get along the way, you could just compute it beforehand.",
            "Because it doesn't depend on the targets that you get.",
            "So it's probably not a good way to do the bandit optimization using the Ed rule, but nevertheless the D rule actually tells you how good that."
        ],
        [
            "CPU CP can be because it's the maximum information gain that controls the rate for this algorithm.",
            "So it's a really funny kind of this rule really tells you how good this rule can be in the, at least if you use this analysis."
        ],
        [
            "So then you say OK, so how do I get this one?",
            "Because it's a.",
            "It's a combinatorial quantity, so greedy I don't know, you know, maybe you really don't.",
            "Don't get it at all.",
            "But The funny thing is that this is."
        ],
        [
            "So submodular function, so you can actually guarantee that if you do the greedy optimization of this, end and you don't, you get there up to a small constant.",
            "So this is approximation guarantee because it's submodular.",
            "The greedy rule is actually getting you close to the true value appear."
        ],
        [
            "And now at this point I think it becomes really clear.",
            "The whole point of the whole talk, because now we're sitting there.",
            "We have this Thirimanne.",
            "We submit it to somewhere, and then the reviewers say, Oh well, that's fine.",
            "But I mean, how am I ever going to, you know, evaluate this bound.",
            "I want to run this UCB.",
            "Here's my kernel.",
            "Here's my input distribution, and then we tell the reviewer, well, you know, that's no problem.",
            "You just run the Ed rule with this kernel and with this D and then you tabulate all these gamma ends here and then you can tell the user afterwards you've done that.",
            "You can tell the user how good is going to be, but that doesn't sound so good, right?",
            "You would want to know how good it does for this kernel without doing all this work.",
            "And that's exactly what I mean.",
            "Is that sometimes data dependent Ness is not quite what you want.",
            "At least you want to do a little bit more work to get rid of this in orders trouble that you really have abound here, but it depends on your data in a sense, and you have to go away in compute it, you really want to finish this business and you want to say how big can it be for kernel K and data set D?"
        ],
        [
            "Oh yeah, it's yeah it's not.",
            "It's probably bad to call this data dependent, but let's call it.",
            "Yeah, you're right actually, so it's probably, but it's something that you would want to know how big it is, so it's otherwise you would have to go away and compute it by running this CD rule.",
            "Well, you can.",
            "I mean, that's half of our theory.",
            "OK, but I mean it says so.",
            "So you probably agree that that's probably fine, but you would still want to know you know how big it is, because it sounds like unfinished somehow.",
            "Well, at least an upper bound.",
            "It's a closed formula.",
            "I mean actually, you know that what we get in the paper and the second part is it cannot be as close as what you would get by run the greedy rule, because snap on that.",
            "But it maybe it's tight.",
            "I mean, you're right.",
            "So this is kind of a nice result already.",
            "But now let's make it even.",
            "I mean, I want to motivate to you why you would want to know how big this this term is."
        ],
        [
            "And it's going to use the paper once more.",
            "So very roughly, and this is actually something I think is really nice, but it could also be improved, so that's what I'm really hoping for inputs here.",
            "So how do we get around on this thing?",
            "So first is that we pull a discretisation of the D. So this is a finite set and the till their quantity is basically the same thing as the gamma.",
            "But it's using the finite set instead of the full set and this is a nested set of sequence sets and it always is this big.",
            "Let's just you know how big is this?",
            "Let's let's do it later and then we use."
        ],
        [
            "Mr. Submodularity, because you know what is this?",
            "It's a combinatorial quantity, I don't know, but if it's a modular I can run the greedy rule and maybe I can say something about it.",
            "So this is not a submodular approximation and this is a small constant and now these subsets that greedy rule selects they have to be in the in the finite set.",
            "And you know, because it's nested.",
            "It's OK, right?",
            "So if you select it here and then, this set gets bigger, but the old things are still in there.",
            "So so This is why it's nested and."
        ],
        [
            "How this is kind of one of the crucial steps here.",
            "So now is kind of because it's finite decisions at finite number of possible arms, you actually can look at it as a linear Gaussian model.",
            "It's just the model over one vector here, and it has this prior with this kernel matrix.",
            "This is not like impact base, where this would be the kernel matrix of the data, but it's the kernel matrix on the discretisation set and then you can say that.",
            "OK, so if you play this game in order to get the gun motility, you would play the single arms to be the Delta functions that basically sample this F at a certain point.",
            "So these are unit norm vectors and you can relax that by saying, well, let's just use instead of deltas.",
            "Let's use arbitrary unit norm vectors that are sampled here and then you use this Rayleigh Ritz idea and say, well, these.",
            "Best unit norm vectors I could play.",
            "They have to be eigenvectors and that's how you get all this thing.",
            "I mean, you can discuss this offline, but that's how you get all this expression to something that you can really say something about.",
            "Now here you have the eigenvalues of this big matrix here and here you have the allocations or how many times do I sample eigenvalue number I?",
            "And this is the empirical spectrum."
        ],
        [
            "So, so that's how we bound this.",
            "And then the rest is kind of almost similar to what to what we did for the expected value, because now you have something that depends on some empirical eigenvalues.",
            "You split the sum, you bound details and then you use the operator spectrum asymptotic's.",
            "And now I guess also a crucial point is how do you choose this discretization?"
        ],
        [
            "And we use the probabilistic method by basically arguing if you sample uniformly from D, you can compute a sufficient size for which certain properties have to be true for a discretization like the nearest neighbour size is small enough and then also this inequality holds with high enough probability, which again comes from short, Taylor and Williams.",
            "So because we have to make that step again from the empirical to the process eigenvalues.",
            "And then the rest goes through.",
            "Now, how big is it?"
        ],
        [
            "So The funny thing is actually matches the result for the expected value in some cases.",
            "For the linear case it matches that.",
            "That's actually you don't need all this analysis for the linear case, because that's kind of easy.",
            "But for the also for the Gaussian kernel it matches it.",
            "So actually this is not only the expense."
        ],
        [
            "That value is small for the Gaussian kernel, but the worst the worst allocation or the maximum allocation is also just about that big.",
            "And then, uh."
        ],
        [
            "Function for the maternal.",
            "It doesn't match it, but that's I think could still be improved.",
            "So we have this result here and it looks the same as what we had in expected case.",
            "But you have instead of D and expected case you have D * D + 1 in the.",
            "In the maximum case."
        ],
        [
            "So that's actually that's it for my talk.",
            "So I think based in theorems are property of them is that they are tight because they depend on things like the model and they also depend on the data and the data dependence.",
            "In some cases at least, it calls for some further work.",
            "So to say, if I know my model but I don't want to get rid of the fluctuations over the data.",
            "So how much do I have to expect?"
        ],
        [
            "And that's the key quantity that comes up.",
            "If you do this in the GP setting, is the information gain for GP for examples, and really it controls how big the relative entropy term is.",
            "It controls the information consistency rates and it also if you take the maximum over that.",
            "It also controls the dis regret for the UCP."
        ],
        [
            "Algorithm.",
            "You can bound it by looking at the kernel operator spectrum.",
            "And that's one thing I really want to."
        ],
        [
            "Find out because by doing that you see once more that what really is in kernel methods is not that their infinite dimensional or finite dimensional, but what matters is what the kernel is.",
            "So what the kernel is depends determines what the capacities of the method.",
            "So if you look at the result that we get for the Gaussian kernel, it almost doesn't.",
            "It's almost no difference to the linear case.",
            "But if you look at what."
        ],
        [
            "Gaussian versus the maternal kernel does.",
            "There's a huge difference, so these are two infinite dimensional cases with arc S and so on.",
            "But actually this Gaussian case is way closer to the linear method in terms of at least in terms of these theorems.",
            "Here then it would actually be to the maternal care case and also what is real."
        ],
        [
            "Not right is the dependence on the input distribution.",
            "For example, what happens if you ever heavy tailed input distribution and abundant support is not there?",
            "So what can happen to this term?"
        ],
        [
            "And that's something I really think one could improve.",
            "So the maximum information gain.",
            "I don't think that the discretization that we choose is in any way optimal.",
            "So for example it should depend on the kernel, but it doesn't.",
            "What we do right now.",
            "So I really hope maybe somebody of you has a better idea.",
            "And also this gap in the result for the modern kernel that really shouldn't be there, or at least one should explain it."
        ],
        [
            "And also the technical condition.",
            "I really would like to either explain why it's there or say, well, it probably shouldn't really be there if you want to explain why it's there, you would have to give some counterexample that you can get such regret.",
            "For example with their own standalone back kernel.",
            "Yeah, that's it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me start by thanking a few people there all here so I can thank them.",
                    "label": 0
                },
                {
                    "sent": "So first of all, David right for coming up with all this stuff and I really think that we shouldn't call this.",
                    "label": 0
                },
                {
                    "sent": "We should call this mcalister's bound and then XY.",
                    "label": 0
                },
                {
                    "sent": "Zed applied some large deviation inequality, plugged it in because what matters is really the idea, right?",
                    "label": 0
                },
                {
                    "sent": "So it's kind of a bound generation idea.",
                    "label": 0
                },
                {
                    "sent": "And then John, I don't know.",
                    "label": 0
                },
                {
                    "sent": "It's not only for inviting me, I don't know if you remember that you were actually the person who who pointed.",
                    "label": 0
                },
                {
                    "sent": "Metepec Basin thing in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "So was this workshop in Germany and I gave this really poor talking and afterwards everybody was staring at me and I asked John.",
                    "label": 0
                },
                {
                    "sent": "So what do you think about this?",
                    "label": 0
                },
                {
                    "sent": "And he said maybe you should look at the pack Bayesian theory.",
                    "label": 0
                },
                {
                    "sent": "So and then month it up because I visited him in Essen and I gave a talk to and I only afterwards I realized how simple these things can really be.",
                    "label": 0
                },
                {
                    "sent": "If you put convexity in there.",
                    "label": 0
                },
                {
                    "sent": "So let's see what this talk is about.",
                    "label": 0
                },
                {
                    "sent": "So very briefly, because we've already did a really good job here, so let's notation.",
                    "label": 0
                },
                {
                    "sent": "So input points, output points, latent functions, F in my talk, not age, the price.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "LP empirical error generalization error.",
                    "label": 0
                },
                {
                    "sent": "So people pointed out the pack basis really simple.",
                    "label": 0
                },
                {
                    "sent": "I would say it's even simpler than that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See, this is how I explained it in my thesis.",
                    "label": 0
                },
                {
                    "sent": "So you start with a large deviation inequality and you can pick anything you want as long as it works, and then you turn that into something.",
                    "label": 0
                },
                {
                    "sent": "I would call a Peck on for dumb classifier so the large deviation inequality tells you something for a fixed function.",
                    "label": 1
                },
                {
                    "sent": "For example, this is something you can do with a with a Bernoulli.",
                    "label": 0
                },
                {
                    "sent": "This is kind of the KL for the Bernoulli.",
                    "label": 0
                },
                {
                    "sent": "You get something like that.",
                    "label": 0
                },
                {
                    "sent": "If you fix F, so then you do a dump classify.",
                    "label": 0
                },
                {
                    "sent": "You just average over F. It's still true right?",
                    "label": 0
                },
                {
                    "sent": "And it's really dumb becausw.",
                    "label": 1
                },
                {
                    "sent": "The way in which you average over your function space doesn't depend on the training data.",
                    "label": 0
                },
                {
                    "sent": "You just do the same thing all the time, so that's not very useful, but now.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Goal is really to convert that into something that's useful in kind of, lifted to something that makes a statement about a smart classifier that would be Q.",
                    "label": 1
                },
                {
                    "sent": "And it's smart because it kind of looks at the data and does something sensible with it, and the only question you have to answer is what does that cost me in order to lift it from the dumb to the smart one?",
                    "label": 0
                },
                {
                    "sent": "What do I have to pay for it and amount you have to pay if you use PAC, Bayes is exactly the relative entropy divided by N versus if you would use union bonds you would have to pay more usually here.",
                    "label": 0
                },
                {
                    "sent": "Something like lock of hypothesis space over and or something if it's infinite and I don't know then you have to do we see and how does it work.",
                    "label": 1
                },
                {
                    "sent": "It really works because there's this one amazing inequality which people college andreoff Angelo variation or whatever.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is this one here.",
                    "label": 0
                },
                {
                    "sent": "Comes from later on duality.",
                    "label": 0
                },
                {
                    "sent": "I don't know about you, but I think this is the most influential inequality that I know so it.",
                    "label": 0
                },
                {
                    "sent": "Maybe Manfred has the right name for it.",
                    "label": 0
                },
                {
                    "sent": "It comes from statistical physics, so this is the inequality.",
                    "label": 0
                },
                {
                    "sent": "It says like this is the thing.",
                    "label": 0
                },
                {
                    "sent": "So this is the lock partition function up here and it's lower bounded by the what people call the energy is sort of free energy or minus that I don't know.",
                    "label": 0
                },
                {
                    "sent": "And then you have the entropy of the negative entropy.",
                    "label": 0
                },
                {
                    "sent": "Here it is the KL diversion.",
                    "label": 0
                },
                {
                    "sent": "So it comes from statistical physics.",
                    "label": 1
                },
                {
                    "sent": "People used it a lot in variational inference.",
                    "label": 0
                },
                {
                    "sent": "For example all the mean field methods use it, or the structured mean field method.",
                    "label": 0
                },
                {
                    "sent": "They just use this inequality and optimize over Q.",
                    "label": 1
                },
                {
                    "sent": "And also if you think about it a little bit, the EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "That's really what the EM algorithm is doing is to use this bound, at least if you want to show.",
                    "label": 0
                },
                {
                    "sent": "It converges, and now if you do Peg base, this is also used in learning theory, so this is really nice.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's really nice.",
                    "label": 0
                },
                {
                    "sent": "In my thesis I said well, it kind of comes full circle because you use it in order to get these methods can also use it to analyze these methods the same idea.",
                    "label": 0
                },
                {
                    "sent": "So that's the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "McAllister bound and somebody plugged in the large deviation inequality here, so this how it works, right?",
                    "label": 0
                },
                {
                    "sent": "So this thing is convex, so you can pull out the expectation.",
                    "label": 0
                },
                {
                    "sent": "This is always true, so you get this.",
                    "label": 0
                },
                {
                    "sent": "Then you plug in.",
                    "label": 0
                },
                {
                    "sent": "This is here, this side you plug in the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Also always true and now we have this thing and now we apply the equality inequality for the dumb classifier in order to bound this and that is the only point where you have to do something with probability and then you get back Bayesian result here.",
                    "label": 0
                },
                {
                    "sent": "So, so we've had some people saying So what they think the pack Bayesian bounds are so he.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is another idea what they are.",
                    "label": 0
                },
                {
                    "sent": "They are tired there, certainly tighter than other bounds, and I think the reason why they are tide.",
                    "label": 0
                },
                {
                    "sent": "The main reason is that they depend on things so they are non uniform bound.",
                    "label": 0
                },
                {
                    "sent": "So they depend on things and if you happen to be some people say lucky other people say you try to make a good guess.",
                    "label": 0
                },
                {
                    "sent": "That's what you always do in statistics.",
                    "label": 0
                },
                {
                    "sent": "If you made a good guess in your prior and your model assumptions then these bonds give you a good small number so they are dependent on the problem.",
                    "label": 0
                },
                {
                    "sent": "And that's usually A plus would come to that, but they're also depending on the data, because the right hand side depends.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No data, so it fluctuates with the sample.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I guess I don't know if all of you agree, but I would say problem depends is always A plus.",
                    "label": 0
                },
                {
                    "sent": "I mean you have to be a really serious pessimist.",
                    "label": 0
                },
                {
                    "sent": "If you disagree here I think.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But data dependence is not so clear, right?",
                    "label": 0
                },
                {
                    "sent": "So data dependence is not always A plus.",
                    "label": 1
                },
                {
                    "sent": "I mean, there are two reasons why not.",
                    "label": 0
                },
                {
                    "sent": "Maybe you want to do optimized active sampling and then certainly this is a problem for you.",
                    "label": 0
                },
                {
                    "sent": "But it also sort of kind of.",
                    "label": 0
                },
                {
                    "sent": "I guess people can point out that you've just been lazy because they will ask you how big is this term.",
                    "label": 0
                },
                {
                    "sent": "I mean it fluctuates with the sample.",
                    "label": 0
                },
                {
                    "sent": "So how big is it?",
                    "label": 0
                },
                {
                    "sent": "For the model of the problem that you look at, so certainly you could say if you have a data dependent result, then there's actually more work to be done.",
                    "label": 0
                },
                {
                    "sent": "You have to say how big can this term be and this will get much clearer later on when I show you some some applications where the data depends then really a problem.",
                    "label": 0
                },
                {
                    "sent": "Well, let's let's just look at.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What how can we analyze this right hand side in the pack Bayesian theorem so this is now Gaussian process regression with Gaussian noise?",
                    "label": 1
                },
                {
                    "sent": "And I guess some people point out.",
                    "label": 0
                },
                {
                    "sent": "So he starts with classification.",
                    "label": 0
                },
                {
                    "sent": "Now he talks about regression, I think.",
                    "label": 0
                },
                {
                    "sent": "So this is just a simple case.",
                    "label": 0
                },
                {
                    "sent": "I think it also holds for classification.",
                    "label": 0
                },
                {
                    "sent": "We can maybe discuss this offline.",
                    "label": 0
                },
                {
                    "sent": "So for Gaussian process classification with Gaussian noise, this is the prior you sample your sample path from the zero mean Gaussian process with kernel K and then you sample your data from that function with some Gaussian noise Sigma Square.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the posterior that you would call P of F given given the data Y.",
                    "label": 0
                },
                {
                    "sent": "Or you could also call it Q in the pack Bayesian bound that would then be also a Gaussian process because this was a Gaussian process and then you multiply in this Gaussian likelihood.",
                    "label": 0
                },
                {
                    "sent": "And then it stays a Gaussian process, and importantly, this likelihood only depends on the process evaluated at a few points, it's kind of shifts to measure on this crew points, and that also means that for the whole remaining analysis you can only concentrate on this viewpoint.",
                    "label": 0
                },
                {
                    "sent": "So this vector F up here.",
                    "label": 0
                },
                {
                    "sent": "So whenever this is powered, I really only mean the function ever.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that these endpoints.",
                    "label": 0
                },
                {
                    "sent": "And that's nice, because now it all becomes linear algebra.",
                    "label": 0
                },
                {
                    "sent": "You only have to define a few matrices and you only have to think about what are the main distributions that we're talking about.",
                    "label": 0
                },
                {
                    "sent": "Now this is the prior zero mean, and it has the kernel matrix is the covariance.",
                    "label": 0
                },
                {
                    "sent": "Then you have the data distribution, which is the distribution of the marginal likelihood of the data and that also has zero mean because the noise didn't have any.",
                    "label": 0
                },
                {
                    "sent": "Also had zero mean and covariance is different.",
                    "label": 0
                },
                {
                    "sent": "It's not K anymore, but you have to add this this noise covariance there and then you also have to posterior which you can write like that so that it does this mean in this covariance?",
                    "label": 0
                },
                {
                    "sent": "So the mean I explicitly wrote it in this Alpha annotation because SVM people like to call of this sister.",
                    "label": 0
                },
                {
                    "sent": "They like to think about this is the dual vector.",
                    "label": 0
                },
                {
                    "sent": "And then you multiply it with the column matrix.",
                    "label": 0
                },
                {
                    "sent": "You get the posterior mean.",
                    "label": 0
                },
                {
                    "sent": "And the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "You can kind of write as this.",
                    "label": 0
                },
                {
                    "sent": "This product of K and the inverse of the Sigma.",
                    "label": 0
                },
                {
                    "sent": "This doesn't look like symmetric matrix, but it's actually one.",
                    "label": 0
                },
                {
                    "sent": "So that's the really neat thing about this model is you can write all this down and you can analyze it and you can say how big it is and you can say which is the dominating term and let's just try to do that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this this guy is going to come out as the one that dominates it.",
                    "label": 0
                },
                {
                    "sent": "So this is the mutual information between the process and the data, so it's kind of the information gain.",
                    "label": 0
                },
                {
                    "sent": "So before you sampled that function you knew about as much as the prior about it.",
                    "label": 0
                },
                {
                    "sent": "Entropy of the prior or you didn't know about as much as the prior, so that the entropy and then you sample it at end points and then you know more about the function.",
                    "label": 0
                },
                {
                    "sent": "So you take this difference.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of expected posterior entropy.",
                    "label": 0
                },
                {
                    "sent": "That's a positive number here, at least for this model, and that tells you how much information do you gain when you sample this thing at end points.",
                    "label": 0
                },
                {
                    "sent": "And it certainly depends on where you sample them, and this is the quantity.",
                    "label": 0
                },
                {
                    "sent": "If you write it down, so that's a lock determinant identity the kernel matrix.",
                    "label": 0
                },
                {
                    "sent": "Something you can compute and you can look at.",
                    "label": 0
                },
                {
                    "sent": "You can also because this is kind of symmetric.",
                    "label": 0
                },
                {
                    "sent": "You can also write it like that, so entropy of the data before and after you've looked at F. Um?",
                    "label": 0
                },
                {
                    "sent": "And this is kind of almost this, so this term it came up like all the time and I really in stepwise I figured out you know, where does this come up and how found it.",
                    "label": 0
                },
                {
                    "sent": "And this is, I guess all this talk is going to be about about this term and what it does and where it comes up and how to bound it.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing this is really well known is that if you take the right hand side in the pack Bayesian theorem for the Gaussian process case, and you take then the average value over the data distribution, then you get this information gain.",
                    "label": 0
                },
                {
                    "sent": "That's that's true.",
                    "label": 0
                },
                {
                    "sent": "That's actually true for any statistical model.",
                    "label": 0
                },
                {
                    "sent": "If all these things are done exactly here.",
                    "label": 0
                },
                {
                    "sent": "So this is just I mean, some people simply say that this is the.",
                    "label": 0
                },
                {
                    "sent": "This is the information gain because they always do the expectation over the over the data.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is very easy to see, so you just take this thing.",
                    "label": 0
                },
                {
                    "sent": "You write it out, then you get one term.",
                    "label": 0
                },
                {
                    "sent": "That is this one.",
                    "label": 0
                },
                {
                    "sent": "Just write it down and then you get another term that is the expectation over the posterior Q and I just plugged it into BP of F. Given Y of the negative log of the prior and then you have to expectation outside over why.",
                    "label": 0
                },
                {
                    "sent": "Now you pull these two things together.",
                    "label": 0
                },
                {
                    "sent": "You get the expectation over the joint.",
                    "label": 0
                },
                {
                    "sent": "And then you realize that there's no way in here.",
                    "label": 0
                },
                {
                    "sent": "So you just integrate it out you.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The entropy of the prior and then you plug it together and you see that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's in fact true, and I mean, as Manfred pointed out, there's nothing like Gaussian.",
                    "label": 0
                },
                {
                    "sent": "I used here.",
                    "label": 0
                },
                {
                    "sent": "This is all true for any distribution, so expected value of this KL is the information gain.",
                    "label": 1
                },
                {
                    "sent": "Be careful here because it's not the expected value over the data or whatever, it's just the expected value over very specific distribution.",
                    "label": 0
                },
                {
                    "sent": "And of course this thing still depends on the input points.",
                    "label": 1
                },
                {
                    "sent": "Yes, this is.",
                    "label": 0
                },
                {
                    "sent": "This is maybe also the main reason why it's interesting.",
                    "label": 0
                },
                {
                    "sent": "So what about the rest?",
                    "label": 1
                },
                {
                    "sent": "So that's fine.",
                    "label": 0
                },
                {
                    "sent": "So you sort of know what it's doing and expectation.",
                    "label": 0
                },
                {
                    "sent": "What about the rest?",
                    "label": 0
                },
                {
                    "sent": "Again, you can just this was on John Slide yesterday, so you can write it down what it is and you can also actually say what these terms are.",
                    "label": 0
                },
                {
                    "sent": "So the first one is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you think about it for a second, it's the square dark iges norm of the mean function.",
                    "label": 0
                },
                {
                    "sent": "So if you think about fitting your GP to some data which the underlying data is function of bounded arcade Jess Norm, then this term is going to go towards that.",
                    "label": 0
                },
                {
                    "sent": "Given that you know that it's consistent, it's going to go towards that number, and it's not going to be larger than this number somehow, so it's going to be actually compared to this term.",
                    "label": 0
                },
                {
                    "sent": "It's going to be subdominant, the second part is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Coming from the posterior variance.",
                    "label": 0
                },
                {
                    "sent": "So if you look up here that was the posterior covariance matrix and here's just a trace of it.",
                    "label": 0
                },
                {
                    "sent": "So it's the sum of the posterior variances, and again you can fairly easily show that this term has to be even.",
                    "label": 0
                },
                {
                    "sent": "Order smaller than the other term by so the idea is that you just look at these two functions.",
                    "label": 0
                },
                {
                    "sent": "We can plot them and you can see that the one is always quite a bit bigger.",
                    "label": 0
                },
                {
                    "sent": "I mean, they're they're the same asymptotically when you go to zero, but sort of the day they give you.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is really then at least kind of.",
                    "label": 0
                },
                {
                    "sent": "This is smaller than that term, so you can in the end what I want to say here is that you can focus on this term if you want to know how big this thing can be.",
                    "label": 0
                },
                {
                    "sent": "Some way the norm term is sort of what was there so so that is it is kind of where your assumption goes in that.",
                    "label": 0
                },
                {
                    "sent": "So you are fitting this to a function which has a bounded complexity.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm brushing this a little bit under the carpet, but you have to make some assumptions.",
                    "label": 0
                },
                {
                    "sent": "Suppose you fit your model to a target function.",
                    "label": 0
                },
                {
                    "sent": "If that function is arbitrarily complicated and you are not going to get any good behavior here, but usually you would assume that you do.",
                    "label": 0
                },
                {
                    "sent": "You know your target function, so this is a bit fluffier.",
                    "label": 0
                },
                {
                    "sent": "How did you say yesterday?",
                    "label": 0
                },
                {
                    "sent": "It's kind of.",
                    "label": 0
                },
                {
                    "sent": "Loosely, but but I would say that in most applications, if you know that your target function is not too complicated, then this thing is going to be small in the end.",
                    "label": 0
                },
                {
                    "sent": "Even a small yeah.",
                    "label": 0
                },
                {
                    "sent": "So I mean in this case I just want to motivate why it's actually important.",
                    "label": 0
                },
                {
                    "sent": "I mean I have a few other reasons why it's important to understand how big distincion be, which may be more convincing than what I'm talking about now.",
                    "label": 0
                },
                {
                    "sent": "But in for the moment I just want to tell you that if you want to know about this term, then you know that this one is in there, and then you know that a few other things are in there which you can argue that they are usually smaller than the others.",
                    "label": 0
                },
                {
                    "sent": "Set the target function came from the prior then if well then everything goes away here right?",
                    "label": 0
                },
                {
                    "sent": "Because then you have to access.",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to assess what month it tries to say it's OK if everything comes from the data distribution from the model then this thing is not there anyway.",
                    "label": 0
                },
                {
                    "sent": "So you directly.",
                    "label": 0
                },
                {
                    "sent": "Actually there's a paper by you and where you?",
                    "label": 0
                },
                {
                    "sent": "Is this is our cages North so if if the mean approaches the true target function with increasing amount of data then this would actually grow.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but there's this negative.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you take the expectation look this, this only depends on why right, and this doesn't depend on why, so the expectation over Y of this term is exactly that one, and that's why it cancels out.",
                    "label": 0
                },
                {
                    "sent": "And so if you take the expectation over why from the data, then you're only left with this term, but I'm just so this is the kind of the non agnostic case.",
                    "label": 0
                },
                {
                    "sent": "If you get your data from somewhere, but you know that it's not infinitely complicated.",
                    "label": 0
                },
                {
                    "sent": "Tennis engross this thing is going to dominate.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's let's switch topic now away from the pack base, but another case where it comes up.",
                    "label": 0
                },
                {
                    "sent": "So this sequential prediction Alok loss.",
                    "label": 0
                },
                {
                    "sent": "So the game is that you always predict the next target given the input that you get and the previous data that you got, so X one you predict why one is in some said Y and then 4X2.",
                    "label": 0
                },
                {
                    "sent": "You have to predict Y two given the previous and so on and so on, and the game goes like you predict the distribution for the next label.",
                    "label": 0
                },
                {
                    "sent": "And then you actually incur a loss, which is the negative log of that distribution.",
                    "label": 0
                },
                {
                    "sent": "Where the nature plugs in the true value or something and then you add up the cumulative lock loss and that is what you want to minimize with a strategy which always.",
                    "label": 0
                },
                {
                    "sent": "Pulls out these distributions for in every new timestep, and now if you fix the likelihood here.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, you could say the loss function, but in this case it's really a likelihood that underlies the loss function.",
                    "label": 0
                },
                {
                    "sent": "Fix the function space.",
                    "label": 0
                },
                {
                    "sent": "So how could you play this game so one of the things that you could play it in the Bayesian way?",
                    "label": 0
                },
                {
                    "sent": "You could always use the predictive Bayesian distribution in order to make that next decision, and that looks like that here and then.",
                    "label": 0
                },
                {
                    "sent": "Funny the lock loss kind of adds up with the chain rule, and so on, and you just get the marginal likelihood here.",
                    "label": 0
                },
                {
                    "sent": "The negative local marginal likelihood, which is your cumulative log loss.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can compare that against an expert strategy.",
                    "label": 0
                },
                {
                    "sent": "So so this is an expert, so he really knows what he's doing, so it's not going to bother about.",
                    "label": 0
                },
                {
                    "sent": "Data is always going to say the same thing, but that might be really dumb, but maybe the best expert in this class is going to be one that is really good and you want to compare your strategy against all of them.",
                    "label": 0
                },
                {
                    "sent": "So here for the expert, the cumulative log loss is just adding up all these negative locks here, and you can write it in this form here, so you always get used the same function for predicting and then you get the loss.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's this notion of information consistency, which kind of is a quality associated with a prediction rule.",
                    "label": 0
                },
                {
                    "sent": "So you'd say Rs information consistent of our space of competitors with respect to some input distribution if for every competitor you are in this KL divergent, not not much worse than this competitor, no matter what it was, so not much worse means that KL divergences between the tool.",
                    "label": 0
                },
                {
                    "sent": "A predictive distributions here this you can also write.",
                    "label": 0
                },
                {
                    "sent": "This is a Cicero average.",
                    "label": 0
                },
                {
                    "sent": "If you just sum it used to chain rules here, but you can also write it like that.",
                    "label": 0
                },
                {
                    "sent": "Expectation over the input distribution outside it has to grow less fast and then and then.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into the Bayesian sequential prediction is that you can write this KL divergent's exactly as the expected value over the data distribution of these two losses.",
                    "label": 0
                },
                {
                    "sent": "Of these two strategies that are head up.",
                    "label": 0
                },
                {
                    "sent": "So that means that if you.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for any why an you can control this thing here with a uniform regret bound uniform, not over expert over Y.",
                    "label": 1
                },
                {
                    "sent": "That implies certainly that it's information consistent.",
                    "label": 0
                },
                {
                    "sent": "Well, if this bound is small enough, smaller than N or goes divided by N goes to 0, then you have information consistency.",
                    "label": 0
                },
                {
                    "sent": "And now we have this so this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regret bound.",
                    "label": 0
                },
                {
                    "sent": "And So what is this?",
                    "label": 0
                },
                {
                    "sent": "This is the cumulative log log loss of the Bayesian.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "The same thing for any expert, and then you have.",
                    "label": 1
                },
                {
                    "sent": "Then you have this squared kitces norm of the expert here, which basically just means that if the expert is very complicated then it might really do a very good job.",
                    "label": 0
                },
                {
                    "sent": "So you would really expect this term to be there.",
                    "label": 0
                },
                {
                    "sent": "And then you have this player again, right?",
                    "label": 0
                },
                {
                    "sent": "So the information gain is in here again.",
                    "label": 1
                },
                {
                    "sent": "We call this a regret term in the paper, but it's really the information gain.",
                    "label": 0
                },
                {
                    "sent": "And Archeage snom that comes from the arcade chest.",
                    "label": 0
                },
                {
                    "sent": "It's defined by the kernel and what's the sea?",
                    "label": 0
                },
                {
                    "sent": "The sea is basically something that if this was done with regression to see would be a Sigma square inverse, but in general it simply bounced II curvature of the negative of the loss function if you want.",
                    "label": 0
                },
                {
                    "sent": "OK, so this works for classification and see what we want over for it also works, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't work for 01, obviously, so there's a step so you have infinite curvature, but it works for all these loss functions F bounded curvature.",
                    "label": 0
                },
                {
                    "sent": "Definitely, oh, because there's all minus here.",
                    "label": 0
                },
                {
                    "sent": "So in the in the PAC Bayes explanation I had this plus and then you know what I mean.",
                    "label": 0
                },
                {
                    "sent": "Was there were different sign between the cage Norman?",
                    "label": 0
                },
                {
                    "sent": "The log of the.",
                    "label": 0
                },
                {
                    "sent": "Determinant.",
                    "label": 0
                },
                {
                    "sent": "'cause they were canceling each other at some point in the.",
                    "label": 0
                },
                {
                    "sent": "But maybe that's not.",
                    "label": 0
                },
                {
                    "sent": "Maybe I missed up, maybe maybe a mixed up some signs somewhere, but this is certainly true.",
                    "label": 0
                },
                {
                    "sent": "I have this in my head, maybe it was wrong.",
                    "label": 0
                },
                {
                    "sent": "What I did earlier.",
                    "label": 0
                },
                {
                    "sent": "What so there's no correct function here.",
                    "label": 0
                },
                {
                    "sent": "The point is that so this is a uniform bound, so it holds for any X&NEY it doesn't.",
                    "label": 0
                },
                {
                    "sent": "There's no correct trying.",
                    "label": 0
                },
                {
                    "sent": "This is actually a bit different, and then from then generalization error bounds.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of this.",
                    "label": 0
                },
                {
                    "sent": "You know this regret type setting where you compare yourself against others, and you do this for any data.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "And then usually there's some condition on where the X comes from.",
                    "label": 0
                },
                {
                    "sent": "I come to that, but the why can be anything?",
                    "label": 0
                },
                {
                    "sent": "So I hope this is correct.",
                    "label": 0
                },
                {
                    "sent": "Maybe there was a sign mix up earlier on.",
                    "label": 1
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "That means that this GP prediction rule is information consistent.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To compare against any function, you are cages that holds for any input distribution and it holds for any stationary kernel as long as it's basically not infinite at 0.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of almost all the cons people use, and unless there may be non stationary and the other really nice thing about this because we can somehow say something about this term and then we can also get.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The size, information, consistency rates and they are what I would call problem dependent because they depend on the kernel and they depend on what you kind of can assume about the input distribution, and they're controlled exactly by this term.",
                    "label": 0
                },
                {
                    "sent": "It's left over here by the expected information gain expectation is over the input distribution now divided by N. So now I have to sort of show you.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little bit how this works, because otherwise you don't believe me that this is pacbase, so it's kind of peg based because it uses the variational inequality again.",
                    "label": 0
                },
                {
                    "sent": "So you start with assuming that this is coming from the span.",
                    "label": 0
                },
                {
                    "sent": "So from this so it's a kernel expansion and then you use immediately this inequality.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "That if we energies or this kind of minus of the thing that I had earlier, this is the energy.",
                    "label": 0
                },
                {
                    "sent": "This is the entropy, and this holds for any distribution.",
                    "label": 0
                },
                {
                    "sent": "And now I'm.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing a trick like in John and John's paper, I'm now.",
                    "label": 0
                },
                {
                    "sent": "Here's no distribution here.",
                    "label": 0
                },
                {
                    "sent": "There's only a competitor.",
                    "label": 0
                },
                {
                    "sent": "There's only a function, so I'm going to construct a GP that does the right thing, and I'm doing it by constructing the GP Q so that its main function is the function I want to compare against and that its covariance function is not exactly the kernel, but it's this kind of this covariance function that I get by adding a noise term to the kernel.",
                    "label": 0
                },
                {
                    "sent": "And when I do that and I get this result.",
                    "label": 0
                },
                {
                    "sent": "So this is for any function that is a kernel expansion on the day to get this inequality.",
                    "label": 0
                },
                {
                    "sent": "And this is actually an equality if The thing is regression.",
                    "label": 0
                },
                {
                    "sent": "So for regression all our results are actually equalities, not inequalities.",
                    "label": 0
                },
                {
                    "sent": "And then the rest thing is to represent us.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you just say, well, if this is true for any expansion, and because this only holds this term only depends on what the function does on the data, then it has to hold for everything in the dark Ages.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now OK so.",
                    "label": 0
                },
                {
                    "sent": "It's really important to know how big this information gain is.",
                    "label": 0
                },
                {
                    "sent": "So how can we do that so we can look at the empirical spectrum and we can relate it to the operator spectrum of the kernel with respect to the input distribution.",
                    "label": 0
                },
                {
                    "sent": "So this empirical spectrum of K / N and that is the information.",
                    "label": 0
                },
                {
                    "sent": "Again, if you write it in the spectrum now that's the problem is that this all depends on the data.",
                    "label": 0
                },
                {
                    "sent": "That's what you don't want.",
                    "label": 0
                },
                {
                    "sent": "So you go to the limit of that and that doesn't depend on the data.",
                    "label": 0
                },
                {
                    "sent": "It depends only on the distribution center data comes from.",
                    "label": 0
                },
                {
                    "sent": "And then you can look at.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is Tom and you can.",
                    "label": 0
                },
                {
                    "sent": "This is always not going to same tricks, so you split it into parts you sum up to I not, and then you summon the rest.",
                    "label": 0
                },
                {
                    "sent": "First part you say OK, if I sum up to IN then it can be only as big as I know times log N and the rest you can say, well log 1 + X smaller equal to X.",
                    "label": 0
                },
                {
                    "sent": "So this is just tail some.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You use again something that John and Chris Williams did, which is a really funny property of these tail sums.",
                    "label": 0
                },
                {
                    "sent": "Because the expected value of the empirical tail sums, at least if they, if everything is stationary.",
                    "label": 0
                },
                {
                    "sent": "So they all sum up to the same value.",
                    "label": 0
                },
                {
                    "sent": "They're actually.",
                    "label": 0
                },
                {
                    "sent": "Inequality is here, so the expected value of detail.",
                    "label": 0
                },
                {
                    "sent": "Some of the empirical is actually cannot be larger than the tail.",
                    "label": 0
                },
                {
                    "sent": "Some of the process eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Let's just call it BI, not so this is the step where we go from the data dependent to the data independent property that we can maybe say more about.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And well, then you get information consistency, but just saying that OK, we use this bound.",
                    "label": 0
                },
                {
                    "sent": "So the first term is speaker stat.",
                    "label": 0
                },
                {
                    "sent": "The second term is his biggest be I not, and because this has to sum up.",
                    "label": 0
                },
                {
                    "sent": "Alright then this thing is to go to 0, so it's information consistent no matter what the input distribution was.",
                    "label": 0
                },
                {
                    "sent": "So Engelstein word pointed that out to me.",
                    "label": 0
                },
                {
                    "sent": "We had all these results for by not, but he said well, looked at implies that it's anyway information consistent because this thing has to go to 0.",
                    "label": 0
                },
                {
                    "sent": "Even nicer you can.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also say how quick it goes to 0, because you actually might be able to say how fast this term the case just by you know using results that people have got on these kernel operator Spectra.",
                    "label": 0
                },
                {
                    "sent": "So for example for the Gaussian kernel or the RBF kernel in the Gaussian input distribution you can.",
                    "label": 0
                },
                {
                    "sent": "This is known how it looks like it's in this paper by through Williams and others, and if you then do this trick with the split some and do some mathematics then you get this one.",
                    "label": 0
                },
                {
                    "sent": "And this is really small.",
                    "label": 0
                },
                {
                    "sent": "I mean, I was really surprised when I got that.",
                    "label": 0
                },
                {
                    "sent": "Maybe I don't know too much about these things, but but this is really small.",
                    "label": 0
                },
                {
                    "sent": "If you divide it by N, it's decaying extremely fast.",
                    "label": 0
                },
                {
                    "sent": "While if you do it for the maternal kernel, which includes some really rough kernels, then this is way way slower.",
                    "label": 0
                },
                {
                    "sent": "So if you do the same trick and you use some results from some mathematician, then you get things like that.",
                    "label": 0
                },
                {
                    "sent": "So here you have a term that depends on end not only on log N and if you get to something like this is the degree of freedom.",
                    "label": 0
                },
                {
                    "sent": "If you set that to 1/2 year on sent one back kernel which is really rough then you get something that's just about.",
                    "label": 0
                },
                {
                    "sent": "Smaller than an.",
                    "label": 0
                },
                {
                    "sent": "So you get information consistency, but the rate is quite slow, while for the Gaussian is extremely fast, you can compare this to the linear where you basically would have something like that in the dimension here.",
                    "label": 0
                },
                {
                    "sent": "So this is almost like the linear case.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some comments on this work actually really nice.",
                    "label": 0
                },
                {
                    "sent": "Some some real mathematicians picked this up so so there's a paper coming up who basically said, OK, they did this and we can, you know, we can do this better.",
                    "label": 0
                },
                {
                    "sent": "I can do that better.",
                    "label": 0
                },
                {
                    "sent": "So first of all, actually we cause it's Gaussian processes.",
                    "label": 0
                },
                {
                    "sent": "You can do many things in a much nicer way than what we did, and I still have to understand it.",
                    "label": 0
                },
                {
                    "sent": "So first of all, you can relax the assumption that the competitor has to be in the arcade.",
                    "label": 0
                },
                {
                    "sent": "Yes, it seems to be that they can actually do this for any continuous function.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then you can don't even have to talk about information consistency, but you can talk about this stronger property here.",
                    "label": 0
                },
                {
                    "sent": "And you can also do something else then on bounding disk information gain.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I have some questions that they are still out on this term, so one of the things is that we looked at the expected value, but what about concentration topic?",
                    "label": 0
                },
                {
                    "sent": "Can it be?",
                    "label": 0
                },
                {
                    "sent": "It's still not done?",
                    "label": 0
                },
                {
                    "sent": "I only say what's the expected value so that could be useful this paper, but we also get to that and then things like what about heavy tailed distributions that don't have bounded support?",
                    "label": 1
                },
                {
                    "sent": "Then this theorem wouldn't work that I use for our non stationary kernel.",
                    "label": 0
                },
                {
                    "sent": "Again there are some ideas in this paper but I still have to understand it.",
                    "label": 0
                },
                {
                    "sent": "You again, that's the input distribution where the X is come from and then they are IID drawn from the X from the distribution.",
                    "label": 0
                },
                {
                    "sent": "So for example, one of one of the things that is a bit unpleasant is that these bounds always depend on what the input distribution should be, while the information consistency didn't depend on it.",
                    "label": 0
                },
                {
                    "sent": "So one would expect that I can bound this only depending on the kernel, and this is something that these guys say that this is possible by using entropy numbers, and I just don't understand it right now, but it's so they say that eigenvalues are with not the right way of analyzing these terms, but you need to use other concepts, but I guess it's the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Once you have them, you can make a good statement.",
                    "label": 0
                },
                {
                    "sent": "So now another thing, another topic, that's what I really wanted to.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tell you about here, because this is where the information gain really comes in and you can't avoid it anymore.",
                    "label": 0
                },
                {
                    "sent": "This stochastic optimization so, so what's that?",
                    "label": 1
                },
                {
                    "sent": "So optimization is hard enough, but what if you don't even know what you want to minimize, right?",
                    "label": 1
                },
                {
                    "sent": "That sounds really hard, but unfortunately it's hard.",
                    "label": 1
                },
                {
                    "sent": "But it also is important in practice.",
                    "label": 1
                },
                {
                    "sent": "So for example, you want to, you know if you're working at Yahoo, you want to choose advertisements and you want to maximize the clickthrough profit.",
                    "label": 0
                },
                {
                    "sent": "But you certainly don't know what the users really want if you do clinical trials, you want to minimize patient loss if you do.",
                    "label": 0
                },
                {
                    "sent": "Adaptive routing you don't know how the network really looks like, but you still have to minimize these delays and this is.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it looks like a formally, so you have this unknown function F~ It has some maximum somewhere, and then you play this sampling game.",
                    "label": 0
                },
                {
                    "sent": "So you sample the function and you observe the function where you sampled it with some noise and you also get a loss or regret, and that loss is basically telling you how much worse than the best possible sample you have been.",
                    "label": 0
                },
                {
                    "sent": "So if you knew where the where the optimum is, then you would always sample it and you would never get any loss.",
                    "label": 0
                },
                {
                    "sent": "But as long as you don't and you get some loss.",
                    "label": 0
                },
                {
                    "sent": "And then you sum up the loss or the cumulative regret, and that you want to minimize that thing.",
                    "label": 0
                },
                {
                    "sent": "And especially interesting, is it again to say when is this thing growing much slower than N?",
                    "label": 0
                },
                {
                    "sent": "So when when am I not doing a regret after some initial time when I'm really getting down to the optimum?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a very interesting problem because it's not the same problem as what people usually wear.",
                    "label": 0
                },
                {
                    "sent": "At least what I thought for a long time.",
                    "label": 0
                },
                {
                    "sent": "People usually do in statistics because there's this explore exploit tradeoff.",
                    "label": 0
                },
                {
                    "sent": "I come to that because it's very nice to illustrate it here, but just for the moment it means that you have to learn just enough about that function so that you can maximize it.",
                    "label": 0
                },
                {
                    "sent": "You must not learn anything more about it, because that would be wasted effort.",
                    "label": 0
                },
                {
                    "sent": "Well, that's true.",
                    "label": 0
                },
                {
                    "sent": "I don't know this regret.",
                    "label": 0
                },
                {
                    "sent": "I didn't say this.",
                    "label": 0
                },
                {
                    "sent": "The only thing I get I don't even get a reward I get nothing.",
                    "label": 0
                },
                {
                    "sent": "I only get the observation this is something that somebody stores and in the end tells me oh, you've done it this good I never observe what that regret was it would be a very strong information of course, but I never get this.",
                    "label": 0
                },
                {
                    "sent": "Nobody ever tells me how good I do.",
                    "label": 0
                },
                {
                    "sent": "Until the end I guess, but I mean this is actually Infinite Horizon.",
                    "label": 0
                },
                {
                    "sent": "This is not so.",
                    "label": 0
                },
                {
                    "sent": "We're not going to contest this setting if you know that you can only sample 1000 times, it's a different game.",
                    "label": 0
                },
                {
                    "sent": "But this is like you can stop at anytime and you want to be as good as possible at any point in time.",
                    "label": 0
                },
                {
                    "sent": "Kate.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "I assume that I know Sigma Square.",
                    "label": 0
                },
                {
                    "sent": "Actually in our theory might come to that.",
                    "label": 0
                },
                {
                    "sent": "We have to assume more than that.",
                    "label": 0
                },
                {
                    "sent": "Actually, there was this questions of what about if Sigma Square Zero?",
                    "label": 0
                },
                {
                    "sent": "I think you can also do it, but we didn't do it so this I think you could do it because doesn't seem like a problem, but in the end we know Sigma and it's not 0.",
                    "label": 0
                },
                {
                    "sent": "So then I guess that's obvious, so that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also implies convergence rates because the maximum is kind of closer to the truth than the average.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And funny enough, this is called multi arm Bandit problem with dependent Arms because it sort of comes from from this idea where every arm would be a possible value of X.",
                    "label": 1
                },
                {
                    "sent": "Now here you have a continuum.",
                    "label": 0
                },
                {
                    "sent": "That's a bit weird this this octopus would have to have a continuous number of arms, but but usually it comes from the fact where you have finite arms and you have to pull them in the right kind of frequency in order to minimize this regret.",
                    "label": 0
                },
                {
                    "sent": "So it sort of comes from this, but it's getting a little bit weird too.",
                    "label": 0
                },
                {
                    "sent": "It's it's coming from people that looked at these multi unbanded problems.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's explore exploit and it's really nice to demonstrate.",
                    "label": 0
                },
                {
                    "sent": "So this is how we do it.",
                    "label": 0
                },
                {
                    "sent": "We say, OK, we do this with GPS, so we represent the knowledge about the function with a cheap posterior, so that has a GP prior.",
                    "label": 0
                },
                {
                    "sent": "And we always look at the mean function in the variance function.",
                    "label": 0
                },
                {
                    "sent": "And now how do I sample this thing if I only want to minimize my cumulative regret?",
                    "label": 0
                },
                {
                    "sent": "So here are a few ideas.",
                    "label": 0
                },
                {
                    "sent": "So one of the things I could do is I could simply always maximize the variance function order square root of it, and that is what experiment design would do.",
                    "label": 0
                },
                {
                    "sent": "So you would decrease the uncertainty globally and then you would say, well, if I really know that function everywhere then I can also optimize it, right?",
                    "label": 0
                },
                {
                    "sent": "But that is not so good because you actually waste effort exploring that function at even at places where you wouldn't want to explore it, because the maximum cannot be there.",
                    "label": 0
                },
                {
                    "sent": "So this is not such a good idea.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can use another idea which, which means you simply always maximize the average mean function that you have right now.",
                    "label": 0
                },
                {
                    "sent": "So the average expected reward.",
                    "label": 1
                },
                {
                    "sent": "That is also not such a good idea, because we actually exploit it very much too soon.",
                    "label": 0
                },
                {
                    "sent": "You are very greedy, you exploit whatever you know right now and you usually get stuck in a local optimum.",
                    "label": 0
                },
                {
                    "sent": "You never find the point where you really make the best gain or the smallest loss.",
                    "label": 0
                },
                {
                    "sent": "So what you can do then is simply taken every.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much of that so you can use this rule, which people called the upper confidence bound idea.",
                    "label": 0
                },
                {
                    "sent": "So you take basically some of these two things.",
                    "label": 0
                },
                {
                    "sent": "You waited in the right way, and that's what you maximize.",
                    "label": 0
                },
                {
                    "sent": "OK, and that is actually way better than these both strategies, because you can actually realize the optimal explore exploit tradeoff that way.",
                    "label": 0
                },
                {
                    "sent": "And then if you do this with GPU, could call this the GP upper confidence bound algorithm.",
                    "label": 1
                },
                {
                    "sent": "And we we've done an analysis of this well.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just show you how this looks like.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you model the unknown function by a GP and then you always in every step you maximize the upper confidence level.",
                    "label": 0
                },
                {
                    "sent": "So here, for example, is an example, so you have to meet function.",
                    "label": 0
                },
                {
                    "sent": "And you assembled already at these points, and that is the upper confidence level.",
                    "label": 0
                },
                {
                    "sent": "So so many people would.",
                    "label": 0
                },
                {
                    "sent": "So where should I sample now, right?",
                    "label": 0
                },
                {
                    "sent": "So probably most people would say well, somewhere here, but the algorithm actually samples here because the upper confidence level is higher here than it would be here.",
                    "label": 0
                },
                {
                    "sent": "Which simply means that if I sample here, I already know the function.",
                    "label": 0
                },
                {
                    "sent": "But here it might.",
                    "label": 0
                },
                {
                    "sent": "There might be actually a maximum here that I missed, so it's samples here.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it wasn't here so little bit up here, but it wasn't quite here and now the next sample would be there because now the upper can.",
                    "label": 0
                },
                {
                    "sent": "I mean, here's maybe another candidate, but this is still a little bit higher here, OK?",
                    "label": 0
                },
                {
                    "sent": "So now we we.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Analyze this algorithm and this is kind of again, this is the one quantity that's important in this analysis, and this is this time is the information gain, but now you maximize it.",
                    "label": 0
                },
                {
                    "sent": "So you do the sampling in a way that maximizes the information gain.",
                    "label": 0
                },
                {
                    "sent": "And then you have this bound here, which basically says that if T is compact, you have to choose the beta that way.",
                    "label": 0
                },
                {
                    "sent": "And now the main assump.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And isn't this is only part of the theorem that we have is that you draw the unknown function from the GP that you actually also use to have the prior for your model, so you draw a sample path from the GP from the zero mean with kernel K, and then you try to find its optimum while you only allowed to sample this function and we also need a technical condition which is kind of something like a Lipschitz property with high probability, and I'd tell you when that holds and then when you assume all that then you get this regret bound and it just says the.",
                    "label": 0
                },
                {
                    "sent": "This is uniform over all N regret is smaller equal then the square root thing here.",
                    "label": 1
                },
                {
                    "sent": "But notice that the information gain so this is N times the maximum information gain due to sampling which is controlling the rate of this algorithm.",
                    "label": 1
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "That means that the rate of this algorithm is dependent on the maximum is controlled by the maximum inform.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action game come back to this point, but just a few comments.",
                    "label": 0
                },
                {
                    "sent": "We have a similar result if the F~ is not from the prior that we assume, but it can be any RKG as function, but I don't get this is more messy so they don't discuss it the technical.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Condition, which is something I'm a bit annoyed about, but it's still there so it holds if the kernel is 4 times differentiable.",
                    "label": 0
                },
                {
                    "sent": "So for example for the Gaussian or the maternal kernel when the UFC is larger than two, but it doesn't hold for the instant wound vac, so we still don't know.",
                    "label": 0
                },
                {
                    "sent": "I mean certainly our theorem falls apart in that case, and all this is not required if the D is finite.",
                    "label": 0
                },
                {
                    "sent": "Of course, then you can use any kernel you want.",
                    "label": 0
                },
                {
                    "sent": "You can use any Gaussian prior you want.",
                    "label": 0
                },
                {
                    "sent": "And note that this implies that actually there's many algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "GP, UCB algorithm with many or most stationary kernels people use in practice.",
                    "label": 0
                },
                {
                    "sent": "We have this no regret statement in probability.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let me emphasis what this means so.",
                    "label": 0
                },
                {
                    "sent": "We have a few different rules for sampling this function right as the experiment design rule, greedy approximation of the maximum information gain.",
                    "label": 1
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "Because you can easily show that if you always maximize the predicted variance in every step, that is exactly the same as if you maximize the information gain by adding one more point.",
                    "label": 0
                },
                {
                    "sent": "That is very.",
                    "label": 0
                },
                {
                    "sent": "That's kind of the lock of that somehow.",
                    "label": 0
                },
                {
                    "sent": "That's kind of easy.",
                    "label": 0
                },
                {
                    "sent": "So what that means is that there is a rule which chooses the points.",
                    "label": 0
                },
                {
                    "sent": "So to maximize the disk, up there to approximate it in a greedy way.",
                    "label": 0
                },
                {
                    "sent": "And let's just call this election by A and so that's the one that the greedy rule would get you if you ran it.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But that is not a good way of doing things.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can do way better than that by basically concentrating your sampling to using this upper confidence idea to actually not just globally explore the function, but to sample it where it really matters here.",
                    "label": 0
                },
                {
                    "sent": "And I mean, you would certainly appreciate what I'm saying by just thinking about the fact that the Ed rule it doesn't even depend on the samples that you get along the way, you could just compute it beforehand.",
                    "label": 0
                },
                {
                    "sent": "Because it doesn't depend on the targets that you get.",
                    "label": 0
                },
                {
                    "sent": "So it's probably not a good way to do the bandit optimization using the Ed rule, but nevertheless the D rule actually tells you how good that.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "CPU CP can be because it's the maximum information gain that controls the rate for this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So it's a really funny kind of this rule really tells you how good this rule can be in the, at least if you use this analysis.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then you say OK, so how do I get this one?",
                    "label": 1
                },
                {
                    "sent": "Because it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a combinatorial quantity, so greedy I don't know, you know, maybe you really don't.",
                    "label": 0
                },
                {
                    "sent": "Don't get it at all.",
                    "label": 0
                },
                {
                    "sent": "But The funny thing is that this is.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So submodular function, so you can actually guarantee that if you do the greedy optimization of this, end and you don't, you get there up to a small constant.",
                    "label": 0
                },
                {
                    "sent": "So this is approximation guarantee because it's submodular.",
                    "label": 0
                },
                {
                    "sent": "The greedy rule is actually getting you close to the true value appear.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now at this point I think it becomes really clear.",
                    "label": 0
                },
                {
                    "sent": "The whole point of the whole talk, because now we're sitting there.",
                    "label": 0
                },
                {
                    "sent": "We have this Thirimanne.",
                    "label": 0
                },
                {
                    "sent": "We submit it to somewhere, and then the reviewers say, Oh well, that's fine.",
                    "label": 0
                },
                {
                    "sent": "But I mean, how am I ever going to, you know, evaluate this bound.",
                    "label": 0
                },
                {
                    "sent": "I want to run this UCB.",
                    "label": 0
                },
                {
                    "sent": "Here's my kernel.",
                    "label": 0
                },
                {
                    "sent": "Here's my input distribution, and then we tell the reviewer, well, you know, that's no problem.",
                    "label": 0
                },
                {
                    "sent": "You just run the Ed rule with this kernel and with this D and then you tabulate all these gamma ends here and then you can tell the user afterwards you've done that.",
                    "label": 0
                },
                {
                    "sent": "You can tell the user how good is going to be, but that doesn't sound so good, right?",
                    "label": 0
                },
                {
                    "sent": "You would want to know how good it does for this kernel without doing all this work.",
                    "label": 0
                },
                {
                    "sent": "And that's exactly what I mean.",
                    "label": 0
                },
                {
                    "sent": "Is that sometimes data dependent Ness is not quite what you want.",
                    "label": 0
                },
                {
                    "sent": "At least you want to do a little bit more work to get rid of this in orders trouble that you really have abound here, but it depends on your data in a sense, and you have to go away in compute it, you really want to finish this business and you want to say how big can it be for kernel K and data set D?",
                    "label": 1
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh yeah, it's yeah it's not.",
                    "label": 0
                },
                {
                    "sent": "It's probably bad to call this data dependent, but let's call it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're right actually, so it's probably, but it's something that you would want to know how big it is, so it's otherwise you would have to go away and compute it by running this CD rule.",
                    "label": 0
                },
                {
                    "sent": "Well, you can.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's half of our theory.",
                    "label": 0
                },
                {
                    "sent": "OK, but I mean it says so.",
                    "label": 0
                },
                {
                    "sent": "So you probably agree that that's probably fine, but you would still want to know you know how big it is, because it sounds like unfinished somehow.",
                    "label": 0
                },
                {
                    "sent": "Well, at least an upper bound.",
                    "label": 0
                },
                {
                    "sent": "It's a closed formula.",
                    "label": 0
                },
                {
                    "sent": "I mean actually, you know that what we get in the paper and the second part is it cannot be as close as what you would get by run the greedy rule, because snap on that.",
                    "label": 0
                },
                {
                    "sent": "But it maybe it's tight.",
                    "label": 0
                },
                {
                    "sent": "I mean, you're right.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a nice result already.",
                    "label": 0
                },
                {
                    "sent": "But now let's make it even.",
                    "label": 0
                },
                {
                    "sent": "I mean, I want to motivate to you why you would want to know how big this this term is.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's going to use the paper once more.",
                    "label": 0
                },
                {
                    "sent": "So very roughly, and this is actually something I think is really nice, but it could also be improved, so that's what I'm really hoping for inputs here.",
                    "label": 0
                },
                {
                    "sent": "So how do we get around on this thing?",
                    "label": 0
                },
                {
                    "sent": "So first is that we pull a discretisation of the D. So this is a finite set and the till their quantity is basically the same thing as the gamma.",
                    "label": 0
                },
                {
                    "sent": "But it's using the finite set instead of the full set and this is a nested set of sequence sets and it always is this big.",
                    "label": 0
                },
                {
                    "sent": "Let's just you know how big is this?",
                    "label": 0
                },
                {
                    "sent": "Let's let's do it later and then we use.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mr. Submodularity, because you know what is this?",
                    "label": 0
                },
                {
                    "sent": "It's a combinatorial quantity, I don't know, but if it's a modular I can run the greedy rule and maybe I can say something about it.",
                    "label": 0
                },
                {
                    "sent": "So this is not a submodular approximation and this is a small constant and now these subsets that greedy rule selects they have to be in the in the finite set.",
                    "label": 0
                },
                {
                    "sent": "And you know, because it's nested.",
                    "label": 0
                },
                {
                    "sent": "It's OK, right?",
                    "label": 0
                },
                {
                    "sent": "So if you select it here and then, this set gets bigger, but the old things are still in there.",
                    "label": 0
                },
                {
                    "sent": "So so This is why it's nested and.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How this is kind of one of the crucial steps here.",
                    "label": 0
                },
                {
                    "sent": "So now is kind of because it's finite decisions at finite number of possible arms, you actually can look at it as a linear Gaussian model.",
                    "label": 0
                },
                {
                    "sent": "It's just the model over one vector here, and it has this prior with this kernel matrix.",
                    "label": 0
                },
                {
                    "sent": "This is not like impact base, where this would be the kernel matrix of the data, but it's the kernel matrix on the discretisation set and then you can say that.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you play this game in order to get the gun motility, you would play the single arms to be the Delta functions that basically sample this F at a certain point.",
                    "label": 0
                },
                {
                    "sent": "So these are unit norm vectors and you can relax that by saying, well, let's just use instead of deltas.",
                    "label": 0
                },
                {
                    "sent": "Let's use arbitrary unit norm vectors that are sampled here and then you use this Rayleigh Ritz idea and say, well, these.",
                    "label": 0
                },
                {
                    "sent": "Best unit norm vectors I could play.",
                    "label": 0
                },
                {
                    "sent": "They have to be eigenvectors and that's how you get all this thing.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can discuss this offline, but that's how you get all this expression to something that you can really say something about.",
                    "label": 0
                },
                {
                    "sent": "Now here you have the eigenvalues of this big matrix here and here you have the allocations or how many times do I sample eigenvalue number I?",
                    "label": 0
                },
                {
                    "sent": "And this is the empirical spectrum.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so that's how we bound this.",
                    "label": 0
                },
                {
                    "sent": "And then the rest is kind of almost similar to what to what we did for the expected value, because now you have something that depends on some empirical eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "You split the sum, you bound details and then you use the operator spectrum asymptotic's.",
                    "label": 0
                },
                {
                    "sent": "And now I guess also a crucial point is how do you choose this discretization?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we use the probabilistic method by basically arguing if you sample uniformly from D, you can compute a sufficient size for which certain properties have to be true for a discretization like the nearest neighbour size is small enough and then also this inequality holds with high enough probability, which again comes from short, Taylor and Williams.",
                    "label": 0
                },
                {
                    "sent": "So because we have to make that step again from the empirical to the process eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "And then the rest goes through.",
                    "label": 0
                },
                {
                    "sent": "Now, how big is it?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So The funny thing is actually matches the result for the expected value in some cases.",
                    "label": 0
                },
                {
                    "sent": "For the linear case it matches that.",
                    "label": 0
                },
                {
                    "sent": "That's actually you don't need all this analysis for the linear case, because that's kind of easy.",
                    "label": 0
                },
                {
                    "sent": "But for the also for the Gaussian kernel it matches it.",
                    "label": 0
                },
                {
                    "sent": "So actually this is not only the expense.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That value is small for the Gaussian kernel, but the worst the worst allocation or the maximum allocation is also just about that big.",
                    "label": 0
                },
                {
                    "sent": "And then, uh.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function for the maternal.",
                    "label": 0
                },
                {
                    "sent": "It doesn't match it, but that's I think could still be improved.",
                    "label": 0
                },
                {
                    "sent": "So we have this result here and it looks the same as what we had in expected case.",
                    "label": 0
                },
                {
                    "sent": "But you have instead of D and expected case you have D * D + 1 in the.",
                    "label": 0
                },
                {
                    "sent": "In the maximum case.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's actually that's it for my talk.",
                    "label": 0
                },
                {
                    "sent": "So I think based in theorems are property of them is that they are tight because they depend on things like the model and they also depend on the data and the data dependence.",
                    "label": 0
                },
                {
                    "sent": "In some cases at least, it calls for some further work.",
                    "label": 0
                },
                {
                    "sent": "So to say, if I know my model but I don't want to get rid of the fluctuations over the data.",
                    "label": 0
                },
                {
                    "sent": "So how much do I have to expect?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's the key quantity that comes up.",
                    "label": 0
                },
                {
                    "sent": "If you do this in the GP setting, is the information gain for GP for examples, and really it controls how big the relative entropy term is.",
                    "label": 1
                },
                {
                    "sent": "It controls the information consistency rates and it also if you take the maximum over that.",
                    "label": 1
                },
                {
                    "sent": "It also controls the dis regret for the UCP.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can bound it by looking at the kernel operator spectrum.",
                    "label": 0
                },
                {
                    "sent": "And that's one thing I really want to.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find out because by doing that you see once more that what really is in kernel methods is not that their infinite dimensional or finite dimensional, but what matters is what the kernel is.",
                    "label": 0
                },
                {
                    "sent": "So what the kernel is depends determines what the capacities of the method.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the result that we get for the Gaussian kernel, it almost doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's almost no difference to the linear case.",
                    "label": 0
                },
                {
                    "sent": "But if you look at what.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gaussian versus the maternal kernel does.",
                    "label": 0
                },
                {
                    "sent": "There's a huge difference, so these are two infinite dimensional cases with arc S and so on.",
                    "label": 0
                },
                {
                    "sent": "But actually this Gaussian case is way closer to the linear method in terms of at least in terms of these theorems.",
                    "label": 0
                },
                {
                    "sent": "Here then it would actually be to the maternal care case and also what is real.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not right is the dependence on the input distribution.",
                    "label": 0
                },
                {
                    "sent": "For example, what happens if you ever heavy tailed input distribution and abundant support is not there?",
                    "label": 0
                },
                {
                    "sent": "So what can happen to this term?",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's something I really think one could improve.",
                    "label": 0
                },
                {
                    "sent": "So the maximum information gain.",
                    "label": 1
                },
                {
                    "sent": "I don't think that the discretization that we choose is in any way optimal.",
                    "label": 0
                },
                {
                    "sent": "So for example it should depend on the kernel, but it doesn't.",
                    "label": 1
                },
                {
                    "sent": "What we do right now.",
                    "label": 1
                },
                {
                    "sent": "So I really hope maybe somebody of you has a better idea.",
                    "label": 0
                },
                {
                    "sent": "And also this gap in the result for the modern kernel that really shouldn't be there, or at least one should explain it.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also the technical condition.",
                    "label": 0
                },
                {
                    "sent": "I really would like to either explain why it's there or say, well, it probably shouldn't really be there if you want to explain why it's there, you would have to give some counterexample that you can get such regret.",
                    "label": 0
                },
                {
                    "sent": "For example with their own standalone back kernel.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}