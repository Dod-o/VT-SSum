{
    "id": "ztlqemypviycluayneevcwwhw2yqoa73",
    "title": "Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation",
    "info": {
        "author": [
            "Sina Honari, Montreal Institute for Learning Algorithms (MILA), University of Montreal"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_honari_recombinator_networks/",
    "segmentation": [
        [
            "So as I don't mention my name is Cinnamon Arianne?",
            "I'm presenting recombinant or networks.",
            "This is joint work with Jason Musinski, Pascal once on an Christopher Pal, and it was done in Miller.",
            "And it was also presented in CPR 2016.",
            "So the."
        ],
        [
            "Problem with the address here is landmark or keep on detection.",
            "So we have an input phase image and we want to localize important points on image such as eye centers.",
            "Know Steve and Mouse corner.",
            "So in such problem we need to preserve the information on where these key points came from.",
            "An use that later for accurate prediction."
        ],
        [
            "So."
        ],
        [
            "What happens mostly in covenant?",
            "We have alternating convolution, an Max pooling layers.",
            "So if we only use convolutional layers we end up with features that you see on the top, so we keep a special information on the face.",
            "So we have most of the information on the facial components, but we end up with lots of false positive.",
            "So for example here you can see that all the white regions have high probability and this is the feature that we get.",
            "For example, for the left eye.",
            "So if we use that directly for prediction, we end up with wrong prediction.",
            "For example, you might end up with the other eye as the.",
            "As the best location, on the other hand, if we use Max pooling layers, so we end up with robust features as you see in the bottom.",
            "But we also can't localize the features accurately, so that means that we roughly know where is the key point.",
            "But we don't.",
            "We have lost already information on where those key points came from, because we use Max pooling layers and Max pooling.",
            "Basically lose that sort of information.",
            "So the challenge here is that is there a way that we can take advantage of robust features and at the same time keep the spatial information that we have over the image?",
            "So."
        ],
        [
            "There are a couple of models that address this issue, and here I review the most important one which is called which we call submission based model.",
            "So here is a very brief overview of that.",
            "So even if you have an input image that you see on the left, if you only apply a few convolutional layers we end up with features that I showed in the previous slide, so they maintain the information over the whole image on where those features came.",
            "But we have a lot of false positives.",
            "Now if we add one pooling layer, soupir is pulling C is convolution.",
            "And use up sampling.",
            "So if we add one pooling layer, we go to a lower resolution.",
            "We add we have a few convolutional layers to do a bit of nonlinearity, and finally we upsample the features back to the images solution.",
            "Then we end up with better features that we can sum with the previous features.",
            "And also here there's a bit of notation that we use which you call a branch and these refer to the kind of couple of convolutional layers that we use from the left to the right that maintains the resolution but does a bit of nonlinearity so we can repeat this process several more times so we can add more pooling layers.",
            "We need to lower resolution, do it up.",
            "Convolutional layers and finally assemble the features an aggregate those features with the features that we got before.",
            "For example, here we have four benches, so all of them are sampled.",
            "The features of the image resolution and we get a weighted average of all those features.",
            "So here what's happening is that we take advantage of robust pull features at the very top, but we also get accurate positional information from the very bottom.",
            "By taking these kind of weighted average, we take the advantage of both words, and there are a couple of models in this line of research.",
            "For example, FCN fully convolutional networks.",
            "And Hyper column that were presented in three 2015.",
            "So we refer to this line of models as some later submission based models."
        ],
        [
            "So here are kind of features that you get from these models.",
            "So if we use the courses branches we can see that they roughly know where is the key point.",
            "For example, you know roughly where is the left eye or where is the right eye and but the problem here is that if you use that for position as you see in the softmax, Maps on the right, you can see that the white region correctly corresponds to the true location and the true location here is indicated by the Green Cross, but we don't know the exact position of it.",
            "However, as we go from the cursor benches to finer branches at the bottom, you can see that we have more and more information on the official components, but we end up with bad predictions.",
            "So if you see the kind of post softmax Maps on, the high likely locations as we go down, this doesn't correspond to the Green Dot because we have a lot of false positives, so we cannot use that directly for prediction.",
            "So if we use some of all those branches as you see in the last row, we end up with some robust features.",
            "So the final branches here kind of add more information to the cursor branches and we can use that for more accurate prediction.",
            "And here you can see that the post office Max of the last row, the green, which is the true location, matches with the red, which is the models or the most likely prediction.",
            "So by using this kind of summations we end up with better features and those weather features can basically localize the key points properly and here."
        ],
        [
            "Another example, so you see the same trend.",
            "The course branches basically have those kind of course information, but they don't know the exact location.",
            "And as we go to the bottom we have more information on the facial components, but we also have false positives.",
            "So by taking summation of them we end up with better features."
        ],
        [
            "So here is a closer look as at the pre softmax Maps that we get for the left eye.",
            "So it kind of learns a kind of distribution over the left eye on where the key point is located."
        ],
        [
            "Now the model that we propose here, which we call the computer networks.",
            "The difference is that instead of upsampling the features at the end of each branch to the image resolution, we upsample the features to the resolution right before the pulling.",
            "For example, at the top, which is the courses branch, we have the features of size 10 by 10.",
            "We upsample to 20 by 20 and then we contacted them across the feature map dimension with the features right before the pulling.",
            "So for example, here is a sample that from 10 to 10 to 20 by 20 and contacted Amanda concatenation is done across the feature map dimension.",
            "For example, if we have.",
            "48 feature Maps at the top.",
            "Then we also have 48 at the bottom and then we end up in 96 feature Maps.",
            "So we repeat this process several times.",
            "K or should I should also mention that is concatenation.",
            "So we repeat this process several times for all the branches and we go all the way down to the finest branches at the bottom and you can see that at the bottom we don't have any pulling so we have all kind of pixel level accuracy or information.",
            "So the main advantage that we have here is that we have a kind of conditional computation, so the final branches at the bottom.",
            "Are conditioned on the cursor branches at the top, so we have that kind of information flow from the cursor branch are to the final branches and this information flow helps us when there is, for example, occlusion, the final branch branches at the top seed the occlusion if let's say left eye or the right eye is included by something and then they can pass that information all the way down to the final branches and the final branches for example, then knows that it shouldn't look locally, it should look more globally and basically for prediction, so this architecture.",
            "Leads to both the results and also faster converges.",
            "So."
        ],
        [
            "So here is a one to one kind of comparison of the two models.",
            "So the main difference here is that in the subnet model, basically all the branches are doing a kind of parallel or independent computation, while in the computer networks we have a kind of conditional information.",
            "So there is the information flow that is happening between different branches and the final branches at the bottom can kind of leverage the information that received from the course of branches at the top, so this helps them for more accurate prediction, and they can learn on their own, but sort of features they need from the top and then use that later on."
        ],
        [
            "So here is the kind of pre softmax Maps that we get from RCN compared to the summit model.",
            "So we end up with more or better features an on this examples.",
            "Both models do accurate prediction, so you can see that the red and green almost match one to one with each other."
        ],
        [
            "And here's a closer look at the pre softmax Maps for the left eye.",
            "So both model learn some self distribution over the left eye on where that should be over the whole image.",
            "But the person model slightly gets a better kind of feature Maps."
        ],
        [
            "So here I talk slightly about the experimental setup.",
            "So in the for training the model we use 10,000 training images.",
            "We did normal documentation like scaling, translation and rotation, and we evaluated on two datasets a FLW and afw, and all of them have five key points as you see here."
        ],
        [
            "And in terms of performance, so we improve the results compared to the standard model, we get better results, but most importantly we have faster convergence time, which means that we need lower turning time to converge to let these models converge.",
            "And we think that this is mostly due to the information flow between different branches."
        ],
        [
            "And here are some examples when we have difficult examples such as occlusion and high contrast.",
            "So both are seen on some other are doing a good job or send us a slightly better and both of them do much better compared to the previous set of the art model which was TCDCN.",
            "And you can see that here green is like the true location, red is the model prediction, and there's a yellow line that connects the two 2 dots."
        ],
        [
            "So in terms of comparison with previous model, we can improve the results both computers subnet and also compare to the previous models that we had on these two datasets that have five key points."
        ],
        [
            "Now I slightly talk about another data set which is 300 W and here we have 68 key points, so have a lot of key points on face contour and also on the mouse.",
            "And here the what they did for this.",
            "As I said, they merge a few other datasets and they have labeled them in order to end up with this data set and a lot of people use that for benchmarking the keypoint detection's."
        ],
        [
            "So when we trained our model and these datasets, we end up with some problem and that was noisy predictions.",
            "So you can see that here the red dots of the models prediction are a bit noisy.",
            "For example, on the first image for the mouse there off the true location of the mouse and for example on the second image you can see the face contour.",
            "It doesn't correspond to its mousse kind of contour of the face and you can also see a few other key points that are on the mouse and on the noise that are off the location.",
            "If we had proper distribution over the whole key points, the model shouldn't give us such predictions.",
            "So that means that there are still some unlikely distributions that the model thinks is possible, but if we had a proper prior, we wouldn't predict in these cases, or we wouldn't have such bad predictions.",
            "So in order to."
        ],
        [
            "Others this problem.",
            "We had denoising model in a convolutional setup.",
            "So what we did was that for example here we had 68 key points.",
            "We ended up with 68 One Hot feature Maps.",
            "The one Hot feature Maps is formed in a way that the true the location of the key point is non zero, everywhere else it's zero for half of the key points we use the true location for the other half digital.",
            "The location of the key point.",
            "So in this way we have a mixture of true and noisy keep on location and what we do is that we ask this model to reconstruct the location of the key points.",
            "So this model has to learn a prior over the distribution of the key points on how these key points are located and further coin their correlation and fix the noisy one to the correct."
        ],
        [
            "Nation.",
            "And at this time what we do is that we train their computer networks in dependently.",
            "We trained the denoising model also independently and then we take the hard Max One Hut prediction of the computer networks, pass that to the denoising model and then sum the pre softmax Maps together.",
            "So it looks as if it works as a multiplication of the two distribution where the denoising model gives us a prior and we can use that prior to fix the distribution that we got from the computer networks.",
            "So by using this project we can fix the noisy prediction that we have from the recombination networks."
        ],
        [
            "So here are some examples on how these models work.",
            "So in these examples you see like 2 images where one of them we have occlusion, another one.",
            "We have extreme expression.",
            "So in these examples RCN is doing a good job and that is for a lot of cases.",
            "In"
        ],
        [
            "Some other examples, we have noisy prediction by arson like in the first example.",
            "You can see that the face contour of red dots it's a bit noisy, so we should have a smooth kind of line which we don't have here or in the second image, which is a soldier for the eyebrow.",
            "We have, again noisy kind of dots and the last two images are.",
            "You also saw before, so the denoising model here basically fixes those noises in these examples, so it can get rid of those noises and improve the results."
        ],
        [
            "And finally, here are some examples where we have noisy prediction by the arson model.",
            "So the denoising model basically learns or predicts some plausable distribution over the key points, but they still it doesn't give us the key points that match properly to the images, and this is mostly due to the fact that the distribution was learned independently of the image, so it gives us some possible cases, but it doesn't match exactly with the image that is predicting, so there's still some room for improvement for improvement, as you can see here.",
            "Anne."
        ],
        [
            "And so we can put the other model.",
            "You can see that are seen on its own.",
            "Does a good job, but we get is still better results when we use the denoising model and we can improve using the dinners in model as well.",
            "Anne."
        ],
        [
            "That's all I want to talk about, so mostly here we have a course to find future allegation of the key points.",
            "So we use that on three facial keypoint datasets to five points and 168 key points.",
            "So these kind of RCN architecture helps us both to get better performance and faster convergence rate.",
            "And we also formulate denoising model in a convolution set up that we can use to kind of get rid of the noise that we have in the images."
        ],
        [
            "And that's all I want talk about.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I don't mention my name is Cinnamon Arianne?",
                    "label": 0
                },
                {
                    "sent": "I'm presenting recombinant or networks.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Jason Musinski, Pascal once on an Christopher Pal, and it was done in Miller.",
                    "label": 1
                },
                {
                    "sent": "And it was also presented in CPR 2016.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem with the address here is landmark or keep on detection.",
                    "label": 0
                },
                {
                    "sent": "So we have an input phase image and we want to localize important points on image such as eye centers.",
                    "label": 1
                },
                {
                    "sent": "Know Steve and Mouse corner.",
                    "label": 0
                },
                {
                    "sent": "So in such problem we need to preserve the information on where these key points came from.",
                    "label": 0
                },
                {
                    "sent": "An use that later for accurate prediction.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What happens mostly in covenant?",
                    "label": 0
                },
                {
                    "sent": "We have alternating convolution, an Max pooling layers.",
                    "label": 0
                },
                {
                    "sent": "So if we only use convolutional layers we end up with features that you see on the top, so we keep a special information on the face.",
                    "label": 0
                },
                {
                    "sent": "So we have most of the information on the facial components, but we end up with lots of false positive.",
                    "label": 0
                },
                {
                    "sent": "So for example here you can see that all the white regions have high probability and this is the feature that we get.",
                    "label": 0
                },
                {
                    "sent": "For example, for the left eye.",
                    "label": 0
                },
                {
                    "sent": "So if we use that directly for prediction, we end up with wrong prediction.",
                    "label": 0
                },
                {
                    "sent": "For example, you might end up with the other eye as the.",
                    "label": 0
                },
                {
                    "sent": "As the best location, on the other hand, if we use Max pooling layers, so we end up with robust features as you see in the bottom.",
                    "label": 0
                },
                {
                    "sent": "But we also can't localize the features accurately, so that means that we roughly know where is the key point.",
                    "label": 0
                },
                {
                    "sent": "But we don't.",
                    "label": 0
                },
                {
                    "sent": "We have lost already information on where those key points came from, because we use Max pooling layers and Max pooling.",
                    "label": 0
                },
                {
                    "sent": "Basically lose that sort of information.",
                    "label": 0
                },
                {
                    "sent": "So the challenge here is that is there a way that we can take advantage of robust features and at the same time keep the spatial information that we have over the image?",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are a couple of models that address this issue, and here I review the most important one which is called which we call submission based model.",
                    "label": 0
                },
                {
                    "sent": "So here is a very brief overview of that.",
                    "label": 0
                },
                {
                    "sent": "So even if you have an input image that you see on the left, if you only apply a few convolutional layers we end up with features that I showed in the previous slide, so they maintain the information over the whole image on where those features came.",
                    "label": 0
                },
                {
                    "sent": "But we have a lot of false positives.",
                    "label": 0
                },
                {
                    "sent": "Now if we add one pooling layer, soupir is pulling C is convolution.",
                    "label": 1
                },
                {
                    "sent": "And use up sampling.",
                    "label": 0
                },
                {
                    "sent": "So if we add one pooling layer, we go to a lower resolution.",
                    "label": 0
                },
                {
                    "sent": "We add we have a few convolutional layers to do a bit of nonlinearity, and finally we upsample the features back to the images solution.",
                    "label": 0
                },
                {
                    "sent": "Then we end up with better features that we can sum with the previous features.",
                    "label": 0
                },
                {
                    "sent": "And also here there's a bit of notation that we use which you call a branch and these refer to the kind of couple of convolutional layers that we use from the left to the right that maintains the resolution but does a bit of nonlinearity so we can repeat this process several more times so we can add more pooling layers.",
                    "label": 0
                },
                {
                    "sent": "We need to lower resolution, do it up.",
                    "label": 0
                },
                {
                    "sent": "Convolutional layers and finally assemble the features an aggregate those features with the features that we got before.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have four benches, so all of them are sampled.",
                    "label": 0
                },
                {
                    "sent": "The features of the image resolution and we get a weighted average of all those features.",
                    "label": 0
                },
                {
                    "sent": "So here what's happening is that we take advantage of robust pull features at the very top, but we also get accurate positional information from the very bottom.",
                    "label": 0
                },
                {
                    "sent": "By taking these kind of weighted average, we take the advantage of both words, and there are a couple of models in this line of research.",
                    "label": 0
                },
                {
                    "sent": "For example, FCN fully convolutional networks.",
                    "label": 1
                },
                {
                    "sent": "And Hyper column that were presented in three 2015.",
                    "label": 0
                },
                {
                    "sent": "So we refer to this line of models as some later submission based models.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are kind of features that you get from these models.",
                    "label": 0
                },
                {
                    "sent": "So if we use the courses branches we can see that they roughly know where is the key point.",
                    "label": 0
                },
                {
                    "sent": "For example, you know roughly where is the left eye or where is the right eye and but the problem here is that if you use that for position as you see in the softmax, Maps on the right, you can see that the white region correctly corresponds to the true location and the true location here is indicated by the Green Cross, but we don't know the exact position of it.",
                    "label": 0
                },
                {
                    "sent": "However, as we go from the cursor benches to finer branches at the bottom, you can see that we have more and more information on the official components, but we end up with bad predictions.",
                    "label": 0
                },
                {
                    "sent": "So if you see the kind of post softmax Maps on, the high likely locations as we go down, this doesn't correspond to the Green Dot because we have a lot of false positives, so we cannot use that directly for prediction.",
                    "label": 0
                },
                {
                    "sent": "So if we use some of all those branches as you see in the last row, we end up with some robust features.",
                    "label": 0
                },
                {
                    "sent": "So the final branches here kind of add more information to the cursor branches and we can use that for more accurate prediction.",
                    "label": 0
                },
                {
                    "sent": "And here you can see that the post office Max of the last row, the green, which is the true location, matches with the red, which is the models or the most likely prediction.",
                    "label": 0
                },
                {
                    "sent": "So by using this kind of summations we end up with better features and those weather features can basically localize the key points properly and here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example, so you see the same trend.",
                    "label": 0
                },
                {
                    "sent": "The course branches basically have those kind of course information, but they don't know the exact location.",
                    "label": 0
                },
                {
                    "sent": "And as we go to the bottom we have more information on the facial components, but we also have false positives.",
                    "label": 0
                },
                {
                    "sent": "So by taking summation of them we end up with better features.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is a closer look as at the pre softmax Maps that we get for the left eye.",
                    "label": 0
                },
                {
                    "sent": "So it kind of learns a kind of distribution over the left eye on where the key point is located.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the model that we propose here, which we call the computer networks.",
                    "label": 0
                },
                {
                    "sent": "The difference is that instead of upsampling the features at the end of each branch to the image resolution, we upsample the features to the resolution right before the pulling.",
                    "label": 0
                },
                {
                    "sent": "For example, at the top, which is the courses branch, we have the features of size 10 by 10.",
                    "label": 0
                },
                {
                    "sent": "We upsample to 20 by 20 and then we contacted them across the feature map dimension with the features right before the pulling.",
                    "label": 0
                },
                {
                    "sent": "So for example, here is a sample that from 10 to 10 to 20 by 20 and contacted Amanda concatenation is done across the feature map dimension.",
                    "label": 0
                },
                {
                    "sent": "For example, if we have.",
                    "label": 0
                },
                {
                    "sent": "48 feature Maps at the top.",
                    "label": 0
                },
                {
                    "sent": "Then we also have 48 at the bottom and then we end up in 96 feature Maps.",
                    "label": 0
                },
                {
                    "sent": "So we repeat this process several times.",
                    "label": 0
                },
                {
                    "sent": "K or should I should also mention that is concatenation.",
                    "label": 0
                },
                {
                    "sent": "So we repeat this process several times for all the branches and we go all the way down to the finest branches at the bottom and you can see that at the bottom we don't have any pulling so we have all kind of pixel level accuracy or information.",
                    "label": 0
                },
                {
                    "sent": "So the main advantage that we have here is that we have a kind of conditional computation, so the final branches at the bottom.",
                    "label": 0
                },
                {
                    "sent": "Are conditioned on the cursor branches at the top, so we have that kind of information flow from the cursor branch are to the final branches and this information flow helps us when there is, for example, occlusion, the final branch branches at the top seed the occlusion if let's say left eye or the right eye is included by something and then they can pass that information all the way down to the final branches and the final branches for example, then knows that it shouldn't look locally, it should look more globally and basically for prediction, so this architecture.",
                    "label": 0
                },
                {
                    "sent": "Leads to both the results and also faster converges.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is a one to one kind of comparison of the two models.",
                    "label": 0
                },
                {
                    "sent": "So the main difference here is that in the subnet model, basically all the branches are doing a kind of parallel or independent computation, while in the computer networks we have a kind of conditional information.",
                    "label": 0
                },
                {
                    "sent": "So there is the information flow that is happening between different branches and the final branches at the bottom can kind of leverage the information that received from the course of branches at the top, so this helps them for more accurate prediction, and they can learn on their own, but sort of features they need from the top and then use that later on.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the kind of pre softmax Maps that we get from RCN compared to the summit model.",
                    "label": 0
                },
                {
                    "sent": "So we end up with more or better features an on this examples.",
                    "label": 0
                },
                {
                    "sent": "Both models do accurate prediction, so you can see that the red and green almost match one to one with each other.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's a closer look at the pre softmax Maps for the left eye.",
                    "label": 0
                },
                {
                    "sent": "So both model learn some self distribution over the left eye on where that should be over the whole image.",
                    "label": 0
                },
                {
                    "sent": "But the person model slightly gets a better kind of feature Maps.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here I talk slightly about the experimental setup.",
                    "label": 0
                },
                {
                    "sent": "So in the for training the model we use 10,000 training images.",
                    "label": 1
                },
                {
                    "sent": "We did normal documentation like scaling, translation and rotation, and we evaluated on two datasets a FLW and afw, and all of them have five key points as you see here.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in terms of performance, so we improve the results compared to the standard model, we get better results, but most importantly we have faster convergence time, which means that we need lower turning time to converge to let these models converge.",
                    "label": 0
                },
                {
                    "sent": "And we think that this is mostly due to the information flow between different branches.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are some examples when we have difficult examples such as occlusion and high contrast.",
                    "label": 0
                },
                {
                    "sent": "So both are seen on some other are doing a good job or send us a slightly better and both of them do much better compared to the previous set of the art model which was TCDCN.",
                    "label": 0
                },
                {
                    "sent": "And you can see that here green is like the true location, red is the model prediction, and there's a yellow line that connects the two 2 dots.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in terms of comparison with previous model, we can improve the results both computers subnet and also compare to the previous models that we had on these two datasets that have five key points.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I slightly talk about another data set which is 300 W and here we have 68 key points, so have a lot of key points on face contour and also on the mouse.",
                    "label": 0
                },
                {
                    "sent": "And here the what they did for this.",
                    "label": 0
                },
                {
                    "sent": "As I said, they merge a few other datasets and they have labeled them in order to end up with this data set and a lot of people use that for benchmarking the keypoint detection's.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we trained our model and these datasets, we end up with some problem and that was noisy predictions.",
                    "label": 0
                },
                {
                    "sent": "So you can see that here the red dots of the models prediction are a bit noisy.",
                    "label": 0
                },
                {
                    "sent": "For example, on the first image for the mouse there off the true location of the mouse and for example on the second image you can see the face contour.",
                    "label": 0
                },
                {
                    "sent": "It doesn't correspond to its mousse kind of contour of the face and you can also see a few other key points that are on the mouse and on the noise that are off the location.",
                    "label": 0
                },
                {
                    "sent": "If we had proper distribution over the whole key points, the model shouldn't give us such predictions.",
                    "label": 0
                },
                {
                    "sent": "So that means that there are still some unlikely distributions that the model thinks is possible, but if we had a proper prior, we wouldn't predict in these cases, or we wouldn't have such bad predictions.",
                    "label": 0
                },
                {
                    "sent": "So in order to.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Others this problem.",
                    "label": 0
                },
                {
                    "sent": "We had denoising model in a convolutional setup.",
                    "label": 1
                },
                {
                    "sent": "So what we did was that for example here we had 68 key points.",
                    "label": 0
                },
                {
                    "sent": "We ended up with 68 One Hot feature Maps.",
                    "label": 0
                },
                {
                    "sent": "The one Hot feature Maps is formed in a way that the true the location of the key point is non zero, everywhere else it's zero for half of the key points we use the true location for the other half digital.",
                    "label": 0
                },
                {
                    "sent": "The location of the key point.",
                    "label": 0
                },
                {
                    "sent": "So in this way we have a mixture of true and noisy keep on location and what we do is that we ask this model to reconstruct the location of the key points.",
                    "label": 1
                },
                {
                    "sent": "So this model has to learn a prior over the distribution of the key points on how these key points are located and further coin their correlation and fix the noisy one to the correct.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation.",
                    "label": 0
                },
                {
                    "sent": "And at this time what we do is that we train their computer networks in dependently.",
                    "label": 0
                },
                {
                    "sent": "We trained the denoising model also independently and then we take the hard Max One Hut prediction of the computer networks, pass that to the denoising model and then sum the pre softmax Maps together.",
                    "label": 1
                },
                {
                    "sent": "So it looks as if it works as a multiplication of the two distribution where the denoising model gives us a prior and we can use that prior to fix the distribution that we got from the computer networks.",
                    "label": 0
                },
                {
                    "sent": "So by using this project we can fix the noisy prediction that we have from the recombination networks.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some examples on how these models work.",
                    "label": 0
                },
                {
                    "sent": "So in these examples you see like 2 images where one of them we have occlusion, another one.",
                    "label": 0
                },
                {
                    "sent": "We have extreme expression.",
                    "label": 0
                },
                {
                    "sent": "So in these examples RCN is doing a good job and that is for a lot of cases.",
                    "label": 0
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some other examples, we have noisy prediction by arson like in the first example.",
                    "label": 0
                },
                {
                    "sent": "You can see that the face contour of red dots it's a bit noisy, so we should have a smooth kind of line which we don't have here or in the second image, which is a soldier for the eyebrow.",
                    "label": 0
                },
                {
                    "sent": "We have, again noisy kind of dots and the last two images are.",
                    "label": 0
                },
                {
                    "sent": "You also saw before, so the denoising model here basically fixes those noises in these examples, so it can get rid of those noises and improve the results.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, here are some examples where we have noisy prediction by the arson model.",
                    "label": 0
                },
                {
                    "sent": "So the denoising model basically learns or predicts some plausable distribution over the key points, but they still it doesn't give us the key points that match properly to the images, and this is mostly due to the fact that the distribution was learned independently of the image, so it gives us some possible cases, but it doesn't match exactly with the image that is predicting, so there's still some room for improvement for improvement, as you can see here.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we can put the other model.",
                    "label": 0
                },
                {
                    "sent": "You can see that are seen on its own.",
                    "label": 0
                },
                {
                    "sent": "Does a good job, but we get is still better results when we use the denoising model and we can improve using the dinners in model as well.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all I want to talk about, so mostly here we have a course to find future allegation of the key points.",
                    "label": 0
                },
                {
                    "sent": "So we use that on three facial keypoint datasets to five points and 168 key points.",
                    "label": 0
                },
                {
                    "sent": "So these kind of RCN architecture helps us both to get better performance and faster convergence rate.",
                    "label": 0
                },
                {
                    "sent": "And we also formulate denoising model in a convolution set up that we can use to kind of get rid of the noise that we have in the images.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's all I want talk about.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}