{
    "id": "6st3pnvo6o3xjk2lvyzqez62i7xv4lji",
    "title": "Mutual Cuts in Graphs: Learning in Bioinformatics",
    "info": {
        "author": [
            "Kristiaan Pelckmans, Department of Information Technology, Uppsala University"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2006",
        "category": [
            "Top->Computer Science->Bioinformatics"
        ]
    },
    "url": "http://videolectures.net/learning06_pelckmans_lb/",
    "segmentation": [
        [
            "So I'm from Belgium, from living and at this joint work with the professor here on Circus and back to work.",
            "So the title is the changed with respect to the program, so it's predicted mutual clustering, learning in bioinformatics and two parts here like the first is predictive mutual clustering and we propose it as a kind of new learning task which is somewhere between classification and clustering and be motivated from the context of bioinformatics."
        ],
        [
            "So first I won't like elaborate and give some intuition about the learning task, and I invite everybody to think of some solution there and then.",
            "I will also motivate from this informatics core.",
            "I will proceed with the transductive inference setting.",
            "Because it seems to be a good way to approach this learning problem and give some intuition about graph cuts and things.",
            "So I give it to example in the application by informatics."
        ],
        [
            "OK, so this is the most important slide, so if you feel sleepy, pay attention to this one and then go sleep for the restaurant of the presentation.",
            "So what's the task exactly?",
            "So we have like a sample here.",
            "Like usually two parts X at, but now is.",
            "It is not a label, not like plus one or minus one, but it's just an alternative to X, so it's.",
            "And we assume that idea simple term joint distribution.",
            "So that's effectively the setting we have, like a couple of objects somewhere in abstract space, and they have two representations.",
            "Which are which?",
            "Have the same value, so we can't say X is unable to that.",
            "We also cannot say that is labeled 2X, but we're after looking for, you know, correspondences between both representations.",
            "So the task we pose ourselves now is look for clustering of both in the representation X and in the representation set such that for all X's at which you sample from joint distribution, the memberships of the clusters will coincide.",
            "So an example gifts maybe some intuition there.",
            "So suppose we have like 15 samples.",
            "Something here in X which are both represented in exquisite and we have like we can cluster them in three clusters both in X and set.",
            "And now we look for isomorphism between the clusters.",
            "So meaning that if a point blank, for example to the green cluster here, then we can predict that point to belong to the green cluster instead, and this effectively gives us some knowledge about the alternative representation.",
            "So it's effectively clustering in the sense that we do not have labels in the classical sense and effectively.",
            "A prediction as a classification in the sense that we want to transducin knowledge from half 11 space to another.",
            "OK, so we're after.",
            "Instead of couples of clustering, so which is morphism?"
        ],
        [
            "So the main task is now to look for clusters such as the memberships go inside.",
            "As I said previously.",
            "So to make this more formal, we can define it in terms of risk functional, so which is typically in prediction setting, so the risk is like how many like for a fixed couple of clusters say CCX CK set.",
            "So how many times two samples coincides so effectively that.",
            "Explained to CX K then that the correspondence that should belong to the alternative cluster inset.",
            "So in the losses of course translates a factor.",
            "There should be the same, so one one is OK, but 1001 is not OK.",
            "So and then actually state the expectation of the distribution function and we want to have this clustering hold over all clusters which we propose and this kind of different with the classical.",
            "Prediction settings as we take the overall case, so which corresponds effectively with the supremum of the complete hypothesis space, and this is something which popups in the classical learning T. When you do this optimization thing and when you have like minimal risk.",
            "But now we want to have the all you know couples all hypothesis to have this property.",
            "Without saying OK, we're off to this hypothesis, but we want to have very such that we can say if we have a new point."
        ],
        [
            "For example, here, then the corresponding guy will belong to that, but we don't know for new point to which cluster it will be long before hand.",
            "So we have to have this."
        ],
        [
            "Premium.",
            "Of course, is the actual hitscan.",
            "You can come up with, like the same guy, but empirically, so it's the expectation replaced by some operator.",
            "OK, and this is basically domain setting.",
            "The main idea of the this paper.",
            "So if you have like this memberships which which correspond in both representations, then we can do predictions also of the X in the desert.",
            "If the classes are effectively concentrated, meaning that if we know some point will belong to a cluster, then we also know that you know prediction will be not too different from the other members of the cluster.",
            "And maybe a final remark is that we have of course a tradeoff between large clusters.",
            "So if you have like one big cluster and the complete data set both in X and that corresponds, then of course we have this property that the memberships transit because you have only one one always 1 one.",
            "But this is not very informative.",
            "I mean you cannot say too much about this very large clusters, so we're after little smaller clusters which say effectively something if we know that it belongs to this cluster, but it's more difficult to have this membership property to hold."
        ],
        [
            "OK, and then I give a motivation.",
            "How did we come to this ID where we were working in the setting of bioinformatics?",
            "Very of course genes and genes occur in many representations and OK, the classical approaches to data Fusion in the sense so we still offer clustering.",
            "But now we want to fuse different representation to one global clustering and but this is somewhat different in that we say OK, But if you have multiple sources there's an opportunity, namely this transaction prediction.",
            "Property.",
            "So in line bioinformatics, because you have typically much uncertainty on your data, so it has for example in micro race I mean the uncertainty is quite substantial and also in text based data and uncertainty in data is something which can be represented quite accurately using such memberships.",
            "And if you talk about sets, memberships, people, I mean you should think about clustering, which is basically a set membership.",
            "And the nice thing is that you if you have like this this framework then you can come up with a procedure to fill in missing information.",
            "So suppose you have sample X of an object, but you don't have to representation instead, so now it becomes possible to have some qualitative feeling of the question mark here.",
            "And it's also in both directions at the same time, so it's quite quite important X?",
            "And?",
            "As it can be filled in so and this follows from the.",
            "The symmetric nature of this prediction.",
            "The goal we set at the beginning so it also gives a very precise goal on clustering, so it's like incense, verifiable or first falsifiable depending on your philosophy.",
            "And this is quite important.",
            "I was at least two workshops on the theoretical foundations of clustering and one of the main outcomes was OK.",
            "There are as many clustering goals as applications of clustering.",
            "But for example you have like clustering based on vector quantization, but other application asks something like clustering based on looking for the maximal densities.",
            "So there are different goals but a clear taxonomy saying OK in this case you should do that.",
            "In this case you should do that.",
            "It's all still lucky and also very many missing.",
            "I mean, it's not clear which kind of clustering goals are there, so I just say OK, this is 1 size code which you can define any way of.",
            "Prediction.",
            "Pacific application we are after.",
            "So as I say by Infomatics, you're talking mostly about jeans.",
            "So we have like an abstract space of all genes, but they can be represented are expressed using microarrays, but they also can be expressed using scientific literature, which is a kind of orthogonal representation.",
            "But then you can ask yourself, OK, what are the correspondences between these two representations?",
            "OK, this was the application.",
            "We're working a tiny bit with.",
            "But then some people came and say OK, we had some discussion and they say OK, but that's nice because we have also this problem of.",
            "Like my crazy experiments in the setting of like yeast Organism or like plants and we have also marker is based on human tissues or I mean on other organisms.",
            "And so the question here is OK which pop?",
            "This does correspond in both representations and can we use nodes which we ain't in used microarrays somehow in for human tissues?",
            "OK, that's about the learning setting.",
            "Maybe it's good point.",
            "Two to consider it somehow.",
            "But otherwise I can proceed next."
        ],
        [
            "OK, is a little bit more technical in the sense of OK. We talk now about predictive clustering.",
            "So effectively we want to have this like this couple of clusters which we call mutual clusters, by the way.",
            "So for prediction purposes.",
            "But it's still about clustering somehow, so but closely is a very difficult thing to have.",
            "Some analytical expressions for, so something which is more easy to work with this transductive inference.",
            "And then if I went over this slides then I will give you the intuition how to go from constructive inference to clusters.",
            "OK, so first, what's the goal of transductive inference?",
            "Well specifically for grass, because in this bioinformatics setting we have like a graph of jeans.",
            "I mean everything can be organized, typically in the graph.",
            "So what's the setting we have, like a fixed amount of nodes, say nodes?",
            "In our application is like engines and they are organized in one deterministic graphs AG with the nodes and edges.",
            "Which is symmetrical and there are no loops and everything is positive, so the very classical setting but important is that we observe like the complete graph.",
            "It's fixed before and so no random mechanism there.",
            "Now with each note you associate affixed label and so labor plus 1 -- 1 as in the classification setting.",
            "But we only observe like a part of the nodes, the label of the nodes.",
            "So for example we have 1000 cheese, but we observe only for 10 genes, whether they are plus or minus one.",
            "So what's the task?",
            "Well, that ask is to complete this node scale says something about the other labels.",
            "If you observe or written.",
            "And that's the transductive problem."
        ],
        [
            "OK, so now we developed account a framework for for doing this in the context of graphs, which is kind of a little bit different from the classical framework.",
            "So because why?",
            "Because we start with hypothesis, which is not like a model or a set of parameters, but which is just your labeling on your nodes.",
            "Because you have a fixed number of nodes, your hypothesis is determined.",
            "So in general, if you impose no prior knowledge, you have like the complete hypothesis set which is.",
            "All the set of all possible labels of the nodes.",
            "So basically this graph is much to what I mean.",
            "You have like 2 to the end possibilities.",
            "So what do we want to do?",
            "We want to restrict this hypothesis set by imposing prior knowledge, and this will proceed in next slide.",
            "But suppose we have a kind of nice restriction.",
            "We have like a hypothesis hypothesis H prime.",
            "Radical counting all these much lower than to the end.",
            "For example, fixed constants.",
            "And also we have observed like a few.",
            "I feel labels so.",
            "Now there was no random mechanism until now, but the choice which nodes we observe is supposed to be a random, so it's not like random sampling.",
            "The classical sense, but it's random sampling sampling without replacement.",
            "So formally, it's dysfunctional.",
            "Is this guy, so it says, OK, the hypothesis corresponds with the labels.",
            "So how many times it doesn't OK and we take the expectation, but there are no capitals here, so the expectation is over the choice of which you know node we take.",
            "So we in the case is biased or so star is like an IG ID choice of your initials and this kind of kind of the twist with classical learning like inductive schemes or something.",
            "So the empirical risk is of course you observe a certain set of nodes and what's the observed.",
            "You know, correspondence with the labels and your hypothesis."
        ],
        [
            "OK, and then we can just proceed through the classical thing and do a union bound over inequality.",
            "So normally we use headings inequality, but here it's pointed out that we should use surface inequality so at the end you arrive at this guy.",
            "So important here is that there are two terms.",
            "Basically this guy and here the size of the hypothesis set so effectively if the set of all hypothesis are possible labelings is.",
            "Really very small then this becomes quite tight and this is a correction factor which say if you observe like very many nodes of the N1 labels of the N1 then then also the bound becomes much tighter.",
            "So and this is new because I knew with respect to the classical hunting derivation.",
            "But what does it say?",
            "Effectively it says if you sample, you know nodes randomly in the same mechanism as we did on the training set, then this bound to hold.",
            "But our intuition is that the node should be right on the average, so effectively says that if we start off with sampling randomly nodes and labels, then we can say something about this guy which is just average greatness of the nodes.",
            "So the point is that this is very specific setting where you like uniform sampling without replacement."
        ],
        [
            "OK, as I point out pointed out in the previous slides, we have this hypothesis set which is had set of all possible labelings of the nodes.",
            "But this clearly much Dwight so we should have like kind of restriction of this hypothesis.",
            "So what can we do?",
            "Well, it was proposed to use like min cut criterion just to impose a restriction.",
            "So saying that OK if you note we label this nodes or plus one and this guys minus one.",
            "Then the cut is like the some of the edges which go from plus one to minus one.",
            "So this is very classical thing, well known in combinatorial optimization and leaning to the spectral relaxation and things.",
            "So this one thing you can do, you can say OK we consider all labelings which have like got which is smaller than a specified number.",
            "And this effectively restricts the set.",
            "But there's also some other things you can do is quite intuitive.",
            "It says that OK, suppose you have a rule, say like one years neighbor rule, then we should say OK.",
            "Consider only like the labelings such that the rule corresponds exactly with the labeling.",
            "So it means that if you have a one nearest neighbor then you look at the nearest neighbor and if this is plus one then the node of this effective who should also be plus one.",
            "So and that's this guy.",
            "So F VI is the rule deciding on OK, what's the exact level of the node and Qi is the label of the node itself, so there should be larger than zero saying stating that they should be the same.",
            "So and now remarked that if we take not the one nearest neighbor or genius there, but if it takes like a weighted neighborhood tool, then this first who will correspond in away with the second rule.",
            "So nearest neighborhood is just taking the average.",
            "Of the neighboring nodes are agents by their the rate of the rating of the edges, and we take the sign of them.",
            "And we have here like this quantity, which is called the merchant support vector machines, and we require that the margin will be large and zero, so this lies effectively relation between.",
            "OK, what's the model for us?",
            "Just kind of constraint the hypothesis set which should be restricted and with the previous guy with them in cut.",
            "So we go a little bit further than the blue.",
            "And shovel a paper on the topic.",
            "Of course you have all kinds of different constraints depending on your application, so people argued already for a few years that there should also be like a balancing constraint.",
            "We should have positive samples, negative samples, but I mean, maybe you require that you have like a low number of positive samples with respect to the negative samples, or the ratios are approximately approximately one or something.",
            "OK, so we have like a number of balancing constraint depending on your application and we can also impose fixed labelings so.",
            "We know from the beginning on that, for example, this gene as a plus one associated to it.",
            "And you can go further.",
            "Can go say OK, we have this literature on material optimization and many different concepts like Max cut like coloring theorems like matching theorems.",
            "And there will be used to restrict in fact this hypothesis this quite intuitively.",
            "But the next slide will show for example that cardinality is effectively restricted in the in the first setting.",
            "So the idea is if we impose enough regularization or problem knowledge on the hypothesis then this touches the statistical guarantee of the transductive inference.",
            "So do I speak clearly enough?",
            "Maybe I'll beat him.",
            "Yeah, sure.",
            "Not important topic because I mean.",
            "For the moment I just give the transductive inference context.",
            "Later on our extended a little bit to the case we have two graphs, which is the previous case, like the predictive clustering case and I will say what's the result there?",
            "No, I just start off with the definition of the problem because I thought that was most important for this learning conference and now the transitive inference gives like some some formal motivation of the clustering goal, so that's a little bit based where we start off.",
            "So, but it's an important topic, and I mean I hope this question will rise again so we can go further."
        ],
        [
            "OK, so here's the formal derivation.",
            "If you have like this, got Cardium if you say OK, all possible labels should be such that.",
            "The cut is lower than the specified value, so we start off OK by stating this hypothesis sets, so the cut is defined as the all the edges which unequal.",
            "But security is different from QJ, so conveniently this can be translated in terms of the Laplacian matrix.",
            "Well, it's not that difficult, but maybe it is too far to go too much in that important is that this this transition is also be used to derive the spectral clustering.",
            "Kind of algorithms.",
            "OK, so we have this set of constraints and then we relax a little bit.",
            "This set of constraints stating that Q is sign of new variable so but this new variable can be anything.",
            "So and then we just replace the queues by the West and then we state that OK this is just an egg value problem right?",
            "And we have just a sign of the vectors which is in the solution space.",
            "So H double prime is relaxation.",
            "Prime and H Double prime is like a signed version of the Eiger space.",
            "Determined by this parameter.",
            "So suppose alcohol exists only a few values, then the hypothesis space will be lowered and the signed version of the corresponding angle space.",
            "So and then you can come up of course with this hours inequality giving like a bound on the original hypothesis space."
        ],
        [
            "OK, and you are some thoughts about the connection between constructive influence and clustering, and I must state from the beginning that is really some ongoing work.",
            "I mean, as far as I know it's the connection is never made explicitly in terms of formulas, so I hope this will trigger someone to.",
            "You know, stating OK from my problem is that and I can plug it in this way.",
            "So what's the ID so we have like a set of hypothesis of different hypothesis.",
            "And now we associate with each hypothesis.",
            "So Q in our terminology, we associate with each one cluster.",
            "So if it's plus one, it indicates that this node belongs to the cluster.",
            "So effectively, if like as many clusters as hypothesis, so we can use the previous result in the cardinality of the hypothesis space to say OK, how many clusters do we have?",
            "OK, so this is an isomorphism between the cluster and the hypothesis space.",
            "Well, a common constraints of clustering is that clusters are disjunct in some ways, so that they do not overlap.",
            "So in this explicity it means that the Q's eyes are like this unit in some way, so meaning that they are exactly plus one in exactly 1 hypothesis, so it's an extra constraint, restrict your hypothesis space.",
            "So, but now we have made a connection between the hypothesis space and the clustering.",
            "In this setting clear.",
            "And the baseline idea is that we do not.",
            "Look for the optimal hypothesis as an SVM or I mean like in most learning machines, but we do.",
            "Examine the hypothesis space explicitly so we go over all different hypothesis to examine the clustering.",
            "So and that's the difference between inductive learning where you say OK, this is optimal one and we hope to have some properties on the optimal para meter sets of hypothesis.",
            "But in this case we just examined the hyperspace explicitly, we won't say.",
            "OK, this hypothesis correspond to this cluster just now, because this cluster means something.",
            "I mean, we just examine how.",
            "Examine it, I put a space after decently and important.",
            "Also is that we can use further domain knowledge to shape this hypothesis space.",
            "So for example here you have that I cannot overlap, but you have of course further restrictions.",
            "For example, you should say that a cluster is concentrated in some point.",
            "OK, it's an additional constraint which you can impose on your hypothesis space.",
            "OK head."
        ],
        [
            "I think I can skip the last point.",
            "So at this point I hope to make the connection between the first setting so the predictive mutual clustering where you have like this set of mutual clusters and various like this property.",
            "If point belongs to cluster in one, you know representation then it also belongs to another to the same.",
            "The corresponding cluster in the other representation and transactive settings so.",
            "Well, effectively, what's difference that you have two graphs?",
            "Of course in OK, they are also fully observed, so now you have like just acts just that.",
            "So now exit are not a metric space.",
            "Or as in our beginning, but they are like embedding in the graph.",
            "There are like the edges of a graph.",
            "OK, what can we do?",
            "For example, we can say OK we have restriction in terms of model so that the labeling should correspond with the kind of model applied on the hypothesis on the labeling.",
            "So we can do the same.",
            "But now we can impose the model on both graphs similar at the same time.",
            "So for example we can say, OK, you know the margin should be larger than the constant vote in the first graph in the second graph.",
            "And now we made the had the transition between the original setting, namely the predictive mutual clustering in the transductive setting.",
            "Does this make sense?",
            "Yeah.",
            "OK, now we remarked OK, this is very.",
            "I mean it looks like a nice idea, but OK.",
            "It seems very difficult to work with because it's not.",
            "It's very common tutorial in nature and OK, there is no clear way to proceed to, you know.",
            "August."
        ],
        [
            "Or something.",
            "So what do we do?",
            "We have two approaches and the first one is we take.",
            "Not like merges should be satisfied for both points at the same time, but we say we have like a cut.",
            "And we have like some other cut sandwich should be small and see and we can proceed in the same well before to derive about on the hypoth."
        ],
        [
            "Space OK, an alternative approaches that we can take, not the margin to hold at the same time, but we want to have the product of the margin to be larger than a constant.",
            "OK, just another way to restrict your hypothesis space.",
            "And we have like a similar result.",
            "Also we use the average of the product of the margin, the average, so we do not impose the margin explicitly on the points.",
            "But we say on the average the motion should be larger than the constant.",
            "And this effectively leads to an interpretation in in terms of this guy.",
            "So instead of the like, Oceania feel like multiplication of two of the two matrixes, and so we just have to pick us before like the maximum.",
            "I had a vectors corresponding with maximal Agar values to shape effect this place.",
            "Of course, take design of the elevators.",
            "OK, so now we have."
        ],
        [
            "Operator restriction of the hypothesis space of the two groups at the same time.",
            "Based on the principle which implements in a certain way our knowledge that across our assumption of the cluster shoot alltrans using both representations.",
            "OK, so now we have a hypothesis based.",
            "The rest is like simple.",
            "If we have new points, say for example this gene OK, what's the cluster of this gene?",
            "There we have one label and we can look for the completion of this label both in one graph and also in the other graph because the ad labeling extents to also do the other graph and we can complete.",
            "You know the hypothesis and we can say OK if we have this label then also this will be member of this node will be plus one, so it will be in the cluster.",
            "So it says effectively something about two classes at the same time, two representations.",
            "The two graphs at the same time.",
            "So and the nice thing is, if we have like this this guy, so we maximize the correlation between the hypothesis now represents in this way and one label then restricting that the solution should be in the hypothesis space.",
            "This can be solved very easily as linear constraint, which just solved by matrix vector product.",
            "So it can be very fast.",
            "So, and that's the main point here that we have an algorithm consists of two parts.",
            "First explicitly shaping your hypothesis space based on the eigenvalue take composition.",
            "And second, picking just the hypothesis in this restricted hypothesis space, which corresponds with your specific setting.",
            "So in eigenvalue problem takes of course along, but this can be executed very fast.",
            "I mean it can be can happen online, so meaning that OK first we compute the value decomposition in the hypothesis space.",
            "But later people can do queries as they like and you can come up with a solution very fast because you just have two matrix vector product."
        ],
        [
            "OK, so simple toy example.",
            "Suppose you have two graphs which, like in this case 150 nodes and they can be represented effectively in 2 dimensional space.",
            "So for example here, here and they look like 2 clusters.",
            "Add the blocks, the pluses and stars, and if we know like a new point which is effectively in this region, then we can also predict that it will be here.",
            "So I guess its inverse way here we say OK and you point occurs here and then we predict the membership will be in this cluster.",
            "So you take them in just to complete the information of the node.",
            "And then we apply our algorithm which gives just.",
            "We have to our Christmas where we have the some of the cuts and we have like the product of the margin and it appears that the product of the margin works more effectively than the than the sum of the cuts.",
            "So this is the product of the margin and it gives a very accurate prediction effect of the corresponding.",
            "Value of the new note and the last guys kind of benchmark where you know everything by you know before OK, this will be the cluster it will belong to this case so you can compute very effectively the missing information and you just impute what you know.",
            "So it looks like the mean of the product of the margin can be more effective than if you know everything which is kind of strange thing.",
            "OK, and we do a count of Monte Carlo integration here.",
            "In this sense we did like 1000 iterations to generate these boxplots."
        ],
        [
            "OK, some intuition about microarray experiments.",
            "Dubai Informatic application.",
            "So this current work.",
            "So this example is quite small and not complete.",
            "So as I mentioned, you have like 2 graphs.",
            "Yes, like genes which are represented in microarray space space and which are represented by scientific literature.",
            "So you can come up with graph graph One, graph 2.",
            "Paragraph one is based on the you know on the Mets database.",
            "So use just natural cosine who to come up with the graph and the second one is based on the micro expression levels which are measured on this GSN use just.",
            "Obvious kind of distance to shape the graph.",
            "And now we have this prediction setting.",
            "But OK, we examine our results by just plain old data Fusion thing.",
            "So we have like 51 genes in this small example, and we know before and that there's some genes are related to motor activity and some to visual perception.",
            "So OK, and now we do the task and supervised that we ask, can we reconstruct the unknown activity based on both source?"
        ],
        [
            "So schematically, maybe very fast you have like 6 keys here, which are represented as a graph based on the text corpus and have like 60s here based on the graph.",
            "Graph based on the expression profile showed graphs are different, but you take the sum of the cuts so meaning that you have like here they cut this one here also one.",
            "So you have two and in this simple case this is optimal got you can make."
        ],
        [
            "OK, and the result is that if you combine both sources, you do better than just plain old clustering in.",
            "Separately, so it's not a surprise so, and I should state that here the prediction setting is still somewhat hidden and must be worked out, but it gives an idea that, OK, this kind of reasoning gives some some organisms which work well on real data."
        ],
        [
            "OK, so some discussion.",
            "So the main point I really want to emphasis of this presentation is the first 2 slides just setting this new code.",
            "So we have like much mutual clusters where you can transduce in some sense the information so you can come up with some qualitative knowledge about the missing values.",
            "So this is really interesting because it gives some prediction meaning about clustering.",
            "As in the sense of classification, you can do some analysis.",
            "So think of it as a prediction of missing values somehow.",
            "So we mentioned bioinformatics setting, but also like collaborative filtering and problems where you have like this baskets of.",
            "Nimick and so if you're on the web and you want to buy something, then you have a basket of things you buy and people do some analysis on that one.",
            "So people are asked to provide some information.",
            "But of course most people don't and there's missing values everywhere, so missing values.",
            "That's the kind of target reset we.",
            "That's the kind of thing we target.",
            "So and here we give like a setting of graph mining and we start off with transductive inference, because again, there's some nice analysis you can do more effectively than in the clustering setting.",
            "OK, we have this setting of bioinformatics.",
            "Um?",
            "Maybe important is that you have the opportunity to zoom in on small coherent groups of relevant clusters by just shaping your hypothesis space by shaping the way clusters will behave.",
            "And there are plenty of open questions.",
            "The 1st and most important is the question you ask about.",
            "What's the exact connection and can you work out further so, but it drops down.",
            "The first slides were expressed in terms of metric space, while the second items were expressed in terms of a graph.",
            "So what's the connection there?",
            "And it's awesome.",
            "Some problems.",
            "There are some open questions I would say.",
            "OK, this is.",
            "Yeah.",
            "Yes, sure, but the difference is that we if we work in a graph setting, it's.",
            "It's kind of different with the kernel setting in the sense of everything is observed.",
            "The graph is completely known and if you talk about kernels and specifically in the alignment, and I also mentioned the core training algorithms and all this kind of stuff, we work more naturally in the setting value of inductive setting.",
            "So where you want to go to new points, new test data.",
            "But here is everything is known, just the sampling mechanism is unknown, so in that sense.",
            "A real transductive setting and it's making more disconnection towards combinatorially optimization and towards you know Colonel results there.",
            "I don't know if this is sufficient also.",
            "We have this hard clustering.",
            "Sure.",
            "Sure, but the problem is that OK heart clusters are somewhat easier to understand because you can think of them as such memberships and you can apply classical theory.",
            "But if you talk about soft clusters, you're more in the setting of probabilistic, maybe somewhat sense, and the classical bounds just saying whether point will be set or not, not be applied in this straightforward way.",
            "OK, so the application.",
            "Well here we were kind of in the sense that we didn't test the prediction setting as we should, but we test OK. Can we use this mechanism to do more effectively?",
            "Data Fusion so the the two results are OK?",
            "We have like 51 jeans and we know before hand that they are related to the visual cortex.",
            "Through their motor behavior, that is something you don't give to the drawing algorithm and you hope clustering will come up with the cluster which you know separates both.",
            "I'm.",
            "Thus effectively, so it's really unsupervised setting in this case.",
            "And then now we observe that if we apply the previous mechanistic things that we come up with.",
            "Secret which more effectively separates the underlying behavior.",
            "If we combine sources in this way, so it's really a data Fusion application.",
            "So it's maybe somewhat confusing.",
            "OK, so how can we evaluate a cluster?",
            "So if you do not know nothing OK, we can do nothing because the cluster is kind of explorative thing and it gives some insight to people and hopefully it triggers some.",
            "Some intuition about the problem, but OK, but how can we measure clustering is good or not if we know before OK, it should be that and that and the closing corresponds, you know which is knowledge, but you don't give it to the algorithm that you know you could ask.",
            "Is.",
            "OK, but if you.",
            "Yeah.",
            "Yeah, sure.",
            "Now we just have a very restricted experiment like 51 clusters.",
            "We made the graphs.",
            "We make a partition and we see that partition corresponds very effectively.",
            "But what we hope to find you know the visual cortex or the motor behavior.",
            "Right, but I agree that's a kind of strange way to evaluate clustering.",
            "But then what's the good way to evaluate the clustering method?",
            "Yeah.",
            "I guess it's main difficulty for for here.",
            "I was also wondering because here the one of the information looks like random.",
            "Trucker should be very close to the to the hunting well.",
            "Yeah, and people suggested still OK.",
            "This guy is based on microarray.",
            "This guy is of course based on the literature because no in literature it's there.",
            "But my credit there is much more about people saying about representing the right information.",
            "It does a little bit better than account, but not much.",
            "But we see that back combining both choices we get effectively.",
            "Better than the best thing we can do based on literature only.",
            "Yeah, but.",
            "What was?",
            "What was proposed, in particular by the Flock, was about combining Roc curves.",
            "Say only the information related to the second record, OK?",
            "Corresponding to the.",
            "The diagonal part of the first one just invert it.",
            "OK, so just adding additional information of the second OK, But I agree there like plenty of methods so I definitely did not base modem and I do not say this method you should use right away.",
            "I just want to give a proof of concept that you know it gives some quite convenient for results.",
            "So a little bit OK. Genealogy.",
            "Absolutely, but this is the best.",
            "So this is the best we can do based on the literature only.",
            "So we do better by combining them.",
            "Yeah, two.",
            "I mean you see clear that there's a clear correlation between literature and and you know the optimal guide.",
            "There's some more information apparently, but I mean, I agree that's not a complete decent way to evaluate clustering.",
            "But then how do we evaluate clustering?",
            "I mean.",
            "Several.",
            "Yep.",
            "Squad car later.",
            "Absolutely.",
            "That's good, I mean, but if you can do better than literature by using other sources, I mean, if 1% of 2%, I mean you should be happy I guess.",
            "Alright.",
            "In this case, OK, it's not.",
            "I mean, it's significant.",
            "That is not the end of the world.",
            "I believe.",
            "Doctor Michael Levitt, of course, sure.",
            "The fleet weakness of the work.",
            "I was wondering also, but I mean I must read the paper because there are many things I didn't understand.",
            "I mean, there was a paper about.",
            "By circumstances and and rankings about extending support vector machines and say in two examples which made up of which were made of two structural parts.",
            "OK project say the expired and zed part to say vectors.",
            "So you should say long.",
            "See what I mean and this was this was also used by by Joaquins in ICM L 2005, so the idea was to project the two structured parts in such a way that you could learn something between the two projections, right?",
            "And it's definitely similar thing.",
            "I've seen this paper.",
            "Also.",
            "The setting is different again in the sense that we do not talk about support vector machines or kernels.",
            "We say OK, this hypothesis space.",
            "It's not a model, but it's just your number of possible labels.",
            "I mean, the animals analysis is quite different because your hypothesis space is not a model like in support vector machine, but your hypothesis spaces the labeling so it makes more sense in the context of graphs.",
            "So it is definitely the difference between the learning problem is also a little bit different in their setting because you do not talk about projections.",
            "But you talk about memberships so that.",
            "About clustering things.",
            "Does this does this also?",
            "Sure.",
            "Sure.",
            "Yeah definitely, and I want to make some advertisements for different that we developed together with the bioinformatics people after University to do exactly this.",
            "Fuse multiple sources, but this really data Fusion go, so it's kind of a little bit different from the original objective of this talk.",
            "But there do the same there that look like like.",
            "12 different sources also based on protein pots and all this kind of application independent sources and actually.",
            "Def.",
            "The main domain difficulty of coming up like from a theoretical view with their work is.",
            "Combining different classifiers into one, you know classifier and they use kind of a ranking mechanism and then it's like combining a ranking to global ranking.",
            "That's something you mentioned yesterday.",
            "They use it kind of Q statistic, but I mean there is also plenty of work going on there, but there's definitely two combining multiple sources and I mean looks like very promising in applications.",
            "Sing yeah.",
            "Good question I.",
            "But I guess the difference is that we here have like an explicit hypothesis space which you wouldn't have in this setting.",
            "If you talk about agreements.",
            "Yeah.",
            "Rice random match.",
            "Yeah.",
            "OK, but the difference somehow between statistical?",
            "I mean as far as we understood it and classical statistical you know.",
            "Disco parametric statistiques or like nonparametric statistics that you have defined explicitly in hypothesis space.",
            "And if you talk about the statistical test just to test whether there's agreement, that's kind of different with making different clusters which correspond to different hypothesis, so I think.",
            "I continue the discussion after I'm sure."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm from Belgium, from living and at this joint work with the professor here on Circus and back to work.",
                    "label": 0
                },
                {
                    "sent": "So the title is the changed with respect to the program, so it's predicted mutual clustering, learning in bioinformatics and two parts here like the first is predictive mutual clustering and we propose it as a kind of new learning task which is somewhere between classification and clustering and be motivated from the context of bioinformatics.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first I won't like elaborate and give some intuition about the learning task, and I invite everybody to think of some solution there and then.",
                    "label": 1
                },
                {
                    "sent": "I will also motivate from this informatics core.",
                    "label": 0
                },
                {
                    "sent": "I will proceed with the transductive inference setting.",
                    "label": 1
                },
                {
                    "sent": "Because it seems to be a good way to approach this learning problem and give some intuition about graph cuts and things.",
                    "label": 0
                },
                {
                    "sent": "So I give it to example in the application by informatics.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the most important slide, so if you feel sleepy, pay attention to this one and then go sleep for the restaurant of the presentation.",
                    "label": 0
                },
                {
                    "sent": "So what's the task exactly?",
                    "label": 0
                },
                {
                    "sent": "So we have like a sample here.",
                    "label": 0
                },
                {
                    "sent": "Like usually two parts X at, but now is.",
                    "label": 0
                },
                {
                    "sent": "It is not a label, not like plus one or minus one, but it's just an alternative to X, so it's.",
                    "label": 0
                },
                {
                    "sent": "And we assume that idea simple term joint distribution.",
                    "label": 0
                },
                {
                    "sent": "So that's effectively the setting we have, like a couple of objects somewhere in abstract space, and they have two representations.",
                    "label": 0
                },
                {
                    "sent": "Which are which?",
                    "label": 0
                },
                {
                    "sent": "Have the same value, so we can't say X is unable to that.",
                    "label": 0
                },
                {
                    "sent": "We also cannot say that is labeled 2X, but we're after looking for, you know, correspondences between both representations.",
                    "label": 0
                },
                {
                    "sent": "So the task we pose ourselves now is look for clustering of both in the representation X and in the representation set such that for all X's at which you sample from joint distribution, the memberships of the clusters will coincide.",
                    "label": 1
                },
                {
                    "sent": "So an example gifts maybe some intuition there.",
                    "label": 0
                },
                {
                    "sent": "So suppose we have like 15 samples.",
                    "label": 0
                },
                {
                    "sent": "Something here in X which are both represented in exquisite and we have like we can cluster them in three clusters both in X and set.",
                    "label": 0
                },
                {
                    "sent": "And now we look for isomorphism between the clusters.",
                    "label": 0
                },
                {
                    "sent": "So meaning that if a point blank, for example to the green cluster here, then we can predict that point to belong to the green cluster instead, and this effectively gives us some knowledge about the alternative representation.",
                    "label": 0
                },
                {
                    "sent": "So it's effectively clustering in the sense that we do not have labels in the classical sense and effectively.",
                    "label": 0
                },
                {
                    "sent": "A prediction as a classification in the sense that we want to transducin knowledge from half 11 space to another.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're after.",
                    "label": 0
                },
                {
                    "sent": "Instead of couples of clustering, so which is morphism?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main task is now to look for clusters such as the memberships go inside.",
                    "label": 0
                },
                {
                    "sent": "As I said previously.",
                    "label": 0
                },
                {
                    "sent": "So to make this more formal, we can define it in terms of risk functional, so which is typically in prediction setting, so the risk is like how many like for a fixed couple of clusters say CCX CK set.",
                    "label": 0
                },
                {
                    "sent": "So how many times two samples coincides so effectively that.",
                    "label": 0
                },
                {
                    "sent": "Explained to CX K then that the correspondence that should belong to the alternative cluster inset.",
                    "label": 0
                },
                {
                    "sent": "So in the losses of course translates a factor.",
                    "label": 0
                },
                {
                    "sent": "There should be the same, so one one is OK, but 1001 is not OK.",
                    "label": 0
                },
                {
                    "sent": "So and then actually state the expectation of the distribution function and we want to have this clustering hold over all clusters which we propose and this kind of different with the classical.",
                    "label": 0
                },
                {
                    "sent": "Prediction settings as we take the overall case, so which corresponds effectively with the supremum of the complete hypothesis space, and this is something which popups in the classical learning T. When you do this optimization thing and when you have like minimal risk.",
                    "label": 0
                },
                {
                    "sent": "But now we want to have the all you know couples all hypothesis to have this property.",
                    "label": 0
                },
                {
                    "sent": "Without saying OK, we're off to this hypothesis, but we want to have very such that we can say if we have a new point.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, here, then the corresponding guy will belong to that, but we don't know for new point to which cluster it will be long before hand.",
                    "label": 0
                },
                {
                    "sent": "So we have to have this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Premium.",
                    "label": 0
                },
                {
                    "sent": "Of course, is the actual hitscan.",
                    "label": 0
                },
                {
                    "sent": "You can come up with, like the same guy, but empirically, so it's the expectation replaced by some operator.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is basically domain setting.",
                    "label": 0
                },
                {
                    "sent": "The main idea of the this paper.",
                    "label": 0
                },
                {
                    "sent": "So if you have like this memberships which which correspond in both representations, then we can do predictions also of the X in the desert.",
                    "label": 0
                },
                {
                    "sent": "If the classes are effectively concentrated, meaning that if we know some point will belong to a cluster, then we also know that you know prediction will be not too different from the other members of the cluster.",
                    "label": 0
                },
                {
                    "sent": "And maybe a final remark is that we have of course a tradeoff between large clusters.",
                    "label": 0
                },
                {
                    "sent": "So if you have like one big cluster and the complete data set both in X and that corresponds, then of course we have this property that the memberships transit because you have only one one always 1 one.",
                    "label": 0
                },
                {
                    "sent": "But this is not very informative.",
                    "label": 0
                },
                {
                    "sent": "I mean you cannot say too much about this very large clusters, so we're after little smaller clusters which say effectively something if we know that it belongs to this cluster, but it's more difficult to have this membership property to hold.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and then I give a motivation.",
                    "label": 0
                },
                {
                    "sent": "How did we come to this ID where we were working in the setting of bioinformatics?",
                    "label": 0
                },
                {
                    "sent": "Very of course genes and genes occur in many representations and OK, the classical approaches to data Fusion in the sense so we still offer clustering.",
                    "label": 0
                },
                {
                    "sent": "But now we want to fuse different representation to one global clustering and but this is somewhat different in that we say OK, But if you have multiple sources there's an opportunity, namely this transaction prediction.",
                    "label": 0
                },
                {
                    "sent": "Property.",
                    "label": 0
                },
                {
                    "sent": "So in line bioinformatics, because you have typically much uncertainty on your data, so it has for example in micro race I mean the uncertainty is quite substantial and also in text based data and uncertainty in data is something which can be represented quite accurately using such memberships.",
                    "label": 1
                },
                {
                    "sent": "And if you talk about sets, memberships, people, I mean you should think about clustering, which is basically a set membership.",
                    "label": 1
                },
                {
                    "sent": "And the nice thing is that you if you have like this this framework then you can come up with a procedure to fill in missing information.",
                    "label": 1
                },
                {
                    "sent": "So suppose you have sample X of an object, but you don't have to representation instead, so now it becomes possible to have some qualitative feeling of the question mark here.",
                    "label": 0
                },
                {
                    "sent": "And it's also in both directions at the same time, so it's quite quite important X?",
                    "label": 0
                },
                {
                    "sent": "And?",
                    "label": 0
                },
                {
                    "sent": "As it can be filled in so and this follows from the.",
                    "label": 0
                },
                {
                    "sent": "The symmetric nature of this prediction.",
                    "label": 0
                },
                {
                    "sent": "The goal we set at the beginning so it also gives a very precise goal on clustering, so it's like incense, verifiable or first falsifiable depending on your philosophy.",
                    "label": 0
                },
                {
                    "sent": "And this is quite important.",
                    "label": 0
                },
                {
                    "sent": "I was at least two workshops on the theoretical foundations of clustering and one of the main outcomes was OK.",
                    "label": 0
                },
                {
                    "sent": "There are as many clustering goals as applications of clustering.",
                    "label": 0
                },
                {
                    "sent": "But for example you have like clustering based on vector quantization, but other application asks something like clustering based on looking for the maximal densities.",
                    "label": 1
                },
                {
                    "sent": "So there are different goals but a clear taxonomy saying OK in this case you should do that.",
                    "label": 0
                },
                {
                    "sent": "In this case you should do that.",
                    "label": 0
                },
                {
                    "sent": "It's all still lucky and also very many missing.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not clear which kind of clustering goals are there, so I just say OK, this is 1 size code which you can define any way of.",
                    "label": 0
                },
                {
                    "sent": "Prediction.",
                    "label": 0
                },
                {
                    "sent": "Pacific application we are after.",
                    "label": 0
                },
                {
                    "sent": "So as I say by Infomatics, you're talking mostly about jeans.",
                    "label": 0
                },
                {
                    "sent": "So we have like an abstract space of all genes, but they can be represented are expressed using microarrays, but they also can be expressed using scientific literature, which is a kind of orthogonal representation.",
                    "label": 0
                },
                {
                    "sent": "But then you can ask yourself, OK, what are the correspondences between these two representations?",
                    "label": 0
                },
                {
                    "sent": "OK, this was the application.",
                    "label": 0
                },
                {
                    "sent": "We're working a tiny bit with.",
                    "label": 0
                },
                {
                    "sent": "But then some people came and say OK, we had some discussion and they say OK, but that's nice because we have also this problem of.",
                    "label": 0
                },
                {
                    "sent": "Like my crazy experiments in the setting of like yeast Organism or like plants and we have also marker is based on human tissues or I mean on other organisms.",
                    "label": 0
                },
                {
                    "sent": "And so the question here is OK which pop?",
                    "label": 0
                },
                {
                    "sent": "This does correspond in both representations and can we use nodes which we ain't in used microarrays somehow in for human tissues?",
                    "label": 0
                },
                {
                    "sent": "OK, that's about the learning setting.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's good point.",
                    "label": 0
                },
                {
                    "sent": "Two to consider it somehow.",
                    "label": 0
                },
                {
                    "sent": "But otherwise I can proceed next.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, is a little bit more technical in the sense of OK. We talk now about predictive clustering.",
                    "label": 0
                },
                {
                    "sent": "So effectively we want to have this like this couple of clusters which we call mutual clusters, by the way.",
                    "label": 0
                },
                {
                    "sent": "So for prediction purposes.",
                    "label": 0
                },
                {
                    "sent": "But it's still about clustering somehow, so but closely is a very difficult thing to have.",
                    "label": 0
                },
                {
                    "sent": "Some analytical expressions for, so something which is more easy to work with this transductive inference.",
                    "label": 0
                },
                {
                    "sent": "And then if I went over this slides then I will give you the intuition how to go from constructive inference to clusters.",
                    "label": 0
                },
                {
                    "sent": "OK, so first, what's the goal of transductive inference?",
                    "label": 1
                },
                {
                    "sent": "Well specifically for grass, because in this bioinformatics setting we have like a graph of jeans.",
                    "label": 0
                },
                {
                    "sent": "I mean everything can be organized, typically in the graph.",
                    "label": 1
                },
                {
                    "sent": "So what's the setting we have, like a fixed amount of nodes, say nodes?",
                    "label": 1
                },
                {
                    "sent": "In our application is like engines and they are organized in one deterministic graphs AG with the nodes and edges.",
                    "label": 0
                },
                {
                    "sent": "Which is symmetrical and there are no loops and everything is positive, so the very classical setting but important is that we observe like the complete graph.",
                    "label": 1
                },
                {
                    "sent": "It's fixed before and so no random mechanism there.",
                    "label": 0
                },
                {
                    "sent": "Now with each note you associate affixed label and so labor plus 1 -- 1 as in the classification setting.",
                    "label": 0
                },
                {
                    "sent": "But we only observe like a part of the nodes, the label of the nodes.",
                    "label": 0
                },
                {
                    "sent": "So for example we have 1000 cheese, but we observe only for 10 genes, whether they are plus or minus one.",
                    "label": 0
                },
                {
                    "sent": "So what's the task?",
                    "label": 0
                },
                {
                    "sent": "Well, that ask is to complete this node scale says something about the other labels.",
                    "label": 0
                },
                {
                    "sent": "If you observe or written.",
                    "label": 0
                },
                {
                    "sent": "And that's the transductive problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we developed account a framework for for doing this in the context of graphs, which is kind of a little bit different from the classical framework.",
                    "label": 0
                },
                {
                    "sent": "So because why?",
                    "label": 0
                },
                {
                    "sent": "Because we start with hypothesis, which is not like a model or a set of parameters, but which is just your labeling on your nodes.",
                    "label": 0
                },
                {
                    "sent": "Because you have a fixed number of nodes, your hypothesis is determined.",
                    "label": 0
                },
                {
                    "sent": "So in general, if you impose no prior knowledge, you have like the complete hypothesis set which is.",
                    "label": 1
                },
                {
                    "sent": "All the set of all possible labels of the nodes.",
                    "label": 0
                },
                {
                    "sent": "So basically this graph is much to what I mean.",
                    "label": 0
                },
                {
                    "sent": "You have like 2 to the end possibilities.",
                    "label": 0
                },
                {
                    "sent": "So what do we want to do?",
                    "label": 1
                },
                {
                    "sent": "We want to restrict this hypothesis set by imposing prior knowledge, and this will proceed in next slide.",
                    "label": 0
                },
                {
                    "sent": "But suppose we have a kind of nice restriction.",
                    "label": 0
                },
                {
                    "sent": "We have like a hypothesis hypothesis H prime.",
                    "label": 0
                },
                {
                    "sent": "Radical counting all these much lower than to the end.",
                    "label": 0
                },
                {
                    "sent": "For example, fixed constants.",
                    "label": 0
                },
                {
                    "sent": "And also we have observed like a few.",
                    "label": 1
                },
                {
                    "sent": "I feel labels so.",
                    "label": 0
                },
                {
                    "sent": "Now there was no random mechanism until now, but the choice which nodes we observe is supposed to be a random, so it's not like random sampling.",
                    "label": 1
                },
                {
                    "sent": "The classical sense, but it's random sampling sampling without replacement.",
                    "label": 0
                },
                {
                    "sent": "So formally, it's dysfunctional.",
                    "label": 1
                },
                {
                    "sent": "Is this guy, so it says, OK, the hypothesis corresponds with the labels.",
                    "label": 0
                },
                {
                    "sent": "So how many times it doesn't OK and we take the expectation, but there are no capitals here, so the expectation is over the choice of which you know node we take.",
                    "label": 0
                },
                {
                    "sent": "So we in the case is biased or so star is like an IG ID choice of your initials and this kind of kind of the twist with classical learning like inductive schemes or something.",
                    "label": 0
                },
                {
                    "sent": "So the empirical risk is of course you observe a certain set of nodes and what's the observed.",
                    "label": 0
                },
                {
                    "sent": "You know, correspondence with the labels and your hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and then we can just proceed through the classical thing and do a union bound over inequality.",
                    "label": 1
                },
                {
                    "sent": "So normally we use headings inequality, but here it's pointed out that we should use surface inequality so at the end you arrive at this guy.",
                    "label": 0
                },
                {
                    "sent": "So important here is that there are two terms.",
                    "label": 1
                },
                {
                    "sent": "Basically this guy and here the size of the hypothesis set so effectively if the set of all hypothesis are possible labelings is.",
                    "label": 0
                },
                {
                    "sent": "Really very small then this becomes quite tight and this is a correction factor which say if you observe like very many nodes of the N1 labels of the N1 then then also the bound becomes much tighter.",
                    "label": 0
                },
                {
                    "sent": "So and this is new because I knew with respect to the classical hunting derivation.",
                    "label": 0
                },
                {
                    "sent": "But what does it say?",
                    "label": 0
                },
                {
                    "sent": "Effectively it says if you sample, you know nodes randomly in the same mechanism as we did on the training set, then this bound to hold.",
                    "label": 1
                },
                {
                    "sent": "But our intuition is that the node should be right on the average, so effectively says that if we start off with sampling randomly nodes and labels, then we can say something about this guy which is just average greatness of the nodes.",
                    "label": 0
                },
                {
                    "sent": "So the point is that this is very specific setting where you like uniform sampling without replacement.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, as I point out pointed out in the previous slides, we have this hypothesis set which is had set of all possible labelings of the nodes.",
                    "label": 0
                },
                {
                    "sent": "But this clearly much Dwight so we should have like kind of restriction of this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So what can we do?",
                    "label": 0
                },
                {
                    "sent": "Well, it was proposed to use like min cut criterion just to impose a restriction.",
                    "label": 0
                },
                {
                    "sent": "So saying that OK if you note we label this nodes or plus one and this guys minus one.",
                    "label": 0
                },
                {
                    "sent": "Then the cut is like the some of the edges which go from plus one to minus one.",
                    "label": 0
                },
                {
                    "sent": "So this is very classical thing, well known in combinatorial optimization and leaning to the spectral relaxation and things.",
                    "label": 0
                },
                {
                    "sent": "So this one thing you can do, you can say OK we consider all labelings which have like got which is smaller than a specified number.",
                    "label": 0
                },
                {
                    "sent": "And this effectively restricts the set.",
                    "label": 0
                },
                {
                    "sent": "But there's also some other things you can do is quite intuitive.",
                    "label": 0
                },
                {
                    "sent": "It says that OK, suppose you have a rule, say like one years neighbor rule, then we should say OK.",
                    "label": 0
                },
                {
                    "sent": "Consider only like the labelings such that the rule corresponds exactly with the labeling.",
                    "label": 0
                },
                {
                    "sent": "So it means that if you have a one nearest neighbor then you look at the nearest neighbor and if this is plus one then the node of this effective who should also be plus one.",
                    "label": 0
                },
                {
                    "sent": "So and that's this guy.",
                    "label": 0
                },
                {
                    "sent": "So F VI is the rule deciding on OK, what's the exact level of the node and Qi is the label of the node itself, so there should be larger than zero saying stating that they should be the same.",
                    "label": 0
                },
                {
                    "sent": "So and now remarked that if we take not the one nearest neighbor or genius there, but if it takes like a weighted neighborhood tool, then this first who will correspond in away with the second rule.",
                    "label": 0
                },
                {
                    "sent": "So nearest neighborhood is just taking the average.",
                    "label": 0
                },
                {
                    "sent": "Of the neighboring nodes are agents by their the rate of the rating of the edges, and we take the sign of them.",
                    "label": 0
                },
                {
                    "sent": "And we have here like this quantity, which is called the merchant support vector machines, and we require that the margin will be large and zero, so this lies effectively relation between.",
                    "label": 0
                },
                {
                    "sent": "OK, what's the model for us?",
                    "label": 0
                },
                {
                    "sent": "Just kind of constraint the hypothesis set which should be restricted and with the previous guy with them in cut.",
                    "label": 0
                },
                {
                    "sent": "So we go a little bit further than the blue.",
                    "label": 0
                },
                {
                    "sent": "And shovel a paper on the topic.",
                    "label": 0
                },
                {
                    "sent": "Of course you have all kinds of different constraints depending on your application, so people argued already for a few years that there should also be like a balancing constraint.",
                    "label": 0
                },
                {
                    "sent": "We should have positive samples, negative samples, but I mean, maybe you require that you have like a low number of positive samples with respect to the negative samples, or the ratios are approximately approximately one or something.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have like a number of balancing constraint depending on your application and we can also impose fixed labelings so.",
                    "label": 0
                },
                {
                    "sent": "We know from the beginning on that, for example, this gene as a plus one associated to it.",
                    "label": 0
                },
                {
                    "sent": "And you can go further.",
                    "label": 0
                },
                {
                    "sent": "Can go say OK, we have this literature on material optimization and many different concepts like Max cut like coloring theorems like matching theorems.",
                    "label": 0
                },
                {
                    "sent": "And there will be used to restrict in fact this hypothesis this quite intuitively.",
                    "label": 0
                },
                {
                    "sent": "But the next slide will show for example that cardinality is effectively restricted in the in the first setting.",
                    "label": 0
                },
                {
                    "sent": "So the idea is if we impose enough regularization or problem knowledge on the hypothesis then this touches the statistical guarantee of the transductive inference.",
                    "label": 1
                },
                {
                    "sent": "So do I speak clearly enough?",
                    "label": 0
                },
                {
                    "sent": "Maybe I'll beat him.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Not important topic because I mean.",
                    "label": 0
                },
                {
                    "sent": "For the moment I just give the transductive inference context.",
                    "label": 0
                },
                {
                    "sent": "Later on our extended a little bit to the case we have two graphs, which is the previous case, like the predictive clustering case and I will say what's the result there?",
                    "label": 0
                },
                {
                    "sent": "No, I just start off with the definition of the problem because I thought that was most important for this learning conference and now the transitive inference gives like some some formal motivation of the clustering goal, so that's a little bit based where we start off.",
                    "label": 0
                },
                {
                    "sent": "So, but it's an important topic, and I mean I hope this question will rise again so we can go further.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's the formal derivation.",
                    "label": 0
                },
                {
                    "sent": "If you have like this, got Cardium if you say OK, all possible labels should be such that.",
                    "label": 0
                },
                {
                    "sent": "The cut is lower than the specified value, so we start off OK by stating this hypothesis sets, so the cut is defined as the all the edges which unequal.",
                    "label": 0
                },
                {
                    "sent": "But security is different from QJ, so conveniently this can be translated in terms of the Laplacian matrix.",
                    "label": 0
                },
                {
                    "sent": "Well, it's not that difficult, but maybe it is too far to go too much in that important is that this this transition is also be used to derive the spectral clustering.",
                    "label": 0
                },
                {
                    "sent": "Kind of algorithms.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have this set of constraints and then we relax a little bit.",
                    "label": 0
                },
                {
                    "sent": "This set of constraints stating that Q is sign of new variable so but this new variable can be anything.",
                    "label": 0
                },
                {
                    "sent": "So and then we just replace the queues by the West and then we state that OK this is just an egg value problem right?",
                    "label": 0
                },
                {
                    "sent": "And we have just a sign of the vectors which is in the solution space.",
                    "label": 0
                },
                {
                    "sent": "So H double prime is relaxation.",
                    "label": 0
                },
                {
                    "sent": "Prime and H Double prime is like a signed version of the Eiger space.",
                    "label": 0
                },
                {
                    "sent": "Determined by this parameter.",
                    "label": 0
                },
                {
                    "sent": "So suppose alcohol exists only a few values, then the hypothesis space will be lowered and the signed version of the corresponding angle space.",
                    "label": 0
                },
                {
                    "sent": "So and then you can come up of course with this hours inequality giving like a bound on the original hypothesis space.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and you are some thoughts about the connection between constructive influence and clustering, and I must state from the beginning that is really some ongoing work.",
                    "label": 0
                },
                {
                    "sent": "I mean, as far as I know it's the connection is never made explicitly in terms of formulas, so I hope this will trigger someone to.",
                    "label": 0
                },
                {
                    "sent": "You know, stating OK from my problem is that and I can plug it in this way.",
                    "label": 0
                },
                {
                    "sent": "So what's the ID so we have like a set of hypothesis of different hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And now we associate with each hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So Q in our terminology, we associate with each one cluster.",
                    "label": 0
                },
                {
                    "sent": "So if it's plus one, it indicates that this node belongs to the cluster.",
                    "label": 0
                },
                {
                    "sent": "So effectively, if like as many clusters as hypothesis, so we can use the previous result in the cardinality of the hypothesis space to say OK, how many clusters do we have?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is an isomorphism between the cluster and the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "Well, a common constraints of clustering is that clusters are disjunct in some ways, so that they do not overlap.",
                    "label": 0
                },
                {
                    "sent": "So in this explicity it means that the Q's eyes are like this unit in some way, so meaning that they are exactly plus one in exactly 1 hypothesis, so it's an extra constraint, restrict your hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "So, but now we have made a connection between the hypothesis space and the clustering.",
                    "label": 0
                },
                {
                    "sent": "In this setting clear.",
                    "label": 0
                },
                {
                    "sent": "And the baseline idea is that we do not.",
                    "label": 0
                },
                {
                    "sent": "Look for the optimal hypothesis as an SVM or I mean like in most learning machines, but we do.",
                    "label": 1
                },
                {
                    "sent": "Examine the hypothesis space explicitly so we go over all different hypothesis to examine the clustering.",
                    "label": 1
                },
                {
                    "sent": "So and that's the difference between inductive learning where you say OK, this is optimal one and we hope to have some properties on the optimal para meter sets of hypothesis.",
                    "label": 0
                },
                {
                    "sent": "But in this case we just examined the hyperspace explicitly, we won't say.",
                    "label": 0
                },
                {
                    "sent": "OK, this hypothesis correspond to this cluster just now, because this cluster means something.",
                    "label": 0
                },
                {
                    "sent": "I mean, we just examine how.",
                    "label": 0
                },
                {
                    "sent": "Examine it, I put a space after decently and important.",
                    "label": 0
                },
                {
                    "sent": "Also is that we can use further domain knowledge to shape this hypothesis space.",
                    "label": 1
                },
                {
                    "sent": "So for example here you have that I cannot overlap, but you have of course further restrictions.",
                    "label": 0
                },
                {
                    "sent": "For example, you should say that a cluster is concentrated in some point.",
                    "label": 0
                },
                {
                    "sent": "OK, it's an additional constraint which you can impose on your hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "OK head.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think I can skip the last point.",
                    "label": 0
                },
                {
                    "sent": "So at this point I hope to make the connection between the first setting so the predictive mutual clustering where you have like this set of mutual clusters and various like this property.",
                    "label": 0
                },
                {
                    "sent": "If point belongs to cluster in one, you know representation then it also belongs to another to the same.",
                    "label": 0
                },
                {
                    "sent": "The corresponding cluster in the other representation and transactive settings so.",
                    "label": 0
                },
                {
                    "sent": "Well, effectively, what's difference that you have two graphs?",
                    "label": 0
                },
                {
                    "sent": "Of course in OK, they are also fully observed, so now you have like just acts just that.",
                    "label": 0
                },
                {
                    "sent": "So now exit are not a metric space.",
                    "label": 0
                },
                {
                    "sent": "Or as in our beginning, but they are like embedding in the graph.",
                    "label": 0
                },
                {
                    "sent": "There are like the edges of a graph.",
                    "label": 0
                },
                {
                    "sent": "OK, what can we do?",
                    "label": 0
                },
                {
                    "sent": "For example, we can say OK we have restriction in terms of model so that the labeling should correspond with the kind of model applied on the hypothesis on the labeling.",
                    "label": 0
                },
                {
                    "sent": "So we can do the same.",
                    "label": 0
                },
                {
                    "sent": "But now we can impose the model on both graphs similar at the same time.",
                    "label": 0
                },
                {
                    "sent": "So for example we can say, OK, you know the margin should be larger than the constant vote in the first graph in the second graph.",
                    "label": 1
                },
                {
                    "sent": "And now we made the had the transition between the original setting, namely the predictive mutual clustering in the transductive setting.",
                    "label": 1
                },
                {
                    "sent": "Does this make sense?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, now we remarked OK, this is very.",
                    "label": 0
                },
                {
                    "sent": "I mean it looks like a nice idea, but OK.",
                    "label": 0
                },
                {
                    "sent": "It seems very difficult to work with because it's not.",
                    "label": 1
                },
                {
                    "sent": "It's very common tutorial in nature and OK, there is no clear way to proceed to, you know.",
                    "label": 0
                },
                {
                    "sent": "August.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or something.",
                    "label": 0
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We have two approaches and the first one is we take.",
                    "label": 0
                },
                {
                    "sent": "Not like merges should be satisfied for both points at the same time, but we say we have like a cut.",
                    "label": 0
                },
                {
                    "sent": "And we have like some other cut sandwich should be small and see and we can proceed in the same well before to derive about on the hypoth.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space OK, an alternative approaches that we can take, not the margin to hold at the same time, but we want to have the product of the margin to be larger than a constant.",
                    "label": 0
                },
                {
                    "sent": "OK, just another way to restrict your hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "And we have like a similar result.",
                    "label": 0
                },
                {
                    "sent": "Also we use the average of the product of the margin, the average, so we do not impose the margin explicitly on the points.",
                    "label": 0
                },
                {
                    "sent": "But we say on the average the motion should be larger than the constant.",
                    "label": 0
                },
                {
                    "sent": "And this effectively leads to an interpretation in in terms of this guy.",
                    "label": 0
                },
                {
                    "sent": "So instead of the like, Oceania feel like multiplication of two of the two matrixes, and so we just have to pick us before like the maximum.",
                    "label": 0
                },
                {
                    "sent": "I had a vectors corresponding with maximal Agar values to shape effect this place.",
                    "label": 0
                },
                {
                    "sent": "Of course, take design of the elevators.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Operator restriction of the hypothesis space of the two groups at the same time.",
                    "label": 0
                },
                {
                    "sent": "Based on the principle which implements in a certain way our knowledge that across our assumption of the cluster shoot alltrans using both representations.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have a hypothesis based.",
                    "label": 0
                },
                {
                    "sent": "The rest is like simple.",
                    "label": 0
                },
                {
                    "sent": "If we have new points, say for example this gene OK, what's the cluster of this gene?",
                    "label": 0
                },
                {
                    "sent": "There we have one label and we can look for the completion of this label both in one graph and also in the other graph because the ad labeling extents to also do the other graph and we can complete.",
                    "label": 0
                },
                {
                    "sent": "You know the hypothesis and we can say OK if we have this label then also this will be member of this node will be plus one, so it will be in the cluster.",
                    "label": 0
                },
                {
                    "sent": "So it says effectively something about two classes at the same time, two representations.",
                    "label": 0
                },
                {
                    "sent": "The two graphs at the same time.",
                    "label": 0
                },
                {
                    "sent": "So and the nice thing is, if we have like this this guy, so we maximize the correlation between the hypothesis now represents in this way and one label then restricting that the solution should be in the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "This can be solved very easily as linear constraint, which just solved by matrix vector product.",
                    "label": 0
                },
                {
                    "sent": "So it can be very fast.",
                    "label": 0
                },
                {
                    "sent": "So, and that's the main point here that we have an algorithm consists of two parts.",
                    "label": 0
                },
                {
                    "sent": "First explicitly shaping your hypothesis space based on the eigenvalue take composition.",
                    "label": 0
                },
                {
                    "sent": "And second, picking just the hypothesis in this restricted hypothesis space, which corresponds with your specific setting.",
                    "label": 0
                },
                {
                    "sent": "So in eigenvalue problem takes of course along, but this can be executed very fast.",
                    "label": 0
                },
                {
                    "sent": "I mean it can be can happen online, so meaning that OK first we compute the value decomposition in the hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "But later people can do queries as they like and you can come up with a solution very fast because you just have two matrix vector product.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so simple toy example.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have two graphs which, like in this case 150 nodes and they can be represented effectively in 2 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So for example here, here and they look like 2 clusters.",
                    "label": 0
                },
                {
                    "sent": "Add the blocks, the pluses and stars, and if we know like a new point which is effectively in this region, then we can also predict that it will be here.",
                    "label": 0
                },
                {
                    "sent": "So I guess its inverse way here we say OK and you point occurs here and then we predict the membership will be in this cluster.",
                    "label": 0
                },
                {
                    "sent": "So you take them in just to complete the information of the node.",
                    "label": 0
                },
                {
                    "sent": "And then we apply our algorithm which gives just.",
                    "label": 0
                },
                {
                    "sent": "We have to our Christmas where we have the some of the cuts and we have like the product of the margin and it appears that the product of the margin works more effectively than the than the sum of the cuts.",
                    "label": 0
                },
                {
                    "sent": "So this is the product of the margin and it gives a very accurate prediction effect of the corresponding.",
                    "label": 0
                },
                {
                    "sent": "Value of the new note and the last guys kind of benchmark where you know everything by you know before OK, this will be the cluster it will belong to this case so you can compute very effectively the missing information and you just impute what you know.",
                    "label": 0
                },
                {
                    "sent": "So it looks like the mean of the product of the margin can be more effective than if you know everything which is kind of strange thing.",
                    "label": 0
                },
                {
                    "sent": "OK, and we do a count of Monte Carlo integration here.",
                    "label": 0
                },
                {
                    "sent": "In this sense we did like 1000 iterations to generate these boxplots.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, some intuition about microarray experiments.",
                    "label": 1
                },
                {
                    "sent": "Dubai Informatic application.",
                    "label": 0
                },
                {
                    "sent": "So this current work.",
                    "label": 0
                },
                {
                    "sent": "So this example is quite small and not complete.",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned, you have like 2 graphs.",
                    "label": 0
                },
                {
                    "sent": "Yes, like genes which are represented in microarray space space and which are represented by scientific literature.",
                    "label": 0
                },
                {
                    "sent": "So you can come up with graph graph One, graph 2.",
                    "label": 0
                },
                {
                    "sent": "Paragraph one is based on the you know on the Mets database.",
                    "label": 0
                },
                {
                    "sent": "So use just natural cosine who to come up with the graph and the second one is based on the micro expression levels which are measured on this GSN use just.",
                    "label": 0
                },
                {
                    "sent": "Obvious kind of distance to shape the graph.",
                    "label": 1
                },
                {
                    "sent": "And now we have this prediction setting.",
                    "label": 0
                },
                {
                    "sent": "But OK, we examine our results by just plain old data Fusion thing.",
                    "label": 0
                },
                {
                    "sent": "So we have like 51 genes in this small example, and we know before and that there's some genes are related to motor activity and some to visual perception.",
                    "label": 1
                },
                {
                    "sent": "So OK, and now we do the task and supervised that we ask, can we reconstruct the unknown activity based on both source?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So schematically, maybe very fast you have like 6 keys here, which are represented as a graph based on the text corpus and have like 60s here based on the graph.",
                    "label": 0
                },
                {
                    "sent": "Graph based on the expression profile showed graphs are different, but you take the sum of the cuts so meaning that you have like here they cut this one here also one.",
                    "label": 0
                },
                {
                    "sent": "So you have two and in this simple case this is optimal got you can make.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and the result is that if you combine both sources, you do better than just plain old clustering in.",
                    "label": 0
                },
                {
                    "sent": "Separately, so it's not a surprise so, and I should state that here the prediction setting is still somewhat hidden and must be worked out, but it gives an idea that, OK, this kind of reasoning gives some some organisms which work well on real data.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so some discussion.",
                    "label": 0
                },
                {
                    "sent": "So the main point I really want to emphasis of this presentation is the first 2 slides just setting this new code.",
                    "label": 0
                },
                {
                    "sent": "So we have like much mutual clusters where you can transduce in some sense the information so you can come up with some qualitative knowledge about the missing values.",
                    "label": 0
                },
                {
                    "sent": "So this is really interesting because it gives some prediction meaning about clustering.",
                    "label": 0
                },
                {
                    "sent": "As in the sense of classification, you can do some analysis.",
                    "label": 0
                },
                {
                    "sent": "So think of it as a prediction of missing values somehow.",
                    "label": 1
                },
                {
                    "sent": "So we mentioned bioinformatics setting, but also like collaborative filtering and problems where you have like this baskets of.",
                    "label": 0
                },
                {
                    "sent": "Nimick and so if you're on the web and you want to buy something, then you have a basket of things you buy and people do some analysis on that one.",
                    "label": 0
                },
                {
                    "sent": "So people are asked to provide some information.",
                    "label": 0
                },
                {
                    "sent": "But of course most people don't and there's missing values everywhere, so missing values.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of target reset we.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of thing we target.",
                    "label": 0
                },
                {
                    "sent": "So and here we give like a setting of graph mining and we start off with transductive inference, because again, there's some nice analysis you can do more effectively than in the clustering setting.",
                    "label": 0
                },
                {
                    "sent": "OK, we have this setting of bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Maybe important is that you have the opportunity to zoom in on small coherent groups of relevant clusters by just shaping your hypothesis space by shaping the way clusters will behave.",
                    "label": 1
                },
                {
                    "sent": "And there are plenty of open questions.",
                    "label": 0
                },
                {
                    "sent": "The 1st and most important is the question you ask about.",
                    "label": 0
                },
                {
                    "sent": "What's the exact connection and can you work out further so, but it drops down.",
                    "label": 0
                },
                {
                    "sent": "The first slides were expressed in terms of metric space, while the second items were expressed in terms of a graph.",
                    "label": 0
                },
                {
                    "sent": "So what's the connection there?",
                    "label": 0
                },
                {
                    "sent": "And it's awesome.",
                    "label": 0
                },
                {
                    "sent": "Some problems.",
                    "label": 0
                },
                {
                    "sent": "There are some open questions I would say.",
                    "label": 0
                },
                {
                    "sent": "OK, this is.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, sure, but the difference is that we if we work in a graph setting, it's.",
                    "label": 0
                },
                {
                    "sent": "It's kind of different with the kernel setting in the sense of everything is observed.",
                    "label": 0
                },
                {
                    "sent": "The graph is completely known and if you talk about kernels and specifically in the alignment, and I also mentioned the core training algorithms and all this kind of stuff, we work more naturally in the setting value of inductive setting.",
                    "label": 0
                },
                {
                    "sent": "So where you want to go to new points, new test data.",
                    "label": 0
                },
                {
                    "sent": "But here is everything is known, just the sampling mechanism is unknown, so in that sense.",
                    "label": 0
                },
                {
                    "sent": "A real transductive setting and it's making more disconnection towards combinatorially optimization and towards you know Colonel results there.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this is sufficient also.",
                    "label": 0
                },
                {
                    "sent": "We have this hard clustering.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Sure, but the problem is that OK heart clusters are somewhat easier to understand because you can think of them as such memberships and you can apply classical theory.",
                    "label": 0
                },
                {
                    "sent": "But if you talk about soft clusters, you're more in the setting of probabilistic, maybe somewhat sense, and the classical bounds just saying whether point will be set or not, not be applied in this straightforward way.",
                    "label": 0
                },
                {
                    "sent": "OK, so the application.",
                    "label": 0
                },
                {
                    "sent": "Well here we were kind of in the sense that we didn't test the prediction setting as we should, but we test OK. Can we use this mechanism to do more effectively?",
                    "label": 0
                },
                {
                    "sent": "Data Fusion so the the two results are OK?",
                    "label": 0
                },
                {
                    "sent": "We have like 51 jeans and we know before hand that they are related to the visual cortex.",
                    "label": 0
                },
                {
                    "sent": "Through their motor behavior, that is something you don't give to the drawing algorithm and you hope clustering will come up with the cluster which you know separates both.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Thus effectively, so it's really unsupervised setting in this case.",
                    "label": 0
                },
                {
                    "sent": "And then now we observe that if we apply the previous mechanistic things that we come up with.",
                    "label": 0
                },
                {
                    "sent": "Secret which more effectively separates the underlying behavior.",
                    "label": 0
                },
                {
                    "sent": "If we combine sources in this way, so it's really a data Fusion application.",
                    "label": 0
                },
                {
                    "sent": "So it's maybe somewhat confusing.",
                    "label": 0
                },
                {
                    "sent": "OK, so how can we evaluate a cluster?",
                    "label": 0
                },
                {
                    "sent": "So if you do not know nothing OK, we can do nothing because the cluster is kind of explorative thing and it gives some insight to people and hopefully it triggers some.",
                    "label": 0
                },
                {
                    "sent": "Some intuition about the problem, but OK, but how can we measure clustering is good or not if we know before OK, it should be that and that and the closing corresponds, you know which is knowledge, but you don't give it to the algorithm that you know you could ask.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "OK, but if you.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Now we just have a very restricted experiment like 51 clusters.",
                    "label": 0
                },
                {
                    "sent": "We made the graphs.",
                    "label": 0
                },
                {
                    "sent": "We make a partition and we see that partition corresponds very effectively.",
                    "label": 0
                },
                {
                    "sent": "But what we hope to find you know the visual cortex or the motor behavior.",
                    "label": 0
                },
                {
                    "sent": "Right, but I agree that's a kind of strange way to evaluate clustering.",
                    "label": 0
                },
                {
                    "sent": "But then what's the good way to evaluate the clustering method?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I guess it's main difficulty for for here.",
                    "label": 0
                },
                {
                    "sent": "I was also wondering because here the one of the information looks like random.",
                    "label": 0
                },
                {
                    "sent": "Trucker should be very close to the to the hunting well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and people suggested still OK.",
                    "label": 0
                },
                {
                    "sent": "This guy is based on microarray.",
                    "label": 0
                },
                {
                    "sent": "This guy is of course based on the literature because no in literature it's there.",
                    "label": 0
                },
                {
                    "sent": "But my credit there is much more about people saying about representing the right information.",
                    "label": 0
                },
                {
                    "sent": "It does a little bit better than account, but not much.",
                    "label": 0
                },
                {
                    "sent": "But we see that back combining both choices we get effectively.",
                    "label": 0
                },
                {
                    "sent": "Better than the best thing we can do based on literature only.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but.",
                    "label": 0
                },
                {
                    "sent": "What was?",
                    "label": 0
                },
                {
                    "sent": "What was proposed, in particular by the Flock, was about combining Roc curves.",
                    "label": 0
                },
                {
                    "sent": "Say only the information related to the second record, OK?",
                    "label": 0
                },
                {
                    "sent": "Corresponding to the.",
                    "label": 0
                },
                {
                    "sent": "The diagonal part of the first one just invert it.",
                    "label": 0
                },
                {
                    "sent": "OK, so just adding additional information of the second OK, But I agree there like plenty of methods so I definitely did not base modem and I do not say this method you should use right away.",
                    "label": 0
                },
                {
                    "sent": "I just want to give a proof of concept that you know it gives some quite convenient for results.",
                    "label": 0
                },
                {
                    "sent": "So a little bit OK. Genealogy.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, but this is the best.",
                    "label": 0
                },
                {
                    "sent": "So this is the best we can do based on the literature only.",
                    "label": 0
                },
                {
                    "sent": "So we do better by combining them.",
                    "label": 0
                },
                {
                    "sent": "Yeah, two.",
                    "label": 0
                },
                {
                    "sent": "I mean you see clear that there's a clear correlation between literature and and you know the optimal guide.",
                    "label": 0
                },
                {
                    "sent": "There's some more information apparently, but I mean, I agree that's not a complete decent way to evaluate clustering.",
                    "label": 0
                },
                {
                    "sent": "But then how do we evaluate clustering?",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "Several.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Squad car later.",
                    "label": 0
                },
                {
                    "sent": "Absolutely.",
                    "label": 0
                },
                {
                    "sent": "That's good, I mean, but if you can do better than literature by using other sources, I mean, if 1% of 2%, I mean you should be happy I guess.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "In this case, OK, it's not.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's significant.",
                    "label": 0
                },
                {
                    "sent": "That is not the end of the world.",
                    "label": 0
                },
                {
                    "sent": "I believe.",
                    "label": 0
                },
                {
                    "sent": "Doctor Michael Levitt, of course, sure.",
                    "label": 0
                },
                {
                    "sent": "The fleet weakness of the work.",
                    "label": 0
                },
                {
                    "sent": "I was wondering also, but I mean I must read the paper because there are many things I didn't understand.",
                    "label": 0
                },
                {
                    "sent": "I mean, there was a paper about.",
                    "label": 0
                },
                {
                    "sent": "By circumstances and and rankings about extending support vector machines and say in two examples which made up of which were made of two structural parts.",
                    "label": 0
                },
                {
                    "sent": "OK project say the expired and zed part to say vectors.",
                    "label": 0
                },
                {
                    "sent": "So you should say long.",
                    "label": 0
                },
                {
                    "sent": "See what I mean and this was this was also used by by Joaquins in ICM L 2005, so the idea was to project the two structured parts in such a way that you could learn something between the two projections, right?",
                    "label": 0
                },
                {
                    "sent": "And it's definitely similar thing.",
                    "label": 0
                },
                {
                    "sent": "I've seen this paper.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "The setting is different again in the sense that we do not talk about support vector machines or kernels.",
                    "label": 0
                },
                {
                    "sent": "We say OK, this hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "It's not a model, but it's just your number of possible labels.",
                    "label": 0
                },
                {
                    "sent": "I mean, the animals analysis is quite different because your hypothesis space is not a model like in support vector machine, but your hypothesis spaces the labeling so it makes more sense in the context of graphs.",
                    "label": 0
                },
                {
                    "sent": "So it is definitely the difference between the learning problem is also a little bit different in their setting because you do not talk about projections.",
                    "label": 0
                },
                {
                    "sent": "But you talk about memberships so that.",
                    "label": 0
                },
                {
                    "sent": "About clustering things.",
                    "label": 0
                },
                {
                    "sent": "Does this does this also?",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah definitely, and I want to make some advertisements for different that we developed together with the bioinformatics people after University to do exactly this.",
                    "label": 0
                },
                {
                    "sent": "Fuse multiple sources, but this really data Fusion go, so it's kind of a little bit different from the original objective of this talk.",
                    "label": 0
                },
                {
                    "sent": "But there do the same there that look like like.",
                    "label": 0
                },
                {
                    "sent": "12 different sources also based on protein pots and all this kind of application independent sources and actually.",
                    "label": 0
                },
                {
                    "sent": "Def.",
                    "label": 0
                },
                {
                    "sent": "The main domain difficulty of coming up like from a theoretical view with their work is.",
                    "label": 0
                },
                {
                    "sent": "Combining different classifiers into one, you know classifier and they use kind of a ranking mechanism and then it's like combining a ranking to global ranking.",
                    "label": 0
                },
                {
                    "sent": "That's something you mentioned yesterday.",
                    "label": 0
                },
                {
                    "sent": "They use it kind of Q statistic, but I mean there is also plenty of work going on there, but there's definitely two combining multiple sources and I mean looks like very promising in applications.",
                    "label": 0
                },
                {
                    "sent": "Sing yeah.",
                    "label": 0
                },
                {
                    "sent": "Good question I.",
                    "label": 0
                },
                {
                    "sent": "But I guess the difference is that we here have like an explicit hypothesis space which you wouldn't have in this setting.",
                    "label": 0
                },
                {
                    "sent": "If you talk about agreements.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Rice random match.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, but the difference somehow between statistical?",
                    "label": 0
                },
                {
                    "sent": "I mean as far as we understood it and classical statistical you know.",
                    "label": 0
                },
                {
                    "sent": "Disco parametric statistiques or like nonparametric statistics that you have defined explicitly in hypothesis space.",
                    "label": 0
                },
                {
                    "sent": "And if you talk about the statistical test just to test whether there's agreement, that's kind of different with making different clusters which correspond to different hypothesis, so I think.",
                    "label": 0
                },
                {
                    "sent": "I continue the discussion after I'm sure.",
                    "label": 0
                }
            ]
        }
    }
}