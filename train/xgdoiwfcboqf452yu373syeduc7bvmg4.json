{
    "id": "xgdoiwfcboqf452yu373syeduc7bvmg4",
    "title": "Adversarial bandit problems: the power of randomization",
    "info": {
        "author": [
            "Gabor Lugosi, Department of Economics and Business, Pompeu Fabra University"
        ],
        "published": "Nov. 16, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2010_lugosi_abp/",
    "segmentation": [
        [
            "OK, I guess we can start so my name is Gabor Lugosi and.",
            "I'll tell you a little bit about bandit problems.",
            "Not all types of bandit problems, but one kind that's that's usually called adversarial bandit problem.",
            "I'll tell you exactly what it is, and I will show you a few variants of this and then show you maybe a little bit of insight of what.",
            "One branch of the research has been recent.",
            "Research has been what type of problems?",
            "Recent research has been interested in so.",
            "I'm sorry for four.",
            "What about the last change of tutorials?",
            "But there was a health problem with the with the the.",
            "Everyone.",
            "I'm like a good bench player.",
            "When the coach calls me, I'm ready, ready to play so."
        ],
        [
            "So OK. All the problems that I'm going to tell you about today are about online prediction, where the model can be given in form of a repeated play between between a forecaster and an environment.",
            "So we are the forecaster.",
            "Maybe we are the forecaster and the environment is is our our adversary and the environment is the one who's trying to play against us and the."
        ],
        [
            "The game is played like this at each round.",
            "Forecast for us.",
            "We choose an action and the action is between is takes finite values.",
            "It's in a set.",
            "Of cording"
        ],
        [
            "City Capital North and sometimes in online learning.",
            "These actions are also called experts, but I will maybe called codem actions.",
            "It's at least because for notation I'm going to use somehow it is more natural to call this actions, but this is the framework that has also been known as prediction with expert advice."
        ],
        [
            "So at each time we choose an action and at the same time the environment assigns a loss to each action, OK?",
            "So these losses I will only assume that they are.",
            "They are bounded, so I can.",
            "I might as well assume that they are between zero and one, but I don't want to assume anything about them.",
            "OK, so this is in when we talk about adversary adversarial problems.",
            "The main assumption is that these.",
            "Losses can be completely anything OK, and in fact these losses can also depend on what the forecaster did in the past.",
            "I'm not going to describe the model in every detail, but I think you will understand what I'm talking about.",
            "OK, so the environment chooses losses and I don't want to assume any stochastic or strategic behavior from part of the environment.",
            "He's completely free to choose the losses anyway.",
            "He likes OK."
        ],
        [
            "And then my loss is just the loss that was assigned to the action I chose.",
            "OK, so these two things happen at the same time and this is what I lose all right."
        ],
        [
            "Now what's my goal?",
            "So if it's if these losses can be completely arbitrary, then then then we have to careful we have to be careful about how we define of our goals because it's very easy to come up with problems that obviously don't have a good solution.",
            "So a meaningful way of setting up this problem is that we're trying to minimize what's known the regret.",
            "So what's the regret this is?",
            "The loss.",
            "Of of the forecaster is my loss accumulated during the end periods of the place, so I will assume that this game is played during little N rounds, and let's just assume for the sake of concreteness, that this little and is known by me.",
            "So the forecaster knows that this game is going to be played for one million rounds.",
            "OK, this is not an essential assumption, but let's just assume this so I know in advance that I'm going to play for a million rounds and my goal is to eventually.",
            "Minimize the loss.",
            "I suffer.",
            "This is the so called cumulative loss.",
            "This is the loss I accumulate during the rounds of the play and I want to.",
            "I want to compare this to the loss of the best possible action.",
            "So for every little I hear, this sum is just the loss that that forecaster that had chosen little I all the time would have suffered so if I had known what the best constant action was.",
            "I could have achieved this loss.",
            "OK.",
            "Right, so for example, I want to invest in the stock market.",
            "These are the impossible, impossible.",
            "The impossible actions and at time T. This is how much I lose if I if I if I bet on Coca Cola or IBM or Yahoo.",
            "OK and if I had known advance what the best stock was then I would have been able to achieve this loss.",
            "OK now I want my loss to be not too far from that.",
            "This is how we set up the online prediction problem.",
            "This and I divide by N so that this.",
            "Number is always between zero and one OK, so this is the regret and all my talk is about this quantity.",
            "OK, how can we come up with strategies in which in which we can minimize?",
            "This regret make this as small as possible."
        ],
        [
            "Alright, no the notation I chose is is maybe not very standard in many papers online learning you will see that there is a loss function and I is the action I pay.",
            "I play and there's some outcome sequence, so there's an outcome sequence that I want to predict and if I take an action I, then if there's given some kind of loss function, then this is the loss of your software.",
            "OK, so you can think about this problem is we are trying to predict.",
            "Some sequence of outcomes.",
            "Let's say we're trying to predict what the weather will be like tomorrow and then as.",
            "I is is whether I take an umbrella or not, so there's a loss associated to whether it's sunny and I take a number lower.",
            "It's it's, it's rainy.",
            "I didn't take an umbrella and so on.",
            "So you can think about this problem that we're trying to.",
            "We're trying to predict an outcome sequence when we are given a loss function, and I want to I want to act as well as if I had known the whole weather sequence.",
            "The whole sequence of outcomes in advance, and if I could have been able to choose the best possible action, the best possible constant action.",
            "OK, so that's that's another way of writing up this problem.",
            "So LTI this is just loss associated to the to the action can may be given in some applications, my loss function and some outcome sequence, But this is somehow more general.",
            "Or actually they are completely equivalent ways of writing the problem, OK?"
        ],
        [
            "So the question is, is it possible to make this regret go to 0?",
            "No matter what the loss assignments are, so our adversaries has no restrictions.",
            "He can choose the loss anyway he wants."
        ],
        [
            "Well, it's easy to see that no, the answer is no, and here's a very little very simple example.",
            "Take two actions.",
            "We have two actions, and the losses are like this, so the remember the adversary can do anything so the adversary can.",
            "Actually know what my algorithm is, how I assign my action so the adversary can always choose zero if I say two, sorry, they assign loss 0 to the action one.",
            "If my prediction is 2 and maximum loss.",
            "To my prediction.",
            "OK, so the adversary can always set the losses such that so that I lose each time the maximum possible.",
            "So in this case, if the loss right?",
            "So this is the loss assigned to action one, which depends on on the forecasters prediction, and this is the loss assigned to action tool, which is just small minus the law section.",
            "So the losses are zeros or ones.",
            "And whenever I choose action number one then that action gets at the maximum loss if.",
            "If I choose that action number 2, the Death action gets the big loss, so in that."
        ],
        [
            "In in the in the if the losses are this and remember I I want to be prepared to all possible assignments, so I must be prepared to the loss assignments that are that are depend on my predictions.",
            "So in this case my losses North at each time I have the maximum loss, but the best of the two actions obviously has because because one one loss is just one minus the other, so the better of the two is always has always accumulated.",
            "Last, less than half.",
            "So the difference between 2:00 is at Lee."
        ],
        [
            "East and half.",
            "So if I normal normalized and the regret is bigger than 1/2, OK.",
            "So then then you can go back.",
            "OK, so let's see what we can do."
        ],
        [
            "Here's the problem.",
            "It seems like it is.",
            "This is not a meaningful setting of the problem I. I cannot be prepared to all possible sequences, so one way out is that you can try to assume that these sequence of losses or the sequence of loss vectors or the sequence of outcomes follows some kind of stochastic process.",
            "So you can try to come up with with stochastic models of the stock market and try to tailor your predictor for that right.",
            "Of course, this is a huge area of research classic from classical statistics to modern statistical learning theory.",
            "Lots of problems are dealt like this, but we don't want to do this.",
            "We're trying to insist on.",
            "The outcomes to be completely arbitrary, and there are reasons for this because there are many applications in which it is really, really difficult to model the sequence of losses.",
            "So what do you do?",
            "Well, let's let's give a little bit more power to the, to the forecaster and that."
        ],
        [
            "Is randomization so?",
            "So the we will allow the forecaster to randomize.",
            "So in in the previous.",
            "In this example, the adversary was allowed to look at what the forecaster does now from now on.",
            "The forecaster will have it coin, or rather the forecaster.",
            "We have a random number generator, and even though the adversary is allowed to look at what probability distribution the forecaster uses the.",
            "Mercer is not allowed to look at the outcome of the of the random number generator.",
            "OK, so this is the additional power we have.",
            "We have a secret random number generator and we can randomize anyway.",
            "We like from that.",
            "Otherwise the adversary sees in our head, right?",
            "You can read our minds, but he cannot read the outcome of the coin flips.",
            "OK, so the way this the problem is set up now is at time T the forecaster.",
            "Now instead of choosing an action, the forecaster chooses the probability distribution.",
            "Over the set of actions and I write PT minus one here because this can depend on everything that happened up to time T -- 1.",
            "OK, so we're of course following the past.",
            "We're looking at what happened up to now and as a function of that we are allowed to choose a probability distribution on the set of the actions.",
            "OK, and now we can randomize according to this probability distribution.",
            "So the adversary can see this vector, but the adversary does not see capital it, which is the random variable whose distribution is this OK?",
            "All right now there are many variants of the model.",
            "In the simplest model, the losses are all observed by the forecaster.",
            "OK, so this is called the full information model, so the."
        ],
        [
            "Go back so the game is played like this.",
            "The forecaster now chooses a probability distribution.",
            "At the same time, the environment chooses the losses.",
            "Now the forecaster chooses a random variable I subte based on.",
            "According to that probability distribution that the forecaster had determined.",
            "And then the forecaster suffers this loss.",
            "So this loss now is it is a random variable.",
            "It depends on our randomizations.",
            "Now there are many variants of this problem, depending on what.",
            "What is the information that the forecaster has access to.",
            "In the simplest case, whenever the.",
            "The forecaster suffers this loss.",
            "All these losses are revealed to the forecaster.",
            "This is called the full information case.",
            "So at every step when after we take an action, we are told how much we would have lost if we had chosen some other action OK.",
            "So this is the so-called full information set up, and this is already."
        ],
        [
            "A very interesting problem.",
            "So each time we are told what the losses, what the real losses were and then then we have to take another action."
        ],
        [
            "OK, so this type of problems have have.",
            "A long history going back to the 50s.",
            "So it started in.",
            "In game theory and in statistics, in the theory of sequential decisions in game theory, this type of problems have many applications, because this is a game, this is a repeated play game, so the outcomes you can think about the loss, the outcomes as the action of our opponents, or the action of our opponent.",
            "So we take an action, the opponent takes an action, and then we see what.",
            "Then I see my pay offs so.",
            "So in game theory this type of problems have been studied.",
            "In information theory already in sixty 70s, going back to Z Vancouver.",
            "When?",
            "For example, if you want to compress a sequence of zeros and ones, then you have to predict it and then these are some models that are very very closely related to the models that I just told you about the beginnings are are in statistics in the theory of sequential decisions.",
            "And now all this type of problems have been big in learning theory of course."
        ],
        [
            "OK, alright so.",
            "This is this is the big inning Hannon black backwards.",
            "So these were the two guys who realized that if we if we let the forecaster randomized then the forecaster can achieve a regret that goes to 0.",
            "So this is very sharp sharp contrast to what we had when when we weren't allowed to randomize.",
            "So just giving you this little extra power, we can already drive the regret to zero no matter what the outcomes are, no matter what the what the law sequences.",
            "OK.",
            "So this is a classical result and the first proofs were not."
        ],
        [
            "Very simple, these are.",
            "This is Hannon and this is Blackwell.",
            "He just died this summer and I'm not sure what happened to Hannah.",
            "OK."
        ],
        [
            "So I will I will.",
            "I will give you."
        ],
        [
            "I won't show you many proofs in this talk, but I will give you the proof of this OK, because because everything is based on on how it goes, I will give you 1 proof of this and which is which is much newer than than their original proofs."
        ],
        [
            "And and very simple, and you can teach this easily.",
            "So the main idea is to introduce the so-called expected loss.",
            "So the expected loss is what you what you think it is.",
            "So we just take.",
            "Remember, we choose.",
            "Action number I with probability PIT.",
            "This is.",
            "The this is the loss associated to action number I.",
            "So if we take the expected value with respect to the distribution, so with respect to the randomizing distribution, this is just the expected value of my loss, OK?",
            "And well, you can write this like esapi esapi, because because it's really a conditional distribution.",
            "Remember this PIT minus one?",
            "This can depend on what happened in the past, so this is really random, because in the past we had, we had all these random losses and random things happening.",
            "It doesn't matter if this is a condition of conditional expected value, right?",
            "So given the past, the forecaster chooses this probability distribution, and according to that.",
            "Probably the distribution.",
            "This is the."
        ],
        [
            "The expected value of the loss now.",
            "But then we have a very nice tool.",
            "The theory of martingales.",
            "That's a classical topic in probability, and it tells us that if this difference.",
            "So LLTIT, that's that's our random loss and this is just this condition, conditional expected value.",
            "So these are called the conditional expectation of this guy given the past equals this guy.",
            "Now if you have sums of differences of this type, these are called martingale differences.",
            "Then we have something that's called the Martindale and then loaf large numbers.",
            "Works just as.",
            "You get something very, very similar, but.",
            "As if you had sums of independent random variables, these are not independent because IT depends.",
            "Depends on the past, but they are uncorrelated.",
            "This is a martingale.",
            "OK so if you have some sort of martingale differences and everything is nice and bounded because I just assume that all the losses are between zero and one then this.",
            "Divided by N converges to zero rapidly.",
            "It's probably this is greater than Delta, is something like 1 / sqrt N times log one over Delta OK, just as if you have sums of independent random variables, so that's nice.",
            "That means that we don't have to worry about our random losses anymore.",
            "We can replace everything by by the expected losses.",
            "OK, so if remember."
        ],
        [
            "If you go back to the definition of the regret, now we can replace this sum by the sum of the expected losses.",
            "We're making just a very, very small mistake."
        ],
        [
            "The mistake we are making is of the order of 1 / sqrt N that's peanuts."
        ],
        [
            "So it suffices to study this difference instead of the true regret.",
            "This is the.",
            "Cumulative expected loss.",
            "And this is the optimum loss.",
            "Alright, so.",
            "How do we do that?",
            "Well, I haven't told you what the the forecaster does.",
            "So this whole thing is true no matter what we do.",
            "The expected loss end and that rules will always be close.",
            "This is independent of what the fork."
        ],
        [
            "There's algorithms so.",
            "What should the forecaster do well?",
            "A natural thing to try is try to favor actions that have worked better in the past.",
            "Everybody would agree that that's a good idea, and the Wolf can littlestone and warmuth."
        ],
        [
            "Said, that's why not use this exponential form.",
            "OK, this is called the exponentially weighted average forecaster, so the probability that we assign to action number I.",
            "Is proportional to the negative exponential of.",
            "The cumulative loss of action number I up to yesterday.",
            "OK.",
            "So this is how much loss we would have suffered if we had chosen action number I all the time.",
            "So if this is big then we will penalize action number I.",
            "That's not a good action.",
            "We will give it a very small.",
            "Probably that's where the negative sign comes downstairs.",
            "This is just a normalization that forces the speed to be a probability distribution.",
            "So it's a very very simple idea.",
            "This number error here is just a parameter that we will set.",
            "So that so that we get the best possible bounds OK?",
            "So this is the exponentially weighted average forecaster, and everything in this talk is based on this.",
            "It will be we will see many variants of of the exponentially weighted."
        ],
        [
            "Bridge forecaster and.",
            "And the theorem that you can get these guys proved and many variants of this is that the regret of this forecaster is.",
            "This should be less than or equal to the square root of log capital N / 2 N, so this is great news.",
            "Well, you get this if data is chosen like this.",
            "OK. That's just that's just an optimal way of of let's just the number which optimizes the bound that I will show you, and that leads to this upper bound.",
            "So this is great news because as little Lang goes to 0.",
            "This goes to zero as one over square root of.",
            "That's the same order of magnitude as as the error that we got from.",
            "From from from the Martingale convergence theorem.",
            "So this is really the main term here, and there's the dependence on the number of actions is very nice, it's only longer it's square root of log North.",
            "So this means that we can really have huge we can deal with a huge number of actions many times in applications actions are not really actions, But button algorithm.",
            "OK, so so if you want if you want to predict the weather then you can have a huge bag of algorithms that predict the weather.",
            "And those are your actions, so every time you just pick an algorithm and you and and use that algorithm, right?",
            "So you can have something that's based on based on graphical models.",
            "Something else that's based on Markov models, something else, so you can have a big variety of algorithms, and each time we just pick one of those according to the exponentially weighted average.",
            "Distribution.",
            "Forecaster and this capital can be huge.",
            "We can have a huge bag of them, and this can still be small, and we will be able to predict as well as the best of them, OK?",
            "So this is really nice.",
            "We are very happy about this log in and then this will also be a recurring theme of this talk that in some other models we will run into troubles when we want to handle very very very big classes of classes of actions.",
            "So I will show you the proof of this."
        ],
        [
            "Alright, so.",
            "Capital LIT is just the cumulative loss of action number I of the time T. OK, that's just notation and.",
            "I just tried down.",
            "I just denote by little WITE to the minus 8 times this.",
            "So this is what we call wait.",
            "These are the weights that appear in the definition, so this is just WIT minus one.",
            "That's just the weight that defines this probability distribution.",
            "So these are the weight weights and W capital W is just the sum of the weights at time T. OK, so the proof is based on looking at the evolution of this quantity WT.",
            "We also call this a potential function somehow sometimes, so W 0 = N because at the time zero these guys are all equal to the cumulative losses equals 0.",
            "So this sum 1 N times.",
            "So that's capitalized.",
            "So at Times 0 W, capital W equals."
        ],
        [
            "North and now we're looking at the log of the ratio of the sum of the weights at time North and at times zero and we will look at it two different ways, so we will get.",
            "Very simple, lower bound in the very simple simple upper bound, and if we compare them then then we get the we get our result.",
            "So there's the strategy.",
            "So what's the log of this ratio?",
            "Well this is just log of WN minus log of.",
            "Zero, so that's log in and this is just the definition.",
            "So there's the definition and the only inequality on this slide is says that the if you have non negative numbers then the sum is greater than the biggest.",
            "The largest term in the sum.",
            "So this is greater than the maximum since this maximum upstairs becomes a minimum because E to the minus positive numbers decreasing function.",
            "So what we have up here is now the loss of the best action, and that's what we get here.",
            "OK, so this is minus 8 times the loss of the best action minus log capital N. OK, now let's."
        ],
        [
            "Let's look at an upper bound for for this ratio, and we will write this ratio.",
            "This ratio as the sum of the log WT divided by WT minus ones.",
            "It's a telescoping sum, OK?",
            "So we decompose this as the sum of N terms and these in terms are just these guys.",
            "OK, so if you look at two neighboring time instances then the log of this ratio?",
            "Well, we can just write it down.",
            "What's how does WWT depend on WIT minus one?",
            "Well, we just multiplied it by E to the area times the loss at time T, right?"
        ],
        [
            "Remember that just is this definition, right?",
            "The WIT is is the sum of the cumulative losses.",
            "So at the next term this is just multiplied by E to the minus eight times the new loss."
        ],
        [
            "So that's what's written here.",
            "This guy upstairs is WIT and I wrote it this way, Becausw now this becomes an expected value.",
            "This is an expected value according to this probability distribution given by the exponentially weighted average.",
            "Off this exponential now there's a very."
        ],
        [
            "Nice and famous inequality due to hub thing from 63, which says that if we if I have abounded random variable between zero and one then this is called the moment generating function.",
            "The log of the moment generating function which is also called a cumulative generating function, is always less than 80 times the expected value plus error squared divided by 8.",
            "OK, this guy is always greater than eight times the expected value.",
            "That's just Jensen's inequality.",
            "So it's between 8 times.",
            "The expected value and data expected value plus error squared divided by 8, so that's how things inequality.",
            "So this guy has exactly this form.",
            "It's the expect, it's a moment generating function of this random variable that takes value Y to the that takes value LP I with probability this probability in WI T -- 1 divided normalized.",
            "OK, so if you use that then this is the expected value right?",
            "And this is this 8 / 8, But the expected value is just, it's just the loss of.",
            "Of the forecaster, because this probability distribution is just.",
            "Is just."
        ],
        [
            "Where is it this guy right?",
            "This is WIT minus one normalized, so that's exactly are are probably to distribute."
        ],
        [
            "So, so the expected value of the loss.",
            "With respect to our probability distribution is just our expected loss.",
            "OK, now we can sum this."
        ],
        [
            "Is this inequality?"
        ],
        [
            "And times.",
            "And we get.",
            "So this is what we just proved.",
            "So if we sum it N times then we get the log of W N / 0 is just the sum.",
            "Of the of the expected losses, that's our expected cumulative loss times N times this error turn.",
            "So if you compare now we have an upper bound on this, and we had a lower bound.",
            "Remember which looked like minus eight times the best possible loss, and we had that log term.",
            "So if we compare then we get this inequality.",
            "OK, and now you can pick era to minimize this.",
            "This guy here.",
            "And if you pick error to be of the order 1 / sqrt N then then both terms are of the order of square root of North.",
            "You divide by N and we're done OK.",
            "So this is.",
            "This is the proof.",
            "OK, so how good is this bound?"
        ],
        [
            "So let's let's look at it again, so it's what it says is that the regret the normalized regret is always bounded less than or equal to square root of log N / 2.",
            "This is not a synthetic.",
            "This is true for every little end and no matter what the outcome sequence is now, it turns out that this is pretty good."
        ],
        [
            "It's so good that you can do better, so this is the regret and this is our upper bound.",
            "Now it turns out that there exists an assignment of assignment of losses such that this will be as close to the regret will be as close to the upper bound is possible.",
            "So in fact the Supreme overall little lens, all capitals and all the assignments of this ratio is greater than one.",
            "OK, so this means that.",
            "You cannot do better unless unless you're willing to assume something about the loss function or something about about the structure of the actions or something, and."
        ],
        [
            "This is very easy to prove.",
            "Again, we can just randomize."
        ],
        [
            "Which let's just choose.",
            "So we want to look at what the worst case regret is.",
            "This is a regret.",
            "And this we want we want to look at what the worst possible assignment is.",
            "OK, So what if you were an adversary and you would?",
            "You would want to set a really difficult problem to predict.",
            "Then you would just assign the losses completely randomly.",
            "Let's somehow intuitively it's clear that should be a difficult problem.",
            "So if all of these guys are let's define all of these as independent coin flips 0.",
            "01's OK with probably 1/2 one, half symmetric so the Supreme then is greater than the average.",
            "OK, that's that's.",
            "That's always true, and it's easy to see that if these are really randomly 01, then no matter what you do, the loss of your loss will be 1/2.",
            "OK. No matter what the forecaster is, the expected loss of the forecaster will be, will be 1/2, and the expected loss of every action will be also 1/2.",
            "So this is just a binomial.",
            "With parameters and 1/2 and so here we have N half and here we have the minimum of binomials and there's an expected value missing here.",
            "OK, so we have the half minus the expected value of the minimum of binomials.",
            "Now if you take a normal approximation then you get this.",
            "OK. Because this square root of.",
            "Sqrt 2 login is just a maximum of an independent normals, so that's where this comes.",
            "So simple normal approximation tells you that this is the best you can do.",
            "Alright."
        ],
        [
            "OK, so let's now slowly go into variants of the problem in which in which we don't have the forecaster does not have full information.",
            "So now the 1st and easiest variant of this is what we call label efficient prediction.",
            "So suppose that that getting.",
            "Getting the true losses is expensive, so in the previous model, let me.",
            "They go back to.",
            "Sorry."
        ],
        [
            "In this, in the exponentially exponentially weighted forecaster, we assumed that.",
            "The forecaster knows all of these guys, knows all the losses of all the actions of the time.",
            "T -- 1 S The forecaster can look back and see the whole past.",
            "OK, if in 1954 I would have bought Coca Cola and this is how much I would have one.",
            "OK so this is full information but in some cases this is expensive to get.",
            "The information is expensive so assume now that we have a budget."
        ],
        [
            "The forecaster can only ask.",
            "The for for the outcomes or losses at a limited number of times.",
            "OK, so the forecaster can always decide whether we forecaster makes a prediction.",
            "The outcomes are set, the forecaster suffers a loss, but the forecaster has no idea what the loss was or what the outcomes were.",
            "OK, and he can decide to ask.",
            "444 dolosis at his convenience but only M times where M is much, much, much, much smaller than.",
            "OK, it sounds like this is very difficult because we have all those losses we want to predict as well as the best possible action, but we won't see the losses.",
            "We're kind of blind.",
            "We don't see the losses most of the time we can.",
            "We can only take a tiny subsample and these are completely arbitrary again, so our adversary is really powerful.",
            "We can do anything so it feels like this should be impossible, but again, random."
        ],
        [
            "Azatian helps.",
            "Very easy randomization, so here this is the."
        ],
        [
            "Is how the game works."
        ],
        [
            "In this case.",
            "So the environment chooses the losses, they are not revealed, the forecaster chooses a probability distribution and draws in action according to this distribution.",
            "This is just the same as before.",
            "The forecaster has this loss, and this is the loss of action number I, but the forecaster is not told these values forecaster doesn't know.",
            "Now, after this is done, the forecaster can decide.",
            "To ask for all these values, the LLT eyes at any given moment of time, the forecast are considered now.",
            "Please tell me I made this prediction.",
            "Please tell me how much would I would have won if I had chosen any other any other action, but the forecaster is only allowed to do this M times in the whole sequence of North rounds and M is is very very very small.",
            "OK, so this is the."
        ],
        [
            "So the idea is again randomized just the simplest possible randomization that you can imagine will work the forecaster just.",
            "Flips a coin.",
            "And the coin will be a biased coin, so with probability M over North you will say when the coin is head, which is this probability, then the forecaster will say.",
            "Now show me the the outcomes completely random and this is set such that on the average for forecaster will see about M. If you actually the probabilities of the of head should be a little bit less than this such that with very large high probability we are guaranteed that the forecaster doesn't ask for more than M times.",
            "OK, but anyways this."
        ],
        [
            "This is the idea, and so we have a Bernoulli random variable which is probability of success is epsilon, which will be a little bit smaller than M divided by North, and the forecaster will ask for the labels or the values of the losses if and only if.",
            "Ed comes up."
        ],
        [
            "OK. OK, so now what should we do?",
            "Well, the forecaster sees the labels now how should we use this information now?",
            "One idea is this.",
            "Let's define the estimated losses and this is a crucial trivial thing.",
            "What I'm writing, but I'm writing it in a way that will be useful later, so we will see that.",
            "Let's estimate.",
            "The true losses.",
            "By this Lt tilt quantity.",
            "So what's Lt Field of I which it's just Lt of I divided by epsilon if.",
            "If I see this label, if I if I if it comes up then I get to know this information so I can use it.",
            "So I divide it by epsilon, which means that I blow it up.",
            "And if I don't see then I just say that I estimate the loss to be 0.",
            "So what is this?",
            "Well, it turns out that this is a good estimate of the true loss.",
            "Good in what sense that it's unbiased?",
            "What does unbiased means?",
            "It means that if let's calculate the expected value of this with respect to the distribution MCT?",
            "With probability epsilon.",
            "Z = 1, So it's probably the epsilon.",
            "This guy equals Lt divided by epsilon is probably 1 minus epsilon.",
            "This is equals 0, so the expected value of this is epsilon times this plus one minus epsilon epsilon times 0 which is just Lt of I. OK, so.",
            "With respect to this newly introduced introduced randomizing distribution, the expected value of this guy is what it should be.",
            "It's a good estimate in this very way."
        ],
        [
            "Make sense.",
            "But a little bit more is true, because I will do this many times as we do this N times.",
            "So remember, if I want to use the exponentially weighted forecaster, then all that matters is that the sum of these guys.",
            "And the sum if I do.",
            "If I do this many times, the sum will be a sum of independent random variables with the right expected value.",
            "So I expect that to be close to what it really should be.",
            "So that's it.",
            "The proof is now you can do it, you just copy the previous proof and you make the modifications.",
            "The algorithm is, we just use the.",
            "The exponentially weighted average forecaster, but with we replace the true losses which we don't know by these estimated losses, these are legally chosen.",
            "These are chosen such that it only uses the information that we that's available.",
            "OK, so."
        ],
        [
            "The proof, so this is what you get.",
            "You get that the regret will be bounded by something that looks exactly as before, except that North the sample size was now replaced by N. Which is of course we expect something.",
            "Verse, but this is not worse.",
            "So if M is large, even though it's not as large as North, this still goes to 0.",
            "So somehow what we get here is is kind of what you expect.",
            "If you think about how much information, how big a sample is available for us before we head North, now we have M that that's how much information we have."
        ],
        [
            "OK, and the proof is is as I said, it's simple we start bounding.",
            "The the regret in terms of these estimated losses that you can do exactly as."
        ],
        [
            "Before and then we just use Martingale inequalities again.",
            "Martin years, that's the main tool, because the difference between Lt of IT&L tilt T of PT.",
            "That's again the conditional expectation of this given the past is the same as this, so these differences are.",
            "Still smarting will differences there sums of martingale differences.",
            "They are not as nice as before because because the these differences are not bounded.",
            "Here's a change.",
            "These differences are not bounded between between zero and one anymore, but they are bounded between zero and one over epsilon, right?",
            "This can be as big as one over epsilon, which is very big.",
            "So if you want.",
            "If you want to apply Martin your differences that you have to be aware of that and then you will get worse bounds, that's where that's why we get something worse here.",
            "OK, and similarly the L tilty eyes the sum of those minus.",
            "So these are the estimated losses and these are the true losses.",
            "The difference between these is again Martin Gale, so we can use.",
            "You can use the same type of martingale inequalities.",
            "OK, so that's how you get this."
        ],
        [
            "So this is labeled efficient prediction, and again you can show by an argument similar to the one in the full information case that this is basically the best you can do.",
            "OK again, if you have to choose the losses.",
            "Randomly, now you have to be a little bit more clever, but but again, this is not very difficult to show, so this is this is."
        ],
        [
            "Truly the best you can hope for now.",
            "The constant is not the best, not optimal anymore.",
            "I don't know what the best constant is before.",
            "The bond was exact up to two.",
            "Even the constant term."
        ],
        [
            "Oh no, I don't know what."
        ],
        [
            "The best constant this year."
        ],
        [
            "OK. Alright, so now we're slowly arriving at at what the title of this talk is.",
            "The Multi armed bandit problem, which is a similar online prediction problem.",
            "But here the problem is the available information is different from the previous one.",
            "Here the forecaster only observes the loss of his own action, but he doesn't know what.",
            "He would have lost if he had chosen some other action.",
            "OK.",
            "So you arrive, you arrive at Barcelona and you know that there are.",
            "10 restaurants in the in the vicinity.",
            "So every day you go, you try.",
            "And you know that you're going to be here for 20 years.",
            "So you want to choose you want to eat?",
            "Well, on a cumulative way.",
            "So you want to eat as well as if you had known in advance for.",
            "The best restaurant was OK, but if you go to a restaurant then you of course you know how valuate but you have no idea what would have happened if you had gone to the different one.",
            "OK and there are many many many many problems that are.",
            "That are like this, so you take an action that then you observe your own loss, but you cannot calculate what would have happened if you had done something else.",
            "You go to a job interview, you reject it.",
            "You know what happened now, but you don't know what would have happened if you accepted it.",
            "So this happens all the time."
        ],
        [
            "And the first guy too.",
            "Define this problem was Herbert Robinson in the 50s.",
            "So he was.",
            "He was one of the main figures when this whole started.",
            "This type of prediction problems him and Blackwall and hang on.",
            "So the name comes from."
        ],
        [
            "This is a one armed bandit.",
            "A1 Armed Bandit is just a slot machine that you pull and you get a reward.",
            "You pull and you get the reward.",
            "Now mostly armed bandit is when when you have many machines and you get to choose one at each time you know how much you get, but you don't know what would have happened if you had.",
            "If you had chosen the others unless."
        ],
        [
            "C or something like this."
        ],
        [
            "OK.",
            "So, so what's the trick here?",
            "Again, the key is trying to estimate the loss.",
            "OK, in the in the label efficient problem we want because we could come up with an estimate which was unbiased.",
            "Unbiased in this very strange sense.",
            "So unbiased estimate in statistics you observe a random variable and then you come up with A and you.",
            "To estimate the expected value, then, then you're trying to come up with functions of this random variable such that the expected value is the same as that parameter.",
            "OK, so that's what unbiased estimate means here.",
            "We are randomizing and unbiasedness is with respect to our our own randomization.",
            "So we want we want to come up with a function of what's observable, which is Lt of IT.",
            "Such that the expected value of that is just what it should be OK, and so here's here's a proposal.",
            "Let's see.",
            "So this is what I observe.",
            "This is the loss, so I'm going to estimate the loss of action number I now.",
            "So how do I do that if I observe action number I then it's easy.",
            "Then I'll just assume I just assign Lt to it and if I don't then I say 0.",
            "Just as before, right in the label deficient case, we had something very, very similar.",
            "Where was it?"
        ],
        [
            "So.",
            "It says here what we observed when we observe it.",
            "We just say that if we don't, then we assign 0.",
            "But then we had to normalize such that the expected value becomes what it should be.",
            "Now this is the same.",
            "It's the same.",
            "The situation is the same here."
        ],
        [
            "If the outcome is if I if my prediction, which is chosen randomly from this distribution is equals I, then I know what to do.",
            "Then then I will estimate the loss of action number.",
            "I buy what I observe normalized and if I if I if every other action that I don't observe I just just assign 0.",
            "So you go to the restaurant, then you know how well you eat.",
            "So you can.",
            "You can update that.",
            "Sure you can estimate the loss there, and for all other restaurants you assign 0.",
            "Now what is this?",
            "We divide by the probability that just the probability that.",
            "Isofix is the.",
            "It was our choice, right?",
            "I remember P. At time T -- 1 is just the probability distribution, so this is.",
            "This is the.",
            "Element of that vector of the probability vector that corresponds to the action that I happen to choose the restaurant I happen to choose so."
        ],
        [
            "Why is this unbiased?",
            "That's very easy to see because the expected value of this?",
            "What's that?",
            "That's just the sum over all actions J goes from one to 312 North of.",
            "So I choose action number J with this probability.",
            "And this is just Lt till J.",
            "Right, so this is if the outcome is if the outcome is J then this is my estimate.",
            "So this thing is guys cancel out and what you have is a sum of the Lt JS Times the indicator that Jake was I.",
            "So there's just Lt off I.",
            "So that's it.",
            "Now we have an unbiased estimate, so we can start celebrating, but we have to be a little bit careful, because if you know about martingales then you will know that that we can.",
            "Again, the key will be to estimate the cumulative difference between true loss and estimated loss.",
            "But this things can go wrong because we don't have a good bound on this.",
            "This can be really, really big.",
            "If the probability that we used to assign aissati, it was very small.",
            "OK, so if you go to if you happen to choose a restaurant that was really bad in the past and has a tiny tiny probability then then you will get an estimate which is huge.",
            "So we have to control that somehow."
        ],
        [
            "And these guys are which is a Bianchi Freund and Schapire in well they published this paper in 2002, but actually the first version of the paper was out way before.",
            "They said that OK, let's do that, but let's mix, let's let's mix our our probability distribution with.",
            "With a uniform.",
            "OK, so here's how it goes.",
            "Choose action number I with from a distribution that works like this.",
            "First I flip a coin this coin with probably the gamma says.",
            "Fail with probability 1 minus gamma.",
            "It will be head if head comes up, then I will just use the exponentially weighted average forecast are based on these estimated losses.",
            "If there comes up then I will just use completely random.",
            "Choice, so we don't need a small probability.",
            "I will just.",
            "This is called exploration and this is exploitation here.",
            "If head comes up then then I will use my accumulated information to choose what I think is optimal.",
            "The exponentially weighted forecaster should be close to optimal.",
            "But if this comes up then I just I just choose completely randomly.",
            "And why is this good?",
            "Because this if I add this term then I can guarantee that the all these probabilities will be greater than gamma divided by N. OK, so this parameter gamma is there to make sure that these estimates are.",
            "Good enough that the martingale inequalities will break.",
            "So what this suggests is that even though you go to restaurant and you hate it after awhile, you should go back so you always have to.",
            "You always have to allow some some chance that they change the chef right?",
            "And because you never know since since we are we allow the adversary full power, the adversary can see that that you assign a very very tiny probability to, so he knows that you will never go there, so he.",
            "It's there for Andrea the best chef in the world, and then then you're screwed.",
            "So once in awhile we have to go back and very quickly you will real.",
            "If you do this randomly then very quickly you will.",
            "You will realize that that that action was indeed very good.",
            "OK, so this just somehow forces that every action is sampled sufficiently often, and we need that for good estimates of the cumulative probabilities.",
            "OK, so if you work this out."
        ],
        [
            "Then you get this wonderful regret bound which shows that I just said the expected value.",
            "But this is in fact true with high probability.",
            "If we compare the well, I can actually put capital I here.",
            "I should have put capitalize.",
            "It doesn't matter.",
            "But so the regret, which is the.",
            "The difference between the loss.",
            "And the best possible loss that we could have chosen if we had known in advance what the best restaurant was, is bounded by some constant and square root of capital and log N / N. So this was."
        ],
        [
            "This result of.",
            "Our Chizar Bianchi Freund and schapire.",
            "This is how happy they were when they found this result.",
            "But this was this was in 95 or 96 or something like that and it was completely unexpected.",
            "It it was so unexpected that their paper was rejected saying that this cannot possibly be true and it took like 7 years at the end.",
            "They published this very well but but they had to fight to convince the referees.",
            "Then this is possible.",
            "'cause if you're not used to this type of arguments, then.",
            "It's really mind boggling, so how the losses are completely arbitrary?",
            "I only see the my own loss, so how can how can randomization do something like this well?"
        ],
        [
            "Now.",
            "This is close to the best bound of."
        ],
        [
            "Of these guys is close to the best possible.",
            "So they had capital log."
        ],
        [
            "But the natural easy lower bounds tell you square root of capital and over North notice that it's in."
        ],
        [
            "Written that.",
            "In either case, we don't have that really nice dependence on the number of actions as before, right before we had logged over.",
            "Now we have this North here, so that means that now we can handle.",
            "10s of thousands of restaurants anymore so and that's a problem in Barcelona at least so.",
            "And you can get.",
            "You can get rid of this log, but you cannot get rid of this, so, but this is again natural, because if you think about it, this was our.",
            "This is our loss in the full information case and now.",
            "So at that time for the full information case we have after time North Little North, we have little N times capital and labels that we have learned.",
            "That's how many losses we know.",
            "Now we have only capital N part of it because each at each time we have only one.",
            "So.",
            "We somehow expect that that little end will be replaced by little and divided by capital N. So this somehow looks like a natural bound."
        ],
        [
            "And then it was.",
            "It was an open."
        ],
        [
            "Problem for a long time, which one of these two is the right answer?",
            "Can you get rid of the login or can you?"
        ],
        [
            "Or is it?",
            "Is it necessary?",
            "Can you improve the lower bound?",
            "What this is really for?",
            "For online learning geeks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I guess we can start so my name is Gabor Lugosi and.",
                    "label": 1
                },
                {
                    "sent": "I'll tell you a little bit about bandit problems.",
                    "label": 0
                },
                {
                    "sent": "Not all types of bandit problems, but one kind that's that's usually called adversarial bandit problem.",
                    "label": 1
                },
                {
                    "sent": "I'll tell you exactly what it is, and I will show you a few variants of this and then show you maybe a little bit of insight of what.",
                    "label": 0
                },
                {
                    "sent": "One branch of the research has been recent.",
                    "label": 0
                },
                {
                    "sent": "Research has been what type of problems?",
                    "label": 0
                },
                {
                    "sent": "Recent research has been interested in so.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for four.",
                    "label": 0
                },
                {
                    "sent": "What about the last change of tutorials?",
                    "label": 0
                },
                {
                    "sent": "But there was a health problem with the with the the.",
                    "label": 0
                },
                {
                    "sent": "Everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm like a good bench player.",
                    "label": 0
                },
                {
                    "sent": "When the coach calls me, I'm ready, ready to play so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK. All the problems that I'm going to tell you about today are about online prediction, where the model can be given in form of a repeated play between between a forecaster and an environment.",
                    "label": 0
                },
                {
                    "sent": "So we are the forecaster.",
                    "label": 0
                },
                {
                    "sent": "Maybe we are the forecaster and the environment is is our our adversary and the environment is the one who's trying to play against us and the.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The game is played like this at each round.",
                    "label": 1
                },
                {
                    "sent": "Forecast for us.",
                    "label": 1
                },
                {
                    "sent": "We choose an action and the action is between is takes finite values.",
                    "label": 0
                },
                {
                    "sent": "It's in a set.",
                    "label": 0
                },
                {
                    "sent": "Of cording",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "City Capital North and sometimes in online learning.",
                    "label": 0
                },
                {
                    "sent": "These actions are also called experts, but I will maybe called codem actions.",
                    "label": 1
                },
                {
                    "sent": "It's at least because for notation I'm going to use somehow it is more natural to call this actions, but this is the framework that has also been known as prediction with expert advice.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So at each time we choose an action and at the same time the environment assigns a loss to each action, OK?",
                    "label": 1
                },
                {
                    "sent": "So these losses I will only assume that they are.",
                    "label": 0
                },
                {
                    "sent": "They are bounded, so I can.",
                    "label": 0
                },
                {
                    "sent": "I might as well assume that they are between zero and one, but I don't want to assume anything about them.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is in when we talk about adversary adversarial problems.",
                    "label": 0
                },
                {
                    "sent": "The main assumption is that these.",
                    "label": 0
                },
                {
                    "sent": "Losses can be completely anything OK, and in fact these losses can also depend on what the forecaster did in the past.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to describe the model in every detail, but I think you will understand what I'm talking about.",
                    "label": 1
                },
                {
                    "sent": "OK, so the environment chooses losses and I don't want to assume any stochastic or strategic behavior from part of the environment.",
                    "label": 0
                },
                {
                    "sent": "He's completely free to choose the losses anyway.",
                    "label": 0
                },
                {
                    "sent": "He likes OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then my loss is just the loss that was assigned to the action I chose.",
                    "label": 0
                },
                {
                    "sent": "OK, so these two things happen at the same time and this is what I lose all right.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what's my goal?",
                    "label": 0
                },
                {
                    "sent": "So if it's if these losses can be completely arbitrary, then then then we have to careful we have to be careful about how we define of our goals because it's very easy to come up with problems that obviously don't have a good solution.",
                    "label": 0
                },
                {
                    "sent": "So a meaningful way of setting up this problem is that we're trying to minimize what's known the regret.",
                    "label": 1
                },
                {
                    "sent": "So what's the regret this is?",
                    "label": 0
                },
                {
                    "sent": "The loss.",
                    "label": 0
                },
                {
                    "sent": "Of of the forecaster is my loss accumulated during the end periods of the place, so I will assume that this game is played during little N rounds, and let's just assume for the sake of concreteness, that this little and is known by me.",
                    "label": 0
                },
                {
                    "sent": "So the forecaster knows that this game is going to be played for one million rounds.",
                    "label": 1
                },
                {
                    "sent": "OK, this is not an essential assumption, but let's just assume this so I know in advance that I'm going to play for a million rounds and my goal is to eventually.",
                    "label": 1
                },
                {
                    "sent": "Minimize the loss.",
                    "label": 0
                },
                {
                    "sent": "I suffer.",
                    "label": 0
                },
                {
                    "sent": "This is the so called cumulative loss.",
                    "label": 0
                },
                {
                    "sent": "This is the loss I accumulate during the rounds of the play and I want to.",
                    "label": 0
                },
                {
                    "sent": "I want to compare this to the loss of the best possible action.",
                    "label": 0
                },
                {
                    "sent": "So for every little I hear, this sum is just the loss that that forecaster that had chosen little I all the time would have suffered so if I had known what the best constant action was.",
                    "label": 0
                },
                {
                    "sent": "I could have achieved this loss.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Right, so for example, I want to invest in the stock market.",
                    "label": 0
                },
                {
                    "sent": "These are the impossible, impossible.",
                    "label": 0
                },
                {
                    "sent": "The impossible actions and at time T. This is how much I lose if I if I if I bet on Coca Cola or IBM or Yahoo.",
                    "label": 0
                },
                {
                    "sent": "OK and if I had known advance what the best stock was then I would have been able to achieve this loss.",
                    "label": 0
                },
                {
                    "sent": "OK now I want my loss to be not too far from that.",
                    "label": 1
                },
                {
                    "sent": "This is how we set up the online prediction problem.",
                    "label": 0
                },
                {
                    "sent": "This and I divide by N so that this.",
                    "label": 0
                },
                {
                    "sent": "Number is always between zero and one OK, so this is the regret and all my talk is about this quantity.",
                    "label": 0
                },
                {
                    "sent": "OK, how can we come up with strategies in which in which we can minimize?",
                    "label": 0
                },
                {
                    "sent": "This regret make this as small as possible.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, no the notation I chose is is maybe not very standard in many papers online learning you will see that there is a loss function and I is the action I pay.",
                    "label": 1
                },
                {
                    "sent": "I play and there's some outcome sequence, so there's an outcome sequence that I want to predict and if I take an action I, then if there's given some kind of loss function, then this is the loss of your software.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can think about this problem is we are trying to predict.",
                    "label": 0
                },
                {
                    "sent": "Some sequence of outcomes.",
                    "label": 0
                },
                {
                    "sent": "Let's say we're trying to predict what the weather will be like tomorrow and then as.",
                    "label": 0
                },
                {
                    "sent": "I is is whether I take an umbrella or not, so there's a loss associated to whether it's sunny and I take a number lower.",
                    "label": 0
                },
                {
                    "sent": "It's it's, it's rainy.",
                    "label": 0
                },
                {
                    "sent": "I didn't take an umbrella and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can think about this problem that we're trying to.",
                    "label": 0
                },
                {
                    "sent": "We're trying to predict an outcome sequence when we are given a loss function, and I want to I want to act as well as if I had known the whole weather sequence.",
                    "label": 1
                },
                {
                    "sent": "The whole sequence of outcomes in advance, and if I could have been able to choose the best possible action, the best possible constant action.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's another way of writing up this problem.",
                    "label": 0
                },
                {
                    "sent": "So LTI this is just loss associated to the to the action can may be given in some applications, my loss function and some outcome sequence, But this is somehow more general.",
                    "label": 0
                },
                {
                    "sent": "Or actually they are completely equivalent ways of writing the problem, OK?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the question is, is it possible to make this regret go to 0?",
                    "label": 0
                },
                {
                    "sent": "No matter what the loss assignments are, so our adversaries has no restrictions.",
                    "label": 0
                },
                {
                    "sent": "He can choose the loss anyway he wants.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, it's easy to see that no, the answer is no, and here's a very little very simple example.",
                    "label": 0
                },
                {
                    "sent": "Take two actions.",
                    "label": 0
                },
                {
                    "sent": "We have two actions, and the losses are like this, so the remember the adversary can do anything so the adversary can.",
                    "label": 0
                },
                {
                    "sent": "Actually know what my algorithm is, how I assign my action so the adversary can always choose zero if I say two, sorry, they assign loss 0 to the action one.",
                    "label": 0
                },
                {
                    "sent": "If my prediction is 2 and maximum loss.",
                    "label": 0
                },
                {
                    "sent": "To my prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, so the adversary can always set the losses such that so that I lose each time the maximum possible.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if the loss right?",
                    "label": 0
                },
                {
                    "sent": "So this is the loss assigned to action one, which depends on on the forecasters prediction, and this is the loss assigned to action tool, which is just small minus the law section.",
                    "label": 0
                },
                {
                    "sent": "So the losses are zeros or ones.",
                    "label": 0
                },
                {
                    "sent": "And whenever I choose action number one then that action gets at the maximum loss if.",
                    "label": 0
                },
                {
                    "sent": "If I choose that action number 2, the Death action gets the big loss, so in that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In in the in the if the losses are this and remember I I want to be prepared to all possible assignments, so I must be prepared to the loss assignments that are that are depend on my predictions.",
                    "label": 0
                },
                {
                    "sent": "So in this case my losses North at each time I have the maximum loss, but the best of the two actions obviously has because because one one loss is just one minus the other, so the better of the two is always has always accumulated.",
                    "label": 0
                },
                {
                    "sent": "Last, less than half.",
                    "label": 0
                },
                {
                    "sent": "So the difference between 2:00 is at Lee.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "East and half.",
                    "label": 0
                },
                {
                    "sent": "So if I normal normalized and the regret is bigger than 1/2, OK.",
                    "label": 0
                },
                {
                    "sent": "So then then you can go back.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's see what we can do.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's the problem.",
                    "label": 0
                },
                {
                    "sent": "It seems like it is.",
                    "label": 0
                },
                {
                    "sent": "This is not a meaningful setting of the problem I. I cannot be prepared to all possible sequences, so one way out is that you can try to assume that these sequence of losses or the sequence of loss vectors or the sequence of outcomes follows some kind of stochastic process.",
                    "label": 0
                },
                {
                    "sent": "So you can try to come up with with stochastic models of the stock market and try to tailor your predictor for that right.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is a huge area of research classic from classical statistics to modern statistical learning theory.",
                    "label": 0
                },
                {
                    "sent": "Lots of problems are dealt like this, but we don't want to do this.",
                    "label": 0
                },
                {
                    "sent": "We're trying to insist on.",
                    "label": 0
                },
                {
                    "sent": "The outcomes to be completely arbitrary, and there are reasons for this because there are many applications in which it is really, really difficult to model the sequence of losses.",
                    "label": 0
                },
                {
                    "sent": "So what do you do?",
                    "label": 0
                },
                {
                    "sent": "Well, let's let's give a little bit more power to the, to the forecaster and that.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is randomization so?",
                    "label": 0
                },
                {
                    "sent": "So the we will allow the forecaster to randomize.",
                    "label": 0
                },
                {
                    "sent": "So in in the previous.",
                    "label": 0
                },
                {
                    "sent": "In this example, the adversary was allowed to look at what the forecaster does now from now on.",
                    "label": 0
                },
                {
                    "sent": "The forecaster will have it coin, or rather the forecaster.",
                    "label": 0
                },
                {
                    "sent": "We have a random number generator, and even though the adversary is allowed to look at what probability distribution the forecaster uses the.",
                    "label": 0
                },
                {
                    "sent": "Mercer is not allowed to look at the outcome of the of the random number generator.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the additional power we have.",
                    "label": 0
                },
                {
                    "sent": "We have a secret random number generator and we can randomize anyway.",
                    "label": 0
                },
                {
                    "sent": "We like from that.",
                    "label": 0
                },
                {
                    "sent": "Otherwise the adversary sees in our head, right?",
                    "label": 0
                },
                {
                    "sent": "You can read our minds, but he cannot read the outcome of the coin flips.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way this the problem is set up now is at time T the forecaster.",
                    "label": 1
                },
                {
                    "sent": "Now instead of choosing an action, the forecaster chooses the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Over the set of actions and I write PT minus one here because this can depend on everything that happened up to time T -- 1.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're of course following the past.",
                    "label": 0
                },
                {
                    "sent": "We're looking at what happened up to now and as a function of that we are allowed to choose a probability distribution on the set of the actions.",
                    "label": 0
                },
                {
                    "sent": "OK, and now we can randomize according to this probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So the adversary can see this vector, but the adversary does not see capital it, which is the random variable whose distribution is this OK?",
                    "label": 0
                },
                {
                    "sent": "All right now there are many variants of the model.",
                    "label": 0
                },
                {
                    "sent": "In the simplest model, the losses are all observed by the forecaster.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is called the full information model, so the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go back so the game is played like this.",
                    "label": 0
                },
                {
                    "sent": "The forecaster now chooses a probability distribution.",
                    "label": 1
                },
                {
                    "sent": "At the same time, the environment chooses the losses.",
                    "label": 1
                },
                {
                    "sent": "Now the forecaster chooses a random variable I subte based on.",
                    "label": 0
                },
                {
                    "sent": "According to that probability distribution that the forecaster had determined.",
                    "label": 0
                },
                {
                    "sent": "And then the forecaster suffers this loss.",
                    "label": 0
                },
                {
                    "sent": "So this loss now is it is a random variable.",
                    "label": 0
                },
                {
                    "sent": "It depends on our randomizations.",
                    "label": 0
                },
                {
                    "sent": "Now there are many variants of this problem, depending on what.",
                    "label": 0
                },
                {
                    "sent": "What is the information that the forecaster has access to.",
                    "label": 0
                },
                {
                    "sent": "In the simplest case, whenever the.",
                    "label": 0
                },
                {
                    "sent": "The forecaster suffers this loss.",
                    "label": 1
                },
                {
                    "sent": "All these losses are revealed to the forecaster.",
                    "label": 0
                },
                {
                    "sent": "This is called the full information case.",
                    "label": 0
                },
                {
                    "sent": "So at every step when after we take an action, we are told how much we would have lost if we had chosen some other action OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the so-called full information set up, and this is already.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A very interesting problem.",
                    "label": 0
                },
                {
                    "sent": "So each time we are told what the losses, what the real losses were and then then we have to take another action.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this type of problems have have.",
                    "label": 0
                },
                {
                    "sent": "A long history going back to the 50s.",
                    "label": 0
                },
                {
                    "sent": "So it started in.",
                    "label": 0
                },
                {
                    "sent": "In game theory and in statistics, in the theory of sequential decisions in game theory, this type of problems have many applications, because this is a game, this is a repeated play game, so the outcomes you can think about the loss, the outcomes as the action of our opponents, or the action of our opponent.",
                    "label": 0
                },
                {
                    "sent": "So we take an action, the opponent takes an action, and then we see what.",
                    "label": 0
                },
                {
                    "sent": "Then I see my pay offs so.",
                    "label": 0
                },
                {
                    "sent": "So in game theory this type of problems have been studied.",
                    "label": 1
                },
                {
                    "sent": "In information theory already in sixty 70s, going back to Z Vancouver.",
                    "label": 0
                },
                {
                    "sent": "When?",
                    "label": 0
                },
                {
                    "sent": "For example, if you want to compress a sequence of zeros and ones, then you have to predict it and then these are some models that are very very closely related to the models that I just told you about the beginnings are are in statistics in the theory of sequential decisions.",
                    "label": 0
                },
                {
                    "sent": "And now all this type of problems have been big in learning theory of course.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, alright so.",
                    "label": 0
                },
                {
                    "sent": "This is this is the big inning Hannon black backwards.",
                    "label": 0
                },
                {
                    "sent": "So these were the two guys who realized that if we if we let the forecaster randomized then the forecaster can achieve a regret that goes to 0.",
                    "label": 0
                },
                {
                    "sent": "So this is very sharp sharp contrast to what we had when when we weren't allowed to randomize.",
                    "label": 0
                },
                {
                    "sent": "So just giving you this little extra power, we can already drive the regret to zero no matter what the outcomes are, no matter what the what the law sequences.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a classical result and the first proofs were not.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very simple, these are.",
                    "label": 0
                },
                {
                    "sent": "This is Hannon and this is Blackwell.",
                    "label": 0
                },
                {
                    "sent": "He just died this summer and I'm not sure what happened to Hannah.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will I will.",
                    "label": 0
                },
                {
                    "sent": "I will give you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I won't show you many proofs in this talk, but I will give you the proof of this OK, because because everything is based on on how it goes, I will give you 1 proof of this and which is which is much newer than than their original proofs.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And and very simple, and you can teach this easily.",
                    "label": 0
                },
                {
                    "sent": "So the main idea is to introduce the so-called expected loss.",
                    "label": 1
                },
                {
                    "sent": "So the expected loss is what you what you think it is.",
                    "label": 0
                },
                {
                    "sent": "So we just take.",
                    "label": 0
                },
                {
                    "sent": "Remember, we choose.",
                    "label": 0
                },
                {
                    "sent": "Action number I with probability PIT.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "The this is the loss associated to action number I.",
                    "label": 0
                },
                {
                    "sent": "So if we take the expected value with respect to the distribution, so with respect to the randomizing distribution, this is just the expected value of my loss, OK?",
                    "label": 0
                },
                {
                    "sent": "And well, you can write this like esapi esapi, because because it's really a conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Remember this PIT minus one?",
                    "label": 0
                },
                {
                    "sent": "This can depend on what happened in the past, so this is really random, because in the past we had, we had all these random losses and random things happening.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter if this is a condition of conditional expected value, right?",
                    "label": 1
                },
                {
                    "sent": "So given the past, the forecaster chooses this probability distribution, and according to that.",
                    "label": 0
                },
                {
                    "sent": "Probably the distribution.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The expected value of the loss now.",
                    "label": 1
                },
                {
                    "sent": "But then we have a very nice tool.",
                    "label": 0
                },
                {
                    "sent": "The theory of martingales.",
                    "label": 0
                },
                {
                    "sent": "That's a classical topic in probability, and it tells us that if this difference.",
                    "label": 0
                },
                {
                    "sent": "So LLTIT, that's that's our random loss and this is just this condition, conditional expected value.",
                    "label": 0
                },
                {
                    "sent": "So these are called the conditional expectation of this guy given the past equals this guy.",
                    "label": 0
                },
                {
                    "sent": "Now if you have sums of differences of this type, these are called martingale differences.",
                    "label": 0
                },
                {
                    "sent": "Then we have something that's called the Martindale and then loaf large numbers.",
                    "label": 0
                },
                {
                    "sent": "Works just as.",
                    "label": 0
                },
                {
                    "sent": "You get something very, very similar, but.",
                    "label": 0
                },
                {
                    "sent": "As if you had sums of independent random variables, these are not independent because IT depends.",
                    "label": 0
                },
                {
                    "sent": "Depends on the past, but they are uncorrelated.",
                    "label": 0
                },
                {
                    "sent": "This is a martingale.",
                    "label": 0
                },
                {
                    "sent": "OK so if you have some sort of martingale differences and everything is nice and bounded because I just assume that all the losses are between zero and one then this.",
                    "label": 0
                },
                {
                    "sent": "Divided by N converges to zero rapidly.",
                    "label": 0
                },
                {
                    "sent": "It's probably this is greater than Delta, is something like 1 / sqrt N times log one over Delta OK, just as if you have sums of independent random variables, so that's nice.",
                    "label": 0
                },
                {
                    "sent": "That means that we don't have to worry about our random losses anymore.",
                    "label": 0
                },
                {
                    "sent": "We can replace everything by by the expected losses.",
                    "label": 0
                },
                {
                    "sent": "OK, so if remember.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you go back to the definition of the regret, now we can replace this sum by the sum of the expected losses.",
                    "label": 0
                },
                {
                    "sent": "We're making just a very, very small mistake.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The mistake we are making is of the order of 1 / sqrt N that's peanuts.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it suffices to study this difference instead of the true regret.",
                    "label": 1
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "Cumulative expected loss.",
                    "label": 0
                },
                {
                    "sent": "And this is the optimum loss.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, I haven't told you what the the forecaster does.",
                    "label": 0
                },
                {
                    "sent": "So this whole thing is true no matter what we do.",
                    "label": 0
                },
                {
                    "sent": "The expected loss end and that rules will always be close.",
                    "label": 0
                },
                {
                    "sent": "This is independent of what the fork.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's algorithms so.",
                    "label": 0
                },
                {
                    "sent": "What should the forecaster do well?",
                    "label": 0
                },
                {
                    "sent": "A natural thing to try is try to favor actions that have worked better in the past.",
                    "label": 0
                },
                {
                    "sent": "Everybody would agree that that's a good idea, and the Wolf can littlestone and warmuth.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Said, that's why not use this exponential form.",
                    "label": 0
                },
                {
                    "sent": "OK, this is called the exponentially weighted average forecaster, so the probability that we assign to action number I.",
                    "label": 0
                },
                {
                    "sent": "Is proportional to the negative exponential of.",
                    "label": 0
                },
                {
                    "sent": "The cumulative loss of action number I up to yesterday.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is how much loss we would have suffered if we had chosen action number I all the time.",
                    "label": 0
                },
                {
                    "sent": "So if this is big then we will penalize action number I.",
                    "label": 0
                },
                {
                    "sent": "That's not a good action.",
                    "label": 0
                },
                {
                    "sent": "We will give it a very small.",
                    "label": 0
                },
                {
                    "sent": "Probably that's where the negative sign comes downstairs.",
                    "label": 0
                },
                {
                    "sent": "This is just a normalization that forces the speed to be a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So it's a very very simple idea.",
                    "label": 0
                },
                {
                    "sent": "This number error here is just a parameter that we will set.",
                    "label": 0
                },
                {
                    "sent": "So that so that we get the best possible bounds OK?",
                    "label": 0
                },
                {
                    "sent": "So this is the exponentially weighted average forecaster, and everything in this talk is based on this.",
                    "label": 0
                },
                {
                    "sent": "It will be we will see many variants of of the exponentially weighted.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bridge forecaster and.",
                    "label": 0
                },
                {
                    "sent": "And the theorem that you can get these guys proved and many variants of this is that the regret of this forecaster is.",
                    "label": 0
                },
                {
                    "sent": "This should be less than or equal to the square root of log capital N / 2 N, so this is great news.",
                    "label": 0
                },
                {
                    "sent": "Well, you get this if data is chosen like this.",
                    "label": 0
                },
                {
                    "sent": "OK. That's just that's just an optimal way of of let's just the number which optimizes the bound that I will show you, and that leads to this upper bound.",
                    "label": 0
                },
                {
                    "sent": "So this is great news because as little Lang goes to 0.",
                    "label": 0
                },
                {
                    "sent": "This goes to zero as one over square root of.",
                    "label": 0
                },
                {
                    "sent": "That's the same order of magnitude as as the error that we got from.",
                    "label": 0
                },
                {
                    "sent": "From from from the Martingale convergence theorem.",
                    "label": 0
                },
                {
                    "sent": "So this is really the main term here, and there's the dependence on the number of actions is very nice, it's only longer it's square root of log North.",
                    "label": 0
                },
                {
                    "sent": "So this means that we can really have huge we can deal with a huge number of actions many times in applications actions are not really actions, But button algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so so if you want if you want to predict the weather then you can have a huge bag of algorithms that predict the weather.",
                    "label": 0
                },
                {
                    "sent": "And those are your actions, so every time you just pick an algorithm and you and and use that algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "So you can have something that's based on based on graphical models.",
                    "label": 0
                },
                {
                    "sent": "Something else that's based on Markov models, something else, so you can have a big variety of algorithms, and each time we just pick one of those according to the exponentially weighted average.",
                    "label": 0
                },
                {
                    "sent": "Distribution.",
                    "label": 0
                },
                {
                    "sent": "Forecaster and this capital can be huge.",
                    "label": 0
                },
                {
                    "sent": "We can have a huge bag of them, and this can still be small, and we will be able to predict as well as the best of them, OK?",
                    "label": 0
                },
                {
                    "sent": "So this is really nice.",
                    "label": 0
                },
                {
                    "sent": "We are very happy about this log in and then this will also be a recurring theme of this talk that in some other models we will run into troubles when we want to handle very very very big classes of classes of actions.",
                    "label": 0
                },
                {
                    "sent": "So I will show you the proof of this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "Capital LIT is just the cumulative loss of action number I of the time T. OK, that's just notation and.",
                    "label": 0
                },
                {
                    "sent": "I just tried down.",
                    "label": 0
                },
                {
                    "sent": "I just denote by little WITE to the minus 8 times this.",
                    "label": 0
                },
                {
                    "sent": "So this is what we call wait.",
                    "label": 0
                },
                {
                    "sent": "These are the weights that appear in the definition, so this is just WIT minus one.",
                    "label": 0
                },
                {
                    "sent": "That's just the weight that defines this probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So these are the weight weights and W capital W is just the sum of the weights at time T. OK, so the proof is based on looking at the evolution of this quantity WT.",
                    "label": 0
                },
                {
                    "sent": "We also call this a potential function somehow sometimes, so W 0 = N because at the time zero these guys are all equal to the cumulative losses equals 0.",
                    "label": 0
                },
                {
                    "sent": "So this sum 1 N times.",
                    "label": 0
                },
                {
                    "sent": "So that's capitalized.",
                    "label": 0
                },
                {
                    "sent": "So at Times 0 W, capital W equals.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "North and now we're looking at the log of the ratio of the sum of the weights at time North and at times zero and we will look at it two different ways, so we will get.",
                    "label": 0
                },
                {
                    "sent": "Very simple, lower bound in the very simple simple upper bound, and if we compare them then then we get the we get our result.",
                    "label": 0
                },
                {
                    "sent": "So there's the strategy.",
                    "label": 0
                },
                {
                    "sent": "So what's the log of this ratio?",
                    "label": 0
                },
                {
                    "sent": "Well this is just log of WN minus log of.",
                    "label": 0
                },
                {
                    "sent": "Zero, so that's log in and this is just the definition.",
                    "label": 0
                },
                {
                    "sent": "So there's the definition and the only inequality on this slide is says that the if you have non negative numbers then the sum is greater than the biggest.",
                    "label": 0
                },
                {
                    "sent": "The largest term in the sum.",
                    "label": 0
                },
                {
                    "sent": "So this is greater than the maximum since this maximum upstairs becomes a minimum because E to the minus positive numbers decreasing function.",
                    "label": 0
                },
                {
                    "sent": "So what we have up here is now the loss of the best action, and that's what we get here.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is minus 8 times the loss of the best action minus log capital N. OK, now let's.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look at an upper bound for for this ratio, and we will write this ratio.",
                    "label": 0
                },
                {
                    "sent": "This ratio as the sum of the log WT divided by WT minus ones.",
                    "label": 0
                },
                {
                    "sent": "It's a telescoping sum, OK?",
                    "label": 0
                },
                {
                    "sent": "So we decompose this as the sum of N terms and these in terms are just these guys.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you look at two neighboring time instances then the log of this ratio?",
                    "label": 0
                },
                {
                    "sent": "Well, we can just write it down.",
                    "label": 0
                },
                {
                    "sent": "What's how does WWT depend on WIT minus one?",
                    "label": 0
                },
                {
                    "sent": "Well, we just multiplied it by E to the area times the loss at time T, right?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remember that just is this definition, right?",
                    "label": 0
                },
                {
                    "sent": "The WIT is is the sum of the cumulative losses.",
                    "label": 0
                },
                {
                    "sent": "So at the next term this is just multiplied by E to the minus eight times the new loss.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's what's written here.",
                    "label": 0
                },
                {
                    "sent": "This guy upstairs is WIT and I wrote it this way, Becausw now this becomes an expected value.",
                    "label": 0
                },
                {
                    "sent": "This is an expected value according to this probability distribution given by the exponentially weighted average.",
                    "label": 0
                },
                {
                    "sent": "Off this exponential now there's a very.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice and famous inequality due to hub thing from 63, which says that if we if I have abounded random variable between zero and one then this is called the moment generating function.",
                    "label": 0
                },
                {
                    "sent": "The log of the moment generating function which is also called a cumulative generating function, is always less than 80 times the expected value plus error squared divided by 8.",
                    "label": 0
                },
                {
                    "sent": "OK, this guy is always greater than eight times the expected value.",
                    "label": 0
                },
                {
                    "sent": "That's just Jensen's inequality.",
                    "label": 0
                },
                {
                    "sent": "So it's between 8 times.",
                    "label": 0
                },
                {
                    "sent": "The expected value and data expected value plus error squared divided by 8, so that's how things inequality.",
                    "label": 0
                },
                {
                    "sent": "So this guy has exactly this form.",
                    "label": 0
                },
                {
                    "sent": "It's the expect, it's a moment generating function of this random variable that takes value Y to the that takes value LP I with probability this probability in WI T -- 1 divided normalized.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you use that then this is the expected value right?",
                    "label": 0
                },
                {
                    "sent": "And this is this 8 / 8, But the expected value is just, it's just the loss of.",
                    "label": 0
                },
                {
                    "sent": "Of the forecaster, because this probability distribution is just.",
                    "label": 0
                },
                {
                    "sent": "Is just.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where is it this guy right?",
                    "label": 0
                },
                {
                    "sent": "This is WIT minus one normalized, so that's exactly are are probably to distribute.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so the expected value of the loss.",
                    "label": 0
                },
                {
                    "sent": "With respect to our probability distribution is just our expected loss.",
                    "label": 0
                },
                {
                    "sent": "OK, now we can sum this.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is this inequality?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And times.",
                    "label": 0
                },
                {
                    "sent": "And we get.",
                    "label": 0
                },
                {
                    "sent": "So this is what we just proved.",
                    "label": 0
                },
                {
                    "sent": "So if we sum it N times then we get the log of W N / 0 is just the sum.",
                    "label": 0
                },
                {
                    "sent": "Of the of the expected losses, that's our expected cumulative loss times N times this error turn.",
                    "label": 0
                },
                {
                    "sent": "So if you compare now we have an upper bound on this, and we had a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Remember which looked like minus eight times the best possible loss, and we had that log term.",
                    "label": 0
                },
                {
                    "sent": "So if we compare then we get this inequality.",
                    "label": 0
                },
                {
                    "sent": "OK, and now you can pick era to minimize this.",
                    "label": 0
                },
                {
                    "sent": "This guy here.",
                    "label": 0
                },
                {
                    "sent": "And if you pick error to be of the order 1 / sqrt N then then both terms are of the order of square root of North.",
                    "label": 0
                },
                {
                    "sent": "You divide by N and we're done OK.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This is the proof.",
                    "label": 0
                },
                {
                    "sent": "OK, so how good is this bound?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's let's look at it again, so it's what it says is that the regret the normalized regret is always bounded less than or equal to square root of log N / 2.",
                    "label": 0
                },
                {
                    "sent": "This is not a synthetic.",
                    "label": 0
                },
                {
                    "sent": "This is true for every little end and no matter what the outcome sequence is now, it turns out that this is pretty good.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's so good that you can do better, so this is the regret and this is our upper bound.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that there exists an assignment of assignment of losses such that this will be as close to the regret will be as close to the upper bound is possible.",
                    "label": 0
                },
                {
                    "sent": "So in fact the Supreme overall little lens, all capitals and all the assignments of this ratio is greater than one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this means that.",
                    "label": 0
                },
                {
                    "sent": "You cannot do better unless unless you're willing to assume something about the loss function or something about about the structure of the actions or something, and.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is very easy to prove.",
                    "label": 0
                },
                {
                    "sent": "Again, we can just randomize.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which let's just choose.",
                    "label": 0
                },
                {
                    "sent": "So we want to look at what the worst case regret is.",
                    "label": 0
                },
                {
                    "sent": "This is a regret.",
                    "label": 0
                },
                {
                    "sent": "And this we want we want to look at what the worst possible assignment is.",
                    "label": 0
                },
                {
                    "sent": "OK, So what if you were an adversary and you would?",
                    "label": 0
                },
                {
                    "sent": "You would want to set a really difficult problem to predict.",
                    "label": 0
                },
                {
                    "sent": "Then you would just assign the losses completely randomly.",
                    "label": 0
                },
                {
                    "sent": "Let's somehow intuitively it's clear that should be a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "So if all of these guys are let's define all of these as independent coin flips 0.",
                    "label": 0
                },
                {
                    "sent": "01's OK with probably 1/2 one, half symmetric so the Supreme then is greater than the average.",
                    "label": 0
                },
                {
                    "sent": "OK, that's that's.",
                    "label": 0
                },
                {
                    "sent": "That's always true, and it's easy to see that if these are really randomly 01, then no matter what you do, the loss of your loss will be 1/2.",
                    "label": 0
                },
                {
                    "sent": "OK. No matter what the forecaster is, the expected loss of the forecaster will be, will be 1/2, and the expected loss of every action will be also 1/2.",
                    "label": 0
                },
                {
                    "sent": "So this is just a binomial.",
                    "label": 0
                },
                {
                    "sent": "With parameters and 1/2 and so here we have N half and here we have the minimum of binomials and there's an expected value missing here.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have the half minus the expected value of the minimum of binomials.",
                    "label": 0
                },
                {
                    "sent": "Now if you take a normal approximation then you get this.",
                    "label": 0
                },
                {
                    "sent": "OK. Because this square root of.",
                    "label": 0
                },
                {
                    "sent": "Sqrt 2 login is just a maximum of an independent normals, so that's where this comes.",
                    "label": 0
                },
                {
                    "sent": "So simple normal approximation tells you that this is the best you can do.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's now slowly go into variants of the problem in which in which we don't have the forecaster does not have full information.",
                    "label": 1
                },
                {
                    "sent": "So now the 1st and easiest variant of this is what we call label efficient prediction.",
                    "label": 0
                },
                {
                    "sent": "So suppose that that getting.",
                    "label": 0
                },
                {
                    "sent": "Getting the true losses is expensive, so in the previous model, let me.",
                    "label": 0
                },
                {
                    "sent": "They go back to.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this, in the exponentially exponentially weighted forecaster, we assumed that.",
                    "label": 0
                },
                {
                    "sent": "The forecaster knows all of these guys, knows all the losses of all the actions of the time.",
                    "label": 0
                },
                {
                    "sent": "T -- 1 S The forecaster can look back and see the whole past.",
                    "label": 0
                },
                {
                    "sent": "OK, if in 1954 I would have bought Coca Cola and this is how much I would have one.",
                    "label": 0
                },
                {
                    "sent": "OK so this is full information but in some cases this is expensive to get.",
                    "label": 0
                },
                {
                    "sent": "The information is expensive so assume now that we have a budget.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The forecaster can only ask.",
                    "label": 0
                },
                {
                    "sent": "The for for the outcomes or losses at a limited number of times.",
                    "label": 0
                },
                {
                    "sent": "OK, so the forecaster can always decide whether we forecaster makes a prediction.",
                    "label": 0
                },
                {
                    "sent": "The outcomes are set, the forecaster suffers a loss, but the forecaster has no idea what the loss was or what the outcomes were.",
                    "label": 1
                },
                {
                    "sent": "OK, and he can decide to ask.",
                    "label": 1
                },
                {
                    "sent": "444 dolosis at his convenience but only M times where M is much, much, much, much smaller than.",
                    "label": 0
                },
                {
                    "sent": "OK, it sounds like this is very difficult because we have all those losses we want to predict as well as the best possible action, but we won't see the losses.",
                    "label": 0
                },
                {
                    "sent": "We're kind of blind.",
                    "label": 1
                },
                {
                    "sent": "We don't see the losses most of the time we can.",
                    "label": 1
                },
                {
                    "sent": "We can only take a tiny subsample and these are completely arbitrary again, so our adversary is really powerful.",
                    "label": 0
                },
                {
                    "sent": "We can do anything so it feels like this should be impossible, but again, random.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Azatian helps.",
                    "label": 0
                },
                {
                    "sent": "Very easy randomization, so here this is the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is how the game works.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "So the environment chooses the losses, they are not revealed, the forecaster chooses a probability distribution and draws in action according to this distribution.",
                    "label": 1
                },
                {
                    "sent": "This is just the same as before.",
                    "label": 1
                },
                {
                    "sent": "The forecaster has this loss, and this is the loss of action number I, but the forecaster is not told these values forecaster doesn't know.",
                    "label": 0
                },
                {
                    "sent": "Now, after this is done, the forecaster can decide.",
                    "label": 0
                },
                {
                    "sent": "To ask for all these values, the LLT eyes at any given moment of time, the forecast are considered now.",
                    "label": 0
                },
                {
                    "sent": "Please tell me I made this prediction.",
                    "label": 0
                },
                {
                    "sent": "Please tell me how much would I would have won if I had chosen any other any other action, but the forecaster is only allowed to do this M times in the whole sequence of North rounds and M is is very very very small.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea is again randomized just the simplest possible randomization that you can imagine will work the forecaster just.",
                    "label": 0
                },
                {
                    "sent": "Flips a coin.",
                    "label": 0
                },
                {
                    "sent": "And the coin will be a biased coin, so with probability M over North you will say when the coin is head, which is this probability, then the forecaster will say.",
                    "label": 0
                },
                {
                    "sent": "Now show me the the outcomes completely random and this is set such that on the average for forecaster will see about M. If you actually the probabilities of the of head should be a little bit less than this such that with very large high probability we are guaranteed that the forecaster doesn't ask for more than M times.",
                    "label": 1
                },
                {
                    "sent": "OK, but anyways this.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the idea, and so we have a Bernoulli random variable which is probability of success is epsilon, which will be a little bit smaller than M divided by North, and the forecaster will ask for the labels or the values of the losses if and only if.",
                    "label": 0
                },
                {
                    "sent": "Ed comes up.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, so now what should we do?",
                    "label": 0
                },
                {
                    "sent": "Well, the forecaster sees the labels now how should we use this information now?",
                    "label": 1
                },
                {
                    "sent": "One idea is this.",
                    "label": 0
                },
                {
                    "sent": "Let's define the estimated losses and this is a crucial trivial thing.",
                    "label": 1
                },
                {
                    "sent": "What I'm writing, but I'm writing it in a way that will be useful later, so we will see that.",
                    "label": 0
                },
                {
                    "sent": "Let's estimate.",
                    "label": 0
                },
                {
                    "sent": "The true losses.",
                    "label": 0
                },
                {
                    "sent": "By this Lt tilt quantity.",
                    "label": 0
                },
                {
                    "sent": "So what's Lt Field of I which it's just Lt of I divided by epsilon if.",
                    "label": 0
                },
                {
                    "sent": "If I see this label, if I if I if it comes up then I get to know this information so I can use it.",
                    "label": 0
                },
                {
                    "sent": "So I divide it by epsilon, which means that I blow it up.",
                    "label": 0
                },
                {
                    "sent": "And if I don't see then I just say that I estimate the loss to be 0.",
                    "label": 0
                },
                {
                    "sent": "So what is this?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that this is a good estimate of the true loss.",
                    "label": 0
                },
                {
                    "sent": "Good in what sense that it's unbiased?",
                    "label": 0
                },
                {
                    "sent": "What does unbiased means?",
                    "label": 0
                },
                {
                    "sent": "It means that if let's calculate the expected value of this with respect to the distribution MCT?",
                    "label": 0
                },
                {
                    "sent": "With probability epsilon.",
                    "label": 0
                },
                {
                    "sent": "Z = 1, So it's probably the epsilon.",
                    "label": 0
                },
                {
                    "sent": "This guy equals Lt divided by epsilon is probably 1 minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "This is equals 0, so the expected value of this is epsilon times this plus one minus epsilon epsilon times 0 which is just Lt of I. OK, so.",
                    "label": 0
                },
                {
                    "sent": "With respect to this newly introduced introduced randomizing distribution, the expected value of this guy is what it should be.",
                    "label": 0
                },
                {
                    "sent": "It's a good estimate in this very way.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Make sense.",
                    "label": 0
                },
                {
                    "sent": "But a little bit more is true, because I will do this many times as we do this N times.",
                    "label": 0
                },
                {
                    "sent": "So remember, if I want to use the exponentially weighted forecaster, then all that matters is that the sum of these guys.",
                    "label": 0
                },
                {
                    "sent": "And the sum if I do.",
                    "label": 0
                },
                {
                    "sent": "If I do this many times, the sum will be a sum of independent random variables with the right expected value.",
                    "label": 0
                },
                {
                    "sent": "So I expect that to be close to what it really should be.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "The proof is now you can do it, you just copy the previous proof and you make the modifications.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is, we just use the.",
                    "label": 1
                },
                {
                    "sent": "The exponentially weighted average forecaster, but with we replace the true losses which we don't know by these estimated losses, these are legally chosen.",
                    "label": 1
                },
                {
                    "sent": "These are chosen such that it only uses the information that we that's available.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The proof, so this is what you get.",
                    "label": 0
                },
                {
                    "sent": "You get that the regret will be bounded by something that looks exactly as before, except that North the sample size was now replaced by N. Which is of course we expect something.",
                    "label": 0
                },
                {
                    "sent": "Verse, but this is not worse.",
                    "label": 0
                },
                {
                    "sent": "So if M is large, even though it's not as large as North, this still goes to 0.",
                    "label": 0
                },
                {
                    "sent": "So somehow what we get here is is kind of what you expect.",
                    "label": 0
                },
                {
                    "sent": "If you think about how much information, how big a sample is available for us before we head North, now we have M that that's how much information we have.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and the proof is is as I said, it's simple we start bounding.",
                    "label": 0
                },
                {
                    "sent": "The the regret in terms of these estimated losses that you can do exactly as.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before and then we just use Martingale inequalities again.",
                    "label": 0
                },
                {
                    "sent": "Martin years, that's the main tool, because the difference between Lt of IT&L tilt T of PT.",
                    "label": 0
                },
                {
                    "sent": "That's again the conditional expectation of this given the past is the same as this, so these differences are.",
                    "label": 0
                },
                {
                    "sent": "Still smarting will differences there sums of martingale differences.",
                    "label": 0
                },
                {
                    "sent": "They are not as nice as before because because the these differences are not bounded.",
                    "label": 0
                },
                {
                    "sent": "Here's a change.",
                    "label": 0
                },
                {
                    "sent": "These differences are not bounded between between zero and one anymore, but they are bounded between zero and one over epsilon, right?",
                    "label": 0
                },
                {
                    "sent": "This can be as big as one over epsilon, which is very big.",
                    "label": 0
                },
                {
                    "sent": "So if you want.",
                    "label": 0
                },
                {
                    "sent": "If you want to apply Martin your differences that you have to be aware of that and then you will get worse bounds, that's where that's why we get something worse here.",
                    "label": 0
                },
                {
                    "sent": "OK, and similarly the L tilty eyes the sum of those minus.",
                    "label": 0
                },
                {
                    "sent": "So these are the estimated losses and these are the true losses.",
                    "label": 0
                },
                {
                    "sent": "The difference between these is again Martin Gale, so we can use.",
                    "label": 0
                },
                {
                    "sent": "You can use the same type of martingale inequalities.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's how you get this.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is labeled efficient prediction, and again you can show by an argument similar to the one in the full information case that this is basically the best you can do.",
                    "label": 0
                },
                {
                    "sent": "OK again, if you have to choose the losses.",
                    "label": 0
                },
                {
                    "sent": "Randomly, now you have to be a little bit more clever, but but again, this is not very difficult to show, so this is this is.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Truly the best you can hope for now.",
                    "label": 0
                },
                {
                    "sent": "The constant is not the best, not optimal anymore.",
                    "label": 0
                },
                {
                    "sent": "I don't know what the best constant is before.",
                    "label": 0
                },
                {
                    "sent": "The bond was exact up to two.",
                    "label": 0
                },
                {
                    "sent": "Even the constant term.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh no, I don't know what.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The best constant this year.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Alright, so now we're slowly arriving at at what the title of this talk is.",
                    "label": 0
                },
                {
                    "sent": "The Multi armed bandit problem, which is a similar online prediction problem.",
                    "label": 0
                },
                {
                    "sent": "But here the problem is the available information is different from the previous one.",
                    "label": 0
                },
                {
                    "sent": "Here the forecaster only observes the loss of his own action, but he doesn't know what.",
                    "label": 0
                },
                {
                    "sent": "He would have lost if he had chosen some other action.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So you arrive, you arrive at Barcelona and you know that there are.",
                    "label": 0
                },
                {
                    "sent": "10 restaurants in the in the vicinity.",
                    "label": 0
                },
                {
                    "sent": "So every day you go, you try.",
                    "label": 0
                },
                {
                    "sent": "And you know that you're going to be here for 20 years.",
                    "label": 0
                },
                {
                    "sent": "So you want to choose you want to eat?",
                    "label": 0
                },
                {
                    "sent": "Well, on a cumulative way.",
                    "label": 0
                },
                {
                    "sent": "So you want to eat as well as if you had known in advance for.",
                    "label": 0
                },
                {
                    "sent": "The best restaurant was OK, but if you go to a restaurant then you of course you know how valuate but you have no idea what would have happened if you had gone to the different one.",
                    "label": 0
                },
                {
                    "sent": "OK and there are many many many many problems that are.",
                    "label": 0
                },
                {
                    "sent": "That are like this, so you take an action that then you observe your own loss, but you cannot calculate what would have happened if you had done something else.",
                    "label": 0
                },
                {
                    "sent": "You go to a job interview, you reject it.",
                    "label": 0
                },
                {
                    "sent": "You know what happened now, but you don't know what would have happened if you accepted it.",
                    "label": 0
                },
                {
                    "sent": "So this happens all the time.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the first guy too.",
                    "label": 0
                },
                {
                    "sent": "Define this problem was Herbert Robinson in the 50s.",
                    "label": 0
                },
                {
                    "sent": "So he was.",
                    "label": 0
                },
                {
                    "sent": "He was one of the main figures when this whole started.",
                    "label": 0
                },
                {
                    "sent": "This type of prediction problems him and Blackwall and hang on.",
                    "label": 0
                },
                {
                    "sent": "So the name comes from.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a one armed bandit.",
                    "label": 0
                },
                {
                    "sent": "A1 Armed Bandit is just a slot machine that you pull and you get a reward.",
                    "label": 0
                },
                {
                    "sent": "You pull and you get the reward.",
                    "label": 0
                },
                {
                    "sent": "Now mostly armed bandit is when when you have many machines and you get to choose one at each time you know how much you get, but you don't know what would have happened if you had.",
                    "label": 0
                },
                {
                    "sent": "If you had chosen the others unless.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "C or something like this.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, so what's the trick here?",
                    "label": 0
                },
                {
                    "sent": "Again, the key is trying to estimate the loss.",
                    "label": 0
                },
                {
                    "sent": "OK, in the in the label efficient problem we want because we could come up with an estimate which was unbiased.",
                    "label": 0
                },
                {
                    "sent": "Unbiased in this very strange sense.",
                    "label": 0
                },
                {
                    "sent": "So unbiased estimate in statistics you observe a random variable and then you come up with A and you.",
                    "label": 0
                },
                {
                    "sent": "To estimate the expected value, then, then you're trying to come up with functions of this random variable such that the expected value is the same as that parameter.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's what unbiased estimate means here.",
                    "label": 0
                },
                {
                    "sent": "We are randomizing and unbiasedness is with respect to our our own randomization.",
                    "label": 0
                },
                {
                    "sent": "So we want we want to come up with a function of what's observable, which is Lt of IT.",
                    "label": 0
                },
                {
                    "sent": "Such that the expected value of that is just what it should be OK, and so here's here's a proposal.",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "So this is what I observe.",
                    "label": 0
                },
                {
                    "sent": "This is the loss, so I'm going to estimate the loss of action number I now.",
                    "label": 0
                },
                {
                    "sent": "So how do I do that if I observe action number I then it's easy.",
                    "label": 0
                },
                {
                    "sent": "Then I'll just assume I just assign Lt to it and if I don't then I say 0.",
                    "label": 0
                },
                {
                    "sent": "Just as before, right in the label deficient case, we had something very, very similar.",
                    "label": 0
                },
                {
                    "sent": "Where was it?",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It says here what we observed when we observe it.",
                    "label": 0
                },
                {
                    "sent": "We just say that if we don't, then we assign 0.",
                    "label": 0
                },
                {
                    "sent": "But then we had to normalize such that the expected value becomes what it should be.",
                    "label": 0
                },
                {
                    "sent": "Now this is the same.",
                    "label": 0
                },
                {
                    "sent": "It's the same.",
                    "label": 0
                },
                {
                    "sent": "The situation is the same here.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the outcome is if I if my prediction, which is chosen randomly from this distribution is equals I, then I know what to do.",
                    "label": 0
                },
                {
                    "sent": "Then then I will estimate the loss of action number.",
                    "label": 0
                },
                {
                    "sent": "I buy what I observe normalized and if I if I if every other action that I don't observe I just just assign 0.",
                    "label": 0
                },
                {
                    "sent": "So you go to the restaurant, then you know how well you eat.",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "You can update that.",
                    "label": 0
                },
                {
                    "sent": "Sure you can estimate the loss there, and for all other restaurants you assign 0.",
                    "label": 0
                },
                {
                    "sent": "Now what is this?",
                    "label": 0
                },
                {
                    "sent": "We divide by the probability that just the probability that.",
                    "label": 0
                },
                {
                    "sent": "Isofix is the.",
                    "label": 0
                },
                {
                    "sent": "It was our choice, right?",
                    "label": 0
                },
                {
                    "sent": "I remember P. At time T -- 1 is just the probability distribution, so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "Element of that vector of the probability vector that corresponds to the action that I happen to choose the restaurant I happen to choose so.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why is this unbiased?",
                    "label": 0
                },
                {
                    "sent": "That's very easy to see because the expected value of this?",
                    "label": 0
                },
                {
                    "sent": "What's that?",
                    "label": 0
                },
                {
                    "sent": "That's just the sum over all actions J goes from one to 312 North of.",
                    "label": 0
                },
                {
                    "sent": "So I choose action number J with this probability.",
                    "label": 0
                },
                {
                    "sent": "And this is just Lt till J.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is if the outcome is if the outcome is J then this is my estimate.",
                    "label": 0
                },
                {
                    "sent": "So this thing is guys cancel out and what you have is a sum of the Lt JS Times the indicator that Jake was I.",
                    "label": 0
                },
                {
                    "sent": "So there's just Lt off I.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Now we have an unbiased estimate, so we can start celebrating, but we have to be a little bit careful, because if you know about martingales then you will know that that we can.",
                    "label": 0
                },
                {
                    "sent": "Again, the key will be to estimate the cumulative difference between true loss and estimated loss.",
                    "label": 0
                },
                {
                    "sent": "But this things can go wrong because we don't have a good bound on this.",
                    "label": 0
                },
                {
                    "sent": "This can be really, really big.",
                    "label": 0
                },
                {
                    "sent": "If the probability that we used to assign aissati, it was very small.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you go to if you happen to choose a restaurant that was really bad in the past and has a tiny tiny probability then then you will get an estimate which is huge.",
                    "label": 0
                },
                {
                    "sent": "So we have to control that somehow.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these guys are which is a Bianchi Freund and Schapire in well they published this paper in 2002, but actually the first version of the paper was out way before.",
                    "label": 0
                },
                {
                    "sent": "They said that OK, let's do that, but let's mix, let's let's mix our our probability distribution with.",
                    "label": 0
                },
                {
                    "sent": "With a uniform.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's how it goes.",
                    "label": 0
                },
                {
                    "sent": "Choose action number I with from a distribution that works like this.",
                    "label": 0
                },
                {
                    "sent": "First I flip a coin this coin with probably the gamma says.",
                    "label": 0
                },
                {
                    "sent": "Fail with probability 1 minus gamma.",
                    "label": 0
                },
                {
                    "sent": "It will be head if head comes up, then I will just use the exponentially weighted average forecast are based on these estimated losses.",
                    "label": 0
                },
                {
                    "sent": "If there comes up then I will just use completely random.",
                    "label": 0
                },
                {
                    "sent": "Choice, so we don't need a small probability.",
                    "label": 0
                },
                {
                    "sent": "I will just.",
                    "label": 0
                },
                {
                    "sent": "This is called exploration and this is exploitation here.",
                    "label": 1
                },
                {
                    "sent": "If head comes up then then I will use my accumulated information to choose what I think is optimal.",
                    "label": 0
                },
                {
                    "sent": "The exponentially weighted forecaster should be close to optimal.",
                    "label": 0
                },
                {
                    "sent": "But if this comes up then I just I just choose completely randomly.",
                    "label": 0
                },
                {
                    "sent": "And why is this good?",
                    "label": 0
                },
                {
                    "sent": "Because this if I add this term then I can guarantee that the all these probabilities will be greater than gamma divided by N. OK, so this parameter gamma is there to make sure that these estimates are.",
                    "label": 0
                },
                {
                    "sent": "Good enough that the martingale inequalities will break.",
                    "label": 0
                },
                {
                    "sent": "So what this suggests is that even though you go to restaurant and you hate it after awhile, you should go back so you always have to.",
                    "label": 0
                },
                {
                    "sent": "You always have to allow some some chance that they change the chef right?",
                    "label": 0
                },
                {
                    "sent": "And because you never know since since we are we allow the adversary full power, the adversary can see that that you assign a very very tiny probability to, so he knows that you will never go there, so he.",
                    "label": 0
                },
                {
                    "sent": "It's there for Andrea the best chef in the world, and then then you're screwed.",
                    "label": 0
                },
                {
                    "sent": "So once in awhile we have to go back and very quickly you will real.",
                    "label": 0
                },
                {
                    "sent": "If you do this randomly then very quickly you will.",
                    "label": 0
                },
                {
                    "sent": "You will realize that that that action was indeed very good.",
                    "label": 0
                },
                {
                    "sent": "OK, so this just somehow forces that every action is sampled sufficiently often, and we need that for good estimates of the cumulative probabilities.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you work this out.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you get this wonderful regret bound which shows that I just said the expected value.",
                    "label": 0
                },
                {
                    "sent": "But this is in fact true with high probability.",
                    "label": 0
                },
                {
                    "sent": "If we compare the well, I can actually put capital I here.",
                    "label": 0
                },
                {
                    "sent": "I should have put capitalize.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "But so the regret, which is the.",
                    "label": 0
                },
                {
                    "sent": "The difference between the loss.",
                    "label": 0
                },
                {
                    "sent": "And the best possible loss that we could have chosen if we had known in advance what the best restaurant was, is bounded by some constant and square root of capital and log N / N. So this was.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This result of.",
                    "label": 0
                },
                {
                    "sent": "Our Chizar Bianchi Freund and schapire.",
                    "label": 0
                },
                {
                    "sent": "This is how happy they were when they found this result.",
                    "label": 0
                },
                {
                    "sent": "But this was this was in 95 or 96 or something like that and it was completely unexpected.",
                    "label": 0
                },
                {
                    "sent": "It it was so unexpected that their paper was rejected saying that this cannot possibly be true and it took like 7 years at the end.",
                    "label": 0
                },
                {
                    "sent": "They published this very well but but they had to fight to convince the referees.",
                    "label": 0
                },
                {
                    "sent": "Then this is possible.",
                    "label": 0
                },
                {
                    "sent": "'cause if you're not used to this type of arguments, then.",
                    "label": 0
                },
                {
                    "sent": "It's really mind boggling, so how the losses are completely arbitrary?",
                    "label": 0
                },
                {
                    "sent": "I only see the my own loss, so how can how can randomization do something like this well?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This is close to the best bound of.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of these guys is close to the best possible.",
                    "label": 0
                },
                {
                    "sent": "So they had capital log.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the natural easy lower bounds tell you square root of capital and over North notice that it's in.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Written that.",
                    "label": 0
                },
                {
                    "sent": "In either case, we don't have that really nice dependence on the number of actions as before, right before we had logged over.",
                    "label": 0
                },
                {
                    "sent": "Now we have this North here, so that means that now we can handle.",
                    "label": 0
                },
                {
                    "sent": "10s of thousands of restaurants anymore so and that's a problem in Barcelona at least so.",
                    "label": 0
                },
                {
                    "sent": "And you can get.",
                    "label": 0
                },
                {
                    "sent": "You can get rid of this log, but you cannot get rid of this, so, but this is again natural, because if you think about it, this was our.",
                    "label": 0
                },
                {
                    "sent": "This is our loss in the full information case and now.",
                    "label": 0
                },
                {
                    "sent": "So at that time for the full information case we have after time North Little North, we have little N times capital and labels that we have learned.",
                    "label": 0
                },
                {
                    "sent": "That's how many losses we know.",
                    "label": 0
                },
                {
                    "sent": "Now we have only capital N part of it because each at each time we have only one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We somehow expect that that little end will be replaced by little and divided by capital N. So this somehow looks like a natural bound.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then it was.",
                    "label": 0
                },
                {
                    "sent": "It was an open.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem for a long time, which one of these two is the right answer?",
                    "label": 0
                },
                {
                    "sent": "Can you get rid of the login or can you?",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or is it?",
                    "label": 0
                },
                {
                    "sent": "Is it necessary?",
                    "label": 0
                },
                {
                    "sent": "Can you improve the lower bound?",
                    "label": 0
                },
                {
                    "sent": "What this is really for?",
                    "label": 0
                },
                {
                    "sent": "For online learning geeks.",
                    "label": 0
                }
            ]
        }
    }
}