{
    "id": "drd3rxgjz5prh5wuakzjgrtzy7ichypr",
    "title": "Molecular Graph Kernels for Drug Discovery",
    "info": {
        "author": [
            "Anthony Demco, University of Southampton"
        ],
        "published": "July 19, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods",
            "Top->Computer Science->Bioinformatics"
        ]
    },
    "url": "http://videolectures.net/gbr07_demco_mgk/",
    "segmentation": [
        [
            "OK hello OK, so today I'm presenting some molecular graph kernels for drug discovery.",
            "This was joint work with Craig Saunders and Alex Julia at ECS at universe."
        ],
        [
            "Southampton Just the overview.",
            "I'm just going to briefly review drug discovery and virtual screening.",
            "Then I'll mention our approach.",
            "Which is using graph kernels and kernel methods.",
            "Afterwards, I'll present our framework of PP length graph kernels using dynamic programming.",
            "And I'm following that will review some results with some extensions we've used, and then we'll compare one class and two class classification and."
        ],
        [
            "The review that."
        ],
        [
            "I'm.",
            "So with drug discovery, there's many stages.",
            "The first stage typically involves.",
            "Target identification is usually done by X chemists who.",
            "I identify.",
            "Pathways and such and.",
            "From that, the set of compounds or ligands is screened against this target.",
            "And the ones that successfully bind at the target are termed hits and from these.",
            "The compounds which are able to meet certain properties that make it a good drug, such as it can be absorbed in the bloodstream and such.",
            "Will allow it to be classified as a lead and from these.",
            "It is from the leads.",
            "These are tested in humans and animals later on.",
            "And so I'm going to be concerned with virtual screening an as a subset of this is quantitative structure, activity analysis.",
            "Which analyzes the relationship between the structure in a molecule and its activity.",
            "The activity is a measure of how well it binds with the target.",
            "Quantify that.",
            "Um?",
            "And so virtual screening it's it's a process.",
            "That looks a lot like typical machine learning where you are given data set and molecular structure where.",
            "You have a molecular structure and about biological activity as the label, and the goal is to predict set of unseen molecules."
        ],
        [
            "In the last sort of 20 years, the typical approaches is to build a fingerprint.",
            "This is basically a vector of.",
            "This is a vector where elements in the vector describe whether the molecule has a certain.",
            "Certain component.",
            "And this is sort of a fixed size.",
            "And then once fingerprint is identified.",
            "As people have applied SVM, decision trees and such an that uses to classify with."
        ],
        [
            "It's a drug or non drug."
        ],
        [
            "In our approach, we're going to be using kernel methods for graphs and.",
            "With this there's a couple of things we need to consider.",
            "Firstly, there's several graph based representations of a molecule.",
            "And Secondly, we need to decide which graph kernel will use in last few years.",
            "A number of graph kernels have been presented."
        ],
        [
            "So the first graph based reference representation is the molecular graph.",
            "This is the standard view of the molecule where vertices are.",
            "The Atom type and bonds are the edges."
        ],
        [
            "Yes.",
            "Another approach, another view of molecules, can be seen with a topological farmer for graph.",
            "Here's the same structure as a molecular graph, although vertices are now labeled with the closest topological pharmacophore which is.",
            "Basically an area of of the molecule which has some function.",
            "And there's also Additionally reduced graph switches.",
            "Here, such as the Mo.",
            "SC and NI.",
            "These are just the actual functional areas are separate vertices."
        ],
        [
            "So we'll be using kernel methods and a kernel function is a positive definite function.",
            "And it corresponds to an inner product in a feature space.",
            "Here lies the mapping from X the input space to the feature space, FX in the input space.",
            "It is mapped to feature space.",
            "Um?",
            "Basically, such algorithms SVM which defines a hyperplane in the in the feature space.",
            "When you map that back to the input, SpaceX again it.",
            "Chose that a more complex function is actually been created, even though it's actually learning a linear function in the feature space.",
            "And there's a number of different algorithms allowed for clustering.",
            "SVM's voted, perceptrons, etc.",
            "And these can and all these algorithms have inner products in them and allows.",
            "For learning with kernel math."
        ],
        [
            "It's.",
            "So where we've been looking at kernels for graphs, and this is a positive definite function.",
            "Between two graphs.",
            "Conceptually, you can think of.",
            "This as.",
            "Building a feature vector which consists of all possible subparts of the structure data.",
            "Although actually the algorithm only needs the inner product, so serve a trick.",
            "Graph kernels.",
            "I can use a number of different different features when building this inner product.",
            "Thomas Gardner show that.",
            "Using all possible subgraphs is.",
            "Probably a class of NP hard problems, so this is not a good approach since the kernel function is used very often in the algorithm, so it's probably too slow.",
            "Um?",
            "A number of different other features that can be used or walks, which is the sequence of vertices.",
            "And this was proposed by Thomas Gardner in Cash, MA.",
            "Furthermore, you could look at consider distances between two labels and molecular graph.",
            "I.",
            "And also you can consider trees and cycles.",
            "But we were going to focus on wok kernels.",
            "Aziz been the most successful approach."
        ],
        [
            "With arcpy, length graph kernels are a framework for walk kernels and it's sort of an extension of.",
            "Or inspired by.",
            "The other walk based kernels.",
            "Here we count all walks of length P using dynamic programming.",
            "With the product to build the first step to calculate this kernel is, we need to build a product graph.",
            "And so given graphs G1 and G2.",
            "Basically, all.",
            "We consider each vertex vertex in each graph and the matching vertices such as A and a.",
            "Their result in a product in Vertex in the product graph.",
            "And similarly, if there is a link between two of the mapped.",
            "Pro vertexes, then you add that in the product graph as well.",
            "And so counting all walks in this product graph is equivalent to counting the walks.",
            "The matching walks in the two graphs, and so we're going to use that fact, and this was.",
            "Presented in Thomas is Colonel.",
            "Dumb."
        ],
        [
            "And to do this.",
            "We use dynamic programming and the dynamic programming equations are.",
            "Basically, you can imagine a vector where each element is a vertex from the product graph.",
            "It's initialized to one, and then at each iteration.",
            "You you add the.",
            "The the the components from the previous iteration.",
            "And then the kernel is the sum of that vector at that at that length P."
        ],
        [
            "And to this we can add previous extensions such as non tottering.",
            "Tottering is when in a graph, if you walk from one vertex to another and back immediately back again, that's considered a tottering path.",
            "This can be removed.",
            "This was shown in mahes paper, and this can be added into RDP equations by storing the contribution at each stage and then.",
            "If if.",
            "The contributions from 2 iterations ago was from the same vertex and you just don't include that.",
            "Furthermore, we consider soft matching and this is sort of an extension natural extension of matching walks.",
            "Here, if now if we're building the product graph, if two vertices don't match, we still add it, but when we're walking to that vertex, we.",
            "We down weight the contribution to that non match walk.",
            "And you can consider a substitution matrix here to decide how much you want to wait this non matching.",
            "So you can include expert information into that substitution matrix."
        ],
        [
            "Another extension we can add into this deep framework is gaps.",
            "The motivation behind this is you might want to match two graphs, even though there's small local changes that differentiate them.",
            "And this is this is done by.",
            "Modifying the original graph she wanted you to.",
            "So now at each edge in the original graphs we add a wildcard vertex above each edge.",
            "An if we want to match single gaps, then we only allow.",
            "Wild card vertices to match to regular vertices and we don't allow for multiple gaps.",
            "You allow wild card matching, although this significantly increases computational complexity, so we're still considering how to do this effect."
        ],
        [
            "For bind"
        ],
        [
            "Re classification we are split the the data set and 10% for parameter tuning.",
            "And we optimize the SVM C parameter and the ratio positive ratio.",
            "And with the remaining 90% we did a 5 fold cross validation.",
            "And we found that with a regular walk based kernel we get AUC area under the RC curve 0.906.",
            "And with soft matching to any vertex with equal probability.",
            "We were able to get a little bit better performance an including single gaps.",
            "Single gaps is decreased slightly.",
            "Although we tried this on smaller data, set them, you tag data set it actually increased it so."
        ],
        [
            "Still need to examine this further."
        ],
        [
            "Another problem we're considering is one class versus two class.",
            "So if you have a set of examples with binary classification, you give the model both positive and negative examples.",
            "But with one class you only give the model positive examples.",
            "And from this it finds a support of the distribution of the positive examples.",
            "An if an example, and then when you give in the test set, both positive and negative examples if.",
            "If it lies outside of this distribution, it's consid."
        ],
        [
            "An outlier.",
            "The motivation for using a one class classifier is that datasets are very often very large like.",
            "In commercial datasets in chem informatics, there's often hundreds, 10s, hundreds, millions of compounds.",
            "And for the more, it's highly unbalanced.",
            "So with NC HIV there's 42,000 examples.",
            "With 96% of them inactive with only 1% active, which will be like the positive class.",
            "Um?",
            "Furthermore, time to build the model usually scales with the number of examples used for training.",
            "So if we consider if we're using 90% of the data for training, then with binary classification the model has to learn from 38,000 examples with one class.",
            "That would just be around 370.",
            "Another motivation is that it is difficult to construct a data set that accurately represents the non drug class.",
            "As this can be extremely large."
        ],
        [
            "So for our experiment we tried again a similar methodology we split, we use 10% of the actives.",
            "For parameter tuning and the remaining 90% of actives were split into five folds and to compare this with binary wear.",
            "We're pairing the actives with a set of inactives."
        ],
        [
            "So the one class classifiers we tried was the schoelkopf method or the one SVM.",
            "And this seems to build a poor classifier.",
            "And afterwards we tried SVD.",
            "Which basically builds a sphere around the positive examples.",
            "And we were able to achieve higher AUC score of 0.75.",
            "I."
        ],
        [
            "And to compare this we are.",
            "We looked at binary classification and we incrementally increase the number of inactives.",
            "We repairing the training set with.",
            "And with just with one active.",
            "With about server in between one and 10 inactives, paired with the actives we could outperform the one class.",
            "And it's interesting to note that with only sort of 500 to 1000, we were able to achieve the best results.",
            "So using the full.",
            "38,000 inactives might not be."
        ],
        [
            "Useful.",
            "So we know that binary classification seems to outperform one class even when using a small inactive set for the more one class is much faster, although we should note that usually this process process.",
            "In the drug discovery cycle is done offline, so even though it may take a week, it still might be useful too.",
            "But tis a model."
        ],
        [
            "Takes longer"
        ],
        [
            "Yeah, so we've looked at our dynamic programming approach to calculating peeling kernels.",
            "I we use graph kernels from other representations, just similar graph.",
            "And we tried out soft matching and gaps in graph kernels and compare this with one and two classes."
        ],
        [
            "Classifiers and that's."
        ],
        [
            "References, that's all."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK hello OK, so today I'm presenting some molecular graph kernels for drug discovery.",
                    "label": 0
                },
                {
                    "sent": "This was joint work with Craig Saunders and Alex Julia at ECS at universe.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Southampton Just the overview.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to briefly review drug discovery and virtual screening.",
                    "label": 1
                },
                {
                    "sent": "Then I'll mention our approach.",
                    "label": 0
                },
                {
                    "sent": "Which is using graph kernels and kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Afterwards, I'll present our framework of PP length graph kernels using dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "And I'm following that will review some results with some extensions we've used, and then we'll compare one class and two class classification and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The review that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So with drug discovery, there's many stages.",
                    "label": 1
                },
                {
                    "sent": "The first stage typically involves.",
                    "label": 1
                },
                {
                    "sent": "Target identification is usually done by X chemists who.",
                    "label": 0
                },
                {
                    "sent": "I identify.",
                    "label": 0
                },
                {
                    "sent": "Pathways and such and.",
                    "label": 0
                },
                {
                    "sent": "From that, the set of compounds or ligands is screened against this target.",
                    "label": 0
                },
                {
                    "sent": "And the ones that successfully bind at the target are termed hits and from these.",
                    "label": 0
                },
                {
                    "sent": "The compounds which are able to meet certain properties that make it a good drug, such as it can be absorbed in the bloodstream and such.",
                    "label": 0
                },
                {
                    "sent": "Will allow it to be classified as a lead and from these.",
                    "label": 0
                },
                {
                    "sent": "It is from the leads.",
                    "label": 0
                },
                {
                    "sent": "These are tested in humans and animals later on.",
                    "label": 0
                },
                {
                    "sent": "And so I'm going to be concerned with virtual screening an as a subset of this is quantitative structure, activity analysis.",
                    "label": 0
                },
                {
                    "sent": "Which analyzes the relationship between the structure in a molecule and its activity.",
                    "label": 0
                },
                {
                    "sent": "The activity is a measure of how well it binds with the target.",
                    "label": 0
                },
                {
                    "sent": "Quantify that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so virtual screening it's it's a process.",
                    "label": 0
                },
                {
                    "sent": "That looks a lot like typical machine learning where you are given data set and molecular structure where.",
                    "label": 0
                },
                {
                    "sent": "You have a molecular structure and about biological activity as the label, and the goal is to predict set of unseen molecules.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the last sort of 20 years, the typical approaches is to build a fingerprint.",
                    "label": 0
                },
                {
                    "sent": "This is basically a vector of.",
                    "label": 0
                },
                {
                    "sent": "This is a vector where elements in the vector describe whether the molecule has a certain.",
                    "label": 0
                },
                {
                    "sent": "Certain component.",
                    "label": 0
                },
                {
                    "sent": "And this is sort of a fixed size.",
                    "label": 0
                },
                {
                    "sent": "And then once fingerprint is identified.",
                    "label": 0
                },
                {
                    "sent": "As people have applied SVM, decision trees and such an that uses to classify with.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a drug or non drug.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our approach, we're going to be using kernel methods for graphs and.",
                    "label": 1
                },
                {
                    "sent": "With this there's a couple of things we need to consider.",
                    "label": 1
                },
                {
                    "sent": "Firstly, there's several graph based representations of a molecule.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, we need to decide which graph kernel will use in last few years.",
                    "label": 0
                },
                {
                    "sent": "A number of graph kernels have been presented.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first graph based reference representation is the molecular graph.",
                    "label": 0
                },
                {
                    "sent": "This is the standard view of the molecule where vertices are.",
                    "label": 0
                },
                {
                    "sent": "The Atom type and bonds are the edges.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Another approach, another view of molecules, can be seen with a topological farmer for graph.",
                    "label": 0
                },
                {
                    "sent": "Here's the same structure as a molecular graph, although vertices are now labeled with the closest topological pharmacophore which is.",
                    "label": 1
                },
                {
                    "sent": "Basically an area of of the molecule which has some function.",
                    "label": 1
                },
                {
                    "sent": "And there's also Additionally reduced graph switches.",
                    "label": 0
                },
                {
                    "sent": "Here, such as the Mo.",
                    "label": 0
                },
                {
                    "sent": "SC and NI.",
                    "label": 0
                },
                {
                    "sent": "These are just the actual functional areas are separate vertices.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we'll be using kernel methods and a kernel function is a positive definite function.",
                    "label": 1
                },
                {
                    "sent": "And it corresponds to an inner product in a feature space.",
                    "label": 1
                },
                {
                    "sent": "Here lies the mapping from X the input space to the feature space, FX in the input space.",
                    "label": 0
                },
                {
                    "sent": "It is mapped to feature space.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Basically, such algorithms SVM which defines a hyperplane in the in the feature space.",
                    "label": 0
                },
                {
                    "sent": "When you map that back to the input, SpaceX again it.",
                    "label": 1
                },
                {
                    "sent": "Chose that a more complex function is actually been created, even though it's actually learning a linear function in the feature space.",
                    "label": 0
                },
                {
                    "sent": "And there's a number of different algorithms allowed for clustering.",
                    "label": 0
                },
                {
                    "sent": "SVM's voted, perceptrons, etc.",
                    "label": 0
                },
                {
                    "sent": "And these can and all these algorithms have inner products in them and allows.",
                    "label": 0
                },
                {
                    "sent": "For learning with kernel math.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "So where we've been looking at kernels for graphs, and this is a positive definite function.",
                    "label": 1
                },
                {
                    "sent": "Between two graphs.",
                    "label": 0
                },
                {
                    "sent": "Conceptually, you can think of.",
                    "label": 0
                },
                {
                    "sent": "This as.",
                    "label": 0
                },
                {
                    "sent": "Building a feature vector which consists of all possible subparts of the structure data.",
                    "label": 1
                },
                {
                    "sent": "Although actually the algorithm only needs the inner product, so serve a trick.",
                    "label": 0
                },
                {
                    "sent": "Graph kernels.",
                    "label": 1
                },
                {
                    "sent": "I can use a number of different different features when building this inner product.",
                    "label": 0
                },
                {
                    "sent": "Thomas Gardner show that.",
                    "label": 0
                },
                {
                    "sent": "Using all possible subgraphs is.",
                    "label": 1
                },
                {
                    "sent": "Probably a class of NP hard problems, so this is not a good approach since the kernel function is used very often in the algorithm, so it's probably too slow.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "A number of different other features that can be used or walks, which is the sequence of vertices.",
                    "label": 0
                },
                {
                    "sent": "And this was proposed by Thomas Gardner in Cash, MA.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, you could look at consider distances between two labels and molecular graph.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "And also you can consider trees and cycles.",
                    "label": 0
                },
                {
                    "sent": "But we were going to focus on wok kernels.",
                    "label": 0
                },
                {
                    "sent": "Aziz been the most successful approach.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With arcpy, length graph kernels are a framework for walk kernels and it's sort of an extension of.",
                    "label": 0
                },
                {
                    "sent": "Or inspired by.",
                    "label": 0
                },
                {
                    "sent": "The other walk based kernels.",
                    "label": 0
                },
                {
                    "sent": "Here we count all walks of length P using dynamic programming.",
                    "label": 1
                },
                {
                    "sent": "With the product to build the first step to calculate this kernel is, we need to build a product graph.",
                    "label": 1
                },
                {
                    "sent": "And so given graphs G1 and G2.",
                    "label": 0
                },
                {
                    "sent": "Basically, all.",
                    "label": 0
                },
                {
                    "sent": "We consider each vertex vertex in each graph and the matching vertices such as A and a.",
                    "label": 1
                },
                {
                    "sent": "Their result in a product in Vertex in the product graph.",
                    "label": 0
                },
                {
                    "sent": "And similarly, if there is a link between two of the mapped.",
                    "label": 0
                },
                {
                    "sent": "Pro vertexes, then you add that in the product graph as well.",
                    "label": 1
                },
                {
                    "sent": "And so counting all walks in this product graph is equivalent to counting the walks.",
                    "label": 0
                },
                {
                    "sent": "The matching walks in the two graphs, and so we're going to use that fact, and this was.",
                    "label": 0
                },
                {
                    "sent": "Presented in Thomas is Colonel.",
                    "label": 0
                },
                {
                    "sent": "Dumb.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to do this.",
                    "label": 0
                },
                {
                    "sent": "We use dynamic programming and the dynamic programming equations are.",
                    "label": 1
                },
                {
                    "sent": "Basically, you can imagine a vector where each element is a vertex from the product graph.",
                    "label": 0
                },
                {
                    "sent": "It's initialized to one, and then at each iteration.",
                    "label": 0
                },
                {
                    "sent": "You you add the.",
                    "label": 0
                },
                {
                    "sent": "The the the components from the previous iteration.",
                    "label": 1
                },
                {
                    "sent": "And then the kernel is the sum of that vector at that at that length P.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to this we can add previous extensions such as non tottering.",
                    "label": 0
                },
                {
                    "sent": "Tottering is when in a graph, if you walk from one vertex to another and back immediately back again, that's considered a tottering path.",
                    "label": 0
                },
                {
                    "sent": "This can be removed.",
                    "label": 0
                },
                {
                    "sent": "This was shown in mahes paper, and this can be added into RDP equations by storing the contribution at each stage and then.",
                    "label": 1
                },
                {
                    "sent": "If if.",
                    "label": 1
                },
                {
                    "sent": "The contributions from 2 iterations ago was from the same vertex and you just don't include that.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, we consider soft matching and this is sort of an extension natural extension of matching walks.",
                    "label": 1
                },
                {
                    "sent": "Here, if now if we're building the product graph, if two vertices don't match, we still add it, but when we're walking to that vertex, we.",
                    "label": 0
                },
                {
                    "sent": "We down weight the contribution to that non match walk.",
                    "label": 1
                },
                {
                    "sent": "And you can consider a substitution matrix here to decide how much you want to wait this non matching.",
                    "label": 0
                },
                {
                    "sent": "So you can include expert information into that substitution matrix.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another extension we can add into this deep framework is gaps.",
                    "label": 0
                },
                {
                    "sent": "The motivation behind this is you might want to match two graphs, even though there's small local changes that differentiate them.",
                    "label": 1
                },
                {
                    "sent": "And this is this is done by.",
                    "label": 0
                },
                {
                    "sent": "Modifying the original graph she wanted you to.",
                    "label": 0
                },
                {
                    "sent": "So now at each edge in the original graphs we add a wildcard vertex above each edge.",
                    "label": 1
                },
                {
                    "sent": "An if we want to match single gaps, then we only allow.",
                    "label": 1
                },
                {
                    "sent": "Wild card vertices to match to regular vertices and we don't allow for multiple gaps.",
                    "label": 0
                },
                {
                    "sent": "You allow wild card matching, although this significantly increases computational complexity, so we're still considering how to do this effect.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For bind",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Re classification we are split the the data set and 10% for parameter tuning.",
                    "label": 0
                },
                {
                    "sent": "And we optimize the SVM C parameter and the ratio positive ratio.",
                    "label": 0
                },
                {
                    "sent": "And with the remaining 90% we did a 5 fold cross validation.",
                    "label": 1
                },
                {
                    "sent": "And we found that with a regular walk based kernel we get AUC area under the RC curve 0.906.",
                    "label": 0
                },
                {
                    "sent": "And with soft matching to any vertex with equal probability.",
                    "label": 0
                },
                {
                    "sent": "We were able to get a little bit better performance an including single gaps.",
                    "label": 0
                },
                {
                    "sent": "Single gaps is decreased slightly.",
                    "label": 0
                },
                {
                    "sent": "Although we tried this on smaller data, set them, you tag data set it actually increased it so.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still need to examine this further.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another problem we're considering is one class versus two class.",
                    "label": 1
                },
                {
                    "sent": "So if you have a set of examples with binary classification, you give the model both positive and negative examples.",
                    "label": 1
                },
                {
                    "sent": "But with one class you only give the model positive examples.",
                    "label": 1
                },
                {
                    "sent": "And from this it finds a support of the distribution of the positive examples.",
                    "label": 0
                },
                {
                    "sent": "An if an example, and then when you give in the test set, both positive and negative examples if.",
                    "label": 1
                },
                {
                    "sent": "If it lies outside of this distribution, it's consid.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An outlier.",
                    "label": 0
                },
                {
                    "sent": "The motivation for using a one class classifier is that datasets are very often very large like.",
                    "label": 1
                },
                {
                    "sent": "In commercial datasets in chem informatics, there's often hundreds, 10s, hundreds, millions of compounds.",
                    "label": 0
                },
                {
                    "sent": "And for the more, it's highly unbalanced.",
                    "label": 0
                },
                {
                    "sent": "So with NC HIV there's 42,000 examples.",
                    "label": 0
                },
                {
                    "sent": "With 96% of them inactive with only 1% active, which will be like the positive class.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Furthermore, time to build the model usually scales with the number of examples used for training.",
                    "label": 1
                },
                {
                    "sent": "So if we consider if we're using 90% of the data for training, then with binary classification the model has to learn from 38,000 examples with one class.",
                    "label": 1
                },
                {
                    "sent": "That would just be around 370.",
                    "label": 0
                },
                {
                    "sent": "Another motivation is that it is difficult to construct a data set that accurately represents the non drug class.",
                    "label": 0
                },
                {
                    "sent": "As this can be extremely large.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for our experiment we tried again a similar methodology we split, we use 10% of the actives.",
                    "label": 0
                },
                {
                    "sent": "For parameter tuning and the remaining 90% of actives were split into five folds and to compare this with binary wear.",
                    "label": 1
                },
                {
                    "sent": "We're pairing the actives with a set of inactives.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the one class classifiers we tried was the schoelkopf method or the one SVM.",
                    "label": 0
                },
                {
                    "sent": "And this seems to build a poor classifier.",
                    "label": 0
                },
                {
                    "sent": "And afterwards we tried SVD.",
                    "label": 0
                },
                {
                    "sent": "Which basically builds a sphere around the positive examples.",
                    "label": 0
                },
                {
                    "sent": "And we were able to achieve higher AUC score of 0.75.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to compare this we are.",
                    "label": 0
                },
                {
                    "sent": "We looked at binary classification and we incrementally increase the number of inactives.",
                    "label": 1
                },
                {
                    "sent": "We repairing the training set with.",
                    "label": 1
                },
                {
                    "sent": "And with just with one active.",
                    "label": 0
                },
                {
                    "sent": "With about server in between one and 10 inactives, paired with the actives we could outperform the one class.",
                    "label": 0
                },
                {
                    "sent": "And it's interesting to note that with only sort of 500 to 1000, we were able to achieve the best results.",
                    "label": 0
                },
                {
                    "sent": "So using the full.",
                    "label": 0
                },
                {
                    "sent": "38,000 inactives might not be.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Useful.",
                    "label": 0
                },
                {
                    "sent": "So we know that binary classification seems to outperform one class even when using a small inactive set for the more one class is much faster, although we should note that usually this process process.",
                    "label": 1
                },
                {
                    "sent": "In the drug discovery cycle is done offline, so even though it may take a week, it still might be useful too.",
                    "label": 0
                },
                {
                    "sent": "But tis a model.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Takes longer",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so we've looked at our dynamic programming approach to calculating peeling kernels.",
                    "label": 0
                },
                {
                    "sent": "I we use graph kernels from other representations, just similar graph.",
                    "label": 1
                },
                {
                    "sent": "And we tried out soft matching and gaps in graph kernels and compare this with one and two classes.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classifiers and that's.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "References, that's all.",
                    "label": 0
                }
            ]
        }
    }
}