{
    "id": "4duzk6bejfoyzrn7ejdxl2suapw2etn6",
    "title": "Discovering Common Sequence Variation in Arabidopsis thaliana",
    "info": {
        "author": [
            "Gunnar R\u00e4tsch, Max Planck Institute"
        ],
        "published": "Nov. 20, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Biology->Systems Biology",
            "Top->Computer Science->Bioinformatics",
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Bioinformatics->Computational Systems Biology"
        ]
    },
    "url": "http://videolectures.net/mlsb07_ratsch_dcs/",
    "segmentation": [
        [
            "Plant.",
            "To."
        ],
        [
            "Quit.",
            "Just make a test.",
            "Hi Hannah, can you hear me?",
            "It's OK."
        ],
        [
            "So.",
            "Arizona.",
            "OK, let's try again.",
            "So this project be considered the re sequencing of a 20 wild strains.",
            "So out of these thousand strains which exists, we selected 20 wild strains of Arabidopsis and we're interested in the analysis of the genomic variation.",
            "So and we want to identify all the different sequence sequence variations which exist in these different strains.",
            "And for this we use high density oligonucleotide areas for high throughput analysis.",
            "If you have questions.",
            "Please ask already during the talk.",
            "This would help understanding.",
            "So just ask anytime."
        ],
        [
            "Please.",
            "OK, So what are timing?",
            "Every high density only going to type areas, so the idea is as follows.",
            "So you have one genome sequenced.",
            "That's the reference equal time which is called Columbia Zero.",
            "OK, so you have the reference sequence, so the idea is that you have other genomes which you would like to know.",
            "The variation.",
            "I mean what is different between the genome and another genome?",
            "And for this you design tropes and these probes are complementary.",
            "Two, so this is the DNA sequence OK, and now you design propes.",
            "These are 25 mayor and nuclear types and these are complementary to the reference sequence.",
            "And important is that you not only have one probe, but you have four probes and the middle position the 13th position.",
            "Here that is actually changed, so you have all all four possibilities, ACG and T for these probes.",
            "So when you see that in another.",
            "Equal Type another strain.",
            "There's a variation in particular like a single nucleotide variation.",
            "Then you would see that maybe this would normally hybridize, because this is identical to the reference, but then you see that another of these poor probes would hybridize most strongly, so in that hybridizes, if there's high sequence identity, right?",
            "So we can essentially read off the sequence position by looking at which of the four propsect?"
        ],
        [
            "So now we do this not only for one position in the genome.",
            "We do this for all this genome position.",
            "OK, so we get proofs which look like this.",
            "So their child over the sequence here and there shifted by one local time.",
            "OK, so and then you see by looking at which nucleotide has the strongest hybridization signal, which of the trope has the strongest hybridization signal?",
            "Each of the four ones for once and then you can read off the sequence.",
            "So here you see the A is strongest here.",
            "the T is strongest inside.",
            "OK, from this data you can actually incur the sequence of the other string."
        ],
        [
            "So using this technique we have tiled 99% of 99.99% of the whole genome.",
            "So remember the genome was about 120 megabytes large.",
            "So this means that we have 4 * 120 * 2.",
            "We do it on both strength, so we have about a billion propes on this microarray.",
            "So this is huge.",
            "My career and this is a huge data set.",
            "So yeah we do this for these nine.",
            "19 equal types for, I mean equal type equals the strain.",
            "OK, 90 equal types plus the reference equal type, so we know what we expect we can expect."
        ],
        [
            "OK, so this is the kind of data which we can see which we get here.",
            "So for every of these support nucleotides we have a color here for instance, it's hard to see so red.",
            "I think it's T and green is A and so on, right?",
            "So you can see, there's always a peek at a certain position and the peak here.",
            "This is strongest hybridization and from that you can essentially read off the signal sequence.",
            "OK, so this is the.",
            "Quotation from the reference equal type.",
            "What you see here is that the peaks all have a different height, so the peak intensity very much depends on many different properties.",
            "In particular, depends on the sequence itself.",
            "So the probe sequence.",
            "So some sequences hybridize better and some do not.",
            "In particular, this depends on whether the probe is duplicated in the genome, on the probe sequence.",
            "It might depend on many other factors.",
            "So there's a lot of noise in this data.",
            "So how does it look like when you have that now?",
            "A single nucleotide polymorphism?",
            "That means there's one."
        ],
        [
            "It's different, so here's a picture of that.",
            "That's another equal type.",
            "It's called CGI zero.",
            "And here you see in regions where it's identical, we get about the same hybridization signals.",
            "But here in this position here we have replaced AT with a C. So and then see here the.",
            "The T would lead to the highest hybridization signal here, so it's a red curve is highest, but here red is very low and instead there's another signal which is much stronger than the blue one and its corresponding to see OK.",
            "So at that position we have another another pro popping up corresponding to another nucleotide.",
            "But you also see is that there's a depleted signal around next to the snip, and this is because there's the other probes.",
            "They are not fully complementary anymore, right?",
            "So because they shifted ones do not have the single nucleotide polymorphism in the probe.",
            "So we have these kind of shapes and these shapes indicated that there is a snip.",
            "So this is actually a good example.",
            "There are many examples which are not as clear as this one.",
            "So at the first task is going to be to identify to solve the two class classification problem.",
            "To find these kind of sleep positions."
        ],
        [
            "But it's not always as easy as it, so when you have now not only one slip, but you have two snips which are very close to each other, so then you see since there's Napier and there's another sleep next to it, so these two snips interfere with each other during the hybridization, and therefore we don't get a signal at all.",
            "So we just have a depletion of the signal here.",
            "So these are the problematic cases.",
            "And this is just ridiculous.",
            "Problematic for highly polymorphic regions where you have maybe a deletion, insertion or clusters of snips all appearing together.",
            "And in the second part of the talk, I'm going to talk about an algorithm which can try which which tries to identify regions of depleted hybridization signal, which then indicates where polymorphisms are."
        ],
        [
            "OK, so let me first explain how we do with the signal snip identification.",
            "So the idea is that we extract features based on the hybridization signal.",
            "So just to give you an idea, here are two features.",
            "One is for instance how high the hybridization signal is at this new position and how much depleted the regions here next to the snip.",
            "So these could be 2 features.",
            "So we totally extract 303 hundred and two different features based on region around, put their potential supposition.",
            "OK, so we use four nucleotides around around the position used quality information from the hybridization and of course the hybridization Sigma."
        ],
        [
            "Self.",
            "OK, so now we have some.",
            "Now we have all the potential positions some correspond to snips, some don't, and we don't know.",
            "I mean, we need some labeled data as well, so unfortunately we could use some previous study from Northbrook, Slap where there considered I think, 80 different equal types were strains where they have sequenced parts of the DNA.",
            "0.5% of the DNA for each of these strings.",
            "So from this we could derive labeled data.",
            "We know all the positions.",
            "There will be no.",
            "We know all the sequence in there.",
            "We can derive all these new positions, deletions and so on.",
            "So here we consider all the only."
        ],
        [
            "This new positions and based on that we can now label the data.",
            "So we have essentially this sequence traces here.",
            "These organization traces and we have labeled data OK, Now we have about 600 kilobases per equal time, which were sequenced and based on this we can have the label data."
        ],
        [
            "OK, so now we can just learn a nonlinear decision surface.",
            "We use RBF kernel quite easily so it is straight."
        ],
        [
            "Forward Application offers support vector machines in principle, so it turned out that it's not as easy as we wanted to have it.",
            "So I mean principle.",
            "We have maybe 600,000 negative examples and maybe 2000 or something.",
            "A positive examples.",
            "And we thought we can simply use product machines to classify this, but it turned out that we can do much better if we do some prefiltering which is more based on heuristic.",
            "For that we only consider those cases which have a certain.",
            "Shape in this inhabitation signal and only those we consider and used for classification by the SVM.",
            "So this is essentially a trick.",
            "We use filters to reduce the number of negative examples, and we Additionally use information across the strains."
        ],
        [
            "I'm showing you how we do this.",
            "OK, so the idea is that we have the reference sequence and we have Additionally.",
            "The labeled sequence and of course the intensity measurements and we use firstly filter.",
            "Then we generate the features for all those sequences for positions which have passed the filter.",
            "Then we use this product or machine for training and validation and so on.",
            "And then we predict on the whole genome."
        ],
        [
            "So we can do this now for all the 19 different equal types separately, so this is useful because all the different equal types have been hybridized separately, so the experimental conditions are slightly different, so the shape of the snip hybridization looks slightly different for each of these different applications, so therefore it's good to have a classifier per equal type.",
            "OK, so the question is can be used now information across these different equal types?",
            "So because it's the case that if it appears in one equal type in one strain, then it's more likely that it also appears in another equal type, because these strains are not completely independent of each other.",
            "So can we use this information somehow in order to improve the classification performance?",
            "And this is?"
        ],
        [
            "How we solved it?",
            "So we had the prediction for each of the 19 equal types at the first level and then looked.",
            "For each of these equal types, whether there was a positive prediction in one of the equal types, and if it was, if there was a positive prediction, then we lowered the threshold for for the filters and then had a second round of an SVM and that lead lead to a better result.",
            "So there was some manual construction of a support vector.",
            "I mean of this filtering and this two layer architecture and this really led to a much improved results.",
            "So it's this clear everything.",
            "Would you comment on the filter appliance repair, touristically or any discourse manual selection way?",
            "I mean, these filters were essentially motivated by biological knowledge.",
            "How this should look like really?",
            "I mean, first of all, one thing you can filter out?",
            "Of course, if the maximum intensity was corresponding to the.",
            "With the true sequence, then of course we don't need to consider this if you see in the reference equal type that the prediction was also wrong.",
            "I mean that the true maximum was not corresponding to the sequence.",
            "Then we also excluded those kind of things.",
            "It's more like based on biological knowledge.",
            "Yeah, so, but this allowed us to reduce the number of negative examples from 600,000 to think about 5000.",
            "So and we lost, we lost snip positions.",
            "Also, we lost about 40% of all true snip positions, so there was a trade off he couldn't cut off too much and there.",
            "Maybe during this trade off we had to optimize a big performance.",
            "OK, so this is quite simple."
        ],
        [
            "Location of Perfect standard machine learning techniques.",
            "And here's some results so.",
            "We we have now the prediction of these perfect machine and we can use different thresholds for when we say.",
            "A position is this new position OK, and for different thresholds we get different false discovery rates and mean the recovery rates so we can identify different numbers of snips, and we have certain false positive rate or false discovery rate.",
            "So when we vary this threshold you get different false positive false discovery rates and recovery rates.",
            "So and we were shown here is these recovery rates and false discovery rates for different sequence types.",
            "So what we found.",
            "This is for coding.",
            "This is for intergenic and this is for UTI and intronic regions.",
            "What we found is that the recovery at the same false discovery rate is much higher in coding regions than intergenic and UTI and intra regions.",
            "So and why is that it turned out as I will show you later that the coding regions are much less polymorphic so there the snips are much much much less there I mean.",
            "They are not close to each other, so therefore we the method works much better.",
            "Additionally, coding regions have higher GC content, there more GS and CS in the probes and therefore the hybridization is better.",
            "OK so these are the main reasons while we get about twice as high recovery rates at the same port discovery rate.",
            "So what you see here maybe at the false discovery rate of 2% we get maybe 30 something percent recovery.",
            "That means we identified 30 something.",
            "Percent of all slips and most of these slips so 1998 out of 100 steps are real slips.",
            "OK, so it's a very high.",
            "Below for this Copyright.",
            "So for intergenic and Utah intronic regions.",
            "It's much lower, so almost half.",
            "What you see here is also is the these dots and these are the performance of the method which was proposed by the company Persian who is actually performing the predictions are performing the hybridization and this was published in Science in 2005 and we see that they are performing better.",
            "They have a higher recovery for regions which are having only little polymorphisms I mean.",
            "Little small rate of polymorphisms.",
            "So it turns out that they are doing well in regions which are not highly polymorphic.",
            "But if the regions are more highly polymorphic like an intronic and intergenic regions, then the performance was lower.",
            "So what you see here is just the number of snips on the whole genome for fault for certain false discovery rates.",
            "So this result is published in Science in July this year."
        ],
        [
            "OK so but we have certain limitations of these techniques of this technique, so and the limitations come from Snips which appear close to each other.",
            "As I mentioned before."
        ],
        [
            "So and what I show here is what show.",
            "Here is the the recovery for the same false discovery rate at a fixed false discovery rate for the model based approach by Persian and the machine learning approach at the false discovery rate of 2%.",
            "What you see here is that the recovery of the model based approach is higher in regions where the distance to the next step is high, so this is on the X axis.",
            "We have the distance to the next snip.",
            "So more than 60 nucleotides away.",
            "And here 126 nucleotides away.",
            "OK so and you see, once you get closer to another polymorphic feature, so another snip or deletions on the recovery really degrades drastically for the Persian method.",
            "For our method it slower here, but it's much higher in the highly polymorphic regions, so the method is better suited to find snips which are closer to each other.",
            "But it also fails in regions where the snips are really close to each other.",
            "Unfortunately, these snips, which appear close to each other, appear very often, and what you see here is the count of Snips, which have a distance smaller than one to six nucleotides, 7 to 12, and so on.",
            "And you see most snips actually in this building, so we cannot identify those.",
            "The recovery is only like 2%.",
            "And that's why we came."
        ],
        [
            "With the new approach of identifying, pulling morfik regions and this is going to be the second part of the talk before I'm going to talk about this, maybe now is a good time for questions, then I have some advertisements in between.",
            "And other questions for this stuff.",
            "OK, so for this work OK.",
            "Yes please.",
            "Comparative method with the method.",
            "When you normalize optimization signal by comparing to normal, in your case, probably better Richfield 20.",
            "Drop somewhere.",
            "So in the original study, we didn't normalize the data and maybe now we're doing this for another Organism for rice.",
            "Here we are normalizing the data because we don't have as much labeled examples, so this allows us to consider all the equal types at once.",
            "We have one model for all the cotypes, so in that sense it helps to have a more homogeneous model.",
            "So, but you're saying, so you would average the hybridization.",
            "Snake sniper way.",
            "Actually what they give you a reference, which is normal.",
            "So I really think that they provide you or you create your.",
            "In our case we create normal from not.",
            "And that's how I mean, the good thing is we have the hybridization of the reference equal type.",
            "OK, so I mean we know the normal signal and most of these features are actually a quotient of the hybridization offer.",
            "The equal type versus the reference equal type.",
            "So we divide these two things and this is an important feature.",
            "So in that sense we we don't need to average, we can just take the reference because we have hybridized the reference.",
            "Does make sense?",
            "The signal keeps going up and down due to different types of medication.",
            "So I would think that once we normalize, sometimes it just shoot at this variation or partnership disappear.",
            "Now their sequence specific probe sequence specific effects which determine the hybridization strength, like how many GS and CS in the sequence and that also position dependence somehow, so therefore averaging wouldn't help.",
            "OK, maybe you can talk after that.",
            "So maybe 3 shorter."
        ],
        [
            "So for this work we use the machine learning toolbox, which is called Segun.",
            "It implements like several support vector machines in one tool box and it provides interfaces to Matlab, Python And Octave.",
            "So it's like a C++ library which you can easily use from Matlab.",
            "There many examples.",
            "It's open source, you can download this for free."
        ],
        [
            "OK, second one, so it's also open source.",
            "This is a.",
            "There's a new special topic in the Journal Journal of Machine Learning Research, and this is organized by postdoc and a PhD student of mine.",
            "And here you can submit software so together with a four page description of the software.",
            "So if you have programmed some package which implements either some machine learning algorithm which is interesting, machine learning toolbox or anything like this, you can just write a description of this and then this is decidable paper.",
            "So this helps you to get the publication for your efforts of providing an open source package.",
            "OK, so there's also an upcoming paper in JAMA R where we discussed the need of open source in machinery."
        ],
        [
            "OK, and the last thing.",
            "Listen workshop at nips.",
            "The machine learning who are the new problems and methods in computational biology?",
            "That's a nips workshop.",
            "The deadline is on the 15th of October.",
            "You can submit extended abstracts of at most 6 pages and accepted contributions will be invited for a submission to a special issue in BMC Band."
        ],
        [
            "Mattox.",
            "Now for the second part.",
            "So in the second part we are interested in identifying polymorphic regions.",
            "So typically when we have many polymorphic features next to each other, then we get a picture like this.",
            "So this is maybe a region of the DNA, and here are some snips and insertions and deletions which we have identified using the sequencing information which we had provided from which were given by the previous project so and.",
            "Given these snips, insertions and deletions, we can like segment the genome into regions which are highly polymorphic and others which are."
        ],
        [
            "Contact OK. And we say something we can identify these kind of blocks.",
            "I mean, given that we know that there is a snip and insertion deletion, we can identify blocks which are highly polymorphic and we say a block is polymorphic block.",
            "If the polymorphic features in this block have a distance less than 18 nucleotides by 18 nucleotides.",
            "These probes are 25 nucleotides long, and if they're 18 nucleotides away, then they're almost not interfering with each other.",
            "OK, so.",
            "So from the sequencing information which we have only for a small small part of the genome, we can generate this target segmentation.",
            "This is a segmentation which we would like to predict on the whole genome, but we don't have the sequencing information for the whole genome."
        ],
        [
            "So we do this by using a method which is called hidden.",
            "Markov seems so this is based on a state model.",
            "We essentially have two states.",
            "One is a conservative state, another supporting morphic state.",
            "So for every position in the genome we have to assign one of these states.",
            "We have some intermediate states which model like the decay of hybridization signal at the boundaries of polymorphic region.",
            "OK, but essentially it's just two States and these.",
            "Correspond these should be like the polymorphic state should be assigned to positions which are within the target block off a polymorphic region."
        ],
        [
            "OK, let me give you an example.",
            "First, here you see the hybridization intensity for the reference equal type Columbia Zero and the another equal type which is drawn in red.",
            "OK, but you also see is the different polymorphic features which have been identified using sequencing.",
            "So you see for instance in this block here there's a high hybridization for the reference equal type butter decreased hybridization signal.",
            "Except maybe for these small peaks for the other equal type.",
            "OK, so using this discrepancy between the hybridization strength of the two equal types, we can now try to identify these blocks.",
            "So this is our target segmentation and this is for instance prediction of our algorithm.",
            "So how we do this?",
            "I explain soon.",
            "This is like a block which we identified, so maybe this one is missed.",
            "Here we have identified a part of the block."
        ],
        [
            "OK, so how do we do this?",
            "So we have the habitation signal and we have hybridization signal of the reference equal type and the equal time which we are interested in.",
            "So in from that we can drive features for every position in the genome.",
            "OK, so and what we would like to learn is a function which is given the hybridization signal features and the segmentation of the sequence which just gives a score to both.",
            "So the segmentation and the hybridization signals.",
            "So given this function, we can maximize this function with respect to the segmentation in order to perform a prediction.",
            "So we just find this segmentation which maximizes this function given the hybridization signals.",
            "OK, how can we now learn this function?",
            "So the idea is that we determine the function such that there is a large margin between the true segmentation which we know for some parts and all other wrong segmentations.",
            "OK, so this is the score for the true segmentation, so we're given labeled part of the sequence and hybridization signal.",
            "So this is the true signal, the true score, and this is the score of another segmentation which is not identical to the true one, and this distance should be large, let's say larger than one.",
            "Except in a few cases, we allowed to be smaller than one, and for this we introduce the slack variables and we penalize the some of these like variables.",
            "And we have some regularizer penalising somehow the form of this function F. OK, so this optimization problem is a linear optimization problem, and as you will have observed that there are many constraints, there's one constraint per wrong labeled sequence and there exponentially many in the length of the sequence.",
            "So but you can use algorithms which are related to column generation which generate one example at a time.",
            "You add it to the optimization problem resolved optimization problem and then you converge in the end and you can show this there's a proof of this.",
            "OK, so now we have learned this function and now we can use this function in order to produce."
        ],
        [
            "The segmentations and what I've shown you before was like a prediction like this one here and sometimes you exactly identify the right block.",
            "Sometimes you don't find it and sometimes you.",
            "Find the block, but maybe the boundaries are not exactly correct.",
            "OK, here maybe it's a bit shorter than it should be.",
            "This one is a bit longer than it should be and sometimes really big chunk of the block is missing.",
            "So the question is now, how do we evaluate this so and we say, whenever we find a block which is overlapping with a true block by at least 75%, then we count this as a true prediction and on the other hand for a for a target block.",
            "Office certain length we counted as being detected if it was covered by predictions, but by at least 75%.",
            "OK, so we can compute sensitivity and specificity for predictions."
        ],
        [
            "So and then we can actually.",
            "Yeah again for the different sequence types for coding regions for intergenic and Utah an intron we can compute the precision and recall for the for these predictions and maybe add a recall rate of 50% we can identify about 89% of all regions, so we can identify.",
            "About 90% of all polymorphic regions.",
            "You can identify 50% of all pretty much regions at a precision of 90%, so 90% of our predictions are correct."
        ],
        [
            "And it's even with the second part.",
            "OK, so now we have two methods.",
            "One is capable of identifying exact positions of a snip.",
            "OK, but it fails in regions which are highly polymorphic, so this is what we see here is again the distance of the snip to the next polymorphic feature you see when the distance is really small, then the recovery recall rate is very low, but once the distance to the next snippet gets larger then we can recover a lot of steps.",
            "The second method here we have we identified the polymorphic regions.",
            "We cannot identify exactly this new position, but we know in that region there must be a sniper or something else like a division or so, and that method performs particularly well when the snip density is very high, right?",
            "Because then the habitation signal is particularly strongly depleted, so therefore here the.",
            "Recall rate for Snips is particularly high, but if the distance to the next step is too large, then the performance of this method creates.",
            "So we have two methods which are complementing each other.",
            "One is good and one domain, and the other one is good in the other domain.",
            "So now you can ask, how many snips can be identified with a combination of both methods, and if this lips are very much clustered, then the region predictor is good and the snip calling method is not so good.",
            "And if you look at all snips, then you see that.",
            "About 32%.",
            "Detected by one method and the 64 is.",
            "By all methods by both message together so that this 42 is exclusively predicted by the region predictor and 8% is exclusively predicted by this new predictor and both together is 64%.",
            "You can also identify deletions you find quite a few of the deletions and you find you can predict about 53% of all division positions in the genome.",
            "In principle you cannot identify insertions because you don't have approach, but some of these insertions are within highly polymorphic regions and you identify at least a few of them."
        ],
        [
            "OK, So what we have created now is a kind of an inventory for polymorphisms in our big offices tiona.",
            "So now we can look what kind of genes are affected or where are these polymorphisms?",
            "What you see here is the statistics of polymorphisms.",
            "Off the different type of types of polymorphisms.",
            "And here we look at again at different sequence types.",
            "So in the inner circle we have the sequence types they are distributed in the whole genome, so you find 43% in the generic 28% of coding and so on.",
            "In the middle circle here in Middle Ring we see the distribution of the snips of Snips, and what you see is for instance.",
            "That there are more encoding regions relative to the background distribution and maybe intergenic regions are left less found here.",
            "What is interesting is that outer ring is the distribution of the polymorphic polymorphic regions and you see for instance, that in transposons, which are only four point, 7% in the genome, you find 8.5% of all positions covered by a polymorphic region.",
            "In transposons, are in transposons.",
            "OK so transposons have much more polymorphic regions than other genomic regions."
        ],
        [
            "So you can also have a look at the distribution of polymorphisms relative to the gene to gene start and end.",
            "So what you see here is like the five prime UTR of a gene.",
            "The three prime UTR for gene he is upstream region downstream region.",
            "What you see here is the density of polymorphic features, or polymorphic regions at each of these positions, averaged over the equal types, and this is the snippet density.",
            "Here.",
            "What you see here is that the polymorphic regions the intensity increases when you go away from the gene start, so the further you are upstream of the gene, the less at the more polymorphic regions.",
            "I mean, the more polymorphic it is, and this makes sense.",
            "I mean, there's a positive selection bias too.",
            "Avoid too much variation in just in front of the gene.",
            "What you see here is the distribution of SIS regulatory elements and we also did some testing how often weather weather is this regulatory elements are avoided by polymorphic bipolar by polymorphisms and there's some result which is not included here that the overlap of six regulatory elements with polymorphic features is.",
            "I mean, is such that we can infer that there's positive.",
            "I mean there's a selection against.",
            "Heitinga sister SIS regulatory element."
        ],
        [
            "So here's another example.",
            "This is relative to splice site, so here we have exons.",
            "Here we have the Intronic region.",
            "Here we have exon again.",
            "So this is again the.",
            "The snip.",
            "You can see at a certain position and here the red in red you have the.",
            "The frequency of a polymorphic region at that position.",
            "What you see here in the polymorphic regions that intensity the frequency goes really as much higher in the intronic region than the Exonic region.",
            "We don't see this feature in the snips themselves, but this is because of the often kind of sustainment buyer.",
            "So, because we cannot predict snips in regions which are highly polymorphic and the introns are highly polymorphic.",
            "So while it looks like that, the snips they're less snips in the introns.",
            "They're actually more snips as we predict up in the polymorphic regions, and we can confirm this by the sequencing results.",
            "So this gives a much better picture on the polymorphism, so the support about regions gives a much better picture of polymorphisms in excellence and entrance, for instance.",
            "Maybe it's a good time for questions.",
            "Yeah.",
            "The Department of Protective Order is in region just a region now.",
            "Subsequence for."
        ],
        [
            "So we start off with labeled sequence and we drive the label sequence from some previously obtained sequencing results.",
            "As I mentioned.",
            "So we have 600 KB of the genome, 0.5% of the genome, which are sequenced, and from that we look at all these snips and insertions and deletions and then say, here's a polymorphic block and a blocks are separated when the distance between polymorphic features are greater than 18 nucleotides.",
            "Turn the signal.",
            "So yeah, usually there sequences of about 500 nucleotides in length.",
            "This is what comes out of sequencing their small fragments and use these fragments for the labeling.",
            "So like one sequence for learning is about 500 nucleotides usually.",
            "Yep."
        ],
        [
            "OK, so now we have identified Snips.",
            "We have identified polymorphic regions, and some of these polymorphic regions just correspond to clusters of snips.",
            "Others correspond to long deletions.",
            "In a few cases we have identified really long deletions of 10 KB or 40 KB, so the question is, how do they interfere with the recognition of a gene of I mean, just with the gene itself, with the gene structure so, and the Snoop may.",
            "Hit like for instance a splice site.",
            "The splice site has a small consensus sequence and what you see here, for instance, maybe what didn't explain.",
            "You see that right at the supply side?",
            "You find much less snips, right?",
            "And this is because when you hit a supply side then this has a large effect on the gene, because then the splicer cannot work anymore and therefore the whole exon intron structure will change.",
            "So when we looked at how often do we find these cases and we not only look at supply side, we also looked at translation starts and stops.",
            "There are certain content the sequences, the transcription start and stops, and maybe also regulatory elements.",
            "We mainly looked at splice sites translation start."
        ],
        [
            "Stocks.",
            "So if there's a consensus sequence, then we it's quite easy to say, OK.",
            "Here's a large effect, because when we hit the stop codon and we destroyed the stop codon, well then this is going to be a strong effect.",
            "So these are the easy to check cases which I'm going to show you mainly.",
            "But there are other cases which may be near splice site.",
            "They may destroy a regulatory sequence to us all these are much harder to detect and the only thing we can do right now is to run like a gene finding system and see whether the given the changes in the sequence where we predict a different.",
            "Gene structure OK, so I'm showing that example later."
        ],
        [
            "So here's just a submarine, so we found about 110,000 amino acid changes in the coding regions, and we found that about 1200 stop codons have been introduced in one of the equal types relative to the reference equal type.",
            "True, had about 200 stop codons have been removed by a snip in one of the Co types relative to the reference equal type.",
            "Also the translation starts have changed and quite a few cases of splice sites have been affected.",
            "And we have considered.",
            "Some of these major changes and 573 genes were validated by by Deoxys sequencing, so just be resequenced small part of the genome for the other types to validate whether the prediction of a sniper or polymorphic region."
        ],
        [
            "Correct?",
            "That's just one case.",
            "For instance, we have gene here and this is actually was a known deletions in one of the Co types.",
            "And this is what the region predictor outputs and the red blocks are the predicted polymorphic regions, and you see there's a long stretch here which is predicted to be highly polymorphic.",
            "And whenever we have these long blocks, these most likely corresponding to the deleted part of the genome.",
            "So this.",
            "In this case, this gene was completely deleted in some of the cotypes.",
            "OK, so in this in this one."
        ],
        [
            "So now we can have a look at how the polymorphisms are distributed over different gene families.",
            "So and we use gene ontologies and we looked at different gene families here and what we found is that in particular three groups of genes.",
            "One is receptor like kinases.",
            "Then F box genes and then genes which are related to resistance to pathogens.",
            "And we found that in particular this last category we found high over representation of a snips, but also polymorphic regions.",
            "So like a large part of the jeans were highly affected by polymorphic regions.",
            "Very often it happened that the whole gene was deleted by appointment.",
            "I mean was completely covered by polymorphic region.",
            "That means probably the dream was completed.",
            "So I mean these jeans here there are like the plant version of the immune system.",
            "Like in animals and here we find a lot of polymorphisms and this is.",
            "These are the genes where most of the adoption is going to happen."
        ],
        [
            "OK, so finally I would like to mention just what we do with a gene finding to identify the effects of different polymorphisms in cases where the where the slip is not directly hitting a supply side or anything so.",
            "But maybe it's only near supply side.",
            "OK, so generally in gene finding you are given the DNA and you look for different signals on the DNA and then you can predict the gene structure with similar algorithms essay."
        ],
        [
            "Presented here, I don't want to go into detail much, but we use a method which is called M splicer for the study.",
            "Here we have also come up with a new method for gene finding.",
            "It's called M gene currently only works.",
            "MG only works on C. Elegans, but we're extending this, and this is a highly accurate gene finding system.",
            "Please contact me if you have interest in this.",
            "OK so but the idea is we can use such systems to apply it to the genomic sequence which we can generate from all the polymorphisms which we have predicted.",
            "OK, if you have predicted a snippet we just fill in the snip into the genomic sequence and then let the gene finer run on this modified sequence."
        ],
        [
            "So until just a few examples.",
            "So for instance here you have the splice form which is known and confirmed.",
            "Then you have a certain snips.",
            "This index on this is maybe in the intron, but very close to the supply side, and now we can run the gene finding system.",
            "In that case it was M. Spicer and predict this platform again and then see whether this splice form changes by the introduction of a snip or not.",
            "And in most cases it doesn't change the display form, so it would not lead to a different gene structure, but in a few cases here in 8% of the cases which we considered we found for instance that intron has been retained, or an Exxon has been skipped, or that this life side the boundary of the insurance and Exxon changes so.",
            "But these are just predictions and we still have to confirm them in the wet lab, so it's not done yet."
        ],
        [
            "Work on that.",
            "OK, here's just one example.",
            "You have the 19 equal types.",
            "You have the the gene model on top here, and you find the different predictions of the gene finding system for these sequence OK and you find in some of the Co types you have a snip here and this snip introduces a new Exxon here OK, and maybe in other cases you have snip here, but nothing changes.",
            "OK."
        ],
        [
            "I'm done.",
            "OK, OK, let me conclude this talk.",
            "What we have done, we have first created an inventory of polymorphisms in arbiters.",
            "Diana, and we have found that.",
            "Architects Diana's genomes are highly morphic.",
            "We found that about 0.5% of the genome contains snips in one of the 20 equal types, and 25% of the gene of the genomes are covered by polymorphic regions.",
            "So that means that large part of the genome is really covered by genomes in one of the 20 equal types, OK?",
            "So."
        ],
        [
            "I mean, it's really, highly pretty morphic.",
            "So what I've presented as a new method for Snip calling based on these tiny areas, it's more accurate on average than Persians, methods, method it less accurate in the coding regions, but more highly accurate, or whenever there appear highly polymorphic regions and the second method was.",
            "For identifying polymorphic regions based on the hidden Markov SVM.",
            "So, and these polymorphic regions are important, of course, for study of variation, but also more practically when people look at when people look at different regions in several equal types, they have to design primers for sequencing.",
            "So in these primers should be put in regions which are not so polymorphic, and for this these polymorphic regions predictions are very important, so we can design that we can put the primers and regions which are not."
        ],
        [
            "Pretty morphic.",
            "So we have predicted a large number of major effect changes and we found that there are over represented in these resistant genes.",
            "The F box genes and receptor like kinases and we have more predicted changes by upper needs."
        ],
        [
            "Gene findings.",
            "And we're currently looking at the rice genome, which is more important for breeding, and maybe we look at a human and mouse as well so we can just apply the same kind of method.",
            "So now we know the variation on the DNA level, so we can now use also timing errors and look at the variation on them on a level and then can try to predict trying to connect this.",
            "I mean what we've done so far is using gene finding, but maybe you can measure these things directly by using expression tiling."
        ],
        [
            "Race.",
            "OK so I would like to acknowledge the work of many other people, particularly the computational analysis have been mainly done by couple English.",
            "My curtain cocktail are in my group and also Richard Clarke and Endless Cycles Group.",
            "Then the the Pi of that project there other people at the Salk Institute, in particular Joseph Ecker and at the University of Southern California, particular Magnus, not Berg also at the MPI.",
            "For biological semantics.",
            "They spent a true copy who contributed alot.",
            "Persian Sciences Sciences he did the hybridization of the areas and also Danielson helped a lot in the initial phase of the project.",
            "OK, thank you very much for attention.",
            "So with.",
            "Could you run out of Christmas?",
            "I mean, you had a Christmas.",
            "His.",
            "It's the same species in the 19.",
            "Yes, yes, it's all the same species you can cross at these, but it's still very high.",
            "I mean, I mean, these genomes are quite different.",
            "I'm not sure whether all the different versions pairs have been tried, but I think it's the same species here.",
            "There's a lot of variation going on, and yeah, it's important to realize that this is not only one genome which we are considering, right?",
            "There's a lot of different versions of geometry.",
            "How many arrays does he should result.",
            "1,000,000 steps?",
            "I mean, you always do just take 1 billion propes and and we then we use 20 arrays right?",
            "So we have 20 billion measurements in total.",
            "So I mean computation time was an issue of certainly.",
            "Actually, I think the right street miss.",
            "Maybe 450 megabases, but it's highly repetitive and only 20% of the genome has been put on these arrays to save money.",
            "And I mean these highly repetitive sequences are not not so important.",
            "I mean, well, I wouldn't say not important, they are not.",
            "Consider this study.",
            "Let's say, so we use only 100 megabases in the right study, mainly coding regions which are not duplicated.",
            "I think in case of human you also think about tiling arrays, but it's much larger.",
            "I think the study has been done for mouse and the same kind of data is there for human.",
            "I'm not sure whether all their genomes have been hybridized, maybe only a part.",
            "I'm not sure, but for now, so there was this publication in nature in August 2nd or July, July, so their data is available.",
            "More problematic are the.",
            "How to obtain data which we can use for training the method?",
            "I mean we need some part of the genome to be sequenced for rice.",
            "We didn't have this every we had to.",
            "Sequence some parts of the genome in order to get to get known polymorphisms.",
            "So we sequenced nothing.",
            "Zero point 1% of the genome for these 20 equal types, which you consider in that case.",
            "Yes.",
            "Repeat.",
            "Some parts are and one part which I didn't really mention this.",
            "The repeat analysis so OK, so maybe this was not included, so it's important to exclude such probes which are duplicated in the genome and not only exactly duplicated but may be duplicated by one mismatch or so.",
            "'cause this leads to strong hybrid cross hybridization signals and we excluded all those cases.",
            "So this was part of the filter which I forgot to mention here.",
            "This does not apply to the regions which are rivets.",
            "Essentially, we don't predict snips snips in regions which are highly repetitive, so we predict polymorphic regions in these in the repeats, but we found whenever something is repeated, then the chance of predicting it as a polymorphic region is lower, so it's more difficult than they repeated regions.",
            "Right?",
            "Because then you have maybe cross hybridization and this overlays the other hybridization and then you don't know exactly whether this is really deleted or not.",
            "While with this really highly polymorphic or not.",
            "Probably there should be quite a difference between what happens.",
            "Yes, yes so.",
            "For the steps we excluded this, but so maybe it's interesting to look into this in more detail.",
            "Yes.",
            "Steps have you proposed to use this information?",
            "I mean, I'm not using completing those steps must be about few really.",
            "So I mean in the Vice project people use this snip information in order to design genotyping arrays and then they can look uses the genotyping arrays for greeting.",
            "For optimizing the plan.",
            "So I guess this is the main news.",
            "And of course we can OK. Then we can.",
            "Using this information we can then try to.",
            "Connect the genome genotyping with phenotypic information and try to understand what's the difference.",
            "Pick up some other person.",
            "Function is a F here on this leg.",
            "If that's a linear function, which it's linear in terms of the hybridization intensity, sequence information, and another information which I can give you later if you like it so.",
            "But it's a linear function that's important, so.",
            "Other things, apart from this PM for me.",
            "People have used hidden Markov models to do this, But the problem is that.",
            "The features at every position.",
            "They are not independent from each other because of the probes are overlapping right there for the independence assumption from hidden Markov models is not satisfied, so you could use conditional fields or something like this, so I'm more an expert in this method.",
            "That's why we use this one so, but there has been a PNS paper on hidden Markov models where the probes were not overlapping, so they used tiling areas where the distance of the probes from each other 35 and.",
            "The length of the probes was 25, so they were not not overlapping and then hit.",
            "Markov models have been used.",
            "I mean OK to use.",
            "5th translating your malfunction corrosion metal probably making you super fast and slow.",
            "Putin is if you Ristic method trying, I mean just taking different thresholds and cutting off this.",
            "I mean similar to our filter, right?",
            "Maybe we used the similar idea as Persian for filtering, but we're not as strict and then we had a larger set of potential potential snips, and here we used the SVM to select the real snips among this smaller set.",
            "So it's more based on heuristic for with using some threshold.",
            "OK.",
            "Very much thank you.",
            "So we are very short.",
            "Something about."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plant.",
                    "label": 0
                },
                {
                    "sent": "To.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quit.",
                    "label": 0
                },
                {
                    "sent": "Just make a test.",
                    "label": 0
                },
                {
                    "sent": "Hi Hannah, can you hear me?",
                    "label": 0
                },
                {
                    "sent": "It's OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Arizona.",
                    "label": 0
                },
                {
                    "sent": "OK, let's try again.",
                    "label": 0
                },
                {
                    "sent": "So this project be considered the re sequencing of a 20 wild strains.",
                    "label": 1
                },
                {
                    "sent": "So out of these thousand strains which exists, we selected 20 wild strains of Arabidopsis and we're interested in the analysis of the genomic variation.",
                    "label": 1
                },
                {
                    "sent": "So and we want to identify all the different sequence sequence variations which exist in these different strains.",
                    "label": 0
                },
                {
                    "sent": "And for this we use high density oligonucleotide areas for high throughput analysis.",
                    "label": 0
                },
                {
                    "sent": "If you have questions.",
                    "label": 0
                },
                {
                    "sent": "Please ask already during the talk.",
                    "label": 0
                },
                {
                    "sent": "This would help understanding.",
                    "label": 0
                },
                {
                    "sent": "So just ask anytime.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Please.",
                    "label": 0
                },
                {
                    "sent": "OK, So what are timing?",
                    "label": 0
                },
                {
                    "sent": "Every high density only going to type areas, so the idea is as follows.",
                    "label": 0
                },
                {
                    "sent": "So you have one genome sequenced.",
                    "label": 0
                },
                {
                    "sent": "That's the reference equal time which is called Columbia Zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have the reference sequence, so the idea is that you have other genomes which you would like to know.",
                    "label": 0
                },
                {
                    "sent": "The variation.",
                    "label": 0
                },
                {
                    "sent": "I mean what is different between the genome and another genome?",
                    "label": 0
                },
                {
                    "sent": "And for this you design tropes and these probes are complementary.",
                    "label": 0
                },
                {
                    "sent": "Two, so this is the DNA sequence OK, and now you design propes.",
                    "label": 0
                },
                {
                    "sent": "These are 25 mayor and nuclear types and these are complementary to the reference sequence.",
                    "label": 0
                },
                {
                    "sent": "And important is that you not only have one probe, but you have four probes and the middle position the 13th position.",
                    "label": 0
                },
                {
                    "sent": "Here that is actually changed, so you have all all four possibilities, ACG and T for these probes.",
                    "label": 0
                },
                {
                    "sent": "So when you see that in another.",
                    "label": 0
                },
                {
                    "sent": "Equal Type another strain.",
                    "label": 0
                },
                {
                    "sent": "There's a variation in particular like a single nucleotide variation.",
                    "label": 0
                },
                {
                    "sent": "Then you would see that maybe this would normally hybridize, because this is identical to the reference, but then you see that another of these poor probes would hybridize most strongly, so in that hybridizes, if there's high sequence identity, right?",
                    "label": 0
                },
                {
                    "sent": "So we can essentially read off the sequence position by looking at which of the four propsect?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we do this not only for one position in the genome.",
                    "label": 0
                },
                {
                    "sent": "We do this for all this genome position.",
                    "label": 0
                },
                {
                    "sent": "OK, so we get proofs which look like this.",
                    "label": 0
                },
                {
                    "sent": "So their child over the sequence here and there shifted by one local time.",
                    "label": 0
                },
                {
                    "sent": "OK, so and then you see by looking at which nucleotide has the strongest hybridization signal, which of the trope has the strongest hybridization signal?",
                    "label": 0
                },
                {
                    "sent": "Each of the four ones for once and then you can read off the sequence.",
                    "label": 0
                },
                {
                    "sent": "So here you see the A is strongest here.",
                    "label": 0
                },
                {
                    "sent": "the T is strongest inside.",
                    "label": 0
                },
                {
                    "sent": "OK, from this data you can actually incur the sequence of the other string.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So using this technique we have tiled 99% of 99.99% of the whole genome.",
                    "label": 0
                },
                {
                    "sent": "So remember the genome was about 120 megabytes large.",
                    "label": 0
                },
                {
                    "sent": "So this means that we have 4 * 120 * 2.",
                    "label": 0
                },
                {
                    "sent": "We do it on both strength, so we have about a billion propes on this microarray.",
                    "label": 0
                },
                {
                    "sent": "So this is huge.",
                    "label": 0
                },
                {
                    "sent": "My career and this is a huge data set.",
                    "label": 0
                },
                {
                    "sent": "So yeah we do this for these nine.",
                    "label": 0
                },
                {
                    "sent": "19 equal types for, I mean equal type equals the strain.",
                    "label": 0
                },
                {
                    "sent": "OK, 90 equal types plus the reference equal type, so we know what we expect we can expect.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the kind of data which we can see which we get here.",
                    "label": 0
                },
                {
                    "sent": "So for every of these support nucleotides we have a color here for instance, it's hard to see so red.",
                    "label": 0
                },
                {
                    "sent": "I think it's T and green is A and so on, right?",
                    "label": 0
                },
                {
                    "sent": "So you can see, there's always a peek at a certain position and the peak here.",
                    "label": 0
                },
                {
                    "sent": "This is strongest hybridization and from that you can essentially read off the signal sequence.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 0
                },
                {
                    "sent": "Quotation from the reference equal type.",
                    "label": 0
                },
                {
                    "sent": "What you see here is that the peaks all have a different height, so the peak intensity very much depends on many different properties.",
                    "label": 0
                },
                {
                    "sent": "In particular, depends on the sequence itself.",
                    "label": 0
                },
                {
                    "sent": "So the probe sequence.",
                    "label": 0
                },
                {
                    "sent": "So some sequences hybridize better and some do not.",
                    "label": 0
                },
                {
                    "sent": "In particular, this depends on whether the probe is duplicated in the genome, on the probe sequence.",
                    "label": 0
                },
                {
                    "sent": "It might depend on many other factors.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of noise in this data.",
                    "label": 0
                },
                {
                    "sent": "So how does it look like when you have that now?",
                    "label": 0
                },
                {
                    "sent": "A single nucleotide polymorphism?",
                    "label": 0
                },
                {
                    "sent": "That means there's one.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's different, so here's a picture of that.",
                    "label": 0
                },
                {
                    "sent": "That's another equal type.",
                    "label": 0
                },
                {
                    "sent": "It's called CGI zero.",
                    "label": 0
                },
                {
                    "sent": "And here you see in regions where it's identical, we get about the same hybridization signals.",
                    "label": 0
                },
                {
                    "sent": "But here in this position here we have replaced AT with a C. So and then see here the.",
                    "label": 0
                },
                {
                    "sent": "The T would lead to the highest hybridization signal here, so it's a red curve is highest, but here red is very low and instead there's another signal which is much stronger than the blue one and its corresponding to see OK.",
                    "label": 0
                },
                {
                    "sent": "So at that position we have another another pro popping up corresponding to another nucleotide.",
                    "label": 0
                },
                {
                    "sent": "But you also see is that there's a depleted signal around next to the snip, and this is because there's the other probes.",
                    "label": 0
                },
                {
                    "sent": "They are not fully complementary anymore, right?",
                    "label": 0
                },
                {
                    "sent": "So because they shifted ones do not have the single nucleotide polymorphism in the probe.",
                    "label": 0
                },
                {
                    "sent": "So we have these kind of shapes and these shapes indicated that there is a snip.",
                    "label": 0
                },
                {
                    "sent": "So this is actually a good example.",
                    "label": 0
                },
                {
                    "sent": "There are many examples which are not as clear as this one.",
                    "label": 0
                },
                {
                    "sent": "So at the first task is going to be to identify to solve the two class classification problem.",
                    "label": 0
                },
                {
                    "sent": "To find these kind of sleep positions.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it's not always as easy as it, so when you have now not only one slip, but you have two snips which are very close to each other, so then you see since there's Napier and there's another sleep next to it, so these two snips interfere with each other during the hybridization, and therefore we don't get a signal at all.",
                    "label": 0
                },
                {
                    "sent": "So we just have a depletion of the signal here.",
                    "label": 0
                },
                {
                    "sent": "So these are the problematic cases.",
                    "label": 1
                },
                {
                    "sent": "And this is just ridiculous.",
                    "label": 0
                },
                {
                    "sent": "Problematic for highly polymorphic regions where you have maybe a deletion, insertion or clusters of snips all appearing together.",
                    "label": 1
                },
                {
                    "sent": "And in the second part of the talk, I'm going to talk about an algorithm which can try which which tries to identify regions of depleted hybridization signal, which then indicates where polymorphisms are.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me first explain how we do with the signal snip identification.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we extract features based on the hybridization signal.",
                    "label": 0
                },
                {
                    "sent": "So just to give you an idea, here are two features.",
                    "label": 0
                },
                {
                    "sent": "One is for instance how high the hybridization signal is at this new position and how much depleted the regions here next to the snip.",
                    "label": 0
                },
                {
                    "sent": "So these could be 2 features.",
                    "label": 0
                },
                {
                    "sent": "So we totally extract 303 hundred and two different features based on region around, put their potential supposition.",
                    "label": 0
                },
                {
                    "sent": "OK, so we use four nucleotides around around the position used quality information from the hybridization and of course the hybridization Sigma.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Self.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have some.",
                    "label": 0
                },
                {
                    "sent": "Now we have all the potential positions some correspond to snips, some don't, and we don't know.",
                    "label": 0
                },
                {
                    "sent": "I mean, we need some labeled data as well, so unfortunately we could use some previous study from Northbrook, Slap where there considered I think, 80 different equal types were strains where they have sequenced parts of the DNA.",
                    "label": 0
                },
                {
                    "sent": "0.5% of the DNA for each of these strings.",
                    "label": 0
                },
                {
                    "sent": "So from this we could derive labeled data.",
                    "label": 0
                },
                {
                    "sent": "We know all the positions.",
                    "label": 0
                },
                {
                    "sent": "There will be no.",
                    "label": 0
                },
                {
                    "sent": "We know all the sequence in there.",
                    "label": 0
                },
                {
                    "sent": "We can derive all these new positions, deletions and so on.",
                    "label": 0
                },
                {
                    "sent": "So here we consider all the only.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This new positions and based on that we can now label the data.",
                    "label": 0
                },
                {
                    "sent": "So we have essentially this sequence traces here.",
                    "label": 0
                },
                {
                    "sent": "These organization traces and we have labeled data OK, Now we have about 600 kilobases per equal time, which were sequenced and based on this we can have the label data.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now we can just learn a nonlinear decision surface.",
                    "label": 0
                },
                {
                    "sent": "We use RBF kernel quite easily so it is straight.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Forward Application offers support vector machines in principle, so it turned out that it's not as easy as we wanted to have it.",
                    "label": 1
                },
                {
                    "sent": "So I mean principle.",
                    "label": 0
                },
                {
                    "sent": "We have maybe 600,000 negative examples and maybe 2000 or something.",
                    "label": 0
                },
                {
                    "sent": "A positive examples.",
                    "label": 0
                },
                {
                    "sent": "And we thought we can simply use product machines to classify this, but it turned out that we can do much better if we do some prefiltering which is more based on heuristic.",
                    "label": 0
                },
                {
                    "sent": "For that we only consider those cases which have a certain.",
                    "label": 0
                },
                {
                    "sent": "Shape in this inhabitation signal and only those we consider and used for classification by the SVM.",
                    "label": 0
                },
                {
                    "sent": "So this is essentially a trick.",
                    "label": 0
                },
                {
                    "sent": "We use filters to reduce the number of negative examples, and we Additionally use information across the strains.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm showing you how we do this.",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea is that we have the reference sequence and we have Additionally.",
                    "label": 0
                },
                {
                    "sent": "The labeled sequence and of course the intensity measurements and we use firstly filter.",
                    "label": 0
                },
                {
                    "sent": "Then we generate the features for all those sequences for positions which have passed the filter.",
                    "label": 0
                },
                {
                    "sent": "Then we use this product or machine for training and validation and so on.",
                    "label": 0
                },
                {
                    "sent": "And then we predict on the whole genome.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can do this now for all the 19 different equal types separately, so this is useful because all the different equal types have been hybridized separately, so the experimental conditions are slightly different, so the shape of the snip hybridization looks slightly different for each of these different applications, so therefore it's good to have a classifier per equal type.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is can be used now information across these different equal types?",
                    "label": 0
                },
                {
                    "sent": "So because it's the case that if it appears in one equal type in one strain, then it's more likely that it also appears in another equal type, because these strains are not completely independent of each other.",
                    "label": 0
                },
                {
                    "sent": "So can we use this information somehow in order to improve the classification performance?",
                    "label": 0
                },
                {
                    "sent": "And this is?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we solved it?",
                    "label": 0
                },
                {
                    "sent": "So we had the prediction for each of the 19 equal types at the first level and then looked.",
                    "label": 0
                },
                {
                    "sent": "For each of these equal types, whether there was a positive prediction in one of the equal types, and if it was, if there was a positive prediction, then we lowered the threshold for for the filters and then had a second round of an SVM and that lead lead to a better result.",
                    "label": 0
                },
                {
                    "sent": "So there was some manual construction of a support vector.",
                    "label": 0
                },
                {
                    "sent": "I mean of this filtering and this two layer architecture and this really led to a much improved results.",
                    "label": 0
                },
                {
                    "sent": "So it's this clear everything.",
                    "label": 0
                },
                {
                    "sent": "Would you comment on the filter appliance repair, touristically or any discourse manual selection way?",
                    "label": 0
                },
                {
                    "sent": "I mean, these filters were essentially motivated by biological knowledge.",
                    "label": 0
                },
                {
                    "sent": "How this should look like really?",
                    "label": 0
                },
                {
                    "sent": "I mean, first of all, one thing you can filter out?",
                    "label": 0
                },
                {
                    "sent": "Of course, if the maximum intensity was corresponding to the.",
                    "label": 0
                },
                {
                    "sent": "With the true sequence, then of course we don't need to consider this if you see in the reference equal type that the prediction was also wrong.",
                    "label": 0
                },
                {
                    "sent": "I mean that the true maximum was not corresponding to the sequence.",
                    "label": 0
                },
                {
                    "sent": "Then we also excluded those kind of things.",
                    "label": 0
                },
                {
                    "sent": "It's more like based on biological knowledge.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so, but this allowed us to reduce the number of negative examples from 600,000 to think about 5000.",
                    "label": 0
                },
                {
                    "sent": "So and we lost, we lost snip positions.",
                    "label": 0
                },
                {
                    "sent": "Also, we lost about 40% of all true snip positions, so there was a trade off he couldn't cut off too much and there.",
                    "label": 0
                },
                {
                    "sent": "Maybe during this trade off we had to optimize a big performance.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is quite simple.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location of Perfect standard machine learning techniques.",
                    "label": 0
                },
                {
                    "sent": "And here's some results so.",
                    "label": 0
                },
                {
                    "sent": "We we have now the prediction of these perfect machine and we can use different thresholds for when we say.",
                    "label": 0
                },
                {
                    "sent": "A position is this new position OK, and for different thresholds we get different false discovery rates and mean the recovery rates so we can identify different numbers of snips, and we have certain false positive rate or false discovery rate.",
                    "label": 0
                },
                {
                    "sent": "So when we vary this threshold you get different false positive false discovery rates and recovery rates.",
                    "label": 0
                },
                {
                    "sent": "So and we were shown here is these recovery rates and false discovery rates for different sequence types.",
                    "label": 0
                },
                {
                    "sent": "So what we found.",
                    "label": 0
                },
                {
                    "sent": "This is for coding.",
                    "label": 0
                },
                {
                    "sent": "This is for intergenic and this is for UTI and intronic regions.",
                    "label": 0
                },
                {
                    "sent": "What we found is that the recovery at the same false discovery rate is much higher in coding regions than intergenic and UTI and intra regions.",
                    "label": 0
                },
                {
                    "sent": "So and why is that it turned out as I will show you later that the coding regions are much less polymorphic so there the snips are much much much less there I mean.",
                    "label": 0
                },
                {
                    "sent": "They are not close to each other, so therefore we the method works much better.",
                    "label": 0
                },
                {
                    "sent": "Additionally, coding regions have higher GC content, there more GS and CS in the probes and therefore the hybridization is better.",
                    "label": 0
                },
                {
                    "sent": "OK so these are the main reasons while we get about twice as high recovery rates at the same port discovery rate.",
                    "label": 0
                },
                {
                    "sent": "So what you see here maybe at the false discovery rate of 2% we get maybe 30 something percent recovery.",
                    "label": 0
                },
                {
                    "sent": "That means we identified 30 something.",
                    "label": 0
                },
                {
                    "sent": "Percent of all slips and most of these slips so 1998 out of 100 steps are real slips.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a very high.",
                    "label": 0
                },
                {
                    "sent": "Below for this Copyright.",
                    "label": 0
                },
                {
                    "sent": "So for intergenic and Utah intronic regions.",
                    "label": 0
                },
                {
                    "sent": "It's much lower, so almost half.",
                    "label": 0
                },
                {
                    "sent": "What you see here is also is the these dots and these are the performance of the method which was proposed by the company Persian who is actually performing the predictions are performing the hybridization and this was published in Science in 2005 and we see that they are performing better.",
                    "label": 0
                },
                {
                    "sent": "They have a higher recovery for regions which are having only little polymorphisms I mean.",
                    "label": 0
                },
                {
                    "sent": "Little small rate of polymorphisms.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that they are doing well in regions which are not highly polymorphic.",
                    "label": 0
                },
                {
                    "sent": "But if the regions are more highly polymorphic like an intronic and intergenic regions, then the performance was lower.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is just the number of snips on the whole genome for fault for certain false discovery rates.",
                    "label": 0
                },
                {
                    "sent": "So this result is published in Science in July this year.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so but we have certain limitations of these techniques of this technique, so and the limitations come from Snips which appear close to each other.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned before.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So and what I show here is what show.",
                    "label": 0
                },
                {
                    "sent": "Here is the the recovery for the same false discovery rate at a fixed false discovery rate for the model based approach by Persian and the machine learning approach at the false discovery rate of 2%.",
                    "label": 0
                },
                {
                    "sent": "What you see here is that the recovery of the model based approach is higher in regions where the distance to the next step is high, so this is on the X axis.",
                    "label": 1
                },
                {
                    "sent": "We have the distance to the next snip.",
                    "label": 0
                },
                {
                    "sent": "So more than 60 nucleotides away.",
                    "label": 0
                },
                {
                    "sent": "And here 126 nucleotides away.",
                    "label": 0
                },
                {
                    "sent": "OK so and you see, once you get closer to another polymorphic feature, so another snip or deletions on the recovery really degrades drastically for the Persian method.",
                    "label": 0
                },
                {
                    "sent": "For our method it slower here, but it's much higher in the highly polymorphic regions, so the method is better suited to find snips which are closer to each other.",
                    "label": 1
                },
                {
                    "sent": "But it also fails in regions where the snips are really close to each other.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, these snips, which appear close to each other, appear very often, and what you see here is the count of Snips, which have a distance smaller than one to six nucleotides, 7 to 12, and so on.",
                    "label": 0
                },
                {
                    "sent": "And you see most snips actually in this building, so we cannot identify those.",
                    "label": 0
                },
                {
                    "sent": "The recovery is only like 2%.",
                    "label": 0
                },
                {
                    "sent": "And that's why we came.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the new approach of identifying, pulling morfik regions and this is going to be the second part of the talk before I'm going to talk about this, maybe now is a good time for questions, then I have some advertisements in between.",
                    "label": 0
                },
                {
                    "sent": "And other questions for this stuff.",
                    "label": 0
                },
                {
                    "sent": "OK, so for this work OK.",
                    "label": 0
                },
                {
                    "sent": "Yes please.",
                    "label": 0
                },
                {
                    "sent": "Comparative method with the method.",
                    "label": 0
                },
                {
                    "sent": "When you normalize optimization signal by comparing to normal, in your case, probably better Richfield 20.",
                    "label": 0
                },
                {
                    "sent": "Drop somewhere.",
                    "label": 0
                },
                {
                    "sent": "So in the original study, we didn't normalize the data and maybe now we're doing this for another Organism for rice.",
                    "label": 0
                },
                {
                    "sent": "Here we are normalizing the data because we don't have as much labeled examples, so this allows us to consider all the equal types at once.",
                    "label": 0
                },
                {
                    "sent": "We have one model for all the cotypes, so in that sense it helps to have a more homogeneous model.",
                    "label": 0
                },
                {
                    "sent": "So, but you're saying, so you would average the hybridization.",
                    "label": 0
                },
                {
                    "sent": "Snake sniper way.",
                    "label": 0
                },
                {
                    "sent": "Actually what they give you a reference, which is normal.",
                    "label": 0
                },
                {
                    "sent": "So I really think that they provide you or you create your.",
                    "label": 0
                },
                {
                    "sent": "In our case we create normal from not.",
                    "label": 0
                },
                {
                    "sent": "And that's how I mean, the good thing is we have the hybridization of the reference equal type.",
                    "label": 0
                },
                {
                    "sent": "OK, so I mean we know the normal signal and most of these features are actually a quotient of the hybridization offer.",
                    "label": 0
                },
                {
                    "sent": "The equal type versus the reference equal type.",
                    "label": 0
                },
                {
                    "sent": "So we divide these two things and this is an important feature.",
                    "label": 0
                },
                {
                    "sent": "So in that sense we we don't need to average, we can just take the reference because we have hybridized the reference.",
                    "label": 0
                },
                {
                    "sent": "Does make sense?",
                    "label": 0
                },
                {
                    "sent": "The signal keeps going up and down due to different types of medication.",
                    "label": 0
                },
                {
                    "sent": "So I would think that once we normalize, sometimes it just shoot at this variation or partnership disappear.",
                    "label": 0
                },
                {
                    "sent": "Now their sequence specific probe sequence specific effects which determine the hybridization strength, like how many GS and CS in the sequence and that also position dependence somehow, so therefore averaging wouldn't help.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe you can talk after that.",
                    "label": 0
                },
                {
                    "sent": "So maybe 3 shorter.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for this work we use the machine learning toolbox, which is called Segun.",
                    "label": 1
                },
                {
                    "sent": "It implements like several support vector machines in one tool box and it provides interfaces to Matlab, Python And Octave.",
                    "label": 0
                },
                {
                    "sent": "So it's like a C++ library which you can easily use from Matlab.",
                    "label": 0
                },
                {
                    "sent": "There many examples.",
                    "label": 0
                },
                {
                    "sent": "It's open source, you can download this for free.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, second one, so it's also open source.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "There's a new special topic in the Journal Journal of Machine Learning Research, and this is organized by postdoc and a PhD student of mine.",
                    "label": 1
                },
                {
                    "sent": "And here you can submit software so together with a four page description of the software.",
                    "label": 0
                },
                {
                    "sent": "So if you have programmed some package which implements either some machine learning algorithm which is interesting, machine learning toolbox or anything like this, you can just write a description of this and then this is decidable paper.",
                    "label": 0
                },
                {
                    "sent": "So this helps you to get the publication for your efforts of providing an open source package.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's also an upcoming paper in JAMA R where we discussed the need of open source in machinery.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and the last thing.",
                    "label": 0
                },
                {
                    "sent": "Listen workshop at nips.",
                    "label": 0
                },
                {
                    "sent": "The machine learning who are the new problems and methods in computational biology?",
                    "label": 1
                },
                {
                    "sent": "That's a nips workshop.",
                    "label": 0
                },
                {
                    "sent": "The deadline is on the 15th of October.",
                    "label": 0
                },
                {
                    "sent": "You can submit extended abstracts of at most 6 pages and accepted contributions will be invited for a submission to a special issue in BMC Band.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mattox.",
                    "label": 0
                },
                {
                    "sent": "Now for the second part.",
                    "label": 0
                },
                {
                    "sent": "So in the second part we are interested in identifying polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "So typically when we have many polymorphic features next to each other, then we get a picture like this.",
                    "label": 0
                },
                {
                    "sent": "So this is maybe a region of the DNA, and here are some snips and insertions and deletions which we have identified using the sequencing information which we had provided from which were given by the previous project so and.",
                    "label": 0
                },
                {
                    "sent": "Given these snips, insertions and deletions, we can like segment the genome into regions which are highly polymorphic and others which are.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Contact OK. And we say something we can identify these kind of blocks.",
                    "label": 0
                },
                {
                    "sent": "I mean, given that we know that there is a snip and insertion deletion, we can identify blocks which are highly polymorphic and we say a block is polymorphic block.",
                    "label": 0
                },
                {
                    "sent": "If the polymorphic features in this block have a distance less than 18 nucleotides by 18 nucleotides.",
                    "label": 0
                },
                {
                    "sent": "These probes are 25 nucleotides long, and if they're 18 nucleotides away, then they're almost not interfering with each other.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So from the sequencing information which we have only for a small small part of the genome, we can generate this target segmentation.",
                    "label": 0
                },
                {
                    "sent": "This is a segmentation which we would like to predict on the whole genome, but we don't have the sequencing information for the whole genome.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we do this by using a method which is called hidden.",
                    "label": 0
                },
                {
                    "sent": "Markov seems so this is based on a state model.",
                    "label": 0
                },
                {
                    "sent": "We essentially have two states.",
                    "label": 0
                },
                {
                    "sent": "One is a conservative state, another supporting morphic state.",
                    "label": 0
                },
                {
                    "sent": "So for every position in the genome we have to assign one of these states.",
                    "label": 0
                },
                {
                    "sent": "We have some intermediate states which model like the decay of hybridization signal at the boundaries of polymorphic region.",
                    "label": 0
                },
                {
                    "sent": "OK, but essentially it's just two States and these.",
                    "label": 0
                },
                {
                    "sent": "Correspond these should be like the polymorphic state should be assigned to positions which are within the target block off a polymorphic region.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "First, here you see the hybridization intensity for the reference equal type Columbia Zero and the another equal type which is drawn in red.",
                    "label": 0
                },
                {
                    "sent": "OK, but you also see is the different polymorphic features which have been identified using sequencing.",
                    "label": 0
                },
                {
                    "sent": "So you see for instance in this block here there's a high hybridization for the reference equal type butter decreased hybridization signal.",
                    "label": 0
                },
                {
                    "sent": "Except maybe for these small peaks for the other equal type.",
                    "label": 0
                },
                {
                    "sent": "OK, so using this discrepancy between the hybridization strength of the two equal types, we can now try to identify these blocks.",
                    "label": 0
                },
                {
                    "sent": "So this is our target segmentation and this is for instance prediction of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "So how we do this?",
                    "label": 0
                },
                {
                    "sent": "I explain soon.",
                    "label": 0
                },
                {
                    "sent": "This is like a block which we identified, so maybe this one is missed.",
                    "label": 0
                },
                {
                    "sent": "Here we have identified a part of the block.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how do we do this?",
                    "label": 0
                },
                {
                    "sent": "So we have the habitation signal and we have hybridization signal of the reference equal type and the equal time which we are interested in.",
                    "label": 0
                },
                {
                    "sent": "So in from that we can drive features for every position in the genome.",
                    "label": 0
                },
                {
                    "sent": "OK, so and what we would like to learn is a function which is given the hybridization signal features and the segmentation of the sequence which just gives a score to both.",
                    "label": 0
                },
                {
                    "sent": "So the segmentation and the hybridization signals.",
                    "label": 0
                },
                {
                    "sent": "So given this function, we can maximize this function with respect to the segmentation in order to perform a prediction.",
                    "label": 0
                },
                {
                    "sent": "So we just find this segmentation which maximizes this function given the hybridization signals.",
                    "label": 0
                },
                {
                    "sent": "OK, how can we now learn this function?",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we determine the function such that there is a large margin between the true segmentation which we know for some parts and all other wrong segmentations.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the score for the true segmentation, so we're given labeled part of the sequence and hybridization signal.",
                    "label": 0
                },
                {
                    "sent": "So this is the true signal, the true score, and this is the score of another segmentation which is not identical to the true one, and this distance should be large, let's say larger than one.",
                    "label": 0
                },
                {
                    "sent": "Except in a few cases, we allowed to be smaller than one, and for this we introduce the slack variables and we penalize the some of these like variables.",
                    "label": 0
                },
                {
                    "sent": "And we have some regularizer penalising somehow the form of this function F. OK, so this optimization problem is a linear optimization problem, and as you will have observed that there are many constraints, there's one constraint per wrong labeled sequence and there exponentially many in the length of the sequence.",
                    "label": 0
                },
                {
                    "sent": "So but you can use algorithms which are related to column generation which generate one example at a time.",
                    "label": 0
                },
                {
                    "sent": "You add it to the optimization problem resolved optimization problem and then you converge in the end and you can show this there's a proof of this.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have learned this function and now we can use this function in order to produce.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The segmentations and what I've shown you before was like a prediction like this one here and sometimes you exactly identify the right block.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you don't find it and sometimes you.",
                    "label": 0
                },
                {
                    "sent": "Find the block, but maybe the boundaries are not exactly correct.",
                    "label": 0
                },
                {
                    "sent": "OK, here maybe it's a bit shorter than it should be.",
                    "label": 0
                },
                {
                    "sent": "This one is a bit longer than it should be and sometimes really big chunk of the block is missing.",
                    "label": 0
                },
                {
                    "sent": "So the question is now, how do we evaluate this so and we say, whenever we find a block which is overlapping with a true block by at least 75%, then we count this as a true prediction and on the other hand for a for a target block.",
                    "label": 0
                },
                {
                    "sent": "Office certain length we counted as being detected if it was covered by predictions, but by at least 75%.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can compute sensitivity and specificity for predictions.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and then we can actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah again for the different sequence types for coding regions for intergenic and Utah an intron we can compute the precision and recall for the for these predictions and maybe add a recall rate of 50% we can identify about 89% of all regions, so we can identify.",
                    "label": 0
                },
                {
                    "sent": "About 90% of all polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "You can identify 50% of all pretty much regions at a precision of 90%, so 90% of our predictions are correct.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's even with the second part.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have two methods.",
                    "label": 0
                },
                {
                    "sent": "One is capable of identifying exact positions of a snip.",
                    "label": 0
                },
                {
                    "sent": "OK, but it fails in regions which are highly polymorphic, so this is what we see here is again the distance of the snip to the next polymorphic feature you see when the distance is really small, then the recovery recall rate is very low, but once the distance to the next snippet gets larger then we can recover a lot of steps.",
                    "label": 0
                },
                {
                    "sent": "The second method here we have we identified the polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "We cannot identify exactly this new position, but we know in that region there must be a sniper or something else like a division or so, and that method performs particularly well when the snip density is very high, right?",
                    "label": 0
                },
                {
                    "sent": "Because then the habitation signal is particularly strongly depleted, so therefore here the.",
                    "label": 0
                },
                {
                    "sent": "Recall rate for Snips is particularly high, but if the distance to the next step is too large, then the performance of this method creates.",
                    "label": 0
                },
                {
                    "sent": "So we have two methods which are complementing each other.",
                    "label": 0
                },
                {
                    "sent": "One is good and one domain, and the other one is good in the other domain.",
                    "label": 0
                },
                {
                    "sent": "So now you can ask, how many snips can be identified with a combination of both methods, and if this lips are very much clustered, then the region predictor is good and the snip calling method is not so good.",
                    "label": 0
                },
                {
                    "sent": "And if you look at all snips, then you see that.",
                    "label": 0
                },
                {
                    "sent": "About 32%.",
                    "label": 0
                },
                {
                    "sent": "Detected by one method and the 64 is.",
                    "label": 0
                },
                {
                    "sent": "By all methods by both message together so that this 42 is exclusively predicted by the region predictor and 8% is exclusively predicted by this new predictor and both together is 64%.",
                    "label": 0
                },
                {
                    "sent": "You can also identify deletions you find quite a few of the deletions and you find you can predict about 53% of all division positions in the genome.",
                    "label": 0
                },
                {
                    "sent": "In principle you cannot identify insertions because you don't have approach, but some of these insertions are within highly polymorphic regions and you identify at least a few of them.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we have created now is a kind of an inventory for polymorphisms in our big offices tiona.",
                    "label": 0
                },
                {
                    "sent": "So now we can look what kind of genes are affected or where are these polymorphisms?",
                    "label": 0
                },
                {
                    "sent": "What you see here is the statistics of polymorphisms.",
                    "label": 0
                },
                {
                    "sent": "Off the different type of types of polymorphisms.",
                    "label": 0
                },
                {
                    "sent": "And here we look at again at different sequence types.",
                    "label": 0
                },
                {
                    "sent": "So in the inner circle we have the sequence types they are distributed in the whole genome, so you find 43% in the generic 28% of coding and so on.",
                    "label": 0
                },
                {
                    "sent": "In the middle circle here in Middle Ring we see the distribution of the snips of Snips, and what you see is for instance.",
                    "label": 0
                },
                {
                    "sent": "That there are more encoding regions relative to the background distribution and maybe intergenic regions are left less found here.",
                    "label": 0
                },
                {
                    "sent": "What is interesting is that outer ring is the distribution of the polymorphic polymorphic regions and you see for instance, that in transposons, which are only four point, 7% in the genome, you find 8.5% of all positions covered by a polymorphic region.",
                    "label": 0
                },
                {
                    "sent": "In transposons, are in transposons.",
                    "label": 0
                },
                {
                    "sent": "OK so transposons have much more polymorphic regions than other genomic regions.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can also have a look at the distribution of polymorphisms relative to the gene to gene start and end.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is like the five prime UTR of a gene.",
                    "label": 0
                },
                {
                    "sent": "The three prime UTR for gene he is upstream region downstream region.",
                    "label": 0
                },
                {
                    "sent": "What you see here is the density of polymorphic features, or polymorphic regions at each of these positions, averaged over the equal types, and this is the snippet density.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "What you see here is that the polymorphic regions the intensity increases when you go away from the gene start, so the further you are upstream of the gene, the less at the more polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "I mean, the more polymorphic it is, and this makes sense.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's a positive selection bias too.",
                    "label": 0
                },
                {
                    "sent": "Avoid too much variation in just in front of the gene.",
                    "label": 0
                },
                {
                    "sent": "What you see here is the distribution of SIS regulatory elements and we also did some testing how often weather weather is this regulatory elements are avoided by polymorphic bipolar by polymorphisms and there's some result which is not included here that the overlap of six regulatory elements with polymorphic features is.",
                    "label": 0
                },
                {
                    "sent": "I mean, is such that we can infer that there's positive.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a selection against.",
                    "label": 0
                },
                {
                    "sent": "Heitinga sister SIS regulatory element.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's another example.",
                    "label": 0
                },
                {
                    "sent": "This is relative to splice site, so here we have exons.",
                    "label": 0
                },
                {
                    "sent": "Here we have the Intronic region.",
                    "label": 0
                },
                {
                    "sent": "Here we have exon again.",
                    "label": 0
                },
                {
                    "sent": "So this is again the.",
                    "label": 0
                },
                {
                    "sent": "The snip.",
                    "label": 0
                },
                {
                    "sent": "You can see at a certain position and here the red in red you have the.",
                    "label": 0
                },
                {
                    "sent": "The frequency of a polymorphic region at that position.",
                    "label": 0
                },
                {
                    "sent": "What you see here in the polymorphic regions that intensity the frequency goes really as much higher in the intronic region than the Exonic region.",
                    "label": 0
                },
                {
                    "sent": "We don't see this feature in the snips themselves, but this is because of the often kind of sustainment buyer.",
                    "label": 0
                },
                {
                    "sent": "So, because we cannot predict snips in regions which are highly polymorphic and the introns are highly polymorphic.",
                    "label": 0
                },
                {
                    "sent": "So while it looks like that, the snips they're less snips in the introns.",
                    "label": 0
                },
                {
                    "sent": "They're actually more snips as we predict up in the polymorphic regions, and we can confirm this by the sequencing results.",
                    "label": 0
                },
                {
                    "sent": "So this gives a much better picture on the polymorphism, so the support about regions gives a much better picture of polymorphisms in excellence and entrance, for instance.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a good time for questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The Department of Protective Order is in region just a region now.",
                    "label": 0
                },
                {
                    "sent": "Subsequence for.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we start off with labeled sequence and we drive the label sequence from some previously obtained sequencing results.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned.",
                    "label": 0
                },
                {
                    "sent": "So we have 600 KB of the genome, 0.5% of the genome, which are sequenced, and from that we look at all these snips and insertions and deletions and then say, here's a polymorphic block and a blocks are separated when the distance between polymorphic features are greater than 18 nucleotides.",
                    "label": 0
                },
                {
                    "sent": "Turn the signal.",
                    "label": 0
                },
                {
                    "sent": "So yeah, usually there sequences of about 500 nucleotides in length.",
                    "label": 0
                },
                {
                    "sent": "This is what comes out of sequencing their small fragments and use these fragments for the labeling.",
                    "label": 0
                },
                {
                    "sent": "So like one sequence for learning is about 500 nucleotides usually.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we have identified Snips.",
                    "label": 0
                },
                {
                    "sent": "We have identified polymorphic regions, and some of these polymorphic regions just correspond to clusters of snips.",
                    "label": 0
                },
                {
                    "sent": "Others correspond to long deletions.",
                    "label": 0
                },
                {
                    "sent": "In a few cases we have identified really long deletions of 10 KB or 40 KB, so the question is, how do they interfere with the recognition of a gene of I mean, just with the gene itself, with the gene structure so, and the Snoop may.",
                    "label": 1
                },
                {
                    "sent": "Hit like for instance a splice site.",
                    "label": 0
                },
                {
                    "sent": "The splice site has a small consensus sequence and what you see here, for instance, maybe what didn't explain.",
                    "label": 1
                },
                {
                    "sent": "You see that right at the supply side?",
                    "label": 0
                },
                {
                    "sent": "You find much less snips, right?",
                    "label": 0
                },
                {
                    "sent": "And this is because when you hit a supply side then this has a large effect on the gene, because then the splicer cannot work anymore and therefore the whole exon intron structure will change.",
                    "label": 0
                },
                {
                    "sent": "So when we looked at how often do we find these cases and we not only look at supply side, we also looked at translation starts and stops.",
                    "label": 0
                },
                {
                    "sent": "There are certain content the sequences, the transcription start and stops, and maybe also regulatory elements.",
                    "label": 1
                },
                {
                    "sent": "We mainly looked at splice sites translation start.",
                    "label": 1
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stocks.",
                    "label": 0
                },
                {
                    "sent": "So if there's a consensus sequence, then we it's quite easy to say, OK.",
                    "label": 1
                },
                {
                    "sent": "Here's a large effect, because when we hit the stop codon and we destroyed the stop codon, well then this is going to be a strong effect.",
                    "label": 1
                },
                {
                    "sent": "So these are the easy to check cases which I'm going to show you mainly.",
                    "label": 1
                },
                {
                    "sent": "But there are other cases which may be near splice site.",
                    "label": 0
                },
                {
                    "sent": "They may destroy a regulatory sequence to us all these are much harder to detect and the only thing we can do right now is to run like a gene finding system and see whether the given the changes in the sequence where we predict a different.",
                    "label": 0
                },
                {
                    "sent": "Gene structure OK, so I'm showing that example later.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's just a submarine, so we found about 110,000 amino acid changes in the coding regions, and we found that about 1200 stop codons have been introduced in one of the equal types relative to the reference equal type.",
                    "label": 1
                },
                {
                    "sent": "True, had about 200 stop codons have been removed by a snip in one of the Co types relative to the reference equal type.",
                    "label": 0
                },
                {
                    "sent": "Also the translation starts have changed and quite a few cases of splice sites have been affected.",
                    "label": 0
                },
                {
                    "sent": "And we have considered.",
                    "label": 0
                },
                {
                    "sent": "Some of these major changes and 573 genes were validated by by Deoxys sequencing, so just be resequenced small part of the genome for the other types to validate whether the prediction of a sniper or polymorphic region.",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Correct?",
                    "label": 0
                },
                {
                    "sent": "That's just one case.",
                    "label": 0
                },
                {
                    "sent": "For instance, we have gene here and this is actually was a known deletions in one of the Co types.",
                    "label": 0
                },
                {
                    "sent": "And this is what the region predictor outputs and the red blocks are the predicted polymorphic regions, and you see there's a long stretch here which is predicted to be highly polymorphic.",
                    "label": 0
                },
                {
                    "sent": "And whenever we have these long blocks, these most likely corresponding to the deleted part of the genome.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "In this case, this gene was completely deleted in some of the cotypes.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this in this one.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we can have a look at how the polymorphisms are distributed over different gene families.",
                    "label": 0
                },
                {
                    "sent": "So and we use gene ontologies and we looked at different gene families here and what we found is that in particular three groups of genes.",
                    "label": 0
                },
                {
                    "sent": "One is receptor like kinases.",
                    "label": 0
                },
                {
                    "sent": "Then F box genes and then genes which are related to resistance to pathogens.",
                    "label": 0
                },
                {
                    "sent": "And we found that in particular this last category we found high over representation of a snips, but also polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "So like a large part of the jeans were highly affected by polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "Very often it happened that the whole gene was deleted by appointment.",
                    "label": 0
                },
                {
                    "sent": "I mean was completely covered by polymorphic region.",
                    "label": 0
                },
                {
                    "sent": "That means probably the dream was completed.",
                    "label": 0
                },
                {
                    "sent": "So I mean these jeans here there are like the plant version of the immune system.",
                    "label": 0
                },
                {
                    "sent": "Like in animals and here we find a lot of polymorphisms and this is.",
                    "label": 0
                },
                {
                    "sent": "These are the genes where most of the adoption is going to happen.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so finally I would like to mention just what we do with a gene finding to identify the effects of different polymorphisms in cases where the where the slip is not directly hitting a supply side or anything so.",
                    "label": 0
                },
                {
                    "sent": "But maybe it's only near supply side.",
                    "label": 0
                },
                {
                    "sent": "OK, so generally in gene finding you are given the DNA and you look for different signals on the DNA and then you can predict the gene structure with similar algorithms essay.",
                    "label": 1
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Presented here, I don't want to go into detail much, but we use a method which is called M splicer for the study.",
                    "label": 0
                },
                {
                    "sent": "Here we have also come up with a new method for gene finding.",
                    "label": 0
                },
                {
                    "sent": "It's called M gene currently only works.",
                    "label": 0
                },
                {
                    "sent": "MG only works on C. Elegans, but we're extending this, and this is a highly accurate gene finding system.",
                    "label": 1
                },
                {
                    "sent": "Please contact me if you have interest in this.",
                    "label": 0
                },
                {
                    "sent": "OK so but the idea is we can use such systems to apply it to the genomic sequence which we can generate from all the polymorphisms which we have predicted.",
                    "label": 0
                },
                {
                    "sent": "OK, if you have predicted a snippet we just fill in the snip into the genomic sequence and then let the gene finer run on this modified sequence.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So until just a few examples.",
                    "label": 0
                },
                {
                    "sent": "So for instance here you have the splice form which is known and confirmed.",
                    "label": 0
                },
                {
                    "sent": "Then you have a certain snips.",
                    "label": 0
                },
                {
                    "sent": "This index on this is maybe in the intron, but very close to the supply side, and now we can run the gene finding system.",
                    "label": 0
                },
                {
                    "sent": "In that case it was M. Spicer and predict this platform again and then see whether this splice form changes by the introduction of a snip or not.",
                    "label": 0
                },
                {
                    "sent": "And in most cases it doesn't change the display form, so it would not lead to a different gene structure, but in a few cases here in 8% of the cases which we considered we found for instance that intron has been retained, or an Exxon has been skipped, or that this life side the boundary of the insurance and Exxon changes so.",
                    "label": 0
                },
                {
                    "sent": "But these are just predictions and we still have to confirm them in the wet lab, so it's not done yet.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work on that.",
                    "label": 0
                },
                {
                    "sent": "OK, here's just one example.",
                    "label": 0
                },
                {
                    "sent": "You have the 19 equal types.",
                    "label": 0
                },
                {
                    "sent": "You have the the gene model on top here, and you find the different predictions of the gene finding system for these sequence OK and you find in some of the Co types you have a snip here and this snip introduces a new Exxon here OK, and maybe in other cases you have snip here, but nothing changes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm done.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, let me conclude this talk.",
                    "label": 0
                },
                {
                    "sent": "What we have done, we have first created an inventory of polymorphisms in arbiters.",
                    "label": 0
                },
                {
                    "sent": "Diana, and we have found that.",
                    "label": 0
                },
                {
                    "sent": "Architects Diana's genomes are highly morphic.",
                    "label": 0
                },
                {
                    "sent": "We found that about 0.5% of the genome contains snips in one of the 20 equal types, and 25% of the gene of the genomes are covered by polymorphic regions.",
                    "label": 0
                },
                {
                    "sent": "So that means that large part of the genome is really covered by genomes in one of the 20 equal types, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean, it's really, highly pretty morphic.",
                    "label": 0
                },
                {
                    "sent": "So what I've presented as a new method for Snip calling based on these tiny areas, it's more accurate on average than Persians, methods, method it less accurate in the coding regions, but more highly accurate, or whenever there appear highly polymorphic regions and the second method was.",
                    "label": 1
                },
                {
                    "sent": "For identifying polymorphic regions based on the hidden Markov SVM.",
                    "label": 0
                },
                {
                    "sent": "So, and these polymorphic regions are important, of course, for study of variation, but also more practically when people look at when people look at different regions in several equal types, they have to design primers for sequencing.",
                    "label": 0
                },
                {
                    "sent": "So in these primers should be put in regions which are not so polymorphic, and for this these polymorphic regions predictions are very important, so we can design that we can put the primers and regions which are not.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty morphic.",
                    "label": 0
                },
                {
                    "sent": "So we have predicted a large number of major effect changes and we found that there are over represented in these resistant genes.",
                    "label": 1
                },
                {
                    "sent": "The F box genes and receptor like kinases and we have more predicted changes by upper needs.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gene findings.",
                    "label": 0
                },
                {
                    "sent": "And we're currently looking at the rice genome, which is more important for breeding, and maybe we look at a human and mouse as well so we can just apply the same kind of method.",
                    "label": 0
                },
                {
                    "sent": "So now we know the variation on the DNA level, so we can now use also timing errors and look at the variation on them on a level and then can try to predict trying to connect this.",
                    "label": 0
                },
                {
                    "sent": "I mean what we've done so far is using gene finding, but maybe you can measure these things directly by using expression tiling.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Race.",
                    "label": 0
                },
                {
                    "sent": "OK so I would like to acknowledge the work of many other people, particularly the computational analysis have been mainly done by couple English.",
                    "label": 0
                },
                {
                    "sent": "My curtain cocktail are in my group and also Richard Clarke and Endless Cycles Group.",
                    "label": 0
                },
                {
                    "sent": "Then the the Pi of that project there other people at the Salk Institute, in particular Joseph Ecker and at the University of Southern California, particular Magnus, not Berg also at the MPI.",
                    "label": 1
                },
                {
                    "sent": "For biological semantics.",
                    "label": 0
                },
                {
                    "sent": "They spent a true copy who contributed alot.",
                    "label": 0
                },
                {
                    "sent": "Persian Sciences Sciences he did the hybridization of the areas and also Danielson helped a lot in the initial phase of the project.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much for attention.",
                    "label": 0
                },
                {
                    "sent": "So with.",
                    "label": 0
                },
                {
                    "sent": "Could you run out of Christmas?",
                    "label": 0
                },
                {
                    "sent": "I mean, you had a Christmas.",
                    "label": 0
                },
                {
                    "sent": "His.",
                    "label": 0
                },
                {
                    "sent": "It's the same species in the 19.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, it's all the same species you can cross at these, but it's still very high.",
                    "label": 0
                },
                {
                    "sent": "I mean, I mean, these genomes are quite different.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether all the different versions pairs have been tried, but I think it's the same species here.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of variation going on, and yeah, it's important to realize that this is not only one genome which we are considering, right?",
                    "label": 0
                },
                {
                    "sent": "There's a lot of different versions of geometry.",
                    "label": 0
                },
                {
                    "sent": "How many arrays does he should result.",
                    "label": 0
                },
                {
                    "sent": "1,000,000 steps?",
                    "label": 0
                },
                {
                    "sent": "I mean, you always do just take 1 billion propes and and we then we use 20 arrays right?",
                    "label": 0
                },
                {
                    "sent": "So we have 20 billion measurements in total.",
                    "label": 0
                },
                {
                    "sent": "So I mean computation time was an issue of certainly.",
                    "label": 0
                },
                {
                    "sent": "Actually, I think the right street miss.",
                    "label": 0
                },
                {
                    "sent": "Maybe 450 megabases, but it's highly repetitive and only 20% of the genome has been put on these arrays to save money.",
                    "label": 0
                },
                {
                    "sent": "And I mean these highly repetitive sequences are not not so important.",
                    "label": 0
                },
                {
                    "sent": "I mean, well, I wouldn't say not important, they are not.",
                    "label": 0
                },
                {
                    "sent": "Consider this study.",
                    "label": 0
                },
                {
                    "sent": "Let's say, so we use only 100 megabases in the right study, mainly coding regions which are not duplicated.",
                    "label": 0
                },
                {
                    "sent": "I think in case of human you also think about tiling arrays, but it's much larger.",
                    "label": 0
                },
                {
                    "sent": "I think the study has been done for mouse and the same kind of data is there for human.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether all their genomes have been hybridized, maybe only a part.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure, but for now, so there was this publication in nature in August 2nd or July, July, so their data is available.",
                    "label": 0
                },
                {
                    "sent": "More problematic are the.",
                    "label": 0
                },
                {
                    "sent": "How to obtain data which we can use for training the method?",
                    "label": 0
                },
                {
                    "sent": "I mean we need some part of the genome to be sequenced for rice.",
                    "label": 0
                },
                {
                    "sent": "We didn't have this every we had to.",
                    "label": 0
                },
                {
                    "sent": "Sequence some parts of the genome in order to get to get known polymorphisms.",
                    "label": 0
                },
                {
                    "sent": "So we sequenced nothing.",
                    "label": 0
                },
                {
                    "sent": "Zero point 1% of the genome for these 20 equal types, which you consider in that case.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Repeat.",
                    "label": 0
                },
                {
                    "sent": "Some parts are and one part which I didn't really mention this.",
                    "label": 0
                },
                {
                    "sent": "The repeat analysis so OK, so maybe this was not included, so it's important to exclude such probes which are duplicated in the genome and not only exactly duplicated but may be duplicated by one mismatch or so.",
                    "label": 0
                },
                {
                    "sent": "'cause this leads to strong hybrid cross hybridization signals and we excluded all those cases.",
                    "label": 0
                },
                {
                    "sent": "So this was part of the filter which I forgot to mention here.",
                    "label": 0
                },
                {
                    "sent": "This does not apply to the regions which are rivets.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we don't predict snips snips in regions which are highly repetitive, so we predict polymorphic regions in these in the repeats, but we found whenever something is repeated, then the chance of predicting it as a polymorphic region is lower, so it's more difficult than they repeated regions.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Because then you have maybe cross hybridization and this overlays the other hybridization and then you don't know exactly whether this is really deleted or not.",
                    "label": 0
                },
                {
                    "sent": "While with this really highly polymorphic or not.",
                    "label": 0
                },
                {
                    "sent": "Probably there should be quite a difference between what happens.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes so.",
                    "label": 0
                },
                {
                    "sent": "For the steps we excluded this, but so maybe it's interesting to look into this in more detail.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Steps have you proposed to use this information?",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm not using completing those steps must be about few really.",
                    "label": 0
                },
                {
                    "sent": "So I mean in the Vice project people use this snip information in order to design genotyping arrays and then they can look uses the genotyping arrays for greeting.",
                    "label": 0
                },
                {
                    "sent": "For optimizing the plan.",
                    "label": 0
                },
                {
                    "sent": "So I guess this is the main news.",
                    "label": 0
                },
                {
                    "sent": "And of course we can OK. Then we can.",
                    "label": 0
                },
                {
                    "sent": "Using this information we can then try to.",
                    "label": 0
                },
                {
                    "sent": "Connect the genome genotyping with phenotypic information and try to understand what's the difference.",
                    "label": 0
                },
                {
                    "sent": "Pick up some other person.",
                    "label": 0
                },
                {
                    "sent": "Function is a F here on this leg.",
                    "label": 0
                },
                {
                    "sent": "If that's a linear function, which it's linear in terms of the hybridization intensity, sequence information, and another information which I can give you later if you like it so.",
                    "label": 0
                },
                {
                    "sent": "But it's a linear function that's important, so.",
                    "label": 0
                },
                {
                    "sent": "Other things, apart from this PM for me.",
                    "label": 0
                },
                {
                    "sent": "People have used hidden Markov models to do this, But the problem is that.",
                    "label": 0
                },
                {
                    "sent": "The features at every position.",
                    "label": 0
                },
                {
                    "sent": "They are not independent from each other because of the probes are overlapping right there for the independence assumption from hidden Markov models is not satisfied, so you could use conditional fields or something like this, so I'm more an expert in this method.",
                    "label": 0
                },
                {
                    "sent": "That's why we use this one so, but there has been a PNS paper on hidden Markov models where the probes were not overlapping, so they used tiling areas where the distance of the probes from each other 35 and.",
                    "label": 0
                },
                {
                    "sent": "The length of the probes was 25, so they were not not overlapping and then hit.",
                    "label": 0
                },
                {
                    "sent": "Markov models have been used.",
                    "label": 0
                },
                {
                    "sent": "I mean OK to use.",
                    "label": 0
                },
                {
                    "sent": "5th translating your malfunction corrosion metal probably making you super fast and slow.",
                    "label": 0
                },
                {
                    "sent": "Putin is if you Ristic method trying, I mean just taking different thresholds and cutting off this.",
                    "label": 0
                },
                {
                    "sent": "I mean similar to our filter, right?",
                    "label": 0
                },
                {
                    "sent": "Maybe we used the similar idea as Persian for filtering, but we're not as strict and then we had a larger set of potential potential snips, and here we used the SVM to select the real snips among this smaller set.",
                    "label": 0
                },
                {
                    "sent": "So it's more based on heuristic for with using some threshold.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Very much thank you.",
                    "label": 0
                },
                {
                    "sent": "So we are very short.",
                    "label": 0
                },
                {
                    "sent": "Something about.",
                    "label": 0
                }
            ]
        }
    }
}