{
    "id": "7zfm3cx4bng2g2u57lfsffholuprbaov",
    "title": "Reinforcement Learning for Structured Data Labeling",
    "info": {
        "author": [
            "Patrick Gallinari, Universit\u00e9 Pierre et Marie Curie - Paris 6"
        ],
        "published": "June 7, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Information Extraction",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/akbc2010_gallinari_rlsdl/",
    "segmentation": [
        [
            "I am Patrick greenery from this University paramedic arena in Paris.",
            "And the talk will be about.",
            "Structured outputs OK, so I will introduce a new method which is based on a reinforcement learning.",
            "And then I'll describe an application to the document mapping, and this is a joint work with for Smith, who was a previous student and colleague."
        ],
        [
            "As outlined, so I will first try to to motivate so need for structured structured prediction and then.",
            "I will just.",
            "Give some some brief comments about traditional machine learning approaches.",
            "To this structure prediction problem, then I will introduce this rain reinforcement learning method and describe the experiments.",
            "So the experiments are I will present concerned about mapping and document mapping.",
            "For me it's the transformation of textual document from one format to another format.",
            "So typically you would have an input document, for example in flat text in HTML or XML.",
            "And you want to map this input document onto predefined XML document XML format."
        ],
        [
            "So what is a structured prediction?",
            "So this is simply the prediction of structured, structured objects.",
            "Where are for me an object is described by your set of.",
            "Internal and variables.",
            "So usually for many applications in a in machine learning classification, usually you don't consider the dependencies between the variables, but here.",
            "We want to explicitly take into account services dependencies.",
            "So here are some some examples of social pressure prediction problems.",
            "Maybe the simplest patient problem is a sequence labeling.",
            "Sorry for example you have.",
            "I know OCR sequence OK and you want to label this this input sequence.",
            "So eventually we will want to take into account the sequence or structure of the input.",
            "Maybe the also the sequence.",
            "On the different labels and.",
            "For example in this.",
            "In this case, where here you have a.",
            "Big noisy OK. You have to take into account so context.",
            "Observes input data, so this is.",
            "This is an example of social prediction.",
            "Complex problem is mapping, yeah.",
            "Of trees.",
            "OK so you have for example here input document or database OK.",
            "Unknown, you want to map this structure onto another one or two.",
            "Learn the mapping between two different schemas, for example.",
            "This is application I will talk about later.",
            "And this image here comes from competition.",
            "Web spam competition.",
            "OK so typically you have a sketch of the web here where you have black dots which are spam sites and white ones which are non spam sites.",
            "Well, if you want to detect stability, you will have to deal with this.",
            "Graph graph structured data and try to propagate, which is typical supervised program.",
            "For example, when you label some some data, some some websites and you want to propagate this information into the into the web graph."
        ],
        [
            "Who saw ministration problems in different domains?",
            "OK in biology.",
            "In natural language understanding for example.",
            "Where you have many fun tasks where you have to label sequences to power sequences and so on, translation is another complex complete example in information retrieval.",
            "For example, if you want to promote diversity in a ranking list, you would have to consider the relations between the different retreat items in social networks.",
            "Of course, an entire basis weight and so on."
        ],
        [
            "What's what is the traditional view of a machine learning for for doing this?",
            "So as usual, you have two steps, training step and inference step.",
            "Training, yeah, we use a set of examples.",
            "OK, so this is a typically supervised learning.",
            "OK, you have a set of examples, input and output examples and what you want to learn is to Maps input onto the outputs.",
            "And for the inference, OK, what you want to do is that when you have a new data, you input data you want to predict structure output.",
            "So the big change with respect to most.",
            "Classical tasks in machine learning.",
            "Is that with the structured output you have to consider also into the interdependencies between the outputs and usually at least for real world problems.",
            "The size of the output space will be exponential OK. Like for example, if you consider a graph labeling problem, you can think about all the different potential labelings of graphs in different ways, different labels.",
            "OK, so this is exponential for when you consider for example parsing, you have an input sentence and the number of parts trees would be extremely off also.",
            "Translation and many other problems."
        ],
        [
            "So just some some notations, so I would consider inputs.",
            "Inputs are X, so this is a.",
            "Space of all possible inputs outputs why?",
            "OK, so we have a training set and we consider a loss function, so I do not define this function because it depends on the application.",
            "But let's say that it measures the quality of the prediction structure prediction."
        ],
        [
            "So this is a traditional view of her future prediction in machine learning so.",
            "Usually what you do is that for training.",
            "You want to to learn some form of correspondence or some score function?",
            "OK, this function.",
            "Most of the time will take as input a joint representation of the input and output.",
            "And it will output the score for for a given solution.",
            "So you will use this core function to rank all the potential outputs.",
            "So she's training problem and for inference when you want to solve is to find the best solution.",
            "When you have a new value input.",
            "So you have to search the rule.",
            "Output space.",
            "Which would be quite great here.",
            "OK to find to service.",
            "These are Max problem.",
            "Well, so as I said, so simple space could be could be huge.",
            "OK, which means that in many problems.",
            "You mean you were real problems?",
            "Feelings without Marks is a is intractable, so when people do, usually is that.",
            "As you can see, the specific social position problems typically not too not too complicated, OK, or they make strong hypothesis either on the structure of the outputs.",
            "Let's say on the dependencies between the different variables.",
            "Orange quest function."
        ],
        [
            "So pretty soon it is about two types of.",
            "Difficulties of models of generative discriminative models.",
            "So I will briefly examines the different hypothesis made into 2 cases.",
            "So first generating models.",
            "Typical examples are hidden Markov models or probably sequences for armors and so on.",
            "So usually you make local dependency hypothesis on the bus outputs and on the inputs.",
            "OK, so for example in there put you make your using most often.",
            "1st order Markov assumptions.",
            "Since it was assumptions.",
            "The cost function, which is here usually is a joint like he would update data, will decompose into a simple cost.",
            "Well.",
            "When you want to solve so decoding problem or the go to perform inference, you will have to search the outside space.",
            "Because of this different assumption.",
            "You will be able to use traditional, traditionally dynamic programming techniques.",
            "OK, so this will help to solve them.",
            "To solve the problem, but even.",
            "With this hypothesis, and when you use dynamic programming.",
            "So it's going problem could be quite quite complex.",
            "For example, if you consider trees with populistic grammars, is complicity will be.",
            "Cubic inch.",
            "The length of sentence so.",
            "Who's ready for a sentence would do it, but if you consider, for example, a long document, you cannot, it's creative."
        ],
        [
            "Weather for discrete models.",
            "It's roughly the same.",
            "The same thing.",
            "So here are some examples of well known instrument models like conditional fields and also.",
            "Mini Russia last matching methods have been proposed recently for structured predictions.",
            "So compared to generative models.",
            "Using this one techniques you can encode.",
            "More easily long term differences in's input OK and also between the input and the injury.",
            "So this is a benefit of discrete models.",
            "What's so for some of them you get nice properties like for example generation bounds OK, but typically is a party.",
            "Sources are also same As for generative models, which means that we use Markov hypothesis and the output space and possibility of the of the score function.",
            "And once again.",
            "For decoding.",
            "I mean, at first inference step you have to use something like dynamic programming and once again you have the same.",
            "The same issue."
        ],
        [
            "Where she's just in an example or A twist rates on the phone."
        ],
        [
            "Observations."
        ],
        [
            "They showed that you didn't introduce OK.",
            "So she's a an example of a.",
            "Social prediction, so you have years of problem is parsing.",
            "So we have an input sentence and what you want to to produce this sparse.",
            "And the city Street, but is rated by.",
            "Global method OK, which is an extension of of SVM center typically.",
            "Is the end portion output?",
            "So here goes input sentence.",
            "One of the potential are both of the other sentence, so she said she would put you want to get.",
            "And what you will do is that you will describe this problem using to joint description here.",
            "Of both input and output, and this will be used for learning and for inference.",
            "So typically for this job description you will use the.",
            "A large size vector.",
            "So it's a large size, but it usually it's a very specific vector where you encode different different characteristics.",
            "So for example, here you can see that you incur different.",
            "So let's say derivation rules here for example.",
            "This one here.",
            "Yeah, OK.",
            "Which characteristic of the output?",
            "And here?",
            "You encode the relations between the input present here.",
            "And the energy output.",
            "So yeah, you have some pretty good said to duration rule for determinant.",
            "Produces Z.",
            "Is present twice here here.",
            "OK.",
            "So this is a.",
            "Joint representation of the input and output OK, and what we will do OK with this as an extension is that we will try to learn the score function, so usually it's a linear function, so this is a dot product between this representation and this.",
            "This vector of parameters OK. OK, so you want to learn this function and once again for inference we have to solve this argmax problem.",
            "At inference time, OK, we have to consider all the potential processes of the sentence."
        ],
        [
            "Also, I will now introduce her."
        ],
        [
            "A recent idea which is quite different from the global techniques I am.",
            "I just briefly described.",
            "So this is called incremental learning.",
            "And the the idea here is that since for inference sources sorting this argmax problem is is difficult.",
            "We will try.",
            "To do it in another way.",
            "And if you keep, it will try to do instead of solving this global optimization problem, you will try to build your structure output not as a result of a global optimization, but will try to build it incrementally, which means that you will try to build your structured output one component at a time, for example here."
        ],
        [
            "OK, for this parsing problem, instead of comparing also potential parses, what we try to do is to build this parse tree incrementally.",
            "What?"
        ],
        [
            "So if you are able to do that.",
            "Inference would be quite easy.",
            "OK, we just have to compute the trajectory in this prediction space.",
            "And training will amount to learn to explore this prediction space."
        ],
        [
            "OK, so just a simple restriction where.",
            "OK, so here you have a.",
            "The sequence as input OK and so problem is to label to label this sequence of three elements.",
            "OK, you have two labels, red and blue.",
            "And this search history here simply describes the search space of the problem.",
            "So here, for example, a pass corresponds to labeling of this of this input sequence.",
            "OK, and so two represents order put in shoulders potentially bring so the search space here will be composed of the input sequence an.",
            "All the potential sequences of labels.",
            "So no, I would call you nude.",
            "The state, so I release quite, but it is just just after and.",
            "Each node in each state.",
            "Here you can take two actions are very simple actions, so for example here when you are at the root root state, you can either levels the first node as red or.",
            "OK."
        ],
        [
            "I know so far we insurance."
        ],
        [
            "Provided you are working on this."
        ],
        [
            "And is such space.",
            "What we have to do is to decide which is the right trajectory, OK?",
            "So suppose that we have additional function policy which is able to decide for each state.",
            "Which is the right action, so typically here."
        ],
        [
            "In this state, you know that the right action, for example is red.",
            "Same thing here.",
            "So next week question is blue, and so on."
        ],
        [
            "So suppose you have this different function then.",
            "OK, so you said you could perform inference greedy.",
            "OK, so you start from the root state then.",
            "You produce.",
            "Sorry, you produce your first partial output here.",
            "This is the first label, then the seven partial put just one label here and so on, and you have enabled for your segments.",
            "So, provided you have this position function.",
            "You must problem will be solved quite easily.",
            "OK, and here's inference.",
            "We have a linear complexity.",
            "OK, in the size of the screen and you will not need anymore so.",
            "Dynamic programming or.",
            "In use of such techniques versus the problem now is how do you learn this?",
            "Function to do that, you have to learn to move in this search space, which is which might be quite complex.",
            "Search space OK. You know, in order to do that, you have to to make some tea."
        ],
        [
            "This is.",
            "What is the?",
            "Idea for incremental learning was first introduced by by 6 guys here by Collins.",
            "For incremental parsing an old domain.",
            "OK, proposed questionnaire algorithms which are called the last one.",
            "I'm sorry.",
            "And in their method the they make different different assumptions about the nature of the problem and the quality of the supervision, for example.",
            "Franklin passing these are special assumption which is the following.",
            "OK, here you suppose that you have access to an optimal learning learning trajectory.",
            "So for example here again I consider a sequence labeling problem OK. And typically.",
            "So you have an input here, which is typically an author input.",
            "You have SOS OK and you want to label it correctly.",
            "And the you suppose that training time you know that the correct label for this first letter is S. For suddenly there is oh and so forth.",
            "Illustrator is OK, so you suppose you have access to this information.",
            "For the sole method.",
            "You have a stronger assumption which is called optimal learning policy.",
            "And.",
            "This assumption says that.",
            "Not only you have access to optimal learning trajectories, but even if doing the inference process of the training process to make an error.",
            "You know?",
            "What will be the next best move?",
            "OK, you don't know to correct the error, but you know that if you make this error OK in order to get.",
            "And I would put.",
            "Which is quite correct.",
            "You would have to do such and such move.",
            "OK, so typically here maybe tomorrow."
        ],
        [
            "Is your 2017 here?",
            "Suppose that my target is this red, red pass.",
            "Here, if I make an error, I know that the next move the best move.",
            "If I made this error, is this one and this one right so there?"
        ],
        [
            "Play stronger."
        ],
        [
            "My.",
            "So now let me introduce some of the ideas of the.",
            "Reinforcement learning for this problem this problem?",
            "So I will introduce a model for structure prediction which is based based on the Markov chain processes.",
            "So usually my condition processes are used to model A sequential decision making.",
            "So this will be the model of social prediction and I will use agorism different families of reinforcement learning.",
            "So usually reinforcement learning techniques could be used to trade mark additional processes, so it should provide quite general framework for this social position problem.",
            "OK, and this means that provided you have this formulation formalisation OK, you could use many different on the shelf reinforcement learning algorithm to train your Markov process.",
            "And and also benefit is that you will not need.",
            "Just to let some assumptions, I just described.",
            "OK so you will be able to learn with very very weak assumptions about.",
            "The problem about the nature of supervision information OK and potentially will be able to deal with the larger class of problems."
        ],
        [
            "Reschedule for processes.",
            "OK, so in Mcafee's own process, you have four components, states, actions, transitions, and rewards.",
            "So I will use this small example here.",
            "You have an input sequence.",
            "OK typically comes from this error.",
            "You have the three letters.",
            "And you want to to label this sequence correctly.",
            "So here is the correct solution.",
            "So state here.",
            "Will be a description of the input, this sequence and the partial output.",
            "So here for example, for the initial state.",
            "So partial, so the state is composed only of the input sequence and so partial put this is empty.",
            "Here at this stage, OK, you have two letters here on this, together with input.",
            "Connection here.",
            "Defines some modification of the parser output.",
            "So typically here you could label this, for example this letter as S or as a whole, or this one as oh and something for the next one.",
            "OK, so this is an action, so you're typically OK. You have different section.",
            "You can choose both.",
            "The location you want to label and then the label.",
            "OK. Well, so this is formalized by your transition function.",
            "So transition here takes state opponent selection and produce a new state.",
            "So you start from this state, you choose an action and you produce system state OK, and by the end when you are finished OK. You get a reward.",
            "And the reward measures the quality of the prediction.",
            "So typically here.",
            "You have the correct output.",
            "OK, and here you have something which is wrong.",
            "Sorry.",
            "Very often magician processes are used.",
            "To explore unknown environments, for example for navigation tasks.",
            "Which can secure for, let's say for robot in amazing OK. You can model the development of the robots using this kind of process, so.",
            "Your robot, he doesn't knows.",
            "It doesn't know there's a maze removes and when you get stuck somewhere.",
            "You get a relative reward.",
            "OK, and if sometimes you find the exit you get positive reward and then you will learn.",
            "How to go to move into into the into the base?",
            "Structured prediction problem is easy, yeah sure.",
            "No, no no.",
            "It's just easier to explain."
        ],
        [
            "No.",
            "For example, for suppressing parsing problem.",
            "OK, so will description of the problem would be quite more complex again.",
            "For example, the state description is not trivial's actions, and so on.",
            "Well, so here we have this.",
            "It's a fundamental property.",
            "And the idea of modeling the social position problem with some DPS.",
            "Re licenses on this property.",
            "So this says that under some hypothesis.",
            "Maximizing's expectation of Torrey Ward, which is what we do usually in with MDPSOK, is equivalent to minimizing the structured prediction loss.",
            "OK, so typically this is what you do with reinforcement learning OK, or when you want to train to train and GPS and typically here.",
            "This is what you do with.",
            "Supervised learning.",
            "So besides I will develop relies on this fully resistance property and this provides a or so in this case a bridge between reinforcement learning and.",
            "And.",
            "Understructure prediction."
        ],
        [
            "Rifle for people who know NDPS.",
            "So some of the things we are using here, is it a little bit special?",
            "First, OK usually and EPS or Stochastics and here we are using deterministic MDP's OK. And then, for example, features of the example of the robot in the in the maze.",
            "OK, So what we move an for each move?",
            "OK, after some moves you will get to reward.",
            "OK, so she's a typical is never ending a story for four year olds continuously.",
            "Yep.",
            "The initial problem is not a reinforcement learning problem, but this is a supervised learning problem.",
            "So typically we will get.",
            "Some training examples.",
            "And then a.",
            "No more supervision.",
            "Which means that at inference time we will get input data.",
            "On the hopefully will be able to generalize and to produce across social output, but you will not get anymore any reinforcement signal.",
            "OK, any reward?",
            "OK, so this is different well.",
            "So what you have to do is to learn on the set of training example, an awful year if you do well, your technique will be able to.",
            "Vagina."
        ],
        [
            "Price.",
            "So typically, in order to do that, we will use what we called with approximate approximated reinforcement learning.",
            "This means that in order to learn the different functions also policy OK will use a linear function, so as before we use a joint description of the input and the output of the state of the actions here OK. And we try to learn.",
            "A linear function.",
            "And see this new function we don't know to provide the correct decision.",
            "OK. Did you see my function will be?",
            "We provide the policy.",
            "OK so decision so alright, this decision at each step of the process.",
            "Well, so here the goal is to learn the parameter vector versus linear function.",
            "Here you're also have a Max problem, but here's our Max is on also potential actions in a given state you have finite set of actions, so this is quite different.",
            "After global landmarks.",
            "Problem welder I described before and for learning we could use any reinforcement learning technique."
        ],
        [
            "So just a brief description here on the simple problem of.",
            "After transcription for state action pairs, so once again this is a sequence sequence labeling problem here.",
            "So we have this word.",
            "Hello Ann here you have already processed OK since it's such a labels so different letters from left to right you have already processed.",
            "So first 3 letters Ann.",
            "You are into the process of labeling so so first one.",
            "So you have already zuza different flavors here.",
            "This is a description.",
            "Of the state.",
            "And the first of the actions.",
            "OK, so you could see that, but it's a binary vector.",
            "As before, it could be quite large and it encodes differences.",
            "Typically it includes relations between the state and actions.",
            "So for example here you have this action.",
            "Which is labeled here.",
            "We saw one.",
            "Whether the action is the decider L here.",
            "OK, if you decide to help.",
            "And sometimes the stick of the image.",
            "For example here, the given pixel in the image is black or white or whatever.",
            "OK, so this relates to transcription of actual an action, an input input data and you also have joined the scription of actions and output that.",
            "For example, here is the context of.",
            "As we become popular neighborhood already been.",
            "Bing predicted.",
            "So typically what you should have in mind is that for all these problems we have.",
            "Very large description spaces OK, but there will be sparse descriptions.",
            "OK, we saw only some bits here.",
            "Your present."
        ],
        [
            "OK so just to show that this kind of technique work.",
            "We have benchmarked this kind of different categories on this front.",
            "Different reinforcement learning algorithm and the unclassical.",
            "Physical benchmarks for sequence prediction.",
            "So I won't go into the details.",
            "So this corresponds to different different datasets.",
            "OK, in blue you have a baseline results, so this is the best baseline and we have compared different different baseline.",
            "OK, so SVM typically CRF's structure in C and so on, and here in red and green you have two different reinforcement learning methods so that we can see here is that the performance is our performance is similar.",
            "In some cases, for example for this specific that I said where you have long term relations into that are, you get better results, but roughly speaking it's.",
            "It's morissette.",
            "So what's what?",
            "HW is on rating.",
            "On the on the rating.",
            "OK.",
            "So, but if you want to solve.",
            "Sequence labeling problem OK. Can you have you already have a set of very good techniques so it's not useful to use this kind of refund?",
            "Super interesting things.",
            "OK, so this is just to show that.",
            "Which is basically the state of the art on this on this problems well."
        ],
        [
            "So now I will introduce a tricky, more more complex problem which is in mapping.",
            "So as I said.",
            "So goal is to learn transformation.",
            "From one one document format, So document format.",
            "OK. For us in machine learning, this is a general.",
            "Problem, I mean learning how to map a tree onto another on another treat quite difficult problem.",
            "For the insurgency, it's interesting, but here I will deal only with very specific application which is a document situation.",
            "So typically in the experiments.",
            "But I will show is out convert different input formats that text, email or XML into a structured Excel format OK?",
            "On the in fact, this kind of problem, learning from mapping was the initial motivation for deriving these algorithms, because at that time we were working on information retrieval for XML data.",
            "OK, and the goal for Excel information retrieval is not to produce around list of document, but to produce a long list of items of XML items.",
            "Let's say two wrongs subtrees OK, what we want to get.",
            "Is to get.",
            "A subtree of an external document which is more relevant and some more specific for a given query.",
            "OK.",
            "But you can also have many front also application fields like information extraction, document collection and whatever."
        ],
        [
            "So we have studied two classes of transformation.",
            "First one is what we call a one to one transformation.",
            "This means that, for example, this input document that area document.",
            "This is the.",
            "Both the input and the target document will have the same sequence of leaves.",
            "OK, so this is a.",
            "Quite normal exceptions for many year documentaries for initial problems.",
            "OK, because it treats from OK. From left to right, let's say OK, but we also studied more complex transformations where it was possible to move here to exchange.",
            "The leaves of the input and between the input and the output and also to skip skip summer.",
            "Information."
        ],
        [
            "By supporting this quick complex here because you have a very large number of mappings, OK, you have to under both the content structure OK?",
            "Some documents would be quite large and say which I wish was actually thrown and for this problem you have no optimal learning policy.",
            "OK. An optimal learning trajectory and typically.",
            "OK, so global like could not be employed for this kind of problem.",
            "Just a previously."
        ],
        [
            "None of her to States and actions here.",
            "Typically what we will do is that you will take an input document.",
            "We will process the leaders of the document one at a time.",
            "And the state is a descripcion of the input document and the partial output tree here, and an action consists in attaching a path OK, an XML path which ends with the current leaf to a given position in the partial tree.",
            "OK, and both the path and the positions are learned from the training data.",
            "OK.",
            "But OK, and for training we use the loss function, which is a kind of F score for trees."
        ],
        [
            "Where so typically orthoses interest rates of States and action for some policies with partial output tree and we're processing this leave here John Walker an so different potential actions and what we could do is attached here.",
            "This path at this node or here's relief at this node or eventually here.",
            "Skips, skips loaded, not appear into the fire into final tree."
        ],
        [
            "OK, so just a brief description of how it works."
        ],
        [
            "Any put document here?",
            "And you want to trance?"
        ],
        [
            "It includes this document of."
        ],
        [
            "Also, at the inference time, you don't know what is the designer would put."
        ],
        [
            "So this is a manual movie.",
            "OK, you can see the 1st."
        ],
        [
            "The first leaf.",
            "You create a."
        ],
        [
            "Brunch in Cyprus."
        ],
        [
            "Me."
        ],
        [
            "You consider this one."
        ],
        [
            "Leave.",
            "Someone branch."
        ],
        [
            "So leave up."
        ],
        [
            "You inserted in between."
        ],
        [
            "OK, and so."
        ],
        [
            "OK. And finally you don't."
        ],
        [
            "You do not want this one, so you get this this final tree."
        ],
        [
            "Well, since this is a quite complex problem with compression problem, you will make some assumptions OK for example.",
            "We learn the OK. End of grammar of the.",
            "Of the desired output.",
            "For example, during the transformation, we only allow path.",
            "Which appear in the training set OK and same thing we only allow sibling labels which appearances winning set plus OK. Use some additional constraints."
        ],
        [
            "OK, so you again I will not describe them, but the features or specific description in a very high dimensional space.",
            "Typically we were working with spaces like 10,000 or 100,000 features or even more OK, and this subscription will characterize both input.",
            "Input, content, infrastructure and the output structure."
        ],
        [
            "OK.",
            "Some tests have been doing on different collections.",
            "So typically it's a description of textual documents here.",
            "Here you have the transformation problem.",
            "For example, here we went to transform an input that I was just in XML into another Excel format.",
            "OK here HTML into Excel and so on.",
            "This is to example input text, sorrow text, flat text.",
            "I want to produce an XML format.",
            "So basically here we have three smaller corpora.",
            "OK, I called that small because so documents inside are quite small and two larger corpora OK.",
            "So for example, this is a real estate copper app developed by an Idol here somewhere.",
            "Anne Shakespeare or ratings of Shakespeare Anne this is a collection of IEEE journals, and this is OK. Data extracted from Wikipedia.",
            "So you can see that for example, here, for these two sets here you have around 150, two 150 different potential labels."
        ],
        [
            "Well."
        ],
        [
            "So here are some are.",
            "Some performance.",
            "So we have used different different measures.",
            "So.",
            "To make it short, for example when you want."
        ],
        [
            "Compare 2 trees for some places, pretty big tree and the.",
            "Desired output three OK. You can do it in in different ways.",
            "For example, you can compare.",
            "The sequences of leaves and their labels OK. You can compare the different paths in the trees also differ or you can compare all the subtrees.",
            "OK, so we have been using different measures OK. We said it was compared trees, sorry leaves.",
            "Bath and also trees."
        ],
        [
            "OK, and this is what appears here, so you can see that for example here.",
            "Forces are different measures OK?",
            "You get quite strong performance.",
            "OK, so he's OK.",
            "This is not perfect, but this is a nearly perfect.",
            "OK.",
            "So this means that this reference modeling technique.",
            "Further, can known and so able to generalize.",
            "OK."
        ],
        [
            "And as a larger corpora, whether it's a better man, Caesar is degraded, but it's still OK.",
            "It means that it does something.",
            "OK, so you must think that typically you have around 700 nodes, parallel payment with several thousand nodes for some documents, and a lot of flavors.",
            "Well.",
            "And the OK.",
            "So by doing this.",
            "Inference is quite fast.",
            "OK, so typically to process your document it takes 1 second OK, but reinforcement learning is not so fast.",
            "OK, so it might take days to train on the logical corollary correct as well."
        ],
        [
            "And that's it.",
            "Try to.",
            "Trying to remember that this attractive extinction between this and the and the CERN in a sort of turning it's.",
            "Modern incarnation, which doesn't have a requirement that the that from any state or is there is a path to completion so that I'm not sure that I I don't know what I mean.",
            "Of course is the results are interesting.",
            "I'm just trying to understand is that the fundamental difference between what you proposed in CERN?",
            "Typically to send the OK is the same family of missiles.",
            "OK to increment on this?",
            "OK, except that here we are using.",
            "Or enforcement learning techniques OK, whereas in concern is using typically a classifier at each node to make a decision OK?",
            "If they threaten noise is a service of reinforcement learning analysis.",
            "That's what they do.",
            "And the classifier, and so that's what I don't understand is today.",
            "I mean whenever I've heard talks about certain results in terms of forcement learning, so you know struggling here.",
            "No, I think that their relations between the sun and a reinforcement learning OK, but it is typically what he's using is supervised training of.",
            "Yeah.",
            "Well, I guess I'll have to ask John Langford because he presents it that way, so yeah, sure.",
            "Here is that you don't need to know for the ground truth set of actions to get to the goal in your framework, whereas last loan Sir, you might even know that to make the incremental updates language so really well done, Sir.",
            "Right?",
            "And also OK for training.",
            "OK, and certainly makes this a central assumption.",
            "OK about the optimal learning.",
            "Running trajectories OK.",
            "The paper so.",
            "OK so I I was checking 'cause I I was confused about the universe always actually pulled the paper jam on the MLJ Pepper 19.",
            "It doesn't make it so.",
            "I know quick release paper yesterday.",
            "Yeah.",
            "OK, typically so difference into interceptions and then on the other machinery.",
            "OK, So what you are using here?",
            "OK, so different the.",
            "Examples are I sure.",
            "Present for the benchmarks have been using traditional are enforcement learning techniques OK?",
            "Also in Sonny's as his own is on missiles better.",
            "Yes, I'm sure that.",
            "Is using supervised learning?",
            "It's originally a sphere.",
            "Yeah.",
            "So using the loss function as your reward at the end and loss function is defined on the complete leveling quiet.",
            "But you can imagine even a partial labeling.",
            "You can calculate some kind of gloss, sure.",
            "Angos intermediate rewards and you think that will benefit yes.",
            "Yes.",
            "In fact, when.",
            "Well.",
            "For example, services dismissed as we saw.",
            "OK, yeah.",
            "You can use.",
            "Eyes are very pisode or prayer decision reward.",
            "Very episode.",
            "I mean at the end OK?",
            "Or their decision reward?",
            "OK, so we have performed experiments with all the possibilities and also intermediate possibilities.",
            "And of course if you can compute an intermediate score.",
            "Even if you give, it provides an imperfect supervision.",
            "It's worth your it's worse.",
            "Yes, yes.",
            "When you can use a position, you have to use it.",
            "Yes, it's much faster.",
            "Typically, typically it will converge very fast here.",
            "Strange to limit expiration is that only during training or also which constraint?",
            "Exploration.",
            "This is kind of constraint here.",
            "Alright well yeah yeah.",
            "Training or also.",
            "In fact, during training.",
            "Here, typically what you do is that you learn.",
            "Kind of grammar of your of your target target trees?",
            "OK, what I mean?",
            "Is that OK?",
            "Here for example you.",
            "You learn all the possible possible paths in the target, treason.",
            "In the examples on the training set.",
            "OK, and then for doing inference.",
            "Only this pass, for example, will be a.",
            "Available OK, you cannot use any OK, otherwise it's completely OK, otherwise the space is really.",
            "Is meant to be.",
            "But typically first for POSIX payments, we have been using doing here.",
            "OK, so consider IEEE journals.",
            "OK bye OK, just looking at some examples.",
            "I've had some papers.",
            "OK, you have an idea of the sale DTD.",
            "OK.",
            "Even if you have two different sources, it's quite easy."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I am Patrick greenery from this University paramedic arena in Paris.",
                    "label": 0
                },
                {
                    "sent": "And the talk will be about.",
                    "label": 0
                },
                {
                    "sent": "Structured outputs OK, so I will introduce a new method which is based on a reinforcement learning.",
                    "label": 1
                },
                {
                    "sent": "And then I'll describe an application to the document mapping, and this is a joint work with for Smith, who was a previous student and colleague.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As outlined, so I will first try to to motivate so need for structured structured prediction and then.",
                    "label": 1
                },
                {
                    "sent": "I will just.",
                    "label": 0
                },
                {
                    "sent": "Give some some brief comments about traditional machine learning approaches.",
                    "label": 1
                },
                {
                    "sent": "To this structure prediction problem, then I will introduce this rain reinforcement learning method and describe the experiments.",
                    "label": 1
                },
                {
                    "sent": "So the experiments are I will present concerned about mapping and document mapping.",
                    "label": 0
                },
                {
                    "sent": "For me it's the transformation of textual document from one format to another format.",
                    "label": 0
                },
                {
                    "sent": "So typically you would have an input document, for example in flat text in HTML or XML.",
                    "label": 0
                },
                {
                    "sent": "And you want to map this input document onto predefined XML document XML format.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is a structured prediction?",
                    "label": 1
                },
                {
                    "sent": "So this is simply the prediction of structured, structured objects.",
                    "label": 1
                },
                {
                    "sent": "Where are for me an object is described by your set of.",
                    "label": 0
                },
                {
                    "sent": "Internal and variables.",
                    "label": 0
                },
                {
                    "sent": "So usually for many applications in a in machine learning classification, usually you don't consider the dependencies between the variables, but here.",
                    "label": 0
                },
                {
                    "sent": "We want to explicitly take into account services dependencies.",
                    "label": 0
                },
                {
                    "sent": "So here are some some examples of social pressure prediction problems.",
                    "label": 0
                },
                {
                    "sent": "Maybe the simplest patient problem is a sequence labeling.",
                    "label": 0
                },
                {
                    "sent": "Sorry for example you have.",
                    "label": 0
                },
                {
                    "sent": "I know OCR sequence OK and you want to label this this input sequence.",
                    "label": 0
                },
                {
                    "sent": "So eventually we will want to take into account the sequence or structure of the input.",
                    "label": 0
                },
                {
                    "sent": "Maybe the also the sequence.",
                    "label": 0
                },
                {
                    "sent": "On the different labels and.",
                    "label": 0
                },
                {
                    "sent": "For example in this.",
                    "label": 0
                },
                {
                    "sent": "In this case, where here you have a.",
                    "label": 0
                },
                {
                    "sent": "Big noisy OK. You have to take into account so context.",
                    "label": 0
                },
                {
                    "sent": "Observes input data, so this is.",
                    "label": 0
                },
                {
                    "sent": "This is an example of social prediction.",
                    "label": 0
                },
                {
                    "sent": "Complex problem is mapping, yeah.",
                    "label": 0
                },
                {
                    "sent": "Of trees.",
                    "label": 0
                },
                {
                    "sent": "OK so you have for example here input document or database OK.",
                    "label": 0
                },
                {
                    "sent": "Unknown, you want to map this structure onto another one or two.",
                    "label": 0
                },
                {
                    "sent": "Learn the mapping between two different schemas, for example.",
                    "label": 0
                },
                {
                    "sent": "This is application I will talk about later.",
                    "label": 0
                },
                {
                    "sent": "And this image here comes from competition.",
                    "label": 0
                },
                {
                    "sent": "Web spam competition.",
                    "label": 0
                },
                {
                    "sent": "OK so typically you have a sketch of the web here where you have black dots which are spam sites and white ones which are non spam sites.",
                    "label": 0
                },
                {
                    "sent": "Well, if you want to detect stability, you will have to deal with this.",
                    "label": 0
                },
                {
                    "sent": "Graph graph structured data and try to propagate, which is typical supervised program.",
                    "label": 0
                },
                {
                    "sent": "For example, when you label some some data, some some websites and you want to propagate this information into the into the web graph.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who saw ministration problems in different domains?",
                    "label": 1
                },
                {
                    "sent": "OK in biology.",
                    "label": 0
                },
                {
                    "sent": "In natural language understanding for example.",
                    "label": 1
                },
                {
                    "sent": "Where you have many fun tasks where you have to label sequences to power sequences and so on, translation is another complex complete example in information retrieval.",
                    "label": 0
                },
                {
                    "sent": "For example, if you want to promote diversity in a ranking list, you would have to consider the relations between the different retreat items in social networks.",
                    "label": 0
                },
                {
                    "sent": "Of course, an entire basis weight and so on.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's what is the traditional view of a machine learning for for doing this?",
                    "label": 1
                },
                {
                    "sent": "So as usual, you have two steps, training step and inference step.",
                    "label": 0
                },
                {
                    "sent": "Training, yeah, we use a set of examples.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is a typically supervised learning.",
                    "label": 0
                },
                {
                    "sent": "OK, you have a set of examples, input and output examples and what you want to learn is to Maps input onto the outputs.",
                    "label": 0
                },
                {
                    "sent": "And for the inference, OK, what you want to do is that when you have a new data, you input data you want to predict structure output.",
                    "label": 0
                },
                {
                    "sent": "So the big change with respect to most.",
                    "label": 0
                },
                {
                    "sent": "Classical tasks in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Is that with the structured output you have to consider also into the interdependencies between the outputs and usually at least for real world problems.",
                    "label": 0
                },
                {
                    "sent": "The size of the output space will be exponential OK. Like for example, if you consider a graph labeling problem, you can think about all the different potential labelings of graphs in different ways, different labels.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is exponential for when you consider for example parsing, you have an input sentence and the number of parts trees would be extremely off also.",
                    "label": 0
                },
                {
                    "sent": "Translation and many other problems.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just some some notations, so I would consider inputs.",
                    "label": 0
                },
                {
                    "sent": "Inputs are X, so this is a.",
                    "label": 0
                },
                {
                    "sent": "Space of all possible inputs outputs why?",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a training set and we consider a loss function, so I do not define this function because it depends on the application.",
                    "label": 0
                },
                {
                    "sent": "But let's say that it measures the quality of the prediction structure prediction.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a traditional view of her future prediction in machine learning so.",
                    "label": 0
                },
                {
                    "sent": "Usually what you do is that for training.",
                    "label": 0
                },
                {
                    "sent": "You want to to learn some form of correspondence or some score function?",
                    "label": 1
                },
                {
                    "sent": "OK, this function.",
                    "label": 0
                },
                {
                    "sent": "Most of the time will take as input a joint representation of the input and output.",
                    "label": 0
                },
                {
                    "sent": "And it will output the score for for a given solution.",
                    "label": 0
                },
                {
                    "sent": "So you will use this core function to rank all the potential outputs.",
                    "label": 1
                },
                {
                    "sent": "So she's training problem and for inference when you want to solve is to find the best solution.",
                    "label": 0
                },
                {
                    "sent": "When you have a new value input.",
                    "label": 0
                },
                {
                    "sent": "So you have to search the rule.",
                    "label": 0
                },
                {
                    "sent": "Output space.",
                    "label": 0
                },
                {
                    "sent": "Which would be quite great here.",
                    "label": 0
                },
                {
                    "sent": "OK to find to service.",
                    "label": 1
                },
                {
                    "sent": "These are Max problem.",
                    "label": 0
                },
                {
                    "sent": "Well, so as I said, so simple space could be could be huge.",
                    "label": 0
                },
                {
                    "sent": "OK, which means that in many problems.",
                    "label": 0
                },
                {
                    "sent": "You mean you were real problems?",
                    "label": 0
                },
                {
                    "sent": "Feelings without Marks is a is intractable, so when people do, usually is that.",
                    "label": 1
                },
                {
                    "sent": "As you can see, the specific social position problems typically not too not too complicated, OK, or they make strong hypothesis either on the structure of the outputs.",
                    "label": 0
                },
                {
                    "sent": "Let's say on the dependencies between the different variables.",
                    "label": 0
                },
                {
                    "sent": "Orange quest function.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So pretty soon it is about two types of.",
                    "label": 0
                },
                {
                    "sent": "Difficulties of models of generative discriminative models.",
                    "label": 0
                },
                {
                    "sent": "So I will briefly examines the different hypothesis made into 2 cases.",
                    "label": 0
                },
                {
                    "sent": "So first generating models.",
                    "label": 0
                },
                {
                    "sent": "Typical examples are hidden Markov models or probably sequences for armors and so on.",
                    "label": 1
                },
                {
                    "sent": "So usually you make local dependency hypothesis on the bus outputs and on the inputs.",
                    "label": 1
                },
                {
                    "sent": "OK, so for example in there put you make your using most often.",
                    "label": 0
                },
                {
                    "sent": "1st order Markov assumptions.",
                    "label": 0
                },
                {
                    "sent": "Since it was assumptions.",
                    "label": 0
                },
                {
                    "sent": "The cost function, which is here usually is a joint like he would update data, will decompose into a simple cost.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "When you want to solve so decoding problem or the go to perform inference, you will have to search the outside space.",
                    "label": 0
                },
                {
                    "sent": "Because of this different assumption.",
                    "label": 0
                },
                {
                    "sent": "You will be able to use traditional, traditionally dynamic programming techniques.",
                    "label": 0
                },
                {
                    "sent": "OK, so this will help to solve them.",
                    "label": 0
                },
                {
                    "sent": "To solve the problem, but even.",
                    "label": 1
                },
                {
                    "sent": "With this hypothesis, and when you use dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "So it's going problem could be quite quite complex.",
                    "label": 0
                },
                {
                    "sent": "For example, if you consider trees with populistic grammars, is complicity will be.",
                    "label": 0
                },
                {
                    "sent": "Cubic inch.",
                    "label": 0
                },
                {
                    "sent": "The length of sentence so.",
                    "label": 0
                },
                {
                    "sent": "Who's ready for a sentence would do it, but if you consider, for example, a long document, you cannot, it's creative.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Weather for discrete models.",
                    "label": 0
                },
                {
                    "sent": "It's roughly the same.",
                    "label": 0
                },
                {
                    "sent": "The same thing.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples of well known instrument models like conditional fields and also.",
                    "label": 0
                },
                {
                    "sent": "Mini Russia last matching methods have been proposed recently for structured predictions.",
                    "label": 0
                },
                {
                    "sent": "So compared to generative models.",
                    "label": 0
                },
                {
                    "sent": "Using this one techniques you can encode.",
                    "label": 0
                },
                {
                    "sent": "More easily long term differences in's input OK and also between the input and the injury.",
                    "label": 1
                },
                {
                    "sent": "So this is a benefit of discrete models.",
                    "label": 0
                },
                {
                    "sent": "What's so for some of them you get nice properties like for example generation bounds OK, but typically is a party.",
                    "label": 1
                },
                {
                    "sent": "Sources are also same As for generative models, which means that we use Markov hypothesis and the output space and possibility of the of the score function.",
                    "label": 0
                },
                {
                    "sent": "And once again.",
                    "label": 1
                },
                {
                    "sent": "For decoding.",
                    "label": 0
                },
                {
                    "sent": "I mean, at first inference step you have to use something like dynamic programming and once again you have the same.",
                    "label": 0
                },
                {
                    "sent": "The same issue.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where she's just in an example or A twist rates on the phone.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observations.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They showed that you didn't introduce OK.",
                    "label": 0
                },
                {
                    "sent": "So she's a an example of a.",
                    "label": 0
                },
                {
                    "sent": "Social prediction, so you have years of problem is parsing.",
                    "label": 0
                },
                {
                    "sent": "So we have an input sentence and what you want to to produce this sparse.",
                    "label": 0
                },
                {
                    "sent": "And the city Street, but is rated by.",
                    "label": 0
                },
                {
                    "sent": "Global method OK, which is an extension of of SVM center typically.",
                    "label": 0
                },
                {
                    "sent": "Is the end portion output?",
                    "label": 0
                },
                {
                    "sent": "So here goes input sentence.",
                    "label": 0
                },
                {
                    "sent": "One of the potential are both of the other sentence, so she said she would put you want to get.",
                    "label": 0
                },
                {
                    "sent": "And what you will do is that you will describe this problem using to joint description here.",
                    "label": 0
                },
                {
                    "sent": "Of both input and output, and this will be used for learning and for inference.",
                    "label": 0
                },
                {
                    "sent": "So typically for this job description you will use the.",
                    "label": 0
                },
                {
                    "sent": "A large size vector.",
                    "label": 0
                },
                {
                    "sent": "So it's a large size, but it usually it's a very specific vector where you encode different different characteristics.",
                    "label": 0
                },
                {
                    "sent": "So for example, here you can see that you incur different.",
                    "label": 0
                },
                {
                    "sent": "So let's say derivation rules here for example.",
                    "label": 0
                },
                {
                    "sent": "This one here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "Which characteristic of the output?",
                    "label": 0
                },
                {
                    "sent": "And here?",
                    "label": 0
                },
                {
                    "sent": "You encode the relations between the input present here.",
                    "label": 0
                },
                {
                    "sent": "And the energy output.",
                    "label": 0
                },
                {
                    "sent": "So yeah, you have some pretty good said to duration rule for determinant.",
                    "label": 0
                },
                {
                    "sent": "Produces Z.",
                    "label": 0
                },
                {
                    "sent": "Is present twice here here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "Joint representation of the input and output OK, and what we will do OK with this as an extension is that we will try to learn the score function, so usually it's a linear function, so this is a dot product between this representation and this.",
                    "label": 0
                },
                {
                    "sent": "This vector of parameters OK. OK, so you want to learn this function and once again for inference we have to solve this argmax problem.",
                    "label": 0
                },
                {
                    "sent": "At inference time, OK, we have to consider all the potential processes of the sentence.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, I will now introduce her.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A recent idea which is quite different from the global techniques I am.",
                    "label": 0
                },
                {
                    "sent": "I just briefly described.",
                    "label": 0
                },
                {
                    "sent": "So this is called incremental learning.",
                    "label": 0
                },
                {
                    "sent": "And the the idea here is that since for inference sources sorting this argmax problem is is difficult.",
                    "label": 0
                },
                {
                    "sent": "We will try.",
                    "label": 0
                },
                {
                    "sent": "To do it in another way.",
                    "label": 0
                },
                {
                    "sent": "And if you keep, it will try to do instead of solving this global optimization problem, you will try to build your structure output not as a result of a global optimization, but will try to build it incrementally, which means that you will try to build your structured output one component at a time, for example here.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, for this parsing problem, instead of comparing also potential parses, what we try to do is to build this parse tree incrementally.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you are able to do that.",
                    "label": 0
                },
                {
                    "sent": "Inference would be quite easy.",
                    "label": 0
                },
                {
                    "sent": "OK, we just have to compute the trajectory in this prediction space.",
                    "label": 1
                },
                {
                    "sent": "And training will amount to learn to explore this prediction space.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just a simple restriction where.",
                    "label": 0
                },
                {
                    "sent": "OK, so here you have a.",
                    "label": 0
                },
                {
                    "sent": "The sequence as input OK and so problem is to label to label this sequence of three elements.",
                    "label": 0
                },
                {
                    "sent": "OK, you have two labels, red and blue.",
                    "label": 0
                },
                {
                    "sent": "And this search history here simply describes the search space of the problem.",
                    "label": 0
                },
                {
                    "sent": "So here, for example, a pass corresponds to labeling of this of this input sequence.",
                    "label": 0
                },
                {
                    "sent": "OK, and so two represents order put in shoulders potentially bring so the search space here will be composed of the input sequence an.",
                    "label": 1
                },
                {
                    "sent": "All the potential sequences of labels.",
                    "label": 0
                },
                {
                    "sent": "So no, I would call you nude.",
                    "label": 0
                },
                {
                    "sent": "The state, so I release quite, but it is just just after and.",
                    "label": 0
                },
                {
                    "sent": "Each node in each state.",
                    "label": 0
                },
                {
                    "sent": "Here you can take two actions are very simple actions, so for example here when you are at the root root state, you can either levels the first node as red or.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I know so far we insurance.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Provided you are working on this.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And is such space.",
                    "label": 0
                },
                {
                    "sent": "What we have to do is to decide which is the right trajectory, OK?",
                    "label": 0
                },
                {
                    "sent": "So suppose that we have additional function policy which is able to decide for each state.",
                    "label": 1
                },
                {
                    "sent": "Which is the right action, so typically here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this state, you know that the right action, for example is red.",
                    "label": 0
                },
                {
                    "sent": "Same thing here.",
                    "label": 0
                },
                {
                    "sent": "So next week question is blue, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So suppose you have this different function then.",
                    "label": 0
                },
                {
                    "sent": "OK, so you said you could perform inference greedy.",
                    "label": 0
                },
                {
                    "sent": "OK, so you start from the root state then.",
                    "label": 0
                },
                {
                    "sent": "You produce.",
                    "label": 0
                },
                {
                    "sent": "Sorry, you produce your first partial output here.",
                    "label": 0
                },
                {
                    "sent": "This is the first label, then the seven partial put just one label here and so on, and you have enabled for your segments.",
                    "label": 0
                },
                {
                    "sent": "So, provided you have this position function.",
                    "label": 0
                },
                {
                    "sent": "You must problem will be solved quite easily.",
                    "label": 0
                },
                {
                    "sent": "OK, and here's inference.",
                    "label": 0
                },
                {
                    "sent": "We have a linear complexity.",
                    "label": 1
                },
                {
                    "sent": "OK, in the size of the screen and you will not need anymore so.",
                    "label": 0
                },
                {
                    "sent": "Dynamic programming or.",
                    "label": 0
                },
                {
                    "sent": "In use of such techniques versus the problem now is how do you learn this?",
                    "label": 0
                },
                {
                    "sent": "Function to do that, you have to learn to move in this search space, which is which might be quite complex.",
                    "label": 1
                },
                {
                    "sent": "Search space OK. You know, in order to do that, you have to to make some tea.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "Idea for incremental learning was first introduced by by 6 guys here by Collins.",
                    "label": 0
                },
                {
                    "sent": "For incremental parsing an old domain.",
                    "label": 1
                },
                {
                    "sent": "OK, proposed questionnaire algorithms which are called the last one.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "And in their method the they make different different assumptions about the nature of the problem and the quality of the supervision, for example.",
                    "label": 0
                },
                {
                    "sent": "Franklin passing these are special assumption which is the following.",
                    "label": 0
                },
                {
                    "sent": "OK, here you suppose that you have access to an optimal learning learning trajectory.",
                    "label": 0
                },
                {
                    "sent": "So for example here again I consider a sequence labeling problem OK. And typically.",
                    "label": 0
                },
                {
                    "sent": "So you have an input here, which is typically an author input.",
                    "label": 0
                },
                {
                    "sent": "You have SOS OK and you want to label it correctly.",
                    "label": 0
                },
                {
                    "sent": "And the you suppose that training time you know that the correct label for this first letter is S. For suddenly there is oh and so forth.",
                    "label": 0
                },
                {
                    "sent": "Illustrator is OK, so you suppose you have access to this information.",
                    "label": 0
                },
                {
                    "sent": "For the sole method.",
                    "label": 0
                },
                {
                    "sent": "You have a stronger assumption which is called optimal learning policy.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This assumption says that.",
                    "label": 0
                },
                {
                    "sent": "Not only you have access to optimal learning trajectories, but even if doing the inference process of the training process to make an error.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "What will be the next best move?",
                    "label": 0
                },
                {
                    "sent": "OK, you don't know to correct the error, but you know that if you make this error OK in order to get.",
                    "label": 0
                },
                {
                    "sent": "And I would put.",
                    "label": 0
                },
                {
                    "sent": "Which is quite correct.",
                    "label": 0
                },
                {
                    "sent": "You would have to do such and such move.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically here maybe tomorrow.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is your 2017 here?",
                    "label": 0
                },
                {
                    "sent": "Suppose that my target is this red, red pass.",
                    "label": 0
                },
                {
                    "sent": "Here, if I make an error, I know that the next move the best move.",
                    "label": 0
                },
                {
                    "sent": "If I made this error, is this one and this one right so there?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Play stronger.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My.",
                    "label": 0
                },
                {
                    "sent": "So now let me introduce some of the ideas of the.",
                    "label": 0
                },
                {
                    "sent": "Reinforcement learning for this problem this problem?",
                    "label": 1
                },
                {
                    "sent": "So I will introduce a model for structure prediction which is based based on the Markov chain processes.",
                    "label": 0
                },
                {
                    "sent": "So usually my condition processes are used to model A sequential decision making.",
                    "label": 0
                },
                {
                    "sent": "So this will be the model of social prediction and I will use agorism different families of reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So usually reinforcement learning techniques could be used to trade mark additional processes, so it should provide quite general framework for this social position problem.",
                    "label": 1
                },
                {
                    "sent": "OK, and this means that provided you have this formulation formalisation OK, you could use many different on the shelf reinforcement learning algorithm to train your Markov process.",
                    "label": 0
                },
                {
                    "sent": "And and also benefit is that you will not need.",
                    "label": 0
                },
                {
                    "sent": "Just to let some assumptions, I just described.",
                    "label": 1
                },
                {
                    "sent": "OK so you will be able to learn with very very weak assumptions about.",
                    "label": 0
                },
                {
                    "sent": "The problem about the nature of supervision information OK and potentially will be able to deal with the larger class of problems.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reschedule for processes.",
                    "label": 0
                },
                {
                    "sent": "OK, so in Mcafee's own process, you have four components, states, actions, transitions, and rewards.",
                    "label": 0
                },
                {
                    "sent": "So I will use this small example here.",
                    "label": 0
                },
                {
                    "sent": "You have an input sequence.",
                    "label": 0
                },
                {
                    "sent": "OK typically comes from this error.",
                    "label": 0
                },
                {
                    "sent": "You have the three letters.",
                    "label": 0
                },
                {
                    "sent": "And you want to to label this sequence correctly.",
                    "label": 0
                },
                {
                    "sent": "So here is the correct solution.",
                    "label": 0
                },
                {
                    "sent": "So state here.",
                    "label": 0
                },
                {
                    "sent": "Will be a description of the input, this sequence and the partial output.",
                    "label": 1
                },
                {
                    "sent": "So here for example, for the initial state.",
                    "label": 0
                },
                {
                    "sent": "So partial, so the state is composed only of the input sequence and so partial put this is empty.",
                    "label": 0
                },
                {
                    "sent": "Here at this stage, OK, you have two letters here on this, together with input.",
                    "label": 0
                },
                {
                    "sent": "Connection here.",
                    "label": 0
                },
                {
                    "sent": "Defines some modification of the parser output.",
                    "label": 0
                },
                {
                    "sent": "So typically here you could label this, for example this letter as S or as a whole, or this one as oh and something for the next one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is an action, so you're typically OK. You have different section.",
                    "label": 0
                },
                {
                    "sent": "You can choose both.",
                    "label": 0
                },
                {
                    "sent": "The location you want to label and then the label.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, so this is formalized by your transition function.",
                    "label": 0
                },
                {
                    "sent": "So transition here takes state opponent selection and produce a new state.",
                    "label": 0
                },
                {
                    "sent": "So you start from this state, you choose an action and you produce system state OK, and by the end when you are finished OK. You get a reward.",
                    "label": 1
                },
                {
                    "sent": "And the reward measures the quality of the prediction.",
                    "label": 0
                },
                {
                    "sent": "So typically here.",
                    "label": 0
                },
                {
                    "sent": "You have the correct output.",
                    "label": 0
                },
                {
                    "sent": "OK, and here you have something which is wrong.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Very often magician processes are used.",
                    "label": 0
                },
                {
                    "sent": "To explore unknown environments, for example for navigation tasks.",
                    "label": 0
                },
                {
                    "sent": "Which can secure for, let's say for robot in amazing OK. You can model the development of the robots using this kind of process, so.",
                    "label": 0
                },
                {
                    "sent": "Your robot, he doesn't knows.",
                    "label": 0
                },
                {
                    "sent": "It doesn't know there's a maze removes and when you get stuck somewhere.",
                    "label": 0
                },
                {
                    "sent": "You get a relative reward.",
                    "label": 0
                },
                {
                    "sent": "OK, and if sometimes you find the exit you get positive reward and then you will learn.",
                    "label": 0
                },
                {
                    "sent": "How to go to move into into the into the base?",
                    "label": 0
                },
                {
                    "sent": "Structured prediction problem is easy, yeah sure.",
                    "label": 0
                },
                {
                    "sent": "No, no no.",
                    "label": 0
                },
                {
                    "sent": "It's just easier to explain.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "For example, for suppressing parsing problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so will description of the problem would be quite more complex again.",
                    "label": 0
                },
                {
                    "sent": "For example, the state description is not trivial's actions, and so on.",
                    "label": 0
                },
                {
                    "sent": "Well, so here we have this.",
                    "label": 0
                },
                {
                    "sent": "It's a fundamental property.",
                    "label": 0
                },
                {
                    "sent": "And the idea of modeling the social position problem with some DPS.",
                    "label": 0
                },
                {
                    "sent": "Re licenses on this property.",
                    "label": 0
                },
                {
                    "sent": "So this says that under some hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Maximizing's expectation of Torrey Ward, which is what we do usually in with MDPSOK, is equivalent to minimizing the structured prediction loss.",
                    "label": 1
                },
                {
                    "sent": "OK, so typically this is what you do with reinforcement learning OK, or when you want to train to train and GPS and typically here.",
                    "label": 0
                },
                {
                    "sent": "This is what you do with.",
                    "label": 0
                },
                {
                    "sent": "Supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So besides I will develop relies on this fully resistance property and this provides a or so in this case a bridge between reinforcement learning and.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Understructure prediction.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rifle for people who know NDPS.",
                    "label": 0
                },
                {
                    "sent": "So some of the things we are using here, is it a little bit special?",
                    "label": 0
                },
                {
                    "sent": "First, OK usually and EPS or Stochastics and here we are using deterministic MDP's OK. And then, for example, features of the example of the robot in the in the maze.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we move an for each move?",
                    "label": 0
                },
                {
                    "sent": "OK, after some moves you will get to reward.",
                    "label": 0
                },
                {
                    "sent": "OK, so she's a typical is never ending a story for four year olds continuously.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "The initial problem is not a reinforcement learning problem, but this is a supervised learning problem.",
                    "label": 0
                },
                {
                    "sent": "So typically we will get.",
                    "label": 0
                },
                {
                    "sent": "Some training examples.",
                    "label": 0
                },
                {
                    "sent": "And then a.",
                    "label": 0
                },
                {
                    "sent": "No more supervision.",
                    "label": 0
                },
                {
                    "sent": "Which means that at inference time we will get input data.",
                    "label": 0
                },
                {
                    "sent": "On the hopefully will be able to generalize and to produce across social output, but you will not get anymore any reinforcement signal.",
                    "label": 0
                },
                {
                    "sent": "OK, any reward?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is different well.",
                    "label": 0
                },
                {
                    "sent": "So what you have to do is to learn on the set of training example, an awful year if you do well, your technique will be able to.",
                    "label": 1
                },
                {
                    "sent": "Vagina.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Price.",
                    "label": 0
                },
                {
                    "sent": "So typically, in order to do that, we will use what we called with approximate approximated reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "This means that in order to learn the different functions also policy OK will use a linear function, so as before we use a joint description of the input and the output of the state of the actions here OK. And we try to learn.",
                    "label": 1
                },
                {
                    "sent": "A linear function.",
                    "label": 0
                },
                {
                    "sent": "And see this new function we don't know to provide the correct decision.",
                    "label": 0
                },
                {
                    "sent": "OK. Did you see my function will be?",
                    "label": 0
                },
                {
                    "sent": "We provide the policy.",
                    "label": 0
                },
                {
                    "sent": "OK so decision so alright, this decision at each step of the process.",
                    "label": 1
                },
                {
                    "sent": "Well, so here the goal is to learn the parameter vector versus linear function.",
                    "label": 0
                },
                {
                    "sent": "Here you're also have a Max problem, but here's our Max is on also potential actions in a given state you have finite set of actions, so this is quite different.",
                    "label": 0
                },
                {
                    "sent": "After global landmarks.",
                    "label": 0
                },
                {
                    "sent": "Problem welder I described before and for learning we could use any reinforcement learning technique.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just a brief description here on the simple problem of.",
                    "label": 0
                },
                {
                    "sent": "After transcription for state action pairs, so once again this is a sequence sequence labeling problem here.",
                    "label": 0
                },
                {
                    "sent": "So we have this word.",
                    "label": 0
                },
                {
                    "sent": "Hello Ann here you have already processed OK since it's such a labels so different letters from left to right you have already processed.",
                    "label": 0
                },
                {
                    "sent": "So first 3 letters Ann.",
                    "label": 0
                },
                {
                    "sent": "You are into the process of labeling so so first one.",
                    "label": 0
                },
                {
                    "sent": "So you have already zuza different flavors here.",
                    "label": 0
                },
                {
                    "sent": "This is a description.",
                    "label": 0
                },
                {
                    "sent": "Of the state.",
                    "label": 0
                },
                {
                    "sent": "And the first of the actions.",
                    "label": 0
                },
                {
                    "sent": "OK, so you could see that, but it's a binary vector.",
                    "label": 0
                },
                {
                    "sent": "As before, it could be quite large and it encodes differences.",
                    "label": 0
                },
                {
                    "sent": "Typically it includes relations between the state and actions.",
                    "label": 0
                },
                {
                    "sent": "So for example here you have this action.",
                    "label": 0
                },
                {
                    "sent": "Which is labeled here.",
                    "label": 0
                },
                {
                    "sent": "We saw one.",
                    "label": 0
                },
                {
                    "sent": "Whether the action is the decider L here.",
                    "label": 0
                },
                {
                    "sent": "OK, if you decide to help.",
                    "label": 0
                },
                {
                    "sent": "And sometimes the stick of the image.",
                    "label": 0
                },
                {
                    "sent": "For example here, the given pixel in the image is black or white or whatever.",
                    "label": 0
                },
                {
                    "sent": "OK, so this relates to transcription of actual an action, an input input data and you also have joined the scription of actions and output that.",
                    "label": 0
                },
                {
                    "sent": "For example, here is the context of.",
                    "label": 0
                },
                {
                    "sent": "As we become popular neighborhood already been.",
                    "label": 0
                },
                {
                    "sent": "Bing predicted.",
                    "label": 0
                },
                {
                    "sent": "So typically what you should have in mind is that for all these problems we have.",
                    "label": 0
                },
                {
                    "sent": "Very large description spaces OK, but there will be sparse descriptions.",
                    "label": 0
                },
                {
                    "sent": "OK, we saw only some bits here.",
                    "label": 0
                },
                {
                    "sent": "Your present.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so just to show that this kind of technique work.",
                    "label": 0
                },
                {
                    "sent": "We have benchmarked this kind of different categories on this front.",
                    "label": 0
                },
                {
                    "sent": "Different reinforcement learning algorithm and the unclassical.",
                    "label": 1
                },
                {
                    "sent": "Physical benchmarks for sequence prediction.",
                    "label": 0
                },
                {
                    "sent": "So I won't go into the details.",
                    "label": 0
                },
                {
                    "sent": "So this corresponds to different different datasets.",
                    "label": 0
                },
                {
                    "sent": "OK, in blue you have a baseline results, so this is the best baseline and we have compared different different baseline.",
                    "label": 0
                },
                {
                    "sent": "OK, so SVM typically CRF's structure in C and so on, and here in red and green you have two different reinforcement learning methods so that we can see here is that the performance is our performance is similar.",
                    "label": 0
                },
                {
                    "sent": "In some cases, for example for this specific that I said where you have long term relations into that are, you get better results, but roughly speaking it's.",
                    "label": 0
                },
                {
                    "sent": "It's morissette.",
                    "label": 0
                },
                {
                    "sent": "So what's what?",
                    "label": 0
                },
                {
                    "sent": "HW is on rating.",
                    "label": 0
                },
                {
                    "sent": "On the on the rating.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, but if you want to solve.",
                    "label": 1
                },
                {
                    "sent": "Sequence labeling problem OK. Can you have you already have a set of very good techniques so it's not useful to use this kind of refund?",
                    "label": 0
                },
                {
                    "sent": "Super interesting things.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just to show that.",
                    "label": 0
                },
                {
                    "sent": "Which is basically the state of the art on this on this problems well.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I will introduce a tricky, more more complex problem which is in mapping.",
                    "label": 0
                },
                {
                    "sent": "So as I said.",
                    "label": 0
                },
                {
                    "sent": "So goal is to learn transformation.",
                    "label": 0
                },
                {
                    "sent": "From one one document format, So document format.",
                    "label": 1
                },
                {
                    "sent": "OK. For us in machine learning, this is a general.",
                    "label": 0
                },
                {
                    "sent": "Problem, I mean learning how to map a tree onto another on another treat quite difficult problem.",
                    "label": 0
                },
                {
                    "sent": "For the insurgency, it's interesting, but here I will deal only with very specific application which is a document situation.",
                    "label": 0
                },
                {
                    "sent": "So typically in the experiments.",
                    "label": 0
                },
                {
                    "sent": "But I will show is out convert different input formats that text, email or XML into a structured Excel format OK?",
                    "label": 0
                },
                {
                    "sent": "On the in fact, this kind of problem, learning from mapping was the initial motivation for deriving these algorithms, because at that time we were working on information retrieval for XML data.",
                    "label": 0
                },
                {
                    "sent": "OK, and the goal for Excel information retrieval is not to produce around list of document, but to produce a long list of items of XML items.",
                    "label": 0
                },
                {
                    "sent": "Let's say two wrongs subtrees OK, what we want to get.",
                    "label": 0
                },
                {
                    "sent": "Is to get.",
                    "label": 0
                },
                {
                    "sent": "A subtree of an external document which is more relevant and some more specific for a given query.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But you can also have many front also application fields like information extraction, document collection and whatever.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have studied two classes of transformation.",
                    "label": 1
                },
                {
                    "sent": "First one is what we call a one to one transformation.",
                    "label": 0
                },
                {
                    "sent": "This means that, for example, this input document that area document.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "Both the input and the target document will have the same sequence of leaves.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a.",
                    "label": 0
                },
                {
                    "sent": "Quite normal exceptions for many year documentaries for initial problems.",
                    "label": 0
                },
                {
                    "sent": "OK, because it treats from OK. From left to right, let's say OK, but we also studied more complex transformations where it was possible to move here to exchange.",
                    "label": 0
                },
                {
                    "sent": "The leaves of the input and between the input and the output and also to skip skip summer.",
                    "label": 0
                },
                {
                    "sent": "Information.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By supporting this quick complex here because you have a very large number of mappings, OK, you have to under both the content structure OK?",
                    "label": 1
                },
                {
                    "sent": "Some documents would be quite large and say which I wish was actually thrown and for this problem you have no optimal learning policy.",
                    "label": 1
                },
                {
                    "sent": "OK. An optimal learning trajectory and typically.",
                    "label": 0
                },
                {
                    "sent": "OK, so global like could not be employed for this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "Just a previously.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "None of her to States and actions here.",
                    "label": 1
                },
                {
                    "sent": "Typically what we will do is that you will take an input document.",
                    "label": 0
                },
                {
                    "sent": "We will process the leaders of the document one at a time.",
                    "label": 1
                },
                {
                    "sent": "And the state is a descripcion of the input document and the partial output tree here, and an action consists in attaching a path OK, an XML path which ends with the current leaf to a given position in the partial tree.",
                    "label": 1
                },
                {
                    "sent": "OK, and both the path and the positions are learned from the training data.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "But OK, and for training we use the loss function, which is a kind of F score for trees.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where so typically orthoses interest rates of States and action for some policies with partial output tree and we're processing this leave here John Walker an so different potential actions and what we could do is attached here.",
                    "label": 0
                },
                {
                    "sent": "This path at this node or here's relief at this node or eventually here.",
                    "label": 0
                },
                {
                    "sent": "Skips, skips loaded, not appear into the fire into final tree.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just a brief description of how it works.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any put document here?",
                    "label": 0
                },
                {
                    "sent": "And you want to trance?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It includes this document of.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, at the inference time, you don't know what is the designer would put.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a manual movie.",
                    "label": 0
                },
                {
                    "sent": "OK, you can see the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first leaf.",
                    "label": 0
                },
                {
                    "sent": "You create a.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Brunch in Cyprus.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Me.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You consider this one.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Leave.",
                    "label": 0
                },
                {
                    "sent": "Someone branch.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So leave up.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You inserted in between.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and so.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And finally you don't.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You do not want this one, so you get this this final tree.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, since this is a quite complex problem with compression problem, you will make some assumptions OK for example.",
                    "label": 1
                },
                {
                    "sent": "We learn the OK. End of grammar of the.",
                    "label": 0
                },
                {
                    "sent": "Of the desired output.",
                    "label": 0
                },
                {
                    "sent": "For example, during the transformation, we only allow path.",
                    "label": 0
                },
                {
                    "sent": "Which appear in the training set OK and same thing we only allow sibling labels which appearances winning set plus OK. Use some additional constraints.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so you again I will not describe them, but the features or specific description in a very high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Typically we were working with spaces like 10,000 or 100,000 features or even more OK, and this subscription will characterize both input.",
                    "label": 0
                },
                {
                    "sent": "Input, content, infrastructure and the output structure.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Some tests have been doing on different collections.",
                    "label": 0
                },
                {
                    "sent": "So typically it's a description of textual documents here.",
                    "label": 0
                },
                {
                    "sent": "Here you have the transformation problem.",
                    "label": 0
                },
                {
                    "sent": "For example, here we went to transform an input that I was just in XML into another Excel format.",
                    "label": 0
                },
                {
                    "sent": "OK here HTML into Excel and so on.",
                    "label": 0
                },
                {
                    "sent": "This is to example input text, sorrow text, flat text.",
                    "label": 0
                },
                {
                    "sent": "I want to produce an XML format.",
                    "label": 0
                },
                {
                    "sent": "So basically here we have three smaller corpora.",
                    "label": 0
                },
                {
                    "sent": "OK, I called that small because so documents inside are quite small and two larger corpora OK.",
                    "label": 0
                },
                {
                    "sent": "So for example, this is a real estate copper app developed by an Idol here somewhere.",
                    "label": 0
                },
                {
                    "sent": "Anne Shakespeare or ratings of Shakespeare Anne this is a collection of IEEE journals, and this is OK. Data extracted from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So you can see that for example, here, for these two sets here you have around 150, two 150 different potential labels.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some are.",
                    "label": 0
                },
                {
                    "sent": "Some performance.",
                    "label": 0
                },
                {
                    "sent": "So we have used different different measures.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To make it short, for example when you want.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compare 2 trees for some places, pretty big tree and the.",
                    "label": 0
                },
                {
                    "sent": "Desired output three OK. You can do it in in different ways.",
                    "label": 0
                },
                {
                    "sent": "For example, you can compare.",
                    "label": 0
                },
                {
                    "sent": "The sequences of leaves and their labels OK. You can compare the different paths in the trees also differ or you can compare all the subtrees.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have been using different measures OK. We said it was compared trees, sorry leaves.",
                    "label": 0
                },
                {
                    "sent": "Bath and also trees.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and this is what appears here, so you can see that for example here.",
                    "label": 0
                },
                {
                    "sent": "Forces are different measures OK?",
                    "label": 0
                },
                {
                    "sent": "You get quite strong performance.",
                    "label": 0
                },
                {
                    "sent": "OK, so he's OK.",
                    "label": 0
                },
                {
                    "sent": "This is not perfect, but this is a nearly perfect.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this means that this reference modeling technique.",
                    "label": 0
                },
                {
                    "sent": "Further, can known and so able to generalize.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as a larger corpora, whether it's a better man, Caesar is degraded, but it's still OK.",
                    "label": 0
                },
                {
                    "sent": "It means that it does something.",
                    "label": 0
                },
                {
                    "sent": "OK, so you must think that typically you have around 700 nodes, parallel payment with several thousand nodes for some documents, and a lot of flavors.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "And the OK.",
                    "label": 0
                },
                {
                    "sent": "So by doing this.",
                    "label": 0
                },
                {
                    "sent": "Inference is quite fast.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically to process your document it takes 1 second OK, but reinforcement learning is not so fast.",
                    "label": 0
                },
                {
                    "sent": "OK, so it might take days to train on the logical corollary correct as well.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Try to.",
                    "label": 0
                },
                {
                    "sent": "Trying to remember that this attractive extinction between this and the and the CERN in a sort of turning it's.",
                    "label": 0
                },
                {
                    "sent": "Modern incarnation, which doesn't have a requirement that the that from any state or is there is a path to completion so that I'm not sure that I I don't know what I mean.",
                    "label": 0
                },
                {
                    "sent": "Of course is the results are interesting.",
                    "label": 0
                },
                {
                    "sent": "I'm just trying to understand is that the fundamental difference between what you proposed in CERN?",
                    "label": 0
                },
                {
                    "sent": "Typically to send the OK is the same family of missiles.",
                    "label": 0
                },
                {
                    "sent": "OK to increment on this?",
                    "label": 0
                },
                {
                    "sent": "OK, except that here we are using.",
                    "label": 0
                },
                {
                    "sent": "Or enforcement learning techniques OK, whereas in concern is using typically a classifier at each node to make a decision OK?",
                    "label": 0
                },
                {
                    "sent": "If they threaten noise is a service of reinforcement learning analysis.",
                    "label": 0
                },
                {
                    "sent": "That's what they do.",
                    "label": 0
                },
                {
                    "sent": "And the classifier, and so that's what I don't understand is today.",
                    "label": 0
                },
                {
                    "sent": "I mean whenever I've heard talks about certain results in terms of forcement learning, so you know struggling here.",
                    "label": 0
                },
                {
                    "sent": "No, I think that their relations between the sun and a reinforcement learning OK, but it is typically what he's using is supervised training of.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, I guess I'll have to ask John Langford because he presents it that way, so yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Here is that you don't need to know for the ground truth set of actions to get to the goal in your framework, whereas last loan Sir, you might even know that to make the incremental updates language so really well done, Sir.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And also OK for training.",
                    "label": 0
                },
                {
                    "sent": "OK, and certainly makes this a central assumption.",
                    "label": 0
                },
                {
                    "sent": "OK about the optimal learning.",
                    "label": 0
                },
                {
                    "sent": "Running trajectories OK.",
                    "label": 0
                },
                {
                    "sent": "The paper so.",
                    "label": 0
                },
                {
                    "sent": "OK so I I was checking 'cause I I was confused about the universe always actually pulled the paper jam on the MLJ Pepper 19.",
                    "label": 0
                },
                {
                    "sent": "It doesn't make it so.",
                    "label": 0
                },
                {
                    "sent": "I know quick release paper yesterday.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, typically so difference into interceptions and then on the other machinery.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you are using here?",
                    "label": 0
                },
                {
                    "sent": "OK, so different the.",
                    "label": 0
                },
                {
                    "sent": "Examples are I sure.",
                    "label": 0
                },
                {
                    "sent": "Present for the benchmarks have been using traditional are enforcement learning techniques OK?",
                    "label": 0
                },
                {
                    "sent": "Also in Sonny's as his own is on missiles better.",
                    "label": 0
                },
                {
                    "sent": "Yes, I'm sure that.",
                    "label": 0
                },
                {
                    "sent": "Is using supervised learning?",
                    "label": 0
                },
                {
                    "sent": "It's originally a sphere.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So using the loss function as your reward at the end and loss function is defined on the complete leveling quiet.",
                    "label": 0
                },
                {
                    "sent": "But you can imagine even a partial labeling.",
                    "label": 0
                },
                {
                    "sent": "You can calculate some kind of gloss, sure.",
                    "label": 0
                },
                {
                    "sent": "Angos intermediate rewards and you think that will benefit yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "In fact, when.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "For example, services dismissed as we saw.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "You can use.",
                    "label": 0
                },
                {
                    "sent": "Eyes are very pisode or prayer decision reward.",
                    "label": 0
                },
                {
                    "sent": "Very episode.",
                    "label": 0
                },
                {
                    "sent": "I mean at the end OK?",
                    "label": 0
                },
                {
                    "sent": "Or their decision reward?",
                    "label": 0
                },
                {
                    "sent": "OK, so we have performed experiments with all the possibilities and also intermediate possibilities.",
                    "label": 0
                },
                {
                    "sent": "And of course if you can compute an intermediate score.",
                    "label": 0
                },
                {
                    "sent": "Even if you give, it provides an imperfect supervision.",
                    "label": 0
                },
                {
                    "sent": "It's worth your it's worse.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "When you can use a position, you have to use it.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's much faster.",
                    "label": 0
                },
                {
                    "sent": "Typically, typically it will converge very fast here.",
                    "label": 0
                },
                {
                    "sent": "Strange to limit expiration is that only during training or also which constraint?",
                    "label": 0
                },
                {
                    "sent": "Exploration.",
                    "label": 0
                },
                {
                    "sent": "This is kind of constraint here.",
                    "label": 0
                },
                {
                    "sent": "Alright well yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Training or also.",
                    "label": 0
                },
                {
                    "sent": "In fact, during training.",
                    "label": 0
                },
                {
                    "sent": "Here, typically what you do is that you learn.",
                    "label": 0
                },
                {
                    "sent": "Kind of grammar of your of your target target trees?",
                    "label": 0
                },
                {
                    "sent": "OK, what I mean?",
                    "label": 0
                },
                {
                    "sent": "Is that OK?",
                    "label": 0
                },
                {
                    "sent": "Here for example you.",
                    "label": 0
                },
                {
                    "sent": "You learn all the possible possible paths in the target, treason.",
                    "label": 0
                },
                {
                    "sent": "In the examples on the training set.",
                    "label": 0
                },
                {
                    "sent": "OK, and then for doing inference.",
                    "label": 0
                },
                {
                    "sent": "Only this pass, for example, will be a.",
                    "label": 0
                },
                {
                    "sent": "Available OK, you cannot use any OK, otherwise it's completely OK, otherwise the space is really.",
                    "label": 0
                },
                {
                    "sent": "Is meant to be.",
                    "label": 0
                },
                {
                    "sent": "But typically first for POSIX payments, we have been using doing here.",
                    "label": 0
                },
                {
                    "sent": "OK, so consider IEEE journals.",
                    "label": 0
                },
                {
                    "sent": "OK bye OK, just looking at some examples.",
                    "label": 0
                },
                {
                    "sent": "I've had some papers.",
                    "label": 0
                },
                {
                    "sent": "OK, you have an idea of the sale DTD.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Even if you have two different sources, it's quite easy.",
                    "label": 0
                }
            ]
        }
    }
}