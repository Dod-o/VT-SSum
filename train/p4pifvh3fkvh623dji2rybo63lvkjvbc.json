{
    "id": "p4pifvh3fkvh623dji2rybo63lvkjvbc",
    "title": "Crowdsourcing for Relevance Evaluation",
    "info": {
        "author": [
            "Daniel E. Rose, A9.com Inc."
        ],
        "published": "Nov. 19, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/cikm08_rose_cfre/",
    "segmentation": [
        [
            "Hear me OK.",
            "So thanks, mark.",
            "So."
        ],
        [
            "Going to talk a little about crowdsourcing for relevance evaluation, but I wanted to start off by giving a little background about a 9.",
            "Some people aren't really sure what a nine dozen that would be useful to give you some context."
        ],
        [
            "So A9 is actually a search technology subsidiary of Amazon.com.",
            "It's not a startup, it's not a company that was bought by Amazon.",
            "It was a company that was created by Amazon to focus on search for Amazon and the primary mission of a 9 is to produce the product search engine that's used by Amazon.",
            "So if you've used Amazon.com, you've used A9 search engine.",
            "We also license it to other other retail sites that use the Amazon ecommerce platform.",
            "We also created something called search inside the book, which you might have used and we also have an advertising business called Click River.",
            "So that's kind of what I'm mostly focuses on now.",
            "Some of you may be saying, well, wait a second, didn't you used to have a website?",
            "What you trying to do?",
            "Web search stuff?"
        ],
        [
            "There was some work in the early days of a nine was about five years ago.",
            "Now in looking at Federated Search and in fact we created something called the Open Search protocol, which is still used.",
            "If you do search in the Firefox and Firefox plugins for example.",
            "We also did some interesting work on geographic location with something called Block View, which was the first system to show what it looks like when you're going around looking at at stores from the humans POV.",
            "But these are things we're focusing on today.",
            "We're really concentrating on product search and advertising.",
            "So what do I mean by?"
        ],
        [
            "Search product search is searching the corpus of retail products and it has a couple of characteristics that make it somewhat different from, say, web search.",
            "So for one thing, the data is typically more structured, so we have things like prices and brands and features, sizes of clothing and colors, and things like that, all of which are attributes on the objects that were searching for.",
            "Also, the search you eyes in a product search context typically have richer interaction that what you find on the web.",
            "So for example on people do sorting other results.",
            "I do filtering the results, they browse them in various ways.",
            "Often there's interesting interactions of searching and browsing with faceted metadata, things like that.",
            "The other interesting thing is we have a lot of different categories, so on the upper right there I've just got a screen grab of some of the categories.",
            "You can search for on Amazon, just in the US.",
            "And as you can imagine, the way you want to search in those different categories might vary, so the way you want to optimize search for books might be different from the way you want to search for video games.",
            "Down at the bottom I put just a few sample queries, the kind of things that we get.",
            "One of those who notices that they range from the fairly general to more generic.",
            "I don't have sorry to.",
            "The more specific I don't have a lot of really general ones here, but I mean you get the flavor of it now.",
            "Some people think, well, the problem could be that hard.",
            "I mean everybody's got the same intent right there all shopping, but in fact when people are shopping, they actually go through a lot of different stages or something called the buying funnel where someone might start out with just a vague awareness of and interest in.",
            "In a category of products and then move toward maybe comparing specific products going down to finding out with the features are for product doing, looking at the price and things like that.",
            "Some people come just to do research.",
            "Some people come to read the reviews.",
            "There's all kinds of user intents, even though everybody is more or less shopping.",
            "So that's what we do.",
            "So like any search engine that has to try."
        ],
        [
            "Produce the best results we can.",
            "We're interested in the question of relevance and how we evaluate relevance.",
            "And as I'm sure you know, relevance is notoriously hard to evaluate.",
            "I've written about that a little bit in the web search context.",
            "There's a lot of research about it.",
            "Just defining relevance is still kind of a research issue.",
            "Much less evaluating.",
            "It's highly subjective.",
            "It's very task specific, and so on, and it's very expensive to measure.",
            "So I thought I would take you through kind of a quick history of some of the main approaches to evaluating relevance, to lead up to the one that we're proposing here."
        ],
        [
            "So one of the classic approaches to evaluating relevance is to get a bunch of human judgments, explicit judgments on a standard test collection, and this test collection is going to have a corpus of documents.",
            "It's going to have a set of queries, and it's going to have relevance judgments, and the idea is, once you put this set together, you can reuse it for multiple experiments."
        ],
        [
            "Really good example of that is the CRAN field studies in the early 1960s and a bunch of other test corporate that were created very similar to this where the idea is you actually exhaustively evaluate every document in the corpus for every query.",
            "So some poor graduate student had to sit down an read every, see ACM abstract or whatever the documents were in the collections at the time.",
            "Well, this kind of breaks down if your documents are long and it also breaks down if you have more than, say, a couple 1000, which is what the typical corpus sizes were back then.",
            "So this was great for the 60s, but it kind of stopped working.",
            "Maybe by the 70s, and certainly by the 80s, and so we moved on to another Strat."
        ],
        [
            "G which is pulling.",
            "Pulling is the idea that's used in track, and several of the other standard IR evaluations.",
            "Where basically you have a whole bunch of participants all wanting to test their engine against the same corpus and then you get each system to say what it stop in.",
            "In this case 100 results are and you take the union of all those you make.",
            "This pool of documents an have someone some kind of relevance assessor decide whether the documents are relevant or not for those queries or those topics.",
            "And in the case of Trek, they got retired intelligence analysts to do the relevance assessments, which is great.",
            "These were pretty expert people.",
            "Experts at judging whether something is relevant or not.",
            "I'm so that worked pretty well and has a lot of advantages, but together with the other approach, both of these ideas of having these explicit human judgments run into some various kinds of problem."
        ],
        [
            "First of all, the test sets get stale.",
            "I think it was Ian Soboroff who said yesterday that if you're using an old Trek collection with new search engine, that's bad methodology, partly because the judgments that are in the pool are only a subset of all the judgments that should be there as search engines get better.",
            "But it's also true just for the fact that the sets that are there may not be there says that you're interested in.",
            "So maybe I've got some kind of specialized search need, so I'm going to give an example in little while where maybe I'm creating a search engine too.",
            "Give you information about facts about the world, locations in the world well, if there's no trek collection for facts about the world, you're kind of out of luck.",
            "So that's a problem in general, just having this batch methodology may not work in all all situations.",
            "So for example, if I'm doing some kind of UI research or I want to see you know the effect of longer or shorter snippets or something like that.",
            "Again, the standard methodology and track is not going to help me.",
            "Now.",
            "That's not to say that trek the organization hasn't done a lot of interesting experiments in other kinds of.",
            "Evaluation methodologies like Track, interactive several years ago and so on, but the standard methodology isn't going to work for these.",
            "It's also pretty expensive to create new sets.",
            "Not everybody has retired intelligence analysts hanging around.",
            "Even even then, even if you have them, it breaks down for really big corpora.",
            "So the original Trek collection I think was about half a million documents, and since then we've seen much larger ones, but it's not quite web scale.",
            "We have 20 billion."
        ],
        [
            "So there's another thing you could do, and this is actually seems to be what's becoming more common now, both in industry and academia, which is just give up on recall focus on DCG.",
            "And create your own collection just for this task.",
            "So let's say you're a professor.",
            "You came up with some new idea.",
            "You try it out on the web, get your own little test collection, get your grad students to judge as many queries as they can stand, and then report the DCG.",
            "So that's that's pretty good.",
            "It works in a lot of cases, but it's pretty time consuming and it's very expensive or it's very expensive.",
            "So if you have grad students and they have a lot of time, then that's OK. Maybe if you're Google or Yahoo and you can afford to hire Staffs of editors, and that's probably OK, But if you're anybody else, it's kind of hard.",
            "So one thing you might say is, well, maybe we can just get rid of the need for having these people doing these explicit judgments all the time.",
            "And of course there are approaches that."
        ],
        [
            "Do that so for example, the interleaving approach that Yokums suggested a couple years ago, where you can compare 2 engines by having their results be interleaved and observe the click positions, so that's great.",
            "That's also another class of problems, but it doesn't handle all the situations again, because first of all you need a lot of real users, so if you want to compare how people are going to click, you want them to be doing it in this kind of organic environment, not not conscious that they're making your relevance judgment.",
            "Otherwise it kind of defeats the purpose there.",
            "And the data isn't really reusable, so if I do an experiment where I'm comparing algorithm 8 algorithm be with by observing people coming in my site and now I want to try algorithm.",
            "see I can't reuse the judgments that were made comparing A to B, they don't do me any good for algorithms see, whereas in the traditional model that wreck style model, everybody can retest their algorithm against the same data.",
            "So you might think that's not a big deal, but if you're.",
            "For example, a startup company and you don't want to disclose what your doing yet you want to just try it in the lab you want to be able to test it without having real users in real traffic."
        ],
        [
            "OK, so we've got these two main approaches.",
            "One of them involves expensive human judgments, but it has the advantage that these judgments are reusable and it's very flexible.",
            "You can make a judgement set for anything you want.",
            "On the other hand, you've got these kind of automated metrics or implicit judgment approach, which allows you to do much larger scale to deal with much larger scale corpora.",
            "But and it's very inexpensive, but it has these drawbacks that I just mentioned, so we'd like to have is something that kind of combines the best of best of both worlds here and So what we're suggesting is something we call Turk technique."
        ],
        [
            "Evaluating relevance by crowdsourcing.",
            "What do I mean by crowd sourcing?",
            "Crowdsourcing is a term that was coined by Jeff Howe at Wired magazine and in an article about a couple years ago.",
            "And the way he described it was everyday.",
            "People using their spare cycles to create content solve problems, even do corporate R&D.",
            "So another way to look at it is just having a large pool of workers who are all across the world doing little bits of work over the Internet for amounts before payment.",
            "Now, this kind of has the flavor of a lot of Web 2.0 applications, but the difference is.",
            "In typical Web 2.0 applications like Flickr or Dig or something like that Wikipedia, the people sort of all know about each other, and they're interacting with each other, and in fact that's one of the benefits is the social aspect, and that's less true for the crowdsourcing paradigm.",
            "Here it's just everybody individually can get access to the work, and you as the person who have the work and get access to all the workers.",
            "But it's not really about the community, although they do tend to form communities and forums and so on."
        ],
        [
            "So the the particular framework for crowdsourcing that we use is called Amazon Mechanical Turk and a lot of people may not realize that Amazon is gone into the services business in a pretty big way.",
            "So they have a cloud computing service called EC2 Elastic Compute Cloud.",
            "They have a storage service and they have a payment service.",
            "So if you're a small business and you don't want to build your own payment infrastructure on your website, you can just call Amazons through this web Services API.",
            "And then another one is this Amazon Mechanical Turk to why is it called Mechanical Turk?",
            "Well, there was a system.",
            "It was this.",
            "A form of entertainment that went around in the 18th century, which purported to be a chess playing automaton in the form of this mannequin that looked like a Turkish guy.",
            "And if you open the cabinet door, use all these gears and wheels and it looked like it was totally mechanical.",
            "But in fact there was someone in a hidden compartment, a small person who actually sat underneath and by using magnets could tell where the chess pieces were on the board and then control the so called automaton.",
            "So what's the connection there with this Mechanical Turk framework well?"
        ],
        [
            "Imagine that you've got some work you want to do, and you want your program you want to be able to do this work programmatically, so you've got your computer program and you want your computer program to be able to call a function, and the function has to do something really smart, has to do something that would require AI like, really good, perfect, you know, science fiction, AI?",
            "Well, we don't have that science fiction AI yet, so we could just pretend to have it by having a person on the other end instead.",
            "So it's artificial, artificial intelligence is, Jeff Bezos says that's how Mechanical Turk work, so.",
            "You put a task through this web Services API and a person on the other end gets the task and returned it and your program keeps going.",
            "So this is how the framework works.",
            "The people who have work they want done are called requesters.",
            "They create things called human intelligence tasks or hits the people who do the work are called workers.",
            "Are they sometimes actually call themselves Turkers and they log in and do the tasks and then if the request is there happy with the work, they pay a little bit of money for the completed work.",
            "As of today, there are about 200,000 people doing work on Mechanical Turk from 100 countries.",
            "They've completed millions of hits and as of when I made these slides, there were over 21,000 tasks available to be done."
        ],
        [
            "Typical task, well, I don't know how you can see that down there, but.",
            "There are things like translate this paragraph of text for $0.10 or label these images.",
            "One of the things down there is labeled images of geological formations.",
            "There are 487 of those tasks.",
            "If you want to do the man, they pay 5 cents each.",
            "So that's the kind of thing we're talking about."
        ],
        [
            "Now we want to do relevance.",
            "We want to use this form this framework for relevance evaluation.",
            "So imagine that we're building this hypothetical world fact search engine, and so we're going to grab some pieces of text from the CIA World Fact book and get people to judge whether or not they're relevant to queries which are going to consist of locations in the world.",
            "And let's say we want to create a test set with 50 queries.",
            "For each query we want to judge the first 50 results, so that gives us 2500 query result pairs."
        ],
        [
            "So you might be thinking well, D. Are you just going to let anybody off the street answer questions about you know geographical facts?",
            "What if they don't know anything about geography?",
            "What if they don't know anything about these places in the world?",
            "So there's a system built into Mechanical Turk to deal with that which is a qualification mechanism where you can give people a test and say you're only allowed to do the task.",
            "If you pass this test so we can have a question like you know which Major City or which country has a city named Kira, or what's closest to the population of India.",
            "And you can set these up however you want.",
            "You can make them be free response, so you're going to manually judge the results.",
            "You can make them be automatically graded.",
            "You can give a certain point value to each one, so you can say you know you get 10 points if you get the right answer, but you get five points if you get a close one, and so on.",
            "And you can set it up so that you can decide what the passing score has to be.",
            "Maybe you have to get him alright, maybe have to get a certain percentage so we can filter out people who don't know about geography.",
            "So we qualified the workers now."
        ],
        [
            "We have to make the hits when you make the hits you do it.",
            "You can use a graphical interface, but if you're doing a lot in batch, you typically create these XML.",
            "Templates and here's an example.",
            "I've just highlighted a couple of attacks to illustrate what the structure looks like.",
            "So you say, oh, it's a question and it has a display name.",
            "In this case, question one has some content and we're going to specify how the answer should appear, so we want a radio button kind of answer, and the first radio button is going to say irrelevant, and when you do all that you put in the system, you get a hit like this."
        ],
        [
            "This is what it looks like to the worker.",
            "The person who's going to do the task.",
            "So they say, oh, there's a relevance evaluation task and here it is.",
            "Is the following text relevant to Andorra?",
            "And then there's this piece of text tourism.",
            "The mainstay of Andorra's.",
            "Tiny well to do economy, blah blah blah and you market irrelevance.",
            "Partially relevant, whatever we're going to use these graded relevance judgments in DCG, so we're going to sign each one a number, let's say zero, through four or three."
        ],
        [
            "OK, so we created the hits.",
            "How much are we going to pay people for a test like this?",
            "We've actually been able to pay typically 1 cent, sometimes 2 cents an get good answers.",
            "So 1 cent per hit.",
            "On one of these query result pairs together with these 50 queries, 50 results, and we're going to have five workers do each one for reasons I'll explain in a second, and that gives us a total of $125 for this task."
        ],
        [
            "Now you might be worried that we aren't going to get very good quality results, but we have a way to deal with that too.",
            "So first of all, as I said, we can just make the test be harder so that we know that people really know something about the topic.",
            "Secondly, we can get redundant judgments, and in fact we've found.",
            "Roughly speaking, about 5 random people doing these tasks on Mechanical Turk work as well as one trained editor.",
            "And other studies have found a similar ratio, but if you're not happy with the quality, you just get more judgments 'cause they're very inexpensive once you have the multiple judgments and you get to decide how you want to combine them.",
            "So you can say, oh, I'm only going to accept things where all the judges agreed otherwise.",
            "I won't count that or I'm going to take the average of the judges ratings or I'm going to let them vote whichever of the result categories you know irrelevant, marginally relevant, and so on gets the most votes.",
            "That's the one I'll sign.",
            "As the judgment, and we also have ways to filter out bad data after the fact.",
            "So first of all you don't have to pay people for data you don't like.",
            "If they're not doing the task properly.",
            "Sometimes there might be someone trying to scan the system by, say, you know hitting the same result for every query and not actually reading them.",
            "We have a way to deal with that so you can write some obvious filters to look at someones answers and see if they follow that kind of pattern.",
            "If you have a lot of judges you can say is there someone who consistently never agrees with anybody else?",
            "Then maybe they're not doing the task correctly.",
            "So again, there are ways to deal with the quality issue."
        ],
        [
            "So just kind of taking stock and looking at the whole system.",
            "Compared to the earlier methods, you can see that it has several different advantages.",
            "One of them is very fast.",
            "Turn around, we found in some cases we can put up a couple thousand of these hits.",
            "These tasks upon one night and in maybe a day or two have them all judged.",
            "Now that depends on the nature of the tasks, and tests are harder than others, but it's pretty amazing.",
            "I mean, you can do experimental turnover pretty fast.",
            "It's very low cost.",
            "There was a talk yesterday, I think it was by William Webber about.",
            "Evaluate getting more power in your evaluations and he was saying how?",
            "You know, there's different different strategies you can take, and one of them is to be a plutocratic here plutocrat and have this picture of like the Google guys.",
            "Oh, they've got all the money they want so they can run experiments with enough power, but otherwise the rest of us have to resort to these other methods.",
            "Well, with a system like Turk, anybody can be a plutocrat, right?",
            "The judgments are really so cheap that if you need more power in your experiment, you can just get more judgments.",
            "The results are pretty high quality as I said, and it's very flexible.",
            "I don't remember.",
            "I still have the slide in here, but we've seen this technique used by a lot of different researchers recently to do different kinds of experiments, so relevance judgments are one.",
            "But people are also using them for natural language processing, annotation tasks for user experience, user interface tasks, all kinds of things.",
            "Now there are some limitations.",
            "Like any method, the task is artificial, so the people doing the work aren't actually people searching their people, pretending there searching and imagining that they have to decide what's relevant.",
            "So that's a limitation, but that's also a limitation of pretty much all of these methods, except where you have real user traffic, so it's not really any more of a barrier.",
            "And the other thing is you do have an unknown population, so it's not like you know these are retired intelligence analysts, or you know these are trained editors.",
            "In fact, you could have someone who conceivably doesn't even understand the task or doesn't know anything about it.",
            "Now I think that problem is addressable pretty squarely by the.",
            "Qualification system, so let's say you were an Italian search engine and you wanted to make sure that people who were answering the queries not only new Italian but knew about Italian culture and knew about what the references were that you were making to be able to make good judgments.",
            "Well, you would have to design excuse me, design your qualification test in such a way that you were testing for that cultural knowledge.",
            "You know you could even say you have to be in Italy."
        ],
        [
            "How we doing that time?",
            "OK, just about done I think.",
            "Yeah so.",
            "Basically, there's there's.",
            "A couple of points.",
            "One is, we think that this Turk methodology is a viable alternative to traditional means of evaluating relevance.",
            "It doesn't mean that those other techniques aren't also useful, but we think this really offers a new way to do very low cost, very rapid evaluation, and we have this framework already built.",
            "Amazon Mechanical Turk, which gives people access to this community of workers who are willing to do a lot of this work in a short time.",
            "So we have a paper coming out about this in Cigar Forum December issue.",
            "It should be on line any day now, and if you're interested in the Mechanical Turk framework, you can go onto the Amtrak website.",
            "That's it.",
            "I'll be happy to take questions."
        ],
        [
            "I had a question you were talking about various things that to increase the quality you get more, ask more questions.",
            "I was wondering whether there was any correlation between the amount you pay and the quality.",
            "You didn't mention that if you pay somebody 5 cents, did they spend more time or do you find that there's just a threshold function that you need to pay enough that they accept the task at all and once they've accepted it?",
            "The quality is pretty much even.",
            "Yeah, it's a good question I think.",
            "The latter is more what we've seen, so there are people who aren't willing to do the task unless you pay them enough, and we've seen some I'm not going to go into details, but we've done certain other task where people just won't do it until you pay enough, and then once once they're doing it, the quality seems to be about the same.",
            "There actually forums where the people who are doing this work talk to each other and they talk about the specific tasks.",
            "It's actually very amusing and go on, and someone say, hey, did you see that you know what did you get for question three?",
            "What do you think about this?",
            "And so you have to be very careful how you design the tasks and how you design the qualifications so that people.",
            "Search cheap, but that's where you see people saying I'm not going to do that task for three cents.",
            "I you know, last week I got paid 5 and you know it took me 30."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hear me OK.",
                    "label": 0
                },
                {
                    "sent": "So thanks, mark.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to talk a little about crowdsourcing for relevance evaluation, but I wanted to start off by giving a little background about a 9.",
                    "label": 0
                },
                {
                    "sent": "Some people aren't really sure what a nine dozen that would be useful to give you some context.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So A9 is actually a search technology subsidiary of Amazon.com.",
                    "label": 1
                },
                {
                    "sent": "It's not a startup, it's not a company that was bought by Amazon.",
                    "label": 0
                },
                {
                    "sent": "It was a company that was created by Amazon to focus on search for Amazon and the primary mission of a 9 is to produce the product search engine that's used by Amazon.",
                    "label": 1
                },
                {
                    "sent": "So if you've used Amazon.com, you've used A9 search engine.",
                    "label": 1
                },
                {
                    "sent": "We also license it to other other retail sites that use the Amazon ecommerce platform.",
                    "label": 0
                },
                {
                    "sent": "We also created something called search inside the book, which you might have used and we also have an advertising business called Click River.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of what I'm mostly focuses on now.",
                    "label": 0
                },
                {
                    "sent": "Some of you may be saying, well, wait a second, didn't you used to have a website?",
                    "label": 0
                },
                {
                    "sent": "What you trying to do?",
                    "label": 0
                },
                {
                    "sent": "Web search stuff?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There was some work in the early days of a nine was about five years ago.",
                    "label": 1
                },
                {
                    "sent": "Now in looking at Federated Search and in fact we created something called the Open Search protocol, which is still used.",
                    "label": 0
                },
                {
                    "sent": "If you do search in the Firefox and Firefox plugins for example.",
                    "label": 0
                },
                {
                    "sent": "We also did some interesting work on geographic location with something called Block View, which was the first system to show what it looks like when you're going around looking at at stores from the humans POV.",
                    "label": 1
                },
                {
                    "sent": "But these are things we're focusing on today.",
                    "label": 0
                },
                {
                    "sent": "We're really concentrating on product search and advertising.",
                    "label": 0
                },
                {
                    "sent": "So what do I mean by?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Search product search is searching the corpus of retail products and it has a couple of characteristics that make it somewhat different from, say, web search.",
                    "label": 1
                },
                {
                    "sent": "So for one thing, the data is typically more structured, so we have things like prices and brands and features, sizes of clothing and colors, and things like that, all of which are attributes on the objects that were searching for.",
                    "label": 0
                },
                {
                    "sent": "Also, the search you eyes in a product search context typically have richer interaction that what you find on the web.",
                    "label": 0
                },
                {
                    "sent": "So for example on people do sorting other results.",
                    "label": 0
                },
                {
                    "sent": "I do filtering the results, they browse them in various ways.",
                    "label": 0
                },
                {
                    "sent": "Often there's interesting interactions of searching and browsing with faceted metadata, things like that.",
                    "label": 0
                },
                {
                    "sent": "The other interesting thing is we have a lot of different categories, so on the upper right there I've just got a screen grab of some of the categories.",
                    "label": 0
                },
                {
                    "sent": "You can search for on Amazon, just in the US.",
                    "label": 0
                },
                {
                    "sent": "And as you can imagine, the way you want to search in those different categories might vary, so the way you want to optimize search for books might be different from the way you want to search for video games.",
                    "label": 0
                },
                {
                    "sent": "Down at the bottom I put just a few sample queries, the kind of things that we get.",
                    "label": 0
                },
                {
                    "sent": "One of those who notices that they range from the fairly general to more generic.",
                    "label": 0
                },
                {
                    "sent": "I don't have sorry to.",
                    "label": 0
                },
                {
                    "sent": "The more specific I don't have a lot of really general ones here, but I mean you get the flavor of it now.",
                    "label": 0
                },
                {
                    "sent": "Some people think, well, the problem could be that hard.",
                    "label": 0
                },
                {
                    "sent": "I mean everybody's got the same intent right there all shopping, but in fact when people are shopping, they actually go through a lot of different stages or something called the buying funnel where someone might start out with just a vague awareness of and interest in.",
                    "label": 0
                },
                {
                    "sent": "In a category of products and then move toward maybe comparing specific products going down to finding out with the features are for product doing, looking at the price and things like that.",
                    "label": 0
                },
                {
                    "sent": "Some people come just to do research.",
                    "label": 0
                },
                {
                    "sent": "Some people come to read the reviews.",
                    "label": 0
                },
                {
                    "sent": "There's all kinds of user intents, even though everybody is more or less shopping.",
                    "label": 0
                },
                {
                    "sent": "So that's what we do.",
                    "label": 0
                },
                {
                    "sent": "So like any search engine that has to try.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Produce the best results we can.",
                    "label": 0
                },
                {
                    "sent": "We're interested in the question of relevance and how we evaluate relevance.",
                    "label": 0
                },
                {
                    "sent": "And as I'm sure you know, relevance is notoriously hard to evaluate.",
                    "label": 1
                },
                {
                    "sent": "I've written about that a little bit in the web search context.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of research about it.",
                    "label": 0
                },
                {
                    "sent": "Just defining relevance is still kind of a research issue.",
                    "label": 0
                },
                {
                    "sent": "Much less evaluating.",
                    "label": 0
                },
                {
                    "sent": "It's highly subjective.",
                    "label": 1
                },
                {
                    "sent": "It's very task specific, and so on, and it's very expensive to measure.",
                    "label": 0
                },
                {
                    "sent": "So I thought I would take you through kind of a quick history of some of the main approaches to evaluating relevance, to lead up to the one that we're proposing here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one of the classic approaches to evaluating relevance is to get a bunch of human judgments, explicit judgments on a standard test collection, and this test collection is going to have a corpus of documents.",
                    "label": 0
                },
                {
                    "sent": "It's going to have a set of queries, and it's going to have relevance judgments, and the idea is, once you put this set together, you can reuse it for multiple experiments.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Really good example of that is the CRAN field studies in the early 1960s and a bunch of other test corporate that were created very similar to this where the idea is you actually exhaustively evaluate every document in the corpus for every query.",
                    "label": 1
                },
                {
                    "sent": "So some poor graduate student had to sit down an read every, see ACM abstract or whatever the documents were in the collections at the time.",
                    "label": 0
                },
                {
                    "sent": "Well, this kind of breaks down if your documents are long and it also breaks down if you have more than, say, a couple 1000, which is what the typical corpus sizes were back then.",
                    "label": 0
                },
                {
                    "sent": "So this was great for the 60s, but it kind of stopped working.",
                    "label": 0
                },
                {
                    "sent": "Maybe by the 70s, and certainly by the 80s, and so we moved on to another Strat.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "G which is pulling.",
                    "label": 0
                },
                {
                    "sent": "Pulling is the idea that's used in track, and several of the other standard IR evaluations.",
                    "label": 1
                },
                {
                    "sent": "Where basically you have a whole bunch of participants all wanting to test their engine against the same corpus and then you get each system to say what it stop in.",
                    "label": 0
                },
                {
                    "sent": "In this case 100 results are and you take the union of all those you make.",
                    "label": 0
                },
                {
                    "sent": "This pool of documents an have someone some kind of relevance assessor decide whether the documents are relevant or not for those queries or those topics.",
                    "label": 0
                },
                {
                    "sent": "And in the case of Trek, they got retired intelligence analysts to do the relevance assessments, which is great.",
                    "label": 1
                },
                {
                    "sent": "These were pretty expert people.",
                    "label": 0
                },
                {
                    "sent": "Experts at judging whether something is relevant or not.",
                    "label": 0
                },
                {
                    "sent": "I'm so that worked pretty well and has a lot of advantages, but together with the other approach, both of these ideas of having these explicit human judgments run into some various kinds of problem.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First of all, the test sets get stale.",
                    "label": 1
                },
                {
                    "sent": "I think it was Ian Soboroff who said yesterday that if you're using an old Trek collection with new search engine, that's bad methodology, partly because the judgments that are in the pool are only a subset of all the judgments that should be there as search engines get better.",
                    "label": 0
                },
                {
                    "sent": "But it's also true just for the fact that the sets that are there may not be there says that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So maybe I've got some kind of specialized search need, so I'm going to give an example in little while where maybe I'm creating a search engine too.",
                    "label": 0
                },
                {
                    "sent": "Give you information about facts about the world, locations in the world well, if there's no trek collection for facts about the world, you're kind of out of luck.",
                    "label": 0
                },
                {
                    "sent": "So that's a problem in general, just having this batch methodology may not work in all all situations.",
                    "label": 0
                },
                {
                    "sent": "So for example, if I'm doing some kind of UI research or I want to see you know the effect of longer or shorter snippets or something like that.",
                    "label": 0
                },
                {
                    "sent": "Again, the standard methodology and track is not going to help me.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "That's not to say that trek the organization hasn't done a lot of interesting experiments in other kinds of.",
                    "label": 0
                },
                {
                    "sent": "Evaluation methodologies like Track, interactive several years ago and so on, but the standard methodology isn't going to work for these.",
                    "label": 0
                },
                {
                    "sent": "It's also pretty expensive to create new sets.",
                    "label": 1
                },
                {
                    "sent": "Not everybody has retired intelligence analysts hanging around.",
                    "label": 0
                },
                {
                    "sent": "Even even then, even if you have them, it breaks down for really big corpora.",
                    "label": 1
                },
                {
                    "sent": "So the original Trek collection I think was about half a million documents, and since then we've seen much larger ones, but it's not quite web scale.",
                    "label": 0
                },
                {
                    "sent": "We have 20 billion.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's another thing you could do, and this is actually seems to be what's becoming more common now, both in industry and academia, which is just give up on recall focus on DCG.",
                    "label": 1
                },
                {
                    "sent": "And create your own collection just for this task.",
                    "label": 0
                },
                {
                    "sent": "So let's say you're a professor.",
                    "label": 0
                },
                {
                    "sent": "You came up with some new idea.",
                    "label": 0
                },
                {
                    "sent": "You try it out on the web, get your own little test collection, get your grad students to judge as many queries as they can stand, and then report the DCG.",
                    "label": 0
                },
                {
                    "sent": "So that's that's pretty good.",
                    "label": 0
                },
                {
                    "sent": "It works in a lot of cases, but it's pretty time consuming and it's very expensive or it's very expensive.",
                    "label": 0
                },
                {
                    "sent": "So if you have grad students and they have a lot of time, then that's OK. Maybe if you're Google or Yahoo and you can afford to hire Staffs of editors, and that's probably OK, But if you're anybody else, it's kind of hard.",
                    "label": 0
                },
                {
                    "sent": "So one thing you might say is, well, maybe we can just get rid of the need for having these people doing these explicit judgments all the time.",
                    "label": 0
                },
                {
                    "sent": "And of course there are approaches that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do that so for example, the interleaving approach that Yokums suggested a couple years ago, where you can compare 2 engines by having their results be interleaved and observe the click positions, so that's great.",
                    "label": 0
                },
                {
                    "sent": "That's also another class of problems, but it doesn't handle all the situations again, because first of all you need a lot of real users, so if you want to compare how people are going to click, you want them to be doing it in this kind of organic environment, not not conscious that they're making your relevance judgment.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it kind of defeats the purpose there.",
                    "label": 0
                },
                {
                    "sent": "And the data isn't really reusable, so if I do an experiment where I'm comparing algorithm 8 algorithm be with by observing people coming in my site and now I want to try algorithm.",
                    "label": 0
                },
                {
                    "sent": "see I can't reuse the judgments that were made comparing A to B, they don't do me any good for algorithms see, whereas in the traditional model that wreck style model, everybody can retest their algorithm against the same data.",
                    "label": 0
                },
                {
                    "sent": "So you might think that's not a big deal, but if you're.",
                    "label": 0
                },
                {
                    "sent": "For example, a startup company and you don't want to disclose what your doing yet you want to just try it in the lab you want to be able to test it without having real users in real traffic.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we've got these two main approaches.",
                    "label": 0
                },
                {
                    "sent": "One of them involves expensive human judgments, but it has the advantage that these judgments are reusable and it's very flexible.",
                    "label": 0
                },
                {
                    "sent": "You can make a judgement set for anything you want.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you've got these kind of automated metrics or implicit judgment approach, which allows you to do much larger scale to deal with much larger scale corpora.",
                    "label": 0
                },
                {
                    "sent": "But and it's very inexpensive, but it has these drawbacks that I just mentioned, so we'd like to have is something that kind of combines the best of best of both worlds here and So what we're suggesting is something we call Turk technique.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evaluating relevance by crowdsourcing.",
                    "label": 0
                },
                {
                    "sent": "What do I mean by crowd sourcing?",
                    "label": 0
                },
                {
                    "sent": "Crowdsourcing is a term that was coined by Jeff Howe at Wired magazine and in an article about a couple years ago.",
                    "label": 0
                },
                {
                    "sent": "And the way he described it was everyday.",
                    "label": 0
                },
                {
                    "sent": "People using their spare cycles to create content solve problems, even do corporate R&D.",
                    "label": 1
                },
                {
                    "sent": "So another way to look at it is just having a large pool of workers who are all across the world doing little bits of work over the Internet for amounts before payment.",
                    "label": 0
                },
                {
                    "sent": "Now, this kind of has the flavor of a lot of Web 2.0 applications, but the difference is.",
                    "label": 0
                },
                {
                    "sent": "In typical Web 2.0 applications like Flickr or Dig or something like that Wikipedia, the people sort of all know about each other, and they're interacting with each other, and in fact that's one of the benefits is the social aspect, and that's less true for the crowdsourcing paradigm.",
                    "label": 0
                },
                {
                    "sent": "Here it's just everybody individually can get access to the work, and you as the person who have the work and get access to all the workers.",
                    "label": 0
                },
                {
                    "sent": "But it's not really about the community, although they do tend to form communities and forums and so on.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the the particular framework for crowdsourcing that we use is called Amazon Mechanical Turk and a lot of people may not realize that Amazon is gone into the services business in a pretty big way.",
                    "label": 1
                },
                {
                    "sent": "So they have a cloud computing service called EC2 Elastic Compute Cloud.",
                    "label": 0
                },
                {
                    "sent": "They have a storage service and they have a payment service.",
                    "label": 0
                },
                {
                    "sent": "So if you're a small business and you don't want to build your own payment infrastructure on your website, you can just call Amazons through this web Services API.",
                    "label": 0
                },
                {
                    "sent": "And then another one is this Amazon Mechanical Turk to why is it called Mechanical Turk?",
                    "label": 0
                },
                {
                    "sent": "Well, there was a system.",
                    "label": 0
                },
                {
                    "sent": "It was this.",
                    "label": 0
                },
                {
                    "sent": "A form of entertainment that went around in the 18th century, which purported to be a chess playing automaton in the form of this mannequin that looked like a Turkish guy.",
                    "label": 0
                },
                {
                    "sent": "And if you open the cabinet door, use all these gears and wheels and it looked like it was totally mechanical.",
                    "label": 0
                },
                {
                    "sent": "But in fact there was someone in a hidden compartment, a small person who actually sat underneath and by using magnets could tell where the chess pieces were on the board and then control the so called automaton.",
                    "label": 0
                },
                {
                    "sent": "So what's the connection there with this Mechanical Turk framework well?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Imagine that you've got some work you want to do, and you want your program you want to be able to do this work programmatically, so you've got your computer program and you want your computer program to be able to call a function, and the function has to do something really smart, has to do something that would require AI like, really good, perfect, you know, science fiction, AI?",
                    "label": 0
                },
                {
                    "sent": "Well, we don't have that science fiction AI yet, so we could just pretend to have it by having a person on the other end instead.",
                    "label": 0
                },
                {
                    "sent": "So it's artificial, artificial intelligence is, Jeff Bezos says that's how Mechanical Turk work, so.",
                    "label": 0
                },
                {
                    "sent": "You put a task through this web Services API and a person on the other end gets the task and returned it and your program keeps going.",
                    "label": 1
                },
                {
                    "sent": "So this is how the framework works.",
                    "label": 0
                },
                {
                    "sent": "The people who have work they want done are called requesters.",
                    "label": 0
                },
                {
                    "sent": "They create things called human intelligence tasks or hits the people who do the work are called workers.",
                    "label": 1
                },
                {
                    "sent": "Are they sometimes actually call themselves Turkers and they log in and do the tasks and then if the request is there happy with the work, they pay a little bit of money for the completed work.",
                    "label": 1
                },
                {
                    "sent": "As of today, there are about 200,000 people doing work on Mechanical Turk from 100 countries.",
                    "label": 1
                },
                {
                    "sent": "They've completed millions of hits and as of when I made these slides, there were over 21,000 tasks available to be done.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Typical task, well, I don't know how you can see that down there, but.",
                    "label": 0
                },
                {
                    "sent": "There are things like translate this paragraph of text for $0.10 or label these images.",
                    "label": 0
                },
                {
                    "sent": "One of the things down there is labeled images of geological formations.",
                    "label": 0
                },
                {
                    "sent": "There are 487 of those tasks.",
                    "label": 0
                },
                {
                    "sent": "If you want to do the man, they pay 5 cents each.",
                    "label": 1
                },
                {
                    "sent": "So that's the kind of thing we're talking about.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we want to do relevance.",
                    "label": 0
                },
                {
                    "sent": "We want to use this form this framework for relevance evaluation.",
                    "label": 0
                },
                {
                    "sent": "So imagine that we're building this hypothetical world fact search engine, and so we're going to grab some pieces of text from the CIA World Fact book and get people to judge whether or not they're relevant to queries which are going to consist of locations in the world.",
                    "label": 0
                },
                {
                    "sent": "And let's say we want to create a test set with 50 queries.",
                    "label": 1
                },
                {
                    "sent": "For each query we want to judge the first 50 results, so that gives us 2500 query result pairs.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you might be thinking well, D. Are you just going to let anybody off the street answer questions about you know geographical facts?",
                    "label": 0
                },
                {
                    "sent": "What if they don't know anything about geography?",
                    "label": 0
                },
                {
                    "sent": "What if they don't know anything about these places in the world?",
                    "label": 0
                },
                {
                    "sent": "So there's a system built into Mechanical Turk to deal with that which is a qualification mechanism where you can give people a test and say you're only allowed to do the task.",
                    "label": 0
                },
                {
                    "sent": "If you pass this test so we can have a question like you know which Major City or which country has a city named Kira, or what's closest to the population of India.",
                    "label": 1
                },
                {
                    "sent": "And you can set these up however you want.",
                    "label": 0
                },
                {
                    "sent": "You can make them be free response, so you're going to manually judge the results.",
                    "label": 0
                },
                {
                    "sent": "You can make them be automatically graded.",
                    "label": 0
                },
                {
                    "sent": "You can give a certain point value to each one, so you can say you know you get 10 points if you get the right answer, but you get five points if you get a close one, and so on.",
                    "label": 0
                },
                {
                    "sent": "And you can set it up so that you can decide what the passing score has to be.",
                    "label": 0
                },
                {
                    "sent": "Maybe you have to get him alright, maybe have to get a certain percentage so we can filter out people who don't know about geography.",
                    "label": 0
                },
                {
                    "sent": "So we qualified the workers now.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have to make the hits when you make the hits you do it.",
                    "label": 0
                },
                {
                    "sent": "You can use a graphical interface, but if you're doing a lot in batch, you typically create these XML.",
                    "label": 0
                },
                {
                    "sent": "Templates and here's an example.",
                    "label": 0
                },
                {
                    "sent": "I've just highlighted a couple of attacks to illustrate what the structure looks like.",
                    "label": 0
                },
                {
                    "sent": "So you say, oh, it's a question and it has a display name.",
                    "label": 0
                },
                {
                    "sent": "In this case, question one has some content and we're going to specify how the answer should appear, so we want a radio button kind of answer, and the first radio button is going to say irrelevant, and when you do all that you put in the system, you get a hit like this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what it looks like to the worker.",
                    "label": 0
                },
                {
                    "sent": "The person who's going to do the task.",
                    "label": 0
                },
                {
                    "sent": "So they say, oh, there's a relevance evaluation task and here it is.",
                    "label": 0
                },
                {
                    "sent": "Is the following text relevant to Andorra?",
                    "label": 0
                },
                {
                    "sent": "And then there's this piece of text tourism.",
                    "label": 0
                },
                {
                    "sent": "The mainstay of Andorra's.",
                    "label": 0
                },
                {
                    "sent": "Tiny well to do economy, blah blah blah and you market irrelevance.",
                    "label": 0
                },
                {
                    "sent": "Partially relevant, whatever we're going to use these graded relevance judgments in DCG, so we're going to sign each one a number, let's say zero, through four or three.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we created the hits.",
                    "label": 0
                },
                {
                    "sent": "How much are we going to pay people for a test like this?",
                    "label": 0
                },
                {
                    "sent": "We've actually been able to pay typically 1 cent, sometimes 2 cents an get good answers.",
                    "label": 0
                },
                {
                    "sent": "So 1 cent per hit.",
                    "label": 1
                },
                {
                    "sent": "On one of these query result pairs together with these 50 queries, 50 results, and we're going to have five workers do each one for reasons I'll explain in a second, and that gives us a total of $125 for this task.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now you might be worried that we aren't going to get very good quality results, but we have a way to deal with that too.",
                    "label": 0
                },
                {
                    "sent": "So first of all, as I said, we can just make the test be harder so that we know that people really know something about the topic.",
                    "label": 0
                },
                {
                    "sent": "Secondly, we can get redundant judgments, and in fact we've found.",
                    "label": 1
                },
                {
                    "sent": "Roughly speaking, about 5 random people doing these tasks on Mechanical Turk work as well as one trained editor.",
                    "label": 0
                },
                {
                    "sent": "And other studies have found a similar ratio, but if you're not happy with the quality, you just get more judgments 'cause they're very inexpensive once you have the multiple judgments and you get to decide how you want to combine them.",
                    "label": 0
                },
                {
                    "sent": "So you can say, oh, I'm only going to accept things where all the judges agreed otherwise.",
                    "label": 0
                },
                {
                    "sent": "I won't count that or I'm going to take the average of the judges ratings or I'm going to let them vote whichever of the result categories you know irrelevant, marginally relevant, and so on gets the most votes.",
                    "label": 0
                },
                {
                    "sent": "That's the one I'll sign.",
                    "label": 0
                },
                {
                    "sent": "As the judgment, and we also have ways to filter out bad data after the fact.",
                    "label": 1
                },
                {
                    "sent": "So first of all you don't have to pay people for data you don't like.",
                    "label": 0
                },
                {
                    "sent": "If they're not doing the task properly.",
                    "label": 0
                },
                {
                    "sent": "Sometimes there might be someone trying to scan the system by, say, you know hitting the same result for every query and not actually reading them.",
                    "label": 0
                },
                {
                    "sent": "We have a way to deal with that so you can write some obvious filters to look at someones answers and see if they follow that kind of pattern.",
                    "label": 0
                },
                {
                    "sent": "If you have a lot of judges you can say is there someone who consistently never agrees with anybody else?",
                    "label": 0
                },
                {
                    "sent": "Then maybe they're not doing the task correctly.",
                    "label": 0
                },
                {
                    "sent": "So again, there are ways to deal with the quality issue.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just kind of taking stock and looking at the whole system.",
                    "label": 0
                },
                {
                    "sent": "Compared to the earlier methods, you can see that it has several different advantages.",
                    "label": 0
                },
                {
                    "sent": "One of them is very fast.",
                    "label": 0
                },
                {
                    "sent": "Turn around, we found in some cases we can put up a couple thousand of these hits.",
                    "label": 0
                },
                {
                    "sent": "These tasks upon one night and in maybe a day or two have them all judged.",
                    "label": 0
                },
                {
                    "sent": "Now that depends on the nature of the tasks, and tests are harder than others, but it's pretty amazing.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can do experimental turnover pretty fast.",
                    "label": 0
                },
                {
                    "sent": "It's very low cost.",
                    "label": 0
                },
                {
                    "sent": "There was a talk yesterday, I think it was by William Webber about.",
                    "label": 0
                },
                {
                    "sent": "Evaluate getting more power in your evaluations and he was saying how?",
                    "label": 0
                },
                {
                    "sent": "You know, there's different different strategies you can take, and one of them is to be a plutocratic here plutocrat and have this picture of like the Google guys.",
                    "label": 0
                },
                {
                    "sent": "Oh, they've got all the money they want so they can run experiments with enough power, but otherwise the rest of us have to resort to these other methods.",
                    "label": 0
                },
                {
                    "sent": "Well, with a system like Turk, anybody can be a plutocrat, right?",
                    "label": 0
                },
                {
                    "sent": "The judgments are really so cheap that if you need more power in your experiment, you can just get more judgments.",
                    "label": 0
                },
                {
                    "sent": "The results are pretty high quality as I said, and it's very flexible.",
                    "label": 1
                },
                {
                    "sent": "I don't remember.",
                    "label": 0
                },
                {
                    "sent": "I still have the slide in here, but we've seen this technique used by a lot of different researchers recently to do different kinds of experiments, so relevance judgments are one.",
                    "label": 0
                },
                {
                    "sent": "But people are also using them for natural language processing, annotation tasks for user experience, user interface tasks, all kinds of things.",
                    "label": 0
                },
                {
                    "sent": "Now there are some limitations.",
                    "label": 0
                },
                {
                    "sent": "Like any method, the task is artificial, so the people doing the work aren't actually people searching their people, pretending there searching and imagining that they have to decide what's relevant.",
                    "label": 0
                },
                {
                    "sent": "So that's a limitation, but that's also a limitation of pretty much all of these methods, except where you have real user traffic, so it's not really any more of a barrier.",
                    "label": 0
                },
                {
                    "sent": "And the other thing is you do have an unknown population, so it's not like you know these are retired intelligence analysts, or you know these are trained editors.",
                    "label": 0
                },
                {
                    "sent": "In fact, you could have someone who conceivably doesn't even understand the task or doesn't know anything about it.",
                    "label": 0
                },
                {
                    "sent": "Now I think that problem is addressable pretty squarely by the.",
                    "label": 0
                },
                {
                    "sent": "Qualification system, so let's say you were an Italian search engine and you wanted to make sure that people who were answering the queries not only new Italian but knew about Italian culture and knew about what the references were that you were making to be able to make good judgments.",
                    "label": 0
                },
                {
                    "sent": "Well, you would have to design excuse me, design your qualification test in such a way that you were testing for that cultural knowledge.",
                    "label": 0
                },
                {
                    "sent": "You know you could even say you have to be in Italy.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How we doing that time?",
                    "label": 0
                },
                {
                    "sent": "OK, just about done I think.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "Basically, there's there's.",
                    "label": 0
                },
                {
                    "sent": "A couple of points.",
                    "label": 0
                },
                {
                    "sent": "One is, we think that this Turk methodology is a viable alternative to traditional means of evaluating relevance.",
                    "label": 1
                },
                {
                    "sent": "It doesn't mean that those other techniques aren't also useful, but we think this really offers a new way to do very low cost, very rapid evaluation, and we have this framework already built.",
                    "label": 0
                },
                {
                    "sent": "Amazon Mechanical Turk, which gives people access to this community of workers who are willing to do a lot of this work in a short time.",
                    "label": 0
                },
                {
                    "sent": "So we have a paper coming out about this in Cigar Forum December issue.",
                    "label": 0
                },
                {
                    "sent": "It should be on line any day now, and if you're interested in the Mechanical Turk framework, you can go onto the Amtrak website.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "I'll be happy to take questions.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I had a question you were talking about various things that to increase the quality you get more, ask more questions.",
                    "label": 0
                },
                {
                    "sent": "I was wondering whether there was any correlation between the amount you pay and the quality.",
                    "label": 0
                },
                {
                    "sent": "You didn't mention that if you pay somebody 5 cents, did they spend more time or do you find that there's just a threshold function that you need to pay enough that they accept the task at all and once they've accepted it?",
                    "label": 0
                },
                {
                    "sent": "The quality is pretty much even.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's a good question I think.",
                    "label": 0
                },
                {
                    "sent": "The latter is more what we've seen, so there are people who aren't willing to do the task unless you pay them enough, and we've seen some I'm not going to go into details, but we've done certain other task where people just won't do it until you pay enough, and then once once they're doing it, the quality seems to be about the same.",
                    "label": 0
                },
                {
                    "sent": "There actually forums where the people who are doing this work talk to each other and they talk about the specific tasks.",
                    "label": 0
                },
                {
                    "sent": "It's actually very amusing and go on, and someone say, hey, did you see that you know what did you get for question three?",
                    "label": 0
                },
                {
                    "sent": "What do you think about this?",
                    "label": 0
                },
                {
                    "sent": "And so you have to be very careful how you design the tasks and how you design the qualifications so that people.",
                    "label": 0
                },
                {
                    "sent": "Search cheap, but that's where you see people saying I'm not going to do that task for three cents.",
                    "label": 0
                },
                {
                    "sent": "I you know, last week I got paid 5 and you know it took me 30.",
                    "label": 0
                }
            ]
        }
    }
}