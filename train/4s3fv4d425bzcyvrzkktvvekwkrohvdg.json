{
    "id": "4s3fv4d425bzcyvrzkktvvekwkrohvdg",
    "title": "Convex Optimization",
    "info": {
        "author": [
            "Lieven Vandenberghe, Electrical Engineering Department, University of California, Los Angeles, UCLA"
        ],
        "published": "Oct. 12, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Optimization Methods->Convex Optimization",
            "Top->Computer Science->Optimization Methods->Linear Programming"
        ]
    },
    "url": "http://videolectures.net/mlss2011_vandenberghe_convex/",
    "segmentation": [
        [
            "So."
        ],
        [
            "I'd like to start with some short introduction about the place of convex optimization optimization in general, and then an overview of those three."
        ],
        [
            "Torreilles so I think everyone is familiar with the standard nonlinear mathematical optimization problem.",
            "Value optimize nonlinear function F0 subject to a number of constraints, and it's clear that a very general problem that doesn't need to be motivated because almost any engineering design problem, any estimation problem can be written in this form.",
            "Now, unfortunately, the general optimization problem is also very intractable, so in general this problem is very difficult to solve.",
            "At least if you mean by minimization, you really mean find the best solution subject to the constraints.",
            "Um and.",
            "Convex optimization is useful or important because, roughly speaking, the nonlinear optimization problems that are tractable coincide with the ones that are convex and the boundary between the convex and convex roughly coincides with easy and difficult problems.",
            "So in general, the general problem is difficult to solve, and it's also very difficult in general, or not always easy to recognize the problems that are easy.",
            "And so that's why one of the major topics of this lecture.",
            "So there's one important exception to this.",
            "So a class of problems that's well known to be tractable and also quite easy to recognize."
        ],
        [
            "And that's the linear programming problem, where you minimize a linear function.",
            "Subject to a set of linear inequalities, so that was.",
            "So actually, the study of linear programming Model S starts with or started the field of mathematical optimization in general or the study of numerical methods for optimization.",
            "With down 6 simplex methods in at the end of the 40s, so the answer introduced an efficient method for solving linear programming problems by computer.",
            "And the applications he had in mind were in logistics and operations planning.",
            "But then since then, the applications of linear programming have multiplied and now it's widely used in engineering and operations research.",
            "Also combinatorial optimization and a wide variety of fields.",
            "And that's a little surprising, because the problem itself is clearly very specialized, because everything is linear.",
            "But that hasn't stopped linear programming from becoming a very important.",
            "And widely used technique and the reason of course, is that it's easy to solve.",
            "People can solve linear programming problems with very large scale, and that makes it interesting to look for applications of linear programming exactly or with approximations.",
            "And also it's makes it useful as a sub problem to solve some problems in combinatorial or non convex or discrete optimization problems where you solve computer problems by branch and bounds, and then every subproblem is a linear programming problem.",
            "And then the scalability of the entire method comes from the tractability of linear programming problem.",
            "So far."
        ],
        [
            "For convex optimization, smaller is the same story, except that this.",
            "Is more recent so convex optimization problem in practice as?",
            "Been applied for maybe last 20 years or so.",
            "And another difference with linear programming is that it's of course much more general, because you can allow the functions in the objective and the constraints to be nonlinear.",
            "They have to be convex.",
            "So it's a very substantial extension of linear programming.",
            "Therefore, it's also more difficult to recognize and simple linear programming problems, but many of the other properties of linear programming also hold for convex optimization, so it's very tractable and we see that the methods that people have developed, or some of the methods for linear programming extend very easily too.",
            "General nonlinear convex optimization problems.",
            "And it's also.",
            "Right here for applications, but also in for nonconvex problems as the basis of either relaxations to be used in exact global optimization problems or heuristics, or.",
            "Similar techniques."
        ],
        [
            "So some brief history.",
            "So I mentioned linear programming at the start of the whole development of mathematical programming.",
            "Then during the 50s people extended linear programming to include an quadratic objective function.",
            "So the first extension they made was to replace the linear objective by quadratic convex objective, and that's a quadratic programming problem.",
            "At the end of the 1960s throws a sort of maybe a smaller development.",
            "It's called geometric programming that will define.",
            "And can also be interpreted as an extension of linear programming.",
            "And then since the beginning of the 1990s has been several nonlinear classes of or extensions of linear programming with different names, semidefinite programming, 2nd order, cone programming, and so on.",
            "So we've seen what we'll see.",
            "What happened around 1990 to make start this evolution?"
        ],
        [
            "For applications we see the same story more or less around 1990 people have developed or started to apply convex optimization in many different areas.",
            "So one of the first was control theory and linear matrix inequalities and semidefinite programming and control theory.",
            "The machine learning has of course been one of the success stories of convex optimization with the support vector machine training via quadratic programming.",
            "There are also applications and combinatorial optimization where people try to find better relaxations for combinatorial problems better than the standard linear programming relaxations by formulating nonlinear convex relaxations.",
            "More recently, there's also the one norm heuristics for sparse optimization that rely on convex formulations and and etc."
        ],
        [
            "So the main event around 1990 that started this interesting convex optimization or the development of interior point methods for convex optimization.",
            "So this came after the 1980s and the development of polynomial time, interior point methods for linear programming, so in 1984.",
            "This famous paper where he proposed an interior point method for linear programming with a polynomial time complexity proof, and I was also considered the first practical polynomial time algorithm for linear programming.",
            "So it solved a major open problem.",
            "And then during the 1980s, starting with the 1984 people simplified his method and extended it.",
            "And optimize it for practical efficiency and practical performance and in.",
            "And so that was the development of linear programming, interior point methods.",
            "And then around 1919 Estavana Brosky, another people extended the interior point methods for linear programming to nonlinear convex optimization, and that generated this interest in convex optimization because the reasoning was if convex optimization problem can be solved with very similar methods as linear programming, then it should also be at least as useful because it's also much more general problem.",
            "So that sort of was a focused you throughout the 1990s, so the emphasis in research and optimization algorithms for convex optimization is an interior point methods.",
            "And then the last 10 years or so there is an increased emphasis on 1st order methods for very large scale or large scale optimization.",
            "Where people?",
            "Try to develop very inexpensive methods that can scale better to large dimensions, and there's been some remarkable new methods that improve on the standard very classical algorithms like gradient descent and etc.",
            "So we'll discuss these two classes of methods tomorrow."
        ],
        [
            "So this is the agenda for the three lectures.",
            "So today we'll talk about some basic theory theory and definitions and examples of convex optimization problems and some applications tomorrow in the first lecture I would like to talk about interior point methods for convex optimization and then in the last lecture will talk about the 1st order methods.",
            "Any questions?"
        ],
        [
            "So start with zombie."
        ],
        [
            "Definitions, so I think most of you know the convex status set is convex.",
            "If the line segment between any two points in the set is contained in the set.",
            "So that's this.",
            "Is a convex set.",
            "This is not convex.",
            "This is also not convex because of the boundary."
        ],
        [
            "So some examples that are very common and affine set, so the solution set of any set of linear equations is convex, independent of the size or the dimension of the matrices.",
            "1/2 space so solution set of linear inequality.",
            "A single linear inequality with a non zero normal vector is convex.",
            "Solution of a finite number of linear inequalities is called a polyhedron.",
            "So in this these nodes are used this inequality sign to denote componentwise inequality between vectors, so this is a component wise and equality between two vectors X&B, so it denotes a set of.",
            "A finite set of linear inequalities.",
            "An ellipsoid or the solution of a quadratic inequality with a positive definite matrix matrix A.",
            "A unit normal or a normal for any norm is always convex that follows from the definition of norm.",
            "And then another interesting set that will uses the positive semidefinite cone or the set of positive semidefinite matrices that will denote like this.",
            "So the Bolt faces with a subscript N will be the set of symmetric matrices of order N. This inequality for a matrix denotes positive semidefinite knus, and then this is the positive semidefinite cone.",
            "So it's a convex set, and it's also a cone, because any positive multiple of any vector in this set is also in the set.",
            "And a useful property is that the intersection of convex sets is always convex, and that follows of course directly from the definition of convexity in terms of the line segments.",
            "But that's also that's a very basic simple property, but it's."
        ],
        [
            "Useful in practice.",
            "For example, this is an example of a convex set specified by an.",
            "As follows, so suppose P of T is a cosine polynomial.",
            "So as terms cosine, T, cosine, tutee, etc, and the coefficients are X1 X 2X.",
            "And then you look at the succeeded find as the coefficients of all the cosine polynomials that are between negative one and one on some interval between 0 and \u03c0 / 3.",
            "So these are.",
            "I hope you can see this.",
            "These are three examples of polynomials P of T that satisfy this condition between minus one and one on this interval.",
            "And then C is a set of those schools and polynomials, or the set of their coefficients?",
            "Well, that's a convex set.",
            "And that's easy to see from this intersection property, because if you fix T, if you look at this condition for a fixed T. Then it says that the absolute value of this expression is between one and negative one.",
            "So that's two linear inequalities.",
            "So for fixty, this is too linear inequality's, so that's a convex set, because this intersection of two parallel half spaces.",
            "And then if you impose this condition for all T. Frailty in this case infinitely many T you get an intersection of many of those have spaces for each D have two parallel spaces and then if you change T they have spaces rotate and it describes a non polyhedral convex set, so it's not polyhedral because you need infinitely many qualities to describe it, but it's clearly convex."
        ],
        [
            "So that's all we will need about to know about convex sets.",
            "A convex function is defined like this, so the function is convex if its domain is convex.",
            "Sets of points where it's defined as convex and on its domain, Jensen's inequality holds.",
            "So that's Jensen's inequality.",
            "So graphically it means that if you have two points on the graph of the function.",
            "We value F of XF of Y.",
            "Then the linear segment defined by those two points on the graph lies above the graph of the function.",
            "That's a convex function.",
            "And F is concave.",
            "If minus F is convex.",
            "So what are some?"
        ],
        [
            "Simple examples.",
            "So obviously linear or affine functions are convex, also concave.",
            "Exponential the negative of a logarithm.",
            "Negative entropy X log X are convex.",
            "Powers certain powers are convex.",
            "For example, if X is positive.",
            "If that's the domain of F, then X to the Alpha is convex.",
            "If offer is greater than one.",
            "Or negative, etc.",
            "Any norm is convex.",
            "This is a function that's not immediately clear, but also convex.",
            "If you have a quadratic function X, transpose X / T. As a function of X&T jointly.",
            "Where T is positive.",
            "That's a convex function of X&T.",
            "A geometric mean of in a non negative variables is concave.",
            "Logged out of the lock of the determinant of a positive definite matrix is concave, so it's concave on the set of positive definite matrices so that function will be important in when you talk about interior point methods.",
            "And then the last one will also encounter is the log of the sum of exponentials of variables is convex.",
            "Of course, the sum of exponentials by itself is convex, because exponentials are convex.",
            "But even if you take the log or apply the logarithm to it, you still have convex function."
        ],
        [
            "So there's also a simple connection between convex functions and convex sets.",
            "So the convex function is convex if its epigraph is convex, convex, as a convex set.",
            "So the epic level function is simply the set defined of everything that lies above the graph of the function.",
            "The graph itself and everything above.",
            "So if X is a function of invariables, its epigraph is set in R N + 1.",
            "Ghosty is the extra variable.",
            "And the so this is if and only if a function is convex if and only if its epigraph is a convex set.",
            "You can also consider the sublevel sets of a function convex function so it's a set of points X in the domain of F that has a have a function value less than or equal in a certain Alpha.",
            "Now a sublevel set of a convex function is always convex, and that follows again directly from the definition, but the converse is not true.",
            "There are functions that are not convex and still have.",
            "Convex sublevel sets for all values of Alpha."
        ],
        [
            "So convex functions were defined in general using Jensen's inequality, so they don't have to be differentiable.",
            "If it also differentiable once or twice differentiable, then you can also give equivalent conditions that can replace Jensen's inequality in the diff."
        ],
        [
            "Mission."
        ],
        [
            "For example, if the function is differentiable, then an equivalent condition is that the function value of the graph.",
            "Function satisfies this inequality, so on the right hand side you see the linear approximation of the function around a point X, so the 1st order linear approximation of.",
            "A function from its function value and its gradient.",
            "Well, if the function is convex, then that linear approximation must be below the graph of the function.",
            "Throw possible points where you take the approximation, so this first order linear approximation is not only a local approximation of the function, but it's also a global lower bound on the function value, so it's a very fundamental.",
            "Property.",
            "An if of course you also have secondary data function is twice differentiable.",
            "Then you can express convexity.",
            "Also simply in terms of the Hessian and say that the Hessian matrix of the function must be positive semidefinite everywhere in its domain.",
            "So those are the definitions, so the Jensen's inequality, then these two equivalent definitions for differentiable or twice differentiable functions.",
            "And then we also have the geometrical interpretation in terms of the epigraph."
        ],
        [
            "So in applications it's very important or useful to be able to recognize convex functions.",
            "And that's not always straightforward.",
            "So of course we can always verify the definition, but that's not always the easiest method, as we'll see, we can try to prove that the Hessian matrix is positive semidefinite, but that can also be quite painful.",
            "And then there also exists a large number of.",
            "Operations or calculus rules that are known to preserve convexity.",
            "So often.",
            "The easiest way is to recognize a convex function is to recognize that it's composed or obtained from a number of more basic convex functions via a number of simple operations.",
            "So we'll go through this list."
        ],
        [
            "So first is obvious if a function is convex then non negative multiple is convex or the sum of two convex functions is convex.",
            "Also, if you replace the argument of F by linear or an affine mapping, then the resulting function is convex, so the composition of F with an affine mapping is convex.",
            "So for example, that allows us to conclude that this function is convex.",
            "That's will be useful as a log rhythmic barrier function for linear inequalities, so we know that miners log is convex.",
            "If you replace the argument with a linear and affine function, we get a convex function of X and then the sum of convex functions is convex.",
            "So you don't need to take the Hessian of this function to decide that it's, or conclude that it's convex.",
            "Also, we've seen that norms are convex functions, so any function of this form is automatically convex.",
            "The norm of X + B is always a convex function for any kind of normal."
        ],
        [
            "So this one is less obvious, maybe.",
            "So if you have M convex functions, if one through FM.",
            "And then you take the pointwise maximum of each of these functions.",
            "So for each X you sign to F of X.",
            "The maximum of those values F of X. Geometrically, that just means that you take the intersection of the epigraphs of those in functions.",
            "The intersection of these epigraphs of these functions will be the epigraph of F. So this is the counterpart for functions of this intersection property for convex sets.",
            "So that's always convex.",
            "And that's very useful, because many convex functions arise as the maximum of a number of functions.",
            "For example, suppose we define a function as a sum function of an in vector X.",
            "As the sum of the our largest components of X.",
            "If you do notice like this.",
            "So it's very easy to compute.",
            "You take the vector X, you sort the coefficients in decreasing order, and then you add the first R coefficients.",
            "Now that's a convex function of X.",
            "And that's not immediately obvious, but you can just writing F in this way.",
            "So what we do here is we write it as a maximum of a very large number of finite number of linear functions of X.",
            "So for each linear function here we take a group of R components of X, an Adam.",
            "And if you take the maximum of this over all possible sets of our components out of in, then you get the same function F of X.",
            "So it's a maximum of.",
            "In this case a very large number of linear functions of X.",
            "So therefore it's convex, so this is not a practical way to compute this function F. It's much easier to sort and then take the maximum.",
            "The first or entries, but it shows that it's convex.",
            "So here we take a maximum of a finite number of discrete or a finite man."
        ],
        [
            "Functions there is an extension of this two sets that can be infinite.",
            "So here we suppose we have a function F of X&Y two parameters XY.",
            "And we know it's convex in the first variable.",
            "If the second variable is given so for fixed Y, it's convex in X.",
            "And there's no condition how it depends on the second variable Y.",
            "And effect why can be an integer or the constraint to be integer?",
            "Or can be a vector or matrix, it doesn't matter.",
            "And then you take the maximum of this function to evaluate this new function G of X.",
            "You take the maximum of F of X&Y over all possible Y.",
            "In some sense A and.",
            "Again there is no restriction on what is doesn't have to be convex or connected, or.",
            "There's no condition on a.",
            "Well, that's always convex in X resulting function, so the previous example is where Y is just.",
            "The index will be, Y is an integer, and the set A is a set of integers from one to M. And I use here in these notes we use the supremum if user maximum for the maximum over a finite set and the supremum over a set that could be infinite.",
            "So that's the definition of that if you like and just replace it by Max.",
            "Just keep in mind that it can be a doesn't have to be a finite set.",
            "So a very good example of this is the maximum eigenvalue of a symmetric matrix.",
            "Which is a convex function of X.",
            "And that's easy to see.",
            "So very short proof is this, so you know, from linear algebra that the maximum eigenvalue can be expressed like this.",
            "It's the maximum.",
            "Of Y transpose XY.",
            "If you take the maximum overall vectors, why with unit norm?",
            "So in this case, this is the set a the unit sphere.",
            "And this is the function F of X&Y, so for fixed Y it's clear that's a linear function of X.",
            "If you expand these products, you get a linear function of all the entries in X, so for fixed why this is a linear or therefore also convex function of X.",
            "So then we know from this property if you take the maximum of these functions over any set Y, you get automatically a convex function of X.",
            "And you can easily think of some other equivalent definitions of the maximum eigenvalue for which it's not immediately obvious that it's convex.",
            "For example, if you think of it as the largest root of the characteristic polynomial.",
            "Then it's not clear at all that if you change the entries in the Matrix X, that largest root is in a convex function of the entries.",
            "It's actually very complicated.",
            "A function."
        ],
        [
            "So that's a maximization rule.",
            "So here we have a function of two variables X&Y.",
            "We maximize over the 2nd and the condition was that the function had to be convex in the first variable X for a given why?",
            "There is something that looks very similar and refers to minimization.",
            "Or the infimum?",
            "So here again, we take a function of two variables XY, an.",
            "Under some conditions you can conclude at a minimum over why gives you a convex function of X.",
            "So it's very similar to this maximization rule on the previous page.",
            "But the conditions are much more restrictive, so here the conditions are that F has to be jointly convex in X or Y, not just convex in X forgiven Y, but has to be jointly convex.",
            "In X&Y, as variable, and also if there are constraints in the optimization, has to be constraints over a convex set C. But if that's the case, then we can conclude that.",
            "Sorry H is convex.",
            "So again, there are some simple, useful examples.",
            "Suppose you take the distance to a convex set C. In any norm that's always a convex function of X.",
            "Because the distance computed like this, it's the minimum distance from X to any point in C. We've seen that norms are always convex, so the norm of X -- Y is jointly convex in X&Y.",
            "C is a convex set, so if you take the minimum distance, you get a convex function of the remaining variable X.",
            "And that's true for any norm, but only for convex sets.",
            "Another one that's very useful in optimization is as follows.",
            "So suppose we take a linear programming problem in YS variable.",
            "So I take minimize C, transpose Y with constraints that AY is less than X, so X is just the right hand side and inequalities.",
            "And then they define as the function H the OR assign assigned to H the optimal value of this linear programming problem.",
            "As a function of the right hand side X.",
            "So to evaluate this function in general, you would have to at a certain X you'd have to pick X and solve this LP and Y, and then the optimal value is the function value at X.",
            "So there's no closed form expression of this H of X, But you can compute it by solving an LP with excess right hand side.",
            "But one useful property that's important in optimization is that if you define a function like this.",
            "Then this is a convex function of X, so the optimal value of a linear programming problem is a convex function of its right hand sides in the constraints.",
            "And it follows from the same rule.",
            "So in this case we define F of XY as a function that has this as its domain, so it's only defied defined for pairs X&Y that satisfied that satisfy this inequality's.",
            "And outside the domain we can give it a value plus Infinity.",
            "And then on its domain, when X or Y satisfy this inequality, we define it as the transpose Y.",
            "So if you do that, you get a function that's jointly convex in X&Y because its domain is convex in X&Y, is just a set of linear inequalities.",
            "And on its domain, it obviously satisfies Jensen's inequality, right?",
            "So that's a convex function of jointly in XY and therefore and its minimum over Y is equal to H of X, so therefore ages can fix.",
            "So this is true for LP's but also of course from any other.",
            "Convex problems the optimal value as a function of the right hand side is convex in general.",
            "H is a function of X, so I define a function of X.",
            "And the value at X is the optimal value of this LP, right?",
            "So I fix X.",
            "And then solve this linear program with wires variable.",
            "And then the optimal value is the function value of HX, so the it's interesting because it's.",
            "The function is how the optimal value changes with changes in the right hand side, so it rises in sensitivity analysis and so on."
        ],
        [
            "Um?",
            "Then we have a few more.",
            "So an obvious question is what about composition?",
            "If I have a composition of H&G of X and the road condition is that convex?",
            "Well, there are some useful rules.",
            "For example, if H is convex and increasing or nondecreasing and GS convex, then you can conclude that F is convex.",
            "For example, X, the exponential of a convex function is automatically convex.",
            "'cause in this case G is convex and exponential is a convex increasing function.",
            "All 1 / G of X is convex.",
            "If GS concave and positive and so on, there is only one thing you have to be careful with in these composition rules.",
            "When we say non decreasing and increasing, you have to add a function.",
            "H is not defined everywhere, so it has a domain.",
            "Then outside its domain you have to assign it value plus Infinity.",
            "And then examine whether it's not increasing and decreasing.",
            "For example, the logarithm of X would not count as an increasing function in this composition rules, because for negative X you sign it plus Infinity and then over the entire real axis you don't get increasing function.",
            "So that's the convention."
        ],
        [
            "And of course, you can also look at.",
            "Functions age with more than one variable and then we have similar theorems.",
            "For example, we've seen that the log of the sum of exponentials as a convex function.",
            "It's also clearly increasing in each of its variables, so you have a log of the sum of the exponentials of the components of a vector.",
            "Then if you change increased one of the components, the function value can only increase.",
            "So if I now replace or substitute the components of this lock, some X function with a convex function GI, then I get a convex function.",
            "Complicated convex function of X and it follows from this one of these theorems.",
            "Clear."
        ],
        [
            "So the last one is.",
            "Interesting, it's maybe the.",
            "It's another construction or another common way in which context functions arise.",
            "Suppose I have a function F of variables X.",
            "And then I construct a new function G with X and new variable scalar variable T as variable.",
            "And to construct GI take, if I substitute its argument with X / T. And then I multiplied the entire thing with T. And I also restrict T to be positive.",
            "Well, with this restriction, G is automatically convex.",
            "And that's sometimes called the perspective of the function if.",
            "So one example is this function that we encountered in the beginning.",
            "If you take X transpose X / T. As a function of XNT, but restricted to positive T, then that's a convex function because it's the perspective of just expose X right.",
            "You obtain the perspective by replacing X with X / T and then multiplying the entire function with T. If you do that, you get access projects over T. Another interesting one.",
            "This is this.",
            "If you take minus log X and replace X with X / T and then multiply with T, you get the relative entropy T log T -- 0 X.",
            "So this property tells us that this function is convex jointly and XNT, and that's not immediately obvious.",
            "Of course, it's only two variables, but it's not immediately obvious because T log T is known to be convex.",
            "But then he also a subtract something something with no interesting convexity properties from it.",
            "TNX but jointly in T An X the result is convex.",
            "So those are the most important of these operations that will."
        ],
        [
            "Encounter and the last one is the definition that will be needed in duality.",
            "Actually lecture the third lecture.",
            "So for every convex function, if you can define a conjugate function F star.",
            "And it's defined like this, so I take.",
            "F of X subtracted from Y, transpose X, and then I maximize over X.",
            "And then the result will be a new function of the vector Y.",
            "So we take what the elevator conjugate at?",
            "Why or define the function conjugate?",
            "That why you take Y transpose X, subtract F of X, and then maximize over X?",
            "So, and there's a nice graphical construction.",
            "So for example, if F of X was like this, and it's unfortunately very clear.",
            "So if this is a non convex function X then you can interpret this graphically as so the XY.",
            "Is a linear function of X with slope Y.",
            "Then the function value at F star of Y is actually can read it off on the vertical axis.",
            "If you shift this linear function with slope Y until as far as possible down until it just touches the graph of the function, then then this distance here is the negative of start of Y.",
            "But it will be important in duality.",
            "And so from the definition and the properties we've seen, it's clear that this is a convex function of Y.",
            "Even if F of X is not convex.",
            "Because we can apply this maximization rule.",
            "We take the supremum over a family of functions that depend on X&Y.",
            "This is convex and Y for fixed X.",
            "The argument of the maximum.",
            "So if I maximize over XI, automatically get a convex function of the remaining variable Y.",
            "So you don't need convexity of F to conclude that F star is convex.",
            "But in practice, you're mostly interested in cases where F is convex and storage convex, so that's called a conjugate an.",
            "It's in some ways similar to three transforms.",
            "For example in signal processing.",
            "So we have pairs of functions and their conjugates.",
            "Same as you have pairs of functions and their Fourier transforms, and some operations are easier when you do them in terms of conjugates and in terms of the function itself.",
            "But you see this."
        ],
        [
            "In the last lecture.",
            "So these are some interesting examples.",
            "Or some examples that we'll encounter later.",
            "So if you take apply the conjugate to a quadratic function with positive definite quadratic function Q, you get a quadratic function, but but Q is replaced with Q inverse.",
            "Fewer the entropy or the negative entropy.",
            "Is an exponential sum of exponentials the conjugates?",
            "If you take a norm any norm, then the conjugates of F is the indicator function of the unit ball for the dual norm of F. So by indicated function I mean a function that's defined as zero.",
            "If you're in this set and plus Infinity otherwise, let's call the indicator function of the set.",
            "So the conjugate of the norm is 0 if Y has a dual normal isn't one, and it's pleasant finity outside.",
            "So if this is the one norm, for example, then this is the Infinity norm.",
            "That's the P norm that is secure norm.",
            "It's one over Peoples 1 / Q is 1 and so on.",
            "Um?",
            "And another one that would be useful tomorrow is the general the indicator function of a convex set C. So if I define a function FS0 on the set C plus Infinity outside, then that's a convex function because it's."
        ],
        [
            "Domain is C and on its domain it's just constant 0."
        ],
        [
            "And its conjugate is defined like this.",
            "It's called the support function of the set C. So it's the maximum of the value at Y is the maximum.",
            "Why transpose X value maximized oversee?",
            "But will counter this tomorrow."
        ],
        [
            "So that's the first section on some basic definitions and properties of convex sets and functions.",
            "Any questions?",
            "Yes.",
            "Function.",
            "Quadratic over linear or.",
            "In general, the numerator has to be linear and positive, and the quadratic function has to be convex.",
            "And then if you restrict the linear function to be positive, you get.",
            "You can apply this."
        ],
        [
            "Um?",
            "This year, if you now replace X&T by linear functions, you get still have a convex function."
        ],
        [
            "So then the second part of this lecture is look at convex optimization problems will go through important classes of problems small as chronologically.",
            "So we start with linear programming and then quadratic programming and.",
            "Finish with the most recent classes, semidefinite programming and 2nd order cone program."
        ],
        [
            "So first convex optimization problem is defined like this, so we take the general nonlinear form, but we restrict all the nonlinear functions in the objective and inequality constraints to be convex.",
            "And the equality constraints must be linear, otherwise it's not a convex problem.",
            "And then it's easy to see that the feasible set is a convex set.",
            "And that if you have a point that's locally optimal, it's automatically globally optimal."
        ],
        [
            "So the first example of course is linear programming.",
            "So and in your programming everything is just linear.",
            "The feasible set is a polyhedron.",
            "It's the intersection of finitely many inequalities.",
            "And, um.",
            "It has some interesting special properties that are not true in general for general convex problems.",
            "So for example, the optimal value is always at the boundary of the feasible set.",
            "An in general, actually, there's usually at a vertex of the feasible set, right?",
            "And SC is exactly perpendicular to this and then this entire edge would be optimal.",
            "But in general you can always restrict yourself to looking for optimal solutions among the verticies, and that's of course the basis of the simplex or the basic idea in the simplex method."
        ],
        [
            "So what are some general convex problems that can be reduced to linear programming so one?",
            "General One is piecewise linear functions which I have taken a set of linear functions of X.",
            "And I take so M of them, and I take the pointwise maximum over them.",
            "Then we already know from the first section that that's a convex function of F. So if you're just trying to show that it's convex, or see that it's convex, or you have to say as well, that's the maximum of a set of pointwise maximum of a number of convex functions of X.",
            "But if you're also looking for a method for solving this.",
            "Then this is not that simple because it's also very non differentiable function.",
            "And.",
            "So if you look at the Hessian, for example in the points where it's differentiable, the Hessian is just zero, so it's not easy to solve using Newton's method or a gradient method and so on, but it's easily solved as an LP, so you write this as a linear programming problem.",
            "We introduce new variable T and then add an inequality.",
            "For each of these components, in the maximum that says that a transpose X + B ISN T. And we optimize this linear program over T&X jointly.",
            "It's an LP because everything is linear in T. The objective and constraints are all linear auntie.",
            "And then it's also difficult to see that if I minimize over T&X jointly, that's equivalent to solving this problem.",
            "And to see that it can just assume that suppose X is fixed in this problem.",
            "It's not a variable, but you only minimize over T. So if you minimize the subject to these mloa rounds on T, then obviously the optimal value of T will be this value.",
            "The maximum of those lower bounds.",
            "So that's if you fix X and optimize over T and then if you minimize jointly over X&T then the optimal solution will be the value of X that minimizes this and T will be equal maximum.",
            "So it's equivalent to this, and this gives you a practical way of solving this piecewise linear.",
            "Optimization problem."
        ],
        [
            "So an application of this are the one or more Infinity norm minimization problems.",
            "So suppose I want to minimize the one norm or the Infinity norm of function X -- B.",
            "So these are, we know already that these are convex functions of X.",
            "Because norms are convex.",
            "And, uh.",
            "You can solve them in practice using linear programming and argument, or the reasoning is very similar.",
            "For example, if you look at the one norm, you would introduce a number of variables Y, one for each row, and AX minus B.",
            "Introduce linear inequalities, upper lower bounds on X -- B and then you minimize the sum of the wise subject to these inequalities.",
            "And again, it's easy to see that these are equivalent.",
            "So assume again that X is fixed, so X -- B is just a given vector.",
            "And then I minimize over Y.",
            "So that's a separate optimization problem.",
            "You can minimize over every component of Y separately.",
            "For each component, why I there are two lower bounds?",
            "There's a lower bounce, why I is greater than the right component of this and greater than the negative of this which created in the absolute value?",
            "Of the right component of X -- B.",
            "So the optimal value for YYI is the absolute value of that component of X -- B, so that's if you fix X.",
            "If you fix X, each component of I will be the absolute value of the corresponding component of X -- B.",
            "So the value that some of those will be the one norm of X of X -- B.",
            "And then if you minimize over X&Y jointly by solving this LP in X&Y, you minimize the one node.",
            "And for the Infinity Norm you have a similar story, except that instead of EM.",
            "Variables you only have one extra variable Y, and then you instead of a vector Y here have Y times vector of all ones, so impose the same upper bound on each of the inequality's and that will minimize the maximum of the absolute values of X -- B.",
            "So this is of course very useful."
        ],
        [
            "And it's also useful to look at the distributions you get by normal approximation with different norms.",
            "So here I just take a random matrix A of size 200 by 80.",
            "I minimize the just the two norm, the squares problem and the one norm of X -- B.",
            "And this is the distribution of the residual.",
            "The 200 residuals in the vector X -- B at those two solutions for the two norm and for the $1.",
            "And the green grass, of course, are the penalty functions you impose on each residual for the two norm, you have a quadratic penalty function for the one norm, it's the absolute value.",
            "So then you see that, roughly speaking, these two problems, of course do the same.",
            "They try to write B as a linear combination of the columns of a.",
            "So roughly speaking, they try to do the same thing, but the distributions you obtain are very different.",
            "And there are actually two important differences that are useful.",
            "So one is, you notice that the of course the High Peak at zero if you use the one norm.",
            "And that's explained by the fact that the absolute value has this breakpoint or this breakpoint at one at zero, whereas the two norm minimizes the quadratic penalty function, which is flat at the origin.",
            "So there's no benefit here.",
            "If you choose X and moving it from something close to 0 to exactly 0, whereas if user one norm actually keep getting a benefit by making it moving it all the way to 0.",
            "So that's an important difference, and the second difference is actually for large residuals, so you see here that the distribution is also much in this case not much, but it's wider than the two norm distribution, so there's some large residuals that are larger than the largest residuals for the two norm.",
            "So it's a wider distribution and you have this High Peak at the origin.",
            "So these two features are both useful, so the first one that is of course used in sparse optimization heuristics.",
            "If you want a regularization term that encourages sparsity in the vector X.",
            "Then the one norm is much more useful than the two norm.",
            "So in this application, of course it's not surprising that if you have a D variables and randomly generated a that you can make 80 of the residuals exactly 0.",
            "It's not very difficult, but you might.",
            "You could imagine an application where B is actually equal to X.",
            "And then an unknown number of values of B were corrupted by noise.",
            "And then you would like to find a solution X that satisfies many of the equations exactly with 0 error.",
            "Then this will be much more useful than the two norm, but it won't give you exactly the solution with maximum number of equations that are satisfied exactly.",
            "It won't give you the sparsest vector of residuals, but it will give you typically a very sparse vector.",
            "So the behavior at the origin is actually very useful for sparse optimization.",
            "The.",
            "The fact that it's a wider distribution is useful in robust regression.",
            "And of course, the fact that it's wider comes from the fact that the absolute value penalty increases much more slowly for large values of residual standard quadratic penalty.",
            "So there's a smaller, relatively smaller penalty on very large residuals than for the quadratic penalty.",
            "This is the.",
            "No, no, it's a fixed matrix.",
            "I selected the Matrix a.",
            "And vector B.",
            "Then I solve these two problems and obtain two solutions X right the least squares solution and one solution.",
            "And then this is the distribution of the residuals in the vector X -- B.",
            "So X -- B is a vector of length two, hundreds have 200 errors in those 200 equations, and this is."
        ],
        [
            "Distribution around."
        ],
        [
            "0.",
            "Sorry.",
            "So, roughly speaking, you would like to minimize the norm of the vector in order to make all the residuals as small as possible.",
            "But you have 200 visuals.",
            "That you minimize by single scalar objective and you see that the distribution of the residuals for the two solutions X is actually very different and depending on your application you might prefer one or the other norms because of this difference in distributions.",
            "Yeah, so this has a large number of zeros.",
            "Typically the one norm will encourage sparsity.",
            "In this case, in the vector X -- B and a second important difference is that it's much wider distribution.",
            "Then the tuner.",
            "And."
        ],
        [
            "Second property is used in robust regression.",
            "You've probably seen this.",
            "Suppose you want to fit a straight line through points, but there are some outliers.",
            "There's a point here and here.",
            "Then the two norm which is in dashed line will be rotated towards these outliers.",
            "Whereas if you minimize the one norm, you minimize the sum of the absolute values of the differences between the points in the line.",
            "Then you get something that almost ignores these two outliers and gives us this straight approximation, so that uses the fact that the one norm is much more robust against or can tolerate a few large errors."
        ],
        [
            "So I think you're all familiar with linear discrimination and support vector machines, so of course that's a very nice application of linear programming.",
            "Suppose you have two sets of points, Zion, why I, and you try to find a hyperplane that strictly separates the two.",
            "Then you can write that as a set of linear inequalities.",
            "So you have strict separation.",
            "The variables are A&B, so the normal vector of the hyperplane and the offset.",
            "But because it's homogeneous, you can replace the right hand side by one and then use a non strict inequality.",
            "And you can write it like this."
        ],
        [
            "If the points are not separable.",
            "You can.",
            "Try to find an hyperplane that approximately separates the two points by minimizing this kind of penalty.",
            "It's an piecewise linear function of the variables A&B.",
            "And.",
            "So for each point XI or why I have a penalty of 0 if the point is on the right side of the hyperplane and otherwise you have a penalty that's proportional to the.",
            "The difference to the hyperplane so we can."
        ],
        [
            "Interpreters in non symmetric version of this.",
            "So here you have a penalty on the residuals if you use the absolute value that's symmetric.",
            "So suppose you actually wanted to minimize the Max, minimize the number of maximize the number of zeros in the vector.",
            "So you really want to minimize the cardinality of this vector.",
            "Then the ideal penalty function will be 0 at the origin and one for non zero values.",
            "And then the sum of those penalty functions will be the number of non zero components.",
            "But of course that's very non convex, so you can interpret this one norm as a convex approximation or replacement of this very minimize this.",
            "Wander.",
            "So in the classification problem we have something that's actually similar but non symmetric.",
            "So in that case you want to minimize the slack between the."
        ],
        [
            "Hyperplane and the points if it's positive.",
            "But they only care about the slack if it's positive.",
            "If it's negative, you have a penalty.",
            "So if you do this, you would use and."
        ],
        [
            "Penalty function that looks like this that's zero for negative values and then linear and then you get.",
            "Sorry."
        ],
        [
            "Exactly this so you can think of this also as a heuristic.",
            "Similar to this one.",
            "Regularization terms and sparse optimization values.",
            "This penalty function as a heuristic for minimizing the number of misclassified points.",
            "Exactly."
        ],
        [
            "OK, so this these were some examples for linear programming.",
            "Then the next class is quadratic programming, so in a quadratic programming problem you have, we keep the constraints linear and we have a quadratic convex cost function.",
            "So then the control lines are ellipsoids.",
            "It's no longer true that the optimum is necessarily at the boundary, or at an extreme point.",
            "It could be the interior of the polyhedron.",
            "It is still a convex problem."
        ],
        [
            "One of the oldest applications of quadratic programming is actually the what today people would call a robust optimization problem.",
            "And it's a linear programming problem with uncertain cost function.",
            "And this application of this was the famous markovits portfolio optimization problem.",
            "So the problem is that suppose you have an LP with coefficients CG&H.",
            "But we assume C is not exactly known.",
            "20 investment problem.",
            "You would minimize or maximize.",
            "In that case the return and X would be your portfolio investment or the different investments.",
            "C transpose X would be the return and the coefficient of C would be the return on your investment for different investments.",
            "But of course in that case the invest the returns are not exactly known.",
            "And then one way to incorporate that in your optimization model is as follows.",
            "You assume that C is a random variable.",
            "And it was just assume that has a certain mean that's known and a covariance matrix that's known, but we don't assume anything about the distribution.",
            "For simplicity, we'll assume that G&H is given, so these are exactly known.",
            "And then of course, your optimal value becomes a random variable C transpose XX is deterministic, but C is a random variable and you have to decide what you mean by optimizing this random variable.",
            "So one common definition is to minimize the weighted sum of the expected value.",
            "Of your system, suppose X and then the variance of this random variable.",
            "Random variable C, transpose X.",
            "And then you can play with this coefficient, to give different weights to these two terms.",
            "So in your investments application this would be the expected return.",
            "If you want to maximize it at least or expected losses, and this would be a measure for the risk in your portfolio.",
            "So in this case I mean these assumption, the expected return is linear in X, the variance is a quadratic functions.",
            "We get a quadratic programming problem.",
            "So in the 1950s, this was one of the first applications that motivated the development of quadratic programming."
        ],
        [
            "You're also familiar with, again, the support vector classifiers.",
            "As a general solved by quadratic programming, so suppose I have two hyperplanes defined like this in the normal vectors A&B.",
            "Then it's easy to calculate the distance between these two hyperplanes and it turns out to be inversely proportional to the norm of the vector A.",
            "In other words, if you normalize a, the distance between these two hyperplanes is just two.",
            "And then if you have these two sets of points and assume that they are separable, then he can maximize the margin between these two hyperplanes by minimizing maximizing the distance or minimizing the norm of A and that's a quadratic programming problem, because it has a quadratic objective and linear coefficients in linear inequalities on A&B."
        ],
        [
            "And then you can combine this with the previous formulation where you allow points to be on the wrong side of the hyperplanes, and then you have this familiar tradeoff between the.",
            "Inverse of the.",
            "The margin of the two hyperplanes and then the classification error."
        ],
        [
            "Another example of quadratic programming.",
            "Suppose."
        ],
        [
            "I have a vector X that represents a signal, so here a corrupted signal.",
            "Of time, for example.",
            "And I would like to smooth this signals.",
            "I'd like to get the smooth smooth signal, but also preserve the edges in the signal."
        ],
        [
            "So you can do that by formulating an optimization problem, so X the corrupted signal is given.",
            "Extract is the estimate of our smooth or reconstructed signal.",
            "So we have a first objective that gives the distance between the reconstructed and the given signal.",
            "And then I add a penalty function that.",
            "In order to make the estimated X smooth, so penalty on variations of X hat.",
            "Right?",
            "And we can look at two penalty functions.",
            "One is just to take the sum of the squares of successive values of XI.",
            "Or I can take the sum of the absolute values of successive values of XI.",
            "And then two cases I get a convex problem.",
            "In the first case it's a simple quadratic problem in the variable, except in the second case it's has a quadratic term and then a sum of absolute values."
        ],
        [
            "But the solutions look quite different, so if you use a quadratic penalty function, you see that the results this singular smooth it, but the edges are also.",
            "A smooth it.",
            "There is a few."
        ],
        [
            "The total variation or the one norm penalty function."
        ],
        [
            "Then the sharp edges are preserved.",
            "And that's very useful in image reconstruction, for example.",
            "And that's obvious or clear why this happens."
        ],
        [
            "Again, you think of the differences between these two penalties.",
            "And those distributions of the residuals in a simple normal approximation.",
            "So in this case you could think of a solution.",
            "X and then plot the distribution of these differences I + 1 minus XI for the two solutions to quadratic and the total variation norm.",
            "And then you see, because this is really the one norm of those differences, that this penalty function will be more robust against a few large values of the differences.",
            "In the same way as robust regression is robust against outliers.",
            "So in this case those sharp edges will be a few outliers or a few values of these differences that are much larger than the rest and the one norm actually will.",
            "Told."
        ],
        [
            "Rates a few more of those large edges."
        ],
        [
            "Then the do not.",
            "So again, it is application of the difference in these two penalty functions, but in this case it's an application of the difference for large values of X, the same as the robust regression application."
        ],
        [
            "So maybe I can skip geometric programming, so geometrical programming is an actual class of problems that are very non convex.",
            "They find like this supposed to have a functional problem like this with inequality is an objective function that all have this.",
            "Of products of variables X Rays to some powers Alpha I.",
            "And there is no restriction on what these powers are.",
            "They can be positive, negative.",
            "They don't have to be integer.",
            "So it's certainly not a polynomial function.",
            "But we do restrict X to be positive.",
            "And you know, people have given that a name polynomial because it looks a little bit like a polynomial.",
            "But the important differences are the exponents can be don't have to be integers or positive, or it can be any real number, but restrict the access to be positive.",
            "And then if you have a problem like this with opposing normal objective and posing your constraints, you call it a geometric programming problem.",
            "So it's obviously not convex in X, because these are very anomalous functions, but there's a simple trick that makes it convex.",
            "So if I make a change of variables at call log of XA new variable Y."
        ],
        [
            "Or equivalently, I."
        ],
        [
            "Replace X with an expansion of a new variable Yi.",
            "Then I get."
        ],
        [
            "This problem."
        ],
        [
            "Right, so each XI is."
        ],
        [
            "Replaced by the exponential of Yi, then the product of these exponentials becomes an exponential for some.",
            "And I get a convex problem because we've seen that these functions are all convex."
        ],
        [
            "Then the so next class of problems is called the 2nd order cone programming problem.",
            "So it's defined like this.",
            "We have a linear objective as in linear programming, but I know you have constraints of this form and each constraint is a constraint on the Euclidean norm of some linear function of X, and then we also include linear terms, so it's clearly includes linear programming as a special case, because if these AI and BI.",
            "Coefficients have dimension 0, then this is just a linear inequality.",
            "But it's it's also convex because norms are convex, so this is a convex constraint on X.",
            "And it's called the 2nd order."
        ],
        [
            "Horn problem."
        ],
        [
            "Reasons that we actually will see tomorrow.",
            "That are not very important here, so this is a very basic definition.",
            "So."
        ],
        [
            "So you can interpret."
        ],
        [
            "This as a robust linear program."
        ],
        [
            "Problem.",
            "And by robust linear programming problem I mean the following.",
            "Suppose I take an LP with coefficient cost function C, transpose X and then M inequality is a transpose X -- B I.",
            "And then in the robust optimization, people are interested in.",
            "Incorporating in the definition or the model for the optimization problem, uncertainty in the coefficients of the data.",
            "So in an LP, the factor cost effective C could be uncertain.",
            "The coefficients A or BI could be uncertain.",
            "And then if you simply ignored the uncertainty in the data and optimize, assuming that those are the exact values.",
            "Then the unfortunately solution X can be sometimes very sensitive to small changes in the coefficients.",
            "And that's true in general, but certainly for optimization, because the solution typically lies on the boundary of the feasible set.",
            "So small changes in the coefficient can make your X feasible optimal X infeasible.",
            "And that's if you like an extreme form of sensitivity, so it's often important to incorporate in your model some measure for the OR some other for the uncertainty in the data.",
            "And then.",
            "One way to do this in linear programming is to do this.",
            "Suppose so here for simplicity.",
            "Assume that the AI's are random.",
            "So BINC are given.",
            "I'll assume some distribution AI in this case that it's normal.",
            "And with a certain given mean, the nominal value of AI and a given covariance.",
            "And then in self saying 8 transpose X doesn't be I. I require that X satisfies that inequality with at least a certain probability, for example 90%.",
            "So that's called a chance constrained in stochastic optimization.",
            "In general, stance constraints are actually very difficult constraints, But in this simple case it's actually something you can easily.",
            "Incorporate and solve as a second order cone problem.",
            "And this is an example for some values, so have an LP.",
            "And this is also the nominal value of our LP.",
            "So if I now assume that the normal vectors of each of these inequalities is a random vector.",
            "With a symmetric distribution normal distribution.",
            "Then and I have a point X that somewhere on the hyperplane.",
            "For example this hyperplane.",
            "And for the normal value or the mean of the normal vector AI?",
            "Then that vector will also in 50% of the cases with 50% probability, will still be feasible.",
            "Even if I.",
            "If a fair reason this distribution.",
            "So if you require this with 50% probability.",
            "The Robust's or the solution set for this feasible set for this M chance constraints is still the original normal value.",
            "But if you take a different value to 50%, it's very different.",
            "So if I require that the inequality is satisfied with the probability 90%.",
            "Then these lines become curved, so this instead of a hyperplane.",
            "Now I have this curve.",
            "Which is actually the level curve where the probability of satisfying that inequality is exactly 90%.",
            "And.",
            "So you have one of these for each of the inequalities and the feasible set shrinks to something that's smaller and convex.",
            "So that's the feasible set for these M chance constraints in equalities.",
            "If it is 90%.",
            "If it is less than 50%, it's actually the other way around.",
            "The we get a larger feasible set.",
            "And these level curves of constant probability curve and the other have the other orientation.",
            "And then the solution set becomes non convex.",
            "And this problem becomes very difficult because if you have a solution set like this, even if the curvature is not very pronounced, then you can easily have any minimize the linear function over this set.",
            "Then you can easily have multiple local minima that are not global.",
            "So we see something interesting here that if you have these chance constraint problems.",
            "If it is greater than 50%, we have a convex feasible set.",
            "If it's less than 50%, it's not convex.",
            "So what we can actually in this case, if we assume that they are normal and we know the mean and the covariance, we can actually calculate this probability from.",
            "Probability theory and you can write this."
        ],
        [
            "Constraint in this form so you have the nominal value of the inequality.",
            "That's a high bar and then this extra term involves the cumulative density function of the Gaussian.",
            "This function 5 teeth between zero and one.",
            "And then that's multiplied with the two norm of the square root of the covariance times X.",
            "So this tells us actually this makes sense because it tells us that if Atom is largest closed in 90%.",
            "Then, in order to make X feasible without high probability.",
            "It's not sufficient to satisfy the inequality for the nominal value of AI, but has to satisfy it with a certain slack or a certain margin.",
            "That depends on the value of the margin required.",
            "Margin depends on the value of data.",
            "And on the covariances, and actually more precisely the product between X and the covariance.",
            "And this also explains why you have this transition between editor at 50%, because this coefficient here the universe of Etta, under this cumulative density function changes sign for 50% of ETA is creating a 50%, and that's a positive coefficient.",
            "We get a convex constraint because we have normal to positive coefficients on the less than or equal side of the inequality.",
            "If data is less than 50%, then this coefficient becomes negative & is wrong.",
            "We have the negative term on the wrong side of the inequality.",
            "So that's the stochastic formulation of the."
        ],
        [
            "Robust LP we can actually."
        ],
        [
            "Give deterministic interpretation to exactly."
        ],
        [
            "The same problem.",
            "So in a distant Mystic interpretation.",
            "We make we don't make any assumptions on the distribution of AI.",
            "But we impose a certain set of allowed allowable values of AI.",
            "So in this case, would assume that the eyes are unknown, but are known to be in a certain ellipsoids with the center AI bar and a certain shape that is determined by this matrix P. And then the robust version of this inequality will be that we require that X is feasible for all values of AI.",
            "Actually you can.",
            "Well so if you work this out, so in order to write this more explicitly, you would have to find a maximum of AI, transpose X for a given X over this ellipsoid, and then you find an expression that exactly similar to this previous one.",
            "So this inequality is satisfied for all values of AI in the ellipsoid if X satisfies this second order cone constraint.",
            "So again, the first term is just a nominal value says that X satisfies it for the central point of the ellipsoid, and then we have Euclidean norm term that involves the product of X&PI transpose."
        ],
        [
            "So mathematically, it's exactly similar to this constraint."
        ],
        [
            "But with a different interpretation.",
            "Right and kind of see that in the robust version of the LP.",
            "It's not sufficient for X to be feasible for the normal value of a. I add an extra margin and the value of that margin actually depends on the size of X, and more precisely the product of X NPI.",
            "Sexier.",
            "So those are two examples of robust optimization problems.",
            "We see that robust LP turns into a second order cone problem."
        ],
        [
            "Then there are some other examples of nonlinear constraints you can write as second order cone constraints.",
            "So this one will be as interesting if you have excess pose X for a vector X.",
            "Is less than or equal than a product of Y&Z?",
            "And Y&Z are restricted to be non negative, so that's not an ellipse ellipsoid.",
            "It's called out in hyperbolic constraints, so this is a quadratic inequality, but the Hessian of the inequality has is not positive definite.",
            "But because of this restriction, it's still a convex set and you can write as a second order constrained by this equivalence you have a two norm of this two vector.",
            "That of this not two vector but this vector.",
            "Involves the vector X and then the scalar y -- Z Y plus Z on the right hand side.",
            "So that's the 2nd order cone constraint, and it's equivalent to this."
        ],
        [
            "Some other non obvious constraints that can be written as second order constraints are powers, constraints on powers of X.",
            "So for example, if you have X to the 1.5 less than T. With a variable tiannan, unlike the variable X, then you can actually write it as a second order cone constraint, and that's not obvious.",
            "But this is a short proof.",
            "And that's actually true for any rational power of XX to the P. For any rational P can be written as a.",
            "2nd order cone constraints.",
            "And it's also true for negative powers.",
            "For example, X 2 -- 3 can be written as a second order cone constraint, and again that's true for extra DP with a negative rational."
        ],
        [
            "OK, so then the last topic will be semidefinite programming.",
            "That's the most general of these problem classes that will discuss.",
            "So again, it's and we have a linear objective of some in vector variable.",
            "And the constraint has this form, so the matrices A&B are all symmetric of the same dimension.",
            "And the constraint is that this linear combination of the matrices A must be less than or equal to B as a matrix inequality, so B minus this left hand side must be positive semidefinite.",
            "After that means that you have as a constraint and symmetric matrix B -- A of X and all the entries of the matrix are linear in the variables X.",
            "And then the constraint is that that matrix must be positive semidefinite or negative semidefinite.",
            "That's called a semidefinite programming problem.",
            "And it's interesting because it includes many nonlinear constraints that special."
        ],
        [
            "This is so.",
            "This is a geometrical interpretation and just matrices of order 2.",
            "So that's the semidefinite cone of matrices of order two.",
            "So you have three elements in the matrix, and that's the cone of matrices."
        ],
        [
            "That are positive semidefinite.",
            "So so."
        ],
        [
            "Definite programming is useful because it turns out that if you take intersection of the semidefinite cone and high dimensions.",
            "With hyperplanes or affine sets in different directions, you can represent very wide variety of nonlinear convex constraints as intersections of the positive semidefinite cone with affine sets.",
            "Have you see some examples?"
        ],
        [
            "For example, if you want suppose you want to minimize the maximum eigenvalue of a symmetric matrix.",
            "You have a matrix A of X, it's symmetric.",
            "All the entries are linear in the variables X and then you want to maximize the maximum eigenvalue, minimize the maximum eigenvalue.",
            "So we've seen that's the convex function of X.",
            "You know, very short proof that that's convex.",
            "That doesn't tell us how to actually minimize it, but it can minimize it if you recognize it at its can be written as a semi definite programming problem.",
            "So here we do a trip trick that's very similar to the way we used in L1 norm and L Infinity normalization.",
            "We introduce a new variable T and then minimize the subject to this matrix inequality.",
            "That says that the Matrix A is less than three times an identity matrix.",
            "And that's equivalent to this, because this constraint is equivalent to saying that T is created on the maximum eigenvalue of a.",
            "So if I minimize the subject to this, it's the same as minimizing the maximum value.",
            "So I convert a very.",
            "A convex nondifferentiable optimization problem in X and the linear.",
            "Semidefinite optimization problem.",
            "Anne."
        ],
        [
            "Another example or matrix norm.",
            "Suppose now a is no longer doesn't have to be symmetric or square, but it's just a rectangular matrix.",
            "Then I can define the two norm maximum single value normal.",
            "We know it's convex because all norms are convex.",
            "Or another interesting norm is the sum of the singular values, which is known as the nuclear norm.",
            "And so both are convex, complicated non differentiable functions of X.",
            "But they can be minimized by solving an SDP, introducing new variables T and in this case U&V and then minimizing a linear function subject to a linear matrix inequality."
        ],
        [
            "Maybe can.",
            "Do this example and then finish.",
            "So semidefinite optimization is useful because many convex problems can be written as convex constraints can be converted into.",
            "Is the constraints.",
            "It's also often used in relaxations for difficult combinatorial problems.",
            "So a simple example would be this.",
            "Suppose I want to minimize the linear at least squares problem, but with constraints that variables X must be minus one of plus one.",
            "And I can write it as a simple quadratic equality constraint on X, so that's a very nonconvex problem.",
            "An in general for general A&B.",
            "It's also very difficult to solve because of this integer constraint.",
            "So we can use semidefinite programming to solve the relaxation of this problem to compute lower bounds on this problem.",
            "And also as a heuristic to find sub optimal solutions.",
            "And the reasoning is as follows.",
            "Suppose I take this."
        ],
        [
            "The squares function and expand it.",
            "Then I get this.",
            "So I have a quadratic term extensible, say transpose X linear term constant.",
            "Suppose then I introduce a new variable.",
            "I called the vector XX transpose this outer product Y and I use Y as a new variable.",
            "Then I can rewrite the correct term as expose A transpose X as a trace of a transpose a * Y.",
            "Just buy properties of traces and products.",
            "And now I and I can also replace this constraint on XI squared.",
            "By a constraint on the diagonal of why?",
            "Because XI squared will be exactly the diagonal elements of why?",
            "So now I've made the.",
            "Constraint the objective linear.",
            "The second constraint is linear.",
            "But the sector the first constraint is still very nonconvex.",
            "It says that why is actually equal to this rank one matrix.",
            "And then to get.",
            "But it's still equivalent to this problem.",
            "Has the same optimal value, and it's also equally difficult.",
            "So then you obtain the relaxation by replacing this equality."
        ],
        [
            "Strained by an inequality.",
            "And then if you replaced by an inequality, can write this constraint while creating are equal to XX transpose as a linear matrix inequality and then the problem becomes an SDP.",
            "That you can solve.",
            "And it's a relaxation because we loosened this constraint, we replaced the original constraint by a weaker constraint that's easier to satisfy.",
            "So the optimal value will be lower than the optimal value of the original problem.",
            "So you can solve this SDP.",
            "Quite easily it gives you a lower bound on the optimal value.",
            "And then you can also try to obtain from the optimal solution of the SDP from Y and the optimal X and the SDP.",
            "A sub optimal solutions of the original problem and one popular method for doing that is to interpret Y&X.",
            "As the mean X and covariance or the.",
            "Second moment of in the distribution.",
            "And then, for example, a normal distribution and then generates random vectors from that distribution that you computed by computing X&Y and then rounding the set.",
            "Just one heuristic to obtain sub optimal solutions from the solution of this."
        ],
        [
            "Relaxation and this is an example of.",
            "Problem with.",
            "3000 variables this is the lower bound we obtained from the SDP.",
            "If you just took the Boolean least squares problem and solve it as a least squares problem without integer constraints, and then rounded the square solution, you get this value.",
            "Just.",
            "Father here.",
            "And then this distribution is obtained by."
        ],
        [
            "Just generating a large number of suboptimal solutions using this randomized rounding."
        ],
        [
            "So we generate solutions and then we get sub optimal solutions like this.",
            "So we know that the true optimal value is somewhere between one and this left edge.",
            "And from the SDP we get certainly better solution than by simply using least squares and rounding the result.",
            "Um?",
            "Maybe I can stop here and finish the last few slides tomorrow."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'd like to start with some short introduction about the place of convex optimization optimization in general, and then an overview of those three.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Torreilles so I think everyone is familiar with the standard nonlinear mathematical optimization problem.",
                    "label": 1
                },
                {
                    "sent": "Value optimize nonlinear function F0 subject to a number of constraints, and it's clear that a very general problem that doesn't need to be motivated because almost any engineering design problem, any estimation problem can be written in this form.",
                    "label": 1
                },
                {
                    "sent": "Now, unfortunately, the general optimization problem is also very intractable, so in general this problem is very difficult to solve.",
                    "label": 0
                },
                {
                    "sent": "At least if you mean by minimization, you really mean find the best solution subject to the constraints.",
                    "label": 1
                },
                {
                    "sent": "Um and.",
                    "label": 0
                },
                {
                    "sent": "Convex optimization is useful or important because, roughly speaking, the nonlinear optimization problems that are tractable coincide with the ones that are convex and the boundary between the convex and convex roughly coincides with easy and difficult problems.",
                    "label": 0
                },
                {
                    "sent": "So in general, the general problem is difficult to solve, and it's also very difficult in general, or not always easy to recognize the problems that are easy.",
                    "label": 0
                },
                {
                    "sent": "And so that's why one of the major topics of this lecture.",
                    "label": 0
                },
                {
                    "sent": "So there's one important exception to this.",
                    "label": 0
                },
                {
                    "sent": "So a class of problems that's well known to be tractable and also quite easy to recognize.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's the linear programming problem, where you minimize a linear function.",
                    "label": 0
                },
                {
                    "sent": "Subject to a set of linear inequalities, so that was.",
                    "label": 1
                },
                {
                    "sent": "So actually, the study of linear programming Model S starts with or started the field of mathematical optimization in general or the study of numerical methods for optimization.",
                    "label": 0
                },
                {
                    "sent": "With down 6 simplex methods in at the end of the 40s, so the answer introduced an efficient method for solving linear programming problems by computer.",
                    "label": 1
                },
                {
                    "sent": "And the applications he had in mind were in logistics and operations planning.",
                    "label": 1
                },
                {
                    "sent": "But then since then, the applications of linear programming have multiplied and now it's widely used in engineering and operations research.",
                    "label": 1
                },
                {
                    "sent": "Also combinatorial optimization and a wide variety of fields.",
                    "label": 0
                },
                {
                    "sent": "And that's a little surprising, because the problem itself is clearly very specialized, because everything is linear.",
                    "label": 0
                },
                {
                    "sent": "But that hasn't stopped linear programming from becoming a very important.",
                    "label": 0
                },
                {
                    "sent": "And widely used technique and the reason of course, is that it's easy to solve.",
                    "label": 0
                },
                {
                    "sent": "People can solve linear programming problems with very large scale, and that makes it interesting to look for applications of linear programming exactly or with approximations.",
                    "label": 0
                },
                {
                    "sent": "And also it's makes it useful as a sub problem to solve some problems in combinatorial or non convex or discrete optimization problems where you solve computer problems by branch and bounds, and then every subproblem is a linear programming problem.",
                    "label": 0
                },
                {
                    "sent": "And then the scalability of the entire method comes from the tractability of linear programming problem.",
                    "label": 0
                },
                {
                    "sent": "So far.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For convex optimization, smaller is the same story, except that this.",
                    "label": 0
                },
                {
                    "sent": "Is more recent so convex optimization problem in practice as?",
                    "label": 1
                },
                {
                    "sent": "Been applied for maybe last 20 years or so.",
                    "label": 0
                },
                {
                    "sent": "And another difference with linear programming is that it's of course much more general, because you can allow the functions in the objective and the constraints to be nonlinear.",
                    "label": 0
                },
                {
                    "sent": "They have to be convex.",
                    "label": 0
                },
                {
                    "sent": "So it's a very substantial extension of linear programming.",
                    "label": 0
                },
                {
                    "sent": "Therefore, it's also more difficult to recognize and simple linear programming problems, but many of the other properties of linear programming also hold for convex optimization, so it's very tractable and we see that the methods that people have developed, or some of the methods for linear programming extend very easily too.",
                    "label": 0
                },
                {
                    "sent": "General nonlinear convex optimization problems.",
                    "label": 1
                },
                {
                    "sent": "And it's also.",
                    "label": 0
                },
                {
                    "sent": "Right here for applications, but also in for nonconvex problems as the basis of either relaxations to be used in exact global optimization problems or heuristics, or.",
                    "label": 0
                },
                {
                    "sent": "Similar techniques.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some brief history.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned linear programming at the start of the whole development of mathematical programming.",
                    "label": 0
                },
                {
                    "sent": "Then during the 50s people extended linear programming to include an quadratic objective function.",
                    "label": 0
                },
                {
                    "sent": "So the first extension they made was to replace the linear objective by quadratic convex objective, and that's a quadratic programming problem.",
                    "label": 0
                },
                {
                    "sent": "At the end of the 1960s throws a sort of maybe a smaller development.",
                    "label": 0
                },
                {
                    "sent": "It's called geometric programming that will define.",
                    "label": 1
                },
                {
                    "sent": "And can also be interpreted as an extension of linear programming.",
                    "label": 0
                },
                {
                    "sent": "And then since the beginning of the 1990s has been several nonlinear classes of or extensions of linear programming with different names, semidefinite programming, 2nd order, cone programming, and so on.",
                    "label": 1
                },
                {
                    "sent": "So we've seen what we'll see.",
                    "label": 0
                },
                {
                    "sent": "What happened around 1990 to make start this evolution?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For applications we see the same story more or less around 1990 people have developed or started to apply convex optimization in many different areas.",
                    "label": 0
                },
                {
                    "sent": "So one of the first was control theory and linear matrix inequalities and semidefinite programming and control theory.",
                    "label": 1
                },
                {
                    "sent": "The machine learning has of course been one of the success stories of convex optimization with the support vector machine training via quadratic programming.",
                    "label": 1
                },
                {
                    "sent": "There are also applications and combinatorial optimization where people try to find better relaxations for combinatorial problems better than the standard linear programming relaxations by formulating nonlinear convex relaxations.",
                    "label": 0
                },
                {
                    "sent": "More recently, there's also the one norm heuristics for sparse optimization that rely on convex formulations and and etc.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main event around 1990 that started this interesting convex optimization or the development of interior point methods for convex optimization.",
                    "label": 1
                },
                {
                    "sent": "So this came after the 1980s and the development of polynomial time, interior point methods for linear programming, so in 1984.",
                    "label": 1
                },
                {
                    "sent": "This famous paper where he proposed an interior point method for linear programming with a polynomial time complexity proof, and I was also considered the first practical polynomial time algorithm for linear programming.",
                    "label": 0
                },
                {
                    "sent": "So it solved a major open problem.",
                    "label": 0
                },
                {
                    "sent": "And then during the 1980s, starting with the 1984 people simplified his method and extended it.",
                    "label": 0
                },
                {
                    "sent": "And optimize it for practical efficiency and practical performance and in.",
                    "label": 0
                },
                {
                    "sent": "And so that was the development of linear programming, interior point methods.",
                    "label": 0
                },
                {
                    "sent": "And then around 1919 Estavana Brosky, another people extended the interior point methods for linear programming to nonlinear convex optimization, and that generated this interest in convex optimization because the reasoning was if convex optimization problem can be solved with very similar methods as linear programming, then it should also be at least as useful because it's also much more general problem.",
                    "label": 0
                },
                {
                    "sent": "So that sort of was a focused you throughout the 1990s, so the emphasis in research and optimization algorithms for convex optimization is an interior point methods.",
                    "label": 0
                },
                {
                    "sent": "And then the last 10 years or so there is an increased emphasis on 1st order methods for very large scale or large scale optimization.",
                    "label": 0
                },
                {
                    "sent": "Where people?",
                    "label": 0
                },
                {
                    "sent": "Try to develop very inexpensive methods that can scale better to large dimensions, and there's been some remarkable new methods that improve on the standard very classical algorithms like gradient descent and etc.",
                    "label": 0
                },
                {
                    "sent": "So we'll discuss these two classes of methods tomorrow.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the agenda for the three lectures.",
                    "label": 0
                },
                {
                    "sent": "So today we'll talk about some basic theory theory and definitions and examples of convex optimization problems and some applications tomorrow in the first lecture I would like to talk about interior point methods for convex optimization and then in the last lecture will talk about the 1st order methods.",
                    "label": 1
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So start with zombie.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Definitions, so I think most of you know the convex status set is convex.",
                    "label": 0
                },
                {
                    "sent": "If the line segment between any two points in the set is contained in the set.",
                    "label": 1
                },
                {
                    "sent": "So that's this.",
                    "label": 0
                },
                {
                    "sent": "Is a convex set.",
                    "label": 0
                },
                {
                    "sent": "This is not convex.",
                    "label": 0
                },
                {
                    "sent": "This is also not convex because of the boundary.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some examples that are very common and affine set, so the solution set of any set of linear equations is convex, independent of the size or the dimension of the matrices.",
                    "label": 1
                },
                {
                    "sent": "1/2 space so solution set of linear inequality.",
                    "label": 0
                },
                {
                    "sent": "A single linear inequality with a non zero normal vector is convex.",
                    "label": 1
                },
                {
                    "sent": "Solution of a finite number of linear inequalities is called a polyhedron.",
                    "label": 1
                },
                {
                    "sent": "So in this these nodes are used this inequality sign to denote componentwise inequality between vectors, so this is a component wise and equality between two vectors X&B, so it denotes a set of.",
                    "label": 1
                },
                {
                    "sent": "A finite set of linear inequalities.",
                    "label": 0
                },
                {
                    "sent": "An ellipsoid or the solution of a quadratic inequality with a positive definite matrix matrix A.",
                    "label": 0
                },
                {
                    "sent": "A unit normal or a normal for any norm is always convex that follows from the definition of norm.",
                    "label": 0
                },
                {
                    "sent": "And then another interesting set that will uses the positive semidefinite cone or the set of positive semidefinite matrices that will denote like this.",
                    "label": 0
                },
                {
                    "sent": "So the Bolt faces with a subscript N will be the set of symmetric matrices of order N. This inequality for a matrix denotes positive semidefinite knus, and then this is the positive semidefinite cone.",
                    "label": 0
                },
                {
                    "sent": "So it's a convex set, and it's also a cone, because any positive multiple of any vector in this set is also in the set.",
                    "label": 1
                },
                {
                    "sent": "And a useful property is that the intersection of convex sets is always convex, and that follows of course directly from the definition of convexity in terms of the line segments.",
                    "label": 0
                },
                {
                    "sent": "But that's also that's a very basic simple property, but it's.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Useful in practice.",
                    "label": 0
                },
                {
                    "sent": "For example, this is an example of a convex set specified by an.",
                    "label": 1
                },
                {
                    "sent": "As follows, so suppose P of T is a cosine polynomial.",
                    "label": 0
                },
                {
                    "sent": "So as terms cosine, T, cosine, tutee, etc, and the coefficients are X1 X 2X.",
                    "label": 0
                },
                {
                    "sent": "And then you look at the succeeded find as the coefficients of all the cosine polynomials that are between negative one and one on some interval between 0 and \u03c0 / 3.",
                    "label": 0
                },
                {
                    "sent": "So these are.",
                    "label": 0
                },
                {
                    "sent": "I hope you can see this.",
                    "label": 0
                },
                {
                    "sent": "These are three examples of polynomials P of T that satisfy this condition between minus one and one on this interval.",
                    "label": 1
                },
                {
                    "sent": "And then C is a set of those schools and polynomials, or the set of their coefficients?",
                    "label": 0
                },
                {
                    "sent": "Well, that's a convex set.",
                    "label": 0
                },
                {
                    "sent": "And that's easy to see from this intersection property, because if you fix T, if you look at this condition for a fixed T. Then it says that the absolute value of this expression is between one and negative one.",
                    "label": 0
                },
                {
                    "sent": "So that's two linear inequalities.",
                    "label": 0
                },
                {
                    "sent": "So for fixty, this is too linear inequality's, so that's a convex set, because this intersection of two parallel half spaces.",
                    "label": 0
                },
                {
                    "sent": "And then if you impose this condition for all T. Frailty in this case infinitely many T you get an intersection of many of those have spaces for each D have two parallel spaces and then if you change T they have spaces rotate and it describes a non polyhedral convex set, so it's not polyhedral because you need infinitely many qualities to describe it, but it's clearly convex.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's all we will need about to know about convex sets.",
                    "label": 0
                },
                {
                    "sent": "A convex function is defined like this, so the function is convex if its domain is convex.",
                    "label": 1
                },
                {
                    "sent": "Sets of points where it's defined as convex and on its domain, Jensen's inequality holds.",
                    "label": 0
                },
                {
                    "sent": "So that's Jensen's inequality.",
                    "label": 0
                },
                {
                    "sent": "So graphically it means that if you have two points on the graph of the function.",
                    "label": 0
                },
                {
                    "sent": "We value F of XF of Y.",
                    "label": 0
                },
                {
                    "sent": "Then the linear segment defined by those two points on the graph lies above the graph of the function.",
                    "label": 0
                },
                {
                    "sent": "That's a convex function.",
                    "label": 0
                },
                {
                    "sent": "And F is concave.",
                    "label": 0
                },
                {
                    "sent": "If minus F is convex.",
                    "label": 0
                },
                {
                    "sent": "So what are some?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simple examples.",
                    "label": 0
                },
                {
                    "sent": "So obviously linear or affine functions are convex, also concave.",
                    "label": 0
                },
                {
                    "sent": "Exponential the negative of a logarithm.",
                    "label": 0
                },
                {
                    "sent": "Negative entropy X log X are convex.",
                    "label": 1
                },
                {
                    "sent": "Powers certain powers are convex.",
                    "label": 0
                },
                {
                    "sent": "For example, if X is positive.",
                    "label": 0
                },
                {
                    "sent": "If that's the domain of F, then X to the Alpha is convex.",
                    "label": 0
                },
                {
                    "sent": "If offer is greater than one.",
                    "label": 0
                },
                {
                    "sent": "Or negative, etc.",
                    "label": 0
                },
                {
                    "sent": "Any norm is convex.",
                    "label": 0
                },
                {
                    "sent": "This is a function that's not immediately clear, but also convex.",
                    "label": 0
                },
                {
                    "sent": "If you have a quadratic function X, transpose X / T. As a function of X&T jointly.",
                    "label": 0
                },
                {
                    "sent": "Where T is positive.",
                    "label": 0
                },
                {
                    "sent": "That's a convex function of X&T.",
                    "label": 0
                },
                {
                    "sent": "A geometric mean of in a non negative variables is concave.",
                    "label": 0
                },
                {
                    "sent": "Logged out of the lock of the determinant of a positive definite matrix is concave, so it's concave on the set of positive definite matrices so that function will be important in when you talk about interior point methods.",
                    "label": 1
                },
                {
                    "sent": "And then the last one will also encounter is the log of the sum of exponentials of variables is convex.",
                    "label": 0
                },
                {
                    "sent": "Of course, the sum of exponentials by itself is convex, because exponentials are convex.",
                    "label": 0
                },
                {
                    "sent": "But even if you take the log or apply the logarithm to it, you still have convex function.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's also a simple connection between convex functions and convex sets.",
                    "label": 0
                },
                {
                    "sent": "So the convex function is convex if its epigraph is convex, convex, as a convex set.",
                    "label": 0
                },
                {
                    "sent": "So the epic level function is simply the set defined of everything that lies above the graph of the function.",
                    "label": 0
                },
                {
                    "sent": "The graph itself and everything above.",
                    "label": 0
                },
                {
                    "sent": "So if X is a function of invariables, its epigraph is set in R N + 1.",
                    "label": 0
                },
                {
                    "sent": "Ghosty is the extra variable.",
                    "label": 0
                },
                {
                    "sent": "And the so this is if and only if a function is convex if and only if its epigraph is a convex set.",
                    "label": 1
                },
                {
                    "sent": "You can also consider the sublevel sets of a function convex function so it's a set of points X in the domain of F that has a have a function value less than or equal in a certain Alpha.",
                    "label": 1
                },
                {
                    "sent": "Now a sublevel set of a convex function is always convex, and that follows again directly from the definition, but the converse is not true.",
                    "label": 0
                },
                {
                    "sent": "There are functions that are not convex and still have.",
                    "label": 0
                },
                {
                    "sent": "Convex sublevel sets for all values of Alpha.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So convex functions were defined in general using Jensen's inequality, so they don't have to be differentiable.",
                    "label": 0
                },
                {
                    "sent": "If it also differentiable once or twice differentiable, then you can also give equivalent conditions that can replace Jensen's inequality in the diff.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mission.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, if the function is differentiable, then an equivalent condition is that the function value of the graph.",
                    "label": 0
                },
                {
                    "sent": "Function satisfies this inequality, so on the right hand side you see the linear approximation of the function around a point X, so the 1st order linear approximation of.",
                    "label": 0
                },
                {
                    "sent": "A function from its function value and its gradient.",
                    "label": 0
                },
                {
                    "sent": "Well, if the function is convex, then that linear approximation must be below the graph of the function.",
                    "label": 0
                },
                {
                    "sent": "Throw possible points where you take the approximation, so this first order linear approximation is not only a local approximation of the function, but it's also a global lower bound on the function value, so it's a very fundamental.",
                    "label": 0
                },
                {
                    "sent": "Property.",
                    "label": 0
                },
                {
                    "sent": "An if of course you also have secondary data function is twice differentiable.",
                    "label": 0
                },
                {
                    "sent": "Then you can express convexity.",
                    "label": 0
                },
                {
                    "sent": "Also simply in terms of the Hessian and say that the Hessian matrix of the function must be positive semidefinite everywhere in its domain.",
                    "label": 0
                },
                {
                    "sent": "So those are the definitions, so the Jensen's inequality, then these two equivalent definitions for differentiable or twice differentiable functions.",
                    "label": 0
                },
                {
                    "sent": "And then we also have the geometrical interpretation in terms of the epigraph.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in applications it's very important or useful to be able to recognize convex functions.",
                    "label": 0
                },
                {
                    "sent": "And that's not always straightforward.",
                    "label": 0
                },
                {
                    "sent": "So of course we can always verify the definition, but that's not always the easiest method, as we'll see, we can try to prove that the Hessian matrix is positive semidefinite, but that can also be quite painful.",
                    "label": 0
                },
                {
                    "sent": "And then there also exists a large number of.",
                    "label": 0
                },
                {
                    "sent": "Operations or calculus rules that are known to preserve convexity.",
                    "label": 1
                },
                {
                    "sent": "So often.",
                    "label": 0
                },
                {
                    "sent": "The easiest way is to recognize a convex function is to recognize that it's composed or obtained from a number of more basic convex functions via a number of simple operations.",
                    "label": 1
                },
                {
                    "sent": "So we'll go through this list.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first is obvious if a function is convex then non negative multiple is convex or the sum of two convex functions is convex.",
                    "label": 1
                },
                {
                    "sent": "Also, if you replace the argument of F by linear or an affine mapping, then the resulting function is convex, so the composition of F with an affine mapping is convex.",
                    "label": 0
                },
                {
                    "sent": "So for example, that allows us to conclude that this function is convex.",
                    "label": 0
                },
                {
                    "sent": "That's will be useful as a log rhythmic barrier function for linear inequalities, so we know that miners log is convex.",
                    "label": 1
                },
                {
                    "sent": "If you replace the argument with a linear and affine function, we get a convex function of X and then the sum of convex functions is convex.",
                    "label": 0
                },
                {
                    "sent": "So you don't need to take the Hessian of this function to decide that it's, or conclude that it's convex.",
                    "label": 1
                },
                {
                    "sent": "Also, we've seen that norms are convex functions, so any function of this form is automatically convex.",
                    "label": 0
                },
                {
                    "sent": "The norm of X + B is always a convex function for any kind of normal.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this one is less obvious, maybe.",
                    "label": 0
                },
                {
                    "sent": "So if you have M convex functions, if one through FM.",
                    "label": 0
                },
                {
                    "sent": "And then you take the pointwise maximum of each of these functions.",
                    "label": 0
                },
                {
                    "sent": "So for each X you sign to F of X.",
                    "label": 0
                },
                {
                    "sent": "The maximum of those values F of X. Geometrically, that just means that you take the intersection of the epigraphs of those in functions.",
                    "label": 0
                },
                {
                    "sent": "The intersection of these epigraphs of these functions will be the epigraph of F. So this is the counterpart for functions of this intersection property for convex sets.",
                    "label": 0
                },
                {
                    "sent": "So that's always convex.",
                    "label": 0
                },
                {
                    "sent": "And that's very useful, because many convex functions arise as the maximum of a number of functions.",
                    "label": 0
                },
                {
                    "sent": "For example, suppose we define a function as a sum function of an in vector X.",
                    "label": 0
                },
                {
                    "sent": "As the sum of the our largest components of X.",
                    "label": 1
                },
                {
                    "sent": "If you do notice like this.",
                    "label": 0
                },
                {
                    "sent": "So it's very easy to compute.",
                    "label": 0
                },
                {
                    "sent": "You take the vector X, you sort the coefficients in decreasing order, and then you add the first R coefficients.",
                    "label": 0
                },
                {
                    "sent": "Now that's a convex function of X.",
                    "label": 0
                },
                {
                    "sent": "And that's not immediately obvious, but you can just writing F in this way.",
                    "label": 0
                },
                {
                    "sent": "So what we do here is we write it as a maximum of a very large number of finite number of linear functions of X.",
                    "label": 0
                },
                {
                    "sent": "So for each linear function here we take a group of R components of X, an Adam.",
                    "label": 0
                },
                {
                    "sent": "And if you take the maximum of this over all possible sets of our components out of in, then you get the same function F of X.",
                    "label": 0
                },
                {
                    "sent": "So it's a maximum of.",
                    "label": 0
                },
                {
                    "sent": "In this case a very large number of linear functions of X.",
                    "label": 0
                },
                {
                    "sent": "So therefore it's convex, so this is not a practical way to compute this function F. It's much easier to sort and then take the maximum.",
                    "label": 0
                },
                {
                    "sent": "The first or entries, but it shows that it's convex.",
                    "label": 0
                },
                {
                    "sent": "So here we take a maximum of a finite number of discrete or a finite man.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Functions there is an extension of this two sets that can be infinite.",
                    "label": 0
                },
                {
                    "sent": "So here we suppose we have a function F of X&Y two parameters XY.",
                    "label": 0
                },
                {
                    "sent": "And we know it's convex in the first variable.",
                    "label": 0
                },
                {
                    "sent": "If the second variable is given so for fixed Y, it's convex in X.",
                    "label": 0
                },
                {
                    "sent": "And there's no condition how it depends on the second variable Y.",
                    "label": 0
                },
                {
                    "sent": "And effect why can be an integer or the constraint to be integer?",
                    "label": 0
                },
                {
                    "sent": "Or can be a vector or matrix, it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "And then you take the maximum of this function to evaluate this new function G of X.",
                    "label": 0
                },
                {
                    "sent": "You take the maximum of F of X&Y over all possible Y.",
                    "label": 0
                },
                {
                    "sent": "In some sense A and.",
                    "label": 0
                },
                {
                    "sent": "Again there is no restriction on what is doesn't have to be convex or connected, or.",
                    "label": 0
                },
                {
                    "sent": "There's no condition on a.",
                    "label": 0
                },
                {
                    "sent": "Well, that's always convex in X resulting function, so the previous example is where Y is just.",
                    "label": 1
                },
                {
                    "sent": "The index will be, Y is an integer, and the set A is a set of integers from one to M. And I use here in these notes we use the supremum if user maximum for the maximum over a finite set and the supremum over a set that could be infinite.",
                    "label": 0
                },
                {
                    "sent": "So that's the definition of that if you like and just replace it by Max.",
                    "label": 0
                },
                {
                    "sent": "Just keep in mind that it can be a doesn't have to be a finite set.",
                    "label": 0
                },
                {
                    "sent": "So a very good example of this is the maximum eigenvalue of a symmetric matrix.",
                    "label": 1
                },
                {
                    "sent": "Which is a convex function of X.",
                    "label": 0
                },
                {
                    "sent": "And that's easy to see.",
                    "label": 0
                },
                {
                    "sent": "So very short proof is this, so you know, from linear algebra that the maximum eigenvalue can be expressed like this.",
                    "label": 0
                },
                {
                    "sent": "It's the maximum.",
                    "label": 0
                },
                {
                    "sent": "Of Y transpose XY.",
                    "label": 0
                },
                {
                    "sent": "If you take the maximum overall vectors, why with unit norm?",
                    "label": 0
                },
                {
                    "sent": "So in this case, this is the set a the unit sphere.",
                    "label": 0
                },
                {
                    "sent": "And this is the function F of X&Y, so for fixed Y it's clear that's a linear function of X.",
                    "label": 0
                },
                {
                    "sent": "If you expand these products, you get a linear function of all the entries in X, so for fixed why this is a linear or therefore also convex function of X.",
                    "label": 0
                },
                {
                    "sent": "So then we know from this property if you take the maximum of these functions over any set Y, you get automatically a convex function of X.",
                    "label": 0
                },
                {
                    "sent": "And you can easily think of some other equivalent definitions of the maximum eigenvalue for which it's not immediately obvious that it's convex.",
                    "label": 0
                },
                {
                    "sent": "For example, if you think of it as the largest root of the characteristic polynomial.",
                    "label": 0
                },
                {
                    "sent": "Then it's not clear at all that if you change the entries in the Matrix X, that largest root is in a convex function of the entries.",
                    "label": 0
                },
                {
                    "sent": "It's actually very complicated.",
                    "label": 0
                },
                {
                    "sent": "A function.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's a maximization rule.",
                    "label": 0
                },
                {
                    "sent": "So here we have a function of two variables X&Y.",
                    "label": 0
                },
                {
                    "sent": "We maximize over the 2nd and the condition was that the function had to be convex in the first variable X for a given why?",
                    "label": 0
                },
                {
                    "sent": "There is something that looks very similar and refers to minimization.",
                    "label": 0
                },
                {
                    "sent": "Or the infimum?",
                    "label": 0
                },
                {
                    "sent": "So here again, we take a function of two variables XY, an.",
                    "label": 0
                },
                {
                    "sent": "Under some conditions you can conclude at a minimum over why gives you a convex function of X.",
                    "label": 0
                },
                {
                    "sent": "So it's very similar to this maximization rule on the previous page.",
                    "label": 0
                },
                {
                    "sent": "But the conditions are much more restrictive, so here the conditions are that F has to be jointly convex in X or Y, not just convex in X forgiven Y, but has to be jointly convex.",
                    "label": 0
                },
                {
                    "sent": "In X&Y, as variable, and also if there are constraints in the optimization, has to be constraints over a convex set C. But if that's the case, then we can conclude that.",
                    "label": 0
                },
                {
                    "sent": "Sorry H is convex.",
                    "label": 0
                },
                {
                    "sent": "So again, there are some simple, useful examples.",
                    "label": 0
                },
                {
                    "sent": "Suppose you take the distance to a convex set C. In any norm that's always a convex function of X.",
                    "label": 1
                },
                {
                    "sent": "Because the distance computed like this, it's the minimum distance from X to any point in C. We've seen that norms are always convex, so the norm of X -- Y is jointly convex in X&Y.",
                    "label": 1
                },
                {
                    "sent": "C is a convex set, so if you take the minimum distance, you get a convex function of the remaining variable X.",
                    "label": 0
                },
                {
                    "sent": "And that's true for any norm, but only for convex sets.",
                    "label": 0
                },
                {
                    "sent": "Another one that's very useful in optimization is as follows.",
                    "label": 0
                },
                {
                    "sent": "So suppose we take a linear programming problem in YS variable.",
                    "label": 0
                },
                {
                    "sent": "So I take minimize C, transpose Y with constraints that AY is less than X, so X is just the right hand side and inequalities.",
                    "label": 0
                },
                {
                    "sent": "And then they define as the function H the OR assign assigned to H the optimal value of this linear programming problem.",
                    "label": 0
                },
                {
                    "sent": "As a function of the right hand side X.",
                    "label": 0
                },
                {
                    "sent": "So to evaluate this function in general, you would have to at a certain X you'd have to pick X and solve this LP and Y, and then the optimal value is the function value at X.",
                    "label": 0
                },
                {
                    "sent": "So there's no closed form expression of this H of X, But you can compute it by solving an LP with excess right hand side.",
                    "label": 0
                },
                {
                    "sent": "But one useful property that's important in optimization is that if you define a function like this.",
                    "label": 0
                },
                {
                    "sent": "Then this is a convex function of X, so the optimal value of a linear programming problem is a convex function of its right hand sides in the constraints.",
                    "label": 0
                },
                {
                    "sent": "And it follows from the same rule.",
                    "label": 0
                },
                {
                    "sent": "So in this case we define F of XY as a function that has this as its domain, so it's only defied defined for pairs X&Y that satisfied that satisfy this inequality's.",
                    "label": 0
                },
                {
                    "sent": "And outside the domain we can give it a value plus Infinity.",
                    "label": 0
                },
                {
                    "sent": "And then on its domain, when X or Y satisfy this inequality, we define it as the transpose Y.",
                    "label": 0
                },
                {
                    "sent": "So if you do that, you get a function that's jointly convex in X&Y because its domain is convex in X&Y, is just a set of linear inequalities.",
                    "label": 0
                },
                {
                    "sent": "And on its domain, it obviously satisfies Jensen's inequality, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a convex function of jointly in XY and therefore and its minimum over Y is equal to H of X, so therefore ages can fix.",
                    "label": 0
                },
                {
                    "sent": "So this is true for LP's but also of course from any other.",
                    "label": 1
                },
                {
                    "sent": "Convex problems the optimal value as a function of the right hand side is convex in general.",
                    "label": 0
                },
                {
                    "sent": "H is a function of X, so I define a function of X.",
                    "label": 0
                },
                {
                    "sent": "And the value at X is the optimal value of this LP, right?",
                    "label": 0
                },
                {
                    "sent": "So I fix X.",
                    "label": 0
                },
                {
                    "sent": "And then solve this linear program with wires variable.",
                    "label": 0
                },
                {
                    "sent": "And then the optimal value is the function value of HX, so the it's interesting because it's.",
                    "label": 0
                },
                {
                    "sent": "The function is how the optimal value changes with changes in the right hand side, so it rises in sensitivity analysis and so on.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then we have a few more.",
                    "label": 0
                },
                {
                    "sent": "So an obvious question is what about composition?",
                    "label": 0
                },
                {
                    "sent": "If I have a composition of H&G of X and the road condition is that convex?",
                    "label": 0
                },
                {
                    "sent": "Well, there are some useful rules.",
                    "label": 0
                },
                {
                    "sent": "For example, if H is convex and increasing or nondecreasing and GS convex, then you can conclude that F is convex.",
                    "label": 1
                },
                {
                    "sent": "For example, X, the exponential of a convex function is automatically convex.",
                    "label": 1
                },
                {
                    "sent": "'cause in this case G is convex and exponential is a convex increasing function.",
                    "label": 0
                },
                {
                    "sent": "All 1 / G of X is convex.",
                    "label": 0
                },
                {
                    "sent": "If GS concave and positive and so on, there is only one thing you have to be careful with in these composition rules.",
                    "label": 0
                },
                {
                    "sent": "When we say non decreasing and increasing, you have to add a function.",
                    "label": 0
                },
                {
                    "sent": "H is not defined everywhere, so it has a domain.",
                    "label": 0
                },
                {
                    "sent": "Then outside its domain you have to assign it value plus Infinity.",
                    "label": 0
                },
                {
                    "sent": "And then examine whether it's not increasing and decreasing.",
                    "label": 0
                },
                {
                    "sent": "For example, the logarithm of X would not count as an increasing function in this composition rules, because for negative X you sign it plus Infinity and then over the entire real axis you don't get increasing function.",
                    "label": 0
                },
                {
                    "sent": "So that's the convention.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course, you can also look at.",
                    "label": 0
                },
                {
                    "sent": "Functions age with more than one variable and then we have similar theorems.",
                    "label": 0
                },
                {
                    "sent": "For example, we've seen that the log of the sum of exponentials as a convex function.",
                    "label": 0
                },
                {
                    "sent": "It's also clearly increasing in each of its variables, so you have a log of the sum of the exponentials of the components of a vector.",
                    "label": 0
                },
                {
                    "sent": "Then if you change increased one of the components, the function value can only increase.",
                    "label": 0
                },
                {
                    "sent": "So if I now replace or substitute the components of this lock, some X function with a convex function GI, then I get a convex function.",
                    "label": 0
                },
                {
                    "sent": "Complicated convex function of X and it follows from this one of these theorems.",
                    "label": 0
                },
                {
                    "sent": "Clear.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last one is.",
                    "label": 0
                },
                {
                    "sent": "Interesting, it's maybe the.",
                    "label": 0
                },
                {
                    "sent": "It's another construction or another common way in which context functions arise.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have a function F of variables X.",
                    "label": 0
                },
                {
                    "sent": "And then I construct a new function G with X and new variable scalar variable T as variable.",
                    "label": 0
                },
                {
                    "sent": "And to construct GI take, if I substitute its argument with X / T. And then I multiplied the entire thing with T. And I also restrict T to be positive.",
                    "label": 0
                },
                {
                    "sent": "Well, with this restriction, G is automatically convex.",
                    "label": 0
                },
                {
                    "sent": "And that's sometimes called the perspective of the function if.",
                    "label": 0
                },
                {
                    "sent": "So one example is this function that we encountered in the beginning.",
                    "label": 0
                },
                {
                    "sent": "If you take X transpose X / T. As a function of XNT, but restricted to positive T, then that's a convex function because it's the perspective of just expose X right.",
                    "label": 0
                },
                {
                    "sent": "You obtain the perspective by replacing X with X / T and then multiplying the entire function with T. If you do that, you get access projects over T. Another interesting one.",
                    "label": 0
                },
                {
                    "sent": "This is this.",
                    "label": 0
                },
                {
                    "sent": "If you take minus log X and replace X with X / T and then multiply with T, you get the relative entropy T log T -- 0 X.",
                    "label": 1
                },
                {
                    "sent": "So this property tells us that this function is convex jointly and XNT, and that's not immediately obvious.",
                    "label": 0
                },
                {
                    "sent": "Of course, it's only two variables, but it's not immediately obvious because T log T is known to be convex.",
                    "label": 0
                },
                {
                    "sent": "But then he also a subtract something something with no interesting convexity properties from it.",
                    "label": 0
                },
                {
                    "sent": "TNX but jointly in T An X the result is convex.",
                    "label": 0
                },
                {
                    "sent": "So those are the most important of these operations that will.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Encounter and the last one is the definition that will be needed in duality.",
                    "label": 0
                },
                {
                    "sent": "Actually lecture the third lecture.",
                    "label": 0
                },
                {
                    "sent": "So for every convex function, if you can define a conjugate function F star.",
                    "label": 0
                },
                {
                    "sent": "And it's defined like this, so I take.",
                    "label": 0
                },
                {
                    "sent": "F of X subtracted from Y, transpose X, and then I maximize over X.",
                    "label": 0
                },
                {
                    "sent": "And then the result will be a new function of the vector Y.",
                    "label": 0
                },
                {
                    "sent": "So we take what the elevator conjugate at?",
                    "label": 0
                },
                {
                    "sent": "Why or define the function conjugate?",
                    "label": 0
                },
                {
                    "sent": "That why you take Y transpose X, subtract F of X, and then maximize over X?",
                    "label": 0
                },
                {
                    "sent": "So, and there's a nice graphical construction.",
                    "label": 0
                },
                {
                    "sent": "So for example, if F of X was like this, and it's unfortunately very clear.",
                    "label": 0
                },
                {
                    "sent": "So if this is a non convex function X then you can interpret this graphically as so the XY.",
                    "label": 0
                },
                {
                    "sent": "Is a linear function of X with slope Y.",
                    "label": 0
                },
                {
                    "sent": "Then the function value at F star of Y is actually can read it off on the vertical axis.",
                    "label": 0
                },
                {
                    "sent": "If you shift this linear function with slope Y until as far as possible down until it just touches the graph of the function, then then this distance here is the negative of start of Y.",
                    "label": 0
                },
                {
                    "sent": "But it will be important in duality.",
                    "label": 0
                },
                {
                    "sent": "And so from the definition and the properties we've seen, it's clear that this is a convex function of Y.",
                    "label": 0
                },
                {
                    "sent": "Even if F of X is not convex.",
                    "label": 1
                },
                {
                    "sent": "Because we can apply this maximization rule.",
                    "label": 0
                },
                {
                    "sent": "We take the supremum over a family of functions that depend on X&Y.",
                    "label": 0
                },
                {
                    "sent": "This is convex and Y for fixed X.",
                    "label": 0
                },
                {
                    "sent": "The argument of the maximum.",
                    "label": 0
                },
                {
                    "sent": "So if I maximize over XI, automatically get a convex function of the remaining variable Y.",
                    "label": 0
                },
                {
                    "sent": "So you don't need convexity of F to conclude that F star is convex.",
                    "label": 0
                },
                {
                    "sent": "But in practice, you're mostly interested in cases where F is convex and storage convex, so that's called a conjugate an.",
                    "label": 0
                },
                {
                    "sent": "It's in some ways similar to three transforms.",
                    "label": 0
                },
                {
                    "sent": "For example in signal processing.",
                    "label": 0
                },
                {
                    "sent": "So we have pairs of functions and their conjugates.",
                    "label": 0
                },
                {
                    "sent": "Same as you have pairs of functions and their Fourier transforms, and some operations are easier when you do them in terms of conjugates and in terms of the function itself.",
                    "label": 0
                },
                {
                    "sent": "But you see this.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the last lecture.",
                    "label": 0
                },
                {
                    "sent": "So these are some interesting examples.",
                    "label": 0
                },
                {
                    "sent": "Or some examples that we'll encounter later.",
                    "label": 0
                },
                {
                    "sent": "So if you take apply the conjugate to a quadratic function with positive definite quadratic function Q, you get a quadratic function, but but Q is replaced with Q inverse.",
                    "label": 0
                },
                {
                    "sent": "Fewer the entropy or the negative entropy.",
                    "label": 0
                },
                {
                    "sent": "Is an exponential sum of exponentials the conjugates?",
                    "label": 0
                },
                {
                    "sent": "If you take a norm any norm, then the conjugates of F is the indicator function of the unit ball for the dual norm of F. So by indicated function I mean a function that's defined as zero.",
                    "label": 0
                },
                {
                    "sent": "If you're in this set and plus Infinity otherwise, let's call the indicator function of the set.",
                    "label": 0
                },
                {
                    "sent": "So the conjugate of the norm is 0 if Y has a dual normal isn't one, and it's pleasant finity outside.",
                    "label": 0
                },
                {
                    "sent": "So if this is the one norm, for example, then this is the Infinity norm.",
                    "label": 0
                },
                {
                    "sent": "That's the P norm that is secure norm.",
                    "label": 0
                },
                {
                    "sent": "It's one over Peoples 1 / Q is 1 and so on.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And another one that would be useful tomorrow is the general the indicator function of a convex set C. So if I define a function FS0 on the set C plus Infinity outside, then that's a convex function because it's.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Domain is C and on its domain it's just constant 0.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And its conjugate is defined like this.",
                    "label": 0
                },
                {
                    "sent": "It's called the support function of the set C. So it's the maximum of the value at Y is the maximum.",
                    "label": 0
                },
                {
                    "sent": "Why transpose X value maximized oversee?",
                    "label": 0
                },
                {
                    "sent": "But will counter this tomorrow.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the first section on some basic definitions and properties of convex sets and functions.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "Quadratic over linear or.",
                    "label": 0
                },
                {
                    "sent": "In general, the numerator has to be linear and positive, and the quadratic function has to be convex.",
                    "label": 0
                },
                {
                    "sent": "And then if you restrict the linear function to be positive, you get.",
                    "label": 0
                },
                {
                    "sent": "You can apply this.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This year, if you now replace X&T by linear functions, you get still have a convex function.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then the second part of this lecture is look at convex optimization problems will go through important classes of problems small as chronologically.",
                    "label": 1
                },
                {
                    "sent": "So we start with linear programming and then quadratic programming and.",
                    "label": 1
                },
                {
                    "sent": "Finish with the most recent classes, semidefinite programming and 2nd order cone program.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first convex optimization problem is defined like this, so we take the general nonlinear form, but we restrict all the nonlinear functions in the objective and inequality constraints to be convex.",
                    "label": 1
                },
                {
                    "sent": "And the equality constraints must be linear, otherwise it's not a convex problem.",
                    "label": 0
                },
                {
                    "sent": "And then it's easy to see that the feasible set is a convex set.",
                    "label": 1
                },
                {
                    "sent": "And that if you have a point that's locally optimal, it's automatically globally optimal.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first example of course is linear programming.",
                    "label": 0
                },
                {
                    "sent": "So and in your programming everything is just linear.",
                    "label": 0
                },
                {
                    "sent": "The feasible set is a polyhedron.",
                    "label": 1
                },
                {
                    "sent": "It's the intersection of finitely many inequalities.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "It has some interesting special properties that are not true in general for general convex problems.",
                    "label": 0
                },
                {
                    "sent": "So for example, the optimal value is always at the boundary of the feasible set.",
                    "label": 0
                },
                {
                    "sent": "An in general, actually, there's usually at a vertex of the feasible set, right?",
                    "label": 0
                },
                {
                    "sent": "And SC is exactly perpendicular to this and then this entire edge would be optimal.",
                    "label": 0
                },
                {
                    "sent": "But in general you can always restrict yourself to looking for optimal solutions among the verticies, and that's of course the basis of the simplex or the basic idea in the simplex method.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what are some general convex problems that can be reduced to linear programming so one?",
                    "label": 0
                },
                {
                    "sent": "General One is piecewise linear functions which I have taken a set of linear functions of X.",
                    "label": 0
                },
                {
                    "sent": "And I take so M of them, and I take the pointwise maximum over them.",
                    "label": 0
                },
                {
                    "sent": "Then we already know from the first section that that's a convex function of F. So if you're just trying to show that it's convex, or see that it's convex, or you have to say as well, that's the maximum of a set of pointwise maximum of a number of convex functions of X.",
                    "label": 0
                },
                {
                    "sent": "But if you're also looking for a method for solving this.",
                    "label": 0
                },
                {
                    "sent": "Then this is not that simple because it's also very non differentiable function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the Hessian, for example in the points where it's differentiable, the Hessian is just zero, so it's not easy to solve using Newton's method or a gradient method and so on, but it's easily solved as an LP, so you write this as a linear programming problem.",
                    "label": 0
                },
                {
                    "sent": "We introduce new variable T and then add an inequality.",
                    "label": 0
                },
                {
                    "sent": "For each of these components, in the maximum that says that a transpose X + B ISN T. And we optimize this linear program over T&X jointly.",
                    "label": 0
                },
                {
                    "sent": "It's an LP because everything is linear in T. The objective and constraints are all linear auntie.",
                    "label": 0
                },
                {
                    "sent": "And then it's also difficult to see that if I minimize over T&X jointly, that's equivalent to solving this problem.",
                    "label": 0
                },
                {
                    "sent": "And to see that it can just assume that suppose X is fixed in this problem.",
                    "label": 0
                },
                {
                    "sent": "It's not a variable, but you only minimize over T. So if you minimize the subject to these mloa rounds on T, then obviously the optimal value of T will be this value.",
                    "label": 0
                },
                {
                    "sent": "The maximum of those lower bounds.",
                    "label": 0
                },
                {
                    "sent": "So that's if you fix X and optimize over T and then if you minimize jointly over X&T then the optimal solution will be the value of X that minimizes this and T will be equal maximum.",
                    "label": 0
                },
                {
                    "sent": "So it's equivalent to this, and this gives you a practical way of solving this piecewise linear.",
                    "label": 0
                },
                {
                    "sent": "Optimization problem.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So an application of this are the one or more Infinity norm minimization problems.",
                    "label": 0
                },
                {
                    "sent": "So suppose I want to minimize the one norm or the Infinity norm of function X -- B.",
                    "label": 0
                },
                {
                    "sent": "So these are, we know already that these are convex functions of X.",
                    "label": 0
                },
                {
                    "sent": "Because norms are convex.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                },
                {
                    "sent": "You can solve them in practice using linear programming and argument, or the reasoning is very similar.",
                    "label": 0
                },
                {
                    "sent": "For example, if you look at the one norm, you would introduce a number of variables Y, one for each row, and AX minus B.",
                    "label": 0
                },
                {
                    "sent": "Introduce linear inequalities, upper lower bounds on X -- B and then you minimize the sum of the wise subject to these inequalities.",
                    "label": 0
                },
                {
                    "sent": "And again, it's easy to see that these are equivalent.",
                    "label": 0
                },
                {
                    "sent": "So assume again that X is fixed, so X -- B is just a given vector.",
                    "label": 0
                },
                {
                    "sent": "And then I minimize over Y.",
                    "label": 0
                },
                {
                    "sent": "So that's a separate optimization problem.",
                    "label": 0
                },
                {
                    "sent": "You can minimize over every component of Y separately.",
                    "label": 0
                },
                {
                    "sent": "For each component, why I there are two lower bounds?",
                    "label": 0
                },
                {
                    "sent": "There's a lower bounce, why I is greater than the right component of this and greater than the negative of this which created in the absolute value?",
                    "label": 0
                },
                {
                    "sent": "Of the right component of X -- B.",
                    "label": 0
                },
                {
                    "sent": "So the optimal value for YYI is the absolute value of that component of X -- B, so that's if you fix X.",
                    "label": 0
                },
                {
                    "sent": "If you fix X, each component of I will be the absolute value of the corresponding component of X -- B.",
                    "label": 0
                },
                {
                    "sent": "So the value that some of those will be the one norm of X of X -- B.",
                    "label": 0
                },
                {
                    "sent": "And then if you minimize over X&Y jointly by solving this LP in X&Y, you minimize the one node.",
                    "label": 0
                },
                {
                    "sent": "And for the Infinity Norm you have a similar story, except that instead of EM.",
                    "label": 0
                },
                {
                    "sent": "Variables you only have one extra variable Y, and then you instead of a vector Y here have Y times vector of all ones, so impose the same upper bound on each of the inequality's and that will minimize the maximum of the absolute values of X -- B.",
                    "label": 0
                },
                {
                    "sent": "So this is of course very useful.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's also useful to look at the distributions you get by normal approximation with different norms.",
                    "label": 0
                },
                {
                    "sent": "So here I just take a random matrix A of size 200 by 80.",
                    "label": 0
                },
                {
                    "sent": "I minimize the just the two norm, the squares problem and the one norm of X -- B.",
                    "label": 0
                },
                {
                    "sent": "And this is the distribution of the residual.",
                    "label": 0
                },
                {
                    "sent": "The 200 residuals in the vector X -- B at those two solutions for the two norm and for the $1.",
                    "label": 0
                },
                {
                    "sent": "And the green grass, of course, are the penalty functions you impose on each residual for the two norm, you have a quadratic penalty function for the one norm, it's the absolute value.",
                    "label": 0
                },
                {
                    "sent": "So then you see that, roughly speaking, these two problems, of course do the same.",
                    "label": 0
                },
                {
                    "sent": "They try to write B as a linear combination of the columns of a.",
                    "label": 0
                },
                {
                    "sent": "So roughly speaking, they try to do the same thing, but the distributions you obtain are very different.",
                    "label": 0
                },
                {
                    "sent": "And there are actually two important differences that are useful.",
                    "label": 0
                },
                {
                    "sent": "So one is, you notice that the of course the High Peak at zero if you use the one norm.",
                    "label": 1
                },
                {
                    "sent": "And that's explained by the fact that the absolute value has this breakpoint or this breakpoint at one at zero, whereas the two norm minimizes the quadratic penalty function, which is flat at the origin.",
                    "label": 0
                },
                {
                    "sent": "So there's no benefit here.",
                    "label": 0
                },
                {
                    "sent": "If you choose X and moving it from something close to 0 to exactly 0, whereas if user one norm actually keep getting a benefit by making it moving it all the way to 0.",
                    "label": 0
                },
                {
                    "sent": "So that's an important difference, and the second difference is actually for large residuals, so you see here that the distribution is also much in this case not much, but it's wider than the two norm distribution, so there's some large residuals that are larger than the largest residuals for the two norm.",
                    "label": 0
                },
                {
                    "sent": "So it's a wider distribution and you have this High Peak at the origin.",
                    "label": 0
                },
                {
                    "sent": "So these two features are both useful, so the first one that is of course used in sparse optimization heuristics.",
                    "label": 0
                },
                {
                    "sent": "If you want a regularization term that encourages sparsity in the vector X.",
                    "label": 0
                },
                {
                    "sent": "Then the one norm is much more useful than the two norm.",
                    "label": 0
                },
                {
                    "sent": "So in this application, of course it's not surprising that if you have a D variables and randomly generated a that you can make 80 of the residuals exactly 0.",
                    "label": 0
                },
                {
                    "sent": "It's not very difficult, but you might.",
                    "label": 0
                },
                {
                    "sent": "You could imagine an application where B is actually equal to X.",
                    "label": 0
                },
                {
                    "sent": "And then an unknown number of values of B were corrupted by noise.",
                    "label": 0
                },
                {
                    "sent": "And then you would like to find a solution X that satisfies many of the equations exactly with 0 error.",
                    "label": 0
                },
                {
                    "sent": "Then this will be much more useful than the two norm, but it won't give you exactly the solution with maximum number of equations that are satisfied exactly.",
                    "label": 0
                },
                {
                    "sent": "It won't give you the sparsest vector of residuals, but it will give you typically a very sparse vector.",
                    "label": 0
                },
                {
                    "sent": "So the behavior at the origin is actually very useful for sparse optimization.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The fact that it's a wider distribution is useful in robust regression.",
                    "label": 0
                },
                {
                    "sent": "And of course, the fact that it's wider comes from the fact that the absolute value penalty increases much more slowly for large values of residual standard quadratic penalty.",
                    "label": 0
                },
                {
                    "sent": "So there's a smaller, relatively smaller penalty on very large residuals than for the quadratic penalty.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "No, no, it's a fixed matrix.",
                    "label": 0
                },
                {
                    "sent": "I selected the Matrix a.",
                    "label": 0
                },
                {
                    "sent": "And vector B.",
                    "label": 0
                },
                {
                    "sent": "Then I solve these two problems and obtain two solutions X right the least squares solution and one solution.",
                    "label": 0
                },
                {
                    "sent": "And then this is the distribution of the residuals in the vector X -- B.",
                    "label": 0
                },
                {
                    "sent": "So X -- B is a vector of length two, hundreds have 200 errors in those 200 equations, and this is.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution around.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "0.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So, roughly speaking, you would like to minimize the norm of the vector in order to make all the residuals as small as possible.",
                    "label": 0
                },
                {
                    "sent": "But you have 200 visuals.",
                    "label": 0
                },
                {
                    "sent": "That you minimize by single scalar objective and you see that the distribution of the residuals for the two solutions X is actually very different and depending on your application you might prefer one or the other norms because of this difference in distributions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this has a large number of zeros.",
                    "label": 0
                },
                {
                    "sent": "Typically the one norm will encourage sparsity.",
                    "label": 0
                },
                {
                    "sent": "In this case, in the vector X -- B and a second important difference is that it's much wider distribution.",
                    "label": 0
                },
                {
                    "sent": "Then the tuner.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second property is used in robust regression.",
                    "label": 0
                },
                {
                    "sent": "You've probably seen this.",
                    "label": 0
                },
                {
                    "sent": "Suppose you want to fit a straight line through points, but there are some outliers.",
                    "label": 0
                },
                {
                    "sent": "There's a point here and here.",
                    "label": 0
                },
                {
                    "sent": "Then the two norm which is in dashed line will be rotated towards these outliers.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you minimize the one norm, you minimize the sum of the absolute values of the differences between the points in the line.",
                    "label": 0
                },
                {
                    "sent": "Then you get something that almost ignores these two outliers and gives us this straight approximation, so that uses the fact that the one norm is much more robust against or can tolerate a few large errors.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I think you're all familiar with linear discrimination and support vector machines, so of course that's a very nice application of linear programming.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have two sets of points, Zion, why I, and you try to find a hyperplane that strictly separates the two.",
                    "label": 1
                },
                {
                    "sent": "Then you can write that as a set of linear inequalities.",
                    "label": 0
                },
                {
                    "sent": "So you have strict separation.",
                    "label": 0
                },
                {
                    "sent": "The variables are A&B, so the normal vector of the hyperplane and the offset.",
                    "label": 0
                },
                {
                    "sent": "But because it's homogeneous, you can replace the right hand side by one and then use a non strict inequality.",
                    "label": 0
                },
                {
                    "sent": "And you can write it like this.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the points are not separable.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "Try to find an hyperplane that approximately separates the two points by minimizing this kind of penalty.",
                    "label": 0
                },
                {
                    "sent": "It's an piecewise linear function of the variables A&B.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So for each point XI or why I have a penalty of 0 if the point is on the right side of the hyperplane and otherwise you have a penalty that's proportional to the.",
                    "label": 0
                },
                {
                    "sent": "The difference to the hyperplane so we can.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interpreters in non symmetric version of this.",
                    "label": 0
                },
                {
                    "sent": "So here you have a penalty on the residuals if you use the absolute value that's symmetric.",
                    "label": 0
                },
                {
                    "sent": "So suppose you actually wanted to minimize the Max, minimize the number of maximize the number of zeros in the vector.",
                    "label": 0
                },
                {
                    "sent": "So you really want to minimize the cardinality of this vector.",
                    "label": 0
                },
                {
                    "sent": "Then the ideal penalty function will be 0 at the origin and one for non zero values.",
                    "label": 0
                },
                {
                    "sent": "And then the sum of those penalty functions will be the number of non zero components.",
                    "label": 0
                },
                {
                    "sent": "But of course that's very non convex, so you can interpret this one norm as a convex approximation or replacement of this very minimize this.",
                    "label": 0
                },
                {
                    "sent": "Wander.",
                    "label": 0
                },
                {
                    "sent": "So in the classification problem we have something that's actually similar but non symmetric.",
                    "label": 0
                },
                {
                    "sent": "So in that case you want to minimize the slack between the.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hyperplane and the points if it's positive.",
                    "label": 0
                },
                {
                    "sent": "But they only care about the slack if it's positive.",
                    "label": 0
                },
                {
                    "sent": "If it's negative, you have a penalty.",
                    "label": 0
                },
                {
                    "sent": "So if you do this, you would use and.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Penalty function that looks like this that's zero for negative values and then linear and then you get.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exactly this so you can think of this also as a heuristic.",
                    "label": 0
                },
                {
                    "sent": "Similar to this one.",
                    "label": 0
                },
                {
                    "sent": "Regularization terms and sparse optimization values.",
                    "label": 0
                },
                {
                    "sent": "This penalty function as a heuristic for minimizing the number of misclassified points.",
                    "label": 1
                },
                {
                    "sent": "Exactly.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this these were some examples for linear programming.",
                    "label": 0
                },
                {
                    "sent": "Then the next class is quadratic programming, so in a quadratic programming problem you have, we keep the constraints linear and we have a quadratic convex cost function.",
                    "label": 0
                },
                {
                    "sent": "So then the control lines are ellipsoids.",
                    "label": 0
                },
                {
                    "sent": "It's no longer true that the optimum is necessarily at the boundary, or at an extreme point.",
                    "label": 0
                },
                {
                    "sent": "It could be the interior of the polyhedron.",
                    "label": 0
                },
                {
                    "sent": "It is still a convex problem.",
                    "label": 1
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One of the oldest applications of quadratic programming is actually the what today people would call a robust optimization problem.",
                    "label": 0
                },
                {
                    "sent": "And it's a linear programming problem with uncertain cost function.",
                    "label": 0
                },
                {
                    "sent": "And this application of this was the famous markovits portfolio optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that suppose you have an LP with coefficients CG&H.",
                    "label": 0
                },
                {
                    "sent": "But we assume C is not exactly known.",
                    "label": 0
                },
                {
                    "sent": "20 investment problem.",
                    "label": 0
                },
                {
                    "sent": "You would minimize or maximize.",
                    "label": 0
                },
                {
                    "sent": "In that case the return and X would be your portfolio investment or the different investments.",
                    "label": 0
                },
                {
                    "sent": "C transpose X would be the return and the coefficient of C would be the return on your investment for different investments.",
                    "label": 0
                },
                {
                    "sent": "But of course in that case the invest the returns are not exactly known.",
                    "label": 0
                },
                {
                    "sent": "And then one way to incorporate that in your optimization model is as follows.",
                    "label": 0
                },
                {
                    "sent": "You assume that C is a random variable.",
                    "label": 1
                },
                {
                    "sent": "And it was just assume that has a certain mean that's known and a covariance matrix that's known, but we don't assume anything about the distribution.",
                    "label": 0
                },
                {
                    "sent": "For simplicity, we'll assume that G&H is given, so these are exactly known.",
                    "label": 0
                },
                {
                    "sent": "And then of course, your optimal value becomes a random variable C transpose XX is deterministic, but C is a random variable and you have to decide what you mean by optimizing this random variable.",
                    "label": 0
                },
                {
                    "sent": "So one common definition is to minimize the weighted sum of the expected value.",
                    "label": 0
                },
                {
                    "sent": "Of your system, suppose X and then the variance of this random variable.",
                    "label": 0
                },
                {
                    "sent": "Random variable C, transpose X.",
                    "label": 0
                },
                {
                    "sent": "And then you can play with this coefficient, to give different weights to these two terms.",
                    "label": 0
                },
                {
                    "sent": "So in your investments application this would be the expected return.",
                    "label": 0
                },
                {
                    "sent": "If you want to maximize it at least or expected losses, and this would be a measure for the risk in your portfolio.",
                    "label": 0
                },
                {
                    "sent": "So in this case I mean these assumption, the expected return is linear in X, the variance is a quadratic functions.",
                    "label": 0
                },
                {
                    "sent": "We get a quadratic programming problem.",
                    "label": 0
                },
                {
                    "sent": "So in the 1950s, this was one of the first applications that motivated the development of quadratic programming.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You're also familiar with, again, the support vector classifiers.",
                    "label": 0
                },
                {
                    "sent": "As a general solved by quadratic programming, so suppose I have two hyperplanes defined like this in the normal vectors A&B.",
                    "label": 0
                },
                {
                    "sent": "Then it's easy to calculate the distance between these two hyperplanes and it turns out to be inversely proportional to the norm of the vector A.",
                    "label": 0
                },
                {
                    "sent": "In other words, if you normalize a, the distance between these two hyperplanes is just two.",
                    "label": 1
                },
                {
                    "sent": "And then if you have these two sets of points and assume that they are separable, then he can maximize the margin between these two hyperplanes by minimizing maximizing the distance or minimizing the norm of A and that's a quadratic programming problem, because it has a quadratic objective and linear coefficients in linear inequalities on A&B.",
                    "label": 1
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can combine this with the previous formulation where you allow points to be on the wrong side of the hyperplanes, and then you have this familiar tradeoff between the.",
                    "label": 0
                },
                {
                    "sent": "Inverse of the.",
                    "label": 0
                },
                {
                    "sent": "The margin of the two hyperplanes and then the classification error.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example of quadratic programming.",
                    "label": 0
                },
                {
                    "sent": "Suppose.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have a vector X that represents a signal, so here a corrupted signal.",
                    "label": 0
                },
                {
                    "sent": "Of time, for example.",
                    "label": 0
                },
                {
                    "sent": "And I would like to smooth this signals.",
                    "label": 0
                },
                {
                    "sent": "I'd like to get the smooth smooth signal, but also preserve the edges in the signal.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can do that by formulating an optimization problem, so X the corrupted signal is given.",
                    "label": 0
                },
                {
                    "sent": "Extract is the estimate of our smooth or reconstructed signal.",
                    "label": 1
                },
                {
                    "sent": "So we have a first objective that gives the distance between the reconstructed and the given signal.",
                    "label": 0
                },
                {
                    "sent": "And then I add a penalty function that.",
                    "label": 1
                },
                {
                    "sent": "In order to make the estimated X smooth, so penalty on variations of X hat.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And we can look at two penalty functions.",
                    "label": 0
                },
                {
                    "sent": "One is just to take the sum of the squares of successive values of XI.",
                    "label": 0
                },
                {
                    "sent": "Or I can take the sum of the absolute values of successive values of XI.",
                    "label": 0
                },
                {
                    "sent": "And then two cases I get a convex problem.",
                    "label": 0
                },
                {
                    "sent": "In the first case it's a simple quadratic problem in the variable, except in the second case it's has a quadratic term and then a sum of absolute values.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the solutions look quite different, so if you use a quadratic penalty function, you see that the results this singular smooth it, but the edges are also.",
                    "label": 0
                },
                {
                    "sent": "A smooth it.",
                    "label": 0
                },
                {
                    "sent": "There is a few.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The total variation or the one norm penalty function.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the sharp edges are preserved.",
                    "label": 0
                },
                {
                    "sent": "And that's very useful in image reconstruction, for example.",
                    "label": 0
                },
                {
                    "sent": "And that's obvious or clear why this happens.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, you think of the differences between these two penalties.",
                    "label": 0
                },
                {
                    "sent": "And those distributions of the residuals in a simple normal approximation.",
                    "label": 0
                },
                {
                    "sent": "So in this case you could think of a solution.",
                    "label": 0
                },
                {
                    "sent": "X and then plot the distribution of these differences I + 1 minus XI for the two solutions to quadratic and the total variation norm.",
                    "label": 0
                },
                {
                    "sent": "And then you see, because this is really the one norm of those differences, that this penalty function will be more robust against a few large values of the differences.",
                    "label": 0
                },
                {
                    "sent": "In the same way as robust regression is robust against outliers.",
                    "label": 0
                },
                {
                    "sent": "So in this case those sharp edges will be a few outliers or a few values of these differences that are much larger than the rest and the one norm actually will.",
                    "label": 0
                },
                {
                    "sent": "Told.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rates a few more of those large edges.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the do not.",
                    "label": 0
                },
                {
                    "sent": "So again, it is application of the difference in these two penalty functions, but in this case it's an application of the difference for large values of X, the same as the robust regression application.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So maybe I can skip geometric programming, so geometrical programming is an actual class of problems that are very non convex.",
                    "label": 0
                },
                {
                    "sent": "They find like this supposed to have a functional problem like this with inequality is an objective function that all have this.",
                    "label": 0
                },
                {
                    "sent": "Of products of variables X Rays to some powers Alpha I.",
                    "label": 0
                },
                {
                    "sent": "And there is no restriction on what these powers are.",
                    "label": 0
                },
                {
                    "sent": "They can be positive, negative.",
                    "label": 0
                },
                {
                    "sent": "They don't have to be integer.",
                    "label": 0
                },
                {
                    "sent": "So it's certainly not a polynomial function.",
                    "label": 0
                },
                {
                    "sent": "But we do restrict X to be positive.",
                    "label": 0
                },
                {
                    "sent": "And you know, people have given that a name polynomial because it looks a little bit like a polynomial.",
                    "label": 0
                },
                {
                    "sent": "But the important differences are the exponents can be don't have to be integers or positive, or it can be any real number, but restrict the access to be positive.",
                    "label": 0
                },
                {
                    "sent": "And then if you have a problem like this with opposing normal objective and posing your constraints, you call it a geometric programming problem.",
                    "label": 0
                },
                {
                    "sent": "So it's obviously not convex in X, because these are very anomalous functions, but there's a simple trick that makes it convex.",
                    "label": 0
                },
                {
                    "sent": "So if I make a change of variables at call log of XA new variable Y.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or equivalently, I.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replace X with an expansion of a new variable Yi.",
                    "label": 0
                },
                {
                    "sent": "Then I get.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This problem.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so each XI is.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replaced by the exponential of Yi, then the product of these exponentials becomes an exponential for some.",
                    "label": 0
                },
                {
                    "sent": "And I get a convex problem because we've seen that these functions are all convex.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the so next class of problems is called the 2nd order cone programming problem.",
                    "label": 0
                },
                {
                    "sent": "So it's defined like this.",
                    "label": 0
                },
                {
                    "sent": "We have a linear objective as in linear programming, but I know you have constraints of this form and each constraint is a constraint on the Euclidean norm of some linear function of X, and then we also include linear terms, so it's clearly includes linear programming as a special case, because if these AI and BI.",
                    "label": 0
                },
                {
                    "sent": "Coefficients have dimension 0, then this is just a linear inequality.",
                    "label": 0
                },
                {
                    "sent": "But it's it's also convex because norms are convex, so this is a convex constraint on X.",
                    "label": 0
                },
                {
                    "sent": "And it's called the 2nd order.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Horn problem.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reasons that we actually will see tomorrow.",
                    "label": 0
                },
                {
                    "sent": "That are not very important here, so this is a very basic definition.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can interpret.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This as a robust linear program.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "And by robust linear programming problem I mean the following.",
                    "label": 0
                },
                {
                    "sent": "Suppose I take an LP with coefficient cost function C, transpose X and then M inequality is a transpose X -- B I.",
                    "label": 0
                },
                {
                    "sent": "And then in the robust optimization, people are interested in.",
                    "label": 0
                },
                {
                    "sent": "Incorporating in the definition or the model for the optimization problem, uncertainty in the coefficients of the data.",
                    "label": 0
                },
                {
                    "sent": "So in an LP, the factor cost effective C could be uncertain.",
                    "label": 0
                },
                {
                    "sent": "The coefficients A or BI could be uncertain.",
                    "label": 0
                },
                {
                    "sent": "And then if you simply ignored the uncertainty in the data and optimize, assuming that those are the exact values.",
                    "label": 0
                },
                {
                    "sent": "Then the unfortunately solution X can be sometimes very sensitive to small changes in the coefficients.",
                    "label": 0
                },
                {
                    "sent": "And that's true in general, but certainly for optimization, because the solution typically lies on the boundary of the feasible set.",
                    "label": 0
                },
                {
                    "sent": "So small changes in the coefficient can make your X feasible optimal X infeasible.",
                    "label": 0
                },
                {
                    "sent": "And that's if you like an extreme form of sensitivity, so it's often important to incorporate in your model some measure for the OR some other for the uncertainty in the data.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "One way to do this in linear programming is to do this.",
                    "label": 0
                },
                {
                    "sent": "Suppose so here for simplicity.",
                    "label": 0
                },
                {
                    "sent": "Assume that the AI's are random.",
                    "label": 0
                },
                {
                    "sent": "So BINC are given.",
                    "label": 0
                },
                {
                    "sent": "I'll assume some distribution AI in this case that it's normal.",
                    "label": 0
                },
                {
                    "sent": "And with a certain given mean, the nominal value of AI and a given covariance.",
                    "label": 0
                },
                {
                    "sent": "And then in self saying 8 transpose X doesn't be I. I require that X satisfies that inequality with at least a certain probability, for example 90%.",
                    "label": 0
                },
                {
                    "sent": "So that's called a chance constrained in stochastic optimization.",
                    "label": 0
                },
                {
                    "sent": "In general, stance constraints are actually very difficult constraints, But in this simple case it's actually something you can easily.",
                    "label": 0
                },
                {
                    "sent": "Incorporate and solve as a second order cone problem.",
                    "label": 0
                },
                {
                    "sent": "And this is an example for some values, so have an LP.",
                    "label": 0
                },
                {
                    "sent": "And this is also the nominal value of our LP.",
                    "label": 0
                },
                {
                    "sent": "So if I now assume that the normal vectors of each of these inequalities is a random vector.",
                    "label": 0
                },
                {
                    "sent": "With a symmetric distribution normal distribution.",
                    "label": 0
                },
                {
                    "sent": "Then and I have a point X that somewhere on the hyperplane.",
                    "label": 0
                },
                {
                    "sent": "For example this hyperplane.",
                    "label": 0
                },
                {
                    "sent": "And for the normal value or the mean of the normal vector AI?",
                    "label": 0
                },
                {
                    "sent": "Then that vector will also in 50% of the cases with 50% probability, will still be feasible.",
                    "label": 0
                },
                {
                    "sent": "Even if I.",
                    "label": 0
                },
                {
                    "sent": "If a fair reason this distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you require this with 50% probability.",
                    "label": 0
                },
                {
                    "sent": "The Robust's or the solution set for this feasible set for this M chance constraints is still the original normal value.",
                    "label": 0
                },
                {
                    "sent": "But if you take a different value to 50%, it's very different.",
                    "label": 0
                },
                {
                    "sent": "So if I require that the inequality is satisfied with the probability 90%.",
                    "label": 0
                },
                {
                    "sent": "Then these lines become curved, so this instead of a hyperplane.",
                    "label": 0
                },
                {
                    "sent": "Now I have this curve.",
                    "label": 0
                },
                {
                    "sent": "Which is actually the level curve where the probability of satisfying that inequality is exactly 90%.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So you have one of these for each of the inequalities and the feasible set shrinks to something that's smaller and convex.",
                    "label": 0
                },
                {
                    "sent": "So that's the feasible set for these M chance constraints in equalities.",
                    "label": 0
                },
                {
                    "sent": "If it is 90%.",
                    "label": 0
                },
                {
                    "sent": "If it is less than 50%, it's actually the other way around.",
                    "label": 0
                },
                {
                    "sent": "The we get a larger feasible set.",
                    "label": 0
                },
                {
                    "sent": "And these level curves of constant probability curve and the other have the other orientation.",
                    "label": 0
                },
                {
                    "sent": "And then the solution set becomes non convex.",
                    "label": 0
                },
                {
                    "sent": "And this problem becomes very difficult because if you have a solution set like this, even if the curvature is not very pronounced, then you can easily have any minimize the linear function over this set.",
                    "label": 0
                },
                {
                    "sent": "Then you can easily have multiple local minima that are not global.",
                    "label": 0
                },
                {
                    "sent": "So we see something interesting here that if you have these chance constraint problems.",
                    "label": 0
                },
                {
                    "sent": "If it is greater than 50%, we have a convex feasible set.",
                    "label": 0
                },
                {
                    "sent": "If it's less than 50%, it's not convex.",
                    "label": 0
                },
                {
                    "sent": "So what we can actually in this case, if we assume that they are normal and we know the mean and the covariance, we can actually calculate this probability from.",
                    "label": 0
                },
                {
                    "sent": "Probability theory and you can write this.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Constraint in this form so you have the nominal value of the inequality.",
                    "label": 0
                },
                {
                    "sent": "That's a high bar and then this extra term involves the cumulative density function of the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "This function 5 teeth between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And then that's multiplied with the two norm of the square root of the covariance times X.",
                    "label": 0
                },
                {
                    "sent": "So this tells us actually this makes sense because it tells us that if Atom is largest closed in 90%.",
                    "label": 0
                },
                {
                    "sent": "Then, in order to make X feasible without high probability.",
                    "label": 0
                },
                {
                    "sent": "It's not sufficient to satisfy the inequality for the nominal value of AI, but has to satisfy it with a certain slack or a certain margin.",
                    "label": 0
                },
                {
                    "sent": "That depends on the value of the margin required.",
                    "label": 0
                },
                {
                    "sent": "Margin depends on the value of data.",
                    "label": 0
                },
                {
                    "sent": "And on the covariances, and actually more precisely the product between X and the covariance.",
                    "label": 0
                },
                {
                    "sent": "And this also explains why you have this transition between editor at 50%, because this coefficient here the universe of Etta, under this cumulative density function changes sign for 50% of ETA is creating a 50%, and that's a positive coefficient.",
                    "label": 0
                },
                {
                    "sent": "We get a convex constraint because we have normal to positive coefficients on the less than or equal side of the inequality.",
                    "label": 0
                },
                {
                    "sent": "If data is less than 50%, then this coefficient becomes negative & is wrong.",
                    "label": 0
                },
                {
                    "sent": "We have the negative term on the wrong side of the inequality.",
                    "label": 0
                },
                {
                    "sent": "So that's the stochastic formulation of the.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Robust LP we can actually.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give deterministic interpretation to exactly.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same problem.",
                    "label": 0
                },
                {
                    "sent": "So in a distant Mystic interpretation.",
                    "label": 0
                },
                {
                    "sent": "We make we don't make any assumptions on the distribution of AI.",
                    "label": 0
                },
                {
                    "sent": "But we impose a certain set of allowed allowable values of AI.",
                    "label": 0
                },
                {
                    "sent": "So in this case, would assume that the eyes are unknown, but are known to be in a certain ellipsoids with the center AI bar and a certain shape that is determined by this matrix P. And then the robust version of this inequality will be that we require that X is feasible for all values of AI.",
                    "label": 0
                },
                {
                    "sent": "Actually you can.",
                    "label": 0
                },
                {
                    "sent": "Well so if you work this out, so in order to write this more explicitly, you would have to find a maximum of AI, transpose X for a given X over this ellipsoid, and then you find an expression that exactly similar to this previous one.",
                    "label": 0
                },
                {
                    "sent": "So this inequality is satisfied for all values of AI in the ellipsoid if X satisfies this second order cone constraint.",
                    "label": 0
                },
                {
                    "sent": "So again, the first term is just a nominal value says that X satisfies it for the central point of the ellipsoid, and then we have Euclidean norm term that involves the product of X&PI transpose.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So mathematically, it's exactly similar to this constraint.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But with a different interpretation.",
                    "label": 0
                },
                {
                    "sent": "Right and kind of see that in the robust version of the LP.",
                    "label": 0
                },
                {
                    "sent": "It's not sufficient for X to be feasible for the normal value of a. I add an extra margin and the value of that margin actually depends on the size of X, and more precisely the product of X NPI.",
                    "label": 0
                },
                {
                    "sent": "Sexier.",
                    "label": 0
                },
                {
                    "sent": "So those are two examples of robust optimization problems.",
                    "label": 1
                },
                {
                    "sent": "We see that robust LP turns into a second order cone problem.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then there are some other examples of nonlinear constraints you can write as second order cone constraints.",
                    "label": 0
                },
                {
                    "sent": "So this one will be as interesting if you have excess pose X for a vector X.",
                    "label": 0
                },
                {
                    "sent": "Is less than or equal than a product of Y&Z?",
                    "label": 0
                },
                {
                    "sent": "And Y&Z are restricted to be non negative, so that's not an ellipse ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "It's called out in hyperbolic constraints, so this is a quadratic inequality, but the Hessian of the inequality has is not positive definite.",
                    "label": 0
                },
                {
                    "sent": "But because of this restriction, it's still a convex set and you can write as a second order constrained by this equivalence you have a two norm of this two vector.",
                    "label": 0
                },
                {
                    "sent": "That of this not two vector but this vector.",
                    "label": 0
                },
                {
                    "sent": "Involves the vector X and then the scalar y -- Z Y plus Z on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "So that's the 2nd order cone constraint, and it's equivalent to this.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some other non obvious constraints that can be written as second order constraints are powers, constraints on powers of X.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have X to the 1.5 less than T. With a variable tiannan, unlike the variable X, then you can actually write it as a second order cone constraint, and that's not obvious.",
                    "label": 0
                },
                {
                    "sent": "But this is a short proof.",
                    "label": 0
                },
                {
                    "sent": "And that's actually true for any rational power of XX to the P. For any rational P can be written as a.",
                    "label": 0
                },
                {
                    "sent": "2nd order cone constraints.",
                    "label": 0
                },
                {
                    "sent": "And it's also true for negative powers.",
                    "label": 0
                },
                {
                    "sent": "For example, X 2 -- 3 can be written as a second order cone constraint, and again that's true for extra DP with a negative rational.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so then the last topic will be semidefinite programming.",
                    "label": 0
                },
                {
                    "sent": "That's the most general of these problem classes that will discuss.",
                    "label": 0
                },
                {
                    "sent": "So again, it's and we have a linear objective of some in vector variable.",
                    "label": 0
                },
                {
                    "sent": "And the constraint has this form, so the matrices A&B are all symmetric of the same dimension.",
                    "label": 0
                },
                {
                    "sent": "And the constraint is that this linear combination of the matrices A must be less than or equal to B as a matrix inequality, so B minus this left hand side must be positive semidefinite.",
                    "label": 0
                },
                {
                    "sent": "After that means that you have as a constraint and symmetric matrix B -- A of X and all the entries of the matrix are linear in the variables X.",
                    "label": 0
                },
                {
                    "sent": "And then the constraint is that that matrix must be positive semidefinite or negative semidefinite.",
                    "label": 0
                },
                {
                    "sent": "That's called a semidefinite programming problem.",
                    "label": 0
                },
                {
                    "sent": "And it's interesting because it includes many nonlinear constraints that special.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is so.",
                    "label": 0
                },
                {
                    "sent": "This is a geometrical interpretation and just matrices of order 2.",
                    "label": 0
                },
                {
                    "sent": "So that's the semidefinite cone of matrices of order two.",
                    "label": 0
                },
                {
                    "sent": "So you have three elements in the matrix, and that's the cone of matrices.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That are positive semidefinite.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Definite programming is useful because it turns out that if you take intersection of the semidefinite cone and high dimensions.",
                    "label": 0
                },
                {
                    "sent": "With hyperplanes or affine sets in different directions, you can represent very wide variety of nonlinear convex constraints as intersections of the positive semidefinite cone with affine sets.",
                    "label": 0
                },
                {
                    "sent": "Have you see some examples?",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, if you want suppose you want to minimize the maximum eigenvalue of a symmetric matrix.",
                    "label": 0
                },
                {
                    "sent": "You have a matrix A of X, it's symmetric.",
                    "label": 0
                },
                {
                    "sent": "All the entries are linear in the variables X and then you want to maximize the maximum eigenvalue, minimize the maximum eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So we've seen that's the convex function of X.",
                    "label": 0
                },
                {
                    "sent": "You know, very short proof that that's convex.",
                    "label": 0
                },
                {
                    "sent": "That doesn't tell us how to actually minimize it, but it can minimize it if you recognize it at its can be written as a semi definite programming problem.",
                    "label": 0
                },
                {
                    "sent": "So here we do a trip trick that's very similar to the way we used in L1 norm and L Infinity normalization.",
                    "label": 0
                },
                {
                    "sent": "We introduce a new variable T and then minimize the subject to this matrix inequality.",
                    "label": 0
                },
                {
                    "sent": "That says that the Matrix A is less than three times an identity matrix.",
                    "label": 0
                },
                {
                    "sent": "And that's equivalent to this, because this constraint is equivalent to saying that T is created on the maximum eigenvalue of a.",
                    "label": 0
                },
                {
                    "sent": "So if I minimize the subject to this, it's the same as minimizing the maximum value.",
                    "label": 0
                },
                {
                    "sent": "So I convert a very.",
                    "label": 0
                },
                {
                    "sent": "A convex nondifferentiable optimization problem in X and the linear.",
                    "label": 0
                },
                {
                    "sent": "Semidefinite optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example or matrix norm.",
                    "label": 0
                },
                {
                    "sent": "Suppose now a is no longer doesn't have to be symmetric or square, but it's just a rectangular matrix.",
                    "label": 0
                },
                {
                    "sent": "Then I can define the two norm maximum single value normal.",
                    "label": 0
                },
                {
                    "sent": "We know it's convex because all norms are convex.",
                    "label": 0
                },
                {
                    "sent": "Or another interesting norm is the sum of the singular values, which is known as the nuclear norm.",
                    "label": 0
                },
                {
                    "sent": "And so both are convex, complicated non differentiable functions of X.",
                    "label": 0
                },
                {
                    "sent": "But they can be minimized by solving an SDP, introducing new variables T and in this case U&V and then minimizing a linear function subject to a linear matrix inequality.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe can.",
                    "label": 0
                },
                {
                    "sent": "Do this example and then finish.",
                    "label": 0
                },
                {
                    "sent": "So semidefinite optimization is useful because many convex problems can be written as convex constraints can be converted into.",
                    "label": 0
                },
                {
                    "sent": "Is the constraints.",
                    "label": 0
                },
                {
                    "sent": "It's also often used in relaxations for difficult combinatorial problems.",
                    "label": 0
                },
                {
                    "sent": "So a simple example would be this.",
                    "label": 0
                },
                {
                    "sent": "Suppose I want to minimize the linear at least squares problem, but with constraints that variables X must be minus one of plus one.",
                    "label": 0
                },
                {
                    "sent": "And I can write it as a simple quadratic equality constraint on X, so that's a very nonconvex problem.",
                    "label": 0
                },
                {
                    "sent": "An in general for general A&B.",
                    "label": 0
                },
                {
                    "sent": "It's also very difficult to solve because of this integer constraint.",
                    "label": 0
                },
                {
                    "sent": "So we can use semidefinite programming to solve the relaxation of this problem to compute lower bounds on this problem.",
                    "label": 0
                },
                {
                    "sent": "And also as a heuristic to find sub optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "And the reasoning is as follows.",
                    "label": 0
                },
                {
                    "sent": "Suppose I take this.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The squares function and expand it.",
                    "label": 0
                },
                {
                    "sent": "Then I get this.",
                    "label": 0
                },
                {
                    "sent": "So I have a quadratic term extensible, say transpose X linear term constant.",
                    "label": 0
                },
                {
                    "sent": "Suppose then I introduce a new variable.",
                    "label": 0
                },
                {
                    "sent": "I called the vector XX transpose this outer product Y and I use Y as a new variable.",
                    "label": 0
                },
                {
                    "sent": "Then I can rewrite the correct term as expose A transpose X as a trace of a transpose a * Y.",
                    "label": 0
                },
                {
                    "sent": "Just buy properties of traces and products.",
                    "label": 0
                },
                {
                    "sent": "And now I and I can also replace this constraint on XI squared.",
                    "label": 0
                },
                {
                    "sent": "By a constraint on the diagonal of why?",
                    "label": 0
                },
                {
                    "sent": "Because XI squared will be exactly the diagonal elements of why?",
                    "label": 0
                },
                {
                    "sent": "So now I've made the.",
                    "label": 0
                },
                {
                    "sent": "Constraint the objective linear.",
                    "label": 0
                },
                {
                    "sent": "The second constraint is linear.",
                    "label": 0
                },
                {
                    "sent": "But the sector the first constraint is still very nonconvex.",
                    "label": 0
                },
                {
                    "sent": "It says that why is actually equal to this rank one matrix.",
                    "label": 0
                },
                {
                    "sent": "And then to get.",
                    "label": 0
                },
                {
                    "sent": "But it's still equivalent to this problem.",
                    "label": 0
                },
                {
                    "sent": "Has the same optimal value, and it's also equally difficult.",
                    "label": 0
                },
                {
                    "sent": "So then you obtain the relaxation by replacing this equality.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Strained by an inequality.",
                    "label": 0
                },
                {
                    "sent": "And then if you replaced by an inequality, can write this constraint while creating are equal to XX transpose as a linear matrix inequality and then the problem becomes an SDP.",
                    "label": 0
                },
                {
                    "sent": "That you can solve.",
                    "label": 0
                },
                {
                    "sent": "And it's a relaxation because we loosened this constraint, we replaced the original constraint by a weaker constraint that's easier to satisfy.",
                    "label": 0
                },
                {
                    "sent": "So the optimal value will be lower than the optimal value of the original problem.",
                    "label": 0
                },
                {
                    "sent": "So you can solve this SDP.",
                    "label": 0
                },
                {
                    "sent": "Quite easily it gives you a lower bound on the optimal value.",
                    "label": 0
                },
                {
                    "sent": "And then you can also try to obtain from the optimal solution of the SDP from Y and the optimal X and the SDP.",
                    "label": 0
                },
                {
                    "sent": "A sub optimal solutions of the original problem and one popular method for doing that is to interpret Y&X.",
                    "label": 0
                },
                {
                    "sent": "As the mean X and covariance or the.",
                    "label": 0
                },
                {
                    "sent": "Second moment of in the distribution.",
                    "label": 0
                },
                {
                    "sent": "And then, for example, a normal distribution and then generates random vectors from that distribution that you computed by computing X&Y and then rounding the set.",
                    "label": 0
                },
                {
                    "sent": "Just one heuristic to obtain sub optimal solutions from the solution of this.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relaxation and this is an example of.",
                    "label": 0
                },
                {
                    "sent": "Problem with.",
                    "label": 0
                },
                {
                    "sent": "3000 variables this is the lower bound we obtained from the SDP.",
                    "label": 0
                },
                {
                    "sent": "If you just took the Boolean least squares problem and solve it as a least squares problem without integer constraints, and then rounded the square solution, you get this value.",
                    "label": 0
                },
                {
                    "sent": "Just.",
                    "label": 0
                },
                {
                    "sent": "Father here.",
                    "label": 0
                },
                {
                    "sent": "And then this distribution is obtained by.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just generating a large number of suboptimal solutions using this randomized rounding.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we generate solutions and then we get sub optimal solutions like this.",
                    "label": 0
                },
                {
                    "sent": "So we know that the true optimal value is somewhere between one and this left edge.",
                    "label": 0
                },
                {
                    "sent": "And from the SDP we get certainly better solution than by simply using least squares and rounding the result.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Maybe I can stop here and finish the last few slides tomorrow.",
                    "label": 0
                }
            ]
        }
    }
}