{
    "id": "2b3ptg2bpfxc2kewgsrksvs7j6qzyuk2",
    "title": "Building an automatic statistician",
    "info": {
        "author": [
            "Zoubin Ghahramani, Department of Engineering, University of Cambridge"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Digital Signal Processing",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Information Theory",
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/sahd2014_ghahramani_automatic_statistician/",
    "segmentation": [
        [
            "So I will talk about something we've been working on over the last couple of years that I'm very, very excited about and this is joint work with James Lloyd David.",
            "Do we know Roger Gross and Josh Tenenbaum?",
            "And our motivation is basically the."
        ],
        [
            "You know, as we all know, everybody is awash with data.",
            "There's a huge demand for data scientists, all of you out there getting job offers all the time.",
            "They're not enough of us and you out there.",
            "And a lot of fields rely on experts, statisticians, machine learning, researchers and data scientists, so.",
            "So why don't we build a tool that will help us do automatic statistics or automatic data scientist data science?",
            "So what do I mean by that?",
            "Well, let's first of all think a little bit about maybe what a statistician might do OK?"
        ],
        [
            "So here is what we're trying to do, so we're trying to make the following process that S statistician might follow when encountering a new data set.",
            "So.",
            "The data set is here.",
            "The statistician says looking at the data set now, we haven't actually included any actual knowledge about background domain information here, so it's just imagined statisticians just looking at the data and trying to figure out what's going on the data.",
            "Now, this statistician will have some language of models that they might know about some set of modeling tools they might know about and ways of composing those modeling tools.",
            "And then looking at the data.",
            "The statistician might start proposing some simple models, then search over a bunch of different models until there's a model that the statistician is happy with, and then what what you want to do this well, you can use that model to make predictions on new data.",
            "Decision might be working for a client, so might want to produce a sort of report about the data and the model.",
            "So translate the model into some sort of written report and then importantly also after learning the model from data you'd like the statistician to do some model checking or model criticism to make sure that there are obvious things the model has failed at doing so.",
            "This is the kind of pipeline that we're trying to.",
            "Reproduce and we're going to.",
            "I'm just going to describe the different components of this."
        ],
        [
            "OK, so our real motivation is the following.",
            "What we really want to do is provide a set of tools for understanding data that require minimal expert input.",
            "Now, this isn't just a big software project, this is actually uncovering a huge number of challenging research problems for how to automate influence on all sorts of different kinds of data for model construction and comparison challenges in data visualization, an model interpretation.",
            "And I generally think this is a very nice way of trying to advance the field of machine learning to automate the process of statistical data analysis OK?"
        ],
        [
            "So here the ingredients of our automatic statistician where we'd like to have is not just a small set of models.",
            "Not like you know 5 or 10 different models, But we'd like to have an open ended language of models expressive enough to capture real world phenomena and to capture a lot of the techniques that statisticians might actually use.",
            "And what I mean by language of models will be more clear a bit later on, But this has to be something compositional where you can build more complex models out of simpler models.",
            "Then we need a search procedure to efficiently explore this language of models.",
            "We need a principled method for evaluating models, trading off complexity and fit to the data, and we need a procedure to automatically explain the model.",
            "Something that's been hugely neglected in our community.",
            "I think in other words, something that will make the assumptions of the model explicit in a way that's intelligible to somebody who is numerate but not necessarily a statistician."
        ],
        [
            "So here is a preview of the kind of thing I'm going to show you in much more detail, and I'll give you tasters of a few other things.",
            "So here is an example of a data set, and then this is a time series data set.",
            "This happens to be airline passengers from the late 40s to the early 60s at a monthly at monthly intervals.",
            "This is the model that's fit by the automatic statistician.",
            "Unfortunately, there are error bars around this and you can't see it after the dashed line.",
            "This is the extrapolation from the automatic statistician and what the automatic session statistician does is.",
            "It produces a report where a small snippet of the executive summary of the report is shown here.",
            "Um?",
            "It says he or she says therefore out of components that have been identified in the data, a linearly increasing function in approximately periodic function with a period of 1.0 years and with linearly increasing amplitude, a smooth function and uncorrelated noise with linearly increasing standard deviation.",
            "So that's this executive summary of what's going on in the data, and that process was completely automated and I'll show you in a lot more detail how we did that."
        ],
        [
            "So let's look at each component one at a time.",
            "The language of models.",
            "So we're going to look the example.",
            "I'm going to give you is regression models and it."
        ],
        [
            "Particular, So what do I mean by that?",
            "We're trying to learn functions F from some input domain X to some outputs Y.",
            "From input, output pairs and our language should include some simple parametric forms of models.",
            "Things like Linears, polynomials, exponential functions, etc, as well as as well as functions specified by high level properties.",
            "Things like smooth functions, periodic functions, etc.",
            "And we'd like our inference to be tractable for all the models in our language, so we can explore a very large space of models."
        ],
        [
            "With the two, we're going to use, here is Gaussian process.",
            "So Gaussian processes are distributions over functions such that any finite subset of function evaluations F1 through XF of X1 through F of XM.",
            "This is an M dimensional vector has a joint multivariate Gaussian distribution and a Gaussian process is completely specified by amine function Anna covariance or kernel function.",
            "The mean tells us the mean of the function of the covariance tells us.",
            "How similar you could think F of X is going to be to F at some other point X prime?",
            "How how much these two covary and we're going tonight it denoted as F is drawn from a GPU with mean function mu and covariance or kernel K."
        ],
        [
            "Now if we want a language of Gaussian processes, you know or do we have to worry about the mean function is very common.",
            "You find almost in the first line under a lot of papers that do Gaussian process.",
            "The assumption to have a zero mean function.",
            "So let's just uncover why that might be sensible.",
            "So imagine that we had some mean.",
            "Well, we had a Gaussian process with some mean mu of X, but we didn't know how much of that mean we wanted to incorporate.",
            "So let's scale that mean by some constant, some scalar A.",
            "Now, if we simply have Gaussian uncertainty about the amount of A to put in here, then that Gaussian process with this particular scaled mean function is equivalent to a Gaussian process with zero mean annanu covariance function.",
            "So that unknown mean can simply be wrapped into the covariance function of a Gaussian process.",
            "So for that technical reason, our language for regression models is simply going to be.",
            "A language of kernels of Gaussian process.",
            "OK."
        ],
        [
            "Now what do I mean by language?",
            "Well, language, for example, human language is composed of words and you can compose words together in certain valid ways to produce valid grammatical sentences.",
            "And that's what we're going to do with kernels.",
            "So what we're going to have are some small number of base kernels.",
            "And we're going to compose these, so let me describe the base kernels.",
            "There's very commonly used Gaussian or squared exponential or exponentiated quadratic kernel different names for the same thing, and that corresponds to smooth functions OK?",
            "So here are two draws of functions with that kernel.",
            "Periodic kernels correspond to periodic functions.",
            "Linear kernels correspond to linear functions, so these are two samples from a Gaussian process with linear kernel.",
            "Constant kernels correspond to constant functions, and the white noise kernel corresponds to additive Gaussian noise.",
            "OK, so these are the basic atoms or elements of our language, and then we have composition rules.",
            "And our composition rules are addition and multiplication."
        ],
        [
            "And we have a couple more as well, but let me describe addition and multiplication.",
            "So if you multiply linear kernel by linear kernel, you get a quadratic kernel.",
            "So by implication we have all polynomials in there.",
            "OK, by simply multiplying in linear's, if we multiply a ^2 exponential Anna periodic for example, the kinds of functions that you get are locally periodic, they're not perfectly periodic.",
            "The period changes as you.",
            "Move further and further away.",
            "That's what multiplying squared exponential by periodic does.",
            "These are two samples from that.",
            "When you see these wiggles are not identical as you move along the change if you."
        ],
        [
            "Add linear and periodic.",
            "For example, you get periodic functions plus linear trends.",
            "If you add squared, exponential and periodic you get you know some smooth trend plus some periodicity.",
            "OK, so of course we can compose these."
        ],
        [
            "In various ways, and in particular, I'm going to talk about applications for the most Part 2 Time series models and in time series something that we also want to capture is changepoints, so time series where something is going on and then suddenly it changes and something else is going on afterwards.",
            "So here is a basic idea for how you model change points is if F1 is drawn from a Gaussian process with kernel K1F2 is drawn from a Gaussian process with kernel K2.",
            "You could take a sigmoid function, some sort of logistic function, and just mix together F1 and F2 switching at some point, which I haven't written down explicitly.",
            "And the picture for that is down here.",
            "You could get a function that very smoothly switching to a function of berries quickly functioned very smoothly.",
            "Switching to a periodic function period of one kind of.",
            "Switching to another kind of.",
            "Etc.",
            "And this operation of having a change point simply corresponds to a new kernel, so this is in the valid space of our language of kernels.",
            "This is the changepoint operation.",
            "This kernel K is the change point of K1 and K2 at some particular location.",
            "OK."
        ],
        [
            "Now what can we do with these elements?",
            "Well, we can do it turns out quite a lot of things we can do that sort of traditional Gaussian process smoothing.",
            "We can do linear regression.",
            "We can do a form of multiple kernel learning.",
            "We can mimic something called the trend cyclical irregular model doing some kind of creative composition, you know.",
            "A variety of different kinds of things that people do as standard for time series.",
            "OK, so now."
        ],
        [
            "Talk a little bit about this search.",
            "Um?"
        ],
        [
            "So our language is defined as an arbitrary composition of these five based kernels.",
            "With these three operators, the space of this language is open ended and can have a quite a high branching factor, so it's important to have a good search algorithm and as a first step we're going to do is simply greedy search which starts with the base kernels and then expands around those.",
            "Group things that it finds.",
            "In analogy, who with how, maybe a statistician might be model building.",
            "Start out with some simple models and then pick the best one and think about how you might want to expand that."
        ],
        [
            "So here is an illustration of that.",
            "This is with a slightly different grammar, so we had a particular kernel called the rational quadratic in here, but the picture is basically the same here some time series.",
            "This is a very famous data set.",
            "The Maunalua Keeling Curve used in climate science, CO2 concentrations on top of Mount Aloa as a function of time.",
            "Here is the initial fit at the first level and then we can see is the interpolation is great.",
            "Extrapolation is lousy.",
            "You can't really see the error bars, but they're pretty huge here.",
            "OK, so then it says OK, rational quadratic was good.",
            "Let me expand that.",
            "Oh periodic, less rational quadratic seems pretty good.",
            "The interpolation is a little better.",
            "The extrapolation also seems sensible.",
            "But can it do better than that?",
            "So then it says, well, actually there seems to be some long term trend modeled by doing squared exponential times periodic plus rational quadratic.",
            "Note that the words are being composed together into more and more complicated sentences, so that's what it gets here and then."
        ],
        [
            "In you know this is what it ends up with at the end, squared exponential plus squared exponential times periodic plus rational quadratic, and that's the final model that it builds."
        ],
        [
            "OK, how does it actually evaluate models to see what's a good model and what's not?",
            "A good model?",
            "So after."
        ],
        [
            "Using a new model with this kernel parameters, we we simply optimize those kernel parameters using conjugate gradients.",
            "OK, now for each optimized model where we do is we evaluate the model evidence.",
            "The marginal likelihood.",
            "The nice thing about a Gaussian process if you know about them is that you integrate out the whole function space analytically, 'cause it's easy.",
            "It's a Gaussian process, so you compute an exact marginal likelihood.",
            "But now we because we did optimization of the kernel hyperparameters, we simply penalize that log marginal likelihood.",
            "By this BIC penalty, which is number of kernel parameters divided by two log N. OK, so that's the search criteria that we use."
        ],
        [
            "And that's it.",
            "That's the sort of model building.",
            "Now what about the translation?",
            "This is perhaps maybe the the most novel and different part of this work, I would say.",
            "So we want to translate this model into a report about the data."
        ],
        [
            "Now the problem is the search can produce very complicated models.",
            "But the good news is that these kernels can be decomposed into a form which is a sum of product form.",
            "And a sum of kernels corresponds to summer functions, and therefore we can describe each product of kernels separately in this sum of product form, and I will describe this in a minute.",
            "Now each kernel is in a product, modifies the model in a consistent way.",
            "This isn't necessarily obvious, but you'll see that in a minute there for each kernel roughly corresponds to an adjective in the text that we're going to produce at the end, OK?"
        ],
        [
            "So here is an example.",
            "Suppose our search finds the following kernel.",
            "Rather complicated.",
            "The change point here can be converted into a sum of products form, so this is a change point between a constant in the periodic.",
            "You can write it as constant times some function, plus periodic times some other sigmoid function.",
            "OK, then multiplication can be distributed over addition.",
            "So let's take this square exponential kernel here and distribute that over that whole expression and we get this expression here.",
            "Then we can apply simplification rules.",
            "So for example squared exponential times, white noise times linear.",
            "Well this gets absorbed into this, which is equivalent to white noise times linear, OK, squared, exponential times constant times.",
            "This change point is just squared exponential times a change point, etc.",
            "So this is the expression that we get at the end."
        ],
        [
            "And now this is in what form this is in the sum of product form.",
            "So the good thing is that if F1 is drawn from a Gaussian process and F2 is drawn from a Gaussian process, then F1 plus F2 is drawn from a Gaussian process with kernel K1 plus K2.",
            "So thinking of that logic in reverse, we have if we have a sum of kernels where we can do is, we can describe properties of F1 and properties of F2, like for example a trend.",
            "Plus a high frequency oscillation or something like that.",
            "Rick."
        ],
        [
            "OK, so here's how that works.",
            "So imagine we have an expression like this.",
            "This kernel is just the periodic function.",
            "We say periodic function and these are just four samples of what that would look like.",
            "If it's squared exponential times periodic, we use the phrase approximately periodic function.",
            "If it's squared exponential times periodic times linear, we might use the phrase approximately periodic function with linearly growing amplitude.",
            "OK. And then there's a change point.",
            "So here we have approximately periodic function with linearly growing amplitude until 1700, and that's a phrase that we use in our report to describe what the model is doing, and that's what we look like with 1700 being so somewhere here maybe.",
            "OK."
        ],
        [
            "So now what do these reports look like?",
            "So again, we come back to this example.",
            "Now you can see is the process that we did here for these time series is relearn the model, then we identified 4."
        ],
        [
            "Sums the sum of 4 product components and these are the the four product components that we ended up with in our best model by the BICS penalized marginal likelihood and each one has been translated into a phrase in the order in order of these are described in order of importance in order of importance corresponds to how much of the signal is being explained by each component so.",
            "If I look at this by I, I would hope that I would see that there's a linearly.",
            "There's some sort of increasing function.",
            "Maybe it's linear, maybe it's not, but there's some sort of increasing function and the model indeed comes up with that as the first thing that it notices.",
            "Then it says on top of that there is periodicity which you can see when you actually connect the dots with a period of 1.0 years and linearly increasing amplitude, and then these other components.",
            "So let's just look at the."
        ],
        [
            "In more detail, so here's the Pacira for componentone.",
            "Sorry, error bars are not showing up because we didn't use a dark enough shade of blue for the projector, but they're all in the papers.",
            "So here is the first component superimposed on the data."
        ],
        [
            "And now this is a bit more text that's actually in one of these reports.",
            "This is for that airline passenger data.",
            "The automatic cessation says this component is approximately reality with period 1.5 years across periods of shape of this function values very smoothly.",
            "The amplitude of the function increases linearly.",
            "The shape of this function within each.",
            "Has a typical N scale of six weeks, so that corresponds to the wiggling of the function within a year."
        ],
        [
            "OK, and then this is the third component.",
            "This sort of trend of at a higher length scale of eight months."
        ],
        [
            "And then this is noise with linearly increasing amplitude.",
            "I don't know if you could.",
            "I don't think you can see that the error bars are increasing there."
        ],
        [
            "OK, and then here's another data set.",
            "This is some spot data.",
            "And this is sunspots from the 1600 to the 2000s, measured yearly.",
            "And there's some, you know, if you look at this by, I would hope that a real statistician would notice some things like what the hell is going on here.",
            "But this, it turns out, is something well known called the Mounder Minimum, a period in the 1600s where they're very small number of sunspots so."
        ],
        [
            "In fact, that's the first thing it finds.",
            "Is this constant?",
            "OK, that explains the fact that these are not centered around 0.",
            "Then it discovers the mounder minimum, OK?"
        ],
        [
            "And discovers that there's some longer variability with a period.",
            "Sorry with the lens scales about 20 three years.",
            "And they."
        ],
        [
            "And it discovers that there is approximately 11 year periodicity in sunspots.",
            "OK, which is which is sort of true.",
            "OK, so."
        ],
        [
            "So we have a nice website you can upload your own datasets if you want.",
            "And we have some examples here where I want to show you.",
            "So just look up automaticstatistician.com.",
            "We have some examples, I just showed you snippets.",
            "I want to actually show you some full reports.",
            "So here is a full report.",
            "So remember, it's data in and this is what comes out is formatted like and it's paper.",
            "In this case it has starts with an executive summary.",
            "OK and then.",
            "It has tables of summary statistics for each of the components that it finds, and then it describes each component in detail.",
            "OK.",
            "So this is a over the page limit for NIPS, but so each component is described in detail with residual plots etc.",
            "Um?",
            "I want to there is a section on extrapolation for time series.",
            "So it shows you where this extrapolations look like.",
            "Then there's a section I want to get to in a couple of minutes.",
            "If I have a couple of minutes.",
            "Um?",
            "Sorry.",
            "On model checking.",
            "And I'll get to that in a minute.",
            "OK, so."
        ],
        [
            "So OK, so I focus on the on the learning and modeling Inter ability but but what most people in machine learning often focus on is on predictive performance.",
            "So we can actually value the predictive performance of our.",
            "Automatic statistician compared to whole bunch of different things.",
            "This is standardized harmacy over 13 datasets.",
            "This is how linear regression would do is roughly around 3:00.",
            "And it turns out that you know if you compare to just vanilla Gaussian processes, most people run them.",
            "Then you get just a bit better than linear regression.",
            "If you add in change points, you get a lot of improvement.",
            "This is Eureka, there's a.",
            "There's a science paper on an equation discovery a few years ago, and the company formed around this doesn't perform all that well.",
            "This is a Bayesian version of multiple kernel learning.",
            "These are things that people might not actually do, maybe even the machine learning researchers might have the patience to do this.",
            "But automatic statistician here, 2 versions of it, the one that produces the interpreter, reports it performs the best out of all of these, and then if we add a few more elements to our grammar which makes our interpretability a little harder.",
            "But a performance a bit better than this automatic search over model space actually performs better than everything else out there, so it's not just about producing interpretable reports, but we also feel that this sort of systematic exploration of models can help us.",
            "Find actually really good models in a way that a human might not have the patience to do, or even the expertise to do.",
            "'cause the humans grammar of models might be smaller than our computers grammar at some point, OK?"
        ],
        [
            "Now model checking criticism is a very neglected topic I feel, but it's really important one.",
            "So now a good statistical modeler should do model criticism.",
            "In other words, after training the model, the question would be does the data match the assumptions of the model.",
            "For example, you know if your model had Gaussian residuals, then just compute the residuals and do a QQ plot and see whether there Gaussian or not.",
            "Now, often statisticians do this, but I I've almost never seen a machine learning paper do this kind of thing, so we're kind of trying to be a little event and our automatic statistician does procedure predictive checks, dependence tests and residual tests, and our model criticism.",
            "Is frequently so essentially what we do is we build up our Bayesian model and then we look at statistics and do classical frequentist sort of procedure, predictive checks and other kinds of methods to discover whether our model fails badly or not, and that's what this kind of this whole Section 4 of the report is like.",
            "So several procedure predictive checks were done autocorrelation functions, periodograms, QQ plots for the different components.",
            "And lo and behold, it found one of them which was statistically significantly different from what it expected in component eight.",
            "OK, so it says it identifies.",
            "You know you can read these reports to see."
        ],
        [
            "Uncorrelated noise that that assumption is not met by the model.",
            "OK, all right now.",
            "We've been very recent work.",
            "We've been developing more systematic nonparametric approaches to model criticism using Kernel 2 sample tests and MMD.",
            "We want to put that into the automatic statistician, but we've sort of apply that to all sorts of models like, you know, restricted Boltzmann machines and deep learning and Gaussian process and so on.",
            "So you can see that in this paper, if you want."
        ],
        [
            "OK, now.",
            "Do I have?",
            "Three more minutes.",
            "OK, I want it because it's fun.",
            "I want to show you something else.",
            "OK, so here are some you know.",
            "I've shown you examples of time series.",
            "The thing on this website if you want to upload stuff we're not doing time series modeling on this website where we're doing is regression models?",
            "OK, we're actually doing linear regression models with automatic statistician and these are completely frequentist version of the automatic statistician.",
            "So here's an example analysis for that linear regression model.",
            "So the way this happened was.",
            "We put this site alone.",
            "We didn't really advertise it much, but about 200 people or maybe more now have uploaded different datasets and one person uploaded a very interesting data set that James noticed it was called affairs.",
            "I want to show you that is worth your 3 minutes.",
            "OK, this is the automatic report on the data set of fares.",
            "If you're married, you should worry.",
            "OK, the automatic statistician has no idea.",
            "It doesn't even know what an affair is, but in this data set.",
            "To confirm that I've interpreted the data correctly, a short summary of the data set follows their six inputs and 601 rose, and the inputs are things like age, years, married, religiousness, education, occupation, an rating of your marriage, and that predict valuable is trying to predict is the number of affairs.",
            "OK, here is the.",
            "Here's what it does.",
            "It compares, in this case full linear model BI, see with stepwise and lasso and it decides that the full linear model is the best thing to use.",
            "This is a very simple version of the automatic session so that people can upload lots and lots of things.",
            "Here's the model in the executive summary of the model.",
            "This is a 10 page report, so blah the output affairs decreases linearly with the input rating.",
            "That's the first thing.",
            "So if you rate your marriage highly, you're less likely to have affairs or fewer affairs.",
            "If you're religious, you're less likely to have affairs.",
            "That's the second thing that it finds.",
            "The third thing increases linearly with input years married.",
            "Decreases linearly with input age, so if you're young here, going around doing things you're not supposed to do, that increases linearly with input occupation, so you could look at that with that means.",
            "This is not really interpreted decreases linearly with input education OK?",
            "And of course, there's you know lots and lots of pages through this report, and then our model criticism.",
            "It finds some things that are grossly wrong, like a I've attempted to falsify the model, presented, both understand assets that are not capturing well, I OK. Below a list of discrepancies I've found the most surprising, with the most surprising first.",
            "High dependence between residuals and model fit, so these are what it expects for the residuals.",
            "These are the actual residuals, so this IT flags up as being really bad.",
            "With you know this dotted line is not in this histogram.",
            "Etc.",
            "Low negative deviation between quantile.",
            "So the QQ plots come out horrible, so it's clearly not good for this linear regression.",
            "OK, I'm just going to wrap up now so there are bunch of challenges in interpretability and accuracy.",
            "These two things can be traded off, but I think we can have very good accuracy and still interpretability, and it's worth doing.",
            "We want to increase the expressivity of our language.",
            "There's a computational complexity of the search through huge space of models and we want to extend it to.",
            "Much extend the reports to multidimensional datasets now."
        ],
        [
            "It kind of built.",
            "I showed you the 1 dimensional time series and linear regression.",
            "We've also done nonlinear regression, some classification and tables and databases, but we haven't done the reports.",
            "There's links to my interests in probabilistic programming.",
            "An that's just the summary."
        ],
        [
            "And some references.",
            "And like everybody else, I'm advertising something.",
            "So I'm looking for post docs.",
            "If you know somebody who might be interested, let me know.",
            "OK, OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I will talk about something we've been working on over the last couple of years that I'm very, very excited about and this is joint work with James Lloyd David.",
                    "label": 0
                },
                {
                    "sent": "Do we know Roger Gross and Josh Tenenbaum?",
                    "label": 1
                },
                {
                    "sent": "And our motivation is basically the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know, as we all know, everybody is awash with data.",
                    "label": 0
                },
                {
                    "sent": "There's a huge demand for data scientists, all of you out there getting job offers all the time.",
                    "label": 0
                },
                {
                    "sent": "They're not enough of us and you out there.",
                    "label": 0
                },
                {
                    "sent": "And a lot of fields rely on experts, statisticians, machine learning, researchers and data scientists, so.",
                    "label": 1
                },
                {
                    "sent": "So why don't we build a tool that will help us do automatic statistics or automatic data scientist data science?",
                    "label": 0
                },
                {
                    "sent": "So what do I mean by that?",
                    "label": 0
                },
                {
                    "sent": "Well, let's first of all think a little bit about maybe what a statistician might do OK?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is what we're trying to do, so we're trying to make the following process that S statistician might follow when encountering a new data set.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The data set is here.",
                    "label": 0
                },
                {
                    "sent": "The statistician says looking at the data set now, we haven't actually included any actual knowledge about background domain information here, so it's just imagined statisticians just looking at the data and trying to figure out what's going on the data.",
                    "label": 0
                },
                {
                    "sent": "Now, this statistician will have some language of models that they might know about some set of modeling tools they might know about and ways of composing those modeling tools.",
                    "label": 1
                },
                {
                    "sent": "And then looking at the data.",
                    "label": 0
                },
                {
                    "sent": "The statistician might start proposing some simple models, then search over a bunch of different models until there's a model that the statistician is happy with, and then what what you want to do this well, you can use that model to make predictions on new data.",
                    "label": 0
                },
                {
                    "sent": "Decision might be working for a client, so might want to produce a sort of report about the data and the model.",
                    "label": 0
                },
                {
                    "sent": "So translate the model into some sort of written report and then importantly also after learning the model from data you'd like the statistician to do some model checking or model criticism to make sure that there are obvious things the model has failed at doing so.",
                    "label": 0
                },
                {
                    "sent": "This is the kind of pipeline that we're trying to.",
                    "label": 0
                },
                {
                    "sent": "Reproduce and we're going to.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to describe the different components of this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so our real motivation is the following.",
                    "label": 0
                },
                {
                    "sent": "What we really want to do is provide a set of tools for understanding data that require minimal expert input.",
                    "label": 1
                },
                {
                    "sent": "Now, this isn't just a big software project, this is actually uncovering a huge number of challenging research problems for how to automate influence on all sorts of different kinds of data for model construction and comparison challenges in data visualization, an model interpretation.",
                    "label": 1
                },
                {
                    "sent": "And I generally think this is a very nice way of trying to advance the field of machine learning to automate the process of statistical data analysis OK?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here the ingredients of our automatic statistician where we'd like to have is not just a small set of models.",
                    "label": 0
                },
                {
                    "sent": "Not like you know 5 or 10 different models, But we'd like to have an open ended language of models expressive enough to capture real world phenomena and to capture a lot of the techniques that statisticians might actually use.",
                    "label": 1
                },
                {
                    "sent": "And what I mean by language of models will be more clear a bit later on, But this has to be something compositional where you can build more complex models out of simpler models.",
                    "label": 0
                },
                {
                    "sent": "Then we need a search procedure to efficiently explore this language of models.",
                    "label": 1
                },
                {
                    "sent": "We need a principled method for evaluating models, trading off complexity and fit to the data, and we need a procedure to automatically explain the model.",
                    "label": 1
                },
                {
                    "sent": "Something that's been hugely neglected in our community.",
                    "label": 0
                },
                {
                    "sent": "I think in other words, something that will make the assumptions of the model explicit in a way that's intelligible to somebody who is numerate but not necessarily a statistician.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is a preview of the kind of thing I'm going to show you in much more detail, and I'll give you tasters of a few other things.",
                    "label": 0
                },
                {
                    "sent": "So here is an example of a data set, and then this is a time series data set.",
                    "label": 0
                },
                {
                    "sent": "This happens to be airline passengers from the late 40s to the early 60s at a monthly at monthly intervals.",
                    "label": 0
                },
                {
                    "sent": "This is the model that's fit by the automatic statistician.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there are error bars around this and you can't see it after the dashed line.",
                    "label": 0
                },
                {
                    "sent": "This is the extrapolation from the automatic statistician and what the automatic session statistician does is.",
                    "label": 0
                },
                {
                    "sent": "It produces a report where a small snippet of the executive summary of the report is shown here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It says he or she says therefore out of components that have been identified in the data, a linearly increasing function in approximately periodic function with a period of 1.0 years and with linearly increasing amplitude, a smooth function and uncorrelated noise with linearly increasing standard deviation.",
                    "label": 1
                },
                {
                    "sent": "So that's this executive summary of what's going on in the data, and that process was completely automated and I'll show you in a lot more detail how we did that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at each component one at a time.",
                    "label": 0
                },
                {
                    "sent": "The language of models.",
                    "label": 0
                },
                {
                    "sent": "So we're going to look the example.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give you is regression models and it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Particular, So what do I mean by that?",
                    "label": 0
                },
                {
                    "sent": "We're trying to learn functions F from some input domain X to some outputs Y.",
                    "label": 0
                },
                {
                    "sent": "From input, output pairs and our language should include some simple parametric forms of models.",
                    "label": 1
                },
                {
                    "sent": "Things like Linears, polynomials, exponential functions, etc, as well as as well as functions specified by high level properties.",
                    "label": 1
                },
                {
                    "sent": "Things like smooth functions, periodic functions, etc.",
                    "label": 0
                },
                {
                    "sent": "And we'd like our inference to be tractable for all the models in our language, so we can explore a very large space of models.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With the two, we're going to use, here is Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So Gaussian processes are distributions over functions such that any finite subset of function evaluations F1 through XF of X1 through F of XM.",
                    "label": 1
                },
                {
                    "sent": "This is an M dimensional vector has a joint multivariate Gaussian distribution and a Gaussian process is completely specified by amine function Anna covariance or kernel function.",
                    "label": 0
                },
                {
                    "sent": "The mean tells us the mean of the function of the covariance tells us.",
                    "label": 0
                },
                {
                    "sent": "How similar you could think F of X is going to be to F at some other point X prime?",
                    "label": 0
                },
                {
                    "sent": "How how much these two covary and we're going tonight it denoted as F is drawn from a GPU with mean function mu and covariance or kernel K.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now if we want a language of Gaussian processes, you know or do we have to worry about the mean function is very common.",
                    "label": 1
                },
                {
                    "sent": "You find almost in the first line under a lot of papers that do Gaussian process.",
                    "label": 1
                },
                {
                    "sent": "The assumption to have a zero mean function.",
                    "label": 0
                },
                {
                    "sent": "So let's just uncover why that might be sensible.",
                    "label": 0
                },
                {
                    "sent": "So imagine that we had some mean.",
                    "label": 0
                },
                {
                    "sent": "Well, we had a Gaussian process with some mean mu of X, but we didn't know how much of that mean we wanted to incorporate.",
                    "label": 0
                },
                {
                    "sent": "So let's scale that mean by some constant, some scalar A.",
                    "label": 1
                },
                {
                    "sent": "Now, if we simply have Gaussian uncertainty about the amount of A to put in here, then that Gaussian process with this particular scaled mean function is equivalent to a Gaussian process with zero mean annanu covariance function.",
                    "label": 0
                },
                {
                    "sent": "So that unknown mean can simply be wrapped into the covariance function of a Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So for that technical reason, our language for regression models is simply going to be.",
                    "label": 0
                },
                {
                    "sent": "A language of kernels of Gaussian process.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what do I mean by language?",
                    "label": 0
                },
                {
                    "sent": "Well, language, for example, human language is composed of words and you can compose words together in certain valid ways to produce valid grammatical sentences.",
                    "label": 0
                },
                {
                    "sent": "And that's what we're going to do with kernels.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to have are some small number of base kernels.",
                    "label": 0
                },
                {
                    "sent": "And we're going to compose these, so let me describe the base kernels.",
                    "label": 0
                },
                {
                    "sent": "There's very commonly used Gaussian or squared exponential or exponentiated quadratic kernel different names for the same thing, and that corresponds to smooth functions OK?",
                    "label": 0
                },
                {
                    "sent": "So here are two draws of functions with that kernel.",
                    "label": 0
                },
                {
                    "sent": "Periodic kernels correspond to periodic functions.",
                    "label": 1
                },
                {
                    "sent": "Linear kernels correspond to linear functions, so these are two samples from a Gaussian process with linear kernel.",
                    "label": 0
                },
                {
                    "sent": "Constant kernels correspond to constant functions, and the white noise kernel corresponds to additive Gaussian noise.",
                    "label": 1
                },
                {
                    "sent": "OK, so these are the basic atoms or elements of our language, and then we have composition rules.",
                    "label": 0
                },
                {
                    "sent": "And our composition rules are addition and multiplication.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have a couple more as well, but let me describe addition and multiplication.",
                    "label": 0
                },
                {
                    "sent": "So if you multiply linear kernel by linear kernel, you get a quadratic kernel.",
                    "label": 0
                },
                {
                    "sent": "So by implication we have all polynomials in there.",
                    "label": 0
                },
                {
                    "sent": "OK, by simply multiplying in linear's, if we multiply a ^2 exponential Anna periodic for example, the kinds of functions that you get are locally periodic, they're not perfectly periodic.",
                    "label": 0
                },
                {
                    "sent": "The period changes as you.",
                    "label": 0
                },
                {
                    "sent": "Move further and further away.",
                    "label": 0
                },
                {
                    "sent": "That's what multiplying squared exponential by periodic does.",
                    "label": 0
                },
                {
                    "sent": "These are two samples from that.",
                    "label": 0
                },
                {
                    "sent": "When you see these wiggles are not identical as you move along the change if you.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add linear and periodic.",
                    "label": 0
                },
                {
                    "sent": "For example, you get periodic functions plus linear trends.",
                    "label": 0
                },
                {
                    "sent": "If you add squared, exponential and periodic you get you know some smooth trend plus some periodicity.",
                    "label": 0
                },
                {
                    "sent": "OK, so of course we can compose these.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In various ways, and in particular, I'm going to talk about applications for the most Part 2 Time series models and in time series something that we also want to capture is changepoints, so time series where something is going on and then suddenly it changes and something else is going on afterwards.",
                    "label": 0
                },
                {
                    "sent": "So here is a basic idea for how you model change points is if F1 is drawn from a Gaussian process with kernel K1F2 is drawn from a Gaussian process with kernel K2.",
                    "label": 0
                },
                {
                    "sent": "You could take a sigmoid function, some sort of logistic function, and just mix together F1 and F2 switching at some point, which I haven't written down explicitly.",
                    "label": 1
                },
                {
                    "sent": "And the picture for that is down here.",
                    "label": 0
                },
                {
                    "sent": "You could get a function that very smoothly switching to a function of berries quickly functioned very smoothly.",
                    "label": 0
                },
                {
                    "sent": "Switching to a periodic function period of one kind of.",
                    "label": 0
                },
                {
                    "sent": "Switching to another kind of.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 0
                },
                {
                    "sent": "And this operation of having a change point simply corresponds to a new kernel, so this is in the valid space of our language of kernels.",
                    "label": 1
                },
                {
                    "sent": "This is the changepoint operation.",
                    "label": 0
                },
                {
                    "sent": "This kernel K is the change point of K1 and K2 at some particular location.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what can we do with these elements?",
                    "label": 0
                },
                {
                    "sent": "Well, we can do it turns out quite a lot of things we can do that sort of traditional Gaussian process smoothing.",
                    "label": 0
                },
                {
                    "sent": "We can do linear regression.",
                    "label": 1
                },
                {
                    "sent": "We can do a form of multiple kernel learning.",
                    "label": 1
                },
                {
                    "sent": "We can mimic something called the trend cyclical irregular model doing some kind of creative composition, you know.",
                    "label": 0
                },
                {
                    "sent": "A variety of different kinds of things that people do as standard for time series.",
                    "label": 0
                },
                {
                    "sent": "OK, so now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk a little bit about this search.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our language is defined as an arbitrary composition of these five based kernels.",
                    "label": 1
                },
                {
                    "sent": "With these three operators, the space of this language is open ended and can have a quite a high branching factor, so it's important to have a good search algorithm and as a first step we're going to do is simply greedy search which starts with the base kernels and then expands around those.",
                    "label": 1
                },
                {
                    "sent": "Group things that it finds.",
                    "label": 0
                },
                {
                    "sent": "In analogy, who with how, maybe a statistician might be model building.",
                    "label": 0
                },
                {
                    "sent": "Start out with some simple models and then pick the best one and think about how you might want to expand that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is an illustration of that.",
                    "label": 0
                },
                {
                    "sent": "This is with a slightly different grammar, so we had a particular kernel called the rational quadratic in here, but the picture is basically the same here some time series.",
                    "label": 0
                },
                {
                    "sent": "This is a very famous data set.",
                    "label": 0
                },
                {
                    "sent": "The Maunalua Keeling Curve used in climate science, CO2 concentrations on top of Mount Aloa as a function of time.",
                    "label": 0
                },
                {
                    "sent": "Here is the initial fit at the first level and then we can see is the interpolation is great.",
                    "label": 0
                },
                {
                    "sent": "Extrapolation is lousy.",
                    "label": 0
                },
                {
                    "sent": "You can't really see the error bars, but they're pretty huge here.",
                    "label": 0
                },
                {
                    "sent": "OK, so then it says OK, rational quadratic was good.",
                    "label": 0
                },
                {
                    "sent": "Let me expand that.",
                    "label": 0
                },
                {
                    "sent": "Oh periodic, less rational quadratic seems pretty good.",
                    "label": 0
                },
                {
                    "sent": "The interpolation is a little better.",
                    "label": 0
                },
                {
                    "sent": "The extrapolation also seems sensible.",
                    "label": 0
                },
                {
                    "sent": "But can it do better than that?",
                    "label": 0
                },
                {
                    "sent": "So then it says, well, actually there seems to be some long term trend modeled by doing squared exponential times periodic plus rational quadratic.",
                    "label": 0
                },
                {
                    "sent": "Note that the words are being composed together into more and more complicated sentences, so that's what it gets here and then.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In you know this is what it ends up with at the end, squared exponential plus squared exponential times periodic plus rational quadratic, and that's the final model that it builds.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, how does it actually evaluate models to see what's a good model and what's not?",
                    "label": 0
                },
                {
                    "sent": "A good model?",
                    "label": 0
                },
                {
                    "sent": "So after.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using a new model with this kernel parameters, we we simply optimize those kernel parameters using conjugate gradients.",
                    "label": 1
                },
                {
                    "sent": "OK, now for each optimized model where we do is we evaluate the model evidence.",
                    "label": 0
                },
                {
                    "sent": "The marginal likelihood.",
                    "label": 1
                },
                {
                    "sent": "The nice thing about a Gaussian process if you know about them is that you integrate out the whole function space analytically, 'cause it's easy.",
                    "label": 0
                },
                {
                    "sent": "It's a Gaussian process, so you compute an exact marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "But now we because we did optimization of the kernel hyperparameters, we simply penalize that log marginal likelihood.",
                    "label": 1
                },
                {
                    "sent": "By this BIC penalty, which is number of kernel parameters divided by two log N. OK, so that's the search criteria that we use.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "That's the sort of model building.",
                    "label": 0
                },
                {
                    "sent": "Now what about the translation?",
                    "label": 0
                },
                {
                    "sent": "This is perhaps maybe the the most novel and different part of this work, I would say.",
                    "label": 0
                },
                {
                    "sent": "So we want to translate this model into a report about the data.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the problem is the search can produce very complicated models.",
                    "label": 1
                },
                {
                    "sent": "But the good news is that these kernels can be decomposed into a form which is a sum of product form.",
                    "label": 1
                },
                {
                    "sent": "And a sum of kernels corresponds to summer functions, and therefore we can describe each product of kernels separately in this sum of product form, and I will describe this in a minute.",
                    "label": 1
                },
                {
                    "sent": "Now each kernel is in a product, modifies the model in a consistent way.",
                    "label": 0
                },
                {
                    "sent": "This isn't necessarily obvious, but you'll see that in a minute there for each kernel roughly corresponds to an adjective in the text that we're going to produce at the end, OK?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is an example.",
                    "label": 0
                },
                {
                    "sent": "Suppose our search finds the following kernel.",
                    "label": 1
                },
                {
                    "sent": "Rather complicated.",
                    "label": 0
                },
                {
                    "sent": "The change point here can be converted into a sum of products form, so this is a change point between a constant in the periodic.",
                    "label": 1
                },
                {
                    "sent": "You can write it as constant times some function, plus periodic times some other sigmoid function.",
                    "label": 1
                },
                {
                    "sent": "OK, then multiplication can be distributed over addition.",
                    "label": 0
                },
                {
                    "sent": "So let's take this square exponential kernel here and distribute that over that whole expression and we get this expression here.",
                    "label": 0
                },
                {
                    "sent": "Then we can apply simplification rules.",
                    "label": 0
                },
                {
                    "sent": "So for example squared exponential times, white noise times linear.",
                    "label": 0
                },
                {
                    "sent": "Well this gets absorbed into this, which is equivalent to white noise times linear, OK, squared, exponential times constant times.",
                    "label": 0
                },
                {
                    "sent": "This change point is just squared exponential times a change point, etc.",
                    "label": 0
                },
                {
                    "sent": "So this is the expression that we get at the end.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now this is in what form this is in the sum of product form.",
                    "label": 0
                },
                {
                    "sent": "So the good thing is that if F1 is drawn from a Gaussian process and F2 is drawn from a Gaussian process, then F1 plus F2 is drawn from a Gaussian process with kernel K1 plus K2.",
                    "label": 0
                },
                {
                    "sent": "So thinking of that logic in reverse, we have if we have a sum of kernels where we can do is, we can describe properties of F1 and properties of F2, like for example a trend.",
                    "label": 0
                },
                {
                    "sent": "Plus a high frequency oscillation or something like that.",
                    "label": 0
                },
                {
                    "sent": "Rick.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's how that works.",
                    "label": 0
                },
                {
                    "sent": "So imagine we have an expression like this.",
                    "label": 0
                },
                {
                    "sent": "This kernel is just the periodic function.",
                    "label": 0
                },
                {
                    "sent": "We say periodic function and these are just four samples of what that would look like.",
                    "label": 0
                },
                {
                    "sent": "If it's squared exponential times periodic, we use the phrase approximately periodic function.",
                    "label": 0
                },
                {
                    "sent": "If it's squared exponential times periodic times linear, we might use the phrase approximately periodic function with linearly growing amplitude.",
                    "label": 1
                },
                {
                    "sent": "OK. And then there's a change point.",
                    "label": 0
                },
                {
                    "sent": "So here we have approximately periodic function with linearly growing amplitude until 1700, and that's a phrase that we use in our report to describe what the model is doing, and that's what we look like with 1700 being so somewhere here maybe.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now what do these reports look like?",
                    "label": 0
                },
                {
                    "sent": "So again, we come back to this example.",
                    "label": 0
                },
                {
                    "sent": "Now you can see is the process that we did here for these time series is relearn the model, then we identified 4.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sums the sum of 4 product components and these are the the four product components that we ended up with in our best model by the BICS penalized marginal likelihood and each one has been translated into a phrase in the order in order of these are described in order of importance in order of importance corresponds to how much of the signal is being explained by each component so.",
                    "label": 0
                },
                {
                    "sent": "If I look at this by I, I would hope that I would see that there's a linearly.",
                    "label": 0
                },
                {
                    "sent": "There's some sort of increasing function.",
                    "label": 1
                },
                {
                    "sent": "Maybe it's linear, maybe it's not, but there's some sort of increasing function and the model indeed comes up with that as the first thing that it notices.",
                    "label": 0
                },
                {
                    "sent": "Then it says on top of that there is periodicity which you can see when you actually connect the dots with a period of 1.0 years and linearly increasing amplitude, and then these other components.",
                    "label": 1
                },
                {
                    "sent": "So let's just look at the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In more detail, so here's the Pacira for componentone.",
                    "label": 0
                },
                {
                    "sent": "Sorry, error bars are not showing up because we didn't use a dark enough shade of blue for the projector, but they're all in the papers.",
                    "label": 0
                },
                {
                    "sent": "So here is the first component superimposed on the data.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now this is a bit more text that's actually in one of these reports.",
                    "label": 0
                },
                {
                    "sent": "This is for that airline passenger data.",
                    "label": 0
                },
                {
                    "sent": "The automatic cessation says this component is approximately reality with period 1.5 years across periods of shape of this function values very smoothly.",
                    "label": 1
                },
                {
                    "sent": "The amplitude of the function increases linearly.",
                    "label": 0
                },
                {
                    "sent": "The shape of this function within each.",
                    "label": 0
                },
                {
                    "sent": "Has a typical N scale of six weeks, so that corresponds to the wiggling of the function within a year.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then this is the third component.",
                    "label": 0
                },
                {
                    "sent": "This sort of trend of at a higher length scale of eight months.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this is noise with linearly increasing amplitude.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you could.",
                    "label": 0
                },
                {
                    "sent": "I don't think you can see that the error bars are increasing there.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then here's another data set.",
                    "label": 0
                },
                {
                    "sent": "This is some spot data.",
                    "label": 0
                },
                {
                    "sent": "And this is sunspots from the 1600 to the 2000s, measured yearly.",
                    "label": 0
                },
                {
                    "sent": "And there's some, you know, if you look at this by, I would hope that a real statistician would notice some things like what the hell is going on here.",
                    "label": 0
                },
                {
                    "sent": "But this, it turns out, is something well known called the Mounder Minimum, a period in the 1600s where they're very small number of sunspots so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, that's the first thing it finds.",
                    "label": 0
                },
                {
                    "sent": "Is this constant?",
                    "label": 0
                },
                {
                    "sent": "OK, that explains the fact that these are not centered around 0.",
                    "label": 0
                },
                {
                    "sent": "Then it discovers the mounder minimum, OK?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And discovers that there's some longer variability with a period.",
                    "label": 0
                },
                {
                    "sent": "Sorry with the lens scales about 20 three years.",
                    "label": 0
                },
                {
                    "sent": "And they.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it discovers that there is approximately 11 year periodicity in sunspots.",
                    "label": 0
                },
                {
                    "sent": "OK, which is which is sort of true.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a nice website you can upload your own datasets if you want.",
                    "label": 0
                },
                {
                    "sent": "And we have some examples here where I want to show you.",
                    "label": 0
                },
                {
                    "sent": "So just look up automaticstatistician.com.",
                    "label": 0
                },
                {
                    "sent": "We have some examples, I just showed you snippets.",
                    "label": 0
                },
                {
                    "sent": "I want to actually show you some full reports.",
                    "label": 0
                },
                {
                    "sent": "So here is a full report.",
                    "label": 0
                },
                {
                    "sent": "So remember, it's data in and this is what comes out is formatted like and it's paper.",
                    "label": 0
                },
                {
                    "sent": "In this case it has starts with an executive summary.",
                    "label": 0
                },
                {
                    "sent": "OK and then.",
                    "label": 0
                },
                {
                    "sent": "It has tables of summary statistics for each of the components that it finds, and then it describes each component in detail.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is a over the page limit for NIPS, but so each component is described in detail with residual plots etc.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I want to there is a section on extrapolation for time series.",
                    "label": 0
                },
                {
                    "sent": "So it shows you where this extrapolations look like.",
                    "label": 0
                },
                {
                    "sent": "Then there's a section I want to get to in a couple of minutes.",
                    "label": 0
                },
                {
                    "sent": "If I have a couple of minutes.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "On model checking.",
                    "label": 0
                },
                {
                    "sent": "And I'll get to that in a minute.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK, so I focus on the on the learning and modeling Inter ability but but what most people in machine learning often focus on is on predictive performance.",
                    "label": 0
                },
                {
                    "sent": "So we can actually value the predictive performance of our.",
                    "label": 1
                },
                {
                    "sent": "Automatic statistician compared to whole bunch of different things.",
                    "label": 0
                },
                {
                    "sent": "This is standardized harmacy over 13 datasets.",
                    "label": 1
                },
                {
                    "sent": "This is how linear regression would do is roughly around 3:00.",
                    "label": 1
                },
                {
                    "sent": "And it turns out that you know if you compare to just vanilla Gaussian processes, most people run them.",
                    "label": 0
                },
                {
                    "sent": "Then you get just a bit better than linear regression.",
                    "label": 0
                },
                {
                    "sent": "If you add in change points, you get a lot of improvement.",
                    "label": 0
                },
                {
                    "sent": "This is Eureka, there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a science paper on an equation discovery a few years ago, and the company formed around this doesn't perform all that well.",
                    "label": 0
                },
                {
                    "sent": "This is a Bayesian version of multiple kernel learning.",
                    "label": 0
                },
                {
                    "sent": "These are things that people might not actually do, maybe even the machine learning researchers might have the patience to do this.",
                    "label": 0
                },
                {
                    "sent": "But automatic statistician here, 2 versions of it, the one that produces the interpreter, reports it performs the best out of all of these, and then if we add a few more elements to our grammar which makes our interpretability a little harder.",
                    "label": 1
                },
                {
                    "sent": "But a performance a bit better than this automatic search over model space actually performs better than everything else out there, so it's not just about producing interpretable reports, but we also feel that this sort of systematic exploration of models can help us.",
                    "label": 0
                },
                {
                    "sent": "Find actually really good models in a way that a human might not have the patience to do, or even the expertise to do.",
                    "label": 0
                },
                {
                    "sent": "'cause the humans grammar of models might be smaller than our computers grammar at some point, OK?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now model checking criticism is a very neglected topic I feel, but it's really important one.",
                    "label": 0
                },
                {
                    "sent": "So now a good statistical modeler should do model criticism.",
                    "label": 1
                },
                {
                    "sent": "In other words, after training the model, the question would be does the data match the assumptions of the model.",
                    "label": 1
                },
                {
                    "sent": "For example, you know if your model had Gaussian residuals, then just compute the residuals and do a QQ plot and see whether there Gaussian or not.",
                    "label": 1
                },
                {
                    "sent": "Now, often statisticians do this, but I I've almost never seen a machine learning paper do this kind of thing, so we're kind of trying to be a little event and our automatic statistician does procedure predictive checks, dependence tests and residual tests, and our model criticism.",
                    "label": 0
                },
                {
                    "sent": "Is frequently so essentially what we do is we build up our Bayesian model and then we look at statistics and do classical frequentist sort of procedure, predictive checks and other kinds of methods to discover whether our model fails badly or not, and that's what this kind of this whole Section 4 of the report is like.",
                    "label": 0
                },
                {
                    "sent": "So several procedure predictive checks were done autocorrelation functions, periodograms, QQ plots for the different components.",
                    "label": 0
                },
                {
                    "sent": "And lo and behold, it found one of them which was statistically significantly different from what it expected in component eight.",
                    "label": 0
                },
                {
                    "sent": "OK, so it says it identifies.",
                    "label": 0
                },
                {
                    "sent": "You know you can read these reports to see.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uncorrelated noise that that assumption is not met by the model.",
                    "label": 0
                },
                {
                    "sent": "OK, all right now.",
                    "label": 0
                },
                {
                    "sent": "We've been very recent work.",
                    "label": 0
                },
                {
                    "sent": "We've been developing more systematic nonparametric approaches to model criticism using Kernel 2 sample tests and MMD.",
                    "label": 0
                },
                {
                    "sent": "We want to put that into the automatic statistician, but we've sort of apply that to all sorts of models like, you know, restricted Boltzmann machines and deep learning and Gaussian process and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can see that in this paper, if you want.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "Do I have?",
                    "label": 0
                },
                {
                    "sent": "Three more minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, I want it because it's fun.",
                    "label": 0
                },
                {
                    "sent": "I want to show you something else.",
                    "label": 0
                },
                {
                    "sent": "OK, so here are some you know.",
                    "label": 0
                },
                {
                    "sent": "I've shown you examples of time series.",
                    "label": 0
                },
                {
                    "sent": "The thing on this website if you want to upload stuff we're not doing time series modeling on this website where we're doing is regression models?",
                    "label": 0
                },
                {
                    "sent": "OK, we're actually doing linear regression models with automatic statistician and these are completely frequentist version of the automatic statistician.",
                    "label": 0
                },
                {
                    "sent": "So here's an example analysis for that linear regression model.",
                    "label": 0
                },
                {
                    "sent": "So the way this happened was.",
                    "label": 0
                },
                {
                    "sent": "We put this site alone.",
                    "label": 0
                },
                {
                    "sent": "We didn't really advertise it much, but about 200 people or maybe more now have uploaded different datasets and one person uploaded a very interesting data set that James noticed it was called affairs.",
                    "label": 0
                },
                {
                    "sent": "I want to show you that is worth your 3 minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the automatic report on the data set of fares.",
                    "label": 0
                },
                {
                    "sent": "If you're married, you should worry.",
                    "label": 0
                },
                {
                    "sent": "OK, the automatic statistician has no idea.",
                    "label": 1
                },
                {
                    "sent": "It doesn't even know what an affair is, but in this data set.",
                    "label": 0
                },
                {
                    "sent": "To confirm that I've interpreted the data correctly, a short summary of the data set follows their six inputs and 601 rose, and the inputs are things like age, years, married, religiousness, education, occupation, an rating of your marriage, and that predict valuable is trying to predict is the number of affairs.",
                    "label": 0
                },
                {
                    "sent": "OK, here is the.",
                    "label": 0
                },
                {
                    "sent": "Here's what it does.",
                    "label": 0
                },
                {
                    "sent": "It compares, in this case full linear model BI, see with stepwise and lasso and it decides that the full linear model is the best thing to use.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple version of the automatic session so that people can upload lots and lots of things.",
                    "label": 0
                },
                {
                    "sent": "Here's the model in the executive summary of the model.",
                    "label": 0
                },
                {
                    "sent": "This is a 10 page report, so blah the output affairs decreases linearly with the input rating.",
                    "label": 0
                },
                {
                    "sent": "That's the first thing.",
                    "label": 0
                },
                {
                    "sent": "So if you rate your marriage highly, you're less likely to have affairs or fewer affairs.",
                    "label": 0
                },
                {
                    "sent": "If you're religious, you're less likely to have affairs.",
                    "label": 0
                },
                {
                    "sent": "That's the second thing that it finds.",
                    "label": 0
                },
                {
                    "sent": "The third thing increases linearly with input years married.",
                    "label": 0
                },
                {
                    "sent": "Decreases linearly with input age, so if you're young here, going around doing things you're not supposed to do, that increases linearly with input occupation, so you could look at that with that means.",
                    "label": 0
                },
                {
                    "sent": "This is not really interpreted decreases linearly with input education OK?",
                    "label": 0
                },
                {
                    "sent": "And of course, there's you know lots and lots of pages through this report, and then our model criticism.",
                    "label": 0
                },
                {
                    "sent": "It finds some things that are grossly wrong, like a I've attempted to falsify the model, presented, both understand assets that are not capturing well, I OK. Below a list of discrepancies I've found the most surprising, with the most surprising first.",
                    "label": 0
                },
                {
                    "sent": "High dependence between residuals and model fit, so these are what it expects for the residuals.",
                    "label": 0
                },
                {
                    "sent": "These are the actual residuals, so this IT flags up as being really bad.",
                    "label": 0
                },
                {
                    "sent": "With you know this dotted line is not in this histogram.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 0
                },
                {
                    "sent": "Low negative deviation between quantile.",
                    "label": 0
                },
                {
                    "sent": "So the QQ plots come out horrible, so it's clearly not good for this linear regression.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm just going to wrap up now so there are bunch of challenges in interpretability and accuracy.",
                    "label": 0
                },
                {
                    "sent": "These two things can be traded off, but I think we can have very good accuracy and still interpretability, and it's worth doing.",
                    "label": 0
                },
                {
                    "sent": "We want to increase the expressivity of our language.",
                    "label": 1
                },
                {
                    "sent": "There's a computational complexity of the search through huge space of models and we want to extend it to.",
                    "label": 1
                },
                {
                    "sent": "Much extend the reports to multidimensional datasets now.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It kind of built.",
                    "label": 0
                },
                {
                    "sent": "I showed you the 1 dimensional time series and linear regression.",
                    "label": 1
                },
                {
                    "sent": "We've also done nonlinear regression, some classification and tables and databases, but we haven't done the reports.",
                    "label": 1
                },
                {
                    "sent": "There's links to my interests in probabilistic programming.",
                    "label": 0
                },
                {
                    "sent": "An that's just the summary.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And some references.",
                    "label": 0
                },
                {
                    "sent": "And like everybody else, I'm advertising something.",
                    "label": 0
                },
                {
                    "sent": "So I'm looking for post docs.",
                    "label": 0
                },
                {
                    "sent": "If you know somebody who might be interested, let me know.",
                    "label": 0
                },
                {
                    "sent": "OK, OK.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}