{
    "id": "6kgovaamliqgsdapud7orhwsv7vttqjp",
    "title": "Imitation Learning and Purposeful Prediction: Probabilistic and Non-probabilistic Methods",
    "info": {
        "author": [
            "Drew Bagnell, Carnegie Mellon University"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_bagnell_ilpppnm/",
    "segmentation": [
        [
            "My name is Drew Bagnell.",
            "Carnegie Mellon working in Robotics and machine learning.",
            "This is kind of a neat workshop because it's an interesting combination of different ideas, including some of these probabilistic techniques for control, and these probabilistic techniques for robotics.",
            "I'm hoping that I get to spend that gap a little bit in the talk, although obviously."
        ],
        [
            "Fully OK, So what am I going to talk about today?",
            "One problem I'm very interested in is the problem of imitation learning, so I want to show a robot what I wanted to do and I want to have it recover the same behavior in well, ideally, different circumstances.",
            "OK, there's kind of two ways to think about the imitation learning problem.",
            "One of them I would call something like the non generalizable imitation learning.",
            "This is where you want to show some behavior and you want to recover exactly that same behavior.",
            "So this great work by for instance Steven Shaw.",
            "On some motor control applications where they're doing this kind of imitation learning Peter building some great work on helicopter acrobatics that have that same kind of imitation learning flavor.",
            "What I'm going to talk about today is where I wanted to generalize to new situations, so I want to show some behavior, and then I want to get in a related but different situation.",
            "The same behavior that I would generate without that.",
            "OK, so there's lots of interesting problems in imitation learning, and I encourage you to go to Stephen Ross is poster and Brian Ziebart.",
            "Poster later this afternoon I'll talk about some of them, but the particular one I want to talk to you about right now."
        ],
        [
            "Is how we get the kind of how we get imitation learning of the kind of behaviors that I'm particularly interested in, which is sort of long horizon or goal directed behaviors."
        ],
        [
            "We do imitation learning of those kind of behaviors, and I'm going to show you a concrete example.",
            "So this is some work.",
            "Make sure the sound is off.",
            "This is some work that I did.",
            "Leading the perception and.",
            "Learning aspects the goal here is very simple.",
            "You have a robot you want to put it down at point A.",
            "You wanted to go to point B, point point B, or separated by somewhere between one and 10 kilometers, and the terrain is potentially very complicated.",
            "OK, so the question is how do you get a robot to do this task?",
            "It turns out to be very hard to hand program or robot to do this task, and the thing you'd like to do is just drive the robot from point A to point B yourself, then give it a new point point be right, Sonu start location, a new goal location and it can figure out how to do.",
            "How to navigate from location to location in that related but not the same problem?",
            "OK, that's the kind of that's the kind of goal here.",
            "Videos funny, I don't know what happened there.",
            "So if you watch carefully here, you'll notice what we call a control failure.",
            "Keep your eyes open right in this ballpark so.",
            "Oh I believe the control guys.",
            "OK, so the problem is very hard because the world is full of things like vegetation and itches and high centering hazards and slopes and all kinds of things that make it really hard to program this behavior.",
            "And there's occlusions from vegetation and it's really hard to tell with vegetation.",
            "The classification problem is really difficult.",
            "It's very difficult to kind of get this behavior with standard machine learning method."
        ],
        [
            "What I want to convince you of is that I think it's pretty easy to convince you of this, that if I just said I'm going to take some input features."
        ],
        [
            "Describe the world.",
            "So think of these as camera imagery or some features computed from Leithart data and I just directly try to use your favorite off the shelf algorithm.",
            "I don't know support vector machine and try to predict what the robot should do at each time step.",
            "Make a left turn, go straight, make a right turn.",
            "You're going to have a really, really hard time making this work, especially if you want to go 10 kilometers away and instead.",
            "Well, we take advantage of is the way state of the art robotic systems actually work, which is that they all have some kind of planning or control or optimal control algorithm that lives close to the bottom.",
            "And I'm showing you here a schematic of this.",
            "The basic idea is what happens is you've got some features that describe the world, and so these are computed from imagery and later potentially overhead.",
            "So maybe I get images of the world from up above.",
            "What ultimately happens is some cost function is generated and there's a planner.",
            "I'm showing it as a 2 dimensional planner here that figures out what the minimum cost is to go from the start to the goal.",
            "OK, and this is the way robot systems work, and now the learning problem becomes one of figuring out how to interpret sensor data so that we get a cost function so that the planner does what we wanted to do.",
            "OK, that's the sort of high level goal of the approach."
        ],
        [
            "So this kind of problem is very naturally phrased as an inverse optimal control problem.",
            "What does that mean?",
            "Inverse optimal control means that optimal control is.",
            "I have some cost function.",
            "I have some planner and my goal is to try to find the minimum cost way to get from point A to point B.",
            "Here we're doing the opposite.",
            "What we're saying is we have examples of the behavior we want to imitate, and we're trying to make the planner do the same thing.",
            "OK, so we're sort of inverting the optimal control problem.",
            "Turns out this is a really old problem.",
            "It goes back in fact, too common.",
            "He looked at the scalar control case, basically taking his own LQ our work and asking the question.",
            "If you take a generic linear controller, is it optimal for any LQ our objective function and he was able to answer this for the scalar control case and then later work answered this for LTI systems and there's been lots of work investigating this for MVP's as well, particularly by.",
            "And ring, Stuart Russell and Peter Beale among others.",
            "OK, so the contributions that I'm going to talk about today are the first set of algorithms for general planning problems.",
            "Meaning these kind of things which you are able to give regret bounds, meaning that you're able to guarantee performance mimicking the person's behavior.",
            "Now, of course, that's under all the usual kind of assumptions of margin and separability.",
            "OK and generalization bounds so that if you see new data, you'll be able to recreate that same kind of behavior and finally want to talk about implementation of some of these IOC algorithms.",
            "Turns out he's been around for a long time, but only recently have people looked at implementing them.",
            "And then I'm going to make the connection between the probabilistic part of this workshop, in particular the by leveraging now."
        ],
        [
            "Using imperfect behavior.",
            "Excellent so I'm 1/3 of the way through with.",
            "1/3 left OK, so the quick version of it is we collect a bunch of.",
            "Teleoperation data?",
            "OK, and I'll skip the.",
            "The rest of the point here, but we collect much teleoperation data of robot moving around.",
            "You kind of get the picture.",
            "OK, and let me show you.",
            "OK."
        ],
        [
            "So what does this look like?",
            "I'm showing you a schematic view.",
            "This is not the actual data from that case, but it gives you the idea you see a robot go from point A to point B because a person is driving it OK and the question is how do you interpret this data so that you agree with the humans interpretation?",
            "OK."
        ],
        [
            "And what that means is that if I give a test example an I tell the robot to go from point A to point."
        ],
        [
            "What do I expected to do?",
            "Well, I expected to do something like that, and the way it's do."
        ],
        [
            "Doing something like that is that it's interpreted the terrain so that it's interpreted.",
            "I'm going to always use black to mean low cost and like to mean high cost so that the road in that image is cheap.",
            "OK, that's the interpretation is large and I'll skip showing you other behavior."
        ],
        [
            "OK, let me give you a very quick intuition for how these algorithms work.",
            "They're really very intuitive.",
            "The basic idea is you want to, in fact, the first discussion of this work was actually done at NIPS couple years ago.",
            "The basic idea is very simple.",
            "You have some features that describe every location in the world, and you're going to create some cost function.",
            "Could be linear, could be much more general that describes the cost at that location.",
            "Alright, what you do algorithmically is very simple.",
            "You start by saying this is the path in green.",
            "I want to follow because that's what the human did.",
            "The path and blue is what the planner would do by default if it had no information.",
            "OK, and what you?"
        ],
        [
            "Do is say when I look at this when I look at the terrain around me, I determined that the obvious thing to do is to make this object higher cost and these objects lower costs because that's my likely to move me towards that."
        ],
        [
            "OK, it's very intuitive if you do this kind of algorithm.",
            "I'm giving it an algorithmic way, but it turns out you know this is a convex optimization problem and I'm giving you kind of the solution of the convex optimization problem.",
            "You'll assign high cost of that location and then you don't still don't drive exactly the path you want.",
            "Instead you drive something that goes over that rock, which is kind of unfortunate.",
            "OK, and at the next iteration you're saying, well that Rock should be high cost, and that graph should be still lower cost, because that's going to."
        ],
        [
            "Things work, so this is an example of the algorithm running.",
            "Unreal data, so this is Unreal data.",
            "Again, you're seeing certain overhead view."
        ],
        [
            "Real data and you're seeing it slowly agree with the human interpretation.",
            "Of the world by human interpretation, I'm saying it's giving the same trajectory the human is driving.",
            "OK, turns out you can use this for lots of things.",
            "Some of Nathan Ratliff's work is in using this on walking robots to figure out what the cost functions are for terrain foot placement.",
            "But"
        ],
        [
            "In the interest of time, I'll skip over that.",
            "OK, so there's a problem.",
            "Which is that this is great for robot programming, and the reason this is great for robot programming is that I can have an expert show me what I want to do, so I have this.",
            "I have this driver over the robot and he's an expert.",
            "He knows how to get from point A to point B.",
            "He knows the dynamics.",
            "The robot are so on and so forth.",
            "If I want to model real people, meaning not roboticists, then what I need to do is take into account the fact that people aren't optimal, right?",
            "They're doing something that's sub optimal.",
            "OK, and in fact people aren't operating in MDP, they're just doing some course product.",
            "This is just some coarse approximation of what's really going on OK, and there's no optimal policy that's going to agree with that."
        ],
        [
            "OK, so there's a very clever observation due to Peter reveal and Andrew Yang, which is that for linear cost functions, the if you can match the expected feature counts by linearity you must be getting the same reward as the.",
            "As the person you're trying to mimic.",
            "OK, so this isn't a statement about mimicking their behavior, it's a statement about getting the same reward as that person.",
            "Alright, so this is just the linearity assumption.",
            "If you can get the, you can get the same expected features, whatever those features are, you must be getting the same expected reward.",
            "OK, and this seems like a good idea, unfortunately."
        ],
        [
            "Getting the getting these expected feature counts right is very hard, so well, not very hard, but it's difficult because there's usually no optimal policy that can do it, and you need some kind of distribution over decisions.",
            "Once you have a distribution over decisions, you end up with a nil post problem in that there are many possible ways to get a particular set of feature counts, so you can achieve this in many particular ways, and the question is how should you solve this problem?"
        ],
        [
            "Alright, the classical way to solve this kind of problem where you have some kind of expectation constraint and you have a.",
            "Ill posed problem is to think about this as a maximum entropy problem.",
            "I want to be minimally committed to the particular policy or set of decisions that I'm making subject to.",
            "I get the same reward as the human.",
            "So that's one way to think about the problem.",
            "Now it turns out there's a detail that I don't have time to go into, but see Brian's poster, which is that you can actually do standard maximum entropy.",
            "You have to do a maximum causal entropy because data comes in overtime, so there's a causal sequence going on.",
            "OK."
        ],
        [
            "This is just what I said before.",
            "We want to ensure we achieve the same performance, but we want to minimize our commitment and that's sort of causal."
        ],
        [
            "Repeat symbol OK. Just to crank through at the end.",
            "Everyone is familiar with NPS."
        ],
        [
            "OK, in a standard MDP, what we do is we do Bellman backup equations OK when I do this maximum entropy model I get a different set of backup equations where."
        ],
        [
            "The only thing that happens is everywhere I see a Max, I replace it with the softmax.",
            "OK, so it turns out then the behavior is like a soft distribution over control actions alright.",
            "And given this softmax backup behavior, we can compute what feature weights will get us, the behavior of the human."
        ],
        [
            "And it turns out that there are simple gradient descent algorithms that do this.",
            "OK, and I'm just going to finish by talking about once you."
        ],
        [
            "Can do once you can predict stochastically what Hume."
        ],
        [
            "Is doing then you can do nice things."
        ],
        [
            "Like model their behavior and I'm showing some examples here of you collect data in some environment, then you try to predict where an agent is going.",
            "These are the places that the agent typically likes go.",
            "This is a person walking around the Intel lab in Pittsburgh."
        ],
        [
            "OK, and if you see the person moving, you can predict where you expect them to go in the future.",
            "OK, and this is this is using the fact that people have goals they're trying to get to certain locations.",
            "And again, if you're poster will show you some of the."
        ],
        [
            "Yeah.",
            "Ways that this adapts if the invite?"
        ],
        [
            "It changes which is kind of nice, so if you change the environment you get different results."
        ],
        [
            "OK, there are.",
            "There's sort of two different methods here.",
            "I just want to point out the nice part about this one is it's really fast.",
            "The nice part about this one is it's probabilistic."
        ],
        [
            "But they're both.",
            "They're both good approaches to the."
        ],
        [
            "Home.",
            "Finally, it's interesting to note that these maximum causal entropy models I'm describing are very closely related to some of the work that are going to be discussed this afternoon, and it's also very closely related to risk sensitive control, which is sort of an interesting connection that would be fun to talk about."
        ],
        [
            "I'm just going to leave it there 'cause I think I'm past time and take questions.",
            "This was worked with lots of people, including a number of people in this room, including Nathan Ratliff and Brian Ziebart.",
            "Dave Bradley.",
            "He's here.",
            "That's it.",
            "Are there any question?",
            "Yes.",
            "Yeah.",
            "For sure.",
            "Everywhere else that's right.",
            "That's right good.",
            "So the examples I was showing you there were very very simple because I was showing you you had all the features in advance, right?",
            "OK but but on the actual robot of course.",
            "Well sometimes you do because you often have overhead information that you're using.",
            "Take advantage of OK, it is.",
            "It is a more difficult problem and I can't tell you about how to do it here.",
            "But roughly speaking you create a ball around the robot.",
            "OK, where you do know the features and then you then you do an approximate answer outside where you're doing assumptive planning.",
            "You're saying that I'm assuming life is good outside of that ball.",
            "And I'm just going to shortest path or use prior information and you do a backup based on that.",
            "But you're absolutely right.",
            "It's that's sort of interesting case as well.",
            "Kevin overweight Ottoman intervention.",
            "Other stuff.",
            "Yes, it made me think.",
            "It is a structured problem, right?",
            "That's exactly right that the original derivation of this stuff for us was exactly we want to solve structured output problem and the in the space of things is plans or policies, right?",
            "And we're doing structured output over those.",
            "This maximum causal entropy classes is more general than the sort of normal class, because you have the side information coming in online, and that's that's the kind of expansion of that.",
            "But but you're absolutely right.",
            "Structured up, it's nice way to think about these problems.",
            "Or from.",
            "Question one is about the number of the exact center actually.",
            "Sure.",
            "Right?",
            "So, so for the typical behavior of that robot, it was on the order of an hour of data of driving, or that's roughly 50 trajectories of the robot to for the outdoor walking robot, I think anything could tell you the number of footsteps for the for the robot, but the most recent version of that kind of stuff is on the order of 500 footsteps.",
            "Just to give you a flavor by comparison, the hand design code that was used before this for the outdoor robot had over 300.",
            "Bitkeeper commits that were all hand vetted, right, that someone went through.",
            "It, ran the robots, all what happened updated things right?",
            "So men, man years of work versus an hour of collection.",
            "See that your local inspection workers.",
            "Yeah, that's right, and that's a really natural thing to do that we have not explored.",
            "Yep, I agree great 'cause you want it.",
            "You want to correct the mistakes that's making online.",
            "Nick for the training every time.",
            "Morning see also feature design problem, how general purpose were are transferred or your features from the other robots.",
            "A little dog to the restroom tracking I see good so.",
            "So yes, there's a feature as with all machine learning right?",
            "Good features make the performance, the features were hand designed on the system because they were designed originally.",
            "The system existed before learning was applied to that part, so they were hand design.",
            "I don't think a lot of them transfer, but the nice approach is that in a lot of the stuff we use a sort of boosting or functional approach where it kind of generates its own more sophisticated features from raw features, and that does alleviate that burden quite a bit.",
            "And so, for instance, you know Nathan's original work on The Walking robot he was looking at raw input patches of the terrain, so you can get away with some things.",
            "And then I guess I should get off the stage.",
            "Jay because it seems as though when you were talking at the start about the difference is kind of true behavior of learning and how generalizable it is that depending on your feature selection.",
            "It's difficult for me to imagine a set of features that I could again predict an action.",
            "Now when I'm thinking 10 kilometers in the future, it's definitely imagine there's any features that would do that for me.",
            "But do I turn left now, given that I've got 10 kilometers to go in front of me?",
            "I find it hard to imagine that working, at least for complicated terrain, but for simple things that can work.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Drew Bagnell.",
                    "label": 0
                },
                {
                    "sent": "Carnegie Mellon working in Robotics and machine learning.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a neat workshop because it's an interesting combination of different ideas, including some of these probabilistic techniques for control, and these probabilistic techniques for robotics.",
                    "label": 0
                },
                {
                    "sent": "I'm hoping that I get to spend that gap a little bit in the talk, although obviously.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fully OK, So what am I going to talk about today?",
                    "label": 0
                },
                {
                    "sent": "One problem I'm very interested in is the problem of imitation learning, so I want to show a robot what I wanted to do and I want to have it recover the same behavior in well, ideally, different circumstances.",
                    "label": 0
                },
                {
                    "sent": "OK, there's kind of two ways to think about the imitation learning problem.",
                    "label": 0
                },
                {
                    "sent": "One of them I would call something like the non generalizable imitation learning.",
                    "label": 0
                },
                {
                    "sent": "This is where you want to show some behavior and you want to recover exactly that same behavior.",
                    "label": 0
                },
                {
                    "sent": "So this great work by for instance Steven Shaw.",
                    "label": 0
                },
                {
                    "sent": "On some motor control applications where they're doing this kind of imitation learning Peter building some great work on helicopter acrobatics that have that same kind of imitation learning flavor.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to talk about today is where I wanted to generalize to new situations, so I want to show some behavior, and then I want to get in a related but different situation.",
                    "label": 0
                },
                {
                    "sent": "The same behavior that I would generate without that.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's lots of interesting problems in imitation learning, and I encourage you to go to Stephen Ross is poster and Brian Ziebart.",
                    "label": 0
                },
                {
                    "sent": "Poster later this afternoon I'll talk about some of them, but the particular one I want to talk to you about right now.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is how we get the kind of how we get imitation learning of the kind of behaviors that I'm particularly interested in, which is sort of long horizon or goal directed behaviors.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do imitation learning of those kind of behaviors, and I'm going to show you a concrete example.",
                    "label": 0
                },
                {
                    "sent": "So this is some work.",
                    "label": 0
                },
                {
                    "sent": "Make sure the sound is off.",
                    "label": 0
                },
                {
                    "sent": "This is some work that I did.",
                    "label": 0
                },
                {
                    "sent": "Leading the perception and.",
                    "label": 0
                },
                {
                    "sent": "Learning aspects the goal here is very simple.",
                    "label": 0
                },
                {
                    "sent": "You have a robot you want to put it down at point A.",
                    "label": 0
                },
                {
                    "sent": "You wanted to go to point B, point point B, or separated by somewhere between one and 10 kilometers, and the terrain is potentially very complicated.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is how do you get a robot to do this task?",
                    "label": 0
                },
                {
                    "sent": "It turns out to be very hard to hand program or robot to do this task, and the thing you'd like to do is just drive the robot from point A to point B yourself, then give it a new point point be right, Sonu start location, a new goal location and it can figure out how to do.",
                    "label": 0
                },
                {
                    "sent": "How to navigate from location to location in that related but not the same problem?",
                    "label": 0
                },
                {
                    "sent": "OK, that's the kind of that's the kind of goal here.",
                    "label": 0
                },
                {
                    "sent": "Videos funny, I don't know what happened there.",
                    "label": 0
                },
                {
                    "sent": "So if you watch carefully here, you'll notice what we call a control failure.",
                    "label": 0
                },
                {
                    "sent": "Keep your eyes open right in this ballpark so.",
                    "label": 0
                },
                {
                    "sent": "Oh I believe the control guys.",
                    "label": 0
                },
                {
                    "sent": "OK, so the problem is very hard because the world is full of things like vegetation and itches and high centering hazards and slopes and all kinds of things that make it really hard to program this behavior.",
                    "label": 0
                },
                {
                    "sent": "And there's occlusions from vegetation and it's really hard to tell with vegetation.",
                    "label": 0
                },
                {
                    "sent": "The classification problem is really difficult.",
                    "label": 0
                },
                {
                    "sent": "It's very difficult to kind of get this behavior with standard machine learning method.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I want to convince you of is that I think it's pretty easy to convince you of this, that if I just said I'm going to take some input features.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Describe the world.",
                    "label": 0
                },
                {
                    "sent": "So think of these as camera imagery or some features computed from Leithart data and I just directly try to use your favorite off the shelf algorithm.",
                    "label": 0
                },
                {
                    "sent": "I don't know support vector machine and try to predict what the robot should do at each time step.",
                    "label": 0
                },
                {
                    "sent": "Make a left turn, go straight, make a right turn.",
                    "label": 0
                },
                {
                    "sent": "You're going to have a really, really hard time making this work, especially if you want to go 10 kilometers away and instead.",
                    "label": 0
                },
                {
                    "sent": "Well, we take advantage of is the way state of the art robotic systems actually work, which is that they all have some kind of planning or control or optimal control algorithm that lives close to the bottom.",
                    "label": 0
                },
                {
                    "sent": "And I'm showing you here a schematic of this.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is what happens is you've got some features that describe the world, and so these are computed from imagery and later potentially overhead.",
                    "label": 0
                },
                {
                    "sent": "So maybe I get images of the world from up above.",
                    "label": 0
                },
                {
                    "sent": "What ultimately happens is some cost function is generated and there's a planner.",
                    "label": 0
                },
                {
                    "sent": "I'm showing it as a 2 dimensional planner here that figures out what the minimum cost is to go from the start to the goal.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is the way robot systems work, and now the learning problem becomes one of figuring out how to interpret sensor data so that we get a cost function so that the planner does what we wanted to do.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the sort of high level goal of the approach.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this kind of problem is very naturally phrased as an inverse optimal control problem.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "Inverse optimal control means that optimal control is.",
                    "label": 1
                },
                {
                    "sent": "I have some cost function.",
                    "label": 0
                },
                {
                    "sent": "I have some planner and my goal is to try to find the minimum cost way to get from point A to point B.",
                    "label": 0
                },
                {
                    "sent": "Here we're doing the opposite.",
                    "label": 0
                },
                {
                    "sent": "What we're saying is we have examples of the behavior we want to imitate, and we're trying to make the planner do the same thing.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're sort of inverting the optimal control problem.",
                    "label": 0
                },
                {
                    "sent": "Turns out this is a really old problem.",
                    "label": 0
                },
                {
                    "sent": "It goes back in fact, too common.",
                    "label": 0
                },
                {
                    "sent": "He looked at the scalar control case, basically taking his own LQ our work and asking the question.",
                    "label": 0
                },
                {
                    "sent": "If you take a generic linear controller, is it optimal for any LQ our objective function and he was able to answer this for the scalar control case and then later work answered this for LTI systems and there's been lots of work investigating this for MVP's as well, particularly by.",
                    "label": 0
                },
                {
                    "sent": "And ring, Stuart Russell and Peter Beale among others.",
                    "label": 0
                },
                {
                    "sent": "OK, so the contributions that I'm going to talk about today are the first set of algorithms for general planning problems.",
                    "label": 1
                },
                {
                    "sent": "Meaning these kind of things which you are able to give regret bounds, meaning that you're able to guarantee performance mimicking the person's behavior.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, that's under all the usual kind of assumptions of margin and separability.",
                    "label": 0
                },
                {
                    "sent": "OK and generalization bounds so that if you see new data, you'll be able to recreate that same kind of behavior and finally want to talk about implementation of some of these IOC algorithms.",
                    "label": 0
                },
                {
                    "sent": "Turns out he's been around for a long time, but only recently have people looked at implementing them.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to make the connection between the probabilistic part of this workshop, in particular the by leveraging now.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using imperfect behavior.",
                    "label": 0
                },
                {
                    "sent": "Excellent so I'm 1/3 of the way through with.",
                    "label": 0
                },
                {
                    "sent": "1/3 left OK, so the quick version of it is we collect a bunch of.",
                    "label": 0
                },
                {
                    "sent": "Teleoperation data?",
                    "label": 0
                },
                {
                    "sent": "OK, and I'll skip the.",
                    "label": 0
                },
                {
                    "sent": "The rest of the point here, but we collect much teleoperation data of robot moving around.",
                    "label": 0
                },
                {
                    "sent": "You kind of get the picture.",
                    "label": 0
                },
                {
                    "sent": "OK, and let me show you.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what does this look like?",
                    "label": 0
                },
                {
                    "sent": "I'm showing you a schematic view.",
                    "label": 0
                },
                {
                    "sent": "This is not the actual data from that case, but it gives you the idea you see a robot go from point A to point B because a person is driving it OK and the question is how do you interpret this data so that you agree with the humans interpretation?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what that means is that if I give a test example an I tell the robot to go from point A to point.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What do I expected to do?",
                    "label": 0
                },
                {
                    "sent": "Well, I expected to do something like that, and the way it's do.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing something like that is that it's interpreted the terrain so that it's interpreted.",
                    "label": 0
                },
                {
                    "sent": "I'm going to always use black to mean low cost and like to mean high cost so that the road in that image is cheap.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the interpretation is large and I'll skip showing you other behavior.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let me give you a very quick intuition for how these algorithms work.",
                    "label": 0
                },
                {
                    "sent": "They're really very intuitive.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is you want to, in fact, the first discussion of this work was actually done at NIPS couple years ago.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "You have some features that describe every location in the world, and you're going to create some cost function.",
                    "label": 0
                },
                {
                    "sent": "Could be linear, could be much more general that describes the cost at that location.",
                    "label": 0
                },
                {
                    "sent": "Alright, what you do algorithmically is very simple.",
                    "label": 0
                },
                {
                    "sent": "You start by saying this is the path in green.",
                    "label": 0
                },
                {
                    "sent": "I want to follow because that's what the human did.",
                    "label": 0
                },
                {
                    "sent": "The path and blue is what the planner would do by default if it had no information.",
                    "label": 0
                },
                {
                    "sent": "OK, and what you?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do is say when I look at this when I look at the terrain around me, I determined that the obvious thing to do is to make this object higher cost and these objects lower costs because that's my likely to move me towards that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, it's very intuitive if you do this kind of algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'm giving it an algorithmic way, but it turns out you know this is a convex optimization problem and I'm giving you kind of the solution of the convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "You'll assign high cost of that location and then you don't still don't drive exactly the path you want.",
                    "label": 1
                },
                {
                    "sent": "Instead you drive something that goes over that rock, which is kind of unfortunate.",
                    "label": 0
                },
                {
                    "sent": "OK, and at the next iteration you're saying, well that Rock should be high cost, and that graph should be still lower cost, because that's going to.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things work, so this is an example of the algorithm running.",
                    "label": 0
                },
                {
                    "sent": "Unreal data, so this is Unreal data.",
                    "label": 0
                },
                {
                    "sent": "Again, you're seeing certain overhead view.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Real data and you're seeing it slowly agree with the human interpretation.",
                    "label": 0
                },
                {
                    "sent": "Of the world by human interpretation, I'm saying it's giving the same trajectory the human is driving.",
                    "label": 0
                },
                {
                    "sent": "OK, turns out you can use this for lots of things.",
                    "label": 0
                },
                {
                    "sent": "Some of Nathan Ratliff's work is in using this on walking robots to figure out what the cost functions are for terrain foot placement.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the interest of time, I'll skip over that.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a problem.",
                    "label": 0
                },
                {
                    "sent": "Which is that this is great for robot programming, and the reason this is great for robot programming is that I can have an expert show me what I want to do, so I have this.",
                    "label": 0
                },
                {
                    "sent": "I have this driver over the robot and he's an expert.",
                    "label": 0
                },
                {
                    "sent": "He knows how to get from point A to point B.",
                    "label": 0
                },
                {
                    "sent": "He knows the dynamics.",
                    "label": 0
                },
                {
                    "sent": "The robot are so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "If I want to model real people, meaning not roboticists, then what I need to do is take into account the fact that people aren't optimal, right?",
                    "label": 0
                },
                {
                    "sent": "They're doing something that's sub optimal.",
                    "label": 0
                },
                {
                    "sent": "OK, and in fact people aren't operating in MDP, they're just doing some course product.",
                    "label": 0
                },
                {
                    "sent": "This is just some coarse approximation of what's really going on OK, and there's no optimal policy that's going to agree with that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there's a very clever observation due to Peter reveal and Andrew Yang, which is that for linear cost functions, the if you can match the expected feature counts by linearity you must be getting the same reward as the.",
                    "label": 0
                },
                {
                    "sent": "As the person you're trying to mimic.",
                    "label": 0
                },
                {
                    "sent": "OK, so this isn't a statement about mimicking their behavior, it's a statement about getting the same reward as that person.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is just the linearity assumption.",
                    "label": 0
                },
                {
                    "sent": "If you can get the, you can get the same expected features, whatever those features are, you must be getting the same expected reward.",
                    "label": 0
                },
                {
                    "sent": "OK, and this seems like a good idea, unfortunately.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Getting the getting these expected feature counts right is very hard, so well, not very hard, but it's difficult because there's usually no optimal policy that can do it, and you need some kind of distribution over decisions.",
                    "label": 0
                },
                {
                    "sent": "Once you have a distribution over decisions, you end up with a nil post problem in that there are many possible ways to get a particular set of feature counts, so you can achieve this in many particular ways, and the question is how should you solve this problem?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, the classical way to solve this kind of problem where you have some kind of expectation constraint and you have a.",
                    "label": 0
                },
                {
                    "sent": "Ill posed problem is to think about this as a maximum entropy problem.",
                    "label": 1
                },
                {
                    "sent": "I want to be minimally committed to the particular policy or set of decisions that I'm making subject to.",
                    "label": 1
                },
                {
                    "sent": "I get the same reward as the human.",
                    "label": 0
                },
                {
                    "sent": "So that's one way to think about the problem.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out there's a detail that I don't have time to go into, but see Brian's poster, which is that you can actually do standard maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "You have to do a maximum causal entropy because data comes in overtime, so there's a causal sequence going on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is just what I said before.",
                    "label": 0
                },
                {
                    "sent": "We want to ensure we achieve the same performance, but we want to minimize our commitment and that's sort of causal.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Repeat symbol OK. Just to crank through at the end.",
                    "label": 0
                },
                {
                    "sent": "Everyone is familiar with NPS.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, in a standard MDP, what we do is we do Bellman backup equations OK when I do this maximum entropy model I get a different set of backup equations where.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The only thing that happens is everywhere I see a Max, I replace it with the softmax.",
                    "label": 0
                },
                {
                    "sent": "OK, so it turns out then the behavior is like a soft distribution over control actions alright.",
                    "label": 0
                },
                {
                    "sent": "And given this softmax backup behavior, we can compute what feature weights will get us, the behavior of the human.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that there are simple gradient descent algorithms that do this.",
                    "label": 0
                },
                {
                    "sent": "OK, and I'm just going to finish by talking about once you.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can do once you can predict stochastically what Hume.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is doing then you can do nice things.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like model their behavior and I'm showing some examples here of you collect data in some environment, then you try to predict where an agent is going.",
                    "label": 0
                },
                {
                    "sent": "These are the places that the agent typically likes go.",
                    "label": 0
                },
                {
                    "sent": "This is a person walking around the Intel lab in Pittsburgh.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and if you see the person moving, you can predict where you expect them to go in the future.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is this is using the fact that people have goals they're trying to get to certain locations.",
                    "label": 0
                },
                {
                    "sent": "And again, if you're poster will show you some of the.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Ways that this adapts if the invite?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It changes which is kind of nice, so if you change the environment you get different results.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there are.",
                    "label": 0
                },
                {
                    "sent": "There's sort of two different methods here.",
                    "label": 0
                },
                {
                    "sent": "I just want to point out the nice part about this one is it's really fast.",
                    "label": 0
                },
                {
                    "sent": "The nice part about this one is it's probabilistic.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But they're both.",
                    "label": 0
                },
                {
                    "sent": "They're both good approaches to the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Home.",
                    "label": 0
                },
                {
                    "sent": "Finally, it's interesting to note that these maximum causal entropy models I'm describing are very closely related to some of the work that are going to be discussed this afternoon, and it's also very closely related to risk sensitive control, which is sort of an interesting connection that would be fun to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm just going to leave it there 'cause I think I'm past time and take questions.",
                    "label": 0
                },
                {
                    "sent": "This was worked with lots of people, including a number of people in this room, including Nathan Ratliff and Brian Ziebart.",
                    "label": 0
                },
                {
                    "sent": "Dave Bradley.",
                    "label": 0
                },
                {
                    "sent": "He's here.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "Are there any question?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "For sure.",
                    "label": 0
                },
                {
                    "sent": "Everywhere else that's right.",
                    "label": 0
                },
                {
                    "sent": "That's right good.",
                    "label": 0
                },
                {
                    "sent": "So the examples I was showing you there were very very simple because I was showing you you had all the features in advance, right?",
                    "label": 0
                },
                {
                    "sent": "OK but but on the actual robot of course.",
                    "label": 0
                },
                {
                    "sent": "Well sometimes you do because you often have overhead information that you're using.",
                    "label": 0
                },
                {
                    "sent": "Take advantage of OK, it is.",
                    "label": 0
                },
                {
                    "sent": "It is a more difficult problem and I can't tell you about how to do it here.",
                    "label": 0
                },
                {
                    "sent": "But roughly speaking you create a ball around the robot.",
                    "label": 0
                },
                {
                    "sent": "OK, where you do know the features and then you then you do an approximate answer outside where you're doing assumptive planning.",
                    "label": 0
                },
                {
                    "sent": "You're saying that I'm assuming life is good outside of that ball.",
                    "label": 0
                },
                {
                    "sent": "And I'm just going to shortest path or use prior information and you do a backup based on that.",
                    "label": 0
                },
                {
                    "sent": "But you're absolutely right.",
                    "label": 0
                },
                {
                    "sent": "It's that's sort of interesting case as well.",
                    "label": 0
                },
                {
                    "sent": "Kevin overweight Ottoman intervention.",
                    "label": 0
                },
                {
                    "sent": "Other stuff.",
                    "label": 0
                },
                {
                    "sent": "Yes, it made me think.",
                    "label": 0
                },
                {
                    "sent": "It is a structured problem, right?",
                    "label": 0
                },
                {
                    "sent": "That's exactly right that the original derivation of this stuff for us was exactly we want to solve structured output problem and the in the space of things is plans or policies, right?",
                    "label": 0
                },
                {
                    "sent": "And we're doing structured output over those.",
                    "label": 0
                },
                {
                    "sent": "This maximum causal entropy classes is more general than the sort of normal class, because you have the side information coming in online, and that's that's the kind of expansion of that.",
                    "label": 0
                },
                {
                    "sent": "But but you're absolutely right.",
                    "label": 0
                },
                {
                    "sent": "Structured up, it's nice way to think about these problems.",
                    "label": 0
                },
                {
                    "sent": "Or from.",
                    "label": 0
                },
                {
                    "sent": "Question one is about the number of the exact center actually.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So, so for the typical behavior of that robot, it was on the order of an hour of data of driving, or that's roughly 50 trajectories of the robot to for the outdoor walking robot, I think anything could tell you the number of footsteps for the for the robot, but the most recent version of that kind of stuff is on the order of 500 footsteps.",
                    "label": 0
                },
                {
                    "sent": "Just to give you a flavor by comparison, the hand design code that was used before this for the outdoor robot had over 300.",
                    "label": 0
                },
                {
                    "sent": "Bitkeeper commits that were all hand vetted, right, that someone went through.",
                    "label": 0
                },
                {
                    "sent": "It, ran the robots, all what happened updated things right?",
                    "label": 0
                },
                {
                    "sent": "So men, man years of work versus an hour of collection.",
                    "label": 0
                },
                {
                    "sent": "See that your local inspection workers.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's right, and that's a really natural thing to do that we have not explored.",
                    "label": 0
                },
                {
                    "sent": "Yep, I agree great 'cause you want it.",
                    "label": 0
                },
                {
                    "sent": "You want to correct the mistakes that's making online.",
                    "label": 0
                },
                {
                    "sent": "Nick for the training every time.",
                    "label": 0
                },
                {
                    "sent": "Morning see also feature design problem, how general purpose were are transferred or your features from the other robots.",
                    "label": 0
                },
                {
                    "sent": "A little dog to the restroom tracking I see good so.",
                    "label": 0
                },
                {
                    "sent": "So yes, there's a feature as with all machine learning right?",
                    "label": 0
                },
                {
                    "sent": "Good features make the performance, the features were hand designed on the system because they were designed originally.",
                    "label": 0
                },
                {
                    "sent": "The system existed before learning was applied to that part, so they were hand design.",
                    "label": 0
                },
                {
                    "sent": "I don't think a lot of them transfer, but the nice approach is that in a lot of the stuff we use a sort of boosting or functional approach where it kind of generates its own more sophisticated features from raw features, and that does alleviate that burden quite a bit.",
                    "label": 0
                },
                {
                    "sent": "And so, for instance, you know Nathan's original work on The Walking robot he was looking at raw input patches of the terrain, so you can get away with some things.",
                    "label": 0
                },
                {
                    "sent": "And then I guess I should get off the stage.",
                    "label": 0
                },
                {
                    "sent": "Jay because it seems as though when you were talking at the start about the difference is kind of true behavior of learning and how generalizable it is that depending on your feature selection.",
                    "label": 0
                },
                {
                    "sent": "It's difficult for me to imagine a set of features that I could again predict an action.",
                    "label": 0
                },
                {
                    "sent": "Now when I'm thinking 10 kilometers in the future, it's definitely imagine there's any features that would do that for me.",
                    "label": 0
                },
                {
                    "sent": "But do I turn left now, given that I've got 10 kilometers to go in front of me?",
                    "label": 0
                },
                {
                    "sent": "I find it hard to imagine that working, at least for complicated terrain, but for simple things that can work.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}