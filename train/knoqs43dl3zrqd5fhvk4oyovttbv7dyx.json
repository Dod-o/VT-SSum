{
    "id": "knoqs43dl3zrqd5fhvk4oyovttbv7dyx",
    "title": "Selection of Basis Functions in Regression as Search Guided by the Evidence",
    "info": {
        "author": [
            "Ignacio Barrio, James Madison University"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2006",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/learning06_barrio_sbfrs/",
    "segmentation": [
        [
            "Anne hello, my name is Ignacio Barrio.",
            "I have called for this work with Integral Meadow and useful answer.",
            "From there we shared that with that particular dunia, and this is about.",
            "The selection of basis functions in regression.",
            "A search guided by the by the evidence."
        ],
        [
            "I will start by.",
            "By presenting the problem definition then.",
            "But when?",
            "Overview just some of the methods that perform this basis.",
            "This base election, along with the.",
            "With regression.",
            "And then we will.",
            "Review that we will present the objectives of this work."
        ],
        [
            "Then we will.",
            "Review two of the.",
            "Of the techniques and necessary for the four R4 methods, which are basically a combination of these two.",
            "So areas which are based on interpolation or regression.",
            "Ann search strategies.",
            "There are models from.",
            "From the feature selection field."
        ],
        [
            "Anne.",
            "Well then we present the methods.",
            "How to implement them and and we will show some expert."
        ],
        [
            "And we will close with the discussion."
        ],
        [
            "Not a problem.",
            "It's a regression problem we have.",
            "Datasets and they said we.",
            "With inputs and outputs where the outputs are real valued.",
            "In order to model this, we will use a generalized linear model.",
            "With N fixed basis functions.",
            "Which are weighted by the parameter.",
            "And then the problem is to buy the one hand to compute the parameters and the other hand to select the basis functions.",
            "From a Dictionary of.",
            "And no other places functions.",
            "And then the M is a function that we want to select this unknown."
        ],
        [
            "There are some methods that can be that basically tackle this same problem.",
            "We can classify them between the methods that perform an implicit selection.",
            "An methods that perform an explicit selection.",
            "Implicit selection we we mean.",
            "An methods that consider the whole Dictionary of basis functions.",
            "And then they compute the parameters in a way in such a way that most of these parameters become zero.",
            "Which produces partial models.",
            "Some of these methods are basic persuade the relevance vector machine, least absolute secrets, an selection operator.",
            "And support vector machines at this support vector machines.",
            "Are special case because they need the Dictionary of basis functions.",
            "Has to be kernel functions centered at the input data.",
            "An on the other hand, there are explicit selection methods.",
            "The what basically they follow an explicit search.",
            "At on the space of of of basis functions.",
            "Most of them follow forward selection and minimizing or maximizing, minimizing some cost function.",
            "Some of these methods are matching persuades orthogonal least squares, regularised orthogonal least squares.",
            "Gonna much impulse weight, which is a generalization of these methods.",
            "And some Gaussian processes, approximations, partials impress approximation.",
            "Where again like support vector machines, they require the basis functions.",
            "To to be kernels because they need cover covariance functions."
        ],
        [
            "Now what is our objective?",
            "We can based on framework?",
            "And the evidence has been suggested.",
            "To compare different models.",
            "This was in an article that we will populate.",
            "And then the objective.",
            "The objective is the evidence has been suggested to compare different models.",
            "Just use the evidence to search in the space of.",
            "Of models and that is we object is to find that a model with high evidence by performing an explicit search.",
            "Anne.",
            "Then we will use different search strategies.",
            "To.",
            "To assess the effect of this effect of evidence maximization, for example, we used.",
            "The sum of square server for example like in most neural networks.",
            "Maximizing minimizing this matter so much this error is known to let overfitting.",
            "Then what is the effect of maximizing too much?",
            "The evidence?",
            "Then we will use different search strategies to.",
            "To."
        ],
        [
            "To assess this.",
            "Now we will."
        ],
        [
            "Review the Mackays approach about based on interpolation for linear models.",
            "Hey, it's an article appear in neural computation.",
            "He considers 3 levels of inference in the first level.",
            "He considers the posterior distribution of the over the parameters.",
            "In the second level, he adapts the hyper parameters that control these parameters an in the third level he.",
            "He proposes the evidence to compare different models."
        ],
        [
            "Now the first, the first level of inference.",
            "We will assume that the targets are generated for a function from a function.",
            "Why?",
            "Why?",
            "Somebody different noise this function?",
            "Why is assumed to come from a from a generalized linear model with where the fee is the sign matrix.",
            "And then we assume that the.",
            "The noise is 0 mean with variance Sigma squared.",
            "Then the likelihood for the data.",
            "Can be written as aghasyan.",
            "And we want.",
            "But this is the inverse variance.",
            "Anne.",
            "Then minimizing maximizing too much of this probability, maximizing this likelihood for the parameters.",
            "Is known to lead to overfitting becausw.",
            "We are not not controlling the scale of these parameters and then they can grow.",
            "And we can we can overfit the data.",
            "Then one common approach is to place a.",
            "A prior probability over the parameters.",
            "One common approach is to consider assuming Gaussian prior.",
            "Like this one.",
            "Well, I've never said this, but I.",
            "We are considering now that we know the.",
            "The noise level, the noise for ions.",
            "And we suppose that we we also know this Alpha.",
            "This inverse variance then.",
            "OK, as you may know."
        ],
        [
            "It is known we can use Bayes rule to compute the posterior over the parameters.",
            "This is a product of two oceans.",
            "Which is a version normalized by the.",
            "Marginal likelihood below.",
            "I mean this is this is a version.",
            "With them in I mean.",
            "Valuan and.",
            "Overhead an.",
            "OK, and this is this mew mew move.",
            "Is the mean for the parameters and then is the most probable value for the parameter, which we will.",
            "Set the parameters to this value.",
            "In practice, however, they know that the movie is dependent on beta.",
            "And also depending on Alpha equals it depends on Sigma which depends on Alpha then OK, we are here.",
            "Considering that we know better alphabet.",
            "In practice, we do not."
        ],
        [
            "Then the second level is inference.",
            "The problem is to.",
            "Anne.",
            "To find the most probable values for Alpha and beta.",
            "Anne, how do this we?",
            "Consider the marginal likelihood, which is this integral here, which is computable because this is a product of two Gaussians.",
            "Which is about in and in Paradise Ocean.",
            "And then in order to compute the most probable value, we should again use Bayes rule.",
            "However, in this case we will assume that the probability for Alpha and beta is flat in original scale and then with the only thing we have to do is to maximize the marginal likelihood.",
            "Well, this is an aggressive browser.",
            "Then he.",
            "In order to do this, there is the.",
            "The equation for marginal likelihood said the result to zero and found a couple of restaurant estimation formulas.",
            "Where this W should be a move in the same mistake.",
            "In the previous slide, then Alpha, Beta and are dependent on more and more is dependent on our fun beta, so we have to rest a mate both formulas until they converge."
        ],
        [
            "And finally, the third level of inference.",
            "Is to have to compare different models?",
            "Anne.",
            "The using Bayes rule again, the first the first term is.",
            "In the in the right in the right hand side.",
            "Is the evidence for the model.",
            "The second term is the prior probability for the model, which we will assume to be the same for all the models.",
            "However, we will see this assumption is not always correct.",
            "They enter in other, compute the evidence we should integrate out Alpha and beta, but well, this integral is.",
            "It's intractable, an approximate.",
            "So with this with a separable Gaussian.",
            "Around the most probable values for Alpha and beta.",
            "What is this formula here?"
        ],
        [
            "Now we see the about the searches."
        ],
        [
            "Bridges Ann search strategies are very commonly used in feature selection, but also in any subset selection method.",
            "And some come on.",
            "Some common strategies are.",
            "Plus Ellen, take away our.",
            "Which is a UR.",
            "L basis function elements not only basis functions, you are elements and then they go away are consecutive.",
            "Forward flexion is a special case which is PTA 10.",
            "So sequential forward floating selection, which is probably the most complex search strategies and the most powerful.",
            "An which also has the highest cost.",
            "Which is I mean one element.",
            "On removing elements while the best solution with that number of elements.",
            "Until this moment is worse than the actual one.",
            "And then is also slating 5 Biofinity operating C. Where you start with a fixed number of elements and then you start to oscillate around this number of elements.",
            "Anne.",
            "When the until you until you don't improve the."
        ],
        [
            "Action.",
            "And now we propose."
        ],
        [
            "Our method is the third strategy is guided by the evidence.",
            "In order to do this, we need to implement the operations to the best basics basis functions from a set of candidates and to remove the worst basis function from the model.",
            "Where the best and worst is with according to the evidence, the best is.",
            "The one with which produces the highest evidence for the model.",
            "And in order to do this is desirable that.",
            "We can take advantage of the previous solution and to perform there incrementally, which is.",
            "Which is implemented in the paper and I won't enter into into the tails here.",
            "And then you you need to create a Dictionary of basis function.",
            "A very common approach is to use RBF.",
            "As many RBF basis functions as data points, each basis function centered at one inch input data.",
            "This is very common.",
            "For example in vector machine and or tonalist squares.",
            "Or even support vector machines.",
            "And finally we have to select the search strategy."
        ],
        [
            "And now it will show the experiment we have performed."
        ],
        [
            "Anne.",
            "We in the Y axis the vertical axis shows the log evidence for the model.",
            "On the horizontal axis, shows a number of basis functions of the model.",
            "We can see that float, sequential forward floating selection.",
            "Achieves the highest evidence.",
            "Which is also achieved with with the lowest number of basis functions I mean.",
            "The model with the lowest basic function is found by.",
            "By floating, we're going to see that forward selection is the worst.",
            "The worst.",
            "Strategy as expected, because it's also the simplest one.",
            "Now this suggests also that if the number of basis functions is achieved with a low number of basis functions.",
            "If the best model is achieved with a low number of basis functions.",
            "Some stuff in criterion is.",
            "Is advisable in order to?",
            "Not to lose too much, too much time in computation.",
            "We have used simple, very simple stuff in criterion.",
            "When the number of basis functions.",
            "Where the best model has been achieved with a number of basis functions.",
            "Lower than 15 lower than the current model, we stop the process."
        ],
        [
            "Anne.",
            "Now we both performing experiments on on some datasets.",
            "Borrowed from the benefit there there were.",
            "Environment.",
            "And there are we have to put money in and clean.",
            "Datasets and there are various different tasks for each model.",
            "The fairly linear with high noise, fairly linear with moderate noise.",
            "Nonlinear with high noise, nonlinear with moderate noise.",
            "Anne.",
            "We're going to see that, for example, the nonlinear ones are the ones that require the highest number of basis functions.",
            "And when we perform with, we've used our 4th.",
            "We've used for search strategies, guided by the evidence, and we have also compared these results with the relevance vector machine.",
            "And the support vector machine, an orthogonal least squares.",
            "We're going to see.",
            "The search strategies guided by the evidence of very simple models.",
            "As compared for example, to support vector machines that requires a very high number of support vectors.",
            "Ann Floating, which is the model the strategy that found the highest evidence is has very similar sparsity to the relevance vector machine."
        ],
        [
            "Now here are the results of the previous one was about the number of basis functions.",
            "This is about the.",
            "The accuracy of the models.",
            "We have included a new method with this all basis functions AVF.",
            "And we use this.",
            "This is a model with all the basis functions included in the model.",
            "And then we simply compute the parameters as we have said in the first level of inference and compute the hyperparameter as we've said in the in the second level of inference.",
            "Then this model has as many basis functions as data.",
            "The data has a training set.",
            "Anne.",
            "Now this the left to right order is the same as the top to bottom.",
            "An Excel shows the number of tasks where the column method perform better.",
            "And then the roll method where better women having a P value lower than 0.05.",
            "And this P value was found in a T test.",
            "That is performed by the Delva.",
            "Environment.",
            "Now there were 40 tasks, 40 tasks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne hello, my name is Ignacio Barrio.",
                    "label": 0
                },
                {
                    "sent": "I have called for this work with Integral Meadow and useful answer.",
                    "label": 0
                },
                {
                    "sent": "From there we shared that with that particular dunia, and this is about.",
                    "label": 0
                },
                {
                    "sent": "The selection of basis functions in regression.",
                    "label": 1
                },
                {
                    "sent": "A search guided by the by the evidence.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will start by.",
                    "label": 0
                },
                {
                    "sent": "By presenting the problem definition then.",
                    "label": 1
                },
                {
                    "sent": "But when?",
                    "label": 0
                },
                {
                    "sent": "Overview just some of the methods that perform this basis.",
                    "label": 0
                },
                {
                    "sent": "This base election, along with the.",
                    "label": 0
                },
                {
                    "sent": "With regression.",
                    "label": 0
                },
                {
                    "sent": "And then we will.",
                    "label": 0
                },
                {
                    "sent": "Review that we will present the objectives of this work.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we will.",
                    "label": 0
                },
                {
                    "sent": "Review two of the.",
                    "label": 0
                },
                {
                    "sent": "Of the techniques and necessary for the four R4 methods, which are basically a combination of these two.",
                    "label": 0
                },
                {
                    "sent": "So areas which are based on interpolation or regression.",
                    "label": 0
                },
                {
                    "sent": "Ann search strategies.",
                    "label": 0
                },
                {
                    "sent": "There are models from.",
                    "label": 0
                },
                {
                    "sent": "From the feature selection field.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Well then we present the methods.",
                    "label": 0
                },
                {
                    "sent": "How to implement them and and we will show some expert.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we will close with the discussion.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not a problem.",
                    "label": 0
                },
                {
                    "sent": "It's a regression problem we have.",
                    "label": 0
                },
                {
                    "sent": "Datasets and they said we.",
                    "label": 0
                },
                {
                    "sent": "With inputs and outputs where the outputs are real valued.",
                    "label": 0
                },
                {
                    "sent": "In order to model this, we will use a generalized linear model.",
                    "label": 1
                },
                {
                    "sent": "With N fixed basis functions.",
                    "label": 0
                },
                {
                    "sent": "Which are weighted by the parameter.",
                    "label": 1
                },
                {
                    "sent": "And then the problem is to buy the one hand to compute the parameters and the other hand to select the basis functions.",
                    "label": 0
                },
                {
                    "sent": "From a Dictionary of.",
                    "label": 0
                },
                {
                    "sent": "And no other places functions.",
                    "label": 0
                },
                {
                    "sent": "And then the M is a function that we want to select this unknown.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some methods that can be that basically tackle this same problem.",
                    "label": 0
                },
                {
                    "sent": "We can classify them between the methods that perform an implicit selection.",
                    "label": 0
                },
                {
                    "sent": "An methods that perform an explicit selection.",
                    "label": 0
                },
                {
                    "sent": "Implicit selection we we mean.",
                    "label": 1
                },
                {
                    "sent": "An methods that consider the whole Dictionary of basis functions.",
                    "label": 0
                },
                {
                    "sent": "And then they compute the parameters in a way in such a way that most of these parameters become zero.",
                    "label": 0
                },
                {
                    "sent": "Which produces partial models.",
                    "label": 0
                },
                {
                    "sent": "Some of these methods are basic persuade the relevance vector machine, least absolute secrets, an selection operator.",
                    "label": 1
                },
                {
                    "sent": "And support vector machines at this support vector machines.",
                    "label": 0
                },
                {
                    "sent": "Are special case because they need the Dictionary of basis functions.",
                    "label": 0
                },
                {
                    "sent": "Has to be kernel functions centered at the input data.",
                    "label": 0
                },
                {
                    "sent": "An on the other hand, there are explicit selection methods.",
                    "label": 0
                },
                {
                    "sent": "The what basically they follow an explicit search.",
                    "label": 0
                },
                {
                    "sent": "At on the space of of of basis functions.",
                    "label": 0
                },
                {
                    "sent": "Most of them follow forward selection and minimizing or maximizing, minimizing some cost function.",
                    "label": 1
                },
                {
                    "sent": "Some of these methods are matching persuades orthogonal least squares, regularised orthogonal least squares.",
                    "label": 0
                },
                {
                    "sent": "Gonna much impulse weight, which is a generalization of these methods.",
                    "label": 0
                },
                {
                    "sent": "And some Gaussian processes, approximations, partials impress approximation.",
                    "label": 1
                },
                {
                    "sent": "Where again like support vector machines, they require the basis functions.",
                    "label": 0
                },
                {
                    "sent": "To to be kernels because they need cover covariance functions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what is our objective?",
                    "label": 0
                },
                {
                    "sent": "We can based on framework?",
                    "label": 0
                },
                {
                    "sent": "And the evidence has been suggested.",
                    "label": 0
                },
                {
                    "sent": "To compare different models.",
                    "label": 0
                },
                {
                    "sent": "This was in an article that we will populate.",
                    "label": 0
                },
                {
                    "sent": "And then the objective.",
                    "label": 0
                },
                {
                    "sent": "The objective is the evidence has been suggested to compare different models.",
                    "label": 1
                },
                {
                    "sent": "Just use the evidence to search in the space of.",
                    "label": 1
                },
                {
                    "sent": "Of models and that is we object is to find that a model with high evidence by performing an explicit search.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Then we will use different search strategies.",
                    "label": 0
                },
                {
                    "sent": "To.",
                    "label": 1
                },
                {
                    "sent": "To assess the effect of this effect of evidence maximization, for example, we used.",
                    "label": 0
                },
                {
                    "sent": "The sum of square server for example like in most neural networks.",
                    "label": 0
                },
                {
                    "sent": "Maximizing minimizing this matter so much this error is known to let overfitting.",
                    "label": 0
                },
                {
                    "sent": "Then what is the effect of maximizing too much?",
                    "label": 1
                },
                {
                    "sent": "The evidence?",
                    "label": 0
                },
                {
                    "sent": "Then we will use different search strategies to.",
                    "label": 0
                },
                {
                    "sent": "To.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To assess this.",
                    "label": 0
                },
                {
                    "sent": "Now we will.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Review the Mackays approach about based on interpolation for linear models.",
                    "label": 0
                },
                {
                    "sent": "Hey, it's an article appear in neural computation.",
                    "label": 1
                },
                {
                    "sent": "He considers 3 levels of inference in the first level.",
                    "label": 1
                },
                {
                    "sent": "He considers the posterior distribution of the over the parameters.",
                    "label": 1
                },
                {
                    "sent": "In the second level, he adapts the hyper parameters that control these parameters an in the third level he.",
                    "label": 0
                },
                {
                    "sent": "He proposes the evidence to compare different models.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the first, the first level of inference.",
                    "label": 1
                },
                {
                    "sent": "We will assume that the targets are generated for a function from a function.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Somebody different noise this function?",
                    "label": 0
                },
                {
                    "sent": "Why is assumed to come from a from a generalized linear model with where the fee is the sign matrix.",
                    "label": 0
                },
                {
                    "sent": "And then we assume that the.",
                    "label": 1
                },
                {
                    "sent": "The noise is 0 mean with variance Sigma squared.",
                    "label": 0
                },
                {
                    "sent": "Then the likelihood for the data.",
                    "label": 0
                },
                {
                    "sent": "Can be written as aghasyan.",
                    "label": 0
                },
                {
                    "sent": "And we want.",
                    "label": 0
                },
                {
                    "sent": "But this is the inverse variance.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Then minimizing maximizing too much of this probability, maximizing this likelihood for the parameters.",
                    "label": 0
                },
                {
                    "sent": "Is known to lead to overfitting becausw.",
                    "label": 0
                },
                {
                    "sent": "We are not not controlling the scale of these parameters and then they can grow.",
                    "label": 0
                },
                {
                    "sent": "And we can we can overfit the data.",
                    "label": 1
                },
                {
                    "sent": "Then one common approach is to place a.",
                    "label": 0
                },
                {
                    "sent": "A prior probability over the parameters.",
                    "label": 0
                },
                {
                    "sent": "One common approach is to consider assuming Gaussian prior.",
                    "label": 0
                },
                {
                    "sent": "Like this one.",
                    "label": 0
                },
                {
                    "sent": "Well, I've never said this, but I.",
                    "label": 0
                },
                {
                    "sent": "We are considering now that we know the.",
                    "label": 0
                },
                {
                    "sent": "The noise level, the noise for ions.",
                    "label": 0
                },
                {
                    "sent": "And we suppose that we we also know this Alpha.",
                    "label": 0
                },
                {
                    "sent": "This inverse variance then.",
                    "label": 0
                },
                {
                    "sent": "OK, as you may know.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is known we can use Bayes rule to compute the posterior over the parameters.",
                    "label": 1
                },
                {
                    "sent": "This is a product of two oceans.",
                    "label": 1
                },
                {
                    "sent": "Which is a version normalized by the.",
                    "label": 0
                },
                {
                    "sent": "Marginal likelihood below.",
                    "label": 0
                },
                {
                    "sent": "I mean this is this is a version.",
                    "label": 0
                },
                {
                    "sent": "With them in I mean.",
                    "label": 0
                },
                {
                    "sent": "Valuan and.",
                    "label": 0
                },
                {
                    "sent": "Overhead an.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is this mew mew move.",
                    "label": 0
                },
                {
                    "sent": "Is the mean for the parameters and then is the most probable value for the parameter, which we will.",
                    "label": 0
                },
                {
                    "sent": "Set the parameters to this value.",
                    "label": 0
                },
                {
                    "sent": "In practice, however, they know that the movie is dependent on beta.",
                    "label": 0
                },
                {
                    "sent": "And also depending on Alpha equals it depends on Sigma which depends on Alpha then OK, we are here.",
                    "label": 0
                },
                {
                    "sent": "Considering that we know better alphabet.",
                    "label": 0
                },
                {
                    "sent": "In practice, we do not.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the second level is inference.",
                    "label": 1
                },
                {
                    "sent": "The problem is to.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "To find the most probable values for Alpha and beta.",
                    "label": 1
                },
                {
                    "sent": "Anne, how do this we?",
                    "label": 0
                },
                {
                    "sent": "Consider the marginal likelihood, which is this integral here, which is computable because this is a product of two Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Which is about in and in Paradise Ocean.",
                    "label": 0
                },
                {
                    "sent": "And then in order to compute the most probable value, we should again use Bayes rule.",
                    "label": 1
                },
                {
                    "sent": "However, in this case we will assume that the probability for Alpha and beta is flat in original scale and then with the only thing we have to do is to maximize the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "Well, this is an aggressive browser.",
                    "label": 0
                },
                {
                    "sent": "Then he.",
                    "label": 0
                },
                {
                    "sent": "In order to do this, there is the.",
                    "label": 0
                },
                {
                    "sent": "The equation for marginal likelihood said the result to zero and found a couple of restaurant estimation formulas.",
                    "label": 0
                },
                {
                    "sent": "Where this W should be a move in the same mistake.",
                    "label": 0
                },
                {
                    "sent": "In the previous slide, then Alpha, Beta and are dependent on more and more is dependent on our fun beta, so we have to rest a mate both formulas until they converge.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, the third level of inference.",
                    "label": 1
                },
                {
                    "sent": "Is to have to compare different models?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The using Bayes rule again, the first the first term is.",
                    "label": 0
                },
                {
                    "sent": "In the in the right in the right hand side.",
                    "label": 1
                },
                {
                    "sent": "Is the evidence for the model.",
                    "label": 0
                },
                {
                    "sent": "The second term is the prior probability for the model, which we will assume to be the same for all the models.",
                    "label": 0
                },
                {
                    "sent": "However, we will see this assumption is not always correct.",
                    "label": 0
                },
                {
                    "sent": "They enter in other, compute the evidence we should integrate out Alpha and beta, but well, this integral is.",
                    "label": 1
                },
                {
                    "sent": "It's intractable, an approximate.",
                    "label": 1
                },
                {
                    "sent": "So with this with a separable Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Around the most probable values for Alpha and beta.",
                    "label": 0
                },
                {
                    "sent": "What is this formula here?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we see the about the searches.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bridges Ann search strategies are very commonly used in feature selection, but also in any subset selection method.",
                    "label": 1
                },
                {
                    "sent": "And some come on.",
                    "label": 0
                },
                {
                    "sent": "Some common strategies are.",
                    "label": 1
                },
                {
                    "sent": "Plus Ellen, take away our.",
                    "label": 0
                },
                {
                    "sent": "Which is a UR.",
                    "label": 0
                },
                {
                    "sent": "L basis function elements not only basis functions, you are elements and then they go away are consecutive.",
                    "label": 0
                },
                {
                    "sent": "Forward flexion is a special case which is PTA 10.",
                    "label": 1
                },
                {
                    "sent": "So sequential forward floating selection, which is probably the most complex search strategies and the most powerful.",
                    "label": 0
                },
                {
                    "sent": "An which also has the highest cost.",
                    "label": 0
                },
                {
                    "sent": "Which is I mean one element.",
                    "label": 0
                },
                {
                    "sent": "On removing elements while the best solution with that number of elements.",
                    "label": 1
                },
                {
                    "sent": "Until this moment is worse than the actual one.",
                    "label": 0
                },
                {
                    "sent": "And then is also slating 5 Biofinity operating C. Where you start with a fixed number of elements and then you start to oscillate around this number of elements.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "When the until you until you don't improve the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action.",
                    "label": 0
                },
                {
                    "sent": "And now we propose.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our method is the third strategy is guided by the evidence.",
                    "label": 1
                },
                {
                    "sent": "In order to do this, we need to implement the operations to the best basics basis functions from a set of candidates and to remove the worst basis function from the model.",
                    "label": 1
                },
                {
                    "sent": "Where the best and worst is with according to the evidence, the best is.",
                    "label": 0
                },
                {
                    "sent": "The one with which produces the highest evidence for the model.",
                    "label": 0
                },
                {
                    "sent": "And in order to do this is desirable that.",
                    "label": 0
                },
                {
                    "sent": "We can take advantage of the previous solution and to perform there incrementally, which is.",
                    "label": 1
                },
                {
                    "sent": "Which is implemented in the paper and I won't enter into into the tails here.",
                    "label": 0
                },
                {
                    "sent": "And then you you need to create a Dictionary of basis function.",
                    "label": 1
                },
                {
                    "sent": "A very common approach is to use RBF.",
                    "label": 0
                },
                {
                    "sent": "As many RBF basis functions as data points, each basis function centered at one inch input data.",
                    "label": 0
                },
                {
                    "sent": "This is very common.",
                    "label": 0
                },
                {
                    "sent": "For example in vector machine and or tonalist squares.",
                    "label": 0
                },
                {
                    "sent": "Or even support vector machines.",
                    "label": 1
                },
                {
                    "sent": "And finally we have to select the search strategy.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now it will show the experiment we have performed.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "We in the Y axis the vertical axis shows the log evidence for the model.",
                    "label": 0
                },
                {
                    "sent": "On the horizontal axis, shows a number of basis functions of the model.",
                    "label": 0
                },
                {
                    "sent": "We can see that float, sequential forward floating selection.",
                    "label": 0
                },
                {
                    "sent": "Achieves the highest evidence.",
                    "label": 0
                },
                {
                    "sent": "Which is also achieved with with the lowest number of basis functions I mean.",
                    "label": 1
                },
                {
                    "sent": "The model with the lowest basic function is found by.",
                    "label": 0
                },
                {
                    "sent": "By floating, we're going to see that forward selection is the worst.",
                    "label": 0
                },
                {
                    "sent": "The worst.",
                    "label": 0
                },
                {
                    "sent": "Strategy as expected, because it's also the simplest one.",
                    "label": 0
                },
                {
                    "sent": "Now this suggests also that if the number of basis functions is achieved with a low number of basis functions.",
                    "label": 1
                },
                {
                    "sent": "If the best model is achieved with a low number of basis functions.",
                    "label": 0
                },
                {
                    "sent": "Some stuff in criterion is.",
                    "label": 0
                },
                {
                    "sent": "Is advisable in order to?",
                    "label": 0
                },
                {
                    "sent": "Not to lose too much, too much time in computation.",
                    "label": 0
                },
                {
                    "sent": "We have used simple, very simple stuff in criterion.",
                    "label": 0
                },
                {
                    "sent": "When the number of basis functions.",
                    "label": 0
                },
                {
                    "sent": "Where the best model has been achieved with a number of basis functions.",
                    "label": 0
                },
                {
                    "sent": "Lower than 15 lower than the current model, we stop the process.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Now we both performing experiments on on some datasets.",
                    "label": 0
                },
                {
                    "sent": "Borrowed from the benefit there there were.",
                    "label": 0
                },
                {
                    "sent": "Environment.",
                    "label": 0
                },
                {
                    "sent": "And there are we have to put money in and clean.",
                    "label": 0
                },
                {
                    "sent": "Datasets and there are various different tasks for each model.",
                    "label": 1
                },
                {
                    "sent": "The fairly linear with high noise, fairly linear with moderate noise.",
                    "label": 0
                },
                {
                    "sent": "Nonlinear with high noise, nonlinear with moderate noise.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "We're going to see that, for example, the nonlinear ones are the ones that require the highest number of basis functions.",
                    "label": 1
                },
                {
                    "sent": "And when we perform with, we've used our 4th.",
                    "label": 0
                },
                {
                    "sent": "We've used for search strategies, guided by the evidence, and we have also compared these results with the relevance vector machine.",
                    "label": 0
                },
                {
                    "sent": "And the support vector machine, an orthogonal least squares.",
                    "label": 0
                },
                {
                    "sent": "We're going to see.",
                    "label": 0
                },
                {
                    "sent": "The search strategies guided by the evidence of very simple models.",
                    "label": 1
                },
                {
                    "sent": "As compared for example, to support vector machines that requires a very high number of support vectors.",
                    "label": 0
                },
                {
                    "sent": "Ann Floating, which is the model the strategy that found the highest evidence is has very similar sparsity to the relevance vector machine.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now here are the results of the previous one was about the number of basis functions.",
                    "label": 1
                },
                {
                    "sent": "This is about the.",
                    "label": 0
                },
                {
                    "sent": "The accuracy of the models.",
                    "label": 0
                },
                {
                    "sent": "We have included a new method with this all basis functions AVF.",
                    "label": 0
                },
                {
                    "sent": "And we use this.",
                    "label": 0
                },
                {
                    "sent": "This is a model with all the basis functions included in the model.",
                    "label": 0
                },
                {
                    "sent": "And then we simply compute the parameters as we have said in the first level of inference and compute the hyperparameter as we've said in the in the second level of inference.",
                    "label": 0
                },
                {
                    "sent": "Then this model has as many basis functions as data.",
                    "label": 0
                },
                {
                    "sent": "The data has a training set.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Now this the left to right order is the same as the top to bottom.",
                    "label": 1
                },
                {
                    "sent": "An Excel shows the number of tasks where the column method perform better.",
                    "label": 1
                },
                {
                    "sent": "And then the roll method where better women having a P value lower than 0.05.",
                    "label": 0
                },
                {
                    "sent": "And this P value was found in a T test.",
                    "label": 0
                },
                {
                    "sent": "That is performed by the Delva.",
                    "label": 0
                },
                {
                    "sent": "Environment.",
                    "label": 0
                },
                {
                    "sent": "Now there were 40 tasks, 40 tasks.",
                    "label": 0
                }
            ]
        }
    }
}