{
    "id": "otijg63tw2exhey25v7fhetoddad7sr7",
    "title": "Toward joint segmentation and classification of dialog acts in multiparty meetings",
    "info": {
        "author": [
            "Matthias Zimmermann, International Computer Science Institute, UC Berkeley"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2005",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlmi04uk_zimmermann_tjscd/",
    "segmentation": [
        [
            "Introduce them from XY and this is our first work for joint segmentation and classification of dialogue acts on multi party meetings.",
            "This is the organization.",
            "First give a brief problem statement.",
            "Then I'll briefly touch in event language model and."
        ],
        [
            "Packer approach I will talk about performance metrics.",
            "There will be some experiments and results.",
            "Finally conclusions and outlook.",
            "We start with."
        ],
        [
            "Input, which is basically just the sequence of words as indicated here and the idea is to find the dialogue, acts.",
            "The dialogue acts are brackets or segmentations inside of the stream of words tacked with dialogue act labels.",
            "So for this sequence of words we would have first single Word Dialogue act as disruptions just well then the statement.",
            "That's pretty good I think, followed by two more statements.",
            "Again, single word statements this year here and the thanks.",
            "At that point, when we do that automatically, then typically we get something."
        ],
        [
            "Like that which is not really nice, but currently we're not doing much better than that.",
            "We get a segmentation which is in certain parts completely different and the labels are different than in other parts.",
            "There is actually some coincidence between the system output and the output we got from the transcript or from the ground truth."
        ],
        [
            "Previous work in dialogue acts typically focused either on segmentation order, classification of dialogue acts, and not on both, but fully automatic systems of course require solutions to both of these problems."
        ],
        [
            "In quite a number of years ago, 97 one canal did in the verbmobil context that integrate segmentation and classification of dialogue acts, while more recently also."
        ],
        [
            "Hi Dixie, Young Adult published this approach on the exit meeting corpus this year.",
            "They were using a sequential approach for the segmentation into the dialogue acts that were using hidden event language models and decision trees.",
            "The decision trees were used for pause feature.",
            "Then in the classification stage.",
            "After the segmentation they were using a maximum entropy approach for word features and again decision trees for processing information."
        ],
        [
            "Motivation for this work is basically to remove the limitations of the sequential approach by trying not to do blind segmentation, and then probably have things which we cannot recover from in the classification, but moving to towards an integrated approach of one key.",
            "This work mainly concentrates on the hidden event language model based segmentation of this ask."
        ],
        [
            "Because publication we use.",
            "The Hidden Events language model not only to to select boundaries, but also to classify at the same time you'll see that in a moment.",
            "Then there's a second technique based on attacker approach as well.",
            "We propose new dialogue act based error metrics and we compare the results with the previous."
        ],
        [
            "Works.",
            "For the invent language model is most cases used to segments data and we assumed to have some stream of words and inside of that stream there are hidden events.",
            "In that case most uses it.",
            "For example, the sentence boundaries.",
            "In our case there are attacked dialogue act boundaries which act as segment's events.",
            "So."
        ],
        [
            "In training we have this stream of words and."
        ],
        [
            "This fact, segmentation boundaries, for example, here we have inserted the end of the of the disruption to end of the statement, and so on.",
            "In the testing week."
        ],
        [
            "Again, this stream of input words and then we are at this point.",
            "Here we calculate the posterior probabilities for all possible hidden events, including the empty events here."
        ],
        [
            "Which actually means that there is no boundary between two dialogue acts and after each word in the input stream we insert the event with the highest posterior.",
            "This is."
        ],
        [
            "Leads to this sort of results were after most works.",
            "We have no boundary.",
            "An for example here to pretty were looking at before.",
            "Again, here is no boundary, but after the quote there is the end of statement boundary.",
            "This makes that at the end.",
            "Here of this algorithm we take the whole instance here as our first statement.",
            "That's how we go from this classification.",
            "Of hidden events to actually segmenting and packing dialogue acts.",
            "In the attacker based approach, the second scheme in case it in this task.",
            "First, what does it take?"
        ],
        [
            "I can do in that case.",
            "Typically it's translating a stream of words from the vocabulary T into words from attack vocabulary Vt, and the system tries to find the VTEC sequence with the highest posterior given a number of things first.",
            "Of course the sequence."
        ],
        [
            "Of normal works, then a map."
        ],
        [
            "The probabilities from words in V to the words in the text vocabulary."
        ],
        [
            "And the Ningrum language model for sequence of words in the tank vocabulary."
        ],
        [
            "The input into that algorithm is against just the sequence of verse without anything.",
            "Then we have this mapping probability.",
            "For example, for this word year we have a set of probabilities that this year has been generated by a year, which actually marks the beginning of a back channel or a year which marks is avert inside of sort of back channel or the unit could also be the first word of disruption, and so on.",
            "Basically we have mapping probability for each of the dialogue acts, then the language model in the Vt says for example.",
            "The probability that we have this year is the beginning of a statement.",
            "And we conditioned that on that the last two words were, I think, and that would have been a disruption."
        ],
        [
            "For the result we get a sequence of packed words and again from this tax we can then.",
            "Assume or extract the sequence of dialogue acts with the segmentation boundaries.",
            "For example, in that case, this means that the well is the first word of us of a statement.",
            "Then all these assets means it's just a word inside of statement.",
            "This would mean that we put all those things together to form or first dialogue active statement in that case."
        ],
        [
            "Now come to the metrics discussion.",
            "Previous metrics were different endeavour boundary base.",
            "For example in this to Sue metrics or eververse based in the especially in this icast paper from from this year.",
            "And the proposed."
        ],
        [
            "Metrix their dialogue act based.",
            "The idea is to have a metric which is simple to interpret and directly related to dialogue acts and not two boundaries or Virgin something else.",
            "So."
        ],
        [
            "So in that case the counting units are the dialogue acts as we found them in the transcripts and one of the metric is the present."
        ],
        [
            "Wrongly segmented dialogue acts.",
            "We call it dialogue act segmentation error."
        ],
        [
            "And the derived metric.",
            "That's what we're actually more interested in, is the percentage of wrongly segmented or classifieds.",
            "Dialogue acts.",
            "The dialogue error rate."
        ],
        [
            "We come here to a sequence of lots of aromatics.",
            "I skip some of them because they're not really interested and they will be covered in the proceedings in order to concentrate more on the metrics we're actually interested in.",
            "That would be the nice assume metrics, which is boundary based, so it's just measuring segmentation that is the."
        ],
        [
            "New measure which measures the number of Mystic mental dialogue acts and divides by the available number of dialogue acts.",
            "We have"
        ],
        [
            "Some small examples here.",
            "First we have the reference line where we have the output which we got from the labellers.",
            "Each letter here means that work out of the stream and the letter itself characterizes the Dialogue Act.",
            "So this means that we have a single Word dialogue act here.",
            "Then we have a question.",
            "This forwards the statement is 3 words, single word, back channel and the statement at the end is 2 words.",
            "The system produces this sort of output and then we have our.",
            "Error metrics."
        ],
        [
            "Do as I said, is just checking the boundaries or knew metric here is looking at whole dialogue acts, so in that case we have acquaintance in this case where is 1 word dialogue.",
            "Act at the beginning was properly segmented so we have a correct case here.",
            "Then this question here was not properly recognized.",
            "We had some problems here.",
            "This statement was OK since we have both sides to proper boundaries so we can have a correct case here.",
            "Then finally this back channel and this statement here they were not correctly recognized.",
            "So that makes 2 errors.",
            "At the end."
        ],
        [
            "If we summarize that we get this kind of error rates in the first case Miss SQL, we have 60% and again 60% in that case.",
            "May"
        ],
        [
            "We move to the segmentation and classification errors that basically the idea is not only to consider segmentation, but classification as well.",
            "Then it's a modified list as you measure, which I don't really want to mention here."
        ],
        [
            "Is the linear work based metrics from the access paper of this year?",
            "Also here I would not like to say too many things because this one does not take segmentation into account, just the classification.",
            "This one district."
        ],
        [
            "Based measure is the one measure which was used in this year.",
            "Add custom paper that actually takes into account both segmentation and classification.",
            "So we count the Mist Act or Mystic Mantid words, and we divide by the number of words than you."
        ],
        [
            "Proposed metric here's the Dialogue Act error rate.",
            "So instead of counting words, is that we are counting whole dialogue acts.",
            "If he again."
        ],
        [
            "Or example from before.",
            "You have here the different error metrics.",
            "I want to concentrate on those two in the strict error metric we have said that we count the birds, which are correct both for correct dialogue acts as well as correct labels."
        ],
        [
            "This means this first dialogue Act here is properly segmented and properly labeled, so we get here correct one.",
            "We have here in this region also something which is properly segmented here and here, but unfortunately this is a different label between the system output and the reference.",
            "So we get those three words wrong and all the others are wrong.",
            "Anyways, instance segmentation boundaries of the dialogues are bad in the Dialogue Act error rate we have the same thing as before for the segmentation error rate.",
            "Also like in the case of district metric we get here an error at that place."
        ],
        [
            "If we give the resulting error rates for this example we have here a 91% error rate for the strict metric.",
            "Basically we have 10 match errors out of 11 works in the dialogue tag error rates.",
            "We have these four match errors out of the five dialogue acts here.",
            "So basically what we can conclude from that is that dialogue act error rate is just a length normalized version of the strict metric."
        ],
        [
            "Come to that experimental setup.",
            "For this.",
            "We were basically using the same setup as in the previous publication.",
            "This means we had 51 meetings for training, 11 meetings for validation in the 11 meetings for testing we had two conditions, the reference conditions and the speech to text condition in their reference condition.",
            "We assume that we have access to the true sequence of words while in the speech text comes condition we use the words from the transcript from the speech to text engine.",
            "This output here you have A at that place we had 40% word error rate or 32% word error rate for native speaker which is quite a lot.",
            "And for our dialogue act types you were using five very simple things to backchannel disruption.",
            "The floor grabbers questions and the statements."
        ],
        [
            "Maybe just look at the segmentation we have the previous system at that place.",
            "In 2 flavors, the one is the full system, including the property information and the other system is a reduced version, not including the property information.",
            "This one is just work based.",
            "This we did since our approaches here are worse.",
            "Base word based also.",
            "So for this we have actually a baseline to measure against.",
            "We can see that in those cases we lose roughly 10 points when we go from the original version to the version which does not include prosody."
        ],
        [
            "When we look at the performance of the Hidden event language model, we get organista symmetric, something which is closed, but the dialogue act segmentation error rate is not so nice."
        ],
        [
            "Result for attackers are much worse.",
            "So basically this means that.",
            "The package seems not really to find good segmentation boundaries compared to the hidden event language model.",
            "The difference here is not really a big surprise since also in this approach invent language model was used for segmentation.",
            "So the difference between this hidden meant language model here and this one here is that at this place the hidden meant language model was using something like a two way classification task.",
            "So of after each word it was decided that these are segmentation boundary or not.",
            "Well in this case it's a six way classification.",
            "Ask after each word we have to define.",
            "Do we have boundary of type statement or question and so on.",
            "While there could also be a non boundary if we move to."
        ],
        [
            "Speech with text conditions results look similar.",
            "We get a little bit closer with the invent language model through this approach here and that."
        ],
        [
            "Back again performs not very nicely."
        ],
        [
            "Then we go to the training classes."
        ],
        [
            "Location and segmentation think first, we have again the two lines for the eye test system.",
            "The second line here means that this is the system is out the property again.",
            "We lose roughly 10 points.",
            "For recognition here.",
            "Anne."
        ],
        [
            "The performance of the Hidden Event language model at that point.",
            "Is a little bit worse here than the icast.",
            "And."
        ],
        [
            "As one could assume, that pattern also is not really good in this place.",
            "Then we moved to the speech to text condition."
        ],
        [
            "But we can see again speech with text increases the error rate by roughly 1010% point, even though the.",
            "Actual error rates of word.",
            "It was in the regional 40%.",
            "The results for the hidden meant land."
        ],
        [
            "This model.",
            "In that area was.",
            "Actually, a little bit nicer than before, so we're actually closing in on the icons version.",
            "Which does not use prosody for attacker."
        ],
        [
            "The results are pretty bad.",
            "There is 1 interesting thing.",
            "So for the linear metric, which I didn't really mention.",
            "So the idea is that also the attackers performs really bad on all the metrics it is performing surprisingly well on the lenient metrics.",
            "But since the linear metric does not include the segmentation, it is somewhat questionable how that what that actually means.",
            "It also adds some points for the discussion about to use which metrics, so it really matters which metrics we use to assess the performance.",
            "Of the system may conclude."
        ],
        [
            "Is that being passive investing?"
        ],
        [
            "Created an extent hidden event language model and attacker based approach to do joint segmentation and classification of dialogue acts."
        ],
        [
            "Established baseline for trying segmentation and classification on the EXE meeting corpus and."
        ],
        [
            "Promising 1st results.",
            "Given the simplicity of the approach."
        ],
        [
            "We Furthermore proposed and motivated dialogue act based error metrics.",
            "And a few."
        ],
        [
            "Your directions are."
        ],
        [
            "We would like to use the A star algorithm to take into account complete dialogue hypothesis.",
            "So how is that different from what we have done?",
            "But we have done so far is the hidden event language model and attacker.",
            "They're basically looking at local evidence, so whatever falls out of the engram window which we currently consider does not contribute anymore really to the decision, whereas in this a store graph search algorithm we would take into account the Complete Dialogue Act hypothesis."
        ],
        [
            "Using this we would also like to integrate both Word Basin prosody based information.",
            "So far we have only used word based information in this work and Furthermore would like to also use word like."
        ],
        [
            "This is to actually find the segmentation boundaries and to do the classification instead of just looking at the one best output of the ASR or the speech text system."
        ],
        [
            "Thank you very much.",
            "Thank you.",
            "I've heard.",
            "So I think we have to thank all."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Introduce them from XY and this is our first work for joint segmentation and classification of dialogue acts on multi party meetings.",
                    "label": 1
                },
                {
                    "sent": "This is the organization.",
                    "label": 0
                },
                {
                    "sent": "First give a brief problem statement.",
                    "label": 0
                },
                {
                    "sent": "Then I'll briefly touch in event language model and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Packer approach I will talk about performance metrics.",
                    "label": 1
                },
                {
                    "sent": "There will be some experiments and results.",
                    "label": 1
                },
                {
                    "sent": "Finally conclusions and outlook.",
                    "label": 0
                },
                {
                    "sent": "We start with.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Input, which is basically just the sequence of words as indicated here and the idea is to find the dialogue, acts.",
                    "label": 0
                },
                {
                    "sent": "The dialogue acts are brackets or segmentations inside of the stream of words tacked with dialogue act labels.",
                    "label": 0
                },
                {
                    "sent": "So for this sequence of words we would have first single Word Dialogue act as disruptions just well then the statement.",
                    "label": 0
                },
                {
                    "sent": "That's pretty good I think, followed by two more statements.",
                    "label": 0
                },
                {
                    "sent": "Again, single word statements this year here and the thanks.",
                    "label": 0
                },
                {
                    "sent": "At that point, when we do that automatically, then typically we get something.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like that which is not really nice, but currently we're not doing much better than that.",
                    "label": 0
                },
                {
                    "sent": "We get a segmentation which is in certain parts completely different and the labels are different than in other parts.",
                    "label": 0
                },
                {
                    "sent": "There is actually some coincidence between the system output and the output we got from the transcript or from the ground truth.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Previous work in dialogue acts typically focused either on segmentation order, classification of dialogue acts, and not on both, but fully automatic systems of course require solutions to both of these problems.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In quite a number of years ago, 97 one canal did in the verbmobil context that integrate segmentation and classification of dialogue acts, while more recently also.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi Dixie, Young Adult published this approach on the exit meeting corpus this year.",
                    "label": 0
                },
                {
                    "sent": "They were using a sequential approach for the segmentation into the dialogue acts that were using hidden event language models and decision trees.",
                    "label": 0
                },
                {
                    "sent": "The decision trees were used for pause feature.",
                    "label": 0
                },
                {
                    "sent": "Then in the classification stage.",
                    "label": 0
                },
                {
                    "sent": "After the segmentation they were using a maximum entropy approach for word features and again decision trees for processing information.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Motivation for this work is basically to remove the limitations of the sequential approach by trying not to do blind segmentation, and then probably have things which we cannot recover from in the classification, but moving to towards an integrated approach of one key.",
                    "label": 0
                },
                {
                    "sent": "This work mainly concentrates on the hidden event language model based segmentation of this ask.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because publication we use.",
                    "label": 0
                },
                {
                    "sent": "The Hidden Events language model not only to to select boundaries, but also to classify at the same time you'll see that in a moment.",
                    "label": 0
                },
                {
                    "sent": "Then there's a second technique based on attacker approach as well.",
                    "label": 1
                },
                {
                    "sent": "We propose new dialogue act based error metrics and we compare the results with the previous.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Works.",
                    "label": 0
                },
                {
                    "sent": "For the invent language model is most cases used to segments data and we assumed to have some stream of words and inside of that stream there are hidden events.",
                    "label": 1
                },
                {
                    "sent": "In that case most uses it.",
                    "label": 0
                },
                {
                    "sent": "For example, the sentence boundaries.",
                    "label": 1
                },
                {
                    "sent": "In our case there are attacked dialogue act boundaries which act as segment's events.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In training we have this stream of words and.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This fact, segmentation boundaries, for example, here we have inserted the end of the of the disruption to end of the statement, and so on.",
                    "label": 0
                },
                {
                    "sent": "In the testing week.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, this stream of input words and then we are at this point.",
                    "label": 0
                },
                {
                    "sent": "Here we calculate the posterior probabilities for all possible hidden events, including the empty events here.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which actually means that there is no boundary between two dialogue acts and after each word in the input stream we insert the event with the highest posterior.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Leads to this sort of results were after most works.",
                    "label": 0
                },
                {
                    "sent": "We have no boundary.",
                    "label": 0
                },
                {
                    "sent": "An for example here to pretty were looking at before.",
                    "label": 0
                },
                {
                    "sent": "Again, here is no boundary, but after the quote there is the end of statement boundary.",
                    "label": 0
                },
                {
                    "sent": "This makes that at the end.",
                    "label": 0
                },
                {
                    "sent": "Here of this algorithm we take the whole instance here as our first statement.",
                    "label": 0
                },
                {
                    "sent": "That's how we go from this classification.",
                    "label": 0
                },
                {
                    "sent": "Of hidden events to actually segmenting and packing dialogue acts.",
                    "label": 0
                },
                {
                    "sent": "In the attacker based approach, the second scheme in case it in this task.",
                    "label": 0
                },
                {
                    "sent": "First, what does it take?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I can do in that case.",
                    "label": 0
                },
                {
                    "sent": "Typically it's translating a stream of words from the vocabulary T into words from attack vocabulary Vt, and the system tries to find the VTEC sequence with the highest posterior given a number of things first.",
                    "label": 1
                },
                {
                    "sent": "Of course the sequence.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of normal works, then a map.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The probabilities from words in V to the words in the text vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the Ningrum language model for sequence of words in the tank vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The input into that algorithm is against just the sequence of verse without anything.",
                    "label": 0
                },
                {
                    "sent": "Then we have this mapping probability.",
                    "label": 0
                },
                {
                    "sent": "For example, for this word year we have a set of probabilities that this year has been generated by a year, which actually marks the beginning of a back channel or a year which marks is avert inside of sort of back channel or the unit could also be the first word of disruption, and so on.",
                    "label": 0
                },
                {
                    "sent": "Basically we have mapping probability for each of the dialogue acts, then the language model in the Vt says for example.",
                    "label": 0
                },
                {
                    "sent": "The probability that we have this year is the beginning of a statement.",
                    "label": 0
                },
                {
                    "sent": "And we conditioned that on that the last two words were, I think, and that would have been a disruption.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the result we get a sequence of packed words and again from this tax we can then.",
                    "label": 1
                },
                {
                    "sent": "Assume or extract the sequence of dialogue acts with the segmentation boundaries.",
                    "label": 1
                },
                {
                    "sent": "For example, in that case, this means that the well is the first word of us of a statement.",
                    "label": 0
                },
                {
                    "sent": "Then all these assets means it's just a word inside of statement.",
                    "label": 0
                },
                {
                    "sent": "This would mean that we put all those things together to form or first dialogue active statement in that case.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now come to the metrics discussion.",
                    "label": 0
                },
                {
                    "sent": "Previous metrics were different endeavour boundary base.",
                    "label": 0
                },
                {
                    "sent": "For example in this to Sue metrics or eververse based in the especially in this icast paper from from this year.",
                    "label": 0
                },
                {
                    "sent": "And the proposed.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Metrix their dialogue act based.",
                    "label": 0
                },
                {
                    "sent": "The idea is to have a metric which is simple to interpret and directly related to dialogue acts and not two boundaries or Virgin something else.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in that case the counting units are the dialogue acts as we found them in the transcripts and one of the metric is the present.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wrongly segmented dialogue acts.",
                    "label": 0
                },
                {
                    "sent": "We call it dialogue act segmentation error.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the derived metric.",
                    "label": 0
                },
                {
                    "sent": "That's what we're actually more interested in, is the percentage of wrongly segmented or classifieds.",
                    "label": 1
                },
                {
                    "sent": "Dialogue acts.",
                    "label": 0
                },
                {
                    "sent": "The dialogue error rate.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We come here to a sequence of lots of aromatics.",
                    "label": 0
                },
                {
                    "sent": "I skip some of them because they're not really interested and they will be covered in the proceedings in order to concentrate more on the metrics we're actually interested in.",
                    "label": 0
                },
                {
                    "sent": "That would be the nice assume metrics, which is boundary based, so it's just measuring segmentation that is the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New measure which measures the number of Mystic mental dialogue acts and divides by the available number of dialogue acts.",
                    "label": 0
                },
                {
                    "sent": "We have",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some small examples here.",
                    "label": 0
                },
                {
                    "sent": "First we have the reference line where we have the output which we got from the labellers.",
                    "label": 0
                },
                {
                    "sent": "Each letter here means that work out of the stream and the letter itself characterizes the Dialogue Act.",
                    "label": 0
                },
                {
                    "sent": "So this means that we have a single Word dialogue act here.",
                    "label": 0
                },
                {
                    "sent": "Then we have a question.",
                    "label": 0
                },
                {
                    "sent": "This forwards the statement is 3 words, single word, back channel and the statement at the end is 2 words.",
                    "label": 0
                },
                {
                    "sent": "The system produces this sort of output and then we have our.",
                    "label": 0
                },
                {
                    "sent": "Error metrics.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do as I said, is just checking the boundaries or knew metric here is looking at whole dialogue acts, so in that case we have acquaintance in this case where is 1 word dialogue.",
                    "label": 0
                },
                {
                    "sent": "Act at the beginning was properly segmented so we have a correct case here.",
                    "label": 0
                },
                {
                    "sent": "Then this question here was not properly recognized.",
                    "label": 0
                },
                {
                    "sent": "We had some problems here.",
                    "label": 0
                },
                {
                    "sent": "This statement was OK since we have both sides to proper boundaries so we can have a correct case here.",
                    "label": 0
                },
                {
                    "sent": "Then finally this back channel and this statement here they were not correctly recognized.",
                    "label": 0
                },
                {
                    "sent": "So that makes 2 errors.",
                    "label": 0
                },
                {
                    "sent": "At the end.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we summarize that we get this kind of error rates in the first case Miss SQL, we have 60% and again 60% in that case.",
                    "label": 0
                },
                {
                    "sent": "May",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We move to the segmentation and classification errors that basically the idea is not only to consider segmentation, but classification as well.",
                    "label": 0
                },
                {
                    "sent": "Then it's a modified list as you measure, which I don't really want to mention here.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the linear work based metrics from the access paper of this year?",
                    "label": 0
                },
                {
                    "sent": "Also here I would not like to say too many things because this one does not take segmentation into account, just the classification.",
                    "label": 0
                },
                {
                    "sent": "This one district.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Based measure is the one measure which was used in this year.",
                    "label": 0
                },
                {
                    "sent": "Add custom paper that actually takes into account both segmentation and classification.",
                    "label": 0
                },
                {
                    "sent": "So we count the Mist Act or Mystic Mantid words, and we divide by the number of words than you.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proposed metric here's the Dialogue Act error rate.",
                    "label": 0
                },
                {
                    "sent": "So instead of counting words, is that we are counting whole dialogue acts.",
                    "label": 0
                },
                {
                    "sent": "If he again.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or example from before.",
                    "label": 0
                },
                {
                    "sent": "You have here the different error metrics.",
                    "label": 0
                },
                {
                    "sent": "I want to concentrate on those two in the strict error metric we have said that we count the birds, which are correct both for correct dialogue acts as well as correct labels.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This means this first dialogue Act here is properly segmented and properly labeled, so we get here correct one.",
                    "label": 0
                },
                {
                    "sent": "We have here in this region also something which is properly segmented here and here, but unfortunately this is a different label between the system output and the reference.",
                    "label": 0
                },
                {
                    "sent": "So we get those three words wrong and all the others are wrong.",
                    "label": 0
                },
                {
                    "sent": "Anyways, instance segmentation boundaries of the dialogues are bad in the Dialogue Act error rate we have the same thing as before for the segmentation error rate.",
                    "label": 0
                },
                {
                    "sent": "Also like in the case of district metric we get here an error at that place.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we give the resulting error rates for this example we have here a 91% error rate for the strict metric.",
                    "label": 1
                },
                {
                    "sent": "Basically we have 10 match errors out of 11 works in the dialogue tag error rates.",
                    "label": 1
                },
                {
                    "sent": "We have these four match errors out of the five dialogue acts here.",
                    "label": 0
                },
                {
                    "sent": "So basically what we can conclude from that is that dialogue act error rate is just a length normalized version of the strict metric.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come to that experimental setup.",
                    "label": 1
                },
                {
                    "sent": "For this.",
                    "label": 1
                },
                {
                    "sent": "We were basically using the same setup as in the previous publication.",
                    "label": 0
                },
                {
                    "sent": "This means we had 51 meetings for training, 11 meetings for validation in the 11 meetings for testing we had two conditions, the reference conditions and the speech to text condition in their reference condition.",
                    "label": 1
                },
                {
                    "sent": "We assume that we have access to the true sequence of words while in the speech text comes condition we use the words from the transcript from the speech to text engine.",
                    "label": 0
                },
                {
                    "sent": "This output here you have A at that place we had 40% word error rate or 32% word error rate for native speaker which is quite a lot.",
                    "label": 0
                },
                {
                    "sent": "And for our dialogue act types you were using five very simple things to backchannel disruption.",
                    "label": 0
                },
                {
                    "sent": "The floor grabbers questions and the statements.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe just look at the segmentation we have the previous system at that place.",
                    "label": 0
                },
                {
                    "sent": "In 2 flavors, the one is the full system, including the property information and the other system is a reduced version, not including the property information.",
                    "label": 0
                },
                {
                    "sent": "This one is just work based.",
                    "label": 0
                },
                {
                    "sent": "This we did since our approaches here are worse.",
                    "label": 0
                },
                {
                    "sent": "Base word based also.",
                    "label": 0
                },
                {
                    "sent": "So for this we have actually a baseline to measure against.",
                    "label": 0
                },
                {
                    "sent": "We can see that in those cases we lose roughly 10 points when we go from the original version to the version which does not include prosody.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we look at the performance of the Hidden event language model, we get organista symmetric, something which is closed, but the dialogue act segmentation error rate is not so nice.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result for attackers are much worse.",
                    "label": 0
                },
                {
                    "sent": "So basically this means that.",
                    "label": 0
                },
                {
                    "sent": "The package seems not really to find good segmentation boundaries compared to the hidden event language model.",
                    "label": 0
                },
                {
                    "sent": "The difference here is not really a big surprise since also in this approach invent language model was used for segmentation.",
                    "label": 0
                },
                {
                    "sent": "So the difference between this hidden meant language model here and this one here is that at this place the hidden meant language model was using something like a two way classification task.",
                    "label": 0
                },
                {
                    "sent": "So of after each word it was decided that these are segmentation boundary or not.",
                    "label": 0
                },
                {
                    "sent": "Well in this case it's a six way classification.",
                    "label": 0
                },
                {
                    "sent": "Ask after each word we have to define.",
                    "label": 0
                },
                {
                    "sent": "Do we have boundary of type statement or question and so on.",
                    "label": 0
                },
                {
                    "sent": "While there could also be a non boundary if we move to.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speech with text conditions results look similar.",
                    "label": 0
                },
                {
                    "sent": "We get a little bit closer with the invent language model through this approach here and that.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back again performs not very nicely.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we go to the training classes.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location and segmentation think first, we have again the two lines for the eye test system.",
                    "label": 0
                },
                {
                    "sent": "The second line here means that this is the system is out the property again.",
                    "label": 0
                },
                {
                    "sent": "We lose roughly 10 points.",
                    "label": 0
                },
                {
                    "sent": "For recognition here.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The performance of the Hidden Event language model at that point.",
                    "label": 0
                },
                {
                    "sent": "Is a little bit worse here than the icast.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As one could assume, that pattern also is not really good in this place.",
                    "label": 0
                },
                {
                    "sent": "Then we moved to the speech to text condition.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we can see again speech with text increases the error rate by roughly 1010% point, even though the.",
                    "label": 0
                },
                {
                    "sent": "Actual error rates of word.",
                    "label": 0
                },
                {
                    "sent": "It was in the regional 40%.",
                    "label": 0
                },
                {
                    "sent": "The results for the hidden meant land.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This model.",
                    "label": 0
                },
                {
                    "sent": "In that area was.",
                    "label": 0
                },
                {
                    "sent": "Actually, a little bit nicer than before, so we're actually closing in on the icons version.",
                    "label": 0
                },
                {
                    "sent": "Which does not use prosody for attacker.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The results are pretty bad.",
                    "label": 0
                },
                {
                    "sent": "There is 1 interesting thing.",
                    "label": 0
                },
                {
                    "sent": "So for the linear metric, which I didn't really mention.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that also the attackers performs really bad on all the metrics it is performing surprisingly well on the lenient metrics.",
                    "label": 0
                },
                {
                    "sent": "But since the linear metric does not include the segmentation, it is somewhat questionable how that what that actually means.",
                    "label": 0
                },
                {
                    "sent": "It also adds some points for the discussion about to use which metrics, so it really matters which metrics we use to assess the performance.",
                    "label": 0
                },
                {
                    "sent": "Of the system may conclude.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that being passive investing?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Created an extent hidden event language model and attacker based approach to do joint segmentation and classification of dialogue acts.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Established baseline for trying segmentation and classification on the EXE meeting corpus and.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Promising 1st results.",
                    "label": 0
                },
                {
                    "sent": "Given the simplicity of the approach.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We Furthermore proposed and motivated dialogue act based error metrics.",
                    "label": 0
                },
                {
                    "sent": "And a few.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your directions are.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We would like to use the A star algorithm to take into account complete dialogue hypothesis.",
                    "label": 1
                },
                {
                    "sent": "So how is that different from what we have done?",
                    "label": 0
                },
                {
                    "sent": "But we have done so far is the hidden event language model and attacker.",
                    "label": 0
                },
                {
                    "sent": "They're basically looking at local evidence, so whatever falls out of the engram window which we currently consider does not contribute anymore really to the decision, whereas in this a store graph search algorithm we would take into account the Complete Dialogue Act hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using this we would also like to integrate both Word Basin prosody based information.",
                    "label": 0
                },
                {
                    "sent": "So far we have only used word based information in this work and Furthermore would like to also use word like.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is to actually find the segmentation boundaries and to do the classification instead of just looking at the one best output of the ASR or the speech text system.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I've heard.",
                    "label": 0
                },
                {
                    "sent": "So I think we have to thank all.",
                    "label": 0
                }
            ]
        }
    }
}