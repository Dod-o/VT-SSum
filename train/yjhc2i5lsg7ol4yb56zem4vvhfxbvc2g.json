{
    "id": "yjhc2i5lsg7ol4yb56zem4vvhfxbvc2g",
    "title": "Probabilistic multi-class multi-kernel learning: On protein fold recognition and remote homology detection",
    "info": {
        "author": [
            "Theodoros Damoulas, University of Glasgow"
        ],
        "published": "April 17, 2008",
        "recorded": "March 2008",
        "category": [
            "Top->Computer Science->Bioinformatics",
            "Top->Computer Science->Bioinformatics->Computational Systems Biology",
            "Top->Computer Science->Machine Learning->Kernel Methods->Multiple Kernel Learning"
        ]
    },
    "url": "http://videolectures.net/licsb08_damoulas_pmm/",
    "segmentation": [
        [
            "I am so in this work I will learn describer class and new classification method.",
            "And.",
            "The main keywords is a probabilistic method, so we've got probabilities for class #4.",
            "For the class of an object for class membership, it's a multi class method, so it's an explicit multi class method and we don't need.",
            "To rely on network combinations.",
            "And it's a multi kernel method in the sense that we have multiple kernels that we can combine and it's kind of can describe a feature space.",
            "So I will describe two applications of that method and try to convince you that it's a very good method producing state of the art results on protein fold recognition and remote homeowners detection."
        ],
        [
            "So I will start first by describing the problem of protein folding, so it gives you an inside Huawei eternal combination approach that might be useful.",
            "And some over the past methods that I will be comparing against and finally the results.",
            "And if I have time I will also talk about remote homology problem.",
            "And how we can also?"
        ],
        [
            "Attack that problem, so protein folding.",
            "What would actually predicting is predicting the structural fold of protein.",
            "So you have got to very nice pictures here.",
            "We got a team battle and bitter propeller.",
            "So these are two classical folds of proteins.",
            "And the whole problem area is in what so called the Twilight zone where you've got you want to put to know that to learn the function of a protein.",
            "But it's a low sequence so might be in the low sequence similarity zone.",
            "That's the Twilight zone.",
            "So you can learn the function by.",
            "In the classical way, by doing something like C blast or blast and compare the sequence of the proteins and assume that they serve the same function.",
            "But there is a problem where they can share the same function but don't have.",
            "Sequence similarity so this is a very multiclass problem there.",
            "In total, in the scope that around.",
            "5000 identified faults until now.",
            "And it's a multi feature problem in the sense that there are a lot of object descriptors available for that task, so you've got amino acid composition, for example, global characteristics and local characteristics."
        ],
        [
            "But you can combine.",
            "And so the the Golden start and there's none of benchmark data set for that problem is was described first by doing and do swag and everybody who's doing work on that problem is following that data set.",
            "And it's based on SCOPE 2001 on PDP40D data set where.",
            "If we got the 27 most populated falls and we use only those and there is less than 35 sequence similarity in the proteins and less than 25% sequence similarity between training set and test set and there is a standard split on the set so the work by doing and boots back, So what they've done and they've used 6 feature sets, each of one is around 20 dimension and the views global characteristics.",
            "Such as only know acid, then secondary structure as well.",
            "And if you sufficiently network support vector machines and becausw its multi class and multi feature.",
            "You end up in an old versus old approach.",
            "You end up employing around 2000 classifiers so that problem.",
            "So they've done a very extensive work and try to identify which feature spaces is more significant and the best performance is around 56%.",
            "So another important work by sending two in 2006 so they've replaced one of them 6 feature sets with an extra 4 ones that I will briefly talk about later on and.",
            "What they've done is they've employed multiclass classifiers on its feature set and then combine those so they end up having nine Kanan classifiers and the reported in best performance of 62%."
        ],
        [
            "So that's the my.",
            "My benchmark so this work is has been accepted by Infomatics.",
            "In may.",
            "It's a composite kernel.",
            "Regression was a composite kernel as we're combining kernels.",
            "I will explain further on better below.",
            "And we're playing them with normal probability likelihood, and it's based on work by Solomon Rogers in Acnl where they've employed the softmax logistic likelihood.",
            "And in this paper we've got that GP with normal probability version.",
            "So.",
            "The best performers were going to get 70%, so it's a very significant improvement for 27 classes around an 8% movement, and we're combining information for both global characteristics.",
            "We talk about these things that don't depend directly on the sequence on the sequence similarity between proteins.",
            "And local characteristics which are.",
            "So basically we're going to use some string kernels to do to see if we can get an improvement.",
            "Anne.",
            "The solution is a full is a Markov chain Monte Carlo Metropolis Hastings within Gibbs, so it's a Gibbs sampler that incorporates Metropolis Hastings sub samplers to sample.",
            "For example, the kernel parameters and combinatorial weights.",
            "And in this work I will present results from the variational."
        ],
        [
            "Proximation so this is the intuition.",
            "So if if you get something out of it, this is the probably most important slide.",
            "So this is the protein.",
            "And we've got different feature spaces, so we've got the composition.",
            "I mean us composition, for example, secondary structure so forth.",
            "And.",
            "This could be for example in our case could be 12 feature spaces.",
            "Now we want to combine them so it is an ensemble method, but we don't want to run one multiclass classifier in every feature space and then combine.",
            "So what we what we can do is embed those feature spaces into kernel space is so inner product spaces of Hilbert spaces if you like.",
            "And.",
            "Therefore, in that level, we've actually created similarities between objects in all those feature spaces, and now we've got a common metric, and having a common metric, we can combine it into a composite kernel.",
            "We can also associate weights on its kernel.",
            "Therefore, doing a proper patient written learning also the significance of its individual source to the the.",
            "Overall classification problem.",
            "And then we've got an explicit explicit multiclass classifier.",
            "And then therefore we can predict the fold of the blood project.",
            "So that's the next slide is the only one that has the model, and I haven't included any any."
        ],
        [
            "Maths.",
            "So.",
            "This is the model that I will be describing very shortly, and these two are just two different extensions of ways of combining the kernels, so I will start so T are the other labels in the class labels that we want to predict, so it'll be one of 27 classes for the protein.",
            "Huawei is an auxiliary variable and this whole diagram is a plates diagram.",
            "So it's repeated sit by and the dimensions of regular variable and the whole use of the auxiliary or latent variable is that enables us to use that multinomial probit likelihood.",
            "And the intuition is that an object that belongs to class.",
            "J.",
            "So an object end that belongs to class J would have an auxiliary variable associated which is going to be greater than.",
            "Why C and for all see different J?",
            "Anne.",
            "So if we go left, we've got our standard regressors on a generalized linear framework.",
            "We've got a hyper prior distribution on the scale of the variance.",
            "And hyperparameters.",
            "This is a normal distribution and the gamma distribution gamma distribution.",
            "To ensure that we've got positive variances.",
            "AM.",
            "FTA are the kernel parameters, so we can also.",
            "Learn the smoothing if you if you like.",
            "On that space.",
            "And finally, this plate is, as we've seen before."
        ],
        [
            "Or is those vitas?"
        ],
        [
            "So it's.",
            "Learning the combinations.",
            "So the distribution of the private distribution over Vita is additional distribution, and that's because we want to ensure positive ITI identify ability of the kernels and digital distribution just defines the simplex where we can move on the simplex and on the parameter of the dearest leg we've got.",
            "I've got a gamma distribution with.",
            "Search hyperparameters.",
            "So this is the standard way of combining which is summation or could be affixed summation of journals.",
            "This extension is when when we can actually combine using what I call a binary vector, which is, which makes hard decisions, which is, it's going to be either zero or one.",
            "So this is a binomial distribution Bernoulli for.",
            "For two states.",
            "And The thing is that we don't need any hyper distribution on that 'cause the possible states are just two to VS.",
            "So we can just go easily through them.",
            "And this is another extension where we're actually using a product of kernels and.",
            "Also weighted combination where the weight is the exponent of the product.",
            "Got the government abuse and exponential distribution.",
            "So.",
            "Yeah.",
            "No, another characteristic about the model.",
            "Is that?",
            "Until here, so all of those parameters or all this model until at this level is actually regression model.",
            "'cause we're regressing on that auxiliary variable, why?",
            "And in this nature, the nature of this model is is quite helpful because we can do things like do an RVM version.",
            "On that, do not blame regression on that and then connect that to the classification.",
            "It's also very intuitive."
        ],
        [
            "So I hope I've done a good job in convincing you.",
            "So I'm going out the results of their manasco.",
            "These are the sort of individual.",
            "So if we take an individual feature space, this is our method and this is things induce back method.",
            "So this is running on individual feature space alone just for comparison reasons.",
            "With following his work.",
            "Those the 1st six are the global characteristics.",
            "Those four are the ones proposed by sending two to replace amino acid and those two are the string kernels that we're actually using employing which the Smith Waterman scores with specific scoring matrices.",
            "And we can see that we've got a massive performing very well, and also you can see that sequence permission is quite."
        ],
        [
            "Different.",
            "And so this is what happens when we start combining them and we can see that we've got a constant improvement.",
            "So this is when we're combining all the feature space together and we're actually improving.",
            "We get the 68%.",
            "Those are results, averaged over 20 rounds.",
            "And.",
            "So on the specific so I'm actually doing a comparison of the exact same feature space is that.",
            "People before have used.",
            "One of the vision is that there is only a 2% increase in predict performance by including pseudo amino acid."
        ],
        [
            "Feature spaces.",
            "And also that this is the best singer and performances.",
            "To compare explicitly again, best run performances by these two yet.",
            "State of the art resolved and 8% improvement.",
            "Anne and.",
            "Those are missable times for the VBS.",
            "We can sit around 45 minutes to run.",
            "And of course, reported times of 12 longer for."
        ],
        [
            "Those are the the weights for them in combination kernel so we can see that.",
            "I mean ask composition secondary structure, the second Smith Water answer Smith, Waterman or String kernel and Lumber one are are ranked higher.",
            "Well, actually employing all of them were not taking out."
        ],
        [
            "Anything?",
            "And this is the true class.",
            "So these are image classification matrix or confusion matrix.",
            "You see the true class and the predicted class.",
            "So ideally everything would be in the diagonal and we can see that there are two patterns and this is actually two classes that are a bit over represented in the problem.",
            "And there's also similarities, so all those proteins that are classified misclassified in this class are usually in the same family level."
        ],
        [
            "Anne."
        ],
        [
            "So.",
            "Thing.",
            "I'll go through so there's another problem is the remote homologies detection problem.",
            "A lot of attention, benefits, community, community and every produced new string kernels.",
            "And what I'm actually doing at this stage is I'm taking four of their state of the art string kernels, so I'm taking a monomer mismatch kernel, local alignment kernel and the pairwise or Smith Waterman kernel.",
            "Just combining that and getting some very good results on AUC scores.",
            "I use a 50 and me."
        ],
        [
            "Irish be.",
            "So this is number of families.",
            "Within performance, so it's.",
            "A very good AUC curve.",
            "Well you see scores pair.",
            "Family achieving, that's cool."
        ],
        [
            "So.",
            "So I hope I've convinced you that the proposed basin for dollars is very formal and is able to provide state of the art results.",
            "I'm actually combining local and global protein characteristics and getting an improvement on a data set that is of low similarity.",
            "So that was quite surprising that.",
            "And we get such an improvement, and so it's a possible way of combining feature spaces so you can do the same in your problem.",
            "It's in probabilistic, so we don't have point estimates for the class membership, but we get a probability so we can do things like further processing like cost sensitive analysis and risk including loss functions.",
            "And."
        ],
        [
            "That's it.",
            "Thank you very much.",
            "Feature spaces.",
            "Sequence information and dependence on the immediate substitution matrix.",
            "Apt 62.",
            "With respect to the substitution matrices or you just combining them all, great learning experience that automatically.",
            "So you're talking about the synchronous.",
            "Yeah.",
            "OK."
        ],
        [
            "So OK, I think that.",
            "Yep, so yeah, OK that's so I'm following.",
            "This approach is described by, so I'm following the approach of Noble basically and the approach of Noble is that this is a pairwise string kernel, some creating Smith Waterman scores between every protein.",
            "And the specific use of the.",
            "The scoring methods, so why I'm using Blosum 62 for example and what kind of gap penalties for the the sequence alignment is?",
            "Basically the ones that have been reported to be.",
            "Kind of.",
            "The best for for this specific channel, so I'm not doing any that's true.",
            "I'm not doing any explicit.",
            "I'm assuming that.",
            "You're looking at.",
            "Extension.",
            "Yeah, I mean maybe with another subscription I would get different ones.",
            "I have no insight into, I mean into.",
            "Really, why there is such a difference between these two?",
            "I mean, I'm assuming that.",
            "Because of that, because what they have, they have different scoring matrices, so they might be able to capture some some different characteristics of those proteins, especially when they are in low sequence.",
            "So again, surprisingly, the although that so that this string kernel.",
            "So it's around 50%, so it's actually just more significant, and I found that this is.",
            "Also the case.",
            "In the in the combination level, so it might be describing proteins that others the other kernels are not describing as well, so that's why it's running fine.",
            "Next 62.",
            "What is it?",
            "Yeah, I mean if you see."
        ],
        [
            "The.",
            "So.",
            "So Mark's work is.",
            "So it's at that level.",
            "So at that level, the best performance.",
            "Well, I don't have it here, but the best performers.",
            "It's it's around 61% OK 60% so it's very compareable to that.",
            "And in that work 'cause we're reporting top performances."
        ],
        [
            "So at the end of the day, if you take out.",
            "Basically, the regression.",
            "You can have a GP, which is exactly.",
            "The similarities."
        ],
        [
            "So yeah, the results are compatible.",
            "And yes, the inclusion of extra string kernels is the major improvement."
        ],
        [
            "Under 7%."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I am so in this work I will learn describer class and new classification method.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The main keywords is a probabilistic method, so we've got probabilities for class #4.",
                    "label": 0
                },
                {
                    "sent": "For the class of an object for class membership, it's a multi class method, so it's an explicit multi class method and we don't need.",
                    "label": 0
                },
                {
                    "sent": "To rely on network combinations.",
                    "label": 0
                },
                {
                    "sent": "And it's a multi kernel method in the sense that we have multiple kernels that we can combine and it's kind of can describe a feature space.",
                    "label": 0
                },
                {
                    "sent": "So I will describe two applications of that method and try to convince you that it's a very good method producing state of the art results on protein fold recognition and remote homeowners detection.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I will start first by describing the problem of protein folding, so it gives you an inside Huawei eternal combination approach that might be useful.",
                    "label": 1
                },
                {
                    "sent": "And some over the past methods that I will be comparing against and finally the results.",
                    "label": 1
                },
                {
                    "sent": "And if I have time I will also talk about remote homology problem.",
                    "label": 0
                },
                {
                    "sent": "And how we can also?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Attack that problem, so protein folding.",
                    "label": 1
                },
                {
                    "sent": "What would actually predicting is predicting the structural fold of protein.",
                    "label": 0
                },
                {
                    "sent": "So you have got to very nice pictures here.",
                    "label": 0
                },
                {
                    "sent": "We got a team battle and bitter propeller.",
                    "label": 0
                },
                {
                    "sent": "So these are two classical folds of proteins.",
                    "label": 0
                },
                {
                    "sent": "And the whole problem area is in what so called the Twilight zone where you've got you want to put to know that to learn the function of a protein.",
                    "label": 0
                },
                {
                    "sent": "But it's a low sequence so might be in the low sequence similarity zone.",
                    "label": 0
                },
                {
                    "sent": "That's the Twilight zone.",
                    "label": 0
                },
                {
                    "sent": "So you can learn the function by.",
                    "label": 0
                },
                {
                    "sent": "In the classical way, by doing something like C blast or blast and compare the sequence of the proteins and assume that they serve the same function.",
                    "label": 0
                },
                {
                    "sent": "But there is a problem where they can share the same function but don't have.",
                    "label": 1
                },
                {
                    "sent": "Sequence similarity so this is a very multiclass problem there.",
                    "label": 0
                },
                {
                    "sent": "In total, in the scope that around.",
                    "label": 0
                },
                {
                    "sent": "5000 identified faults until now.",
                    "label": 0
                },
                {
                    "sent": "And it's a multi feature problem in the sense that there are a lot of object descriptors available for that task, so you've got amino acid composition, for example, global characteristics and local characteristics.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But you can combine.",
                    "label": 0
                },
                {
                    "sent": "And so the the Golden start and there's none of benchmark data set for that problem is was described first by doing and do swag and everybody who's doing work on that problem is following that data set.",
                    "label": 0
                },
                {
                    "sent": "And it's based on SCOPE 2001 on PDP40D data set where.",
                    "label": 0
                },
                {
                    "sent": "If we got the 27 most populated falls and we use only those and there is less than 35 sequence similarity in the proteins and less than 25% sequence similarity between training set and test set and there is a standard split on the set so the work by doing and boots back, So what they've done and they've used 6 feature sets, each of one is around 20 dimension and the views global characteristics.",
                    "label": 1
                },
                {
                    "sent": "Such as only know acid, then secondary structure as well.",
                    "label": 0
                },
                {
                    "sent": "And if you sufficiently network support vector machines and becausw its multi class and multi feature.",
                    "label": 0
                },
                {
                    "sent": "You end up in an old versus old approach.",
                    "label": 0
                },
                {
                    "sent": "You end up employing around 2000 classifiers so that problem.",
                    "label": 1
                },
                {
                    "sent": "So they've done a very extensive work and try to identify which feature spaces is more significant and the best performance is around 56%.",
                    "label": 0
                },
                {
                    "sent": "So another important work by sending two in 2006 so they've replaced one of them 6 feature sets with an extra 4 ones that I will briefly talk about later on and.",
                    "label": 0
                },
                {
                    "sent": "What they've done is they've employed multiclass classifiers on its feature set and then combine those so they end up having nine Kanan classifiers and the reported in best performance of 62%.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the my.",
                    "label": 0
                },
                {
                    "sent": "My benchmark so this work is has been accepted by Infomatics.",
                    "label": 0
                },
                {
                    "sent": "In may.",
                    "label": 0
                },
                {
                    "sent": "It's a composite kernel.",
                    "label": 0
                },
                {
                    "sent": "Regression was a composite kernel as we're combining kernels.",
                    "label": 0
                },
                {
                    "sent": "I will explain further on better below.",
                    "label": 0
                },
                {
                    "sent": "And we're playing them with normal probability likelihood, and it's based on work by Solomon Rogers in Acnl where they've employed the softmax logistic likelihood.",
                    "label": 0
                },
                {
                    "sent": "And in this paper we've got that GP with normal probability version.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The best performers were going to get 70%, so it's a very significant improvement for 27 classes around an 8% movement, and we're combining information for both global characteristics.",
                    "label": 0
                },
                {
                    "sent": "We talk about these things that don't depend directly on the sequence on the sequence similarity between proteins.",
                    "label": 0
                },
                {
                    "sent": "And local characteristics which are.",
                    "label": 0
                },
                {
                    "sent": "So basically we're going to use some string kernels to do to see if we can get an improvement.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The solution is a full is a Markov chain Monte Carlo Metropolis Hastings within Gibbs, so it's a Gibbs sampler that incorporates Metropolis Hastings sub samplers to sample.",
                    "label": 0
                },
                {
                    "sent": "For example, the kernel parameters and combinatorial weights.",
                    "label": 0
                },
                {
                    "sent": "And in this work I will present results from the variational.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proximation so this is the intuition.",
                    "label": 1
                },
                {
                    "sent": "So if if you get something out of it, this is the probably most important slide.",
                    "label": 0
                },
                {
                    "sent": "So this is the protein.",
                    "label": 0
                },
                {
                    "sent": "And we've got different feature spaces, so we've got the composition.",
                    "label": 0
                },
                {
                    "sent": "I mean us composition, for example, secondary structure so forth.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This could be for example in our case could be 12 feature spaces.",
                    "label": 0
                },
                {
                    "sent": "Now we want to combine them so it is an ensemble method, but we don't want to run one multiclass classifier in every feature space and then combine.",
                    "label": 1
                },
                {
                    "sent": "So what we what we can do is embed those feature spaces into kernel space is so inner product spaces of Hilbert spaces if you like.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "Therefore, in that level, we've actually created similarities between objects in all those feature spaces, and now we've got a common metric, and having a common metric, we can combine it into a composite kernel.",
                    "label": 0
                },
                {
                    "sent": "We can also associate weights on its kernel.",
                    "label": 0
                },
                {
                    "sent": "Therefore, doing a proper patient written learning also the significance of its individual source to the the.",
                    "label": 0
                },
                {
                    "sent": "Overall classification problem.",
                    "label": 1
                },
                {
                    "sent": "And then we've got an explicit explicit multiclass classifier.",
                    "label": 0
                },
                {
                    "sent": "And then therefore we can predict the fold of the blood project.",
                    "label": 0
                },
                {
                    "sent": "So that's the next slide is the only one that has the model, and I haven't included any any.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maths.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is the model that I will be describing very shortly, and these two are just two different extensions of ways of combining the kernels, so I will start so T are the other labels in the class labels that we want to predict, so it'll be one of 27 classes for the protein.",
                    "label": 0
                },
                {
                    "sent": "Huawei is an auxiliary variable and this whole diagram is a plates diagram.",
                    "label": 0
                },
                {
                    "sent": "So it's repeated sit by and the dimensions of regular variable and the whole use of the auxiliary or latent variable is that enables us to use that multinomial probit likelihood.",
                    "label": 0
                },
                {
                    "sent": "And the intuition is that an object that belongs to class.",
                    "label": 0
                },
                {
                    "sent": "J.",
                    "label": 0
                },
                {
                    "sent": "So an object end that belongs to class J would have an auxiliary variable associated which is going to be greater than.",
                    "label": 0
                },
                {
                    "sent": "Why C and for all see different J?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So if we go left, we've got our standard regressors on a generalized linear framework.",
                    "label": 0
                },
                {
                    "sent": "We've got a hyper prior distribution on the scale of the variance.",
                    "label": 0
                },
                {
                    "sent": "And hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "This is a normal distribution and the gamma distribution gamma distribution.",
                    "label": 0
                },
                {
                    "sent": "To ensure that we've got positive variances.",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "FTA are the kernel parameters, so we can also.",
                    "label": 0
                },
                {
                    "sent": "Learn the smoothing if you if you like.",
                    "label": 0
                },
                {
                    "sent": "On that space.",
                    "label": 0
                },
                {
                    "sent": "And finally, this plate is, as we've seen before.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or is those vitas?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's.",
                    "label": 0
                },
                {
                    "sent": "Learning the combinations.",
                    "label": 0
                },
                {
                    "sent": "So the distribution of the private distribution over Vita is additional distribution, and that's because we want to ensure positive ITI identify ability of the kernels and digital distribution just defines the simplex where we can move on the simplex and on the parameter of the dearest leg we've got.",
                    "label": 0
                },
                {
                    "sent": "I've got a gamma distribution with.",
                    "label": 0
                },
                {
                    "sent": "Search hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So this is the standard way of combining which is summation or could be affixed summation of journals.",
                    "label": 0
                },
                {
                    "sent": "This extension is when when we can actually combine using what I call a binary vector, which is, which makes hard decisions, which is, it's going to be either zero or one.",
                    "label": 0
                },
                {
                    "sent": "So this is a binomial distribution Bernoulli for.",
                    "label": 0
                },
                {
                    "sent": "For two states.",
                    "label": 0
                },
                {
                    "sent": "And The thing is that we don't need any hyper distribution on that 'cause the possible states are just two to VS.",
                    "label": 0
                },
                {
                    "sent": "So we can just go easily through them.",
                    "label": 0
                },
                {
                    "sent": "And this is another extension where we're actually using a product of kernels and.",
                    "label": 0
                },
                {
                    "sent": "Also weighted combination where the weight is the exponent of the product.",
                    "label": 1
                },
                {
                    "sent": "Got the government abuse and exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "No, another characteristic about the model.",
                    "label": 1
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Until here, so all of those parameters or all this model until at this level is actually regression model.",
                    "label": 0
                },
                {
                    "sent": "'cause we're regressing on that auxiliary variable, why?",
                    "label": 1
                },
                {
                    "sent": "And in this nature, the nature of this model is is quite helpful because we can do things like do an RVM version.",
                    "label": 0
                },
                {
                    "sent": "On that, do not blame regression on that and then connect that to the classification.",
                    "label": 0
                },
                {
                    "sent": "It's also very intuitive.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I hope I've done a good job in convincing you.",
                    "label": 0
                },
                {
                    "sent": "So I'm going out the results of their manasco.",
                    "label": 0
                },
                {
                    "sent": "These are the sort of individual.",
                    "label": 0
                },
                {
                    "sent": "So if we take an individual feature space, this is our method and this is things induce back method.",
                    "label": 0
                },
                {
                    "sent": "So this is running on individual feature space alone just for comparison reasons.",
                    "label": 0
                },
                {
                    "sent": "With following his work.",
                    "label": 0
                },
                {
                    "sent": "Those the 1st six are the global characteristics.",
                    "label": 0
                },
                {
                    "sent": "Those four are the ones proposed by sending two to replace amino acid and those two are the string kernels that we're actually using employing which the Smith Waterman scores with specific scoring matrices.",
                    "label": 0
                },
                {
                    "sent": "And we can see that we've got a massive performing very well, and also you can see that sequence permission is quite.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different.",
                    "label": 0
                },
                {
                    "sent": "And so this is what happens when we start combining them and we can see that we've got a constant improvement.",
                    "label": 0
                },
                {
                    "sent": "So this is when we're combining all the feature space together and we're actually improving.",
                    "label": 0
                },
                {
                    "sent": "We get the 68%.",
                    "label": 0
                },
                {
                    "sent": "Those are results, averaged over 20 rounds.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So on the specific so I'm actually doing a comparison of the exact same feature space is that.",
                    "label": 0
                },
                {
                    "sent": "People before have used.",
                    "label": 0
                },
                {
                    "sent": "One of the vision is that there is only a 2% increase in predict performance by including pseudo amino acid.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Feature spaces.",
                    "label": 0
                },
                {
                    "sent": "And also that this is the best singer and performances.",
                    "label": 0
                },
                {
                    "sent": "To compare explicitly again, best run performances by these two yet.",
                    "label": 1
                },
                {
                    "sent": "State of the art resolved and 8% improvement.",
                    "label": 0
                },
                {
                    "sent": "Anne and.",
                    "label": 0
                },
                {
                    "sent": "Those are missable times for the VBS.",
                    "label": 1
                },
                {
                    "sent": "We can sit around 45 minutes to run.",
                    "label": 1
                },
                {
                    "sent": "And of course, reported times of 12 longer for.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those are the the weights for them in combination kernel so we can see that.",
                    "label": 0
                },
                {
                    "sent": "I mean ask composition secondary structure, the second Smith Water answer Smith, Waterman or String kernel and Lumber one are are ranked higher.",
                    "label": 0
                },
                {
                    "sent": "Well, actually employing all of them were not taking out.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anything?",
                    "label": 0
                },
                {
                    "sent": "And this is the true class.",
                    "label": 0
                },
                {
                    "sent": "So these are image classification matrix or confusion matrix.",
                    "label": 0
                },
                {
                    "sent": "You see the true class and the predicted class.",
                    "label": 0
                },
                {
                    "sent": "So ideally everything would be in the diagonal and we can see that there are two patterns and this is actually two classes that are a bit over represented in the problem.",
                    "label": 0
                },
                {
                    "sent": "And there's also similarities, so all those proteins that are classified misclassified in this class are usually in the same family level.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Thing.",
                    "label": 0
                },
                {
                    "sent": "I'll go through so there's another problem is the remote homologies detection problem.",
                    "label": 0
                },
                {
                    "sent": "A lot of attention, benefits, community, community and every produced new string kernels.",
                    "label": 0
                },
                {
                    "sent": "And what I'm actually doing at this stage is I'm taking four of their state of the art string kernels, so I'm taking a monomer mismatch kernel, local alignment kernel and the pairwise or Smith Waterman kernel.",
                    "label": 0
                },
                {
                    "sent": "Just combining that and getting some very good results on AUC scores.",
                    "label": 0
                },
                {
                    "sent": "I use a 50 and me.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Irish be.",
                    "label": 0
                },
                {
                    "sent": "So this is number of families.",
                    "label": 0
                },
                {
                    "sent": "Within performance, so it's.",
                    "label": 0
                },
                {
                    "sent": "A very good AUC curve.",
                    "label": 0
                },
                {
                    "sent": "Well you see scores pair.",
                    "label": 0
                },
                {
                    "sent": "Family achieving, that's cool.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So I hope I've convinced you that the proposed basin for dollars is very formal and is able to provide state of the art results.",
                    "label": 1
                },
                {
                    "sent": "I'm actually combining local and global protein characteristics and getting an improvement on a data set that is of low similarity.",
                    "label": 1
                },
                {
                    "sent": "So that was quite surprising that.",
                    "label": 1
                },
                {
                    "sent": "And we get such an improvement, and so it's a possible way of combining feature spaces so you can do the same in your problem.",
                    "label": 0
                },
                {
                    "sent": "It's in probabilistic, so we don't have point estimates for the class membership, but we get a probability so we can do things like further processing like cost sensitive analysis and risk including loss functions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Feature spaces.",
                    "label": 0
                },
                {
                    "sent": "Sequence information and dependence on the immediate substitution matrix.",
                    "label": 0
                },
                {
                    "sent": "Apt 62.",
                    "label": 0
                },
                {
                    "sent": "With respect to the substitution matrices or you just combining them all, great learning experience that automatically.",
                    "label": 0
                },
                {
                    "sent": "So you're talking about the synchronous.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, I think that.",
                    "label": 0
                },
                {
                    "sent": "Yep, so yeah, OK that's so I'm following.",
                    "label": 0
                },
                {
                    "sent": "This approach is described by, so I'm following the approach of Noble basically and the approach of Noble is that this is a pairwise string kernel, some creating Smith Waterman scores between every protein.",
                    "label": 0
                },
                {
                    "sent": "And the specific use of the.",
                    "label": 0
                },
                {
                    "sent": "The scoring methods, so why I'm using Blosum 62 for example and what kind of gap penalties for the the sequence alignment is?",
                    "label": 0
                },
                {
                    "sent": "Basically the ones that have been reported to be.",
                    "label": 0
                },
                {
                    "sent": "Kind of.",
                    "label": 0
                },
                {
                    "sent": "The best for for this specific channel, so I'm not doing any that's true.",
                    "label": 0
                },
                {
                    "sent": "I'm not doing any explicit.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming that.",
                    "label": 0
                },
                {
                    "sent": "You're looking at.",
                    "label": 0
                },
                {
                    "sent": "Extension.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean maybe with another subscription I would get different ones.",
                    "label": 0
                },
                {
                    "sent": "I have no insight into, I mean into.",
                    "label": 0
                },
                {
                    "sent": "Really, why there is such a difference between these two?",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm assuming that.",
                    "label": 0
                },
                {
                    "sent": "Because of that, because what they have, they have different scoring matrices, so they might be able to capture some some different characteristics of those proteins, especially when they are in low sequence.",
                    "label": 0
                },
                {
                    "sent": "So again, surprisingly, the although that so that this string kernel.",
                    "label": 0
                },
                {
                    "sent": "So it's around 50%, so it's actually just more significant, and I found that this is.",
                    "label": 0
                },
                {
                    "sent": "Also the case.",
                    "label": 0
                },
                {
                    "sent": "In the in the combination level, so it might be describing proteins that others the other kernels are not describing as well, so that's why it's running fine.",
                    "label": 0
                },
                {
                    "sent": "Next 62.",
                    "label": 0
                },
                {
                    "sent": "What is it?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean if you see.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So Mark's work is.",
                    "label": 0
                },
                {
                    "sent": "So it's at that level.",
                    "label": 0
                },
                {
                    "sent": "So at that level, the best performance.",
                    "label": 0
                },
                {
                    "sent": "Well, I don't have it here, but the best performers.",
                    "label": 0
                },
                {
                    "sent": "It's it's around 61% OK 60% so it's very compareable to that.",
                    "label": 0
                },
                {
                    "sent": "And in that work 'cause we're reporting top performances.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at the end of the day, if you take out.",
                    "label": 0
                },
                {
                    "sent": "Basically, the regression.",
                    "label": 0
                },
                {
                    "sent": "You can have a GP, which is exactly.",
                    "label": 0
                },
                {
                    "sent": "The similarities.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So yeah, the results are compatible.",
                    "label": 0
                },
                {
                    "sent": "And yes, the inclusion of extra string kernels is the major improvement.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Under 7%.",
                    "label": 0
                }
            ]
        }
    }
}