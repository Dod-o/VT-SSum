{
    "id": "imuzriahmaw5hifq3gkkrmys5toatvov",
    "title": "Language and Domain Aware Lightweight Ontology Matching",
    "info": {
        "author": [
            "G\u00e1bor Bella, School of Informatics, University of Edinburgh"
        ],
        "published": "Nov. 28, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2017_bella_ontology_matching/",
    "segmentation": [
        [
            "So it I SWC there have been hundreds of talks I think about on top."
        ],
        [
            "Matching ontology alignment.",
            "But of course not only the methods differ, but the kinds of ontologies that you are matching, and the ones that we are particularly interested in.",
            "A specific type of ontologies that we call lightweight ontologies, which are the formalizations of classifications of catalogs, library, subject, heading, these kinds of things.",
            "So like like the one that you see in the example, which is a classification magic, medical procedures.",
            "So these kinds of informal structures are actually more common, more widely used than than real formal ontologies, and often they serve as as backbones for domain knowledge."
        ],
        [
            "I'm going to present you a specific use case.",
            "Of course there are lots, but we don't have time, so this is something that we are working on right now.",
            "This is on medical research, so as a research in medicine is becoming more and more precise.",
            "So for example, today we know about hundreds of types of cancer, whereas I don't know.",
            "20 years ago we knew of much less, so we need more and more data for this precise research.",
            "Statistical research to be statistically significant.",
            "So this means that the pool of data that you can get from a single country is often not enough anymore, so you need to combine data patient data from lots of countries for step from several countries.",
            "And of course, this is a hard data integration problem because the language can be different because the standards being used are different and so on."
        ],
        [
            "So if you look at this example here where you see.",
            "The British standard for the classification of medical procedures or PC S and the French one, CCIM.",
            "So you see that you you need to match across languages that often you have domain terminology that appears in them and that you need to understand to be to be able to match.",
            "And that the mappings themselves.",
            "Sometimes for some use cases need to be really precise, so general similarity mapping that most matches return may not be enough.",
            "So if I tell you that you have a flu or you have something similar to a flu.",
            "It's not the same thing, right?",
            "So, um.",
            "OK, so let's look at the state of the art.",
            "So I had this confirmed from Ernesto Lee."
        ],
        [
            "Yeah, if you look at the ontology Alignment Evaluation initiative on the multilingual track, what you see that?",
            "What everyone does is basically.",
            "So if there are not English non English ontologist to match, first they translate everything to English and then using machine translation and then they use plain old English to English Matcher.",
            "So this of course is a very sensible useful approach.",
            "There are lots of advantages, but this is quite trivial to implement.",
            "There is no language of awareness in the model in the matcher.",
            "The language awareness of the linguistic processing is totally outsourced into machine translator.",
            "If this is a good quality machine translator such as Google Translate, then you will get very good quality translations and and you will get support for lots of languages at the same time.",
            "Of course, there are also disadvantages, so a good quality machine translator is usually not for free.",
            "It is a black box for you, so you can.",
            "You can use it as an outside resource, but you have no influence over it.",
            "You cannot extend it, you cannot retrain it, you cannot adapt it.",
            "And the the the quality that it will give you.",
            "So this is true for the statistical machine.",
            "Translators will depend on the size of the Corp around which they were trained for.",
            "Languages with smaller Internet presence.",
            "The quality will not be as good."
        ],
        [
            "So I our idea was to try something, try a different approach.",
            "Try to build an ontology matcher where language awareness and domain awareness or language support and domain support are built in.",
            "And we end the ideas to to compare the results to the state of the art approach and see what is different."
        ],
        [
            "OK, so very quickly how it works.",
            "So in as input of your make sure you have the two hierarchies and the mappings is output.",
            "So far so good.",
            "The first main step is formalization, where you take your labels and you construct language independent meanings for them.",
            "This is done by multilingual NLP, multilingual NLP and turn uses lexical concepts from a background knowledge to construct the label meanings.",
            "And this background knowledge is also used in the next step.",
            "The actual matching step as axioms for the matching."
        ],
        [
            "OK, now let's have a look at how the background knowledge is constructed.",
            "There are two layers as you can see the there's a language independent layer of concepts and relations, language independent ontology.",
            "And then there are language dependent lexicons.",
            "Well, this is a kind of.",
            "This kind of architecture has become commonplace nowadays, so there are there are several resources that offer you these two layer structure.",
            "For example bobbinet.",
            "We use the different one called the Universal Knowledge Core, but the principle is the same.",
            "And then extensibility, of course, is is key here.",
            "So if you need to extend this architecture to a new language, you need to plug in a new lexicon.",
            "And of course you need to plug in language support for the NLP.",
            "And if you want to extend by domain knowledge, you need to plug in domain terminology than domain ontologies on both levels of background knowledge.",
            "A few words about NLP so."
        ],
        [
            "So the.",
            "The engineering problem that that is to be solved with language and domain aware matching is of course the cost of building these built-in resources, so we saw that for the background knowledge we are able to reuse existing resources for NLP.",
            "It's also the case, so I will show you how we we managed to mitigate the inherent costly Ness of multilingual NLP.",
            "We divided the NLP pipeline into 2 main parts.",
            "The semantic part and the syntactic preprocessing part.",
            "The semantic part is totally language independent.",
            "And the syntactic part is a kind of a lightweight NLP with few components.",
            "Those are language dependent, but with few components especially.",
            "Tokenization, lemmatization, and optionally syntactic parsing.",
            "So the matcher that we used needs a kind of a lightweight syntactic parser.",
            "Other matches don't need and don't use any syntactic parsing, so there it's not needed.",
            "So The thing is that if we need to extend the NLP to new language, it's only this lightweight preprocessing part that needs to be adapted.",
            "Currently we are supporting our system.",
            "We are supporting 7 languages on the NLP level, English, Italian, Spanish, German, Arabic, Chinese and Mongolian.",
            "And in terms of languages in the background knowledge, we have roughly 300 with varying levels of coverage, of course."
        ],
        [
            "OK, so how did we evaluate this?",
            "We took two corpora you revoke and UDC universal decimal classifications, and in three languages English, Spanish, Italian in all three combinations of these.",
            "And the matcher that we used was as match it's.",
            "It's because it's a.",
            "It's a semantic matcher that was designed specifically for lightweight ontologies.",
            "And we use the the old version of S match that is English only for the purposes of machine translation and we used.",
            "For the purposes of.",
            "Overmatching machine translated English labels and we use the new version.",
            "The language and domain aware version for the built in.",
            "My."
        ],
        [
            "Watching.",
            "So this is the set up as you see, so we have the two versions of S match and we have as machine translator.",
            "We used Google Translate and we also used opportune to compare the two."
        ],
        [
            "And these are the results.",
            "What you see RF measures.",
            "So the.",
            "The dark bars are the language and domain aware.",
            "Measure.",
            "The light bars are the ones obtained using Google Translate and the third one is a per team.",
            "So per team didn't support Italian, that's why it's result are missing in some places, So what you can see is that armature obtained between 70 and 80% for you revoke a little bit a little bit less between 50 and 64.",
            "UDC on the UDC corpus.",
            "Google Translate was better, sometimes by as much as 12%, sometimes only marginally or not at all.",
            "And the perfume when when we had it, was significantly worse.",
            "And then either of the two.",
            "So here already we have some insight that the quality of the machine translator is very important for the for the results.",
            "Then something else that is interesting that you observe is that for the Spanish to Italian language pair, the difference was almost was actually negligible.",
            "I don't have the pointer, never mind, so this is not very surprising because here the machine translator has to do 2 translations, so both Spanish and Italian need to be translated to English and so the probability of error is higher.",
            "And then there was another thing.",
            "So we we had a look at the matching mistakes, the failures in our system and what will.",
            "And we realized that the number one reason for failure was lexical incompleteness so.",
            "Basically, these were the words that were not words and expressions that were not present in our background knowledge.",
            "So we did another round of tests where we eliminated this lexical incompleteness and what we got were results that were much closer to Google similar and on the on the non English language pair.",
            "So Spanish Italian, we actually outperformed Google by how much.",
            "2 to 6%."
        ],
        [
            "So, um.",
            "Of course, these are two completely different ways of doing matching, and they make different mistakes.",
            "So we did an analysis of the kinds of mistakes that each technique makes in the paper.",
            "And the idea came that we can combine them and create a kind of a Fusion matcher which would outperform either of the two.",
            "Which is what we did the the combination method that we used."
        ],
        [
            "The simplest possible.",
            "Basically an all based combination that will that will boost recall and F measure, and these are the results that you see.",
            "So with respect to the best measure we consistently gained this way 5 to 10%.",
            "OK, and these are finally my conclusions.",
            "So without wanting to."
        ],
        [
            "To be to take vague and two general conclusions on statistical versus formal methods, we can say that at least for ontology matching, they seem to be able to produce similar results with very, very good quality machine translators.",
            "Still having a certain advantage.",
            "But disadvantages is really dependent on what kind of.",
            "Machine translator you use.",
            "And on what language pairs you are using it?",
            "You saw that a combined approach between the two can significantly improve the results.",
            "On the other hand, so the method that we tested.",
            "Is extensible, you have complete control over it.",
            "You can adapt it to various domains.",
            "You can adapt it to various languages, but there's an inherent cost.",
            "Of course to building it.",
            "This is it.",
            "Thank you very much.",
            "I was wondering if you compare your approach to the state of the art approaches on the motor linguo AI modifier MA Track.",
            "If you had tried to run it, no, I didn't.",
            "The that's quite a different game, so This is why we don't participate to to that track, because basically they because they all use machine translation.",
            "They use the evaluation, they have lots of languages and we don't have support for all those fall off.",
            "So yeah, it was my second question.",
            "Why not participate in the campaigns, because in fact all the matching those you are using translations.",
            "And using a hybrid approach, as you are proposing, could be a nice comparison as well.",
            "Even if a force impairs, so it would be nice to have a. Yeah, I agree, actually it would be very interesting, so it's we just need to invest the work into participating.",
            "Thank you.",
            "Thank you for the presentation.",
            "Yeah, so I think it's going to the right direction and I wonder if we could push it a bit more and.",
            "So may I make the relation between 2 words on embeddings?",
            "We start to do to see work on embedding entities in knowledge, graphs and concepts in ontologies.",
            "It's on one side and the other on the other side in translation language translation.",
            "Machine translation embeddings are also used as a common universal representation of language, and then when you do translation you translate from one language to the embedding and then to the other language.",
            "And I wonder if that would be something that we could apply in ontology, right?",
            "Apply this model.",
            "I'm adding concepts in an ontology and then translate into the other ontology too.",
            "To do some matching, yes, I think that definitely the answer is yes and there are people doing it.",
            "I'm sure, and the.",
            "We didn't do this.",
            "And one reason is that.",
            "With that kind of solution, word embeddings.",
            "What you necessarily get our is is similarities.",
            "So numerical similarities and we are operating on with semantic relations as mapping relations.",
            "So so the matter that we used for these evaluations is one that doesn't work with similarities.",
            "It works with with with logical inference and semantic relations.",
            "So the solution you are proposing goes in a different direction, and nevertheless the answer is yes.",
            "So that is that is a good way to go.",
            "Another, just a quick quick question regarding the use of Google Translate your your test data set.",
            "You revoke your using your work and another one euro work is available online with the translations that are associated to it already.",
            "An Google Translate is mainly trained using some available online sources, so you're using the result as part of the evaluation.",
            "The data is already there, right so?",
            "There's somebody is there.",
            "You are very much right.",
            "So actually we are giving advantage to Google Becausw.",
            "A lot of expressions and labels are part of its training data set.",
            "Nevertheless, the results were not perfect with Google either, so it's not generally true, but to some extent this is true, yes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it I SWC there have been hundreds of talks I think about on top.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Matching ontology alignment.",
                    "label": 0
                },
                {
                    "sent": "But of course not only the methods differ, but the kinds of ontologies that you are matching, and the ones that we are particularly interested in.",
                    "label": 0
                },
                {
                    "sent": "A specific type of ontologies that we call lightweight ontologies, which are the formalizations of classifications of catalogs, library, subject, heading, these kinds of things.",
                    "label": 1
                },
                {
                    "sent": "So like like the one that you see in the example, which is a classification magic, medical procedures.",
                    "label": 0
                },
                {
                    "sent": "So these kinds of informal structures are actually more common, more widely used than than real formal ontologies, and often they serve as as backbones for domain knowledge.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to present you a specific use case.",
                    "label": 0
                },
                {
                    "sent": "Of course there are lots, but we don't have time, so this is something that we are working on right now.",
                    "label": 0
                },
                {
                    "sent": "This is on medical research, so as a research in medicine is becoming more and more precise.",
                    "label": 0
                },
                {
                    "sent": "So for example, today we know about hundreds of types of cancer, whereas I don't know.",
                    "label": 0
                },
                {
                    "sent": "20 years ago we knew of much less, so we need more and more data for this precise research.",
                    "label": 0
                },
                {
                    "sent": "Statistical research to be statistically significant.",
                    "label": 0
                },
                {
                    "sent": "So this means that the pool of data that you can get from a single country is often not enough anymore, so you need to combine data patient data from lots of countries for step from several countries.",
                    "label": 0
                },
                {
                    "sent": "And of course, this is a hard data integration problem because the language can be different because the standards being used are different and so on.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you look at this example here where you see.",
                    "label": 0
                },
                {
                    "sent": "The British standard for the classification of medical procedures or PC S and the French one, CCIM.",
                    "label": 0
                },
                {
                    "sent": "So you see that you you need to match across languages that often you have domain terminology that appears in them and that you need to understand to be to be able to match.",
                    "label": 1
                },
                {
                    "sent": "And that the mappings themselves.",
                    "label": 0
                },
                {
                    "sent": "Sometimes for some use cases need to be really precise, so general similarity mapping that most matches return may not be enough.",
                    "label": 0
                },
                {
                    "sent": "So if I tell you that you have a flu or you have something similar to a flu.",
                    "label": 0
                },
                {
                    "sent": "It's not the same thing, right?",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at the state of the art.",
                    "label": 0
                },
                {
                    "sent": "So I had this confirmed from Ernesto Lee.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, if you look at the ontology Alignment Evaluation initiative on the multilingual track, what you see that?",
                    "label": 0
                },
                {
                    "sent": "What everyone does is basically.",
                    "label": 0
                },
                {
                    "sent": "So if there are not English non English ontologist to match, first they translate everything to English and then using machine translation and then they use plain old English to English Matcher.",
                    "label": 0
                },
                {
                    "sent": "So this of course is a very sensible useful approach.",
                    "label": 0
                },
                {
                    "sent": "There are lots of advantages, but this is quite trivial to implement.",
                    "label": 1
                },
                {
                    "sent": "There is no language of awareness in the model in the matcher.",
                    "label": 0
                },
                {
                    "sent": "The language awareness of the linguistic processing is totally outsourced into machine translator.",
                    "label": 0
                },
                {
                    "sent": "If this is a good quality machine translator such as Google Translate, then you will get very good quality translations and and you will get support for lots of languages at the same time.",
                    "label": 1
                },
                {
                    "sent": "Of course, there are also disadvantages, so a good quality machine translator is usually not for free.",
                    "label": 0
                },
                {
                    "sent": "It is a black box for you, so you can.",
                    "label": 0
                },
                {
                    "sent": "You can use it as an outside resource, but you have no influence over it.",
                    "label": 0
                },
                {
                    "sent": "You cannot extend it, you cannot retrain it, you cannot adapt it.",
                    "label": 0
                },
                {
                    "sent": "And the the the quality that it will give you.",
                    "label": 0
                },
                {
                    "sent": "So this is true for the statistical machine.",
                    "label": 0
                },
                {
                    "sent": "Translators will depend on the size of the Corp around which they were trained for.",
                    "label": 0
                },
                {
                    "sent": "Languages with smaller Internet presence.",
                    "label": 0
                },
                {
                    "sent": "The quality will not be as good.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I our idea was to try something, try a different approach.",
                    "label": 0
                },
                {
                    "sent": "Try to build an ontology matcher where language awareness and domain awareness or language support and domain support are built in.",
                    "label": 1
                },
                {
                    "sent": "And we end the ideas to to compare the results to the state of the art approach and see what is different.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so very quickly how it works.",
                    "label": 0
                },
                {
                    "sent": "So in as input of your make sure you have the two hierarchies and the mappings is output.",
                    "label": 0
                },
                {
                    "sent": "So far so good.",
                    "label": 0
                },
                {
                    "sent": "The first main step is formalization, where you take your labels and you construct language independent meanings for them.",
                    "label": 0
                },
                {
                    "sent": "This is done by multilingual NLP, multilingual NLP and turn uses lexical concepts from a background knowledge to construct the label meanings.",
                    "label": 1
                },
                {
                    "sent": "And this background knowledge is also used in the next step.",
                    "label": 0
                },
                {
                    "sent": "The actual matching step as axioms for the matching.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now let's have a look at how the background knowledge is constructed.",
                    "label": 0
                },
                {
                    "sent": "There are two layers as you can see the there's a language independent layer of concepts and relations, language independent ontology.",
                    "label": 0
                },
                {
                    "sent": "And then there are language dependent lexicons.",
                    "label": 0
                },
                {
                    "sent": "Well, this is a kind of.",
                    "label": 0
                },
                {
                    "sent": "This kind of architecture has become commonplace nowadays, so there are there are several resources that offer you these two layer structure.",
                    "label": 0
                },
                {
                    "sent": "For example bobbinet.",
                    "label": 0
                },
                {
                    "sent": "We use the different one called the Universal Knowledge Core, but the principle is the same.",
                    "label": 0
                },
                {
                    "sent": "And then extensibility, of course, is is key here.",
                    "label": 0
                },
                {
                    "sent": "So if you need to extend this architecture to a new language, you need to plug in a new lexicon.",
                    "label": 0
                },
                {
                    "sent": "And of course you need to plug in language support for the NLP.",
                    "label": 1
                },
                {
                    "sent": "And if you want to extend by domain knowledge, you need to plug in domain terminology than domain ontologies on both levels of background knowledge.",
                    "label": 1
                },
                {
                    "sent": "A few words about NLP so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "The engineering problem that that is to be solved with language and domain aware matching is of course the cost of building these built-in resources, so we saw that for the background knowledge we are able to reuse existing resources for NLP.",
                    "label": 0
                },
                {
                    "sent": "It's also the case, so I will show you how we we managed to mitigate the inherent costly Ness of multilingual NLP.",
                    "label": 0
                },
                {
                    "sent": "We divided the NLP pipeline into 2 main parts.",
                    "label": 0
                },
                {
                    "sent": "The semantic part and the syntactic preprocessing part.",
                    "label": 0
                },
                {
                    "sent": "The semantic part is totally language independent.",
                    "label": 0
                },
                {
                    "sent": "And the syntactic part is a kind of a lightweight NLP with few components.",
                    "label": 0
                },
                {
                    "sent": "Those are language dependent, but with few components especially.",
                    "label": 0
                },
                {
                    "sent": "Tokenization, lemmatization, and optionally syntactic parsing.",
                    "label": 0
                },
                {
                    "sent": "So the matcher that we used needs a kind of a lightweight syntactic parser.",
                    "label": 0
                },
                {
                    "sent": "Other matches don't need and don't use any syntactic parsing, so there it's not needed.",
                    "label": 0
                },
                {
                    "sent": "So The thing is that if we need to extend the NLP to new language, it's only this lightweight preprocessing part that needs to be adapted.",
                    "label": 0
                },
                {
                    "sent": "Currently we are supporting our system.",
                    "label": 0
                },
                {
                    "sent": "We are supporting 7 languages on the NLP level, English, Italian, Spanish, German, Arabic, Chinese and Mongolian.",
                    "label": 0
                },
                {
                    "sent": "And in terms of languages in the background knowledge, we have roughly 300 with varying levels of coverage, of course.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how did we evaluate this?",
                    "label": 0
                },
                {
                    "sent": "We took two corpora you revoke and UDC universal decimal classifications, and in three languages English, Spanish, Italian in all three combinations of these.",
                    "label": 1
                },
                {
                    "sent": "And the matcher that we used was as match it's.",
                    "label": 0
                },
                {
                    "sent": "It's because it's a.",
                    "label": 1
                },
                {
                    "sent": "It's a semantic matcher that was designed specifically for lightweight ontologies.",
                    "label": 0
                },
                {
                    "sent": "And we use the the old version of S match that is English only for the purposes of machine translation and we used.",
                    "label": 0
                },
                {
                    "sent": "For the purposes of.",
                    "label": 0
                },
                {
                    "sent": "Overmatching machine translated English labels and we use the new version.",
                    "label": 0
                },
                {
                    "sent": "The language and domain aware version for the built in.",
                    "label": 0
                },
                {
                    "sent": "My.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Watching.",
                    "label": 0
                },
                {
                    "sent": "So this is the set up as you see, so we have the two versions of S match and we have as machine translator.",
                    "label": 0
                },
                {
                    "sent": "We used Google Translate and we also used opportune to compare the two.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these are the results.",
                    "label": 0
                },
                {
                    "sent": "What you see RF measures.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "The dark bars are the language and domain aware.",
                    "label": 0
                },
                {
                    "sent": "Measure.",
                    "label": 0
                },
                {
                    "sent": "The light bars are the ones obtained using Google Translate and the third one is a per team.",
                    "label": 0
                },
                {
                    "sent": "So per team didn't support Italian, that's why it's result are missing in some places, So what you can see is that armature obtained between 70 and 80% for you revoke a little bit a little bit less between 50 and 64.",
                    "label": 0
                },
                {
                    "sent": "UDC on the UDC corpus.",
                    "label": 0
                },
                {
                    "sent": "Google Translate was better, sometimes by as much as 12%, sometimes only marginally or not at all.",
                    "label": 0
                },
                {
                    "sent": "And the perfume when when we had it, was significantly worse.",
                    "label": 0
                },
                {
                    "sent": "And then either of the two.",
                    "label": 0
                },
                {
                    "sent": "So here already we have some insight that the quality of the machine translator is very important for the for the results.",
                    "label": 0
                },
                {
                    "sent": "Then something else that is interesting that you observe is that for the Spanish to Italian language pair, the difference was almost was actually negligible.",
                    "label": 0
                },
                {
                    "sent": "I don't have the pointer, never mind, so this is not very surprising because here the machine translator has to do 2 translations, so both Spanish and Italian need to be translated to English and so the probability of error is higher.",
                    "label": 0
                },
                {
                    "sent": "And then there was another thing.",
                    "label": 0
                },
                {
                    "sent": "So we we had a look at the matching mistakes, the failures in our system and what will.",
                    "label": 0
                },
                {
                    "sent": "And we realized that the number one reason for failure was lexical incompleteness so.",
                    "label": 0
                },
                {
                    "sent": "Basically, these were the words that were not words and expressions that were not present in our background knowledge.",
                    "label": 0
                },
                {
                    "sent": "So we did another round of tests where we eliminated this lexical incompleteness and what we got were results that were much closer to Google similar and on the on the non English language pair.",
                    "label": 0
                },
                {
                    "sent": "So Spanish Italian, we actually outperformed Google by how much.",
                    "label": 0
                },
                {
                    "sent": "2 to 6%.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Of course, these are two completely different ways of doing matching, and they make different mistakes.",
                    "label": 0
                },
                {
                    "sent": "So we did an analysis of the kinds of mistakes that each technique makes in the paper.",
                    "label": 0
                },
                {
                    "sent": "And the idea came that we can combine them and create a kind of a Fusion matcher which would outperform either of the two.",
                    "label": 0
                },
                {
                    "sent": "Which is what we did the the combination method that we used.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The simplest possible.",
                    "label": 0
                },
                {
                    "sent": "Basically an all based combination that will that will boost recall and F measure, and these are the results that you see.",
                    "label": 0
                },
                {
                    "sent": "So with respect to the best measure we consistently gained this way 5 to 10%.",
                    "label": 1
                },
                {
                    "sent": "OK, and these are finally my conclusions.",
                    "label": 0
                },
                {
                    "sent": "So without wanting to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To be to take vague and two general conclusions on statistical versus formal methods, we can say that at least for ontology matching, they seem to be able to produce similar results with very, very good quality machine translators.",
                    "label": 0
                },
                {
                    "sent": "Still having a certain advantage.",
                    "label": 0
                },
                {
                    "sent": "But disadvantages is really dependent on what kind of.",
                    "label": 0
                },
                {
                    "sent": "Machine translator you use.",
                    "label": 0
                },
                {
                    "sent": "And on what language pairs you are using it?",
                    "label": 0
                },
                {
                    "sent": "You saw that a combined approach between the two can significantly improve the results.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, so the method that we tested.",
                    "label": 0
                },
                {
                    "sent": "Is extensible, you have complete control over it.",
                    "label": 0
                },
                {
                    "sent": "You can adapt it to various domains.",
                    "label": 0
                },
                {
                    "sent": "You can adapt it to various languages, but there's an inherent cost.",
                    "label": 0
                },
                {
                    "sent": "Of course to building it.",
                    "label": 0
                },
                {
                    "sent": "This is it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "I was wondering if you compare your approach to the state of the art approaches on the motor linguo AI modifier MA Track.",
                    "label": 0
                },
                {
                    "sent": "If you had tried to run it, no, I didn't.",
                    "label": 0
                },
                {
                    "sent": "The that's quite a different game, so This is why we don't participate to to that track, because basically they because they all use machine translation.",
                    "label": 1
                },
                {
                    "sent": "They use the evaluation, they have lots of languages and we don't have support for all those fall off.",
                    "label": 1
                },
                {
                    "sent": "So yeah, it was my second question.",
                    "label": 0
                },
                {
                    "sent": "Why not participate in the campaigns, because in fact all the matching those you are using translations.",
                    "label": 0
                },
                {
                    "sent": "And using a hybrid approach, as you are proposing, could be a nice comparison as well.",
                    "label": 0
                },
                {
                    "sent": "Even if a force impairs, so it would be nice to have a. Yeah, I agree, actually it would be very interesting, so it's we just need to invest the work into participating.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the presentation.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I think it's going to the right direction and I wonder if we could push it a bit more and.",
                    "label": 0
                },
                {
                    "sent": "So may I make the relation between 2 words on embeddings?",
                    "label": 0
                },
                {
                    "sent": "We start to do to see work on embedding entities in knowledge, graphs and concepts in ontologies.",
                    "label": 0
                },
                {
                    "sent": "It's on one side and the other on the other side in translation language translation.",
                    "label": 0
                },
                {
                    "sent": "Machine translation embeddings are also used as a common universal representation of language, and then when you do translation you translate from one language to the embedding and then to the other language.",
                    "label": 0
                },
                {
                    "sent": "And I wonder if that would be something that we could apply in ontology, right?",
                    "label": 0
                },
                {
                    "sent": "Apply this model.",
                    "label": 0
                },
                {
                    "sent": "I'm adding concepts in an ontology and then translate into the other ontology too.",
                    "label": 0
                },
                {
                    "sent": "To do some matching, yes, I think that definitely the answer is yes and there are people doing it.",
                    "label": 0
                },
                {
                    "sent": "I'm sure, and the.",
                    "label": 0
                },
                {
                    "sent": "We didn't do this.",
                    "label": 0
                },
                {
                    "sent": "And one reason is that.",
                    "label": 0
                },
                {
                    "sent": "With that kind of solution, word embeddings.",
                    "label": 0
                },
                {
                    "sent": "What you necessarily get our is is similarities.",
                    "label": 0
                },
                {
                    "sent": "So numerical similarities and we are operating on with semantic relations as mapping relations.",
                    "label": 0
                },
                {
                    "sent": "So so the matter that we used for these evaluations is one that doesn't work with similarities.",
                    "label": 0
                },
                {
                    "sent": "It works with with with logical inference and semantic relations.",
                    "label": 0
                },
                {
                    "sent": "So the solution you are proposing goes in a different direction, and nevertheless the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "So that is that is a good way to go.",
                    "label": 0
                },
                {
                    "sent": "Another, just a quick quick question regarding the use of Google Translate your your test data set.",
                    "label": 1
                },
                {
                    "sent": "You revoke your using your work and another one euro work is available online with the translations that are associated to it already.",
                    "label": 0
                },
                {
                    "sent": "An Google Translate is mainly trained using some available online sources, so you're using the result as part of the evaluation.",
                    "label": 0
                },
                {
                    "sent": "The data is already there, right so?",
                    "label": 0
                },
                {
                    "sent": "There's somebody is there.",
                    "label": 0
                },
                {
                    "sent": "You are very much right.",
                    "label": 0
                },
                {
                    "sent": "So actually we are giving advantage to Google Becausw.",
                    "label": 0
                },
                {
                    "sent": "A lot of expressions and labels are part of its training data set.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, the results were not perfect with Google either, so it's not generally true, but to some extent this is true, yes.",
                    "label": 0
                }
            ]
        }
    }
}