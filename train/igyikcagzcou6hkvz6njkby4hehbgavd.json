{
    "id": "igyikcagzcou6hkvz6njkby4hehbgavd",
    "title": "Pattern Based Knowledge Base Enrichment",
    "info": {
        "author": [
            "Lorenz B\u00fchmann, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Databases",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2013_buehmann_base_enrichment/",
    "segmentation": [
        [
            "My name is Lawrence.",
            "I'm from the University of Leipzig and they're my PhD student at the HSW Group, and today I present joint work with my colleague and supervisor against Lemon.",
            "And I will talk about pattern based ontology or knowledge base enrichment.",
            "Anne."
        ],
        [
            "And here we have a short outline of my talk, so it's rather straightforward.",
            "So first of all, I will give some motivation for work and then I will propose an approach we developed or built in or work.",
            "And of course we run some experiments to show that our approach works.",
            "And finally, I will conclude my talk.",
            "And before I start with the talk, I have to say if I speak about ontology enrichment, I basically means that we want to enrich the existing schema based on instance data if available in the knowledge base.",
            "And starting with motivation."
        ],
        [
            "What we have so."
        ],
        [
            "'cause we have many knowledge base is known semantic web which are available and also used by users and tools.",
            "And but the problem is that many of the knowledge bases are still with order very sophisticated schema.",
            "And for example, in the life science domain we have knowledge bases which only consist of schema axioms and on the other hand we also have knowledge bases which are more or less more or less collection of facts only.",
            "And if we would.",
            "Buying both into one knowledge base and we could of course benefit from it because then we could do more powerful reasoning.",
            "We could also improve querying or use the schema information for debugging as well as data validation.",
            "And that's why we want to enrich knowledge basis."
        ],
        [
            "And here here we have an example for a knowledge base and entities.",
            "So suppose sorry we have the property birth place and we have some resources, for instance Angela Merkel, which is our German counselor.",
            "And also would put Albert Einstein or some other resources.",
            "And then we could, for instance, suggests that property birthplace has domain person and the range is always a place, and we could also maybe derives that birthplace is functional.",
            "That means there's only one birthplace for each person."
        ],
        [
            "And as I already said, if we have such schema exams, we could use this for reasoning.",
            "But schema axioms can also be seen as some kind of documentation.",
            "So how to use entities?",
            "Here we have two properties, author and writer, both contained in the DB Pedia ontology.",
            "And it might be not clear for a knowledge engineer which property to use and the deep knowledge base is the property.",
            "Also is mostly used for books, while the property writer is mostly used for film scripts.",
            "And as I already mentioned, we can also use the schema axioms for debugging."
        ],
        [
            "Here we have an example for an entity and the pedia.",
            "Her name is Arduino done and you can see here that several birthplace is declared and if we do not consider that we have here some part of Geo geographical part of modeling problems then we still have Shanghai and Sydney.",
            "As birthplace here below you can see the corresponding Wikipedia entry and here it's explained that she was born in Shanghai, but it's grown up in Sydney."
        ],
        [
            "So what we have is are we not done in the middle and then we have two birth places, Sydney and Shanghai and what we also know is that Shanghai and Sydney are obviously not the same entities in the knowledge base, so there is no I will say mess relationship until this point we cannot do anything so we wouldn't find.",
            "This, let's say data quality problem, but if we would have effects that property birthplace this functional, then we have an inconsistency in the knowledge base and we could easily."
        ],
        [
            "Check for example using this bucket query, but I have to say that's not totally correct.",
            "'cause if it would be totally correctly, you would have to check for our same as path."
        ],
        [
            "OK, so that's why we build an approach to learn schema axioms."
        ],
        [
            "And our approach is lightweight.",
            "It's Simi automatic.",
            "That means at the end user has to decide if the suggested axiom makes sense or not, and we're basically we're working on knowledge bases which are accessible via sparkle."
        ],
        [
            "And the approach basically consists of three steps.",
            "So if we start from a given knowledge base as well as the XM type and the entity.",
            "In the first step, which is an optional step, we could get existing information schema information from the knowledge base.",
            "So for example, we could get.",
            "Subtypes of hierarchy.",
            "If excess and in the second step we.",
            "Have to obtain data from the knowledge base which is necessary to learn the exome type for the entity.",
            "And finally, in the third step we can then run some machine learning algorithm so that we get some confidence value for the axiom suggestions.",
            "And of course we could iterate over the over the exome types and entities in the knowledge base."
        ],
        [
            "So again, an example.",
            "Let's use again DB pedia.",
            "And suppose we have the property author and we want to learn the domain."
        ],
        [
            "The first step is just here to get subclass of statements.",
            "By using this construct query above so we could get for instance, that Filosofa subclass of person or agent is our thing, which is of course trivial.",
            "And in the second step."
        ],
        [
            "But then we won't get to get data which is necessary to derive, so the domain of the property.",
            "That means, of course we want to get the types of the subjects.",
            "That's why we run this concept query above and then we could get for instance triplets you can see here.",
            "And yeah."
        ],
        [
            "Such steps and we want to get some evidence score for each possible excellent candidate.",
            "So basically here we have two classes which can be the domain of the property author that our book and written work, and the easiest form.",
            "We could just comment.",
            "So we have two times class books, so we would have two out of sweets.",
            "That means we have 6766%.",
            "Scoran for written work.",
            "We only have one out of three, so we have 33% as a problem is when we only use OK, no one more point.",
            "So in the first step we got subclass of information and if we could reuse is then we would get a higher score for written work 'cause we know that each book is also written work and so we would get score of 100%.",
            "But the problem is if we only use a simple.",
            "The way of counting and computing the score is that we do not take into account the support for the eczema knowledge base."
        ],
        [
            "So we have no difference between 303 or 1000.",
            "Out of 1000, all this P 100% score and that's why we use 95% confidence interval which we can compute efficiently using the word method and that would result in some different scores which are much lower than before."
        ],
        [
            "OK, until here we only cover the basic axioms like domain range and characteristics of properties.",
            "But the question is what about more complex axioms?",
            "So what about for instance with subclass of axioms, whereas a subclass or superclass is a complex class expression.",
            "The problem is obviously that infinite many possibilities.",
            "So."
        ],
        [
            "Yes, one example from medical domain so you can see here that the superclass of this subclass statement is.",
            "Conjunction of many class expressions."
        ],
        [
            "And here we have one example.",
            "Forms a gallon ontology.",
            "And here we can also see that might be possible that superclass or here's an equivalent classes nested class expression.",
            "And that's why we had the idea to analyze existing ontologies from existing repositories.",
            "To get axioms which are most frequently used."
        ],
        [
            "And we extended our basic approach with a separate preparation phase which you can see above.",
            "And starting from some, let's say collections of ontologies.",
            "Here scored repositories, we have to process each ontology and there and we process each axiom.",
            "So in the first step we normalize each axiom and that means we get a corresponding action pattern and then.",
            "In the end, we have for each excellent pattern the frequency.",
            "And as we are working on sparkle, accessible knowledge base is of course we have to transforms into a corresponding sparkle query, which is done in the second step.",
            "And this Parker queries can then be used for other basic approach here."
        ],
        [
            "Some comments with the extra normalization that's very informal here, so we rely on the structural equivalence definition of axioms, which is defined in the our two specification.",
            "And.",
            "For instance, if we have subclass axioms, we transform them by first or reordering of the class expressions in the sub and super class.",
            "And then we place the entities from left to right.",
            "So in this transformation or normalization ensures that we get from both extremes.",
            "Here's the same extreme pattern that a subclass of B and accessed some are, which is of Type C. Anne."
        ],
        [
            "And yeah, and it's only a small overview for the pattern transformation, so the basic idea for class expressions is that we transform them into triple patterns or set of triple patterns.",
            "So for name Class A, it's rather simple and just get a RDF type statement.",
            "That variable has to be of type A and for the negation we use filter not exist.",
            "Clause of Sparkly 11.",
            "And if we go back to our example from the normalization, we."
        ],
        [
            "We would get then.",
            "The the set of triple patterns here.",
            "So for a we get that X has to be of type A and it had.",
            "It has also to be of Type B and has to be one relationship for as a predicate R. Whereas the object has to be of type C. And here we have on the left hand side name class so we can then set run of the existing classes in our ontology as A and finally we could transform that into the spark query which you can see here.",
            "So we replace all other entities with variable.",
            "It's an group PRISM and also current frequency."
        ],
        [
            "OK, and as already mentioned, we run some experiments."
        ],
        [
            "V1 for the pattern detection part.",
            "We process three ontology repository's which are the tones repository which is.",
            "Yeah, provided by the University of Manchester then we process ontologies from the bio portal repository and also ontologies from the Oxford repository.",
            "And you can see that some of the methologies we could not process because there were some syntax errors or they were not accessible.",
            "And here are some information about the number of axioms and overall we processed 1400 ontologies approximately.",
            "And."
        ],
        [
            "Here you can see the top 50 in Tee box, excellent patterns and of course most.",
            "We can reuse.",
            "Pattern is a subclass of B pattern.",
            "But there are also some more complex.",
            "Sims like for instance here number 10 where we have some conjunctions or here we have some nested class expressions for the superclass."
        ],
        [
            "And what we also try to find out this in a very preliminary experiment, if the ranking is stable at one point, and here it seems to be, is that.",
            "Let's say 1300 ontologies ranking is more or less stable.",
            "But of course.",
            "We have to do it for more ontologies and further experiments."
        ],
        [
            "Yeah, and for the pattern application we applied a manual user studies, so we used DB pedia and we chose randomly 100 classes with at least five instances.",
            "And we provided two or three evaluators, Soto three colleagues of my working group.",
            "We provided at most 100 pattern and sensations which have a score above a threshold.",
            "Of I think it was oh point 6."
        ],
        [
            "And.",
            "As a result, you can see that.",
            "We've gotten over flights Copa value of 66%."
        ],
        [
            "OK, and we also did some special analysis."
        ],
        [
            "OK, and finally I can."
        ],
        [
            "With my talk.",
            "So we propose an approach which can detect frequently Exelon patterns.",
            "And we also can transform the patterns into sparkle queries.",
            "So finally, we are able to learn complexity books and artworks axioms on knowledge bases which are accessible via sparkle."
        ],
        [
            "And in future work we want to improve the scoring functions process more ontologies like the Entity 2 cloud.",
            "And also learn appropriate specialists for the axiom types, OK?"
        ],
        [
            "That's it, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is Lawrence.",
                    "label": 0
                },
                {
                    "sent": "I'm from the University of Leipzig and they're my PhD student at the HSW Group, and today I present joint work with my colleague and supervisor against Lemon.",
                    "label": 0
                },
                {
                    "sent": "And I will talk about pattern based ontology or knowledge base enrichment.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we have a short outline of my talk, so it's rather straightforward.",
                    "label": 0
                },
                {
                    "sent": "So first of all, I will give some motivation for work and then I will propose an approach we developed or built in or work.",
                    "label": 0
                },
                {
                    "sent": "And of course we run some experiments to show that our approach works.",
                    "label": 0
                },
                {
                    "sent": "And finally, I will conclude my talk.",
                    "label": 0
                },
                {
                    "sent": "And before I start with the talk, I have to say if I speak about ontology enrichment, I basically means that we want to enrich the existing schema based on instance data if available in the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "And starting with motivation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we have so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause we have many knowledge base is known semantic web which are available and also used by users and tools.",
                    "label": 0
                },
                {
                    "sent": "And but the problem is that many of the knowledge bases are still with order very sophisticated schema.",
                    "label": 1
                },
                {
                    "sent": "And for example, in the life science domain we have knowledge bases which only consist of schema axioms and on the other hand we also have knowledge bases which are more or less more or less collection of facts only.",
                    "label": 1
                },
                {
                    "sent": "And if we would.",
                    "label": 0
                },
                {
                    "sent": "Buying both into one knowledge base and we could of course benefit from it because then we could do more powerful reasoning.",
                    "label": 0
                },
                {
                    "sent": "We could also improve querying or use the schema information for debugging as well as data validation.",
                    "label": 0
                },
                {
                    "sent": "And that's why we want to enrich knowledge basis.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here here we have an example for a knowledge base and entities.",
                    "label": 0
                },
                {
                    "sent": "So suppose sorry we have the property birth place and we have some resources, for instance Angela Merkel, which is our German counselor.",
                    "label": 0
                },
                {
                    "sent": "And also would put Albert Einstein or some other resources.",
                    "label": 1
                },
                {
                    "sent": "And then we could, for instance, suggests that property birthplace has domain person and the range is always a place, and we could also maybe derives that birthplace is functional.",
                    "label": 1
                },
                {
                    "sent": "That means there's only one birthplace for each person.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And as I already said, if we have such schema exams, we could use this for reasoning.",
                    "label": 0
                },
                {
                    "sent": "But schema axioms can also be seen as some kind of documentation.",
                    "label": 0
                },
                {
                    "sent": "So how to use entities?",
                    "label": 0
                },
                {
                    "sent": "Here we have two properties, author and writer, both contained in the DB Pedia ontology.",
                    "label": 0
                },
                {
                    "sent": "And it might be not clear for a knowledge engineer which property to use and the deep knowledge base is the property.",
                    "label": 1
                },
                {
                    "sent": "Also is mostly used for books, while the property writer is mostly used for film scripts.",
                    "label": 1
                },
                {
                    "sent": "And as I already mentioned, we can also use the schema axioms for debugging.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we have an example for an entity and the pedia.",
                    "label": 0
                },
                {
                    "sent": "Her name is Arduino done and you can see here that several birthplace is declared and if we do not consider that we have here some part of Geo geographical part of modeling problems then we still have Shanghai and Sydney.",
                    "label": 0
                },
                {
                    "sent": "As birthplace here below you can see the corresponding Wikipedia entry and here it's explained that she was born in Shanghai, but it's grown up in Sydney.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we have is are we not done in the middle and then we have two birth places, Sydney and Shanghai and what we also know is that Shanghai and Sydney are obviously not the same entities in the knowledge base, so there is no I will say mess relationship until this point we cannot do anything so we wouldn't find.",
                    "label": 0
                },
                {
                    "sent": "This, let's say data quality problem, but if we would have effects that property birthplace this functional, then we have an inconsistency in the knowledge base and we could easily.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Check for example using this bucket query, but I have to say that's not totally correct.",
                    "label": 0
                },
                {
                    "sent": "'cause if it would be totally correctly, you would have to check for our same as path.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's why we build an approach to learn schema axioms.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our approach is lightweight.",
                    "label": 0
                },
                {
                    "sent": "It's Simi automatic.",
                    "label": 0
                },
                {
                    "sent": "That means at the end user has to decide if the suggested axiom makes sense or not, and we're basically we're working on knowledge bases which are accessible via sparkle.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the approach basically consists of three steps.",
                    "label": 0
                },
                {
                    "sent": "So if we start from a given knowledge base as well as the XM type and the entity.",
                    "label": 1
                },
                {
                    "sent": "In the first step, which is an optional step, we could get existing information schema information from the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So for example, we could get.",
                    "label": 0
                },
                {
                    "sent": "Subtypes of hierarchy.",
                    "label": 0
                },
                {
                    "sent": "If excess and in the second step we.",
                    "label": 0
                },
                {
                    "sent": "Have to obtain data from the knowledge base which is necessary to learn the exome type for the entity.",
                    "label": 0
                },
                {
                    "sent": "And finally, in the third step we can then run some machine learning algorithm so that we get some confidence value for the axiom suggestions.",
                    "label": 1
                },
                {
                    "sent": "And of course we could iterate over the over the exome types and entities in the knowledge base.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, an example.",
                    "label": 0
                },
                {
                    "sent": "Let's use again DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And suppose we have the property author and we want to learn the domain.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first step is just here to get subclass of statements.",
                    "label": 0
                },
                {
                    "sent": "By using this construct query above so we could get for instance, that Filosofa subclass of person or agent is our thing, which is of course trivial.",
                    "label": 0
                },
                {
                    "sent": "And in the second step.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then we won't get to get data which is necessary to derive, so the domain of the property.",
                    "label": 0
                },
                {
                    "sent": "That means, of course we want to get the types of the subjects.",
                    "label": 0
                },
                {
                    "sent": "That's why we run this concept query above and then we could get for instance triplets you can see here.",
                    "label": 0
                },
                {
                    "sent": "And yeah.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such steps and we want to get some evidence score for each possible excellent candidate.",
                    "label": 0
                },
                {
                    "sent": "So basically here we have two classes which can be the domain of the property author that our book and written work, and the easiest form.",
                    "label": 0
                },
                {
                    "sent": "We could just comment.",
                    "label": 0
                },
                {
                    "sent": "So we have two times class books, so we would have two out of sweets.",
                    "label": 0
                },
                {
                    "sent": "That means we have 6766%.",
                    "label": 0
                },
                {
                    "sent": "Scoran for written work.",
                    "label": 0
                },
                {
                    "sent": "We only have one out of three, so we have 33% as a problem is when we only use OK, no one more point.",
                    "label": 0
                },
                {
                    "sent": "So in the first step we got subclass of information and if we could reuse is then we would get a higher score for written work 'cause we know that each book is also written work and so we would get score of 100%.",
                    "label": 0
                },
                {
                    "sent": "But the problem is if we only use a simple.",
                    "label": 0
                },
                {
                    "sent": "The way of counting and computing the score is that we do not take into account the support for the eczema knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have no difference between 303 or 1000.",
                    "label": 0
                },
                {
                    "sent": "Out of 1000, all this P 100% score and that's why we use 95% confidence interval which we can compute efficiently using the word method and that would result in some different scores which are much lower than before.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, until here we only cover the basic axioms like domain range and characteristics of properties.",
                    "label": 0
                },
                {
                    "sent": "But the question is what about more complex axioms?",
                    "label": 0
                },
                {
                    "sent": "So what about for instance with subclass of axioms, whereas a subclass or superclass is a complex class expression.",
                    "label": 0
                },
                {
                    "sent": "The problem is obviously that infinite many possibilities.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, one example from medical domain so you can see here that the superclass of this subclass statement is.",
                    "label": 0
                },
                {
                    "sent": "Conjunction of many class expressions.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we have one example.",
                    "label": 0
                },
                {
                    "sent": "Forms a gallon ontology.",
                    "label": 0
                },
                {
                    "sent": "And here we can also see that might be possible that superclass or here's an equivalent classes nested class expression.",
                    "label": 0
                },
                {
                    "sent": "And that's why we had the idea to analyze existing ontologies from existing repositories.",
                    "label": 0
                },
                {
                    "sent": "To get axioms which are most frequently used.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we extended our basic approach with a separate preparation phase which you can see above.",
                    "label": 0
                },
                {
                    "sent": "And starting from some, let's say collections of ontologies.",
                    "label": 0
                },
                {
                    "sent": "Here scored repositories, we have to process each ontology and there and we process each axiom.",
                    "label": 0
                },
                {
                    "sent": "So in the first step we normalize each axiom and that means we get a corresponding action pattern and then.",
                    "label": 0
                },
                {
                    "sent": "In the end, we have for each excellent pattern the frequency.",
                    "label": 0
                },
                {
                    "sent": "And as we are working on sparkle, accessible knowledge base is of course we have to transforms into a corresponding sparkle query, which is done in the second step.",
                    "label": 0
                },
                {
                    "sent": "And this Parker queries can then be used for other basic approach here.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some comments with the extra normalization that's very informal here, so we rely on the structural equivalence definition of axioms, which is defined in the our two specification.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For instance, if we have subclass axioms, we transform them by first or reordering of the class expressions in the sub and super class.",
                    "label": 1
                },
                {
                    "sent": "And then we place the entities from left to right.",
                    "label": 0
                },
                {
                    "sent": "So in this transformation or normalization ensures that we get from both extremes.",
                    "label": 0
                },
                {
                    "sent": "Here's the same extreme pattern that a subclass of B and accessed some are, which is of Type C. Anne.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah, and it's only a small overview for the pattern transformation, so the basic idea for class expressions is that we transform them into triple patterns or set of triple patterns.",
                    "label": 0
                },
                {
                    "sent": "So for name Class A, it's rather simple and just get a RDF type statement.",
                    "label": 0
                },
                {
                    "sent": "That variable has to be of type A and for the negation we use filter not exist.",
                    "label": 0
                },
                {
                    "sent": "Clause of Sparkly 11.",
                    "label": 0
                },
                {
                    "sent": "And if we go back to our example from the normalization, we.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We would get then.",
                    "label": 0
                },
                {
                    "sent": "The the set of triple patterns here.",
                    "label": 0
                },
                {
                    "sent": "So for a we get that X has to be of type A and it had.",
                    "label": 0
                },
                {
                    "sent": "It has also to be of Type B and has to be one relationship for as a predicate R. Whereas the object has to be of type C. And here we have on the left hand side name class so we can then set run of the existing classes in our ontology as A and finally we could transform that into the spark query which you can see here.",
                    "label": 0
                },
                {
                    "sent": "So we replace all other entities with variable.",
                    "label": 0
                },
                {
                    "sent": "It's an group PRISM and also current frequency.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and as already mentioned, we run some experiments.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "V1 for the pattern detection part.",
                    "label": 1
                },
                {
                    "sent": "We process three ontology repository's which are the tones repository which is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, provided by the University of Manchester then we process ontologies from the bio portal repository and also ontologies from the Oxford repository.",
                    "label": 0
                },
                {
                    "sent": "And you can see that some of the methologies we could not process because there were some syntax errors or they were not accessible.",
                    "label": 0
                },
                {
                    "sent": "And here are some information about the number of axioms and overall we processed 1400 ontologies approximately.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you can see the top 50 in Tee box, excellent patterns and of course most.",
                    "label": 0
                },
                {
                    "sent": "We can reuse.",
                    "label": 0
                },
                {
                    "sent": "Pattern is a subclass of B pattern.",
                    "label": 0
                },
                {
                    "sent": "But there are also some more complex.",
                    "label": 0
                },
                {
                    "sent": "Sims like for instance here number 10 where we have some conjunctions or here we have some nested class expressions for the superclass.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we also try to find out this in a very preliminary experiment, if the ranking is stable at one point, and here it seems to be, is that.",
                    "label": 0
                },
                {
                    "sent": "Let's say 1300 ontologies ranking is more or less stable.",
                    "label": 0
                },
                {
                    "sent": "But of course.",
                    "label": 0
                },
                {
                    "sent": "We have to do it for more ontologies and further experiments.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, and for the pattern application we applied a manual user studies, so we used DB pedia and we chose randomly 100 classes with at least five instances.",
                    "label": 1
                },
                {
                    "sent": "And we provided two or three evaluators, Soto three colleagues of my working group.",
                    "label": 1
                },
                {
                    "sent": "We provided at most 100 pattern and sensations which have a score above a threshold.",
                    "label": 0
                },
                {
                    "sent": "Of I think it was oh point 6.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "As a result, you can see that.",
                    "label": 0
                },
                {
                    "sent": "We've gotten over flights Copa value of 66%.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and we also did some special analysis.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and finally I can.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With my talk.",
                    "label": 0
                },
                {
                    "sent": "So we propose an approach which can detect frequently Exelon patterns.",
                    "label": 1
                },
                {
                    "sent": "And we also can transform the patterns into sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "So finally, we are able to learn complexity books and artworks axioms on knowledge bases which are accessible via sparkle.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in future work we want to improve the scoring functions process more ontologies like the Entity 2 cloud.",
                    "label": 0
                },
                {
                    "sent": "And also learn appropriate specialists for the axiom types, OK?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}