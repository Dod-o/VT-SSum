{
    "id": "iqoek5ynh2ufxbppnlpnz32ls3nz3zjv",
    "title": "The Automatic Design of Feature Spaces for Local Image Descriptors using an Ensemble of Non-linear Feature Extractors",
    "info": {
        "author": [
            "Gustavo Carneiro, Institute for Systems and Robotics - Lisbon"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_carneiro_adfs/",
    "segmentation": [
        [
            "Thanks for the introduction.",
            "So I mean I'm stubborn.",
            "Narrow.",
            "So I'm presenting this work.",
            "So this is.",
            "I mean I'm studying this problem of finding good feature spaces for general matching problems, and I'm assuming that I don't know exactly what matching problem I have at the beginning, so I want to design automatically designing feature spaces for general matching problems and what is."
        ],
        [
            "So here is a rectangle representing the set of matching problems that you can have.",
            "For example, elements in the set should be wide baseline matching visual object recognition, visual class recognition.",
            "But there are many other elements in this set."
        ],
        [
            "So in the last 15 years or so, there's a lot of work on designing feature spaces that facilitate certain types of matching problems, and probably the most known feature spaces sift.",
            "And what I do, whatever presented here, is that safety safety can solve a subset of all the matching problems.",
            "The the big issue here is that we don't know exactly what matching problems, so we don't know the limits of this set of seat.",
            "And the same thing is for shape, context, hogs and all other features that have been proposed in the past 15 years or so.",
            "And you can also see that there are intersection between these sets."
        ],
        [
            "I mean, in the last couple of years there has been a shift kind of a paradigm shift where instead of starting with feature space is what it started with is the target matching problem.",
            "So for example, have a target matching problem and and you know that there are a lot of features that can work well, but you don't know exactly which ones will work better for this specific problem, so you know that's if can solve a subset of this problems, But we don't know exactly what subset SIFT can solve.",
            "Also, shape context also hog.",
            "So what you do is you build an optimization function that will combine all these features.",
            "The trouble here is that you have to retrain for each new target matching problem.",
            "You have to retrain the whole system and this is not exactly what I want to do.",
            "What I want to do is to have a feature space that can solve as much matching problems as you can.",
            "And then also a couple of years ago there was this."
        ],
        [
            "Paper by Hua Winder and Brown, which is was probably my main inspiration for this work.",
            "They also start with a matching problem and but what they do is that they have a collection of feature spaces with some parameters Theta, each one with its own set of parameters, and then what you do is you train this set of parameters to optimize in order to minimize the errors in this target matching problem.",
            "So you have feature transform one and then you find Theta star which gives the best results for this target matching problem and then have feature transform two with data.",
            "And then you find Theta star.",
            "So I mean this is a great work.",
            "It probably extends alot what what has happened, but the problem is that you still have the limitation of the feature transform.",
            "You don't know exactly what you can solve here.",
            "You can solve very well the target matching problem, but you don't know if it can solve much more than that.",
            "And that's what I'm interested in.",
            "So let's say you want to solve as."
        ],
        [
            "Any matching problems as you can in this set of matching problems and you don't want to retrain every time and then you don't want to commit to just one feature space as well.",
            "So what I do here is imagine that you have a bag of bag of target matching problems and every time you take one matching problem from this bag and solve a feature transform.",
            "And typically what you get is a feature form that is very specific for that target matching problem.",
            "Now, let's say you have a second matching problem from this bag and solve it, and then have a second feature transform and then you keep doing that.",
            "You know, keep solving and finding new feature transforms in.",
            "And after awhile you'll be solving a lot of this big matching problems and then you can solve a lot of you know your feature space will be will be covering a lot of this matching problems.",
            "So let's say you have a target matching problem, one which is unknown at the beginning.",
            "So what you do here is you use only the feature spaces that are good for solving this target matching problem one.",
            "And all the feature spaces that don't cover the target matching problem one should be forgotten.",
            "They shouldn't be used, so there is a trick in the algorithm that does that.",
            "And then you have another target matching problem that uses only the feature spaces inside this target matching problem, and then you forgot about.",
            "Forget about everything else.",
            "Of course, I mean if you train features specifically for solving each one of these target matching problems, you get better results than my algorithm, But this will provide very good results.",
            "You know very competitive as we will see.",
            "And that I."
        ],
        [
            "I called this the universal feature transform where solve random and simple matching problems.",
            "So the more matching problem solved, the easier it will be to solve new problems, and the restriction here is that problems that should be similar feature ranges.",
            "You know if you have a new matching problem, it should be the original feature space should be in similar ranges than the new matching problems.",
            "I mean what is solved and the new the new ones should be similar feature ranges and similar classes statistics in terms of separation between visual classes and.",
            "Variance in terms of within class?"
        ],
        [
            "So this work is rooted on distance metric learning, so this is just an overview.",
            "So let's say you have image patches or with features X axis.",
            "RNNY is just the label and then you want to find a linear transform, typically EMS less than N. And then you have the distance in the T space, which is this Mahalanobis distance where M is T * T transpose and M is positive semi definite.",
            "And what you do here is simply you try to maximize the distance between points from different classes and minimize the distance between points from the same class.",
            "So this leads to this minimization, which is very simple.",
            "You impose this constraint in order to have a unique solution, and then that if you solve the dual here, you get this generalized eigenvalue problem.",
            "So the extension of linear."
        ],
        [
            "This metric learning salonia is straightforward.",
            "You just rewrite SV&SW.",
            "And then by taking this by transforming T into X * U, then you have this matrix K representing XX transpose X and then now you want to find the matrix U.",
            "And then by solving exactly the same problem with just this trick, the kernel trick, then you arrive at this generalized eigenvalue problem and then I'll key that product can be replaced by kernel function.",
            "So in this work I didn't play too much with the kernel functions.",
            "But I mean this is for future work.",
            "I used only the Gaussian and that's it.",
            "And then finally the feature transform is very simple and this work is by Susie, and it's not.",
            "It's not my work, I just use his algorithm."
        ],
        [
            "OK, so it's very.",
            "It's much easier to see what's going on when you see this graph, so let's say you have this problem with three classes and then you have all this points here in the in this feature space.",
            "And they have of course the points inside the class, so if you learn a linear distance metric, learning with exactly the three classes, you will get a result that looks like this.",
            "It doesn't help much better see that there's some rotation scale and translation.",
            "But much more interesting is when you do the nonlinear distance metric learning.",
            "So what you see here is that points from the same class.",
            "They kind of collapse in the very small region and they are very far from each other, which is exactly the objective function you're solving.",
            "And the trick that I told before is this.",
            "Once they don't belong to any class, they are very likely to collapse at the origin, so that's what I mean when I said that if the if the feature space doesn't have the target matching problem, you shouldn't influence at all, and that's what I mean.",
            "So you just collapse the origin and that's it."
        ],
        [
            "So the intuition of the algorithm is this.",
            "So we train several feature transforms with random matching problems, and then you aggregate the distance by just summing the distance in each one of these spaces, and then you just do a threshold based classifier, which is if the distance is smaller than some threshold, there's two points belong to the same class."
        ],
        [
            "So here's a like a little animation about the intuition.",
            "So let's say you want to solve this unknown target problem on the top.",
            "And then you have the Randall training problem, one on the bottom, and then if you learn the nonlinear distance metric learning, you typically get something like this, which is very similar to what we saw before.",
            "And then you can see that out of the three classes of the unknown target matching problem, only one coincides with one of the classes in the random training problem.",
            "If you apply the same transformation while you typically get is the points from the red and green class will be at the origin and points of the blue class will be similar to the points of the purple class.",
            "No.",
            "And then if you aggregate the distance, that means there is only one space here.",
            "You see that we can separate really well the blue points, but we cannot separate the green and the red points.",
            "Let's take a second random."
        ],
        [
            "Training problem with these three classes and then you apply the transformation again.",
            "You get the same thing with the points collapsed and then you can see the unknown target matching problem.",
            "Only one of those classes go inside the red class.",
            "Go inside and then you have more or less the same story, so have points.",
            "Right at the origin and then other points there, red points coinciding with the red points up and down, and then when you aggregate the distances you apply the threshold based classifier.",
            "You get a perfect orosi with these two.",
            "Formations.",
            "So this is the main intuition of the algorithm."
        ],
        [
            "So I took this exactly this light example with three classes to have an unknown target matching problem, and then I learned 100 random 100 random feature spaces and then what you see here is.",
            "This black curve here, which is the most important one on the left.",
            "You see, this is the error at 2 positive at 90 ninety 95%.",
            "And then you can see that this error keeps decreasing with the feature space.",
            "With adding more feature spaces.",
            "And it doesn't matter the error individually in each of the feature spaces, so the error keeps decreasing while the error error in each of the feature spaces you know keeps going up and down.",
            "And the RC curve shows that the UFT provides a better result than the original.",
            "But it's not as good as if you actually trained for that specifically matching problem.",
            "So you see, in science is the training for the specific matching problem."
        ],
        [
            "So for the experiments they use the photo tourism data datasets where you see classes of visual patches.",
            "So I mean I don't do any processing except for contrast normalization and things like very simple and classes are 3D points that are projected and aligned.",
            "So this this class is here on the bottom represent the classes of the photo tourism.",
            "And then you have variations in single location, brightness and partial occlusion.",
            "For training I used all the Patch classes from trivia user data set and for testing I use the 50,000 matching and non matching from Notre Dam."
        ],
        [
            "OK, so using cross validation I arrived at this.",
            "This numbers which is 50 training classes for training each feature space, so each each random problem has 50 training classes.",
            "And then I have 50 training feature spaces, so I just basically some the distance in each one of these 50 training spaces and on the left you'll see that the error of the UFT is is much smaller compared to the Arab seat.",
            "In this, in this data set.",
            "And on the right you see again the same.",
            "Sorry that the error decreases with the number of feature spaces.",
            "So you see it read the error at 95% of 2 positive.",
            "And it doesn't matter.",
            "The area in each one of the feature spaces."
        ],
        [
            "OK, and finally I took this.",
            "This feature space learned with the Microsoft data set and apply that to the matching database of Nicholas, Nick and Schmidt, and from all the cases actually for all these eight sequences that we have the UFT UFT provide a much much better result than SIFT and Glo which are considered the state of the art for this case."
        ],
        [
            "OK, so in conclusion.",
            "This system provides a competitive performance.",
            "It's a simple and simple classifier which can be efficiently implemented, although I didn't.",
            "I didn't handle address this problem and it can adapt to new classification problems.",
            "So which means that there is no need for retraining every time we need.",
            "You want to solve a new target matching problem, thank you."
        ],
        [
            "So my question is, how do you expect this to scale in sort of high dimensions in the case given that?",
            "Taking random cuts presumably doesn't fill all possible directions in this space.",
            "So each one of the spaces has very small dimension dimensionality, so I mean you're doing this distance in each one of these spaces independently.",
            "So I mean it doesn't matter.",
            "I mean in terms of dimensions doesn't matter, OK, but that but that sort of ignores dependencies between dimensions in that case.",
            "OK, thanks the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks for the introduction.",
                    "label": 0
                },
                {
                    "sent": "So I mean I'm stubborn.",
                    "label": 0
                },
                {
                    "sent": "Narrow.",
                    "label": 0
                },
                {
                    "sent": "So I'm presenting this work.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "I mean I'm studying this problem of finding good feature spaces for general matching problems, and I'm assuming that I don't know exactly what matching problem I have at the beginning, so I want to design automatically designing feature spaces for general matching problems and what is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is a rectangle representing the set of matching problems that you can have.",
                    "label": 0
                },
                {
                    "sent": "For example, elements in the set should be wide baseline matching visual object recognition, visual class recognition.",
                    "label": 1
                },
                {
                    "sent": "But there are many other elements in this set.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the last 15 years or so, there's a lot of work on designing feature spaces that facilitate certain types of matching problems, and probably the most known feature spaces sift.",
                    "label": 1
                },
                {
                    "sent": "And what I do, whatever presented here, is that safety safety can solve a subset of all the matching problems.",
                    "label": 0
                },
                {
                    "sent": "The the big issue here is that we don't know exactly what matching problems, so we don't know the limits of this set of seat.",
                    "label": 1
                },
                {
                    "sent": "And the same thing is for shape, context, hogs and all other features that have been proposed in the past 15 years or so.",
                    "label": 0
                },
                {
                    "sent": "And you can also see that there are intersection between these sets.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean, in the last couple of years there has been a shift kind of a paradigm shift where instead of starting with feature space is what it started with is the target matching problem.",
                    "label": 0
                },
                {
                    "sent": "So for example, have a target matching problem and and you know that there are a lot of features that can work well, but you don't know exactly which ones will work better for this specific problem, so you know that's if can solve a subset of this problems, But we don't know exactly what subset SIFT can solve.",
                    "label": 0
                },
                {
                    "sent": "Also, shape context also hog.",
                    "label": 1
                },
                {
                    "sent": "So what you do is you build an optimization function that will combine all these features.",
                    "label": 0
                },
                {
                    "sent": "The trouble here is that you have to retrain for each new target matching problem.",
                    "label": 1
                },
                {
                    "sent": "You have to retrain the whole system and this is not exactly what I want to do.",
                    "label": 0
                },
                {
                    "sent": "What I want to do is to have a feature space that can solve as much matching problems as you can.",
                    "label": 0
                },
                {
                    "sent": "And then also a couple of years ago there was this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Paper by Hua Winder and Brown, which is was probably my main inspiration for this work.",
                    "label": 0
                },
                {
                    "sent": "They also start with a matching problem and but what they do is that they have a collection of feature spaces with some parameters Theta, each one with its own set of parameters, and then what you do is you train this set of parameters to optimize in order to minimize the errors in this target matching problem.",
                    "label": 0
                },
                {
                    "sent": "So you have feature transform one and then you find Theta star which gives the best results for this target matching problem and then have feature transform two with data.",
                    "label": 1
                },
                {
                    "sent": "And then you find Theta star.",
                    "label": 0
                },
                {
                    "sent": "So I mean this is a great work.",
                    "label": 1
                },
                {
                    "sent": "It probably extends alot what what has happened, but the problem is that you still have the limitation of the feature transform.",
                    "label": 0
                },
                {
                    "sent": "You don't know exactly what you can solve here.",
                    "label": 0
                },
                {
                    "sent": "You can solve very well the target matching problem, but you don't know if it can solve much more than that.",
                    "label": 0
                },
                {
                    "sent": "And that's what I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "So let's say you want to solve as.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Any matching problems as you can in this set of matching problems and you don't want to retrain every time and then you don't want to commit to just one feature space as well.",
                    "label": 1
                },
                {
                    "sent": "So what I do here is imagine that you have a bag of bag of target matching problems and every time you take one matching problem from this bag and solve a feature transform.",
                    "label": 0
                },
                {
                    "sent": "And typically what you get is a feature form that is very specific for that target matching problem.",
                    "label": 0
                },
                {
                    "sent": "Now, let's say you have a second matching problem from this bag and solve it, and then have a second feature transform and then you keep doing that.",
                    "label": 0
                },
                {
                    "sent": "You know, keep solving and finding new feature transforms in.",
                    "label": 0
                },
                {
                    "sent": "And after awhile you'll be solving a lot of this big matching problems and then you can solve a lot of you know your feature space will be will be covering a lot of this matching problems.",
                    "label": 0
                },
                {
                    "sent": "So let's say you have a target matching problem, one which is unknown at the beginning.",
                    "label": 0
                },
                {
                    "sent": "So what you do here is you use only the feature spaces that are good for solving this target matching problem one.",
                    "label": 0
                },
                {
                    "sent": "And all the feature spaces that don't cover the target matching problem one should be forgotten.",
                    "label": 0
                },
                {
                    "sent": "They shouldn't be used, so there is a trick in the algorithm that does that.",
                    "label": 0
                },
                {
                    "sent": "And then you have another target matching problem that uses only the feature spaces inside this target matching problem, and then you forgot about.",
                    "label": 1
                },
                {
                    "sent": "Forget about everything else.",
                    "label": 0
                },
                {
                    "sent": "Of course, I mean if you train features specifically for solving each one of these target matching problems, you get better results than my algorithm, But this will provide very good results.",
                    "label": 0
                },
                {
                    "sent": "You know very competitive as we will see.",
                    "label": 0
                },
                {
                    "sent": "And that I.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I called this the universal feature transform where solve random and simple matching problems.",
                    "label": 1
                },
                {
                    "sent": "So the more matching problem solved, the easier it will be to solve new problems, and the restriction here is that problems that should be similar feature ranges.",
                    "label": 1
                },
                {
                    "sent": "You know if you have a new matching problem, it should be the original feature space should be in similar ranges than the new matching problems.",
                    "label": 0
                },
                {
                    "sent": "I mean what is solved and the new the new ones should be similar feature ranges and similar classes statistics in terms of separation between visual classes and.",
                    "label": 0
                },
                {
                    "sent": "Variance in terms of within class?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this work is rooted on distance metric learning, so this is just an overview.",
                    "label": 1
                },
                {
                    "sent": "So let's say you have image patches or with features X axis.",
                    "label": 0
                },
                {
                    "sent": "RNNY is just the label and then you want to find a linear transform, typically EMS less than N. And then you have the distance in the T space, which is this Mahalanobis distance where M is T * T transpose and M is positive semi definite.",
                    "label": 0
                },
                {
                    "sent": "And what you do here is simply you try to maximize the distance between points from different classes and minimize the distance between points from the same class.",
                    "label": 0
                },
                {
                    "sent": "So this leads to this minimization, which is very simple.",
                    "label": 0
                },
                {
                    "sent": "You impose this constraint in order to have a unique solution, and then that if you solve the dual here, you get this generalized eigenvalue problem.",
                    "label": 0
                },
                {
                    "sent": "So the extension of linear.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This metric learning salonia is straightforward.",
                    "label": 1
                },
                {
                    "sent": "You just rewrite SV&SW.",
                    "label": 0
                },
                {
                    "sent": "And then by taking this by transforming T into X * U, then you have this matrix K representing XX transpose X and then now you want to find the matrix U.",
                    "label": 0
                },
                {
                    "sent": "And then by solving exactly the same problem with just this trick, the kernel trick, then you arrive at this generalized eigenvalue problem and then I'll key that product can be replaced by kernel function.",
                    "label": 1
                },
                {
                    "sent": "So in this work I didn't play too much with the kernel functions.",
                    "label": 0
                },
                {
                    "sent": "But I mean this is for future work.",
                    "label": 0
                },
                {
                    "sent": "I used only the Gaussian and that's it.",
                    "label": 0
                },
                {
                    "sent": "And then finally the feature transform is very simple and this work is by Susie, and it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not my work, I just use his algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's very.",
                    "label": 0
                },
                {
                    "sent": "It's much easier to see what's going on when you see this graph, so let's say you have this problem with three classes and then you have all this points here in the in this feature space.",
                    "label": 0
                },
                {
                    "sent": "And they have of course the points inside the class, so if you learn a linear distance metric, learning with exactly the three classes, you will get a result that looks like this.",
                    "label": 0
                },
                {
                    "sent": "It doesn't help much better see that there's some rotation scale and translation.",
                    "label": 0
                },
                {
                    "sent": "But much more interesting is when you do the nonlinear distance metric learning.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is that points from the same class.",
                    "label": 1
                },
                {
                    "sent": "They kind of collapse in the very small region and they are very far from each other, which is exactly the objective function you're solving.",
                    "label": 0
                },
                {
                    "sent": "And the trick that I told before is this.",
                    "label": 0
                },
                {
                    "sent": "Once they don't belong to any class, they are very likely to collapse at the origin, so that's what I mean when I said that if the if the feature space doesn't have the target matching problem, you shouldn't influence at all, and that's what I mean.",
                    "label": 0
                },
                {
                    "sent": "So you just collapse the origin and that's it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the intuition of the algorithm is this.",
                    "label": 0
                },
                {
                    "sent": "So we train several feature transforms with random matching problems, and then you aggregate the distance by just summing the distance in each one of these spaces, and then you just do a threshold based classifier, which is if the distance is smaller than some threshold, there's two points belong to the same class.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a like a little animation about the intuition.",
                    "label": 0
                },
                {
                    "sent": "So let's say you want to solve this unknown target problem on the top.",
                    "label": 1
                },
                {
                    "sent": "And then you have the Randall training problem, one on the bottom, and then if you learn the nonlinear distance metric learning, you typically get something like this, which is very similar to what we saw before.",
                    "label": 0
                },
                {
                    "sent": "And then you can see that out of the three classes of the unknown target matching problem, only one coincides with one of the classes in the random training problem.",
                    "label": 1
                },
                {
                    "sent": "If you apply the same transformation while you typically get is the points from the red and green class will be at the origin and points of the blue class will be similar to the points of the purple class.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "And then if you aggregate the distance, that means there is only one space here.",
                    "label": 0
                },
                {
                    "sent": "You see that we can separate really well the blue points, but we cannot separate the green and the red points.",
                    "label": 0
                },
                {
                    "sent": "Let's take a second random.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Training problem with these three classes and then you apply the transformation again.",
                    "label": 1
                },
                {
                    "sent": "You get the same thing with the points collapsed and then you can see the unknown target matching problem.",
                    "label": 0
                },
                {
                    "sent": "Only one of those classes go inside the red class.",
                    "label": 0
                },
                {
                    "sent": "Go inside and then you have more or less the same story, so have points.",
                    "label": 0
                },
                {
                    "sent": "Right at the origin and then other points there, red points coinciding with the red points up and down, and then when you aggregate the distances you apply the threshold based classifier.",
                    "label": 0
                },
                {
                    "sent": "You get a perfect orosi with these two.",
                    "label": 0
                },
                {
                    "sent": "Formations.",
                    "label": 0
                },
                {
                    "sent": "So this is the main intuition of the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I took this exactly this light example with three classes to have an unknown target matching problem, and then I learned 100 random 100 random feature spaces and then what you see here is.",
                    "label": 0
                },
                {
                    "sent": "This black curve here, which is the most important one on the left.",
                    "label": 0
                },
                {
                    "sent": "You see, this is the error at 2 positive at 90 ninety 95%.",
                    "label": 0
                },
                {
                    "sent": "And then you can see that this error keeps decreasing with the feature space.",
                    "label": 0
                },
                {
                    "sent": "With adding more feature spaces.",
                    "label": 0
                },
                {
                    "sent": "And it doesn't matter the error individually in each of the feature spaces, so the error keeps decreasing while the error error in each of the feature spaces you know keeps going up and down.",
                    "label": 1
                },
                {
                    "sent": "And the RC curve shows that the UFT provides a better result than the original.",
                    "label": 0
                },
                {
                    "sent": "But it's not as good as if you actually trained for that specifically matching problem.",
                    "label": 0
                },
                {
                    "sent": "So you see, in science is the training for the specific matching problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the experiments they use the photo tourism data datasets where you see classes of visual patches.",
                    "label": 0
                },
                {
                    "sent": "So I mean I don't do any processing except for contrast normalization and things like very simple and classes are 3D points that are projected and aligned.",
                    "label": 0
                },
                {
                    "sent": "So this this class is here on the bottom represent the classes of the photo tourism.",
                    "label": 0
                },
                {
                    "sent": "And then you have variations in single location, brightness and partial occlusion.",
                    "label": 1
                },
                {
                    "sent": "For training I used all the Patch classes from trivia user data set and for testing I use the 50,000 matching and non matching from Notre Dam.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so using cross validation I arrived at this.",
                    "label": 1
                },
                {
                    "sent": "This numbers which is 50 training classes for training each feature space, so each each random problem has 50 training classes.",
                    "label": 1
                },
                {
                    "sent": "And then I have 50 training feature spaces, so I just basically some the distance in each one of these 50 training spaces and on the left you'll see that the error of the UFT is is much smaller compared to the Arab seat.",
                    "label": 0
                },
                {
                    "sent": "In this, in this data set.",
                    "label": 0
                },
                {
                    "sent": "And on the right you see again the same.",
                    "label": 1
                },
                {
                    "sent": "Sorry that the error decreases with the number of feature spaces.",
                    "label": 1
                },
                {
                    "sent": "So you see it read the error at 95% of 2 positive.",
                    "label": 0
                },
                {
                    "sent": "And it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "The area in each one of the feature spaces.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and finally I took this.",
                    "label": 0
                },
                {
                    "sent": "This feature space learned with the Microsoft data set and apply that to the matching database of Nicholas, Nick and Schmidt, and from all the cases actually for all these eight sequences that we have the UFT UFT provide a much much better result than SIFT and Glo which are considered the state of the art for this case.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in conclusion.",
                    "label": 0
                },
                {
                    "sent": "This system provides a competitive performance.",
                    "label": 1
                },
                {
                    "sent": "It's a simple and simple classifier which can be efficiently implemented, although I didn't.",
                    "label": 1
                },
                {
                    "sent": "I didn't handle address this problem and it can adapt to new classification problems.",
                    "label": 1
                },
                {
                    "sent": "So which means that there is no need for retraining every time we need.",
                    "label": 0
                },
                {
                    "sent": "You want to solve a new target matching problem, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my question is, how do you expect this to scale in sort of high dimensions in the case given that?",
                    "label": 0
                },
                {
                    "sent": "Taking random cuts presumably doesn't fill all possible directions in this space.",
                    "label": 0
                },
                {
                    "sent": "So each one of the spaces has very small dimension dimensionality, so I mean you're doing this distance in each one of these spaces independently.",
                    "label": 0
                },
                {
                    "sent": "So I mean it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "I mean in terms of dimensions doesn't matter, OK, but that but that sort of ignores dependencies between dimensions in that case.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}