{
    "id": "xkdtf2ftvd3fbp6jjj2ychlmcvscfxdz",
    "title": "Integrated Network Construction Using Event Based Text Mining",
    "info": {
        "author": [
            "Yvan Saeys, Bioinformatics and Evolutionary Genomics Group, Ghent University"
        ],
        "published": "Oct. 5, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Text Mining"
        ]
    },
    "url": "http://videolectures.net/mlsb09_saeys_incu/",
    "segmentation": [
        [
            "Good morning everyone.",
            "So my name is Ivan size.",
            "I will give this presentation but I would like to let you know that most of the work has been done by my PhD students Sophie, but she's at the moment at the machine Learning Summer School in Cambridge doing probably more interesting things, so this talk will be on."
        ],
        [
            "Constructing integrated networks and I will focus on the text mining input of creating this type of integrated networks, integrated networks or kind of networks where you combine different types of interactions between the entities in a network and here well, I will present an approach where we do this based on text mining techniques, so the broad picture is that you start from some literature.",
            "Some articles, for example you download it from.",
            "Submit which is called the information retrieval step down in it.",
            "In the next step we are scanning these articles sentence by sentence and we're retrieving the entities that are of interest for us to construct or network, which is called the named entity recognition step.",
            "Then in the next step we put it in some kind of structure text and we try to extract information in.",
            "This work interactions between the entities, for example, the proteins that are mentioned in the sentences of the text.",
            "So in this talk I will focus only on this last part, the extraction of interactions from structured sentences.",
            "So."
        ],
        [
            "If you look at the history of text mining and systems biology, most of the work has been done on discovering protein protein interactions from text.",
            "So this started with very simple Co occurrence based approaches.",
            "For example, if two proteins that occur in the same sentence then these methods just assume that by occurring in the same sentence there is an interaction or a relation between these two proteins.",
            "Later on, there were a more advanced systems using, for example, handcrafted rules and later on also machine learning approaches where you represent the sentence by some more advanced data structure.",
            "For example, the dependency graph of your sentence, and then apply, for example graph kernels or other types of machine learning techniques to extract the interactions that are mentioned in these sentences.",
            "Now this has all been done mostly on protein protein interaction detection, but in the beginning of this year there was some kind of new stimulus in the field of natural language processing for biological or biomedical domains, which is called bio NLP, and this is called the binal P shared task.",
            "So this was more from the linguistic domain challenge post towards the whole community of detecting not only protein protein interactions, but more specific.",
            "And variety interactions between entities in in text, so this task.",
            "So these interactions are called events.",
            "An text mining and similar to the machine learning challenges.",
            "Here you are given some kind of training set and this case also validation set and participants had to come up with our best machine learning method to detect these different kinds of events from the text and then submit their results on the website.",
            "And then there were evaluated on some hidden.",
            "Test set an you got back the results and in the end all the results were compared and also the different methods were compared.",
            "So we will take advantage of these publicly available training and validation.",
            "Set.",
            "The test set is not yet publicly available.",
            "2.",
            "Develop some new methods for the construction of these integrated networks, so these."
        ],
        [
            "Shared task consists of three sub tasks.",
            "One was a mandatory task for all the participants which was core event extraction.",
            "So yet to extract from text these different kinds of interactions of event types.",
            "So for example there are six different event types for gene expression localization, transcription binding, protein catabolism and phosphorylation, and then three kind of regulation events, so positive regulation.",
            "A promotes B or enhances B negative regulation.",
            "A inhibits P. Some kind of this regulation effects between proteins and then some general regulation term.",
            "So what you have to do is from a certain sentence tag the different type of words that were pointing to this particular event.",
            "The second task, which we didn't participate in, was in finding some additional information that could enrich the event.",
            "For example, if you have some localization event, then additional talk task would have been to find the location to where the protein in this case could be localized.",
            "So for example, in this sentence, localization of beta catenin into the nucleus, the type to predict would be a localization event, the team.",
            "So the main protein involved in this.",
            "Would be better catenin and then the additional event or richemond step would be that it was transported to the nucleus.",
            "The last task which we do participate, it was the detection of negation and speculation in text.",
            "So negation for example thread did not interact with test two speculation.",
            "Others sometimes state.",
            "We hypothesize debt and then certain interaction.",
            "So these were additional.",
            "Thus it made it."
        ],
        [
            "A little bit more complex.",
            "So this is what the size of the data looks like, so we had 800 abstracts from for the training data.",
            "Then a development or validation set that the participants could use to validate their methods, and finally a test set of 260 abstracts what you see for all these different types of events that would have to be recognized by your machine learning technique was that most of them are regulation effects.",
            "So the T1 and T2.",
            "They point to the teams of the event.",
            "For example, if you look at phosphorylation, for example, it could be that is mentioned in a sense and in a sentence.",
            "Phosphorylation of protein, a blah blah blah.",
            "Then it would be only team one.",
            "But if it would be protein A phosphorylates protein B, then you would have two teams, so one the actor an one, the other protein that is acted upon.",
            "So these give quite an impression of these datasets."
        ],
        [
            "So the framework that we used to tackle this problem was some kind of parallel pipelines for each type of event to be detected.",
            "So we constructed a classifier for each different event that should have been recognized from the text that we merge these predictions.",
            "We do some consistency check on the output of the predictions and then we run deregulation pipelines because with the regulation, pipelines can be that there are some more complex formulations.",
            "Like for example, a hierarchical nested regulation, events of other events, but I will give an example later on.",
            "Then with these results of this first talk task, we then apply the speculation an negation rules to have the results for the work."
        ],
        [
            "3rd task, so for each of these events, we have a pipeline like this which first detects the important words in a sentence that points to a certain event.",
            "For example, if you have binding events, then the word binding would be an important triggers that could lead you to suspect that it will be a binding event.",
            "We extract candidate arguments for these trigger words.",
            "Then we go on to define some instances from the sentence.",
            "We extract features from it.",
            "We do the classification and we end up with.",
            "Predictions I will detail now.",
            "Each of these steps a bit more into detail, but I will first give you some example of how this looks like.",
            "So, for example, we have the sentence here.",
            "Multi Master nuclear localization signal P-65."
        ],
        [
            "And if it's P-65 DNA binding, so there are three proteins mentioned in this sentence MoD 3, the first one and then twice P-65.",
            "There are three trigger words that can be detected in this sentence, so these are words that point to some particular event.",
            "So triggered mask which points to a negative regulation event trigger words in a bit also to a negative regulation event and word binding which points to a binding event.",
            "Then there is one additional argument which could be used for the second task, like the nuclear localization signal.",
            "Some extra information about a certain event.",
            "So the 1st event which could be found in this sentence was that P-65 binds DNA.",
            "So in this case P-65 and binding is an important or important words to detect this event.",
            "The second event would be that MoD 3 inhibits another event, namely the 1st event.",
            "So this is an example of a hierarchical nested regulation events so.",
            "P-65 binds DNA is an event in itself and it is regulated.",
            "As an event by metric.",
            "And then the last event is this Mudry Matri masks be 65.",
            "So in this case, for this sentence, the prediction task would be to detect correctly all these different events or assign them to the correct category an all assign the correct teams for each event.",
            "And if you want some additional information like the nuclear."
        ],
        [
            "Localization signal, so how we gonna do this?",
            "We're using a dependency graph to model the internal structure of the sentence, so it's kind of a parsing of your sentence which associates the.",
            "Words of the sentence with their function in the sentence and then graphically displays structure or the connections between all the words in the sentence.",
            "So for example, the binding event one, so P-65 binds DNA would be kind of in this subtree of the dependency graph.",
            "The second event two would be the most recombined with this subtree.",
            "Here so much re inhibits and then.",
            "Event one and then the last event to be detected in this sentence would be that my three masks the nuclear localization signal P-65.",
            "So all this information is conveniently represented in this dependency graph.",
            "We will use them of this dependency graph to extract features from it that could be useful for."
        ],
        [
            "Classifier to detect all these types of events.",
            "Now of 1 very important step is of course to define these important words that can be linked to specific events which are called the trigger words.",
            "So we use a dictionary approach to find all these triggers events.",
            "So these were annotated in the training data.",
            "So we used just the training data to construct a Dictionary of all the words that could be linked to certain events.",
            "We stemmed all them using the Porter stemming algorithm.",
            "And then we filtered manually some words that are not very informative, like or fire or true.",
            "In our approach, we also for the binding events make a distinction between single binding and multiple binding.",
            "Then the most important step is to generate features."
        ],
        [
            "Um, this dependency graph, which can be used by the classifier.",
            "So we parse every sentence in the abstract with the Stanford dependency parser, and then we use for certain trigger that is mentioned.",
            "The small sub graph that spends the whole event, and from this small sub graph we extract some information.",
            "Some features from this dependency graph.",
            "First type of information are so called vertex works, so vertex work is a connection of a vertex and edge and a vertex in the dependency graph.",
            "We consider two variants of every such vertex walk in the dependency graph, the lexical variant, which just is stemmed version of the trigger and protein, which are then blinded to make it more general.",
            "So the trigger word then subject of the trigger and a certain protein is for example an example of such.",
            "Lexical friend and syntactic variant would be just announced the subject and then another noun.",
            "We also use some typical order text mining features like bag of words, representations, and in our case it was stemmed trigram.",
            "So consecutive patterns of three words that occur in these dependency graph, some lexical and some syntactic information about the trigger words, then some additional information on the subgraph spending defense.",
            "So the length of the sub sentence size of the subgraph and for regulation events we also record whether the arguments of the regulation.",
            "Or proteins themselves, or separate events.",
            "These or DC archical events that I explained you before, so we end up with for each event a separate classification problem with."
        ],
        [
            "A number of features.",
            "You see that if you look at the number of negative and positive instances in this training data set, that these datasets can be very imbalanced.",
            "So sometimes we end up with much more negative instances than positive instances, which is typical characteristic of these types of datasets.",
            "So."
        ],
        [
            "For the classification, we're just confronted with high dimensional an highly unbalanced datasets.",
            "We're going to parallel all to process all the events in parallel using binary classifiers.",
            "So either it is an event or it is not an event.",
            "We use support vector machines, standard Ricker lip SVM implementation, which uses a radial basis, kernel hideaway and internal 5 fold cross validation loop to tune the parameters of the SVM."
        ],
        [
            "So on the whole tasks task of this bio NLP challenge, we obtain the third position for detecting protein effects.",
            "The fourth position of detecting binding events and the fifth position of detecting regulation events.",
            "An overall.",
            "This resulted in a fifth position because regulation events, the ones that we scored worst on most present in these datasets.",
            "Now we did some additional recent experiments.",
            "Which were able to improve this 40.54 F measure to 44 already by just doing some some tuning in the pre processing of of the sentences.",
            "So which could be compareable to the previous two or three teams?",
            "Of course the best.",
            "Team for this.",
            "Task was the University of Turku which obtained even higher performance for this problem.",
            "They didn't participate in task three, and most of the first participants also did not participate in the task tree, so detecting negative negation and speculation events so for this task, we performed the second best.",
            "I didn't give any details on this, but this is just a simple rule based system.",
            "We also explored with the machine learning based system, but this did not perform so well.",
            "And by the way, I just would like to point you to the fact that the organizers of this talk of this task combined the top systems together in an ensemble way, and they were even able to improve further upon the best system by an overall 4% gain in F measure.",
            "So which shows?"
        ],
        [
            "Is that really?",
            "You can do some some more things by using some different kind of methods in a nice way, so the second part is on using the predictions of this first text mining step to."
        ],
        [
            "Strict integrated networks.",
            "So for each of these interactions, events like binding, phosphorylation, regulation events, we build a separate graph GY associated to a specific event type and these are graphs are kind of hit Rd genius graph Y because there can be multiple edges between two nodes in a graph because of multiple predictions, some of the edges may be directed and others may be underrated.",
            "For example, a regulates B is.",
            "A directed edge, but binding of CMD is.",
            "An undirected edge and we also weigh the edges according to the confidence associated with the SVM prediction.",
            "So each each graph can then be represented in a matrix form, where each entry in this matrix is a set of weighted connections between nodes."
        ],
        [
            "Say an note K in the network.",
            "And then we just create a tensor of all these graphs which just combines all defense together in its big hetrogenous graph, which just combines all the different types of interactions into a graph, which, as the dimensionality of M by N by N. So is the cardinality of the Union of all nodes over all these different event type graphs and is a number of events to to integrate.",
            "So in this tensor every entry.",
            "Presents a connection.",
            "Two from node Chaton OK for certain event type L. If you visualize this, we can see that.",
            "We here."
        ],
        [
            "And some subnetwork of the predicted output where every node represents a protein in this case and all the connections between the nodes represent the different interaction that have been found by the text mining system.",
            "For example, the black lines denote binding of or in specified regulation events.",
            "The Orange Arrows .2 phosphorylation events, the Blue Arrows to transcription events and then green and the red point to positive or negative regulation.",
            "Events from this network.",
            "You can then do some more inference and extract local patterns like for example."
        ],
        [
            "Protein that negatively negatively regulates another one that positively regulates another one which could lead you to postulate some more hypothesis about the regulation of pathways in this case."
        ],
        [
            "So some future work we have to do some work on improving the prediction performance of for these different types of events.",
            "We also now looking into the application of feature selection techniques because the datasets are quite high dimensional and I'm pretty sure that we can eliminate a lot of features of the dependency graph that represents redundant information so that we can have more robust classifiers.",
            "Maybe we're also planning on releasing some library.",
            "Of a Java based tools for biomedical text mining that can be used by other people to to process abstracts with of course also combining this.",
            "Output of the text mining with known datasets of protein, protein interactions, or forceful relation events, and also combining it with things that are other people in our group are doing creating module network and apply some inference algorithms to see if we can derive some potentially new biological knowledge.",
            "So thank you for your attention.",
            "That yeah.",
            "This one."
        ],
        [
            "So there is one inhibition event of mettrie masking nuclear localization signal.",
            "This one.",
            "What?",
            "Nope.",
            "No well.",
            "The second one is metri masks.",
            "Matri inhibits the binding of P-65 to DNA, which you could argue that.",
            "I'm sorry.",
            "Find.",
            "Within.",
            "What?",
            "It follows from the masking.",
            "I'm not a biologist, so I'm not sure if well.",
            "Anyway it was annotated like this by the biological experts who created the training status.",
            "Yeah it could be, but.",
            "Anyway, it might be useful to have both.",
            "Types of knowledge for your network now.",
            "Well, aren't these two different lights onto the same thing?",
            "That might give you some additional information.",
            "Well, we concur one from the other, but notes.",
            "Finding but then you would need probably additional biological knowledge to make that detection or not.",
            "While here you have it only from from the text, I would say.",
            "In this case there there tag just as proteins here.",
            "But unclear what they're saying.",
            "Yeah, but that's problem with ambiguity of biologists using gene names.",
            "I think, which is another problem, yes.",
            "The triggers in the sentences, so you have a trigger.",
            "For example, the word binds.",
            "You have some associated teams to it, and then you have to predict if that's a true binding event that occurs in this sentence.",
            "In the training set, yes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "So my name is Ivan size.",
                    "label": 0
                },
                {
                    "sent": "I will give this presentation but I would like to let you know that most of the work has been done by my PhD students Sophie, but she's at the moment at the machine Learning Summer School in Cambridge doing probably more interesting things, so this talk will be on.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Constructing integrated networks and I will focus on the text mining input of creating this type of integrated networks, integrated networks or kind of networks where you combine different types of interactions between the entities in a network and here well, I will present an approach where we do this based on text mining techniques, so the broad picture is that you start from some literature.",
                    "label": 0
                },
                {
                    "sent": "Some articles, for example you download it from.",
                    "label": 0
                },
                {
                    "sent": "Submit which is called the information retrieval step down in it.",
                    "label": 0
                },
                {
                    "sent": "In the next step we are scanning these articles sentence by sentence and we're retrieving the entities that are of interest for us to construct or network, which is called the named entity recognition step.",
                    "label": 0
                },
                {
                    "sent": "Then in the next step we put it in some kind of structure text and we try to extract information in.",
                    "label": 0
                },
                {
                    "sent": "This work interactions between the entities, for example, the proteins that are mentioned in the sentences of the text.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I will focus only on this last part, the extraction of interactions from structured sentences.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you look at the history of text mining and systems biology, most of the work has been done on discovering protein protein interactions from text.",
                    "label": 0
                },
                {
                    "sent": "So this started with very simple Co occurrence based approaches.",
                    "label": 1
                },
                {
                    "sent": "For example, if two proteins that occur in the same sentence then these methods just assume that by occurring in the same sentence there is an interaction or a relation between these two proteins.",
                    "label": 0
                },
                {
                    "sent": "Later on, there were a more advanced systems using, for example, handcrafted rules and later on also machine learning approaches where you represent the sentence by some more advanced data structure.",
                    "label": 0
                },
                {
                    "sent": "For example, the dependency graph of your sentence, and then apply, for example graph kernels or other types of machine learning techniques to extract the interactions that are mentioned in these sentences.",
                    "label": 0
                },
                {
                    "sent": "Now this has all been done mostly on protein protein interaction detection, but in the beginning of this year there was some kind of new stimulus in the field of natural language processing for biological or biomedical domains, which is called bio NLP, and this is called the binal P shared task.",
                    "label": 0
                },
                {
                    "sent": "So this was more from the linguistic domain challenge post towards the whole community of detecting not only protein protein interactions, but more specific.",
                    "label": 0
                },
                {
                    "sent": "And variety interactions between entities in in text, so this task.",
                    "label": 0
                },
                {
                    "sent": "So these interactions are called events.",
                    "label": 0
                },
                {
                    "sent": "An text mining and similar to the machine learning challenges.",
                    "label": 1
                },
                {
                    "sent": "Here you are given some kind of training set and this case also validation set and participants had to come up with our best machine learning method to detect these different kinds of events from the text and then submit their results on the website.",
                    "label": 0
                },
                {
                    "sent": "And then there were evaluated on some hidden.",
                    "label": 0
                },
                {
                    "sent": "Test set an you got back the results and in the end all the results were compared and also the different methods were compared.",
                    "label": 1
                },
                {
                    "sent": "So we will take advantage of these publicly available training and validation.",
                    "label": 1
                },
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "The test set is not yet publicly available.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Develop some new methods for the construction of these integrated networks, so these.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shared task consists of three sub tasks.",
                    "label": 1
                },
                {
                    "sent": "One was a mandatory task for all the participants which was core event extraction.",
                    "label": 1
                },
                {
                    "sent": "So yet to extract from text these different kinds of interactions of event types.",
                    "label": 0
                },
                {
                    "sent": "So for example there are six different event types for gene expression localization, transcription binding, protein catabolism and phosphorylation, and then three kind of regulation events, so positive regulation.",
                    "label": 1
                },
                {
                    "sent": "A promotes B or enhances B negative regulation.",
                    "label": 0
                },
                {
                    "sent": "A inhibits P. Some kind of this regulation effects between proteins and then some general regulation term.",
                    "label": 0
                },
                {
                    "sent": "So what you have to do is from a certain sentence tag the different type of words that were pointing to this particular event.",
                    "label": 0
                },
                {
                    "sent": "The second task, which we didn't participate in, was in finding some additional information that could enrich the event.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have some localization event, then additional talk task would have been to find the location to where the protein in this case could be localized.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this sentence, localization of beta catenin into the nucleus, the type to predict would be a localization event, the team.",
                    "label": 0
                },
                {
                    "sent": "So the main protein involved in this.",
                    "label": 0
                },
                {
                    "sent": "Would be better catenin and then the additional event or richemond step would be that it was transported to the nucleus.",
                    "label": 0
                },
                {
                    "sent": "The last task which we do participate, it was the detection of negation and speculation in text.",
                    "label": 1
                },
                {
                    "sent": "So negation for example thread did not interact with test two speculation.",
                    "label": 0
                },
                {
                    "sent": "Others sometimes state.",
                    "label": 0
                },
                {
                    "sent": "We hypothesize debt and then certain interaction.",
                    "label": 0
                },
                {
                    "sent": "So these were additional.",
                    "label": 0
                },
                {
                    "sent": "Thus it made it.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little bit more complex.",
                    "label": 0
                },
                {
                    "sent": "So this is what the size of the data looks like, so we had 800 abstracts from for the training data.",
                    "label": 0
                },
                {
                    "sent": "Then a development or validation set that the participants could use to validate their methods, and finally a test set of 260 abstracts what you see for all these different types of events that would have to be recognized by your machine learning technique was that most of them are regulation effects.",
                    "label": 0
                },
                {
                    "sent": "So the T1 and T2.",
                    "label": 0
                },
                {
                    "sent": "They point to the teams of the event.",
                    "label": 0
                },
                {
                    "sent": "For example, if you look at phosphorylation, for example, it could be that is mentioned in a sense and in a sentence.",
                    "label": 0
                },
                {
                    "sent": "Phosphorylation of protein, a blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "Then it would be only team one.",
                    "label": 0
                },
                {
                    "sent": "But if it would be protein A phosphorylates protein B, then you would have two teams, so one the actor an one, the other protein that is acted upon.",
                    "label": 0
                },
                {
                    "sent": "So these give quite an impression of these datasets.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the framework that we used to tackle this problem was some kind of parallel pipelines for each type of event to be detected.",
                    "label": 0
                },
                {
                    "sent": "So we constructed a classifier for each different event that should have been recognized from the text that we merge these predictions.",
                    "label": 0
                },
                {
                    "sent": "We do some consistency check on the output of the predictions and then we run deregulation pipelines because with the regulation, pipelines can be that there are some more complex formulations.",
                    "label": 0
                },
                {
                    "sent": "Like for example, a hierarchical nested regulation, events of other events, but I will give an example later on.",
                    "label": 0
                },
                {
                    "sent": "Then with these results of this first talk task, we then apply the speculation an negation rules to have the results for the work.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3rd task, so for each of these events, we have a pipeline like this which first detects the important words in a sentence that points to a certain event.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have binding events, then the word binding would be an important triggers that could lead you to suspect that it will be a binding event.",
                    "label": 0
                },
                {
                    "sent": "We extract candidate arguments for these trigger words.",
                    "label": 0
                },
                {
                    "sent": "Then we go on to define some instances from the sentence.",
                    "label": 0
                },
                {
                    "sent": "We extract features from it.",
                    "label": 0
                },
                {
                    "sent": "We do the classification and we end up with.",
                    "label": 0
                },
                {
                    "sent": "Predictions I will detail now.",
                    "label": 0
                },
                {
                    "sent": "Each of these steps a bit more into detail, but I will first give you some example of how this looks like.",
                    "label": 0
                },
                {
                    "sent": "So, for example, we have the sentence here.",
                    "label": 0
                },
                {
                    "sent": "Multi Master nuclear localization signal P-65.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if it's P-65 DNA binding, so there are three proteins mentioned in this sentence MoD 3, the first one and then twice P-65.",
                    "label": 1
                },
                {
                    "sent": "There are three trigger words that can be detected in this sentence, so these are words that point to some particular event.",
                    "label": 0
                },
                {
                    "sent": "So triggered mask which points to a negative regulation event trigger words in a bit also to a negative regulation event and word binding which points to a binding event.",
                    "label": 0
                },
                {
                    "sent": "Then there is one additional argument which could be used for the second task, like the nuclear localization signal.",
                    "label": 1
                },
                {
                    "sent": "Some extra information about a certain event.",
                    "label": 0
                },
                {
                    "sent": "So the 1st event which could be found in this sentence was that P-65 binds DNA.",
                    "label": 0
                },
                {
                    "sent": "So in this case P-65 and binding is an important or important words to detect this event.",
                    "label": 0
                },
                {
                    "sent": "The second event would be that MoD 3 inhibits another event, namely the 1st event.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of a hierarchical nested regulation events so.",
                    "label": 0
                },
                {
                    "sent": "P-65 binds DNA is an event in itself and it is regulated.",
                    "label": 0
                },
                {
                    "sent": "As an event by metric.",
                    "label": 0
                },
                {
                    "sent": "And then the last event is this Mudry Matri masks be 65.",
                    "label": 0
                },
                {
                    "sent": "So in this case, for this sentence, the prediction task would be to detect correctly all these different events or assign them to the correct category an all assign the correct teams for each event.",
                    "label": 0
                },
                {
                    "sent": "And if you want some additional information like the nuclear.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Localization signal, so how we gonna do this?",
                    "label": 0
                },
                {
                    "sent": "We're using a dependency graph to model the internal structure of the sentence, so it's kind of a parsing of your sentence which associates the.",
                    "label": 0
                },
                {
                    "sent": "Words of the sentence with their function in the sentence and then graphically displays structure or the connections between all the words in the sentence.",
                    "label": 0
                },
                {
                    "sent": "So for example, the binding event one, so P-65 binds DNA would be kind of in this subtree of the dependency graph.",
                    "label": 0
                },
                {
                    "sent": "The second event two would be the most recombined with this subtree.",
                    "label": 0
                },
                {
                    "sent": "Here so much re inhibits and then.",
                    "label": 0
                },
                {
                    "sent": "Event one and then the last event to be detected in this sentence would be that my three masks the nuclear localization signal P-65.",
                    "label": 1
                },
                {
                    "sent": "So all this information is conveniently represented in this dependency graph.",
                    "label": 0
                },
                {
                    "sent": "We will use them of this dependency graph to extract features from it that could be useful for.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Classifier to detect all these types of events.",
                    "label": 0
                },
                {
                    "sent": "Now of 1 very important step is of course to define these important words that can be linked to specific events which are called the trigger words.",
                    "label": 0
                },
                {
                    "sent": "So we use a dictionary approach to find all these triggers events.",
                    "label": 0
                },
                {
                    "sent": "So these were annotated in the training data.",
                    "label": 0
                },
                {
                    "sent": "So we used just the training data to construct a Dictionary of all the words that could be linked to certain events.",
                    "label": 1
                },
                {
                    "sent": "We stemmed all them using the Porter stemming algorithm.",
                    "label": 1
                },
                {
                    "sent": "And then we filtered manually some words that are not very informative, like or fire or true.",
                    "label": 1
                },
                {
                    "sent": "In our approach, we also for the binding events make a distinction between single binding and multiple binding.",
                    "label": 0
                },
                {
                    "sent": "Then the most important step is to generate features.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, this dependency graph, which can be used by the classifier.",
                    "label": 0
                },
                {
                    "sent": "So we parse every sentence in the abstract with the Stanford dependency parser, and then we use for certain trigger that is mentioned.",
                    "label": 0
                },
                {
                    "sent": "The small sub graph that spends the whole event, and from this small sub graph we extract some information.",
                    "label": 0
                },
                {
                    "sent": "Some features from this dependency graph.",
                    "label": 0
                },
                {
                    "sent": "First type of information are so called vertex works, so vertex work is a connection of a vertex and edge and a vertex in the dependency graph.",
                    "label": 0
                },
                {
                    "sent": "We consider two variants of every such vertex walk in the dependency graph, the lexical variant, which just is stemmed version of the trigger and protein, which are then blinded to make it more general.",
                    "label": 0
                },
                {
                    "sent": "So the trigger word then subject of the trigger and a certain protein is for example an example of such.",
                    "label": 1
                },
                {
                    "sent": "Lexical friend and syntactic variant would be just announced the subject and then another noun.",
                    "label": 1
                },
                {
                    "sent": "We also use some typical order text mining features like bag of words, representations, and in our case it was stemmed trigram.",
                    "label": 0
                },
                {
                    "sent": "So consecutive patterns of three words that occur in these dependency graph, some lexical and some syntactic information about the trigger words, then some additional information on the subgraph spending defense.",
                    "label": 0
                },
                {
                    "sent": "So the length of the sub sentence size of the subgraph and for regulation events we also record whether the arguments of the regulation.",
                    "label": 1
                },
                {
                    "sent": "Or proteins themselves, or separate events.",
                    "label": 0
                },
                {
                    "sent": "These or DC archical events that I explained you before, so we end up with for each event a separate classification problem with.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A number of features.",
                    "label": 0
                },
                {
                    "sent": "You see that if you look at the number of negative and positive instances in this training data set, that these datasets can be very imbalanced.",
                    "label": 0
                },
                {
                    "sent": "So sometimes we end up with much more negative instances than positive instances, which is typical characteristic of these types of datasets.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the classification, we're just confronted with high dimensional an highly unbalanced datasets.",
                    "label": 1
                },
                {
                    "sent": "We're going to parallel all to process all the events in parallel using binary classifiers.",
                    "label": 1
                },
                {
                    "sent": "So either it is an event or it is not an event.",
                    "label": 0
                },
                {
                    "sent": "We use support vector machines, standard Ricker lip SVM implementation, which uses a radial basis, kernel hideaway and internal 5 fold cross validation loop to tune the parameters of the SVM.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So on the whole tasks task of this bio NLP challenge, we obtain the third position for detecting protein effects.",
                    "label": 1
                },
                {
                    "sent": "The fourth position of detecting binding events and the fifth position of detecting regulation events.",
                    "label": 1
                },
                {
                    "sent": "An overall.",
                    "label": 0
                },
                {
                    "sent": "This resulted in a fifth position because regulation events, the ones that we scored worst on most present in these datasets.",
                    "label": 0
                },
                {
                    "sent": "Now we did some additional recent experiments.",
                    "label": 0
                },
                {
                    "sent": "Which were able to improve this 40.54 F measure to 44 already by just doing some some tuning in the pre processing of of the sentences.",
                    "label": 0
                },
                {
                    "sent": "So which could be compareable to the previous two or three teams?",
                    "label": 0
                },
                {
                    "sent": "Of course the best.",
                    "label": 0
                },
                {
                    "sent": "Team for this.",
                    "label": 0
                },
                {
                    "sent": "Task was the University of Turku which obtained even higher performance for this problem.",
                    "label": 0
                },
                {
                    "sent": "They didn't participate in task three, and most of the first participants also did not participate in the task tree, so detecting negative negation and speculation events so for this task, we performed the second best.",
                    "label": 0
                },
                {
                    "sent": "I didn't give any details on this, but this is just a simple rule based system.",
                    "label": 0
                },
                {
                    "sent": "We also explored with the machine learning based system, but this did not perform so well.",
                    "label": 0
                },
                {
                    "sent": "And by the way, I just would like to point you to the fact that the organizers of this talk of this task combined the top systems together in an ensemble way, and they were even able to improve further upon the best system by an overall 4% gain in F measure.",
                    "label": 0
                },
                {
                    "sent": "So which shows?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that really?",
                    "label": 0
                },
                {
                    "sent": "You can do some some more things by using some different kind of methods in a nice way, so the second part is on using the predictions of this first text mining step to.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Strict integrated networks.",
                    "label": 0
                },
                {
                    "sent": "So for each of these interactions, events like binding, phosphorylation, regulation events, we build a separate graph GY associated to a specific event type and these are graphs are kind of hit Rd genius graph Y because there can be multiple edges between two nodes in a graph because of multiple predictions, some of the edges may be directed and others may be underrated.",
                    "label": 1
                },
                {
                    "sent": "For example, a regulates B is.",
                    "label": 0
                },
                {
                    "sent": "A directed edge, but binding of CMD is.",
                    "label": 0
                },
                {
                    "sent": "An undirected edge and we also weigh the edges according to the confidence associated with the SVM prediction.",
                    "label": 0
                },
                {
                    "sent": "So each each graph can then be represented in a matrix form, where each entry in this matrix is a set of weighted connections between nodes.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Say an note K in the network.",
                    "label": 0
                },
                {
                    "sent": "And then we just create a tensor of all these graphs which just combines all defense together in its big hetrogenous graph, which just combines all the different types of interactions into a graph, which, as the dimensionality of M by N by N. So is the cardinality of the Union of all nodes over all these different event type graphs and is a number of events to to integrate.",
                    "label": 1
                },
                {
                    "sent": "So in this tensor every entry.",
                    "label": 0
                },
                {
                    "sent": "Presents a connection.",
                    "label": 0
                },
                {
                    "sent": "Two from node Chaton OK for certain event type L. If you visualize this, we can see that.",
                    "label": 0
                },
                {
                    "sent": "We here.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And some subnetwork of the predicted output where every node represents a protein in this case and all the connections between the nodes represent the different interaction that have been found by the text mining system.",
                    "label": 0
                },
                {
                    "sent": "For example, the black lines denote binding of or in specified regulation events.",
                    "label": 0
                },
                {
                    "sent": "The Orange Arrows .2 phosphorylation events, the Blue Arrows to transcription events and then green and the red point to positive or negative regulation.",
                    "label": 1
                },
                {
                    "sent": "Events from this network.",
                    "label": 0
                },
                {
                    "sent": "You can then do some more inference and extract local patterns like for example.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Protein that negatively negatively regulates another one that positively regulates another one which could lead you to postulate some more hypothesis about the regulation of pathways in this case.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some future work we have to do some work on improving the prediction performance of for these different types of events.",
                    "label": 1
                },
                {
                    "sent": "We also now looking into the application of feature selection techniques because the datasets are quite high dimensional and I'm pretty sure that we can eliminate a lot of features of the dependency graph that represents redundant information so that we can have more robust classifiers.",
                    "label": 1
                },
                {
                    "sent": "Maybe we're also planning on releasing some library.",
                    "label": 0
                },
                {
                    "sent": "Of a Java based tools for biomedical text mining that can be used by other people to to process abstracts with of course also combining this.",
                    "label": 1
                },
                {
                    "sent": "Output of the text mining with known datasets of protein, protein interactions, or forceful relation events, and also combining it with things that are other people in our group are doing creating module network and apply some inference algorithms to see if we can derive some potentially new biological knowledge.",
                    "label": 0
                },
                {
                    "sent": "So thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "That yeah.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is one inhibition event of mettrie masking nuclear localization signal.",
                    "label": 1
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Nope.",
                    "label": 0
                },
                {
                    "sent": "No well.",
                    "label": 0
                },
                {
                    "sent": "The second one is metri masks.",
                    "label": 1
                },
                {
                    "sent": "Matri inhibits the binding of P-65 to DNA, which you could argue that.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Find.",
                    "label": 0
                },
                {
                    "sent": "Within.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "It follows from the masking.",
                    "label": 0
                },
                {
                    "sent": "I'm not a biologist, so I'm not sure if well.",
                    "label": 0
                },
                {
                    "sent": "Anyway it was annotated like this by the biological experts who created the training status.",
                    "label": 0
                },
                {
                    "sent": "Yeah it could be, but.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it might be useful to have both.",
                    "label": 0
                },
                {
                    "sent": "Types of knowledge for your network now.",
                    "label": 0
                },
                {
                    "sent": "Well, aren't these two different lights onto the same thing?",
                    "label": 0
                },
                {
                    "sent": "That might give you some additional information.",
                    "label": 0
                },
                {
                    "sent": "Well, we concur one from the other, but notes.",
                    "label": 0
                },
                {
                    "sent": "Finding but then you would need probably additional biological knowledge to make that detection or not.",
                    "label": 0
                },
                {
                    "sent": "While here you have it only from from the text, I would say.",
                    "label": 0
                },
                {
                    "sent": "In this case there there tag just as proteins here.",
                    "label": 0
                },
                {
                    "sent": "But unclear what they're saying.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but that's problem with ambiguity of biologists using gene names.",
                    "label": 0
                },
                {
                    "sent": "I think, which is another problem, yes.",
                    "label": 0
                },
                {
                    "sent": "The triggers in the sentences, so you have a trigger.",
                    "label": 0
                },
                {
                    "sent": "For example, the word binds.",
                    "label": 0
                },
                {
                    "sent": "You have some associated teams to it, and then you have to predict if that's a true binding event that occurs in this sentence.",
                    "label": 0
                },
                {
                    "sent": "In the training set, yes.",
                    "label": 0
                }
            ]
        }
    }
}