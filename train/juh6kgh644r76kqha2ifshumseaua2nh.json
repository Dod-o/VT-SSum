{
    "id": "juh6kgh644r76kqha2ifshumseaua2nh",
    "title": "Adaptive Mesh Compression in 3D Computer Graphics using Multiscale Manifold Learning",
    "info": {
        "author": [
            "Sridhar Mahadevan, University of Massachusetts Amherst"
        ],
        "published": "June 23, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Computer Graphics"
        ]
    },
    "url": "http://videolectures.net/icml07_mahadevan_amc/",
    "segmentation": [
        [
            "Everybody knows JPEG.",
            "It's a type of four year analysis on images."
        ],
        [
            "And it assumes a fixed 2D topology, so we really can't use it in 3D.",
            "And but given the widespread importance of 3D, there's really an the fact that 3D images and 3D objects are very large.",
            "You want some sort of compression method, and there's a lot of interest in this in the computer graphics community.",
            "So what I'm going to show you is one of the solutions that was developed in computer graphics and I'm going to compare it with another approach that I."
        ],
        [
            "I've been working on.",
            "So let's first familiarize ourselves with what we mean by 3D objects.",
            "So a 3D object essentially is specified by generally two components, so you have an object here.",
            "This is a pretty small object.",
            "You can model this as a graph and this is the adjacency matrix of the graph, so the topology of the object.",
            "And it's geometry by its geometry, I mean you can think of the XYZ coordinates functions on the graph.",
            "So essentially I'm plotting here.",
            "Each of these coordinate functions on the graph.",
            "So the problem of three decompression is essentially to find.",
            "And you set of coordinate representations that you can use the projective geometry on the take up far less space than the original representation.",
            "Now there are two approaches to solve this problem.",
            "One approach is to essentially ignore topology and just focus on geometry, so you can just take these coordinate functions and then use your favorite compression method.",
            "But there's been a growing movement in computer graphics to see whether you can actually do something with topology and derive adaptive compression methods that build that are specific to each object."
        ],
        [
            "So as you go to larger objects, you can notice the size of the object keeping on growing and so."
        ],
        [
            "And.",
            "Even this is not a particularly large object, so you this is.",
            "This is a very challenging problem because you can objects with millions of vertices and so you want to fast compression method."
        ],
        [
            "So the method I want to start talking about first is 1 that was introduced by Carney and Gottesman from Israel in SIGGRAPH 2000.",
            "The idea is very simple.",
            "You take the topology of the object, it's a graph, you generate the eigenvectors at the graphic policy and and then you project the coordinate functions on the first few eigenvectors of the graph Laplacian.",
            "This is essentially four year analysis extended to graphs so.",
            "Let's first review this method and then let's see what the limitations of this method are before it."
        ],
        [
            "Using a different method.",
            "So we've seen that the graph Laplacian has been used in many contexts and machine learning actually was first studied on the mid 70s by Fiedler, who was a check mathematician to be news for spectral clustering, lots of work and semi supervised learning in this conference.",
            "And some work that you might not be familiar with.",
            "We've been exploring the use of the Laplacian for approximating functions called value functions and Markov decision."
        ],
        [
            "ISIS.",
            "Search introduces Buffalo classy and let's think of our differential representation of a coordinate functions rather than represent each function.",
            "Exactly what we're going to do is we're going to look at the difference between the value of the function at some coordinate at some vertex X minus the average of the values that you would get by taking the neighbors and computing sort of the average.",
            "So your DX is the degree of vertex X, so you can represent this effect in matrix form using this, and this is one form of the Laplacian.",
            "This is called discrete Laplacian.",
            "Um and."
        ],
        [
            "So.",
            "There's a strong connection between the discrete Laplacian and random walks, so if I take any weighted graph undirected graph, then the random walk is just the probability of visiting any neighbor with probability proportional to 1 by degree of the vertex.",
            "The two kinds of Laplacian you might be familiar with other combinatorial Laplacian that was mentioned in the first talk and the normalized Laplacian, and we can easily show that the normalized Laplacian has spectral structure.",
            "Very closely related to the random walk matrix, and that's a fairly easy identity show.",
            "So.",
            "This is classical Fourier analysis on graphs and let's see how it works on this problem.",
            "Before we look at what limitation."
        ],
        [
            "It has.",
            "So first let's look at like in vectors, losian on 3D objects.",
            "Here are some low order eigenvectors on this cow head.",
            "Here's the higher order eigenvectors.",
            "The two things are known.",
            "One is generally the supported eigenvectors, the whole object.",
            "So these basis functions are global.",
            "They're not local.",
            "This is actually going to be a problem, and second, you see that higher order eigenvectors generally start illuminating high frequency regions, and so as you look at the eigenvectors from lower to higher order, you will see that they essentially have more variation and.",
            "They get less smooth."
        ],
        [
            "So the process is very simple.",
            "You take your target function you projected on the first few eigenvectors of the Laplacian.",
            "If you're doing linearly squares.",
            "If you're doing nonlinear least squares, you can select the eigenvectors out of order.",
            "And this is standard for your least squares projection, so here's an example of a pig, and here's a reconstruction with 100 basis functions.",
            "An here's with 800 basis functions.",
            "There's been a lot of follow on work about with this approach in computer graphics, where people have applied this to do things like spectral Warren watermarking and various other things, there are some variants of this approach that I won't talk about."
        ],
        [
            "One of the limitations of this approach, the limitations of this approach primarily have to do with the limitations of Fourier analysis.",
            "So one of the problems we're doing eigenvector approximations of these coordinate functions is that when you have functions that have very varying degree of smoothness, it's very hard to get them right.",
            "So here you have the horns of the cow, which are very sharp, and you also have very smooth regions, and you're trying to get large eigenvectors to correspond to.",
            "Approximate these sort of very sharp regions while retaining Fidelity in the very smooth regions, and So what happens is while you're trying to correct these high frequency eigenvectors, you set up a lot of noise over here.",
            "This is a standard problem with four year basis.",
            "If you truncated, you essentially chop off the horns of the column so it doesn't look very good.",
            "So this problem was notice McCartney and got some men and they didn't suggest a solution, which is what we're going to do."
        ],
        [
            "So we're going to look at wavelet analysis and graphs.",
            "I assume many of you are familiar with standard wavelet analysis.",
            "This was motivated largely to address the problems of four year basis.",
            "They've been extensively explored in Euclidean space.",
            "Is the key idea of wavelets?",
            "Is this notion of dilation.",
            "You start with the what's usually called the mother wavelet, which is usually one simple example is a hard wavelet, and then you dilate the mother wavelet to produce wavelets at multiple scales and it's intrinsically a multiresolution analysis.",
            "We're interested in doing this on graphs.",
            "This has been done very recently by a group at Yale Koifman.",
            "Raffi Kaufman's growth and I've been working with Maggioni on extensions of this approach, and, of course, applying it to things like Markov decision processes and semi supervised learning.",
            "So there are many advantages off graph based wavelets and I won't be able to get into some of the more interesting aspects of it.",
            "One really interesting aspect of it is that it gives you a very fast way of computing the Greens function.",
            "So if you look at semi supervised learning, one of the ways of doing semi supervised learning is to invert the Laplacian on the unlabeled examples and this is generally considered to be a cubic operation, but actually you can do it considerably faster for diffusion matrices with the.",
            "With diffusion wavelets and I don't have time to explain that, but that's if you're interested in semi supervised learning.",
            "This is actually a."
        ],
        [
            "A nice way to go.",
            "So here is a simple way to understand what diffusion wavelets give you.",
            "We can do dilation in time or space on graph, so we have to come up with some other idea.",
            "So let's start with unit vectors.",
            "These are going to be our our finest vector space.",
            "We can represent any function exactly on this vector space, so I'm showing this for a simple mesh graph here.",
            "So we start with a system of unit vectors and now we're going to dilate these vectors.",
            "How are we going to direct these vectors?",
            "We take our random walk diffusion matrix and we're going to take powers of this random walk diffusion matrix.",
            "So intuitively, you can think of it is starting in a vertex and doing progressively longer random walks.",
            "So in the first step of random walk you can visit any of the neighboring vertex vertice is so essentially you can think of this unit vector dilating proportional to the local degree of the graph at that vertex.",
            "So you start with the collection of unit vectors.",
            "These will get dilated, and now you do a gram Schmidt authorization to get back what you would call scaling functions.",
            "Now you lost some resolution in going from this representation, but this representation.",
            "So you can try to recover that by constructing a set of basis functions that are orthogonal to the set of basis functions you get here.",
            "This will be a wavelets so you can do this at at multiple scales, and what I'm showing here is a dyadic powers the powers of two of your diffusion matrix, so this is 2, four, 816 and 32.",
            "One of the nice things that you get with this is you start with the unit vectors and you converge to the eigenvectors of the Laplacian so the highest level you essentially have the eigenvectors Laplacian.",
            "The lowest level you have the unit vectors.",
            "And at scales in between, you have basis functions which progressively have larger and larger supports.",
            "And because the basis functions are on the graph they support they.",
            "They follow the manifold and so for example in this case we have actually the meshes.",
            "There's a bottleneck between these two regions of the meshes, only one edge in between, so you see that these basis functions are defined on either the first sub graph or the second sub graph.",
            "Now this is a very general representation.",
            "You can do anything with this.",
            "You can do any kind of semi supervised learning regression on graphs and we're going to use this for compressing 3D objects."
        ],
        [
            "So the details of the construction are in the paper.",
            "Essentially use their two main steps.",
            "There's a downsampling step where you start with basis function that some resolution and you throw away those that you don't need to capture the resolution interest in.",
            "Typically the input to this construction is a graph.",
            "Anna specified resolution that you're interested in capturing, and at every step you're doing dilation.",
            "Using this process I just mentioned, which you can think of as trying to represent.",
            "Dyadic powers of the diffusion matrix using basis functions that are constructed at each level, so in this case you start by representing the original diffusion matrix using basis functions that you start with both in the domain and the range.",
            "So this is the notation that we use for that.",
            "Then you're trying to represent the basis functions teeth.",
            "The second part of the diffusion matrix, chi squared, using new basis functions that you got from the first level by throwing away the ones we didn't need, and so on and so forth."
        ],
        [
            "So, um.",
            "These basis functions look very interesting on 3D objects, So what you notice is basis functions that are at the top of the tree look like eigenvectors.",
            "They have global support basis functions, lower and lower levels have much much lower support.",
            "The much more local, and if you look at some of the levels you actually see that it."
        ],
        [
            "Exxon very interesting features.",
            "So here are basis functions.",
            "At Level 5 you see one that corresponds to a horn and I.",
            "The cheek, the year and the neck.",
            "So these basis functions seem to be picking out interesting geometric features of the object because of the localized properties of the graph at this."
        ],
        [
            "Asians?",
            "So now you can do it.",
            "Essentially the same approach using these basis functions and you solve the problem that we had before where you do a much better job of approximating the horns of the cow.",
            "So what are the challenges in extending this approach to large objects?",
            "The problem is again dealing with very very large graphs so.",
            "One approach which actually."
        ],
        [
            "Indian Gossman studied in that paper is simply to use graph partitioning.",
            "So you can use any favorite graph partitioning method, for example medicine, which takes an original graph and constructs a series of smaller graphs partitions the smaller graphs and then UN portions the smaller graphs to get back the original partition, and so the colors you show the graph partitions.",
            "You can then form local basis functions on each partition and you can approximate each other coordinate functions on each partition.",
            "There is some error you introduce, so there's a tradeoff here between the level at which you partition.",
            "And the overall speed of the of the algorithm.",
            "And there are some results in the paper that that show these tradeoffs here."
        ],
        [
            "So here are some examples.",
            "Here's an elephant.",
            "This is about 20,000 verticies.",
            "What I'm showing here on the Y axis is a combination of two terms.",
            "One is the geometric error, so you can take the literal object, exact coordinate functions and you can measure the error between that and your approximation.",
            "Unfortunately, that error alone is somewhat misleading because you can have a very choppy reconstruction that doesn't look very nice.",
            "So to avoid that.",
            "There's another term which Carney and got some introduce which is the Laplacian enter.",
            "This is exactly the difference, the differential representation I showed you earlier, which is the difference between the average of the neighboring verticies, coordinate functions and the value that you actually compute.",
            "So the sum of these two is 1 simple way to compute the error and the horizontal axis is measuring the number of basis functions you use.",
            "So this object was for example divided by 300 partitions.",
            "So the red curve is the Laplacian basis and the blue curve is the performance of the diffusion of basis."
        ],
        [
            "So when you go to objects that are somewhat smooth, you see the less of a difference between these two, understandably, because if you have a very smooth object for your methods, do reasonably well.",
            "This is about 34,000 verticies.",
            "Um?"
        ],
        [
            "And as I mentioned, if you explore the error that you get was partition size, you notice that as you partition the object into finer and finer regions and do local approximation, you are introducing error and that's because all the edges that cross between partitions you're going to get introduced some error basis functions now or computer only on each sub graph.",
            "So you've lost track of the overall geometry of the object in the topology of the object.",
            "So this is.",
            "And I don't know why double compromise, but you've gained a lot in terms of the running time, so this is something that you would have to sort of choose as a compromise between you know the Fidelity of the reconstruction you want and how fast you want your method to run."
        ],
        [
            "So, um.",
            "What I've shown you is a way of doing compression of 3D objects.",
            "It's adaptive that means the basis functions are computed with respect to the individual objects.",
            "The new approach here uses a type of analysis on graphs that builds on the theory of wavelets.",
            "It differs from eigenvectors in that basis functions are local and analysis is multi resolution.",
            "Um?",
            "And for objects that are have degree varying degrees of smoothness, you can show that the performance is quite a bit better.",
            "No, there's a bunch of extensions that that I've been working on.",
            "One of the extensions has to do with.",
            "Trying to improve the performance of the Laplacian basis by including other information.",
            "So, for example, supposing you take the Laplacian basis and allow.",
            "Use of jump geometrical information because you know the functions that you're trying to approximate.",
            "It turns out that you can improve their performance considerably by doing this.",
            "So one strategy has been studied to some extent in graphics users, properties of two manifolds.",
            "These are essentially two manifolds, and there's a way of setting the weights of the Laplacian base of two manifolds called cotangent basis, and that actually improves the performance of Laplacian basis quite a bit because you still have the problem that these basis functions are going to be global and they're not multi scale.",
            "The the diffusion wavelet construction needs considerable time for very large graphs, and most of it has not been actually not.",
            "There's not as much intensive study of this As for example, there has been of eigen solvers, so a lot of this code runs in Matlab.",
            "It's not very fast for the problems I'm showing you, there's not a huge difference, but for very large graphs you would need to have faster methods and there are faster methods that have been.",
            "Designed, but they haven't really been implemented yet.",
            "There are many other graphics applications that can benefit from this.",
            "One example is when you're trying to.",
            "Render objects that are translucent where some light passes through the object.",
            "Some light gets reflected.",
            "The way this is dealt with in graphics is to store matrices at every every vertex and sort of simple coordinate functions.",
            "You actually have an entire set of matrices.",
            "And there's some interesting ways of extending this to doing compression of matrices and graphs that I can talk about.",
            "Um, finally let me just end with a very short demo to show you what it looks like.",
            "So what I'm showing here is the.",
            "Compression of this of the skull head first starting with the Laplacian for larger and larger number of bases and what you can see here is the similar.",
            "Run on the diffusion wavelet and if you put these two things side by side.",
            "You can pick out the differences fairly easily in terms of, for example, the sharpness of the horns and the rendition of the year, the eyes, and so on and so forth.",
            "OK, let me stop there, thank you.",
            "When?",
            "Is it possible to restrict graph to certain class of graphs?",
            "Easier to develop more efficient algorithm, so I'm looking at your presentation, I'm wondering.",
            "What are the restrictions on those graphs?",
            "That represent this teenager can be used.",
            "Yeah, that's a good question, so so.",
            "One thing you can try to do is take advantage of the fact that a lot of these graphs are, for example, triangulated meshes, and so you know that their degree is specified an.",
            "So I mentioned this notion of cotangent bases actually takes advantage of that property.",
            "So I.",
            "The other thing people have tried is to embed these triangulated meshes in.",
            "In meshes of fixed topology, so one of the problems here that I didn't talk about is it's a very natural question is OK, so I generated basis for compressing this cow.",
            "But then you give me another shape.",
            "Now I'm going to generate new basis for that.",
            "So there is an additional overhead now that you have to generate these basis functions for every new object, and so one might wonder why is this some sort of transfer learning you can do where I generate the basis for one object and then somehow I can reuse these bases for some other object.",
            "So one approach that's been studied is to take these triangle meshes and embed them into planar meshes of specified pre specified connectivity and then you generate the basis for these.",
            "Play in our meshes once and then you reuse them so there are some tradeoffs there.",
            "Because you don't, you know you're losing some.",
            "Some of the topology in doing this, so this is this.",
            "This is an interesting thing you can try to do.",
            "So this question might be what?",
            "What are the challenges using this technology for recognition?",
            "So learning classes of objects?",
            "So there the function is going to be essentially computing.",
            "So you have.",
            "So when you say recognition you mean for example, there will be different classes of cows, say and chairs and then you have to try.",
            "Yeah, that would be.",
            "That would be.",
            "I mean that would follow what I was saying before, which is essentially what you would have to do is to recognize that these are actually different.",
            "Your sister generating different graphs.",
            "Of different sizes and different scales, and somehow you would have to recognize that these all came from the same object.",
            "So I think an approach that embedded these different objects into a constant or sort of a fixed planar sort of structure might help there.",
            "Yeah.",
            "The other thing you can do, which I didn't talk about, is so if you notice from Schoellkopf stop, he showed some graphics applications where he starts with the point set, but he doesn't generate the triangle mesh.",
            "So he directly takes the point set and doesn't implicit surface parametrization using one class SVM.",
            "So no one can we can sort of look at an approach like that with diffusion wavelets.",
            "I didn't talk about that here where you don't generate the mesh at all, you just directly use directly the point set.",
            "For all of these.",
            "Is there services and 3D space appear technique applied at all to have areas where, for example, in medicine, we're taking a pretty picture of a bottle and it's not only important ones on the surface, but also it's on the inside wherever else image and it extends that.",
            "Yeah, actually.",
            "No, no no.",
            "So this this yeah, the wavelet construction applies affect my colleague who I worked with more maggioni they have applied this to hyperspectral imaging where this is exactly what you're doing.",
            "You have tissue samples from like in pathology.",
            "We have tissue samples in a different frequencies and so you can apply this sort of method there till.",
            "Accessible with application.",
            "Don't know too much about that, sorry.",
            "Based on the.",
            "He started.",
            "OK so yeah, so so this uses a nonlinear, so there's a basis pursuit method that essentially so.",
            "One thing that if you looked at the basis construction I mentioned, diffusion wavelets generated over complete basis set because you have this whole spectrum of bases from very local basis to very global basis, and so there's a basis pursuit method that essentially picks out the basis functions that you would need to.",
            "Construct to approximate a given given coordinate function.",
            "So this is the expensive part of constructing diffusion wavelets, which can be considerably speeded up if you input the function that you're approximating in the construction of different wavelets.",
            "So certain bases at certain levels may not need to be computed at all, for example by starting the construction top down.",
            "You can actually speed this up considerably.",
            "Speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody knows JPEG.",
                    "label": 0
                },
                {
                    "sent": "It's a type of four year analysis on images.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it assumes a fixed 2D topology, so we really can't use it in 3D.",
                    "label": 1
                },
                {
                    "sent": "And but given the widespread importance of 3D, there's really an the fact that 3D images and 3D objects are very large.",
                    "label": 1
                },
                {
                    "sent": "You want some sort of compression method, and there's a lot of interest in this in the computer graphics community.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to show you is one of the solutions that was developed in computer graphics and I'm going to compare it with another approach that I.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've been working on.",
                    "label": 0
                },
                {
                    "sent": "So let's first familiarize ourselves with what we mean by 3D objects.",
                    "label": 0
                },
                {
                    "sent": "So a 3D object essentially is specified by generally two components, so you have an object here.",
                    "label": 0
                },
                {
                    "sent": "This is a pretty small object.",
                    "label": 0
                },
                {
                    "sent": "You can model this as a graph and this is the adjacency matrix of the graph, so the topology of the object.",
                    "label": 0
                },
                {
                    "sent": "And it's geometry by its geometry, I mean you can think of the XYZ coordinates functions on the graph.",
                    "label": 0
                },
                {
                    "sent": "So essentially I'm plotting here.",
                    "label": 0
                },
                {
                    "sent": "Each of these coordinate functions on the graph.",
                    "label": 0
                },
                {
                    "sent": "So the problem of three decompression is essentially to find.",
                    "label": 0
                },
                {
                    "sent": "And you set of coordinate representations that you can use the projective geometry on the take up far less space than the original representation.",
                    "label": 0
                },
                {
                    "sent": "Now there are two approaches to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "One approach is to essentially ignore topology and just focus on geometry, so you can just take these coordinate functions and then use your favorite compression method.",
                    "label": 0
                },
                {
                    "sent": "But there's been a growing movement in computer graphics to see whether you can actually do something with topology and derive adaptive compression methods that build that are specific to each object.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as you go to larger objects, you can notice the size of the object keeping on growing and so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Even this is not a particularly large object, so you this is.",
                    "label": 0
                },
                {
                    "sent": "This is a very challenging problem because you can objects with millions of vertices and so you want to fast compression method.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the method I want to start talking about first is 1 that was introduced by Carney and Gottesman from Israel in SIGGRAPH 2000.",
                    "label": 0
                },
                {
                    "sent": "The idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "You take the topology of the object, it's a graph, you generate the eigenvectors at the graphic policy and and then you project the coordinate functions on the first few eigenvectors of the graph Laplacian.",
                    "label": 1
                },
                {
                    "sent": "This is essentially four year analysis extended to graphs so.",
                    "label": 0
                },
                {
                    "sent": "Let's first review this method and then let's see what the limitations of this method are before it.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using a different method.",
                    "label": 0
                },
                {
                    "sent": "So we've seen that the graph Laplacian has been used in many contexts and machine learning actually was first studied on the mid 70s by Fiedler, who was a check mathematician to be news for spectral clustering, lots of work and semi supervised learning in this conference.",
                    "label": 0
                },
                {
                    "sent": "And some work that you might not be familiar with.",
                    "label": 0
                },
                {
                    "sent": "We've been exploring the use of the Laplacian for approximating functions called value functions and Markov decision.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "ISIS.",
                    "label": 0
                },
                {
                    "sent": "Search introduces Buffalo classy and let's think of our differential representation of a coordinate functions rather than represent each function.",
                    "label": 0
                },
                {
                    "sent": "Exactly what we're going to do is we're going to look at the difference between the value of the function at some coordinate at some vertex X minus the average of the values that you would get by taking the neighbors and computing sort of the average.",
                    "label": 0
                },
                {
                    "sent": "So your DX is the degree of vertex X, so you can represent this effect in matrix form using this, and this is one form of the Laplacian.",
                    "label": 0
                },
                {
                    "sent": "This is called discrete Laplacian.",
                    "label": 0
                },
                {
                    "sent": "Um and.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's a strong connection between the discrete Laplacian and random walks, so if I take any weighted graph undirected graph, then the random walk is just the probability of visiting any neighbor with probability proportional to 1 by degree of the vertex.",
                    "label": 1
                },
                {
                    "sent": "The two kinds of Laplacian you might be familiar with other combinatorial Laplacian that was mentioned in the first talk and the normalized Laplacian, and we can easily show that the normalized Laplacian has spectral structure.",
                    "label": 0
                },
                {
                    "sent": "Very closely related to the random walk matrix, and that's a fairly easy identity show.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is classical Fourier analysis on graphs and let's see how it works on this problem.",
                    "label": 0
                },
                {
                    "sent": "Before we look at what limitation.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It has.",
                    "label": 0
                },
                {
                    "sent": "So first let's look at like in vectors, losian on 3D objects.",
                    "label": 1
                },
                {
                    "sent": "Here are some low order eigenvectors on this cow head.",
                    "label": 0
                },
                {
                    "sent": "Here's the higher order eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "The two things are known.",
                    "label": 0
                },
                {
                    "sent": "One is generally the supported eigenvectors, the whole object.",
                    "label": 0
                },
                {
                    "sent": "So these basis functions are global.",
                    "label": 0
                },
                {
                    "sent": "They're not local.",
                    "label": 0
                },
                {
                    "sent": "This is actually going to be a problem, and second, you see that higher order eigenvectors generally start illuminating high frequency regions, and so as you look at the eigenvectors from lower to higher order, you will see that they essentially have more variation and.",
                    "label": 0
                },
                {
                    "sent": "They get less smooth.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the process is very simple.",
                    "label": 0
                },
                {
                    "sent": "You take your target function you projected on the first few eigenvectors of the Laplacian.",
                    "label": 0
                },
                {
                    "sent": "If you're doing linearly squares.",
                    "label": 0
                },
                {
                    "sent": "If you're doing nonlinear least squares, you can select the eigenvectors out of order.",
                    "label": 0
                },
                {
                    "sent": "And this is standard for your least squares projection, so here's an example of a pig, and here's a reconstruction with 100 basis functions.",
                    "label": 1
                },
                {
                    "sent": "An here's with 800 basis functions.",
                    "label": 1
                },
                {
                    "sent": "There's been a lot of follow on work about with this approach in computer graphics, where people have applied this to do things like spectral Warren watermarking and various other things, there are some variants of this approach that I won't talk about.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the limitations of this approach, the limitations of this approach primarily have to do with the limitations of Fourier analysis.",
                    "label": 0
                },
                {
                    "sent": "So one of the problems we're doing eigenvector approximations of these coordinate functions is that when you have functions that have very varying degree of smoothness, it's very hard to get them right.",
                    "label": 0
                },
                {
                    "sent": "So here you have the horns of the cow, which are very sharp, and you also have very smooth regions, and you're trying to get large eigenvectors to correspond to.",
                    "label": 0
                },
                {
                    "sent": "Approximate these sort of very sharp regions while retaining Fidelity in the very smooth regions, and So what happens is while you're trying to correct these high frequency eigenvectors, you set up a lot of noise over here.",
                    "label": 0
                },
                {
                    "sent": "This is a standard problem with four year basis.",
                    "label": 0
                },
                {
                    "sent": "If you truncated, you essentially chop off the horns of the column so it doesn't look very good.",
                    "label": 0
                },
                {
                    "sent": "So this problem was notice McCartney and got some men and they didn't suggest a solution, which is what we're going to do.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're going to look at wavelet analysis and graphs.",
                    "label": 0
                },
                {
                    "sent": "I assume many of you are familiar with standard wavelet analysis.",
                    "label": 0
                },
                {
                    "sent": "This was motivated largely to address the problems of four year basis.",
                    "label": 0
                },
                {
                    "sent": "They've been extensively explored in Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "Is the key idea of wavelets?",
                    "label": 0
                },
                {
                    "sent": "Is this notion of dilation.",
                    "label": 0
                },
                {
                    "sent": "You start with the what's usually called the mother wavelet, which is usually one simple example is a hard wavelet, and then you dilate the mother wavelet to produce wavelets at multiple scales and it's intrinsically a multiresolution analysis.",
                    "label": 0
                },
                {
                    "sent": "We're interested in doing this on graphs.",
                    "label": 0
                },
                {
                    "sent": "This has been done very recently by a group at Yale Koifman.",
                    "label": 0
                },
                {
                    "sent": "Raffi Kaufman's growth and I've been working with Maggioni on extensions of this approach, and, of course, applying it to things like Markov decision processes and semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So there are many advantages off graph based wavelets and I won't be able to get into some of the more interesting aspects of it.",
                    "label": 0
                },
                {
                    "sent": "One really interesting aspect of it is that it gives you a very fast way of computing the Greens function.",
                    "label": 1
                },
                {
                    "sent": "So if you look at semi supervised learning, one of the ways of doing semi supervised learning is to invert the Laplacian on the unlabeled examples and this is generally considered to be a cubic operation, but actually you can do it considerably faster for diffusion matrices with the.",
                    "label": 0
                },
                {
                    "sent": "With diffusion wavelets and I don't have time to explain that, but that's if you're interested in semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "This is actually a.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A nice way to go.",
                    "label": 0
                },
                {
                    "sent": "So here is a simple way to understand what diffusion wavelets give you.",
                    "label": 0
                },
                {
                    "sent": "We can do dilation in time or space on graph, so we have to come up with some other idea.",
                    "label": 0
                },
                {
                    "sent": "So let's start with unit vectors.",
                    "label": 0
                },
                {
                    "sent": "These are going to be our our finest vector space.",
                    "label": 0
                },
                {
                    "sent": "We can represent any function exactly on this vector space, so I'm showing this for a simple mesh graph here.",
                    "label": 0
                },
                {
                    "sent": "So we start with a system of unit vectors and now we're going to dilate these vectors.",
                    "label": 0
                },
                {
                    "sent": "How are we going to direct these vectors?",
                    "label": 0
                },
                {
                    "sent": "We take our random walk diffusion matrix and we're going to take powers of this random walk diffusion matrix.",
                    "label": 0
                },
                {
                    "sent": "So intuitively, you can think of it is starting in a vertex and doing progressively longer random walks.",
                    "label": 0
                },
                {
                    "sent": "So in the first step of random walk you can visit any of the neighboring vertex vertice is so essentially you can think of this unit vector dilating proportional to the local degree of the graph at that vertex.",
                    "label": 0
                },
                {
                    "sent": "So you start with the collection of unit vectors.",
                    "label": 0
                },
                {
                    "sent": "These will get dilated, and now you do a gram Schmidt authorization to get back what you would call scaling functions.",
                    "label": 0
                },
                {
                    "sent": "Now you lost some resolution in going from this representation, but this representation.",
                    "label": 0
                },
                {
                    "sent": "So you can try to recover that by constructing a set of basis functions that are orthogonal to the set of basis functions you get here.",
                    "label": 0
                },
                {
                    "sent": "This will be a wavelets so you can do this at at multiple scales, and what I'm showing here is a dyadic powers the powers of two of your diffusion matrix, so this is 2, four, 816 and 32.",
                    "label": 0
                },
                {
                    "sent": "One of the nice things that you get with this is you start with the unit vectors and you converge to the eigenvectors of the Laplacian so the highest level you essentially have the eigenvectors Laplacian.",
                    "label": 0
                },
                {
                    "sent": "The lowest level you have the unit vectors.",
                    "label": 0
                },
                {
                    "sent": "And at scales in between, you have basis functions which progressively have larger and larger supports.",
                    "label": 0
                },
                {
                    "sent": "And because the basis functions are on the graph they support they.",
                    "label": 0
                },
                {
                    "sent": "They follow the manifold and so for example in this case we have actually the meshes.",
                    "label": 0
                },
                {
                    "sent": "There's a bottleneck between these two regions of the meshes, only one edge in between, so you see that these basis functions are defined on either the first sub graph or the second sub graph.",
                    "label": 0
                },
                {
                    "sent": "Now this is a very general representation.",
                    "label": 0
                },
                {
                    "sent": "You can do anything with this.",
                    "label": 0
                },
                {
                    "sent": "You can do any kind of semi supervised learning regression on graphs and we're going to use this for compressing 3D objects.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the details of the construction are in the paper.",
                    "label": 0
                },
                {
                    "sent": "Essentially use their two main steps.",
                    "label": 0
                },
                {
                    "sent": "There's a downsampling step where you start with basis function that some resolution and you throw away those that you don't need to capture the resolution interest in.",
                    "label": 0
                },
                {
                    "sent": "Typically the input to this construction is a graph.",
                    "label": 0
                },
                {
                    "sent": "Anna specified resolution that you're interested in capturing, and at every step you're doing dilation.",
                    "label": 0
                },
                {
                    "sent": "Using this process I just mentioned, which you can think of as trying to represent.",
                    "label": 0
                },
                {
                    "sent": "Dyadic powers of the diffusion matrix using basis functions that are constructed at each level, so in this case you start by representing the original diffusion matrix using basis functions that you start with both in the domain and the range.",
                    "label": 0
                },
                {
                    "sent": "So this is the notation that we use for that.",
                    "label": 0
                },
                {
                    "sent": "Then you're trying to represent the basis functions teeth.",
                    "label": 0
                },
                {
                    "sent": "The second part of the diffusion matrix, chi squared, using new basis functions that you got from the first level by throwing away the ones we didn't need, and so on and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "These basis functions look very interesting on 3D objects, So what you notice is basis functions that are at the top of the tree look like eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "They have global support basis functions, lower and lower levels have much much lower support.",
                    "label": 0
                },
                {
                    "sent": "The much more local, and if you look at some of the levels you actually see that it.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exxon very interesting features.",
                    "label": 0
                },
                {
                    "sent": "So here are basis functions.",
                    "label": 1
                },
                {
                    "sent": "At Level 5 you see one that corresponds to a horn and I.",
                    "label": 0
                },
                {
                    "sent": "The cheek, the year and the neck.",
                    "label": 0
                },
                {
                    "sent": "So these basis functions seem to be picking out interesting geometric features of the object because of the localized properties of the graph at this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Asians?",
                    "label": 0
                },
                {
                    "sent": "So now you can do it.",
                    "label": 0
                },
                {
                    "sent": "Essentially the same approach using these basis functions and you solve the problem that we had before where you do a much better job of approximating the horns of the cow.",
                    "label": 0
                },
                {
                    "sent": "So what are the challenges in extending this approach to large objects?",
                    "label": 0
                },
                {
                    "sent": "The problem is again dealing with very very large graphs so.",
                    "label": 0
                },
                {
                    "sent": "One approach which actually.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Indian Gossman studied in that paper is simply to use graph partitioning.",
                    "label": 0
                },
                {
                    "sent": "So you can use any favorite graph partitioning method, for example medicine, which takes an original graph and constructs a series of smaller graphs partitions the smaller graphs and then UN portions the smaller graphs to get back the original partition, and so the colors you show the graph partitions.",
                    "label": 1
                },
                {
                    "sent": "You can then form local basis functions on each partition and you can approximate each other coordinate functions on each partition.",
                    "label": 0
                },
                {
                    "sent": "There is some error you introduce, so there's a tradeoff here between the level at which you partition.",
                    "label": 0
                },
                {
                    "sent": "And the overall speed of the of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And there are some results in the paper that that show these tradeoffs here.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "Here's an elephant.",
                    "label": 0
                },
                {
                    "sent": "This is about 20,000 verticies.",
                    "label": 0
                },
                {
                    "sent": "What I'm showing here on the Y axis is a combination of two terms.",
                    "label": 0
                },
                {
                    "sent": "One is the geometric error, so you can take the literal object, exact coordinate functions and you can measure the error between that and your approximation.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, that error alone is somewhat misleading because you can have a very choppy reconstruction that doesn't look very nice.",
                    "label": 0
                },
                {
                    "sent": "So to avoid that.",
                    "label": 0
                },
                {
                    "sent": "There's another term which Carney and got some introduce which is the Laplacian enter.",
                    "label": 0
                },
                {
                    "sent": "This is exactly the difference, the differential representation I showed you earlier, which is the difference between the average of the neighboring verticies, coordinate functions and the value that you actually compute.",
                    "label": 0
                },
                {
                    "sent": "So the sum of these two is 1 simple way to compute the error and the horizontal axis is measuring the number of basis functions you use.",
                    "label": 0
                },
                {
                    "sent": "So this object was for example divided by 300 partitions.",
                    "label": 0
                },
                {
                    "sent": "So the red curve is the Laplacian basis and the blue curve is the performance of the diffusion of basis.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you go to objects that are somewhat smooth, you see the less of a difference between these two, understandably, because if you have a very smooth object for your methods, do reasonably well.",
                    "label": 0
                },
                {
                    "sent": "This is about 34,000 verticies.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I mentioned, if you explore the error that you get was partition size, you notice that as you partition the object into finer and finer regions and do local approximation, you are introducing error and that's because all the edges that cross between partitions you're going to get introduced some error basis functions now or computer only on each sub graph.",
                    "label": 0
                },
                {
                    "sent": "So you've lost track of the overall geometry of the object in the topology of the object.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "And I don't know why double compromise, but you've gained a lot in terms of the running time, so this is something that you would have to sort of choose as a compromise between you know the Fidelity of the reconstruction you want and how fast you want your method to run.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "What I've shown you is a way of doing compression of 3D objects.",
                    "label": 1
                },
                {
                    "sent": "It's adaptive that means the basis functions are computed with respect to the individual objects.",
                    "label": 1
                },
                {
                    "sent": "The new approach here uses a type of analysis on graphs that builds on the theory of wavelets.",
                    "label": 0
                },
                {
                    "sent": "It differs from eigenvectors in that basis functions are local and analysis is multi resolution.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And for objects that are have degree varying degrees of smoothness, you can show that the performance is quite a bit better.",
                    "label": 0
                },
                {
                    "sent": "No, there's a bunch of extensions that that I've been working on.",
                    "label": 0
                },
                {
                    "sent": "One of the extensions has to do with.",
                    "label": 0
                },
                {
                    "sent": "Trying to improve the performance of the Laplacian basis by including other information.",
                    "label": 0
                },
                {
                    "sent": "So, for example, supposing you take the Laplacian basis and allow.",
                    "label": 0
                },
                {
                    "sent": "Use of jump geometrical information because you know the functions that you're trying to approximate.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you can improve their performance considerably by doing this.",
                    "label": 0
                },
                {
                    "sent": "So one strategy has been studied to some extent in graphics users, properties of two manifolds.",
                    "label": 0
                },
                {
                    "sent": "These are essentially two manifolds, and there's a way of setting the weights of the Laplacian base of two manifolds called cotangent basis, and that actually improves the performance of Laplacian basis quite a bit because you still have the problem that these basis functions are going to be global and they're not multi scale.",
                    "label": 0
                },
                {
                    "sent": "The the diffusion wavelet construction needs considerable time for very large graphs, and most of it has not been actually not.",
                    "label": 0
                },
                {
                    "sent": "There's not as much intensive study of this As for example, there has been of eigen solvers, so a lot of this code runs in Matlab.",
                    "label": 0
                },
                {
                    "sent": "It's not very fast for the problems I'm showing you, there's not a huge difference, but for very large graphs you would need to have faster methods and there are faster methods that have been.",
                    "label": 1
                },
                {
                    "sent": "Designed, but they haven't really been implemented yet.",
                    "label": 1
                },
                {
                    "sent": "There are many other graphics applications that can benefit from this.",
                    "label": 0
                },
                {
                    "sent": "One example is when you're trying to.",
                    "label": 0
                },
                {
                    "sent": "Render objects that are translucent where some light passes through the object.",
                    "label": 0
                },
                {
                    "sent": "Some light gets reflected.",
                    "label": 0
                },
                {
                    "sent": "The way this is dealt with in graphics is to store matrices at every every vertex and sort of simple coordinate functions.",
                    "label": 0
                },
                {
                    "sent": "You actually have an entire set of matrices.",
                    "label": 0
                },
                {
                    "sent": "And there's some interesting ways of extending this to doing compression of matrices and graphs that I can talk about.",
                    "label": 0
                },
                {
                    "sent": "Um, finally let me just end with a very short demo to show you what it looks like.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing here is the.",
                    "label": 0
                },
                {
                    "sent": "Compression of this of the skull head first starting with the Laplacian for larger and larger number of bases and what you can see here is the similar.",
                    "label": 0
                },
                {
                    "sent": "Run on the diffusion wavelet and if you put these two things side by side.",
                    "label": 0
                },
                {
                    "sent": "You can pick out the differences fairly easily in terms of, for example, the sharpness of the horns and the rendition of the year, the eyes, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, let me stop there, thank you.",
                    "label": 0
                },
                {
                    "sent": "When?",
                    "label": 0
                },
                {
                    "sent": "Is it possible to restrict graph to certain class of graphs?",
                    "label": 0
                },
                {
                    "sent": "Easier to develop more efficient algorithm, so I'm looking at your presentation, I'm wondering.",
                    "label": 0
                },
                {
                    "sent": "What are the restrictions on those graphs?",
                    "label": 0
                },
                {
                    "sent": "That represent this teenager can be used.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's a good question, so so.",
                    "label": 0
                },
                {
                    "sent": "One thing you can try to do is take advantage of the fact that a lot of these graphs are, for example, triangulated meshes, and so you know that their degree is specified an.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned this notion of cotangent bases actually takes advantage of that property.",
                    "label": 0
                },
                {
                    "sent": "So I.",
                    "label": 0
                },
                {
                    "sent": "The other thing people have tried is to embed these triangulated meshes in.",
                    "label": 0
                },
                {
                    "sent": "In meshes of fixed topology, so one of the problems here that I didn't talk about is it's a very natural question is OK, so I generated basis for compressing this cow.",
                    "label": 0
                },
                {
                    "sent": "But then you give me another shape.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to generate new basis for that.",
                    "label": 0
                },
                {
                    "sent": "So there is an additional overhead now that you have to generate these basis functions for every new object, and so one might wonder why is this some sort of transfer learning you can do where I generate the basis for one object and then somehow I can reuse these bases for some other object.",
                    "label": 0
                },
                {
                    "sent": "So one approach that's been studied is to take these triangle meshes and embed them into planar meshes of specified pre specified connectivity and then you generate the basis for these.",
                    "label": 1
                },
                {
                    "sent": "Play in our meshes once and then you reuse them so there are some tradeoffs there.",
                    "label": 0
                },
                {
                    "sent": "Because you don't, you know you're losing some.",
                    "label": 0
                },
                {
                    "sent": "Some of the topology in doing this, so this is this.",
                    "label": 0
                },
                {
                    "sent": "This is an interesting thing you can try to do.",
                    "label": 0
                },
                {
                    "sent": "So this question might be what?",
                    "label": 0
                },
                {
                    "sent": "What are the challenges using this technology for recognition?",
                    "label": 0
                },
                {
                    "sent": "So learning classes of objects?",
                    "label": 0
                },
                {
                    "sent": "So there the function is going to be essentially computing.",
                    "label": 0
                },
                {
                    "sent": "So you have.",
                    "label": 0
                },
                {
                    "sent": "So when you say recognition you mean for example, there will be different classes of cows, say and chairs and then you have to try.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that would be.",
                    "label": 0
                },
                {
                    "sent": "That would be.",
                    "label": 0
                },
                {
                    "sent": "I mean that would follow what I was saying before, which is essentially what you would have to do is to recognize that these are actually different.",
                    "label": 0
                },
                {
                    "sent": "Your sister generating different graphs.",
                    "label": 0
                },
                {
                    "sent": "Of different sizes and different scales, and somehow you would have to recognize that these all came from the same object.",
                    "label": 0
                },
                {
                    "sent": "So I think an approach that embedded these different objects into a constant or sort of a fixed planar sort of structure might help there.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The other thing you can do, which I didn't talk about, is so if you notice from Schoellkopf stop, he showed some graphics applications where he starts with the point set, but he doesn't generate the triangle mesh.",
                    "label": 0
                },
                {
                    "sent": "So he directly takes the point set and doesn't implicit surface parametrization using one class SVM.",
                    "label": 0
                },
                {
                    "sent": "So no one can we can sort of look at an approach like that with diffusion wavelets.",
                    "label": 0
                },
                {
                    "sent": "I didn't talk about that here where you don't generate the mesh at all, you just directly use directly the point set.",
                    "label": 0
                },
                {
                    "sent": "For all of these.",
                    "label": 0
                },
                {
                    "sent": "Is there services and 3D space appear technique applied at all to have areas where, for example, in medicine, we're taking a pretty picture of a bottle and it's not only important ones on the surface, but also it's on the inside wherever else image and it extends that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, actually.",
                    "label": 0
                },
                {
                    "sent": "No, no no.",
                    "label": 0
                },
                {
                    "sent": "So this this yeah, the wavelet construction applies affect my colleague who I worked with more maggioni they have applied this to hyperspectral imaging where this is exactly what you're doing.",
                    "label": 0
                },
                {
                    "sent": "You have tissue samples from like in pathology.",
                    "label": 0
                },
                {
                    "sent": "We have tissue samples in a different frequencies and so you can apply this sort of method there till.",
                    "label": 0
                },
                {
                    "sent": "Accessible with application.",
                    "label": 0
                },
                {
                    "sent": "Don't know too much about that, sorry.",
                    "label": 0
                },
                {
                    "sent": "Based on the.",
                    "label": 0
                },
                {
                    "sent": "He started.",
                    "label": 0
                },
                {
                    "sent": "OK so yeah, so so this uses a nonlinear, so there's a basis pursuit method that essentially so.",
                    "label": 0
                },
                {
                    "sent": "One thing that if you looked at the basis construction I mentioned, diffusion wavelets generated over complete basis set because you have this whole spectrum of bases from very local basis to very global basis, and so there's a basis pursuit method that essentially picks out the basis functions that you would need to.",
                    "label": 0
                },
                {
                    "sent": "Construct to approximate a given given coordinate function.",
                    "label": 0
                },
                {
                    "sent": "So this is the expensive part of constructing diffusion wavelets, which can be considerably speeded up if you input the function that you're approximating in the construction of different wavelets.",
                    "label": 0
                },
                {
                    "sent": "So certain bases at certain levels may not need to be computed at all, for example by starting the construction top down.",
                    "label": 0
                },
                {
                    "sent": "You can actually speed this up considerably.",
                    "label": 0
                },
                {
                    "sent": "Speaker.",
                    "label": 0
                }
            ]
        }
    }
}