{
    "id": "a2uyqrs5a77dalv5t4vhoh6txa3tsxn4",
    "title": "Learning and inference in the presence of corrupted inputs",
    "info": {
        "author": [
            "Yishay Mansour, Blavatnik School of Computer Science, Tel Aviv University"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_mansour_corrupted_inputs/",
    "segmentation": [
        [
            "Thank you very much.",
            "This is a joint work with further before we figure in the rope Shapira."
        ],
        [
            "So.",
            "One of my main names in this talk is sort of try to explain to what do we mean by robustness and why do I think it's a very interesting.",
            "This is why I spend some time on motivating example and defining the model.",
            "Then sort of a sketch of the main results and hopefully I will have time to sort of say a few words about how the proofs of structured."
        ],
        [
            "Let's start with the motivating example.",
            "The first one is sort of think about spam detection so so in spam detection there is many little feature that you want to find in an email which are called sort of filters, and through those those filters you would like to detect whether an email is a spam somehow you would like to detect those individual features and to combine them into a global decision."
        ],
        [
            "But when you think about spam detection, it's really about a game.",
            "In some sense it's a game between the spammers and the detectors.",
            "On the one hand side, this payment would really like to to avoid those getting detected in the detection are working against them.",
            "So if this power would sort of be left by themselves, they would be able to walk around any detection system.",
            "So easy about, really sort of.",
            "The question that we sort of food poses robustness is sort of we should expect this family in the short range would be able to overcome a few of the detectors and what we would like to get.",
            "We would like to be able to perform very well even if a few of the detectors are faulty.",
            "So within this a setting would like to classify the email correctly, even if the spammer can adversarially cropped a few of the inputs.",
            "So by the robustness, we are sort of.",
            "I will interpretation is that the ability that some of the inputs might be corrupted.",
            "OK, let's."
        ],
        [
            "Give you a second motivating example, which is a network failure, so in any large networks of what you would have is that there are rooms in which there are operators trying to make the show that the network is up and running.",
            "In order to make the network."
        ],
        [
            "Chronic what you have is you ever usually additional hardware that is put in the network to detect the failure.",
            "But then the question should come up with sort of what would happen when the detectors fail.",
            "So in some sense, the one hand side would like to detect failures in the huddle inside.",
            "You'd like to avoid false detections, so of course you can model it in more than one way.",
            "If you have a Bayesian that public, you would put a prior over the failures and under this fire you could put the posterior of what you observe.",
            "But notice that the prior here is is very strange pilot supplier over things that you never observe because it what would happen if you're trying to detect an error Bay on the link.",
            "You need to say what the probability of seeing 5% when it's 1% what will pull, pull it off, sync 12%, etc.",
            "Our approach is trying to do a worst case analysis and sort of this is sort of what I'll try to convince you.",
            "So I think the more natural thing.",
            "So our goal is to perform well in the Faroe detection.",
            "You can think about is trying to overcome K points of failure.",
            "In in the system.",
            "So what would be the adversary here in the spam detection model?",
            "It too, it was very clear that the adversary as a spammer here there is not a clear adversary, but we'd like to think of the worst case scenario is really in adversarial behavior."
        ],
        [
            "OK, so here is sort of going to be our model.",
            "We have a joint distribution over X&YY is going to be the label X is going to be the observable.",
            "And if I look at this picture by itself, seeing X to predict why this is inference.",
            "How are we going to modify this model?",
            "We're going to add another layer which is adversary here.",
            "The adversary in our model can observe EIX and given X.",
            "You can modify to.",
            "To a new value so it will allow the adversary arbitrarily to do a modification.",
            "It's probably hopeless, but what will restrict the adversary will restrict him to some set of things that you can modify.",
            "So given the X&Y, there is some set of things that you can modify.",
            "X into let me see."
        ],
        [
            "Giving it a more formal model so we have a label which is the Y it's a Boolean label.",
            "We have signals X.",
            "Just think of and bit vectors and we have a joint distribution over the inputs and outputs.",
            "We are assuming that there is.",
            "It's a known pile, so essentially the inference problem is is simple.",
            "Given the this distribution, you can sort of solve the interest problem.",
            "We assume the distribution is computable and sampleable and everything is nice with respect to it.",
            "The main difference that we want to discuss in robustness is the what are you observing?",
            "So you're observing a different set of attributes, which is really easy.",
            "So how long is easy build?",
            "So this build is for any X&Y.",
            "There is a set of things that we can map.",
            "X in two, so this is the role of wife in X.",
            "Will assume that is computed in polynomial time, given X&Y, because we want efficient algorithms and really the adversary is the one who sort of gets to decide which Z is is selected.",
            "Justice to have a concrete example in mind, think that.",
            "Given X, the possible corruption is to take one of the axes and bits and we can take one of the end bits and flip it.",
            "So this is a very simple example.",
            "We have a Hamming distance one.",
            "This is our set easily computable and now sort of what would happen when the adversary can flip one.",
            "We will return to this examples in a few minutes.",
            "What is our goal?",
            "We would like to to build a prediction and prediction is now observing Z and given the observation of Z it would like to predict.",
            "The beat why?",
            "OK."
        ],
        [
            "So far the predictor will observe the.",
            "This is observed signal.",
            "We predict why, which implicitly means that we are defining a policy policy that Maps this into predictions.",
            "Prediction could be probabilistic.",
            "The adversary.",
            "Task, on the other hand, is given X&Y.",
            "To select the Z to decide how to corrupt Toulouse, do see of Winx is sort of the policy of the adversary how to corrupt given the true value is Y&X.",
            "So now if we have a predictor in an adversary I almost built in a way that it's clear that the right thing to do here is the game between the two 60 sum game between the predictor and the adversary, and what we would like to observe as a value is the arrow.",
            "So if you fix the policy of the predictor.",
            "And the policy of the adversary.",
            "So his pie for prediction in C. For corruption we can compute a the error rate, right?",
            "This is a probability.",
            "This is an expectation over double the true wine X was the probability that.",
            "The prediction is incorrect.",
            "OK."
        ],
        [
            "So now, given that we have a value, we can now look it's a 0 sum game.",
            "We have a value of the game, so the optimal error rate that you can hope to achieve is it like you would like to have.",
            "To find really a policy which minimizes the error, assuming that the adversary is going to select the worst case that he can.",
            "So Aerostar is going to be the value of the game.",
            "And we're not going to to get.",
            "Exactly the value of a game, but we sort of be able to get almost the value of a game so epsilon optimal would really mean that you're just epsilon away from the value of the game.",
            "So that's our main result for inference.",
            "For the inference setting.",
            "So basically we have a distribution.",
            "It's known it's computable and.",
            "Where is it possible corruption so basically?",
            "Given an excellent why, we know how.",
            "What are the possible mappings that can go with X&Y?",
            "What is our main result with for any distribution given the observable sync signal, we can compute the prediction for Y. I will L would be near optimal epsilon optimal and the algorithm is going to be efficient, efficient with minutes.",
            "If you think of the accesses N bits, it's going to run in time.",
            "Polynomial in N. It is unfortunately good go going to running times which is exponential in the number of.",
            "Or things that you can map into.",
            "But the main issue is that.",
            "For N bit strings, it's going to be a polynomial time algorithm.",
            "I should mention here that in a previous work with motion and holding a vehicle instead, we looked in in the last order.",
            "We looked at the static setting so where the adversary circuit can select the modification rule independent of the expertise is realized and we given a fairly different efficient algorithm in that setting.",
            "OK."
        ],
        [
            "The main result we have.",
            "For learning software really two parts in the paper, one is influence and one is learning.",
            "In the learning setting is.",
            "Is much more in line with what most of you are familiar with.",
            "This is why I'm going to spend much less time in the talk about it.",
            "So you have a distribution.",
            "It's unknown, it's arbitrary.",
            "You're going to observe a training set.",
            "Unfortunately, we need to assume that the examples are uncorrupted, but you need to plan for for a bit future for a raining day that really that the future test example are going to be corrupted by the adversary, you have a prothesis class from which would like to to select the best hypothesis under those conditions and we'll assume also that you're given an Oracle that can minimize the risk with respect to this class, and the goal is really to select the hypothesis for age, or really a mixture of a process from age with can minimize.",
            "The aeillo under this adversarial model.",
            "Any sort of.",
            "We have two things to resort with short of combine into one.",
            "The first is given a sample we can compute efficiently a mixture.",
            "Of the hypothesis, which is near optimal for this set.",
            "So given a training set we can find.",
            "Aneel optimally prothesis for this training set.",
            "And the second thing is that we have a generalization result if our training set is large enough, then with high probability.",
            "The two arrow and the observed arrow have is very small difference.",
            "Notice attorney generalization result.",
            "Is it is not as straightforward as we're sort of used to because there is an adversary and the adversary has a huge flexibility on farm modifying things.",
            "But still with you can we can get.",
            "A generalization bar, so basically if we take a large enough training set, we can learn and it's going to be close to the optimal thing."
        ],
        [
            "OK.",
            "So this is this.",
            "I think in this title tried to explain why does it make a difference in how does it make a difference that you want to learn the robust in or just regular learning.",
            "So think about learning hyperplanes, homogeneous hyperplanes, regular learning means minimizing the error, large margin is you want to minimize the error within margin.",
            "And let's add an adversary that can take one of the attributes and flip them to zero.",
            "What would it make?",
            "For simplicity, let's fix a uniform distribution.",
            "So if you think of it about the problem statically, we know exactly what the adversary is going to do.",
            "He's going to pick, given a weight is going to pick the attribute it belongs to the highest weight.",
            "And he's going to zero it out, so really would like to minimize over WS, but in some sense you have a margin that depends on the on the W feeling the adaptive setting which are in here.",
            "It's slightly even more complex, but the adversary would do is sort of taking it really an attribute.",
            "Who's signal is correct?",
            "And it's sort of going to zero it out.",
            "The bottom line here is that.",
            "What you when you have robustness really what you really would like is to spread things along the different attribute.",
            "It's just the reverse of what you expect that you want sparsity in order to avoid robot in order to enable robustness you want the anti sparsity.",
            "And therefore you have a margin with really depends.",
            "On the weight vector itself.",
            "OK.",
            "So they would like to."
        ],
        [
            "Sort of to give a very quick overview of sort of the techniques in the tools, because at least I find them very interesting and you're here to hear."
        ],
        [
            "So, so let's like to to model the setting on the one inside we have a corruption graph which really Maps inputs into possible corruptions.",
            "So this is 1 bipartite graph.",
            "On the other hand we have an interference graph.",
            "So take all the possible inputs and divide them into those which are positive and negative spam and not spam and put an edge between the two.",
            "If you can map them both to the same corrupted input.",
            "So this is going to be the interference graph.",
            "We will have wait.",
            "On on the on the note, but let's assume for now is the uniform distribution, so we can ignore those weights.",
            "How?"
        ],
        [
            "The optimal policy would look like, so the optimal policy here is what the adversary can do.",
            "The adversary can find the matching.",
            "And basically, if one of those things would come up, it will map them to a value with confuses in them too.",
            "So basically for each edge it can get one error and therefore the number of errors is at least the number of matchings.",
            "Now what can they predict or do?",
            "So what we show is that predictor can build a policy which is built on a vertex cover and can guarantee that the number of errors is most number of the size of the vertex cover.",
            "So for bipartite graphs maximum matchings equals minimum vertex cover and this implies that those two are the optimal policy.",
            "I just didn't tell you what what was this policy."
        ],
        [
            "OK, so we have an optimal policy.",
            "It's computed efficiently, but deficient in what in the size of X?",
            "So if you think about N bit strength it sufficient in two to the end.",
            "How can we hope?",
            "To get around it so in order to get around it, we cannot even inspect the entire graph.",
            "So really what we need is local computation algorithms."
        ],
        [
            "And in the next 2 minutes I'm going to give you a brief overview of local computation algorithm.",
            "So what is the local computation algorithm?",
            "It really sort of for a matching problem.",
            "Would say I would like to match.",
            "A person to a food or a vegetable, and I don't want to have the matching explicit, but I would like just to be able to answer a query that given, let's say a person who is it matched or given an edge.",
            "Is this edge part of the matching?"
        ],
        [
            "So for local computation algorithm you have on the one inside the graph.",
            "We have an implicit output which sort of you're shooting for is a matching.",
            "You'd like to always maintain correctness, which is feasibility.",
            "Whatever you say yes is a matching, so you can say all the edges if they are not in the matching but would like also performance to be near optimal.",
            "So local computation algorithm would have queries.",
            "So it takes to answer whether an edge is in the matching or not in this example.",
            "It has.",
            "It can probe the graph.",
            "With the edges really exist in the original graph."
        ],
        [
            "And can reply and what his main aim is to reply in times logarithmic so log in our graph size would really mean polynomial time and without any break computational storage.",
            "And there are algorithms known for the matching.",
            "So.",
            "Formatting would like to go to vertex cover, so the classic the classical way of going from maximum matching to minimum vertex cover.",
            "The challenge here is that we don't really have a maximum matching, but we have an approximate maximum matching.",
            "And we do really sort of look on how in approximate maximum matching doesn't translate well to.",
            "Two, if you do the same translation, it wouldn't translate to something approximate minimum because it's a maximization problem versus a minimization problem.",
            "So we sort of give a randomized algorithm we can.",
            "Do also the approximation for the vertex cover and hopefully I'm ending with this slide so."
        ],
        [
            "Maintains hopefully I convinced you that robustness is an interesting issue, is definitely interesting in practice, and I think it's also interesting in theory.",
            "I sort of sketch the ideas of robust inference.",
            "I think that one of the things that is interesting is that you get a very nice and clean connection.",
            "To graph properties.",
            "And it gives like for me it gives a very natural domain to local algorithms, because the fact that you need to create a running time which is logarithmic in the graph size, it's very natural for the learning.",
            "I very vaguely described it.",
            "If you have more like to know more, go ahead and read the paper.",
            "Ask me ask Rob and will be glad to answer."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with further before we figure in the rope Shapira.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One of my main names in this talk is sort of try to explain to what do we mean by robustness and why do I think it's a very interesting.",
                    "label": 0
                },
                {
                    "sent": "This is why I spend some time on motivating example and defining the model.",
                    "label": 0
                },
                {
                    "sent": "Then sort of a sketch of the main results and hopefully I will have time to sort of say a few words about how the proofs of structured.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's start with the motivating example.",
                    "label": 0
                },
                {
                    "sent": "The first one is sort of think about spam detection so so in spam detection there is many little feature that you want to find in an email which are called sort of filters, and through those those filters you would like to detect whether an email is a spam somehow you would like to detect those individual features and to combine them into a global decision.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But when you think about spam detection, it's really about a game.",
                    "label": 1
                },
                {
                    "sent": "In some sense it's a game between the spammers and the detectors.",
                    "label": 0
                },
                {
                    "sent": "On the one hand side, this payment would really like to to avoid those getting detected in the detection are working against them.",
                    "label": 0
                },
                {
                    "sent": "So if this power would sort of be left by themselves, they would be able to walk around any detection system.",
                    "label": 0
                },
                {
                    "sent": "So easy about, really sort of.",
                    "label": 0
                },
                {
                    "sent": "The question that we sort of food poses robustness is sort of we should expect this family in the short range would be able to overcome a few of the detectors and what we would like to get.",
                    "label": 0
                },
                {
                    "sent": "We would like to be able to perform very well even if a few of the detectors are faulty.",
                    "label": 0
                },
                {
                    "sent": "So within this a setting would like to classify the email correctly, even if the spammer can adversarially cropped a few of the inputs.",
                    "label": 1
                },
                {
                    "sent": "So by the robustness, we are sort of.",
                    "label": 0
                },
                {
                    "sent": "I will interpretation is that the ability that some of the inputs might be corrupted.",
                    "label": 0
                },
                {
                    "sent": "OK, let's.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give you a second motivating example, which is a network failure, so in any large networks of what you would have is that there are rooms in which there are operators trying to make the show that the network is up and running.",
                    "label": 0
                },
                {
                    "sent": "In order to make the network.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chronic what you have is you ever usually additional hardware that is put in the network to detect the failure.",
                    "label": 0
                },
                {
                    "sent": "But then the question should come up with sort of what would happen when the detectors fail.",
                    "label": 1
                },
                {
                    "sent": "So in some sense, the one hand side would like to detect failures in the huddle inside.",
                    "label": 0
                },
                {
                    "sent": "You'd like to avoid false detections, so of course you can model it in more than one way.",
                    "label": 0
                },
                {
                    "sent": "If you have a Bayesian that public, you would put a prior over the failures and under this fire you could put the posterior of what you observe.",
                    "label": 0
                },
                {
                    "sent": "But notice that the prior here is is very strange pilot supplier over things that you never observe because it what would happen if you're trying to detect an error Bay on the link.",
                    "label": 0
                },
                {
                    "sent": "You need to say what the probability of seeing 5% when it's 1% what will pull, pull it off, sync 12%, etc.",
                    "label": 0
                },
                {
                    "sent": "Our approach is trying to do a worst case analysis and sort of this is sort of what I'll try to convince you.",
                    "label": 0
                },
                {
                    "sent": "So I think the more natural thing.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to perform well in the Faroe detection.",
                    "label": 0
                },
                {
                    "sent": "You can think about is trying to overcome K points of failure.",
                    "label": 0
                },
                {
                    "sent": "In in the system.",
                    "label": 0
                },
                {
                    "sent": "So what would be the adversary here in the spam detection model?",
                    "label": 0
                },
                {
                    "sent": "It too, it was very clear that the adversary as a spammer here there is not a clear adversary, but we'd like to think of the worst case scenario is really in adversarial behavior.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here is sort of going to be our model.",
                    "label": 0
                },
                {
                    "sent": "We have a joint distribution over X&YY is going to be the label X is going to be the observable.",
                    "label": 0
                },
                {
                    "sent": "And if I look at this picture by itself, seeing X to predict why this is inference.",
                    "label": 0
                },
                {
                    "sent": "How are we going to modify this model?",
                    "label": 0
                },
                {
                    "sent": "We're going to add another layer which is adversary here.",
                    "label": 0
                },
                {
                    "sent": "The adversary in our model can observe EIX and given X.",
                    "label": 0
                },
                {
                    "sent": "You can modify to.",
                    "label": 0
                },
                {
                    "sent": "To a new value so it will allow the adversary arbitrarily to do a modification.",
                    "label": 0
                },
                {
                    "sent": "It's probably hopeless, but what will restrict the adversary will restrict him to some set of things that you can modify.",
                    "label": 0
                },
                {
                    "sent": "So given the X&Y, there is some set of things that you can modify.",
                    "label": 0
                },
                {
                    "sent": "X into let me see.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Giving it a more formal model so we have a label which is the Y it's a Boolean label.",
                    "label": 0
                },
                {
                    "sent": "We have signals X.",
                    "label": 0
                },
                {
                    "sent": "Just think of and bit vectors and we have a joint distribution over the inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "We are assuming that there is.",
                    "label": 0
                },
                {
                    "sent": "It's a known pile, so essentially the inference problem is is simple.",
                    "label": 0
                },
                {
                    "sent": "Given the this distribution, you can sort of solve the interest problem.",
                    "label": 0
                },
                {
                    "sent": "We assume the distribution is computable and sampleable and everything is nice with respect to it.",
                    "label": 0
                },
                {
                    "sent": "The main difference that we want to discuss in robustness is the what are you observing?",
                    "label": 0
                },
                {
                    "sent": "So you're observing a different set of attributes, which is really easy.",
                    "label": 0
                },
                {
                    "sent": "So how long is easy build?",
                    "label": 0
                },
                {
                    "sent": "So this build is for any X&Y.",
                    "label": 0
                },
                {
                    "sent": "There is a set of things that we can map.",
                    "label": 0
                },
                {
                    "sent": "X in two, so this is the role of wife in X.",
                    "label": 0
                },
                {
                    "sent": "Will assume that is computed in polynomial time, given X&Y, because we want efficient algorithms and really the adversary is the one who sort of gets to decide which Z is is selected.",
                    "label": 0
                },
                {
                    "sent": "Justice to have a concrete example in mind, think that.",
                    "label": 0
                },
                {
                    "sent": "Given X, the possible corruption is to take one of the axes and bits and we can take one of the end bits and flip it.",
                    "label": 0
                },
                {
                    "sent": "So this is a very simple example.",
                    "label": 0
                },
                {
                    "sent": "We have a Hamming distance one.",
                    "label": 0
                },
                {
                    "sent": "This is our set easily computable and now sort of what would happen when the adversary can flip one.",
                    "label": 0
                },
                {
                    "sent": "We will return to this examples in a few minutes.",
                    "label": 0
                },
                {
                    "sent": "What is our goal?",
                    "label": 0
                },
                {
                    "sent": "We would like to to build a prediction and prediction is now observing Z and given the observation of Z it would like to predict.",
                    "label": 0
                },
                {
                    "sent": "The beat why?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far the predictor will observe the.",
                    "label": 0
                },
                {
                    "sent": "This is observed signal.",
                    "label": 0
                },
                {
                    "sent": "We predict why, which implicitly means that we are defining a policy policy that Maps this into predictions.",
                    "label": 0
                },
                {
                    "sent": "Prediction could be probabilistic.",
                    "label": 0
                },
                {
                    "sent": "The adversary.",
                    "label": 0
                },
                {
                    "sent": "Task, on the other hand, is given X&Y.",
                    "label": 0
                },
                {
                    "sent": "To select the Z to decide how to corrupt Toulouse, do see of Winx is sort of the policy of the adversary how to corrupt given the true value is Y&X.",
                    "label": 0
                },
                {
                    "sent": "So now if we have a predictor in an adversary I almost built in a way that it's clear that the right thing to do here is the game between the two 60 sum game between the predictor and the adversary, and what we would like to observe as a value is the arrow.",
                    "label": 0
                },
                {
                    "sent": "So if you fix the policy of the predictor.",
                    "label": 0
                },
                {
                    "sent": "And the policy of the adversary.",
                    "label": 0
                },
                {
                    "sent": "So his pie for prediction in C. For corruption we can compute a the error rate, right?",
                    "label": 0
                },
                {
                    "sent": "This is a probability.",
                    "label": 0
                },
                {
                    "sent": "This is an expectation over double the true wine X was the probability that.",
                    "label": 0
                },
                {
                    "sent": "The prediction is incorrect.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now, given that we have a value, we can now look it's a 0 sum game.",
                    "label": 0
                },
                {
                    "sent": "We have a value of the game, so the optimal error rate that you can hope to achieve is it like you would like to have.",
                    "label": 0
                },
                {
                    "sent": "To find really a policy which minimizes the error, assuming that the adversary is going to select the worst case that he can.",
                    "label": 0
                },
                {
                    "sent": "So Aerostar is going to be the value of the game.",
                    "label": 0
                },
                {
                    "sent": "And we're not going to to get.",
                    "label": 0
                },
                {
                    "sent": "Exactly the value of a game, but we sort of be able to get almost the value of a game so epsilon optimal would really mean that you're just epsilon away from the value of the game.",
                    "label": 0
                },
                {
                    "sent": "So that's our main result for inference.",
                    "label": 0
                },
                {
                    "sent": "For the inference setting.",
                    "label": 0
                },
                {
                    "sent": "So basically we have a distribution.",
                    "label": 0
                },
                {
                    "sent": "It's known it's computable and.",
                    "label": 0
                },
                {
                    "sent": "Where is it possible corruption so basically?",
                    "label": 0
                },
                {
                    "sent": "Given an excellent why, we know how.",
                    "label": 0
                },
                {
                    "sent": "What are the possible mappings that can go with X&Y?",
                    "label": 0
                },
                {
                    "sent": "What is our main result with for any distribution given the observable sync signal, we can compute the prediction for Y. I will L would be near optimal epsilon optimal and the algorithm is going to be efficient, efficient with minutes.",
                    "label": 1
                },
                {
                    "sent": "If you think of the accesses N bits, it's going to run in time.",
                    "label": 0
                },
                {
                    "sent": "Polynomial in N. It is unfortunately good go going to running times which is exponential in the number of.",
                    "label": 0
                },
                {
                    "sent": "Or things that you can map into.",
                    "label": 0
                },
                {
                    "sent": "But the main issue is that.",
                    "label": 0
                },
                {
                    "sent": "For N bit strings, it's going to be a polynomial time algorithm.",
                    "label": 0
                },
                {
                    "sent": "I should mention here that in a previous work with motion and holding a vehicle instead, we looked in in the last order.",
                    "label": 0
                },
                {
                    "sent": "We looked at the static setting so where the adversary circuit can select the modification rule independent of the expertise is realized and we given a fairly different efficient algorithm in that setting.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main result we have.",
                    "label": 1
                },
                {
                    "sent": "For learning software really two parts in the paper, one is influence and one is learning.",
                    "label": 1
                },
                {
                    "sent": "In the learning setting is.",
                    "label": 0
                },
                {
                    "sent": "Is much more in line with what most of you are familiar with.",
                    "label": 0
                },
                {
                    "sent": "This is why I'm going to spend much less time in the talk about it.",
                    "label": 0
                },
                {
                    "sent": "So you have a distribution.",
                    "label": 1
                },
                {
                    "sent": "It's unknown, it's arbitrary.",
                    "label": 0
                },
                {
                    "sent": "You're going to observe a training set.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, we need to assume that the examples are uncorrupted, but you need to plan for for a bit future for a raining day that really that the future test example are going to be corrupted by the adversary, you have a prothesis class from which would like to to select the best hypothesis under those conditions and we'll assume also that you're given an Oracle that can minimize the risk with respect to this class, and the goal is really to select the hypothesis for age, or really a mixture of a process from age with can minimize.",
                    "label": 1
                },
                {
                    "sent": "The aeillo under this adversarial model.",
                    "label": 0
                },
                {
                    "sent": "Any sort of.",
                    "label": 0
                },
                {
                    "sent": "We have two things to resort with short of combine into one.",
                    "label": 1
                },
                {
                    "sent": "The first is given a sample we can compute efficiently a mixture.",
                    "label": 0
                },
                {
                    "sent": "Of the hypothesis, which is near optimal for this set.",
                    "label": 0
                },
                {
                    "sent": "So given a training set we can find.",
                    "label": 0
                },
                {
                    "sent": "Aneel optimally prothesis for this training set.",
                    "label": 0
                },
                {
                    "sent": "And the second thing is that we have a generalization result if our training set is large enough, then with high probability.",
                    "label": 0
                },
                {
                    "sent": "The two arrow and the observed arrow have is very small difference.",
                    "label": 0
                },
                {
                    "sent": "Notice attorney generalization result.",
                    "label": 0
                },
                {
                    "sent": "Is it is not as straightforward as we're sort of used to because there is an adversary and the adversary has a huge flexibility on farm modifying things.",
                    "label": 0
                },
                {
                    "sent": "But still with you can we can get.",
                    "label": 0
                },
                {
                    "sent": "A generalization bar, so basically if we take a large enough training set, we can learn and it's going to be close to the optimal thing.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is this.",
                    "label": 0
                },
                {
                    "sent": "I think in this title tried to explain why does it make a difference in how does it make a difference that you want to learn the robust in or just regular learning.",
                    "label": 1
                },
                {
                    "sent": "So think about learning hyperplanes, homogeneous hyperplanes, regular learning means minimizing the error, large margin is you want to minimize the error within margin.",
                    "label": 0
                },
                {
                    "sent": "And let's add an adversary that can take one of the attributes and flip them to zero.",
                    "label": 0
                },
                {
                    "sent": "What would it make?",
                    "label": 1
                },
                {
                    "sent": "For simplicity, let's fix a uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you think of it about the problem statically, we know exactly what the adversary is going to do.",
                    "label": 0
                },
                {
                    "sent": "He's going to pick, given a weight is going to pick the attribute it belongs to the highest weight.",
                    "label": 0
                },
                {
                    "sent": "And he's going to zero it out, so really would like to minimize over WS, but in some sense you have a margin that depends on the on the W feeling the adaptive setting which are in here.",
                    "label": 0
                },
                {
                    "sent": "It's slightly even more complex, but the adversary would do is sort of taking it really an attribute.",
                    "label": 0
                },
                {
                    "sent": "Who's signal is correct?",
                    "label": 0
                },
                {
                    "sent": "And it's sort of going to zero it out.",
                    "label": 0
                },
                {
                    "sent": "The bottom line here is that.",
                    "label": 0
                },
                {
                    "sent": "What you when you have robustness really what you really would like is to spread things along the different attribute.",
                    "label": 0
                },
                {
                    "sent": "It's just the reverse of what you expect that you want sparsity in order to avoid robot in order to enable robustness you want the anti sparsity.",
                    "label": 0
                },
                {
                    "sent": "And therefore you have a margin with really depends.",
                    "label": 0
                },
                {
                    "sent": "On the weight vector itself.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So they would like to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of to give a very quick overview of sort of the techniques in the tools, because at least I find them very interesting and you're here to hear.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so let's like to to model the setting on the one inside we have a corruption graph which really Maps inputs into possible corruptions.",
                    "label": 1
                },
                {
                    "sent": "So this is 1 bipartite graph.",
                    "label": 1
                },
                {
                    "sent": "On the other hand we have an interference graph.",
                    "label": 0
                },
                {
                    "sent": "So take all the possible inputs and divide them into those which are positive and negative spam and not spam and put an edge between the two.",
                    "label": 0
                },
                {
                    "sent": "If you can map them both to the same corrupted input.",
                    "label": 0
                },
                {
                    "sent": "So this is going to be the interference graph.",
                    "label": 0
                },
                {
                    "sent": "We will have wait.",
                    "label": 0
                },
                {
                    "sent": "On on the on the note, but let's assume for now is the uniform distribution, so we can ignore those weights.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The optimal policy would look like, so the optimal policy here is what the adversary can do.",
                    "label": 0
                },
                {
                    "sent": "The adversary can find the matching.",
                    "label": 0
                },
                {
                    "sent": "And basically, if one of those things would come up, it will map them to a value with confuses in them too.",
                    "label": 0
                },
                {
                    "sent": "So basically for each edge it can get one error and therefore the number of errors is at least the number of matchings.",
                    "label": 0
                },
                {
                    "sent": "Now what can they predict or do?",
                    "label": 0
                },
                {
                    "sent": "So what we show is that predictor can build a policy which is built on a vertex cover and can guarantee that the number of errors is most number of the size of the vertex cover.",
                    "label": 0
                },
                {
                    "sent": "So for bipartite graphs maximum matchings equals minimum vertex cover and this implies that those two are the optimal policy.",
                    "label": 1
                },
                {
                    "sent": "I just didn't tell you what what was this policy.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we have an optimal policy.",
                    "label": 0
                },
                {
                    "sent": "It's computed efficiently, but deficient in what in the size of X?",
                    "label": 1
                },
                {
                    "sent": "So if you think about N bit strength it sufficient in two to the end.",
                    "label": 0
                },
                {
                    "sent": "How can we hope?",
                    "label": 0
                },
                {
                    "sent": "To get around it so in order to get around it, we cannot even inspect the entire graph.",
                    "label": 1
                },
                {
                    "sent": "So really what we need is local computation algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the next 2 minutes I'm going to give you a brief overview of local computation algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what is the local computation algorithm?",
                    "label": 0
                },
                {
                    "sent": "It really sort of for a matching problem.",
                    "label": 0
                },
                {
                    "sent": "Would say I would like to match.",
                    "label": 0
                },
                {
                    "sent": "A person to a food or a vegetable, and I don't want to have the matching explicit, but I would like just to be able to answer a query that given, let's say a person who is it matched or given an edge.",
                    "label": 0
                },
                {
                    "sent": "Is this edge part of the matching?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for local computation algorithm you have on the one inside the graph.",
                    "label": 1
                },
                {
                    "sent": "We have an implicit output which sort of you're shooting for is a matching.",
                    "label": 0
                },
                {
                    "sent": "You'd like to always maintain correctness, which is feasibility.",
                    "label": 0
                },
                {
                    "sent": "Whatever you say yes is a matching, so you can say all the edges if they are not in the matching but would like also performance to be near optimal.",
                    "label": 1
                },
                {
                    "sent": "So local computation algorithm would have queries.",
                    "label": 0
                },
                {
                    "sent": "So it takes to answer whether an edge is in the matching or not in this example.",
                    "label": 0
                },
                {
                    "sent": "It has.",
                    "label": 0
                },
                {
                    "sent": "It can probe the graph.",
                    "label": 0
                },
                {
                    "sent": "With the edges really exist in the original graph.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And can reply and what his main aim is to reply in times logarithmic so log in our graph size would really mean polynomial time and without any break computational storage.",
                    "label": 0
                },
                {
                    "sent": "And there are algorithms known for the matching.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Formatting would like to go to vertex cover, so the classic the classical way of going from maximum matching to minimum vertex cover.",
                    "label": 1
                },
                {
                    "sent": "The challenge here is that we don't really have a maximum matching, but we have an approximate maximum matching.",
                    "label": 0
                },
                {
                    "sent": "And we do really sort of look on how in approximate maximum matching doesn't translate well to.",
                    "label": 0
                },
                {
                    "sent": "Two, if you do the same translation, it wouldn't translate to something approximate minimum because it's a maximization problem versus a minimization problem.",
                    "label": 1
                },
                {
                    "sent": "So we sort of give a randomized algorithm we can.",
                    "label": 0
                },
                {
                    "sent": "Do also the approximation for the vertex cover and hopefully I'm ending with this slide so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maintains hopefully I convinced you that robustness is an interesting issue, is definitely interesting in practice, and I think it's also interesting in theory.",
                    "label": 0
                },
                {
                    "sent": "I sort of sketch the ideas of robust inference.",
                    "label": 0
                },
                {
                    "sent": "I think that one of the things that is interesting is that you get a very nice and clean connection.",
                    "label": 0
                },
                {
                    "sent": "To graph properties.",
                    "label": 0
                },
                {
                    "sent": "And it gives like for me it gives a very natural domain to local algorithms, because the fact that you need to create a running time which is logarithmic in the graph size, it's very natural for the learning.",
                    "label": 1
                },
                {
                    "sent": "I very vaguely described it.",
                    "label": 0
                },
                {
                    "sent": "If you have more like to know more, go ahead and read the paper.",
                    "label": 0
                },
                {
                    "sent": "Ask me ask Rob and will be glad to answer.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}