{
    "id": "k66llnkafw42qoxd7bbnqdlwwl7jepth",
    "title": "Learning to Compare",
    "info": {
        "author": [
            "Graham Taylor, School of Engineering, University of Guelph"
        ],
        "published": "Sept. 13, 2015",
        "recorded": "August 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2015_taylor_learning_compare/",
    "segmentation": [
        [
            "OK, thank you very much.",
            "Thanks again to the organizers, Yahshua Ann, Roland and Erin.",
            "I think it's also involved in this for inviting me here today.",
            "It's great to see this amazing, diverse audience and I've only been here.",
            "I just arrived last night so the two talks I saw today have been fantastic and I'm happy to be able to build on some of the previous work.",
            "I'm not going to be talking a lot about algorithms or architectures per say.",
            "I'm going to use some of the.",
            "Architectures that were already developed in the previous lecture and talk about a different type of problem, so we focused a lot on the Community, has focused a lot on recognition or detection tasks with deep learning.",
            "I'm going to talk about a different family of applications, which is some people called distance learning or similarity learning or distance metric or distance measure goes by different names.",
            "I like just to say, learning to compare because we're going to have learning methods that can compare examples so."
        ],
        [
            "In terms of the overview of this talk, the metric learning or distance metric learning field is absolutely huge.",
            "I'm not going to be able to do a complete survey of the entire field, but I will focus on representation learning an feature learning techniques as they apply to this field.",
            "So basically this picture I'm going to keep referring to here is I'm going to be talking about taking images of people or objects that are perceptually similar and being able to map them into a space or a manifold.",
            "In which the observations that are perceptually similar or nearby in this space, and similarly some of these methods that will talk about will actually take points that are dissimilar and ensure that they live far apart in these manifolds so."
        ],
        [
            "The types of applications that I will hit on today I'll talk about about document retrieval.",
            "I will talk about finding people in similar poses like I've shown here and at the end I'll even talk about zero shot learning, which I think Hong Lat started to talk about but ran out of time.",
            "So I think that's great.",
            "We're thinking along the same line, so I will pick up at the end of the presentation where he left off.",
            "I will try.",
            "I'll try not to."
        ],
        [
            "Yeah.",
            "My guess is that will be OK for time, but well, I've got a timer here in front of me, so I'll be conscious of that.",
            "So OK, so learning similarity, learning similarity, it's a fundamental operation in many applications within machine learning and computer vision.",
            "So the idea here is that we want to determine similarity.",
            "Often I'm going to be talking about images, but doesn't have to be image data.",
            "It could be objects in general, so we wanted to have some sort of learning system that can take for example a pair of objects and output a number that describes how similar they are.",
            "Most notable applications of this are retrieval based methods, so document retrieval, image retrieval people are probably familiar with Google Image Search and also nearest neighbor methods, so there's nearest neighbor methods for classification, regression and so forth.",
            "Those all require a means of computing similarity.",
            "So when we talk about similarity, we usually have some notion of perceptual similarity.",
            "I'm showing you here a picture of people that are all in the same pose.",
            "This is my favorite example of this because the.",
            "Image content with the pixel content of these images is completely different, so if you were to compute Euclidean distance in pixel space, that would really tell you nothing about whether these people are holding up their hand in the same position or not OK, so pixel distance or pixel distance or input distance as computed by Euclidean distance measure usually is not informative of perceptual similarity, so.",
            "The other problem with computing distances, for example in pixel space, is very expensive.",
            "OK, so it's not an efficient thing to do.",
            "Images are high dimensional, so we want to do finding images that are similar and learn very large databases.",
            "We're not going to be computing Euclidean distances on images, so the idea here is to learn these parametric embeddings so that perceptual similarity is captured in the embedding space, and typically the way that will go about this is we will learn codes.",
            "That are low dimensional such that these similarities can be computed rather efficiently.",
            "An important part of this again, is, like has been already mentioned in some of the other talks, learning these embeddings such that their invariant to certain factors of variation.",
            "So we want to do in our embedding is highlight the important stuff.",
            "So in this example, let's suppose it might not be domain specific, might not be as simple as pose.",
            "It might refer to a large number of similarity attributes.",
            "For example, let's use is to say we want to find similar images right on Google Image Search.",
            "That may not just depend on pose, it could depend on many things.",
            "But we want to focus on those things that are important and sort of downgrade the other factors of."
        ],
        [
            "Creation.",
            "OK, so the key question in setting up this problem is where does this similarity information come from and the way I'm going to set up this talk is is talking really dividing it up into answers for this question."
        ],
        [
            "OK, so the typical setup that I'm going to be using today is that I'm going to map an input.",
            "I'm going to call the input X through some function.",
            "It may be very complicated and nonlinear, like a neural net, and I'm going to produce a code and will call the code said I'm also."
        ],
        [
            "Take another input and pass it through the same functional mapping, and that's going to produce another code.",
            "The code is going to be different because it has a different input to start with, but these functional mappings are the same, and then I'm going to compare."
        ],
        [
            "Distances and we're hoping to see is that the distance in the embedding space is capturing perceptual similarity, whereas the distance in the input space was non informative."
        ],
        [
            "OK, so one motivation I mentioned for these techniques are nearest neighbor methods and there is some work a number of years ago boiman and colleagues have a paper called in defense of nearest neighbor.",
            "It's a nice paper because they look back on nearest neighbor and they say many of the things that were wrong about the way that people applied nearest neighbor.",
            "One of the problems with nearest neighbor.",
            "Basically the way that features are typically computed.",
            "Another problem with nearest neighbor, the way that people often apply it is that they use what's called an image to image type of distance.",
            "So they take a query.",
            "And they compare that query to every single image in the database and they find the the neighbors, the ones that are most similar.",
            "OK, so we called the nearest neighbors Boiman and colleagues propose a different technique where they wish they call image to class.",
            "So the idea is to go and take a query image and go inside every class and compare it to the examples in that class and produce a single number representing how similar that image Ware was.",
            "Two examples in the class.",
            "So here's a picture of this so.",
            "Have you take this query image?",
            "And you look at each of these examples within this class individually.",
            "It actually might not be similar.",
            "Say we have a similar measure here between this query and these different examples, so we're comparing it sort of image to image.",
            "It's not very similar, but when we compare it to the entire class and let all of the images within the class essentially explain this image and you can see by color what parts of this image are being explained by each of the images in this class.",
            "We actually have a small distance in that space.",
            "OK, so this is the notion of image to class.",
            "I'll get back to this a little bit later on.",
            "Nearest neighbor methods are pretty fast, especially when you combine them with approximate methods or hashing techniques, which we'll talk about later, and they can generalize the new classes at basically no cost.",
            "So there are some some motivations for using."
        ],
        [
            "The other motivation for this similarity learning is retrieval.",
            "In very large databases, so this is a Google data center, one of many, and as these databases grow large, the ability to learn these compact representations and determine similarity very quickly becomes more and more important.",
            "So hashing algorithms which are going to encode objects into compact binary codes to preserve similarity are particularly useful in this setting and will describe.",
            "What hashing is a little bit later on?"
        ],
        [
            "OK, so that's just the intro of this talk.",
            "Now let me just give you an outline of how I'm going to proceed, so I said I'm going to base this on how to determine similarity.",
            "So the first type of similarity learning is going to assume that you have no external information about the similarity amongst objects in your training set, so nobody has given you some some indication or no teacher has said these examples are similar.",
            "These ones are dissimilar.",
            "You're just going to rely on good unsupervised learning or representation learning algorithms.",
            "The next."
        ],
        [
            "Passive algorithms are going to allow you to utilize some external information, so this will often come.",
            "In the form of class information.",
            "So we'll see objects that lie within the same class should be similar objects that are in different classes or not similar.",
            "It may come in the form of a neighborhood graph, so we have may have much more structured information saying which objects are similar to one another in the form of the graph, and then we may have some techniques that are derived, for example from queries on the Internet.",
            "So this has been a popular method of determining similarity.",
            "Recently"
        ],
        [
            "Final technique I'll be talking about are weakly supervised techniques, so it fits somewhere between unsupervised and supervised learning.",
            "The idea is that you don't have very rich information about similarity, but you're going to capture it from some other mechanism."
        ],
        [
            "OK.",
            "So the unsupervised learning approach says let's do our best to utilize these models that we've already been talking about in the summer school.",
            "Are BMS, autoencoders and so forth.",
            "We're going to rely on their ability to learn good representations.",
            "But instead of using the representations, learn from these algorithms and feeding them into, say, for example, a classification model, we're going to focus on computing distances, typically in the higher levels of these representation learning algorithms to do this efficiently.",
            "Like I mentioned before, often in these architectures that are used for similarity learning.",
            "We're going to restrict the representations to be smaller bottlenecked."
        ],
        [
            "Classical methods for doing this have typically derived from directed graphical models, so there's essentially latent semantic analysis and its variants have been popular.",
            "They're very simple techniques, they're fast, they're reasonably effective.",
            "But the problem with using these directed graphical models is the difficulty in performing inference, and when we want to do very large scale, look up some databases and do this very efficiently, methods.",
            "Using Gibbs sampling MCMC to be able to discover these representations don't seem like a good fit.",
            "Now there is a recent family of methods called variational autoencoders and their variants, which people are very excited about.",
            "These are directed graphical models, but they maintain a separate inference procedure, which is very efficient, and I think Hugo Libor.",
            "She'll be talking about these methods in his talk.",
            "I won't go into the details of these right now, but this might be.",
            "I haven't seen any papers doing similarity learning with these types of techniques, but it might be a few future Avenue of.",
            "Research.",
            "Oh, Aaron will talk about them.",
            "OK, excellent.",
            "So this is for a future talk."
        ],
        [
            "OK, so typically what we're going to do is we can't rely on directed graphical models as we will rely on undirected models where inference is fast and the first techniques that sort of stemmed from the the emergence of the beginnings of the deep learning field were sort of 2005 2007.",
            "Max Welling took our BMS, which were typically binary valued observations, binary valued hedons and he was able to generalize them to general exponential family distributions.",
            "What allowed him to do?",
            "With model integer counts, which were useful way of representing documents OK, and we'll hear more about document representations when we have the NLP lectures.",
            "Wrestling Cela Kutna fan Geoff Hinton went to step further and built very deep techniques based on our BMS and that's the first thing I'd like to talk about in terms of on super."
        ],
        [
            "Learning.",
            "So the building block or the first building block of the semantic hashing technique proposed by Russ and Jeff is something called the constrained passam model, and this is a special type of GBM that's effective modeling integer word counts.",
            "So there's a picture of this model up here.",
            "It just looks like a standard PBM, so it keeps all of the favorable properties that you've already learned about of our BMS.",
            "It has a little bit of specialized machinery to cope with variable world word lengths.",
            "And so one way of interpreting these visible units.",
            "Always integers, so each of these visibles represents a particular word, and the integer is how many times it occurs in a particular document.",
            "You can also take another view where you just divide each of the visible vectors by the total number of words in the document, so we'll call that N, and you can and then you can view these visibles as probabilities, so the probabilities of a word occurring, and then every time you want to sample a word, you're not sampling a document at once.",
            "You're sampling from this RBM multiple times, one for each word in the document.",
            "So you sample at end times for.",
            "Acument of length N when you when you normalize this way you have to be careful to multiply the upgoing waits by the number of words in the document, but there's some nice stability properties associated with doing this and it also allows you to cope with varying document links, so this quick constrained puts on model what you need to remember is just it's an efficient way of representing integer data, and this forms the first layer of a deeper model."
        ],
        [
            "So the way that they rolled this out as a train, what's called a deep autoencoder, and I guess we've already spoken about deep autoencoders.",
            "A little bit.",
            "Paschall OK so Pascals talked about autoencoders.",
            "This approach was very popular in this the early days of deep learning.",
            "Training a deep autoencoder by pre training it with our."
        ],
        [
            "M's so the idea is that you would start with this constraint plus on binary RBM which models word counts and you learn a binary representation of the document.",
            "OK, so this takes the integer words and it encodes it into a series of binary features.",
            "Then you would take a binary to binary RBM and learn another layer.",
            "Features on top of that.",
            "And then you learn another layer of features on top of that, and that would give you something called an encoder.",
            "So Roland was talking about autoencoders.",
            "Today he was talking about single layer autoencoders.",
            "And he talked about the encoder in the decoder.",
            "This is the encoder.",
            "It just happens to consist of multiple layers of representation.",
            "OK, and it's been pre trained with multiple PBM's.",
            "Now once you have that encoded representation, which is typically low dimensional, it becomes what you call your code.",
            "OK, so this isn't encoded document and then we take that an we just transpose."
        ],
        [
            "This is our BMS.",
            "Into the decoder.",
            "OK, so we take the exact same weights that were here, here and here and we do.",
            "It's called unrolling and that is the pre trained deep autoencoder.",
            "So once you've initialized with all these carbs, you've trained each of these PBM separately.",
            "You've unrolled them into the decoder without doing any more training.",
            "Then you can basically fine tune this whole thing using backdrop and use error.",
            "This reconstruction error between what went in as the input and what came out is the output as your error signal.",
            "For learning this this network.",
            "So.",
            "That is a means of deriving a very low dimensional but good representation of the documents in an unsupervised."
        ],
        [
            "Now there's an additional trick that Russ and Jeff used to make.",
            "This method is extremely efficient for modeling documents, in particular for retrieval.",
            "They added noise to the learning process, so they inject a little bit of Gaussian noise during the at the code layer during learning, and this forced the network to be resilient to this noise by encouraging the the code here produced here to be binary close to binary.",
            "So these are these are binary to binary.",
            "IBM's but the outputs are sigmoidal, so basically by injecting noise at force of the value should be very close to 0 or very close to 1.",
            "Even though there are sigmoids and So what happened then is that they could take the codes that were produced and threshold them and there wouldn't be a lot of error introducing that thresholding process because they are already close to binary anyways, yes.",
            "Alright, so well, I guess the idea is if you have sort of an uncertain value in there and you had you had sort of say it's close to .5 and you add noise in there, then the essentially the when you threshold it could essentially go either way, whereas if the if you're adding noise and it moves closer to zero or one then you sort of made a representation that's resilient to any sort of thresholding type of error.",
            "Set as your question, do a better.",
            "Do you have a better answer?",
            "You don't.",
            "You don't look pretty happy with that answer.",
            "Yeah.",
            "Yep.",
            "The error that you would like.",
            "You can view it as a regular.",
            "Yep.",
            "You can view.",
            "I mean people use, not.",
            "They use inject noise not just for this reason as well as the four squares to be binary, but these are regularizer as well.",
            "So it's another way of inducing weight weight decay.",
            "So it's related to that.",
            "OK. Back there.",
            "Oh OK, yeah, thank you.",
            "Yeah, I was going to say I wasn't sure.",
            "Next slide, I'll get to that in one second.",
            "Yeah, that's an import."
        ],
        [
            "Question OK so the.",
            "Title of this slide.",
            "Extremely fast retrieval.",
            "OK, so if you have binary codes essentially, but you can use is, you can use a hash table which allows you to find the codes that are closest to the query, sort of a Hamming.",
            "They call it a Hamming ball or Hamming radius.",
            "An constant time essentially so you don't have to do linear search over your entire database of code, so you can do very fast retrieval and we have in a couple of slides will go through exactly how that works.",
            "So this is the main point here.",
            "You could retrieve these similar documents to your query with essentially no search.",
            "OK, so it's time sub linear in the size of your database.",
            "Now if you do this thresholding to the directed model latent semantic analysis, so you just it produces continuous valued codes and so you just threshold them and try to do this fast.",
            "Look up.",
            "It actually significantly reduces the performance of that mechanism because the codes that LSA produce weren't trained to be.",
            "Good binary representations.",
            "So a weakness here is that even though you'll find once you go, you take a query, you find it where it is in this binary embedded space, and you look at the documents around it.",
            "Those documents around it are going to be good hits.",
            "OK, so they're going to be similar, but if you take 2 documents that are similar and you embed them, there's no guarantee that they're going to lie in the same location.",
            "Embedding space.",
            "OK, so two similar documents might still be embedded far away in other ways of thinking about that, so we'll talk a little bit later about how we can sort of force them together.",
            "That's going to be used through suits unsupervised learning, so the question here is can we use external information like labels to pull them together?",
            "Yes we can, but let's let's wait a few slides to figure out how that works."
        ],
        [
            "OK, so I want to go back to this idea of hashing.",
            "So in Russ and Jeff's experience experiments using semantic hashing, they typically kept the dimensionality low, so they're using basically 20 bits for their code, others are using 3032 bits and so forth.",
            "You can use this trick where you use the basically the binary codes themselves as direct indices to some hash table, and so you can do find nearest neighbors with no search.",
            "The problem is, once you start using code links that are much larger than 32 bits.",
            "This procedure kind of breaks down because the amount of neighbors that get retrieved within a certain Hamming radius or Hamming ball blows up near exponentially once you get.",
            "Pretty high dimensional codes and the other part important point to make is that larger codes typically work better, so you kind of you're motivated to use larger codes, but they're less efficient, and so Mohammed noroozi from University of Toronto and David fleet have some work where they did.",
            "Some studies on this, so I guess the here's the curves that they published.",
            "They're showing you for different code links if you take a particular Hamming radius around, look around a query and you look at how many neighbors so.",
            "For example, a Hamming radius of 6 would mean how many other documents or.",
            "Differ by 6 bits or less to that query and you'll see with 32 bits it's reasonable, but as soon as you get to 64 bits, if you're looking at a Hamming radius of 7 bits, you're getting about a billion hits.",
            "OK, and typically you're not going to have a database of a billion.",
            "I mean for large scale applications you might get there, but that's that's a problem.",
            "OK, so in that case, if your database is smaller than a billion, it's better to just do a linear search over all the documents, right?",
            "So what they've done is?",
            "They've proposed some much better technique for doing hashing called multiindex hashing.",
            "Now the other thing, the other plot that they made, which is important to look at, is there's a little bit of uncertainty in terms of.",
            "What hamming radius you need to consider when you're doing nearest neighbor look up.",
            "So typically the at application time you're trying to find the K nearest neighbors of a document document, or the most similar similar neighbors.",
            "You're not typically looking for how many documents lie around inside this Hamming ball so, but there is uncertainty in terms of how big that radius needs to be.",
            "Depending on your data set.",
            "So they took a data set called it was 1 billion examples of SIFT features.",
            "And they essentially did some statistics on.",
            "You know, for a given number of nearest neighbors, so 10 or 100 nearest neighbors, what was the Hamming radius or Hamming ball?",
            "You need to search, right?",
            "And there's some uncertainty.",
            "There's variability there, so for 128 bit codes you're getting upwards of 15, sort of 20 Hamming radius, right?",
            "And so then you're dealing way way way up here, like massive number of retreat results.",
            "OK, So what do you do?",
            "Well if you are."
        ],
        [
            "In this problem you should turn to Newsies code so he has on GitHub and he has this technique called multiindex hashing and so he has an algorithm that is approvable Y sub linear in the number of documents in your database or images in your database.",
            "And so you know the key idea here is that if you have.",
            "Binary codes of qubits.",
            "You're going to have two to the Q possible codes, but that's typically much, much larger than your database.",
            "OK, when you're using a large number for Q, So what you're going to do in this algorithm is you're going to start collapsing buckets so you can do a much more efficient, efficient search.",
            "So the way that they go about this is they essentially take these binary codes.",
            "You can see them like this, and they break them up into M subgroups, and they do a hash on.",
            "Each of these individually and essentially this is allowing them to sort of collapse this space, and when you are given a query code, you go search for the.",
            "Neighbors within a Hamming ball in each of these sub sequences and they have some very nice theory to show that you're guaranteed in.",
            "You know in all of these searches to find the nearest neighbors that you're looking for.",
            "OK, so it is actually exact, but it's just much more efficient than doing search on the entire code.",
            "There's there question back there.",
            "OK, so the question is, what's the likelihood that you're going to see uniformly distributed codes?",
            "That depends on the learning technique.",
            "The technique that's actually getting your code.",
            "So now we're talking about hashing.",
            "This hashing can actually be used with any types of binary codes that can be generated.",
            "It's independent of the algorithm that produces the codes themselves.",
            "So to answer your question.",
            "Depends on the algorithm.",
            "Now different hashing techniques will produce different levels of uniform code, so you might, if that's it.",
            "It's generally for this theory to work.",
            "It depends on uniform code, so you should choose a technique that sort of should give you uniformity.",
            "OK. And some some techniques are more explicit than others, like for example spectral hashing that's made explicit in its objective function to ensure they're looking for independence in the observations, and they relax that to sort of being uncorrelated.",
            "OK, so locality sensitive hashing there there are similar motivation.",
            "It's just again this is kind of getting back the same question.",
            "The algorithms for determining the hash codes are different, so locality sensitive hashing is using random prediction projections.",
            "The this technique that we just talked about for example deep autoencoders and semantic hashing are using learning, so representation learning.",
            "To discover the hashes now this algorithm, whether you straight up hashing or the multiindex hashing, is independent of whether you used semantic hashing or spectral hashing or LSH.",
            "OK, so whether this is different than LSH, it's not really a matter of whether this multiindex hashing is different, because this can be used with anything, but there is certainly a difference between semantic hashing and LSH.",
            "OK cool, let's move on."
        ],
        [
            "OK, so that concludes the unsupervised learning portion of this talk.",
            "The next thing I want to talk about now is this problem that we talked about before of the fact that you might take points which are similar in embed them and they actually lie very far apart.",
            "So what we're going to use now is this setup where we're going to actually show the network.",
            "So imagine this is a neural network or a convolutional network will will define that later on you're showing it pairs of examples and if those are examples you know should be similar, then those should form a small distance in their code.",
            "OK, I'm not necessarily going to restrict the codes to be binary at this point forward, but we're just going to produce some vector that's usually low dimensional and we want it to be small for examples."
        ],
        [
            "You know are similar, and then we're going to feed it examples that we know are dissimilar, and we're going to want to force it to have a large distance in code space.",
            "OK, the key change now is that we actually have some label information or is external information that's telling us that those examples should be similar or not."
        ],
        [
            "OK, so this idea of Siamese neural networks it's not new, so this goes back to at least the 90s and there was being considered by different groups at the same time and I was sort of all discovered with Pierre ability.",
            "Sue Becker, Jeff Hinton.",
            "And then this was a group at Bell Labs, I think at the time Jan Luken was involved with this project and they were actually doing signature verification.",
            "So this is this is like early days of comments.",
            "They're doing 1D convolutional net.",
            "Signatures and they had.",
            "This is a Siamese network from from the 90s.",
            "Now according to Jan what they didn't really get right was the objective function.",
            "So they had the part of the objective function that said, take similar examples and embed them to nearby locations in the embedded space, but they didn't have a contrastive term.",
            "They had, they had nothing.",
            "That said, the examples that are far apart should be separated.",
            "OK, so according to you on the embedding kind of collapsed and the other thing is they didn't have a lot of data so.",
            "It was it worked reasonably well, but it wasn't.",
            "It wasn't a massive success at the time."
        ],
        [
            "So modern day approaches to Siamese neural networks typically will use convolutional Nets.",
            "Good thing hung like was just here to tell you all about convolutional Nets, so I don't have to spend too much time.",
            "But this is just basically a refresher.",
            "Convolutional Nets are have these three stages, convolution layer, some sort of rectification or contrast normalization, and then some pooling operation and we."
        ],
        [
            "Stack these operations up, but the difference now is that your typical common set Hong Laxman talking about taking As for example, an input image and produce a class label.",
            "The ones that I'm going to be talking about for the remainder of the."
        ],
        [
            "Talk are going to take in pairs of images, and they're going to produce vectors.",
            "And then we're going to really concerned about the distances between those vectors.",
            "At the back, yeah.",
            "Right, so the name Siamese really refers to the pairing of the networks, so it's the fact that you have identical copies, so it might be 2.",
            "In some cases it might be 3.",
            "We'll see later on examples we have 3 copies that all have the same parameters, so this pathway and this pathway are the exact same convolutional net, but we're taking in pairs of inputs instead of a single input.",
            "So in a standard confident you say, put an image in an you get.",
            "A label out there's one pathway in this commnet there's there's two inputs which are two images, and both of these comments produce vectors, and then we compute distances on these vectors.",
            "Which is.",
            "Yeah, so the key is 2.",
            "It might.",
            "It might be more as well identical copies, so the the key concern here is you know really what's the objective function.",
            "So in a typical comment it's clear what that should be.",
            "If you're doing classification, you'll have something related to the accuracy of that classification.",
            "Here it's related to making these distances small for similar examples and making them big for.",
            "Examples that should be far apart.",
            "OK, so the next portion of this talk will really focus on these objectives.",
            "OK."
        ],
        [
            "Alright, so just sort of an overview of the way that these things can be trained.",
            "Typically, Siamese Nets are overall trained by backpropagation, so the procedure is quite similar.",
            "What's being changed versus a regular comnet is at the very top.",
            "How that error metric is defined, and so that the most popular ones are technique called neighborhood components analysis.",
            "So this is a probabilistic objective.",
            "Will talk about that Doctor Limits a really long name which has a nice sounding acronym, and then we have triplet and quadruplet based criterion.",
            "I'll talk about triplets as well.",
            "So go into the."
        ],
        [
            "Details of all these so.",
            "Neighborhood Components Analysis is a technique that was proposed little over 10 years ago by researchers including Sam Royce at University of Toronto and it's it's a popular method.",
            "I think, as it has a very simple explanation, it's trying to.",
            "Maximize the success of K nearest neighbor classification OK?"
        ],
        [
            "Other words, you know we want to minimize classification error.",
            "If we were to use KNN as our classification algorithm.",
            "So the idea of most of you're probably already familiar with KNN, but just quick refresher.",
            "You have a point here.",
            "You don't know it's labeled, so you're going to search a number of nearest neighbors around it and have their classes.",
            "This is binary class.",
            "Vote on what its label should be.",
            "OK, so let's say, let's let's define an error metric or mapping.",
            "We talked about these projections such that the KNN classification error will be minimized.",
            "Now there's a couple of problems with just implementing this in the sort of naive way.",
            "First, that this KNN error is really highly discontinuous function of the parameters of this network.",
            "So the way to think about this is you might you have some mapping that takes a data point, it embeds it in some space.",
            "And then you do KNN in this embedded space.",
            "If you change the parameters of that network ever so slightly, that might suddenly really change this neighborhood structure, right?",
            "And then the votes for the classification would change, so it could be a big big effect.",
            "Or you might wiggle those parameters in that embedding and nothing happens to the neighborhood.",
            "OK, so it's discontinuous and you still need to choose K OK with Canon, So what Jacob Goldberger and colleagues propose to do.",
            "Is to look for a smoother.",
            "But KNN like objective function."
        ],
        [
            "OK, So what they propose is something called stochastic nearest neighbor, and so instead of picking from the set of K nearest neighbors, you're going to try to choose one.",
            "You're going to look at all the points and stochastically choose one with some probability.",
            "So here's point.",
            "XI and XI is going to look at all the other points, and it's going to associate a probability with choosing another point as its neighbor.",
            "OXI will choose XJ as its single neighbor with probability PIJ.",
            "Anne."
        ],
        [
            "How we get that?",
            "Probability is just a little bit of math, but it's not too complicated.",
            "Remember, we're trying to learn this embedding, right?",
            "So XI goes into some mapping or some network.",
            "This could be linear, or it could be a neural net, or it could be confident and outcomes this vector said.",
            "So then we're going to compute you're going to do this for both points I and point J.",
            "We're going to get their embeddings zed.",
            "Then we're going to compute their distances, and so the probability that their neighbors just depend on these distances.",
            "So we're exponentiating, and we're normalizing this distances.",
            "So you can already see what the problem with nearest this this this neighborhood components analysis technique is that it requires this normalization over all of the data points OK, But has this very nice, easily understandable probabilistic interpretation.",
            "Now, so that's how you select neighbors stochastically.",
            "Now, what does this smooth cannon like objective function look like?"
        ],
        [
            "Well, the NCA loss says take these probabilities, and for a given point sum them over only the other points that lie in the same class.",
            "An easier way of saying this is you only want to put probability mass on the guys that are in the same class as you.",
            "OK, so if you sum the probabilities over the class over the class, the best you could do is put all the probability mass on guys are in the same class and that means voting.",
            "They would all vote the correct class for you, right?",
            "So you would get the the KNN classification correct?",
            "So you can.",
            "This is actually smooth because this definition of sorry this definition of."
        ],
        [
            "P is smooth based on the parameters of this model."
        ],
        [
            "So you can differentiate this with respect to the parameters of the embedding and train it by gradient descent.",
            "So it doesn't matter if you're embedding is linear or it's a neural net or com net, you can differentiate this thing with respect to the parameters, as long as each of the steps in that embedding are differentiable.",
            "So it's nice that you can just use SGD or another gradient based optimizer.",
            "It's not so nice because of this normalization term, but there's also no explicit parameter K because we've said let's choose one neighbor stochastically now.",
            "Recently Danny Tarlow at University of Toronto and colleagues there.",
            "Define an NCA based objective for K greater than one and they show it working a little bit better, but it is a bit more complicated."
        ],
        [
            "OK, so let's look at question.",
            "OK, so it's because of that, the denominator, so it's because."
        ],
        [
            "Love.",
            "This bottom bottom term if you just tried to draw them all together, we just sort of push them altogether.",
            "It would collapse, but the fact that you only have so much probability to spread out among amongst the points so that the by nature of being probabilistic, it doesn't collapse.",
            "OK.",
            "Yes, so you have time.",
            "Yes, so this is where the labels come in is it's telling you which points should be close together, right?",
            "It doesn't necessarily have to be class enables, but you have to have some information about where they are and where that's coming into NCA."
        ],
        [
            "Is basically in here you're summing over guys in the same class.",
            "You can extend NCA to non classification tasks as well.",
            "Will talk a little bit about that later on.",
            "Well, because the the embedding is learned, then network can kind of implicitly learn the right scale.",
            "Right?",
            "Yes.",
            "So OK, so I guess one way and what people would typically do in NCS.",
            "They would regularize as well so you know you're shrinking the weights in that case, but I guess the other is some redundancy.",
            "OK."
        ],
        [
            "Alright, so in terms of just looking how NCA looking at how NCA works so these are from some kind of toyish smaller datasets, I think these are the Brendan Frey, Brendan Frey faces, USPS digits which are kind of smaller than M NIST.",
            "If we choose a linear embedding for NCA, and we learn the best setting of this matrix a such that IT projects X to this new vector Z that satisfies at NCA criterion, what is the embedding look like for these different classification problems?",
            "PCA is kind of terrible.",
            "You see, the points aren't well separated.",
            "Same with these other classes, faces are not so bad.",
            "LDA also doesn't work very well, but NCA actually does reasonably well on these toy days.",
            "That's a lot better than the other.",
            "Simple methods Now when you look at."
        ],
        [
            "At M NIS, which is a little bit higher dimensional, NCA actually doesn't work so well.",
            "So now an amnesty review is a toy data set and completely trivial in 2004.",
            "NCA wasn't working well on it, but that wasn't considered a deal breaker.",
            "Now what you can do with NCS, you can extend it to a nonlinear version and we'll talk about that, and it works a lot better."
        ],
        [
            "OK, so nonlinear NCA essentially is just exploiting the fact that this mapping from X to this code space doesn't have to be linear right before in the in the last example we saw was just a matrix A.",
            "We can now replace this with the neural net Russ Salakhutdinov and Jeff Hinton around the same time that they were doing semantic hashing were also experience.",
            "Experimenting with nonlinear NCA, and when they were also training these autoencoders, and they considered doing two things at the same time training and with the NCA criterion.",
            "But also training with an autoencoder objective at the same time to regularize it, and this allows them to take advantage of unlabeled data so they get data points that are unlabeled.",
            "They can just compute error based on the autoencoder objective and for the points that are actually labeled.",
            "Then they can use the NCA objective."
        ],
        [
            "What their network actually looks like.",
            "So we talked about this a little bit earlier using our BMS to train the deep auto encoder.",
            "Same procedure.",
            "So you take an image, you map it to 500 binary units.",
            "You have another 500 Finder 500 by binary RBM.",
            "Another binary RBM to 2000 and in a top layer PBM that produces a compact code.",
            "You then unroll those PBM's into this deep autoencoder.",
            "But the interesting thing here that's happening is that at the very top where you're actually performing the reconstruction, so you're mapping this image down to this low dimensional code.",
            "Then you're reconstructing it.",
            "You're applying the autoencoder loss, but then at the internal the innermost internal representation here that's low dimensional.",
            "You're applying the NCA objective to draw these codes together for images that are in the same class.",
            "OK."
        ],
        [
            "And so when you look at their ability to do an embedding, this is in two dimensions on the emnace data set, it looks way better than the linear case of NCA, 'cause there's a lot more flexibility in that deep net compared to just learning a matrix through the embedding.",
            "OK, so NCA it's nice.",
            "It's kind of general.",
            "You can use it to train any kind of architecture that does the embedding.",
            "You had a question.",
            "Oh, I believe that.",
            "I believe that's test data, but I'm not 100% sure on that.",
            "Yeah, you have to go back in the paper to look at that for details."
        ],
        [
            "However, you know, in the in the architecture that they're using for retrieval, they're using 30 dimensional units, so we're obviously making these."
        ],
        [
            "Lots in in 2 dimensions, so it's it's a different architecture.",
            "OK."
        ],
        [
            "I just wanted to highlight a poster that's going to be here presented by Daniel M, who's in the audience.",
            "So he graduated recently from Guelph at doing a Masters degree.",
            "He's working here at Montreal and going back to this idea of.",
            "Class conditional."
        ],
        [
            "Up image the class distance.",
            "Remember I was saying compared to each of the images in the class instead of looking at each image to image comparison on its own.",
            "So Daniel and I were working out a way of actually doing a sort of using NCS and inspiration."
        ],
        [
            "To learn a stochastic neighbor selection rule that optimizes image to class rather than image the image distance and he's had some results showing that this actually works better than standard NCA.",
            "Again, the limitation of this is it still has a quadratic in the number of points.",
            "You still need to consider a distance from every point every other point, but there's we have some ideas about how to extend that to the linear case, so check out his poster."
        ],
        [
            "I think it's today.",
            "Got today."
        ],
        [
            "OK, so that's the NCA family of criterion.",
            "Now there's also something I mentioned called Doctor Lim, and this is out of the NYU Group, so the advantage of Doctor Lim over NCA is that you don't have this normalization term, so it's no longer probabilistic, but you can do online learning with it, so you only need to care.",
            "Consider pairs of data points at a time.",
            "And so it takes a pretty simple objective function, so you can use this again to training trained Siamese Nets.",
            "Your Siamese Nets output codes and then you determine a loss function that has two terms.",
            "OK, so the first term is called the similarity loss, so this applies when you have similar data points, we're going to assume similar data points.",
            "This SIJ is an Indic binary indicator variable, and it's one when the points are similar, so similar could mean coming from the same class.",
            "So when they're similar, the similarity losses apply.",
            "Dan, this is a quadratic in their distance, right?",
            "So the points should be similar in the same class you're going to pay a quadratic cost, they pay more and more costs to further their apart, and then when they are not similar so they're in different classes and you pay this dissimilarity loss, which is basically the same thing.",
            "It's still quadratic, but it cuts off after a certain point, so it allows dissimilar points to lie outside a window of each other.",
            "And essentially it doesn't care about them once they've fallen outside this margin.",
            "So once this is where you see in the red curve, so the blue curve is a similarity loss.",
            "If points are far apart and they should be the same class, then you pay a cost.",
            "If points are in different classes and their close together, you're going to pay a cost until they get outside this margin.",
            "Another way of looking at this."
        ],
        [
            "Through a spring analogy, so when you're considering a particular point and looking at neighbors within the same or points within the same class, these guys are all being pulled together via that loss function, regardless of how far away they are and the strength of these Springs is going to depend on the distance, right?",
            "And then points that are in different classes, which are the hollow points those guys are repelled.",
            "So these guys are getting repelled, but once they get outside that radius you don't care about them anymore, so.",
            "Basically, the algorithm is not wasting modeling effort on pushing these points further and further away that are coming from different classes.",
            "OK, so the margin.",
            "The Alpha parameter unfortunately is is a hyperparameter needs to be tuned, but people generally.",
            "I mean there's there's not a lot of sensitivity generally in that parameter."
        ],
        [
            "OK, so the the work that considered document proposed Doctor Lim considered this NORB data set.",
            "Who's here heard of Nortb?",
            "OK, a lot of people.",
            "So some people that haven't heard of it.",
            "It's a bunch of images taken of toy objects so airplanes, trucks, cars, people and animals and their capture under different lighting conditions and different azimuth.",
            "So azimuth is this angle around that you're seeing around here and different elevations which you can see sort of overhead the plane versus looking at the side view of the plane and so forth.",
            "And so if you use Doctor Lim to learn an embedding from the NORB data set where you have a very explicitly defined neighborhood graph.",
            "You learn embedding to 3 dimensions.",
            "It gives you something that cylindrical.",
            "So let me just take a second to explain the neighborhood information that was given to this algorithm.",
            "So what it was told is that neighbors should be.",
            "The same object that are within two neighbors away in terms of its azimuth.",
            "So this guy would be neighbors with this guy and this guy as well as this guy and this guy an also.",
            "Ones that are one elevation away so one elevation would be one hop in this direction.",
            "Either way, it doesn't care about lighting, so it's your neighbors regardless of the lighting.",
            "And so when you give Doctor Lim that neighborhood similarity information which is used to define that S variable which points are similar in which are not, then you get this roughly cylindrical embedding.",
            "So it's essentially it's learn to organize these objects at different azimuths around the exterior of the single cylinder and then.",
            "Sort of along the length of the cylinder.",
            "You're getting changes in azimuth lighting.",
            "It is learned to be invariant to lighting, so you'll see essentially clusters of six points together, and those are representing images of different lighting conditions.",
            "They are all embedded closely together.",
            "OK, so again, downside of NCA is having to give it or Doctor Lim is having to give it all this information about the neighborhood class structure to get in a nice embedding like this.",
            "And this was in terms of the architecture that was used.",
            "It was a Siamese confident sort of Lynette 5 style at the back.",
            "Correct top of the top of the cylinder and then the sides of the cylinder.",
            "Yeah, 3D projected into 2D.",
            "OK."
        ],
        [
            "Alright, so the last type of objective function that's quite popular and I want to cover today is triplet based embedding.",
            "OK, so we talked about Doctor Lim being a pairwise embedding, so triplet embeddings look at three data points together so typically will call them the anchor.",
            "So we'll call XI.",
            "The anchor will look at a positive point and a negative point.",
            "And what this means is that the positive point should be more similar to the anchor.",
            "Then the negative point.",
            "OK, so you have some similarity score associated with these inputs and then you want to learn an embedding such that for cases where the similarity is, you know for the positive example to the anchor is greater than the similarity of the negative guide to the anchor, you want the distance between the positive guide to the well, the embedded distance between the positive side of the anchor to be smaller than the distance between the.",
            "Negative guide to the anchor.",
            "OK, that's a bit of a mouthful, so you know you want to put points that the positive guy should be embedded closer to the anchor than the negative guy, basically.",
            "OK, so this I think the first time this was proposed was in a paper called Oasis Oasis from some authors at Google.",
            "I'm not 100% sure on this.",
            "I haven't been able to uncover any references before this, but I kind of.",
            "I have this feeling that people had discovered this before then.",
            "Do you Yoshua know?",
            "If people were doing triplet embeddings before Oasis?",
            "I haven't been able to find it, but it seems like an idea that people have the same thing about reluz.",
            "Someone was asking why didn't people consider relatives in the in the 90s, so it might have been just one of those ideas that wasn't really proven.",
            "OK.",
            "So in this original paper Oasis, the authors considered essentially handcrafted features, sparse features from images."
        ],
        [
            "And more recently, this has been incorporated into deep learning where you're actually doing a feature learning pipeline using this triplet based objective as your error measure, and so there is a recent paper from some researchers at Google and Northwestern University where their learning a specialized type of commnet todo embeddings.",
            "So there's a little bit of architectural difference here between this confident in the standard ones that you saw in Hong Lex talk.",
            "So what you have is sort of a standard Alex net.",
            "This is the image.",
            "Net 2012.",
            "Type of pipeline has seven layers, but you also have these low resolution pipelines, so you have.",
            "These are not really calm, that's just a convolution plus a subsampling layer plus and essentially what you're doing is you're taking two low resolution pipelines that capture sort of more global information about the image, and then combining that with information that's coming out from standard commnet and representation.",
            "That's kind of invariant to certain properties of global properties of the image.",
            "Ann, you're combining those after normalization into a linear layer and then forming a code.",
            "OK, So what these authors did is they use this triplet based comparison and that's sort of the natural cost function to go with these triplet based criterions is a hinge loss.",
            "So it's essentially saying you know when your distance between the anchor, the embedded distance between the anchor and the negative guy is greater than the distance between the anchor in the positive guy.",
            "You won't pay any is greater than some gap, then you won't play any cost, but as soon as your distance between the anchor and the positive side gets bigger.",
            "Then you're going to suffer some loss right?",
            "'cause you want the distance between the anchor in the positive to be smaller, so standard hinge loss function and they are able to train train pretty nice embedding model."
        ],
        [
            "Now 1 issue that they face an basically all of these models face that are doing pairwise or triplet based embeddings is how to select these triplets because they blow up pretty quickly.",
            "So if you're considering.",
            "12 million images, which is what these authors considered.",
            "You're getting something on the order of 10 to the 21 triplets because the number of triplets increases cubically with the number of images that you have.",
            "They also find that the optimization converges and only after looking at 24 million triplets.",
            "So that's way less than this, right?",
            "You don't have to exhaustively look at all possible triplets.",
            "And when I was training these sorts of models, I was actually struggling with these issues as well in terms of what?",
            "Trip list do you look at so?",
            "They've proposed sort of based on efficiency.",
            "Kind of a nice approach where they insert a layer before their Siamese.",
            "This is now a sort of a Siamese triplet network that draws samples that draws triplet samples in a, not a sort of a uniform way.",
            "So let's just go over through the basic intuition behind this."
        ],
        [
            "So what they want to do is they first they sample an anchor image according to its relevance for a category.",
            "So let's say all of the points come from categories that could be classes.",
            "And the relevance within the category is based on the similarity of that image with all of the other images within the category.",
            "So they want to choose relevant anchors and then they go and they sample a positive image that has high relevance within that category as well, so they don't care about positives that have low relevance, 'cause they're probably going to bed far apart anyways.",
            "And then they go and they pick two types of negative images.",
            "They pick ones that are out of class.",
            "In that case they just sample them uniformly from the other classes.",
            "But they also sample in class negatives that should be relevant.",
            "OK, so they go.",
            "They use the same relevance measure.",
            "They pick relevant negatives because those are the ones that the network is being fooled by, but they ensure that there's a margin.",
            "In terms of the similarity between the positive and the negative example, yes.",
            "This point right here.",
            "Yeah.",
            "Northwind 4th Bullet Third Point.",
            "Yeah, these guys are sort of these two sort of fit into the Third Point.",
            "It could be one or the other, so this is coming from the same category, but it had an.",
            "It's also relevant, but it's less relevant than the positive example they already selected.",
            "So this is kind of a fooling example or or a hard negative.",
            "Sometimes people call it.",
            "What's the?",
            "What's the constraint?",
            "It's a.",
            "It's a hyperparameter that's based on the similarity between the.",
            "So you can look at the similarity between the positive example in the anchor and this negative example in the anchor, and you're going to make sure that there's a certain gap between them.",
            "That makes sense.",
            "Yes.",
            "So.",
            "So for one thing, it may be, and this is particularly relevant to this example.",
            "Computing that similarity score on the fly might be very expensive.",
            "Seem so.",
            "In this case, the way that these authors determine the similarity was they call it the Golden feature.",
            "They don't actually publish any details about it, so I guess it's an internal secret at Google, but essentially, it's based on something like 27 features that are extracted from the images and also from some textual information associated with the images.",
            "It's quite a complicated procedure, so you absolutely keep trying to look up in a data space like Google Image Search or something like that.",
            "You wouldn't want to.",
            "Extract that sort of at at query time you say somebody uploads an image and you want to find it.",
            "You don't want to run that feature extraction pipeline, so it's more efficient to compute this low dimensional code through a forward pass in the neural net, for example.",
            "Then doing this very complicated procedure.",
            "That sound reasonable.",
            "OK, so this is just sort of a sketch.",
            "You can read the details and there's some math behind.",
            "Basically the math behind these distributions.",
            "That's kind of an overview of how they're drawing the samples.",
            "Now what they're doing is they're actually proposing a way to do this online where you don't have to put all of these examples in memory, 'cause you might not be able to fit a very large database in memory, and So what they're doing is they're keeping buffers for each class or each category.",
            "And they add examples to these buffers with these ratios or these probabilities.",
            "So then at you know at training time you're drawing examples uniformly from these buffers, but the the distribution you're getting respects the distribution for which they were in which they were added basically, right?",
            "So it's kind of it they call it reservoir sampling.",
            "There's some older work that uses this, but it's.",
            "It's a.",
            "It's a neat trick, and this I just want to add.",
            "This came up at lunch.",
            "We were talking about.",
            "Leon Bottou's talk and him talking about you know the problem at doing sort of IID test time examples and then idea that came up was maybe more of these networks need to have some sort of layer before learning in terms of selecting appropriate examples for learning Lyons.",
            "Talking more about test time, but this could apply to things like curriculum learning as well as we're talking about at lunch, right?",
            "So anyway, this is a very efficient way to handle the enormous number of.",
            "Triplets."
        ],
        [
            "OK, so.",
            "Some of the limitations here Enciende.",
            "Doctor Lim?",
            "We saw that they were using a binary notion of similarity that was determined either by class information or it was determined by this neighborhood graph.",
            "In the case of the norm data set."
        ],
        [
            "This deep ranking paper I just talked about from Google was using this Golden feature, which is a very complicated pipeline.",
            "Determine relevance between images."
        ],
        [
            "Not all of us have access to these datasets.",
            "For certain certain domains, and even though we have services like Amazon Turk out there which can go in label data for us, asking people to label images as semantically relevant or not is inconsistent amongst observers, right?",
            "It's difficult for them to do so in the Google Paper.",
            "What they did is they had three raters for each of the images, and they only accepted it as an evaluation triplet.",
            "If the Raiders were unanimous.",
            "Right, but that requires a fairly large budget on Turk.",
            "If you're going to do this.",
            "So the last thing I want to talk about here is techniques that don't necessarily require you to.",
            "Do you explicit labeling?"
        ],
        [
            "So what we wanted to really do is look at unconstrained images and video, so that sort of YouTube quality where there's various degrees of.",
            "Fidelity in this in the signal and so Ian Spiro, who was a grad student at NYU.",
            "You worked out an interface by which which one could label just the hands in the head very quickly of an individual.",
            "So we were working on another project the same time that was investigating politician body language.",
            "So I don't know if anybody remembers this guy.",
            "Maybe Natalia does, so he was quite an animated character, so we were we were using this tool.",
            "And basically it was it was predicting where their poses go.",
            "Assuming that pose is going to be smooth and in video and so forth.",
            "And so the the annotator would only note need to go back and fix up the errors made by the annotation tool.",
            "So this allowed us to annotate peoples head in hands.",
            "Very quickly.",
            "OK, zero Noske always gets a few less.",
            "OK, So what we did back then was we trained a opposed sensitive embedding technique that took a database that was labeled by peoples hands and head and sort of use that as a proxy for pose.",
            "So we quickly label it on Mechanical Turk and then we could come along with.",
            "A Siamese neural net.",
            "In this case learning embedding just like I talked about and then we could take."
        ],
        [
            "The query search the database, find nearest neighbors and then we could even do sort of nearest neighbor based regression to say OK, we think the persons head in their hands are here.",
            "So.",
            "Nearest neighbor was quick because we learned low dimensional codes, but it also learned invariant representation, so is invariant to clothing and scale background lighting and so forth."
        ],
        [
            "So what we use as our error criterion was NCA, but remember, NCA is based on classification, so nearest neighbor classification, so we actually changed the NCA term to take into account the fact that we had labeled information about the poses of the individual.",
            "So the wise in this case, or 6 dimensional vectors which represent the X&Y location of the hands that the left and the right hand in the head, and essentially what we would do then, is we flip this around, and we said minimizes instead of maximize it.",
            "So we don't want you to put probability on guys where their poses live very far apart in terms of the Euclidean distance, right?",
            "So we had a convolutional neural network that would output and embedding.",
            "We would determine the probability from the distance in that embedding and then we would wait that by the label information which was supposed."
        ],
        [
            "We train that with gradient descent, we and we tested this on data set, called SNOWBIRD where we recorded everybody at the 2010 Workshop Yahshuah was there.",
            "I don't know if anybody else was there, and then we distribute these right after the talks in Mechanical Turk and."
        ],
        [
            "But labels right away, so Roland mentioned just earlier, which was sort of a global feature transform based on Fourier coefficients.",
            "I think hung like even had some results that we're using, just it's a global descriptor.",
            "It's a bit better than pixel based distance, but it produces a 512 dimensional code, so it's a little bit slow to work with.",
            "We tried linear and convolutional variants of our technique using NCA based objective, and we also had a doctor Lim.",
            "Style objective using the pose information as well, so we compare the."
        ],
        [
            "So we used a condom."
        ],
        [
            "But to do the embedding and we found sort of here you can see qualitatively what it does, the techniques that use convolutional Nets and either the NCA or Doctor Lim style objective did really well in terms of their matches.",
            "This is so this is a query image and then this is the nearest neighbor from the database that was received, did a reasonable job of matching, and the error here.",
            "As you can see, the error between the located the OR the found pozan the pose of the query.",
            "We've superimposed with magenta here.",
            "The pose that's been copied from the nearest neighbor it from C Ncar an it's actually seems to be capturing even though we just label the head in hands, something more substantial about the overall pose of the body."
        ],
        [
            "In terms of the qualitative results, what these techniques do on average, we tried two different datasets, so we had this real SNOWBIRD data set, and then we also had synthetic data where we could just produce a whole lot of different poses on the synthetic data.",
            "It was on average of 25.4 pixel error for our technique, which is better than the other embedding methods, and that corresponds to a radius of this.",
            "This distance around the hands, and then for the real data set it was a 16.4 pixel error on a smaller resolution image.",
            "And that corresponds to sort of an average.",
            "Getting the hands within that radius."
        ],
        [
            "Now I mentioned in the five years since we did this work, there's been some real serious advancements.",
            "I don't know what that is.",
            "Do you know what that is?",
            "Is there a phone?",
            "Oh there is a phone here.",
            "Bizarre OK.",
            "So I like.",
            "I don't think I think I'm still doing OK for time, right?",
            "Have 2010 minutes.",
            "Something like that.",
            "OK, that's why I thought.",
            "OK so.",
            "Anyways, so I was saying is in 2010 we did this work.",
            "You know five years ensued and there's been a lot of progress on datasets that are labeled with two depots information.",
            "So there's a paper from last year CPR by Misha Andrew Luca, and he proposes this Max Planck Institute for Informatics Human pose data set.",
            "They have about 40,000 examples of people labeled with a full skeleton, so including 16 different joints where we only considered 3.",
            "And these people are doing all kinds of different activities, so they're doing 491 different activities.",
            "Alot of previous datasets, even the bigger ones like lead sports would only be focused on sports or somewhere only sort of focused on people wearing funny clothing.",
            "You know people indoors stuff like that.",
            "This is a very diverse data set.",
            "So recently some researchers at Google."
        ],
        [
            "Including a Greg Morey who's a faculty member at Simon Fraser here in Canada.",
            "He is doing his sabbatical there.",
            "They did something very similar in motivation to our work, but they use a better database.",
            "They used a triplet style learning instead of NCAR doctor Lim, and they also scaled up the type of comment.",
            "So five years ago we didn't have Alex Net.",
            "We didn't have inception, they're using this Google Inception style comment that hung like just talked about.",
            "Which is this big?",
            "Big Deep commnet and essentially they they perform reasonable embedding so you can see if you want to see a modern version of that.",
            "You can look at the paper on archive that was put there just in just in June."
        ],
        [
            "OK, so the final part of the talk.",
            "There's a couple of things I'd like to highlight, which is can we do these sorts of embedding without labeling explicitly body parts or other other things in other data domains?"
        ],
        [
            "So this again, this works a little bit older, but I like to highlight it 'cause it's one of my favorite projects that I ever did."
        ],
        [
            "A lot of fun.",
            "We had a rock banner or they call themselves a like an Electro.",
            "Now I forget.",
            "Electro progressive group from the Netherlands who made a music video and some of you may have seen this already.",
            "'cause I often talk about this.",
            "They have a video where they're, you know, just doing cool band stuff, making funky poses and doing this to music obviously, and then they have a web interface where people."
        ],
        [
            "Actually imitate them through a webcam.",
            "Frame by frame.",
            "OK, so this actually turns out to be a very cool data set for learning these sorts of embeddings, because you can look and these are just like I was saying before.",
            "The pixels are completely different, right?",
            "But the semantic information is the same now.",
            "The caveat here is it's restricted to one particular domain we care here about pose, so this is not really working outside of this domain, but for this particular domain we're getting really rich data of people performing the same pose and all kinds of.",
            "Means of variation.",
            "So the other thing is not only within a single frame, we could also look between frames, assuming that video is smooth and assume that people that are nearby temporally.",
            "Share similar posts.",
            "That idea is called temporal coherence, and we're not the first ones to use temporal coherence.",
            "But this is a very nice signal that can be used from video data to inform your algorithm, so maybe even beyond this application, often you consider this idea of temporal coherence, and this allows you to do weekly supervised learning.",
            "So again, one of my favorite papers ever worked on to CVP."
        ],
        [
            "PR paper you can check it out if you want to read more and see the video more recently, Mohammed Nuru see the guy that did the multiindex hashing at Google, he's doing a Google internship and he worked on zero shot learning where they were looking at embeddings of multiple domains and I also saw Hong Lac was trying to get to this at the very end and didn't quite make it so I'm glad to have a chance to talk.",
            "Talk for a couple of seconds on it.",
            "So basically the idea is you do.",
            "Semantic embeddings of word vectors.",
            "And that allows you to essentially build a bridge from words through the class labels back to images through a recognition model.",
            "So in other words, you have an image net style recognition model.",
            "You have a word embedding model and you're using class.",
            "Then the words on the class labels as the link between the two of them.",
            "So the problem here is what you're trying to do is at Test time you're trying to classify an image which has a class label you've never observed before, so here it's dress or frock.",
            "So this is not in the training database, or in this case I can't even read that now.",
            "Sorry if I can't read it, you probably can't read it.",
            "Ratite red eyed bird, flightless bird.",
            "In that case, you're trying to put that label on it, but you never seen that label before.",
            "So what's happening here?",
            "Is there actually they've?",
            "This is a very simple approach.",
            "They've taken Alex net style image net.",
            "Com.",
            "Net, which goes from image to distribution of work over object categories, and they've taken Google's word to VEC embedding model, which goes from a word to a vector representation, and they essentially take the output of the softmax in the recognition model, and that essentially allows you to define the weightings between these different word embeddings.",
            "So the example that they use in that paper is.",
            "Say you put an image in and you get output for the classes.",
            "Oh point, 6 Tiger, an oh point 4 lion.",
            "OK, so now you you go and you look in your embedding space on these word vectors and you combine oh point 6 lion on that word vector with oh point 4 Tiger on the word vector and you get another one.",
            "You see, look what's close to that and it should be Liger because it should be close.",
            "This is what's the movie that the lock.",
            "Sorry Napoleon dynamite yeah, this conference of the movie.",
            "OK, Napoleon dynamite, you find Liger even though you've never seen longer before as a training example, it's somewhere sort of in the middle of the examples that the labels that you had seen before.",
            "So it's a nice way of connecting word embeddings to recognition model so you can check that out.",
            "Mohammed noroozi and."
        ],
        [
            "Um?",
            "Basically, I'm going now to summarize everything I've talked about, so we looked at three different paradigms for doing embeddings, learning similarity, learning to compare whatever you want to call it.",
            "We talked about unsupervised techniques where you basically did representation learning and hope for the best, use clever methods of regularization you use advanced learning algorithms, but you still couldn't control points that got where was similar and got embedded to different places.",
            "So you can introduce supervised information in domains where you have labels available to you and we looked at different objective functions, so we focused on Doctor Limon NCA, triplet embeddings, and so forth, and then finally I gave a couple of pointers to some weakly supervised techniques, sort of variants that don't really fit into the unsupervised or supervised learning paradigm that are still sort of similarity based research projects.",
            "So in closing."
        ],
        [
            "So where do we go from here?",
            "Think we're going to still keep pushing on architectural improvements?",
            "That seems to me what's happened in the last five years.",
            "People have really moved to where it's comments, and now they're looking at specialized architectures that are really efficient in terms of parameter spaces using multiscale techniques.",
            "Going very deep people will keep pushing on this, and also they'll start thinking more about mapping this to the hardware.",
            "So you want to sort of sparse computations that doesn't really fit right now with today's hardware.",
            "So what kind of specialized hardware architectures can you use to learn these embeddings?",
            "And then also do search within these embeddings?",
            "Databases are only going to continue to grow, so this last point I just was talking about also plays a role here in terms of speeding up search.",
            "Hashing techniques will still continue to be innovative and then finally will be probably rolling about rolling out these embedding techniques to domains beyond the classical image, video, speech and our audio and text, right?",
            "So hopefully we'll see these in other domains where there's just not that much labeled data.",
            "I think that's probably where unsupervised learning is going to play more of a role.",
            "So with that I know there's one question out there waiting.",
            "I'll thank you for your attention and look forward to talking to you again tomorrow.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thanks again to the organizers, Yahshua Ann, Roland and Erin.",
                    "label": 0
                },
                {
                    "sent": "I think it's also involved in this for inviting me here today.",
                    "label": 0
                },
                {
                    "sent": "It's great to see this amazing, diverse audience and I've only been here.",
                    "label": 0
                },
                {
                    "sent": "I just arrived last night so the two talks I saw today have been fantastic and I'm happy to be able to build on some of the previous work.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to be talking a lot about algorithms or architectures per say.",
                    "label": 0
                },
                {
                    "sent": "I'm going to use some of the.",
                    "label": 0
                },
                {
                    "sent": "Architectures that were already developed in the previous lecture and talk about a different type of problem, so we focused a lot on the Community, has focused a lot on recognition or detection tasks with deep learning.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about a different family of applications, which is some people called distance learning or similarity learning or distance metric or distance measure goes by different names.",
                    "label": 0
                },
                {
                    "sent": "I like just to say, learning to compare because we're going to have learning methods that can compare examples so.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of the overview of this talk, the metric learning or distance metric learning field is absolutely huge.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to be able to do a complete survey of the entire field, but I will focus on representation learning an feature learning techniques as they apply to this field.",
                    "label": 1
                },
                {
                    "sent": "So basically this picture I'm going to keep referring to here is I'm going to be talking about taking images of people or objects that are perceptually similar and being able to map them into a space or a manifold.",
                    "label": 0
                },
                {
                    "sent": "In which the observations that are perceptually similar or nearby in this space, and similarly some of these methods that will talk about will actually take points that are dissimilar and ensure that they live far apart in these manifolds so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The types of applications that I will hit on today I'll talk about about document retrieval.",
                    "label": 0
                },
                {
                    "sent": "I will talk about finding people in similar poses like I've shown here and at the end I'll even talk about zero shot learning, which I think Hong Lat started to talk about but ran out of time.",
                    "label": 0
                },
                {
                    "sent": "So I think that's great.",
                    "label": 0
                },
                {
                    "sent": "We're thinking along the same line, so I will pick up at the end of the presentation where he left off.",
                    "label": 0
                },
                {
                    "sent": "I will try.",
                    "label": 0
                },
                {
                    "sent": "I'll try not to.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "My guess is that will be OK for time, but well, I've got a timer here in front of me, so I'll be conscious of that.",
                    "label": 0
                },
                {
                    "sent": "So OK, so learning similarity, learning similarity, it's a fundamental operation in many applications within machine learning and computer vision.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that we want to determine similarity.",
                    "label": 0
                },
                {
                    "sent": "Often I'm going to be talking about images, but doesn't have to be image data.",
                    "label": 0
                },
                {
                    "sent": "It could be objects in general, so we wanted to have some sort of learning system that can take for example a pair of objects and output a number that describes how similar they are.",
                    "label": 0
                },
                {
                    "sent": "Most notable applications of this are retrieval based methods, so document retrieval, image retrieval people are probably familiar with Google Image Search and also nearest neighbor methods, so there's nearest neighbor methods for classification, regression and so forth.",
                    "label": 0
                },
                {
                    "sent": "Those all require a means of computing similarity.",
                    "label": 0
                },
                {
                    "sent": "So when we talk about similarity, we usually have some notion of perceptual similarity.",
                    "label": 0
                },
                {
                    "sent": "I'm showing you here a picture of people that are all in the same pose.",
                    "label": 0
                },
                {
                    "sent": "This is my favorite example of this because the.",
                    "label": 0
                },
                {
                    "sent": "Image content with the pixel content of these images is completely different, so if you were to compute Euclidean distance in pixel space, that would really tell you nothing about whether these people are holding up their hand in the same position or not OK, so pixel distance or pixel distance or input distance as computed by Euclidean distance measure usually is not informative of perceptual similarity, so.",
                    "label": 0
                },
                {
                    "sent": "The other problem with computing distances, for example in pixel space, is very expensive.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's not an efficient thing to do.",
                    "label": 0
                },
                {
                    "sent": "Images are high dimensional, so we want to do finding images that are similar and learn very large databases.",
                    "label": 0
                },
                {
                    "sent": "We're not going to be computing Euclidean distances on images, so the idea here is to learn these parametric embeddings so that perceptual similarity is captured in the embedding space, and typically the way that will go about this is we will learn codes.",
                    "label": 0
                },
                {
                    "sent": "That are low dimensional such that these similarities can be computed rather efficiently.",
                    "label": 0
                },
                {
                    "sent": "An important part of this again, is, like has been already mentioned in some of the other talks, learning these embeddings such that their invariant to certain factors of variation.",
                    "label": 0
                },
                {
                    "sent": "So we want to do in our embedding is highlight the important stuff.",
                    "label": 0
                },
                {
                    "sent": "So in this example, let's suppose it might not be domain specific, might not be as simple as pose.",
                    "label": 0
                },
                {
                    "sent": "It might refer to a large number of similarity attributes.",
                    "label": 0
                },
                {
                    "sent": "For example, let's use is to say we want to find similar images right on Google Image Search.",
                    "label": 0
                },
                {
                    "sent": "That may not just depend on pose, it could depend on many things.",
                    "label": 0
                },
                {
                    "sent": "But we want to focus on those things that are important and sort of downgrade the other factors of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Creation.",
                    "label": 0
                },
                {
                    "sent": "OK, so the key question in setting up this problem is where does this similarity information come from and the way I'm going to set up this talk is is talking really dividing it up into answers for this question.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the typical setup that I'm going to be using today is that I'm going to map an input.",
                    "label": 0
                },
                {
                    "sent": "I'm going to call the input X through some function.",
                    "label": 0
                },
                {
                    "sent": "It may be very complicated and nonlinear, like a neural net, and I'm going to produce a code and will call the code said I'm also.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take another input and pass it through the same functional mapping, and that's going to produce another code.",
                    "label": 0
                },
                {
                    "sent": "The code is going to be different because it has a different input to start with, but these functional mappings are the same, and then I'm going to compare.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distances and we're hoping to see is that the distance in the embedding space is capturing perceptual similarity, whereas the distance in the input space was non informative.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so one motivation I mentioned for these techniques are nearest neighbor methods and there is some work a number of years ago boiman and colleagues have a paper called in defense of nearest neighbor.",
                    "label": 0
                },
                {
                    "sent": "It's a nice paper because they look back on nearest neighbor and they say many of the things that were wrong about the way that people applied nearest neighbor.",
                    "label": 0
                },
                {
                    "sent": "One of the problems with nearest neighbor.",
                    "label": 0
                },
                {
                    "sent": "Basically the way that features are typically computed.",
                    "label": 0
                },
                {
                    "sent": "Another problem with nearest neighbor, the way that people often apply it is that they use what's called an image to image type of distance.",
                    "label": 1
                },
                {
                    "sent": "So they take a query.",
                    "label": 0
                },
                {
                    "sent": "And they compare that query to every single image in the database and they find the the neighbors, the ones that are most similar.",
                    "label": 0
                },
                {
                    "sent": "OK, so we called the nearest neighbors Boiman and colleagues propose a different technique where they wish they call image to class.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to go and take a query image and go inside every class and compare it to the examples in that class and produce a single number representing how similar that image Ware was.",
                    "label": 0
                },
                {
                    "sent": "Two examples in the class.",
                    "label": 0
                },
                {
                    "sent": "So here's a picture of this so.",
                    "label": 0
                },
                {
                    "sent": "Have you take this query image?",
                    "label": 0
                },
                {
                    "sent": "And you look at each of these examples within this class individually.",
                    "label": 1
                },
                {
                    "sent": "It actually might not be similar.",
                    "label": 0
                },
                {
                    "sent": "Say we have a similar measure here between this query and these different examples, so we're comparing it sort of image to image.",
                    "label": 1
                },
                {
                    "sent": "It's not very similar, but when we compare it to the entire class and let all of the images within the class essentially explain this image and you can see by color what parts of this image are being explained by each of the images in this class.",
                    "label": 0
                },
                {
                    "sent": "We actually have a small distance in that space.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the notion of image to class.",
                    "label": 0
                },
                {
                    "sent": "I'll get back to this a little bit later on.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbor methods are pretty fast, especially when you combine them with approximate methods or hashing techniques, which we'll talk about later, and they can generalize the new classes at basically no cost.",
                    "label": 1
                },
                {
                    "sent": "So there are some some motivations for using.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other motivation for this similarity learning is retrieval.",
                    "label": 0
                },
                {
                    "sent": "In very large databases, so this is a Google data center, one of many, and as these databases grow large, the ability to learn these compact representations and determine similarity very quickly becomes more and more important.",
                    "label": 0
                },
                {
                    "sent": "So hashing algorithms which are going to encode objects into compact binary codes to preserve similarity are particularly useful in this setting and will describe.",
                    "label": 0
                },
                {
                    "sent": "What hashing is a little bit later on?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's just the intro of this talk.",
                    "label": 0
                },
                {
                    "sent": "Now let me just give you an outline of how I'm going to proceed, so I said I'm going to base this on how to determine similarity.",
                    "label": 0
                },
                {
                    "sent": "So the first type of similarity learning is going to assume that you have no external information about the similarity amongst objects in your training set, so nobody has given you some some indication or no teacher has said these examples are similar.",
                    "label": 0
                },
                {
                    "sent": "These ones are dissimilar.",
                    "label": 0
                },
                {
                    "sent": "You're just going to rely on good unsupervised learning or representation learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "The next.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Passive algorithms are going to allow you to utilize some external information, so this will often come.",
                    "label": 0
                },
                {
                    "sent": "In the form of class information.",
                    "label": 0
                },
                {
                    "sent": "So we'll see objects that lie within the same class should be similar objects that are in different classes or not similar.",
                    "label": 0
                },
                {
                    "sent": "It may come in the form of a neighborhood graph, so we have may have much more structured information saying which objects are similar to one another in the form of the graph, and then we may have some techniques that are derived, for example from queries on the Internet.",
                    "label": 0
                },
                {
                    "sent": "So this has been a popular method of determining similarity.",
                    "label": 0
                },
                {
                    "sent": "Recently",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Final technique I'll be talking about are weakly supervised techniques, so it fits somewhere between unsupervised and supervised learning.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you don't have very rich information about similarity, but you're going to capture it from some other mechanism.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the unsupervised learning approach says let's do our best to utilize these models that we've already been talking about in the summer school.",
                    "label": 0
                },
                {
                    "sent": "Are BMS, autoencoders and so forth.",
                    "label": 0
                },
                {
                    "sent": "We're going to rely on their ability to learn good representations.",
                    "label": 0
                },
                {
                    "sent": "But instead of using the representations, learn from these algorithms and feeding them into, say, for example, a classification model, we're going to focus on computing distances, typically in the higher levels of these representation learning algorithms to do this efficiently.",
                    "label": 0
                },
                {
                    "sent": "Like I mentioned before, often in these architectures that are used for similarity learning.",
                    "label": 0
                },
                {
                    "sent": "We're going to restrict the representations to be smaller bottlenecked.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classical methods for doing this have typically derived from directed graphical models, so there's essentially latent semantic analysis and its variants have been popular.",
                    "label": 0
                },
                {
                    "sent": "They're very simple techniques, they're fast, they're reasonably effective.",
                    "label": 0
                },
                {
                    "sent": "But the problem with using these directed graphical models is the difficulty in performing inference, and when we want to do very large scale, look up some databases and do this very efficiently, methods.",
                    "label": 0
                },
                {
                    "sent": "Using Gibbs sampling MCMC to be able to discover these representations don't seem like a good fit.",
                    "label": 0
                },
                {
                    "sent": "Now there is a recent family of methods called variational autoencoders and their variants, which people are very excited about.",
                    "label": 0
                },
                {
                    "sent": "These are directed graphical models, but they maintain a separate inference procedure, which is very efficient, and I think Hugo Libor.",
                    "label": 0
                },
                {
                    "sent": "She'll be talking about these methods in his talk.",
                    "label": 0
                },
                {
                    "sent": "I won't go into the details of these right now, but this might be.",
                    "label": 0
                },
                {
                    "sent": "I haven't seen any papers doing similarity learning with these types of techniques, but it might be a few future Avenue of.",
                    "label": 0
                },
                {
                    "sent": "Research.",
                    "label": 0
                },
                {
                    "sent": "Oh, Aaron will talk about them.",
                    "label": 0
                },
                {
                    "sent": "OK, excellent.",
                    "label": 0
                },
                {
                    "sent": "So this is for a future talk.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so typically what we're going to do is we can't rely on directed graphical models as we will rely on undirected models where inference is fast and the first techniques that sort of stemmed from the the emergence of the beginnings of the deep learning field were sort of 2005 2007.",
                    "label": 0
                },
                {
                    "sent": "Max Welling took our BMS, which were typically binary valued observations, binary valued hedons and he was able to generalize them to general exponential family distributions.",
                    "label": 0
                },
                {
                    "sent": "What allowed him to do?",
                    "label": 0
                },
                {
                    "sent": "With model integer counts, which were useful way of representing documents OK, and we'll hear more about document representations when we have the NLP lectures.",
                    "label": 0
                },
                {
                    "sent": "Wrestling Cela Kutna fan Geoff Hinton went to step further and built very deep techniques based on our BMS and that's the first thing I'd like to talk about in terms of on super.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning.",
                    "label": 0
                },
                {
                    "sent": "So the building block or the first building block of the semantic hashing technique proposed by Russ and Jeff is something called the constrained passam model, and this is a special type of GBM that's effective modeling integer word counts.",
                    "label": 0
                },
                {
                    "sent": "So there's a picture of this model up here.",
                    "label": 0
                },
                {
                    "sent": "It just looks like a standard PBM, so it keeps all of the favorable properties that you've already learned about of our BMS.",
                    "label": 0
                },
                {
                    "sent": "It has a little bit of specialized machinery to cope with variable world word lengths.",
                    "label": 0
                },
                {
                    "sent": "And so one way of interpreting these visible units.",
                    "label": 0
                },
                {
                    "sent": "Always integers, so each of these visibles represents a particular word, and the integer is how many times it occurs in a particular document.",
                    "label": 0
                },
                {
                    "sent": "You can also take another view where you just divide each of the visible vectors by the total number of words in the document, so we'll call that N, and you can and then you can view these visibles as probabilities, so the probabilities of a word occurring, and then every time you want to sample a word, you're not sampling a document at once.",
                    "label": 0
                },
                {
                    "sent": "You're sampling from this RBM multiple times, one for each word in the document.",
                    "label": 0
                },
                {
                    "sent": "So you sample at end times for.",
                    "label": 0
                },
                {
                    "sent": "Acument of length N when you when you normalize this way you have to be careful to multiply the upgoing waits by the number of words in the document, but there's some nice stability properties associated with doing this and it also allows you to cope with varying document links, so this quick constrained puts on model what you need to remember is just it's an efficient way of representing integer data, and this forms the first layer of a deeper model.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way that they rolled this out as a train, what's called a deep autoencoder, and I guess we've already spoken about deep autoencoders.",
                    "label": 1
                },
                {
                    "sent": "A little bit.",
                    "label": 0
                },
                {
                    "sent": "Paschall OK so Pascals talked about autoencoders.",
                    "label": 0
                },
                {
                    "sent": "This approach was very popular in this the early days of deep learning.",
                    "label": 0
                },
                {
                    "sent": "Training a deep autoencoder by pre training it with our.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "M's so the idea is that you would start with this constraint plus on binary RBM which models word counts and you learn a binary representation of the document.",
                    "label": 0
                },
                {
                    "sent": "OK, so this takes the integer words and it encodes it into a series of binary features.",
                    "label": 0
                },
                {
                    "sent": "Then you would take a binary to binary RBM and learn another layer.",
                    "label": 0
                },
                {
                    "sent": "Features on top of that.",
                    "label": 0
                },
                {
                    "sent": "And then you learn another layer of features on top of that, and that would give you something called an encoder.",
                    "label": 0
                },
                {
                    "sent": "So Roland was talking about autoencoders.",
                    "label": 0
                },
                {
                    "sent": "Today he was talking about single layer autoencoders.",
                    "label": 0
                },
                {
                    "sent": "And he talked about the encoder in the decoder.",
                    "label": 0
                },
                {
                    "sent": "This is the encoder.",
                    "label": 0
                },
                {
                    "sent": "It just happens to consist of multiple layers of representation.",
                    "label": 0
                },
                {
                    "sent": "OK, and it's been pre trained with multiple PBM's.",
                    "label": 0
                },
                {
                    "sent": "Now once you have that encoded representation, which is typically low dimensional, it becomes what you call your code.",
                    "label": 0
                },
                {
                    "sent": "OK, so this isn't encoded document and then we take that an we just transpose.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is our BMS.",
                    "label": 0
                },
                {
                    "sent": "Into the decoder.",
                    "label": 0
                },
                {
                    "sent": "OK, so we take the exact same weights that were here, here and here and we do.",
                    "label": 0
                },
                {
                    "sent": "It's called unrolling and that is the pre trained deep autoencoder.",
                    "label": 0
                },
                {
                    "sent": "So once you've initialized with all these carbs, you've trained each of these PBM separately.",
                    "label": 0
                },
                {
                    "sent": "You've unrolled them into the decoder without doing any more training.",
                    "label": 0
                },
                {
                    "sent": "Then you can basically fine tune this whole thing using backdrop and use error.",
                    "label": 0
                },
                {
                    "sent": "This reconstruction error between what went in as the input and what came out is the output as your error signal.",
                    "label": 0
                },
                {
                    "sent": "For learning this this network.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That is a means of deriving a very low dimensional but good representation of the documents in an unsupervised.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's an additional trick that Russ and Jeff used to make.",
                    "label": 0
                },
                {
                    "sent": "This method is extremely efficient for modeling documents, in particular for retrieval.",
                    "label": 0
                },
                {
                    "sent": "They added noise to the learning process, so they inject a little bit of Gaussian noise during the at the code layer during learning, and this forced the network to be resilient to this noise by encouraging the the code here produced here to be binary close to binary.",
                    "label": 0
                },
                {
                    "sent": "So these are these are binary to binary.",
                    "label": 0
                },
                {
                    "sent": "IBM's but the outputs are sigmoidal, so basically by injecting noise at force of the value should be very close to 0 or very close to 1.",
                    "label": 0
                },
                {
                    "sent": "Even though there are sigmoids and So what happened then is that they could take the codes that were produced and threshold them and there wouldn't be a lot of error introducing that thresholding process because they are already close to binary anyways, yes.",
                    "label": 0
                },
                {
                    "sent": "Alright, so well, I guess the idea is if you have sort of an uncertain value in there and you had you had sort of say it's close to .5 and you add noise in there, then the essentially the when you threshold it could essentially go either way, whereas if the if you're adding noise and it moves closer to zero or one then you sort of made a representation that's resilient to any sort of thresholding type of error.",
                    "label": 0
                },
                {
                    "sent": "Set as your question, do a better.",
                    "label": 0
                },
                {
                    "sent": "Do you have a better answer?",
                    "label": 0
                },
                {
                    "sent": "You don't.",
                    "label": 0
                },
                {
                    "sent": "You don't look pretty happy with that answer.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "The error that you would like.",
                    "label": 0
                },
                {
                    "sent": "You can view it as a regular.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "You can view.",
                    "label": 0
                },
                {
                    "sent": "I mean people use, not.",
                    "label": 0
                },
                {
                    "sent": "They use inject noise not just for this reason as well as the four squares to be binary, but these are regularizer as well.",
                    "label": 0
                },
                {
                    "sent": "So it's another way of inducing weight weight decay.",
                    "label": 0
                },
                {
                    "sent": "So it's related to that.",
                    "label": 0
                },
                {
                    "sent": "OK. Back there.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, yeah, thank you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I was going to say I wasn't sure.",
                    "label": 0
                },
                {
                    "sent": "Next slide, I'll get to that in one second.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's an import.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Question OK so the.",
                    "label": 0
                },
                {
                    "sent": "Title of this slide.",
                    "label": 0
                },
                {
                    "sent": "Extremely fast retrieval.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have binary codes essentially, but you can use is, you can use a hash table which allows you to find the codes that are closest to the query, sort of a Hamming.",
                    "label": 0
                },
                {
                    "sent": "They call it a Hamming ball or Hamming radius.",
                    "label": 0
                },
                {
                    "sent": "An constant time essentially so you don't have to do linear search over your entire database of code, so you can do very fast retrieval and we have in a couple of slides will go through exactly how that works.",
                    "label": 0
                },
                {
                    "sent": "So this is the main point here.",
                    "label": 0
                },
                {
                    "sent": "You could retrieve these similar documents to your query with essentially no search.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's time sub linear in the size of your database.",
                    "label": 0
                },
                {
                    "sent": "Now if you do this thresholding to the directed model latent semantic analysis, so you just it produces continuous valued codes and so you just threshold them and try to do this fast.",
                    "label": 0
                },
                {
                    "sent": "Look up.",
                    "label": 0
                },
                {
                    "sent": "It actually significantly reduces the performance of that mechanism because the codes that LSA produce weren't trained to be.",
                    "label": 0
                },
                {
                    "sent": "Good binary representations.",
                    "label": 0
                },
                {
                    "sent": "So a weakness here is that even though you'll find once you go, you take a query, you find it where it is in this binary embedded space, and you look at the documents around it.",
                    "label": 0
                },
                {
                    "sent": "Those documents around it are going to be good hits.",
                    "label": 0
                },
                {
                    "sent": "OK, so they're going to be similar, but if you take 2 documents that are similar and you embed them, there's no guarantee that they're going to lie in the same location.",
                    "label": 0
                },
                {
                    "sent": "Embedding space.",
                    "label": 0
                },
                {
                    "sent": "OK, so two similar documents might still be embedded far away in other ways of thinking about that, so we'll talk a little bit later about how we can sort of force them together.",
                    "label": 0
                },
                {
                    "sent": "That's going to be used through suits unsupervised learning, so the question here is can we use external information like labels to pull them together?",
                    "label": 1
                },
                {
                    "sent": "Yes we can, but let's let's wait a few slides to figure out how that works.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I want to go back to this idea of hashing.",
                    "label": 0
                },
                {
                    "sent": "So in Russ and Jeff's experience experiments using semantic hashing, they typically kept the dimensionality low, so they're using basically 20 bits for their code, others are using 3032 bits and so forth.",
                    "label": 0
                },
                {
                    "sent": "You can use this trick where you use the basically the binary codes themselves as direct indices to some hash table, and so you can do find nearest neighbors with no search.",
                    "label": 1
                },
                {
                    "sent": "The problem is, once you start using code links that are much larger than 32 bits.",
                    "label": 0
                },
                {
                    "sent": "This procedure kind of breaks down because the amount of neighbors that get retrieved within a certain Hamming radius or Hamming ball blows up near exponentially once you get.",
                    "label": 1
                },
                {
                    "sent": "Pretty high dimensional codes and the other part important point to make is that larger codes typically work better, so you kind of you're motivated to use larger codes, but they're less efficient, and so Mohammed noroozi from University of Toronto and David fleet have some work where they did.",
                    "label": 1
                },
                {
                    "sent": "Some studies on this, so I guess the here's the curves that they published.",
                    "label": 0
                },
                {
                    "sent": "They're showing you for different code links if you take a particular Hamming radius around, look around a query and you look at how many neighbors so.",
                    "label": 1
                },
                {
                    "sent": "For example, a Hamming radius of 6 would mean how many other documents or.",
                    "label": 0
                },
                {
                    "sent": "Differ by 6 bits or less to that query and you'll see with 32 bits it's reasonable, but as soon as you get to 64 bits, if you're looking at a Hamming radius of 7 bits, you're getting about a billion hits.",
                    "label": 1
                },
                {
                    "sent": "OK, and typically you're not going to have a database of a billion.",
                    "label": 0
                },
                {
                    "sent": "I mean for large scale applications you might get there, but that's that's a problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so in that case, if your database is smaller than a billion, it's better to just do a linear search over all the documents, right?",
                    "label": 0
                },
                {
                    "sent": "So what they've done is?",
                    "label": 0
                },
                {
                    "sent": "They've proposed some much better technique for doing hashing called multiindex hashing.",
                    "label": 0
                },
                {
                    "sent": "Now the other thing, the other plot that they made, which is important to look at, is there's a little bit of uncertainty in terms of.",
                    "label": 0
                },
                {
                    "sent": "What hamming radius you need to consider when you're doing nearest neighbor look up.",
                    "label": 0
                },
                {
                    "sent": "So typically the at application time you're trying to find the K nearest neighbors of a document document, or the most similar similar neighbors.",
                    "label": 0
                },
                {
                    "sent": "You're not typically looking for how many documents lie around inside this Hamming ball so, but there is uncertainty in terms of how big that radius needs to be.",
                    "label": 0
                },
                {
                    "sent": "Depending on your data set.",
                    "label": 0
                },
                {
                    "sent": "So they took a data set called it was 1 billion examples of SIFT features.",
                    "label": 0
                },
                {
                    "sent": "And they essentially did some statistics on.",
                    "label": 0
                },
                {
                    "sent": "You know, for a given number of nearest neighbors, so 10 or 100 nearest neighbors, what was the Hamming radius or Hamming ball?",
                    "label": 0
                },
                {
                    "sent": "You need to search, right?",
                    "label": 0
                },
                {
                    "sent": "And there's some uncertainty.",
                    "label": 0
                },
                {
                    "sent": "There's variability there, so for 128 bit codes you're getting upwards of 15, sort of 20 Hamming radius, right?",
                    "label": 0
                },
                {
                    "sent": "And so then you're dealing way way way up here, like massive number of retreat results.",
                    "label": 0
                },
                {
                    "sent": "OK, So what do you do?",
                    "label": 0
                },
                {
                    "sent": "Well if you are.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this problem you should turn to Newsies code so he has on GitHub and he has this technique called multiindex hashing and so he has an algorithm that is approvable Y sub linear in the number of documents in your database or images in your database.",
                    "label": 0
                },
                {
                    "sent": "And so you know the key idea here is that if you have.",
                    "label": 0
                },
                {
                    "sent": "Binary codes of qubits.",
                    "label": 0
                },
                {
                    "sent": "You're going to have two to the Q possible codes, but that's typically much, much larger than your database.",
                    "label": 1
                },
                {
                    "sent": "OK, when you're using a large number for Q, So what you're going to do in this algorithm is you're going to start collapsing buckets so you can do a much more efficient, efficient search.",
                    "label": 1
                },
                {
                    "sent": "So the way that they go about this is they essentially take these binary codes.",
                    "label": 1
                },
                {
                    "sent": "You can see them like this, and they break them up into M subgroups, and they do a hash on.",
                    "label": 0
                },
                {
                    "sent": "Each of these individually and essentially this is allowing them to sort of collapse this space, and when you are given a query code, you go search for the.",
                    "label": 1
                },
                {
                    "sent": "Neighbors within a Hamming ball in each of these sub sequences and they have some very nice theory to show that you're guaranteed in.",
                    "label": 0
                },
                {
                    "sent": "You know in all of these searches to find the nearest neighbors that you're looking for.",
                    "label": 0
                },
                {
                    "sent": "OK, so it is actually exact, but it's just much more efficient than doing search on the entire code.",
                    "label": 0
                },
                {
                    "sent": "There's there question back there.",
                    "label": 1
                },
                {
                    "sent": "OK, so the question is, what's the likelihood that you're going to see uniformly distributed codes?",
                    "label": 0
                },
                {
                    "sent": "That depends on the learning technique.",
                    "label": 0
                },
                {
                    "sent": "The technique that's actually getting your code.",
                    "label": 0
                },
                {
                    "sent": "So now we're talking about hashing.",
                    "label": 0
                },
                {
                    "sent": "This hashing can actually be used with any types of binary codes that can be generated.",
                    "label": 0
                },
                {
                    "sent": "It's independent of the algorithm that produces the codes themselves.",
                    "label": 0
                },
                {
                    "sent": "So to answer your question.",
                    "label": 0
                },
                {
                    "sent": "Depends on the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now different hashing techniques will produce different levels of uniform code, so you might, if that's it.",
                    "label": 0
                },
                {
                    "sent": "It's generally for this theory to work.",
                    "label": 0
                },
                {
                    "sent": "It depends on uniform code, so you should choose a technique that sort of should give you uniformity.",
                    "label": 0
                },
                {
                    "sent": "OK. And some some techniques are more explicit than others, like for example spectral hashing that's made explicit in its objective function to ensure they're looking for independence in the observations, and they relax that to sort of being uncorrelated.",
                    "label": 0
                },
                {
                    "sent": "OK, so locality sensitive hashing there there are similar motivation.",
                    "label": 1
                },
                {
                    "sent": "It's just again this is kind of getting back the same question.",
                    "label": 0
                },
                {
                    "sent": "The algorithms for determining the hash codes are different, so locality sensitive hashing is using random prediction projections.",
                    "label": 0
                },
                {
                    "sent": "The this technique that we just talked about for example deep autoencoders and semantic hashing are using learning, so representation learning.",
                    "label": 0
                },
                {
                    "sent": "To discover the hashes now this algorithm, whether you straight up hashing or the multiindex hashing, is independent of whether you used semantic hashing or spectral hashing or LSH.",
                    "label": 0
                },
                {
                    "sent": "OK, so whether this is different than LSH, it's not really a matter of whether this multiindex hashing is different, because this can be used with anything, but there is certainly a difference between semantic hashing and LSH.",
                    "label": 0
                },
                {
                    "sent": "OK cool, let's move on.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that concludes the unsupervised learning portion of this talk.",
                    "label": 0
                },
                {
                    "sent": "The next thing I want to talk about now is this problem that we talked about before of the fact that you might take points which are similar in embed them and they actually lie very far apart.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to use now is this setup where we're going to actually show the network.",
                    "label": 0
                },
                {
                    "sent": "So imagine this is a neural network or a convolutional network will will define that later on you're showing it pairs of examples and if those are examples you know should be similar, then those should form a small distance in their code.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm not necessarily going to restrict the codes to be binary at this point forward, but we're just going to produce some vector that's usually low dimensional and we want it to be small for examples.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know are similar, and then we're going to feed it examples that we know are dissimilar, and we're going to want to force it to have a large distance in code space.",
                    "label": 0
                },
                {
                    "sent": "OK, the key change now is that we actually have some label information or is external information that's telling us that those examples should be similar or not.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this idea of Siamese neural networks it's not new, so this goes back to at least the 90s and there was being considered by different groups at the same time and I was sort of all discovered with Pierre ability.",
                    "label": 0
                },
                {
                    "sent": "Sue Becker, Jeff Hinton.",
                    "label": 0
                },
                {
                    "sent": "And then this was a group at Bell Labs, I think at the time Jan Luken was involved with this project and they were actually doing signature verification.",
                    "label": 1
                },
                {
                    "sent": "So this is this is like early days of comments.",
                    "label": 0
                },
                {
                    "sent": "They're doing 1D convolutional net.",
                    "label": 0
                },
                {
                    "sent": "Signatures and they had.",
                    "label": 0
                },
                {
                    "sent": "This is a Siamese network from from the 90s.",
                    "label": 0
                },
                {
                    "sent": "Now according to Jan what they didn't really get right was the objective function.",
                    "label": 1
                },
                {
                    "sent": "So they had the part of the objective function that said, take similar examples and embed them to nearby locations in the embedded space, but they didn't have a contrastive term.",
                    "label": 0
                },
                {
                    "sent": "They had, they had nothing.",
                    "label": 0
                },
                {
                    "sent": "That said, the examples that are far apart should be separated.",
                    "label": 0
                },
                {
                    "sent": "OK, so according to you on the embedding kind of collapsed and the other thing is they didn't have a lot of data so.",
                    "label": 0
                },
                {
                    "sent": "It was it worked reasonably well, but it wasn't.",
                    "label": 0
                },
                {
                    "sent": "It wasn't a massive success at the time.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So modern day approaches to Siamese neural networks typically will use convolutional Nets.",
                    "label": 0
                },
                {
                    "sent": "Good thing hung like was just here to tell you all about convolutional Nets, so I don't have to spend too much time.",
                    "label": 0
                },
                {
                    "sent": "But this is just basically a refresher.",
                    "label": 0
                },
                {
                    "sent": "Convolutional Nets are have these three stages, convolution layer, some sort of rectification or contrast normalization, and then some pooling operation and we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stack these operations up, but the difference now is that your typical common set Hong Laxman talking about taking As for example, an input image and produce a class label.",
                    "label": 0
                },
                {
                    "sent": "The ones that I'm going to be talking about for the remainder of the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk are going to take in pairs of images, and they're going to produce vectors.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to really concerned about the distances between those vectors.",
                    "label": 0
                },
                {
                    "sent": "At the back, yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, so the name Siamese really refers to the pairing of the networks, so it's the fact that you have identical copies, so it might be 2.",
                    "label": 0
                },
                {
                    "sent": "In some cases it might be 3.",
                    "label": 0
                },
                {
                    "sent": "We'll see later on examples we have 3 copies that all have the same parameters, so this pathway and this pathway are the exact same convolutional net, but we're taking in pairs of inputs instead of a single input.",
                    "label": 0
                },
                {
                    "sent": "So in a standard confident you say, put an image in an you get.",
                    "label": 0
                },
                {
                    "sent": "A label out there's one pathway in this commnet there's there's two inputs which are two images, and both of these comments produce vectors, and then we compute distances on these vectors.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the key is 2.",
                    "label": 0
                },
                {
                    "sent": "It might.",
                    "label": 0
                },
                {
                    "sent": "It might be more as well identical copies, so the the key concern here is you know really what's the objective function.",
                    "label": 0
                },
                {
                    "sent": "So in a typical comment it's clear what that should be.",
                    "label": 0
                },
                {
                    "sent": "If you're doing classification, you'll have something related to the accuracy of that classification.",
                    "label": 0
                },
                {
                    "sent": "Here it's related to making these distances small for similar examples and making them big for.",
                    "label": 0
                },
                {
                    "sent": "Examples that should be far apart.",
                    "label": 0
                },
                {
                    "sent": "OK, so the next portion of this talk will really focus on these objectives.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so just sort of an overview of the way that these things can be trained.",
                    "label": 1
                },
                {
                    "sent": "Typically, Siamese Nets are overall trained by backpropagation, so the procedure is quite similar.",
                    "label": 1
                },
                {
                    "sent": "What's being changed versus a regular comnet is at the very top.",
                    "label": 0
                },
                {
                    "sent": "How that error metric is defined, and so that the most popular ones are technique called neighborhood components analysis.",
                    "label": 0
                },
                {
                    "sent": "So this is a probabilistic objective.",
                    "label": 0
                },
                {
                    "sent": "Will talk about that Doctor Limits a really long name which has a nice sounding acronym, and then we have triplet and quadruplet based criterion.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about triplets as well.",
                    "label": 0
                },
                {
                    "sent": "So go into the.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Details of all these so.",
                    "label": 0
                },
                {
                    "sent": "Neighborhood Components Analysis is a technique that was proposed little over 10 years ago by researchers including Sam Royce at University of Toronto and it's it's a popular method.",
                    "label": 0
                },
                {
                    "sent": "I think, as it has a very simple explanation, it's trying to.",
                    "label": 0
                },
                {
                    "sent": "Maximize the success of K nearest neighbor classification OK?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other words, you know we want to minimize classification error.",
                    "label": 0
                },
                {
                    "sent": "If we were to use KNN as our classification algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the idea of most of you're probably already familiar with KNN, but just quick refresher.",
                    "label": 0
                },
                {
                    "sent": "You have a point here.",
                    "label": 0
                },
                {
                    "sent": "You don't know it's labeled, so you're going to search a number of nearest neighbors around it and have their classes.",
                    "label": 0
                },
                {
                    "sent": "This is binary class.",
                    "label": 0
                },
                {
                    "sent": "Vote on what its label should be.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's say, let's let's define an error metric or mapping.",
                    "label": 0
                },
                {
                    "sent": "We talked about these projections such that the KNN classification error will be minimized.",
                    "label": 1
                },
                {
                    "sent": "Now there's a couple of problems with just implementing this in the sort of naive way.",
                    "label": 0
                },
                {
                    "sent": "First, that this KNN error is really highly discontinuous function of the parameters of this network.",
                    "label": 1
                },
                {
                    "sent": "So the way to think about this is you might you have some mapping that takes a data point, it embeds it in some space.",
                    "label": 0
                },
                {
                    "sent": "And then you do KNN in this embedded space.",
                    "label": 0
                },
                {
                    "sent": "If you change the parameters of that network ever so slightly, that might suddenly really change this neighborhood structure, right?",
                    "label": 0
                },
                {
                    "sent": "And then the votes for the classification would change, so it could be a big big effect.",
                    "label": 0
                },
                {
                    "sent": "Or you might wiggle those parameters in that embedding and nothing happens to the neighborhood.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's discontinuous and you still need to choose K OK with Canon, So what Jacob Goldberger and colleagues propose to do.",
                    "label": 0
                },
                {
                    "sent": "Is to look for a smoother.",
                    "label": 0
                },
                {
                    "sent": "But KNN like objective function.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what they propose is something called stochastic nearest neighbor, and so instead of picking from the set of K nearest neighbors, you're going to try to choose one.",
                    "label": 1
                },
                {
                    "sent": "You're going to look at all the points and stochastically choose one with some probability.",
                    "label": 0
                },
                {
                    "sent": "So here's point.",
                    "label": 1
                },
                {
                    "sent": "XI and XI is going to look at all the other points, and it's going to associate a probability with choosing another point as its neighbor.",
                    "label": 0
                },
                {
                    "sent": "OXI will choose XJ as its single neighbor with probability PIJ.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we get that?",
                    "label": 0
                },
                {
                    "sent": "Probability is just a little bit of math, but it's not too complicated.",
                    "label": 0
                },
                {
                    "sent": "Remember, we're trying to learn this embedding, right?",
                    "label": 0
                },
                {
                    "sent": "So XI goes into some mapping or some network.",
                    "label": 0
                },
                {
                    "sent": "This could be linear, or it could be a neural net, or it could be confident and outcomes this vector said.",
                    "label": 0
                },
                {
                    "sent": "So then we're going to compute you're going to do this for both points I and point J.",
                    "label": 0
                },
                {
                    "sent": "We're going to get their embeddings zed.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to compute their distances, and so the probability that their neighbors just depend on these distances.",
                    "label": 0
                },
                {
                    "sent": "So we're exponentiating, and we're normalizing this distances.",
                    "label": 0
                },
                {
                    "sent": "So you can already see what the problem with nearest this this this neighborhood components analysis technique is that it requires this normalization over all of the data points OK, But has this very nice, easily understandable probabilistic interpretation.",
                    "label": 0
                },
                {
                    "sent": "Now, so that's how you select neighbors stochastically.",
                    "label": 0
                },
                {
                    "sent": "Now, what does this smooth cannon like objective function look like?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, the NCA loss says take these probabilities, and for a given point sum them over only the other points that lie in the same class.",
                    "label": 0
                },
                {
                    "sent": "An easier way of saying this is you only want to put probability mass on the guys that are in the same class as you.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you sum the probabilities over the class over the class, the best you could do is put all the probability mass on guys are in the same class and that means voting.",
                    "label": 0
                },
                {
                    "sent": "They would all vote the correct class for you, right?",
                    "label": 0
                },
                {
                    "sent": "So you would get the the KNN classification correct?",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "This is actually smooth because this definition of sorry this definition of.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "P is smooth based on the parameters of this model.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can differentiate this with respect to the parameters of the embedding and train it by gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't matter if you're embedding is linear or it's a neural net or com net, you can differentiate this thing with respect to the parameters, as long as each of the steps in that embedding are differentiable.",
                    "label": 0
                },
                {
                    "sent": "So it's nice that you can just use SGD or another gradient based optimizer.",
                    "label": 0
                },
                {
                    "sent": "It's not so nice because of this normalization term, but there's also no explicit parameter K because we've said let's choose one neighbor stochastically now.",
                    "label": 0
                },
                {
                    "sent": "Recently Danny Tarlow at University of Toronto and colleagues there.",
                    "label": 0
                },
                {
                    "sent": "Define an NCA based objective for K greater than one and they show it working a little bit better, but it is a bit more complicated.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's look at question.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's because of that, the denominator, so it's because.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Love.",
                    "label": 0
                },
                {
                    "sent": "This bottom bottom term if you just tried to draw them all together, we just sort of push them altogether.",
                    "label": 0
                },
                {
                    "sent": "It would collapse, but the fact that you only have so much probability to spread out among amongst the points so that the by nature of being probabilistic, it doesn't collapse.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Yes, so you have time.",
                    "label": 0
                },
                {
                    "sent": "Yes, so this is where the labels come in is it's telling you which points should be close together, right?",
                    "label": 0
                },
                {
                    "sent": "It doesn't necessarily have to be class enables, but you have to have some information about where they are and where that's coming into NCA.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is basically in here you're summing over guys in the same class.",
                    "label": 0
                },
                {
                    "sent": "You can extend NCA to non classification tasks as well.",
                    "label": 0
                },
                {
                    "sent": "Will talk a little bit about that later on.",
                    "label": 0
                },
                {
                    "sent": "Well, because the the embedding is learned, then network can kind of implicitly learn the right scale.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So OK, so I guess one way and what people would typically do in NCS.",
                    "label": 0
                },
                {
                    "sent": "They would regularize as well so you know you're shrinking the weights in that case, but I guess the other is some redundancy.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so in terms of just looking how NCA looking at how NCA works so these are from some kind of toyish smaller datasets, I think these are the Brendan Frey, Brendan Frey faces, USPS digits which are kind of smaller than M NIST.",
                    "label": 0
                },
                {
                    "sent": "If we choose a linear embedding for NCA, and we learn the best setting of this matrix a such that IT projects X to this new vector Z that satisfies at NCA criterion, what is the embedding look like for these different classification problems?",
                    "label": 0
                },
                {
                    "sent": "PCA is kind of terrible.",
                    "label": 0
                },
                {
                    "sent": "You see, the points aren't well separated.",
                    "label": 0
                },
                {
                    "sent": "Same with these other classes, faces are not so bad.",
                    "label": 0
                },
                {
                    "sent": "LDA also doesn't work very well, but NCA actually does reasonably well on these toy days.",
                    "label": 0
                },
                {
                    "sent": "That's a lot better than the other.",
                    "label": 0
                },
                {
                    "sent": "Simple methods Now when you look at.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At M NIS, which is a little bit higher dimensional, NCA actually doesn't work so well.",
                    "label": 0
                },
                {
                    "sent": "So now an amnesty review is a toy data set and completely trivial in 2004.",
                    "label": 0
                },
                {
                    "sent": "NCA wasn't working well on it, but that wasn't considered a deal breaker.",
                    "label": 0
                },
                {
                    "sent": "Now what you can do with NCS, you can extend it to a nonlinear version and we'll talk about that, and it works a lot better.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so nonlinear NCA essentially is just exploiting the fact that this mapping from X to this code space doesn't have to be linear right before in the in the last example we saw was just a matrix A.",
                    "label": 0
                },
                {
                    "sent": "We can now replace this with the neural net Russ Salakhutdinov and Jeff Hinton around the same time that they were doing semantic hashing were also experience.",
                    "label": 0
                },
                {
                    "sent": "Experimenting with nonlinear NCA, and when they were also training these autoencoders, and they considered doing two things at the same time training and with the NCA criterion.",
                    "label": 0
                },
                {
                    "sent": "But also training with an autoencoder objective at the same time to regularize it, and this allows them to take advantage of unlabeled data so they get data points that are unlabeled.",
                    "label": 1
                },
                {
                    "sent": "They can just compute error based on the autoencoder objective and for the points that are actually labeled.",
                    "label": 1
                },
                {
                    "sent": "Then they can use the NCA objective.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What their network actually looks like.",
                    "label": 0
                },
                {
                    "sent": "So we talked about this a little bit earlier using our BMS to train the deep auto encoder.",
                    "label": 0
                },
                {
                    "sent": "Same procedure.",
                    "label": 0
                },
                {
                    "sent": "So you take an image, you map it to 500 binary units.",
                    "label": 0
                },
                {
                    "sent": "You have another 500 Finder 500 by binary RBM.",
                    "label": 0
                },
                {
                    "sent": "Another binary RBM to 2000 and in a top layer PBM that produces a compact code.",
                    "label": 0
                },
                {
                    "sent": "You then unroll those PBM's into this deep autoencoder.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing here that's happening is that at the very top where you're actually performing the reconstruction, so you're mapping this image down to this low dimensional code.",
                    "label": 0
                },
                {
                    "sent": "Then you're reconstructing it.",
                    "label": 0
                },
                {
                    "sent": "You're applying the autoencoder loss, but then at the internal the innermost internal representation here that's low dimensional.",
                    "label": 0
                },
                {
                    "sent": "You're applying the NCA objective to draw these codes together for images that are in the same class.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so when you look at their ability to do an embedding, this is in two dimensions on the emnace data set, it looks way better than the linear case of NCA, 'cause there's a lot more flexibility in that deep net compared to just learning a matrix through the embedding.",
                    "label": 0
                },
                {
                    "sent": "OK, so NCA it's nice.",
                    "label": 0
                },
                {
                    "sent": "It's kind of general.",
                    "label": 0
                },
                {
                    "sent": "You can use it to train any kind of architecture that does the embedding.",
                    "label": 0
                },
                {
                    "sent": "You had a question.",
                    "label": 0
                },
                {
                    "sent": "Oh, I believe that.",
                    "label": 0
                },
                {
                    "sent": "I believe that's test data, but I'm not 100% sure on that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you have to go back in the paper to look at that for details.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, you know, in the in the architecture that they're using for retrieval, they're using 30 dimensional units, so we're obviously making these.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lots in in 2 dimensions, so it's it's a different architecture.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I just wanted to highlight a poster that's going to be here presented by Daniel M, who's in the audience.",
                    "label": 0
                },
                {
                    "sent": "So he graduated recently from Guelph at doing a Masters degree.",
                    "label": 0
                },
                {
                    "sent": "He's working here at Montreal and going back to this idea of.",
                    "label": 0
                },
                {
                    "sent": "Class conditional.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up image the class distance.",
                    "label": 0
                },
                {
                    "sent": "Remember I was saying compared to each of the images in the class instead of looking at each image to image comparison on its own.",
                    "label": 0
                },
                {
                    "sent": "So Daniel and I were working out a way of actually doing a sort of using NCS and inspiration.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To learn a stochastic neighbor selection rule that optimizes image to class rather than image the image distance and he's had some results showing that this actually works better than standard NCA.",
                    "label": 0
                },
                {
                    "sent": "Again, the limitation of this is it still has a quadratic in the number of points.",
                    "label": 0
                },
                {
                    "sent": "You still need to consider a distance from every point every other point, but there's we have some ideas about how to extend that to the linear case, so check out his poster.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think it's today.",
                    "label": 0
                },
                {
                    "sent": "Got today.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's the NCA family of criterion.",
                    "label": 0
                },
                {
                    "sent": "Now there's also something I mentioned called Doctor Lim, and this is out of the NYU Group, so the advantage of Doctor Lim over NCA is that you don't have this normalization term, so it's no longer probabilistic, but you can do online learning with it, so you only need to care.",
                    "label": 0
                },
                {
                    "sent": "Consider pairs of data points at a time.",
                    "label": 0
                },
                {
                    "sent": "And so it takes a pretty simple objective function, so you can use this again to training trained Siamese Nets.",
                    "label": 0
                },
                {
                    "sent": "Your Siamese Nets output codes and then you determine a loss function that has two terms.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first term is called the similarity loss, so this applies when you have similar data points, we're going to assume similar data points.",
                    "label": 1
                },
                {
                    "sent": "This SIJ is an Indic binary indicator variable, and it's one when the points are similar, so similar could mean coming from the same class.",
                    "label": 0
                },
                {
                    "sent": "So when they're similar, the similarity losses apply.",
                    "label": 0
                },
                {
                    "sent": "Dan, this is a quadratic in their distance, right?",
                    "label": 1
                },
                {
                    "sent": "So the points should be similar in the same class you're going to pay a quadratic cost, they pay more and more costs to further their apart, and then when they are not similar so they're in different classes and you pay this dissimilarity loss, which is basically the same thing.",
                    "label": 0
                },
                {
                    "sent": "It's still quadratic, but it cuts off after a certain point, so it allows dissimilar points to lie outside a window of each other.",
                    "label": 1
                },
                {
                    "sent": "And essentially it doesn't care about them once they've fallen outside this margin.",
                    "label": 0
                },
                {
                    "sent": "So once this is where you see in the red curve, so the blue curve is a similarity loss.",
                    "label": 0
                },
                {
                    "sent": "If points are far apart and they should be the same class, then you pay a cost.",
                    "label": 0
                },
                {
                    "sent": "If points are in different classes and their close together, you're going to pay a cost until they get outside this margin.",
                    "label": 0
                },
                {
                    "sent": "Another way of looking at this.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Through a spring analogy, so when you're considering a particular point and looking at neighbors within the same or points within the same class, these guys are all being pulled together via that loss function, regardless of how far away they are and the strength of these Springs is going to depend on the distance, right?",
                    "label": 1
                },
                {
                    "sent": "And then points that are in different classes, which are the hollow points those guys are repelled.",
                    "label": 1
                },
                {
                    "sent": "So these guys are getting repelled, but once they get outside that radius you don't care about them anymore, so.",
                    "label": 0
                },
                {
                    "sent": "Basically, the algorithm is not wasting modeling effort on pushing these points further and further away that are coming from different classes.",
                    "label": 0
                },
                {
                    "sent": "OK, so the margin.",
                    "label": 0
                },
                {
                    "sent": "The Alpha parameter unfortunately is is a hyperparameter needs to be tuned, but people generally.",
                    "label": 0
                },
                {
                    "sent": "I mean there's there's not a lot of sensitivity generally in that parameter.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the the work that considered document proposed Doctor Lim considered this NORB data set.",
                    "label": 0
                },
                {
                    "sent": "Who's here heard of Nortb?",
                    "label": 0
                },
                {
                    "sent": "OK, a lot of people.",
                    "label": 0
                },
                {
                    "sent": "So some people that haven't heard of it.",
                    "label": 0
                },
                {
                    "sent": "It's a bunch of images taken of toy objects so airplanes, trucks, cars, people and animals and their capture under different lighting conditions and different azimuth.",
                    "label": 0
                },
                {
                    "sent": "So azimuth is this angle around that you're seeing around here and different elevations which you can see sort of overhead the plane versus looking at the side view of the plane and so forth.",
                    "label": 0
                },
                {
                    "sent": "And so if you use Doctor Lim to learn an embedding from the NORB data set where you have a very explicitly defined neighborhood graph.",
                    "label": 0
                },
                {
                    "sent": "You learn embedding to 3 dimensions.",
                    "label": 0
                },
                {
                    "sent": "It gives you something that cylindrical.",
                    "label": 0
                },
                {
                    "sent": "So let me just take a second to explain the neighborhood information that was given to this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what it was told is that neighbors should be.",
                    "label": 0
                },
                {
                    "sent": "The same object that are within two neighbors away in terms of its azimuth.",
                    "label": 0
                },
                {
                    "sent": "So this guy would be neighbors with this guy and this guy as well as this guy and this guy an also.",
                    "label": 0
                },
                {
                    "sent": "Ones that are one elevation away so one elevation would be one hop in this direction.",
                    "label": 0
                },
                {
                    "sent": "Either way, it doesn't care about lighting, so it's your neighbors regardless of the lighting.",
                    "label": 0
                },
                {
                    "sent": "And so when you give Doctor Lim that neighborhood similarity information which is used to define that S variable which points are similar in which are not, then you get this roughly cylindrical embedding.",
                    "label": 0
                },
                {
                    "sent": "So it's essentially it's learn to organize these objects at different azimuths around the exterior of the single cylinder and then.",
                    "label": 0
                },
                {
                    "sent": "Sort of along the length of the cylinder.",
                    "label": 0
                },
                {
                    "sent": "You're getting changes in azimuth lighting.",
                    "label": 0
                },
                {
                    "sent": "It is learned to be invariant to lighting, so you'll see essentially clusters of six points together, and those are representing images of different lighting conditions.",
                    "label": 0
                },
                {
                    "sent": "They are all embedded closely together.",
                    "label": 0
                },
                {
                    "sent": "OK, so again, downside of NCA is having to give it or Doctor Lim is having to give it all this information about the neighborhood class structure to get in a nice embedding like this.",
                    "label": 0
                },
                {
                    "sent": "And this was in terms of the architecture that was used.",
                    "label": 0
                },
                {
                    "sent": "It was a Siamese confident sort of Lynette 5 style at the back.",
                    "label": 0
                },
                {
                    "sent": "Correct top of the top of the cylinder and then the sides of the cylinder.",
                    "label": 0
                },
                {
                    "sent": "Yeah, 3D projected into 2D.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so the last type of objective function that's quite popular and I want to cover today is triplet based embedding.",
                    "label": 0
                },
                {
                    "sent": "OK, so we talked about Doctor Lim being a pairwise embedding, so triplet embeddings look at three data points together so typically will call them the anchor.",
                    "label": 0
                },
                {
                    "sent": "So we'll call XI.",
                    "label": 0
                },
                {
                    "sent": "The anchor will look at a positive point and a negative point.",
                    "label": 0
                },
                {
                    "sent": "And what this means is that the positive point should be more similar to the anchor.",
                    "label": 0
                },
                {
                    "sent": "Then the negative point.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have some similarity score associated with these inputs and then you want to learn an embedding such that for cases where the similarity is, you know for the positive example to the anchor is greater than the similarity of the negative guide to the anchor, you want the distance between the positive guide to the well, the embedded distance between the positive side of the anchor to be smaller than the distance between the.",
                    "label": 1
                },
                {
                    "sent": "Negative guide to the anchor.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a bit of a mouthful, so you know you want to put points that the positive guy should be embedded closer to the anchor than the negative guy, basically.",
                    "label": 0
                },
                {
                    "sent": "OK, so this I think the first time this was proposed was in a paper called Oasis Oasis from some authors at Google.",
                    "label": 0
                },
                {
                    "sent": "I'm not 100% sure on this.",
                    "label": 0
                },
                {
                    "sent": "I haven't been able to uncover any references before this, but I kind of.",
                    "label": 0
                },
                {
                    "sent": "I have this feeling that people had discovered this before then.",
                    "label": 0
                },
                {
                    "sent": "Do you Yoshua know?",
                    "label": 0
                },
                {
                    "sent": "If people were doing triplet embeddings before Oasis?",
                    "label": 0
                },
                {
                    "sent": "I haven't been able to find it, but it seems like an idea that people have the same thing about reluz.",
                    "label": 0
                },
                {
                    "sent": "Someone was asking why didn't people consider relatives in the in the 90s, so it might have been just one of those ideas that wasn't really proven.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So in this original paper Oasis, the authors considered essentially handcrafted features, sparse features from images.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And more recently, this has been incorporated into deep learning where you're actually doing a feature learning pipeline using this triplet based objective as your error measure, and so there is a recent paper from some researchers at Google and Northwestern University where their learning a specialized type of commnet todo embeddings.",
                    "label": 0
                },
                {
                    "sent": "So there's a little bit of architectural difference here between this confident in the standard ones that you saw in Hong Lex talk.",
                    "label": 0
                },
                {
                    "sent": "So what you have is sort of a standard Alex net.",
                    "label": 0
                },
                {
                    "sent": "This is the image.",
                    "label": 0
                },
                {
                    "sent": "Net 2012.",
                    "label": 0
                },
                {
                    "sent": "Type of pipeline has seven layers, but you also have these low resolution pipelines, so you have.",
                    "label": 0
                },
                {
                    "sent": "These are not really calm, that's just a convolution plus a subsampling layer plus and essentially what you're doing is you're taking two low resolution pipelines that capture sort of more global information about the image, and then combining that with information that's coming out from standard commnet and representation.",
                    "label": 0
                },
                {
                    "sent": "That's kind of invariant to certain properties of global properties of the image.",
                    "label": 0
                },
                {
                    "sent": "Ann, you're combining those after normalization into a linear layer and then forming a code.",
                    "label": 0
                },
                {
                    "sent": "OK, So what these authors did is they use this triplet based comparison and that's sort of the natural cost function to go with these triplet based criterions is a hinge loss.",
                    "label": 0
                },
                {
                    "sent": "So it's essentially saying you know when your distance between the anchor, the embedded distance between the anchor and the negative guy is greater than the distance between the anchor in the positive guy.",
                    "label": 0
                },
                {
                    "sent": "You won't pay any is greater than some gap, then you won't play any cost, but as soon as your distance between the anchor and the positive side gets bigger.",
                    "label": 0
                },
                {
                    "sent": "Then you're going to suffer some loss right?",
                    "label": 0
                },
                {
                    "sent": "'cause you want the distance between the anchor in the positive to be smaller, so standard hinge loss function and they are able to train train pretty nice embedding model.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now 1 issue that they face an basically all of these models face that are doing pairwise or triplet based embeddings is how to select these triplets because they blow up pretty quickly.",
                    "label": 0
                },
                {
                    "sent": "So if you're considering.",
                    "label": 0
                },
                {
                    "sent": "12 million images, which is what these authors considered.",
                    "label": 0
                },
                {
                    "sent": "You're getting something on the order of 10 to the 21 triplets because the number of triplets increases cubically with the number of images that you have.",
                    "label": 0
                },
                {
                    "sent": "They also find that the optimization converges and only after looking at 24 million triplets.",
                    "label": 0
                },
                {
                    "sent": "So that's way less than this, right?",
                    "label": 0
                },
                {
                    "sent": "You don't have to exhaustively look at all possible triplets.",
                    "label": 0
                },
                {
                    "sent": "And when I was training these sorts of models, I was actually struggling with these issues as well in terms of what?",
                    "label": 0
                },
                {
                    "sent": "Trip list do you look at so?",
                    "label": 0
                },
                {
                    "sent": "They've proposed sort of based on efficiency.",
                    "label": 0
                },
                {
                    "sent": "Kind of a nice approach where they insert a layer before their Siamese.",
                    "label": 0
                },
                {
                    "sent": "This is now a sort of a Siamese triplet network that draws samples that draws triplet samples in a, not a sort of a uniform way.",
                    "label": 0
                },
                {
                    "sent": "So let's just go over through the basic intuition behind this.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what they want to do is they first they sample an anchor image according to its relevance for a category.",
                    "label": 0
                },
                {
                    "sent": "So let's say all of the points come from categories that could be classes.",
                    "label": 0
                },
                {
                    "sent": "And the relevance within the category is based on the similarity of that image with all of the other images within the category.",
                    "label": 0
                },
                {
                    "sent": "So they want to choose relevant anchors and then they go and they sample a positive image that has high relevance within that category as well, so they don't care about positives that have low relevance, 'cause they're probably going to bed far apart anyways.",
                    "label": 0
                },
                {
                    "sent": "And then they go and they pick two types of negative images.",
                    "label": 0
                },
                {
                    "sent": "They pick ones that are out of class.",
                    "label": 0
                },
                {
                    "sent": "In that case they just sample them uniformly from the other classes.",
                    "label": 0
                },
                {
                    "sent": "But they also sample in class negatives that should be relevant.",
                    "label": 0
                },
                {
                    "sent": "OK, so they go.",
                    "label": 0
                },
                {
                    "sent": "They use the same relevance measure.",
                    "label": 0
                },
                {
                    "sent": "They pick relevant negatives because those are the ones that the network is being fooled by, but they ensure that there's a margin.",
                    "label": 0
                },
                {
                    "sent": "In terms of the similarity between the positive and the negative example, yes.",
                    "label": 0
                },
                {
                    "sent": "This point right here.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Northwind 4th Bullet Third Point.",
                    "label": 0
                },
                {
                    "sent": "Yeah, these guys are sort of these two sort of fit into the Third Point.",
                    "label": 0
                },
                {
                    "sent": "It could be one or the other, so this is coming from the same category, but it had an.",
                    "label": 0
                },
                {
                    "sent": "It's also relevant, but it's less relevant than the positive example they already selected.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a fooling example or or a hard negative.",
                    "label": 0
                },
                {
                    "sent": "Sometimes people call it.",
                    "label": 0
                },
                {
                    "sent": "What's the?",
                    "label": 0
                },
                {
                    "sent": "What's the constraint?",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "It's a hyperparameter that's based on the similarity between the.",
                    "label": 0
                },
                {
                    "sent": "So you can look at the similarity between the positive example in the anchor and this negative example in the anchor, and you're going to make sure that there's a certain gap between them.",
                    "label": 0
                },
                {
                    "sent": "That makes sense.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So for one thing, it may be, and this is particularly relevant to this example.",
                    "label": 0
                },
                {
                    "sent": "Computing that similarity score on the fly might be very expensive.",
                    "label": 0
                },
                {
                    "sent": "Seem so.",
                    "label": 0
                },
                {
                    "sent": "In this case, the way that these authors determine the similarity was they call it the Golden feature.",
                    "label": 0
                },
                {
                    "sent": "They don't actually publish any details about it, so I guess it's an internal secret at Google, but essentially, it's based on something like 27 features that are extracted from the images and also from some textual information associated with the images.",
                    "label": 0
                },
                {
                    "sent": "It's quite a complicated procedure, so you absolutely keep trying to look up in a data space like Google Image Search or something like that.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't want to.",
                    "label": 0
                },
                {
                    "sent": "Extract that sort of at at query time you say somebody uploads an image and you want to find it.",
                    "label": 0
                },
                {
                    "sent": "You don't want to run that feature extraction pipeline, so it's more efficient to compute this low dimensional code through a forward pass in the neural net, for example.",
                    "label": 0
                },
                {
                    "sent": "Then doing this very complicated procedure.",
                    "label": 0
                },
                {
                    "sent": "That sound reasonable.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just sort of a sketch.",
                    "label": 0
                },
                {
                    "sent": "You can read the details and there's some math behind.",
                    "label": 0
                },
                {
                    "sent": "Basically the math behind these distributions.",
                    "label": 0
                },
                {
                    "sent": "That's kind of an overview of how they're drawing the samples.",
                    "label": 0
                },
                {
                    "sent": "Now what they're doing is they're actually proposing a way to do this online where you don't have to put all of these examples in memory, 'cause you might not be able to fit a very large database in memory, and So what they're doing is they're keeping buffers for each class or each category.",
                    "label": 0
                },
                {
                    "sent": "And they add examples to these buffers with these ratios or these probabilities.",
                    "label": 0
                },
                {
                    "sent": "So then at you know at training time you're drawing examples uniformly from these buffers, but the the distribution you're getting respects the distribution for which they were in which they were added basically, right?",
                    "label": 0
                },
                {
                    "sent": "So it's kind of it they call it reservoir sampling.",
                    "label": 0
                },
                {
                    "sent": "There's some older work that uses this, but it's.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "It's a neat trick, and this I just want to add.",
                    "label": 0
                },
                {
                    "sent": "This came up at lunch.",
                    "label": 0
                },
                {
                    "sent": "We were talking about.",
                    "label": 0
                },
                {
                    "sent": "Leon Bottou's talk and him talking about you know the problem at doing sort of IID test time examples and then idea that came up was maybe more of these networks need to have some sort of layer before learning in terms of selecting appropriate examples for learning Lyons.",
                    "label": 0
                },
                {
                    "sent": "Talking more about test time, but this could apply to things like curriculum learning as well as we're talking about at lunch, right?",
                    "label": 0
                },
                {
                    "sent": "So anyway, this is a very efficient way to handle the enormous number of.",
                    "label": 0
                },
                {
                    "sent": "Triplets.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Some of the limitations here Enciende.",
                    "label": 0
                },
                {
                    "sent": "Doctor Lim?",
                    "label": 0
                },
                {
                    "sent": "We saw that they were using a binary notion of similarity that was determined either by class information or it was determined by this neighborhood graph.",
                    "label": 1
                },
                {
                    "sent": "In the case of the norm data set.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This deep ranking paper I just talked about from Google was using this Golden feature, which is a very complicated pipeline.",
                    "label": 0
                },
                {
                    "sent": "Determine relevance between images.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not all of us have access to these datasets.",
                    "label": 0
                },
                {
                    "sent": "For certain certain domains, and even though we have services like Amazon Turk out there which can go in label data for us, asking people to label images as semantically relevant or not is inconsistent amongst observers, right?",
                    "label": 0
                },
                {
                    "sent": "It's difficult for them to do so in the Google Paper.",
                    "label": 0
                },
                {
                    "sent": "What they did is they had three raters for each of the images, and they only accepted it as an evaluation triplet.",
                    "label": 0
                },
                {
                    "sent": "If the Raiders were unanimous.",
                    "label": 0
                },
                {
                    "sent": "Right, but that requires a fairly large budget on Turk.",
                    "label": 0
                },
                {
                    "sent": "If you're going to do this.",
                    "label": 0
                },
                {
                    "sent": "So the last thing I want to talk about here is techniques that don't necessarily require you to.",
                    "label": 0
                },
                {
                    "sent": "Do you explicit labeling?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we wanted to really do is look at unconstrained images and video, so that sort of YouTube quality where there's various degrees of.",
                    "label": 0
                },
                {
                    "sent": "Fidelity in this in the signal and so Ian Spiro, who was a grad student at NYU.",
                    "label": 0
                },
                {
                    "sent": "You worked out an interface by which which one could label just the hands in the head very quickly of an individual.",
                    "label": 0
                },
                {
                    "sent": "So we were working on another project the same time that was investigating politician body language.",
                    "label": 0
                },
                {
                    "sent": "So I don't know if anybody remembers this guy.",
                    "label": 0
                },
                {
                    "sent": "Maybe Natalia does, so he was quite an animated character, so we were we were using this tool.",
                    "label": 0
                },
                {
                    "sent": "And basically it was it was predicting where their poses go.",
                    "label": 0
                },
                {
                    "sent": "Assuming that pose is going to be smooth and in video and so forth.",
                    "label": 0
                },
                {
                    "sent": "And so the the annotator would only note need to go back and fix up the errors made by the annotation tool.",
                    "label": 0
                },
                {
                    "sent": "So this allowed us to annotate peoples head in hands.",
                    "label": 0
                },
                {
                    "sent": "Very quickly.",
                    "label": 0
                },
                {
                    "sent": "OK, zero Noske always gets a few less.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we did back then was we trained a opposed sensitive embedding technique that took a database that was labeled by peoples hands and head and sort of use that as a proxy for pose.",
                    "label": 0
                },
                {
                    "sent": "So we quickly label it on Mechanical Turk and then we could come along with.",
                    "label": 0
                },
                {
                    "sent": "A Siamese neural net.",
                    "label": 0
                },
                {
                    "sent": "In this case learning embedding just like I talked about and then we could take.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The query search the database, find nearest neighbors and then we could even do sort of nearest neighbor based regression to say OK, we think the persons head in their hands are here.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbor was quick because we learned low dimensional codes, but it also learned invariant representation, so is invariant to clothing and scale background lighting and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we use as our error criterion was NCA, but remember, NCA is based on classification, so nearest neighbor classification, so we actually changed the NCA term to take into account the fact that we had labeled information about the poses of the individual.",
                    "label": 0
                },
                {
                    "sent": "So the wise in this case, or 6 dimensional vectors which represent the X&Y location of the hands that the left and the right hand in the head, and essentially what we would do then, is we flip this around, and we said minimizes instead of maximize it.",
                    "label": 0
                },
                {
                    "sent": "So we don't want you to put probability on guys where their poses live very far apart in terms of the Euclidean distance, right?",
                    "label": 0
                },
                {
                    "sent": "So we had a convolutional neural network that would output and embedding.",
                    "label": 0
                },
                {
                    "sent": "We would determine the probability from the distance in that embedding and then we would wait that by the label information which was supposed.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We train that with gradient descent, we and we tested this on data set, called SNOWBIRD where we recorded everybody at the 2010 Workshop Yahshuah was there.",
                    "label": 0
                },
                {
                    "sent": "I don't know if anybody else was there, and then we distribute these right after the talks in Mechanical Turk and.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But labels right away, so Roland mentioned just earlier, which was sort of a global feature transform based on Fourier coefficients.",
                    "label": 0
                },
                {
                    "sent": "I think hung like even had some results that we're using, just it's a global descriptor.",
                    "label": 0
                },
                {
                    "sent": "It's a bit better than pixel based distance, but it produces a 512 dimensional code, so it's a little bit slow to work with.",
                    "label": 0
                },
                {
                    "sent": "We tried linear and convolutional variants of our technique using NCA based objective, and we also had a doctor Lim.",
                    "label": 0
                },
                {
                    "sent": "Style objective using the pose information as well, so we compare the.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we used a condom.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But to do the embedding and we found sort of here you can see qualitatively what it does, the techniques that use convolutional Nets and either the NCA or Doctor Lim style objective did really well in terms of their matches.",
                    "label": 0
                },
                {
                    "sent": "This is so this is a query image and then this is the nearest neighbor from the database that was received, did a reasonable job of matching, and the error here.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the error between the located the OR the found pozan the pose of the query.",
                    "label": 0
                },
                {
                    "sent": "We've superimposed with magenta here.",
                    "label": 0
                },
                {
                    "sent": "The pose that's been copied from the nearest neighbor it from C Ncar an it's actually seems to be capturing even though we just label the head in hands, something more substantial about the overall pose of the body.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of the qualitative results, what these techniques do on average, we tried two different datasets, so we had this real SNOWBIRD data set, and then we also had synthetic data where we could just produce a whole lot of different poses on the synthetic data.",
                    "label": 0
                },
                {
                    "sent": "It was on average of 25.4 pixel error for our technique, which is better than the other embedding methods, and that corresponds to a radius of this.",
                    "label": 0
                },
                {
                    "sent": "This distance around the hands, and then for the real data set it was a 16.4 pixel error on a smaller resolution image.",
                    "label": 0
                },
                {
                    "sent": "And that corresponds to sort of an average.",
                    "label": 0
                },
                {
                    "sent": "Getting the hands within that radius.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I mentioned in the five years since we did this work, there's been some real serious advancements.",
                    "label": 0
                },
                {
                    "sent": "I don't know what that is.",
                    "label": 0
                },
                {
                    "sent": "Do you know what that is?",
                    "label": 0
                },
                {
                    "sent": "Is there a phone?",
                    "label": 0
                },
                {
                    "sent": "Oh there is a phone here.",
                    "label": 0
                },
                {
                    "sent": "Bizarre OK.",
                    "label": 0
                },
                {
                    "sent": "So I like.",
                    "label": 0
                },
                {
                    "sent": "I don't think I think I'm still doing OK for time, right?",
                    "label": 0
                },
                {
                    "sent": "Have 2010 minutes.",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "OK, that's why I thought.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Anyways, so I was saying is in 2010 we did this work.",
                    "label": 0
                },
                {
                    "sent": "You know five years ensued and there's been a lot of progress on datasets that are labeled with two depots information.",
                    "label": 0
                },
                {
                    "sent": "So there's a paper from last year CPR by Misha Andrew Luca, and he proposes this Max Planck Institute for Informatics Human pose data set.",
                    "label": 0
                },
                {
                    "sent": "They have about 40,000 examples of people labeled with a full skeleton, so including 16 different joints where we only considered 3.",
                    "label": 0
                },
                {
                    "sent": "And these people are doing all kinds of different activities, so they're doing 491 different activities.",
                    "label": 0
                },
                {
                    "sent": "Alot of previous datasets, even the bigger ones like lead sports would only be focused on sports or somewhere only sort of focused on people wearing funny clothing.",
                    "label": 0
                },
                {
                    "sent": "You know people indoors stuff like that.",
                    "label": 0
                },
                {
                    "sent": "This is a very diverse data set.",
                    "label": 0
                },
                {
                    "sent": "So recently some researchers at Google.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Including a Greg Morey who's a faculty member at Simon Fraser here in Canada.",
                    "label": 0
                },
                {
                    "sent": "He is doing his sabbatical there.",
                    "label": 0
                },
                {
                    "sent": "They did something very similar in motivation to our work, but they use a better database.",
                    "label": 0
                },
                {
                    "sent": "They used a triplet style learning instead of NCAR doctor Lim, and they also scaled up the type of comment.",
                    "label": 0
                },
                {
                    "sent": "So five years ago we didn't have Alex Net.",
                    "label": 0
                },
                {
                    "sent": "We didn't have inception, they're using this Google Inception style comment that hung like just talked about.",
                    "label": 0
                },
                {
                    "sent": "Which is this big?",
                    "label": 0
                },
                {
                    "sent": "Big Deep commnet and essentially they they perform reasonable embedding so you can see if you want to see a modern version of that.",
                    "label": 0
                },
                {
                    "sent": "You can look at the paper on archive that was put there just in just in June.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the final part of the talk.",
                    "label": 0
                },
                {
                    "sent": "There's a couple of things I'd like to highlight, which is can we do these sorts of embedding without labeling explicitly body parts or other other things in other data domains?",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this again, this works a little bit older, but I like to highlight it 'cause it's one of my favorite projects that I ever did.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of fun.",
                    "label": 0
                },
                {
                    "sent": "We had a rock banner or they call themselves a like an Electro.",
                    "label": 0
                },
                {
                    "sent": "Now I forget.",
                    "label": 0
                },
                {
                    "sent": "Electro progressive group from the Netherlands who made a music video and some of you may have seen this already.",
                    "label": 0
                },
                {
                    "sent": "'cause I often talk about this.",
                    "label": 0
                },
                {
                    "sent": "They have a video where they're, you know, just doing cool band stuff, making funky poses and doing this to music obviously, and then they have a web interface where people.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually imitate them through a webcam.",
                    "label": 0
                },
                {
                    "sent": "Frame by frame.",
                    "label": 0
                },
                {
                    "sent": "OK, so this actually turns out to be a very cool data set for learning these sorts of embeddings, because you can look and these are just like I was saying before.",
                    "label": 0
                },
                {
                    "sent": "The pixels are completely different, right?",
                    "label": 0
                },
                {
                    "sent": "But the semantic information is the same now.",
                    "label": 0
                },
                {
                    "sent": "The caveat here is it's restricted to one particular domain we care here about pose, so this is not really working outside of this domain, but for this particular domain we're getting really rich data of people performing the same pose and all kinds of.",
                    "label": 0
                },
                {
                    "sent": "Means of variation.",
                    "label": 0
                },
                {
                    "sent": "So the other thing is not only within a single frame, we could also look between frames, assuming that video is smooth and assume that people that are nearby temporally.",
                    "label": 0
                },
                {
                    "sent": "Share similar posts.",
                    "label": 0
                },
                {
                    "sent": "That idea is called temporal coherence, and we're not the first ones to use temporal coherence.",
                    "label": 0
                },
                {
                    "sent": "But this is a very nice signal that can be used from video data to inform your algorithm, so maybe even beyond this application, often you consider this idea of temporal coherence, and this allows you to do weekly supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So again, one of my favorite papers ever worked on to CVP.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "PR paper you can check it out if you want to read more and see the video more recently, Mohammed Nuru see the guy that did the multiindex hashing at Google, he's doing a Google internship and he worked on zero shot learning where they were looking at embeddings of multiple domains and I also saw Hong Lac was trying to get to this at the very end and didn't quite make it so I'm glad to have a chance to talk.",
                    "label": 0
                },
                {
                    "sent": "Talk for a couple of seconds on it.",
                    "label": 0
                },
                {
                    "sent": "So basically the idea is you do.",
                    "label": 0
                },
                {
                    "sent": "Semantic embeddings of word vectors.",
                    "label": 0
                },
                {
                    "sent": "And that allows you to essentially build a bridge from words through the class labels back to images through a recognition model.",
                    "label": 0
                },
                {
                    "sent": "So in other words, you have an image net style recognition model.",
                    "label": 0
                },
                {
                    "sent": "You have a word embedding model and you're using class.",
                    "label": 0
                },
                {
                    "sent": "Then the words on the class labels as the link between the two of them.",
                    "label": 0
                },
                {
                    "sent": "So the problem here is what you're trying to do is at Test time you're trying to classify an image which has a class label you've never observed before, so here it's dress or frock.",
                    "label": 0
                },
                {
                    "sent": "So this is not in the training database, or in this case I can't even read that now.",
                    "label": 0
                },
                {
                    "sent": "Sorry if I can't read it, you probably can't read it.",
                    "label": 0
                },
                {
                    "sent": "Ratite red eyed bird, flightless bird.",
                    "label": 0
                },
                {
                    "sent": "In that case, you're trying to put that label on it, but you never seen that label before.",
                    "label": 0
                },
                {
                    "sent": "So what's happening here?",
                    "label": 0
                },
                {
                    "sent": "Is there actually they've?",
                    "label": 0
                },
                {
                    "sent": "This is a very simple approach.",
                    "label": 0
                },
                {
                    "sent": "They've taken Alex net style image net.",
                    "label": 0
                },
                {
                    "sent": "Com.",
                    "label": 0
                },
                {
                    "sent": "Net, which goes from image to distribution of work over object categories, and they've taken Google's word to VEC embedding model, which goes from a word to a vector representation, and they essentially take the output of the softmax in the recognition model, and that essentially allows you to define the weightings between these different word embeddings.",
                    "label": 0
                },
                {
                    "sent": "So the example that they use in that paper is.",
                    "label": 0
                },
                {
                    "sent": "Say you put an image in and you get output for the classes.",
                    "label": 0
                },
                {
                    "sent": "Oh point, 6 Tiger, an oh point 4 lion.",
                    "label": 0
                },
                {
                    "sent": "OK, so now you you go and you look in your embedding space on these word vectors and you combine oh point 6 lion on that word vector with oh point 4 Tiger on the word vector and you get another one.",
                    "label": 0
                },
                {
                    "sent": "You see, look what's close to that and it should be Liger because it should be close.",
                    "label": 1
                },
                {
                    "sent": "This is what's the movie that the lock.",
                    "label": 0
                },
                {
                    "sent": "Sorry Napoleon dynamite yeah, this conference of the movie.",
                    "label": 1
                },
                {
                    "sent": "OK, Napoleon dynamite, you find Liger even though you've never seen longer before as a training example, it's somewhere sort of in the middle of the examples that the labels that you had seen before.",
                    "label": 0
                },
                {
                    "sent": "So it's a nice way of connecting word embeddings to recognition model so you can check that out.",
                    "label": 0
                },
                {
                    "sent": "Mohammed noroozi and.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Basically, I'm going now to summarize everything I've talked about, so we looked at three different paradigms for doing embeddings, learning similarity, learning to compare whatever you want to call it.",
                    "label": 0
                },
                {
                    "sent": "We talked about unsupervised techniques where you basically did representation learning and hope for the best, use clever methods of regularization you use advanced learning algorithms, but you still couldn't control points that got where was similar and got embedded to different places.",
                    "label": 0
                },
                {
                    "sent": "So you can introduce supervised information in domains where you have labels available to you and we looked at different objective functions, so we focused on Doctor Limon NCA, triplet embeddings, and so forth, and then finally I gave a couple of pointers to some weakly supervised techniques, sort of variants that don't really fit into the unsupervised or supervised learning paradigm that are still sort of similarity based research projects.",
                    "label": 0
                },
                {
                    "sent": "So in closing.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So where do we go from here?",
                    "label": 0
                },
                {
                    "sent": "Think we're going to still keep pushing on architectural improvements?",
                    "label": 0
                },
                {
                    "sent": "That seems to me what's happened in the last five years.",
                    "label": 0
                },
                {
                    "sent": "People have really moved to where it's comments, and now they're looking at specialized architectures that are really efficient in terms of parameter spaces using multiscale techniques.",
                    "label": 0
                },
                {
                    "sent": "Going very deep people will keep pushing on this, and also they'll start thinking more about mapping this to the hardware.",
                    "label": 0
                },
                {
                    "sent": "So you want to sort of sparse computations that doesn't really fit right now with today's hardware.",
                    "label": 0
                },
                {
                    "sent": "So what kind of specialized hardware architectures can you use to learn these embeddings?",
                    "label": 0
                },
                {
                    "sent": "And then also do search within these embeddings?",
                    "label": 0
                },
                {
                    "sent": "Databases are only going to continue to grow, so this last point I just was talking about also plays a role here in terms of speeding up search.",
                    "label": 0
                },
                {
                    "sent": "Hashing techniques will still continue to be innovative and then finally will be probably rolling about rolling out these embedding techniques to domains beyond the classical image, video, speech and our audio and text, right?",
                    "label": 0
                },
                {
                    "sent": "So hopefully we'll see these in other domains where there's just not that much labeled data.",
                    "label": 0
                },
                {
                    "sent": "I think that's probably where unsupervised learning is going to play more of a role.",
                    "label": 0
                },
                {
                    "sent": "So with that I know there's one question out there waiting.",
                    "label": 0
                },
                {
                    "sent": "I'll thank you for your attention and look forward to talking to you again tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}