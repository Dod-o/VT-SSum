{
    "id": "vzvqthoegujnjxxfzldw6fwknkjxymcf",
    "title": "Let the Shape Speak - Discriminative Face Alignment using Conjugate Priors",
    "info": {
        "author": [
            "Pedro Martins, Institute for Systems and Robotics, University of Coimbra"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Shape Analysis"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_martins_conjugate_priors/",
    "segmentation": [
        [
            "So let me start by showing."
        ],
        [
            "What we are trying to do here we are doing face alignment.",
            "Our aim is to to align faces that were not previously seen by the detector.",
            "So this is.",
            "This is somehow related to active constraint local models or active shape models where we get where we use the shape model and the set of local detectors associated which.",
            "Which 11 mark on the on the model?",
            "So I'll be showing this video again."
        ],
        [
            "At the end, right now I must continue so.",
            "Typically, fitting such a model involves 2 steps.",
            "First we search for each tackle.",
            "Each detector we perform a local search, producing a response map for for all the landmarks.",
            "Then there's a.",
            "Something called the global optimization strategy that aims to find the shape parameters that maximizes all the responses at once.",
            "So in this work we actually propose a new global optimization strategy using a Bayesian approach, where in fact we use.",
            "We use the prior distribution to dynamic to encode the dynamically transition of the shape parameters."
        ],
        [
            "So this is a brief brief review.",
            "This kind of work can be either generative or discriminative.",
            "The difference is how do we model the texture in them?",
            "So in this case will be more.",
            "Gen 2 two.",
            "It works better on unseen people, so in both cases we actually use the shape model, which is also known as a point distribution model, where we learn from previous annotations the mean them in shape.",
            "A matrix with the principal components and shape parameters the shipping which is controlled is different motion and we have also the for similarity pose parameters.",
            "So.",
            "Given given vector measurement vector Y, we want to.",
            "Our goal is to find the best set of shape parameters that maximize these posterior so we can reduce the complexity of this problem by making some assumptions.",
            "The first assumption could be.",
            "Assume conditional independence within one marks.",
            "This can be done by simply by simply scanning each landmark independently.",
            "And the the product.",
            "Also, you can assume."
        ],
        [
            "That we are near solution and we actually use the prior to model out the Shepherd meters change."
        ],
        [
            "So a little bit in detail, their likelihood likelihood will follow Gaussian farm, so we are aiming to extract from each response map only a single Gaussian.",
            "So we get Y our observation an over.",
            "Here we get our uncertainty since we do is, we assume conditional independence within one marks.",
            "These uncertainties will be a block diagonal matrix with blocks to buy tools.",
            "So just for notation sake we define this Delta Delta Y which which is simply this difference and.",
            "In summary, the likelihood followed this a Gaussian, where the mean is function of the shape parameters."
        ],
        [
            "So the typical detectors that are used to locate the landmarks are based on solving a linear SVM where the positive examples are patches that are aligned and the negative examples are slightly misaligned examples.",
            "So we we learn an SVM for each detector and we scan around around that region for in the search phase, although this is."
        ],
        [
            "A good approach.",
            "We actually use something else that works better.",
            "Something like something colored Demoss filter.",
            "So in this video we show the SVM.",
            "Typical detectors use it in this class of works and the response from the most filter within this case with each case.",
            "Produce always Gaussian like responses.",
            "You can see over here we get a lot of confusion between the eyes and the eyebrows and over here we get a strong response."
        ],
        [
            "So in brief, the the most filters were proposed in 2010 and the goal is to see that the correlation is the freedom of the input image and the filter in the most filter we aim to find this filter that by setting the output correlation to be Gaussian, so these input images will be our alignment examples, which must be composed with the cosine window which is required for the Fourier transform.",
            "The solution is given by this.",
            "And actually, you can see these filters by using the investments form.",
            "Then the filters look like this.",
            "And again, this is our response is taken over that location."
        ],
        [
            "So even the filters work.",
            "Quite well, they are not perfect.",
            "We get here some results when we had one.",
            "We have lots of good lots of texture.",
            "We have a good response like this one but.",
            "In some other cases we need to use someone something else so and I recall that we are.",
            "We are aiming to extract only single Gaussian for each response.",
            "For that we can use one of these three approaches.",
            "The first approach, which which matches the one user in active shape models is just to select the center of the Gaussian to be the location with maximum intensity of the response and the uncertainty of that response will be proportional to the height of the response.",
            "It works fine in some cases, but for instance over here we are aiming to look of this by this landmark and the maximum is over there.",
            "Another approach that could overcome this this problem is to use to approximate the all the response by a full Gaussian.",
            "But it has also it also have some problems, for instance over here we get two modes and the correct mode is the first one, but the Gaussian response is something in between.",
            "So you look we lose a lot of accuracy by using this approach.",
            "Finally, we get.",
            "We can use something like approximate the full response by a kernel density estimation.",
            "This can be done by simply using the mean shift algorithm that moves to the nearest.",
            "Mode of the distribution.",
            "Then certainty will be just computing the governance around the currently found move.",
            "For instance, over here we get.",
            "We get patches that are under occlusion.",
            "The mean shift will move to the nearest mode and we get some problem with the projector.",
            "I don't know.",
            "And then suddenly will be quite large where that this allow us to deal with occlusion naturally."
        ],
        [
            "So this quick video shows the the main chairmanship landmark updates.",
            "At each iteration we can see over here that we need to warp the image at each iteration, which is required because the detectors are designed to operate at a given scale and over here we get uncertainty about about the updates given.",
            "I need to move on."
        ],
        [
            "So about the global alignment.",
            "So we see that the likelihood follows a Gaussian by now.",
            "Let's assume that the prior is still is also a Gaussian by the Bayes theorem theorem for Gaussian variables.",
            "It states that the posterior also follows a Gaussian and has these parameters that are function from the perimeter software from the likelihood and prior.",
            "This could be a possible solution for the global alignment, but we actually use a second order estimate which is given by this.",
            "Also, these equations also include this summation that allow us, for instance, to use more than one detector for each one mark, which in general improves the fitting accuracy."
        ],
        [
            "So about the prior.",
            "We see that the prior falls are Gaussian, but.",
            "We assume that the Gaussian parameters are unknown and by means of recursive Bayesian estimation we can can treat them as random variables.",
            "So by using the the Bayes theorem theorem you can write this equation where these are the parameters that we want to infer and these these are the shape parameters that are our incoming measures.",
            "So noticing that.",
            "The conjugate prior for a Gaussian with unknown mean.",
            "An unknown governance is something which is.",
            "This part is this is a Gaussian with Anon mean and non covariance.",
            "Is normal inverse Wishart distribution.",
            "This means that if we choose this prior to be a normal inverse Wishart, this ensures that this posterior is also a normal inverse Wishart and this distribution is modeled by these four parameters.",
            "Over here we can see that, for instance, the mean is something like an average weighted average along each incoming average incoming measures, and the same for the scale matrix."
        ],
        [
            "So, but we still need an update for the mean and covariance, and for that we use the expectation of marginal posterior distributions.",
            "For instance, we stuck by this joint posterior that we see that follows a normal inverse Wishart and we can integrate along Sigma B and this gives the marginal posterior distribution for the mean that follows student distribution and the expectation for this distribution is giving.",
            "Is given by this.",
            "You can do the same for integrating along the mean, which gives the posterior distribution for the covariance, which in this case follows inverse Wishart and the expectation for the inverse Wishart is something like this.",
            "So all of these equations.",
            "Aim to continuously keep up-to-date the prior, so at incoming each incoming measure updates the prior every time."
        ],
        [
            "So the overall algorithm says that we should.",
            "Precompute the shape model and the Bank of filters.",
            "We start by warping the image and generate the current shape.",
            "This shape will give positions to search for using the detectors, and we use.",
            "We can use one of the tree local approaches to exact a Gaussian, then we.",
            "But the four parameters of of the joint.",
            "The joint posterior distribution and then we compute the expectation and get updates for the prior.",
            "And finally we.",
            "This is the final step where we do the global optimization step using the estimated current shape parameters and the covariance."
        ],
        [
            "So this is a minor minor modification if you use.",
            "If we used the.",
            "The main shift one mark update.",
            "We still have to to set.",
            "We still have a free parameter.",
            "A common approaches to for each local response we use them in shift with a given landmark with a given bandwidth, and then we shrink a bit and go go up.",
            "Using all the schedule, another approach is to simply move the schedule to upper level, forcing more global steps to happen and more updates to the prior.",
            "In some cases, this approach works a little better."
        ],
        [
            "So about the result.",
            "We test this our approach in several data sets, the Umm, the extended M2 VTS database and the bio ID.",
            "These are performance fitting performance curves where over here we get the amount of RMS error and over here we get the.",
            "The percentage percentage of image that's converged with the given.",
            "Ever so as higher is a curve better the method is.",
            "Also.",
            "In all of these evaluation.",
            "We use always the same detectors and.",
            "To be fair, we should compare our approach.",
            "By judging the local by using similar, let me rephrase.",
            "When I use the local, my approach using taking low is the maximum response I should compare with active shape models.",
            "If I approximate my responses with full Gaussian, I should compare with constrained quadratic fitting and if I use if I use mean shift I should compare with space constraint in shifts in all the cases we get better results between 10 and 20% better.",
            "And this is the final line is just is matter that uses 2 detectors.",
            "The second detector is also a must filter, but built from the magnitude of image gradients."
        ],
        [
            "So we also perform evaluation in the talking face video.",
            "This is our result.",
            "Switches are better and in this case the vertical approach performed a little better than the standard one.",
            "An over here, which is the best one, is using more than one detector."
        ],
        [
            "This is the video from from the evaluation.",
            "I don't have much time to show you, but this is.",
            "This is part of the preceding, so we can show it can be.",
            "You can see it in more detail or in my web page, so this is my my my tool.",
            "This is our methods in this world, the standard method, the method that do erotical search active shape models, the convex quadratic fitting.",
            "This is a basic version of this one and over here, so space constraint is being shifts.",
            "You can see in the video that our model is more stable because it uses a second order estimate and.",
            "So instead let me continue."
        ],
        [
            "So this is our some images from the faces in the world.",
            "So we get we can deal with images with a very large amount of occlusion without any special treatment about that."
        ],
        [
            "So this is the one.",
            "Conclusion So we present here a new method Bayesian method to align faces and our main technical contribution is to keep the prior always up to date.",
            "So.",
            "And something is.",
            "It's all I'll be lifting lifting with the video in the on the beginning, and we can move to the questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me start by showing.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we are trying to do here we are doing face alignment.",
                    "label": 0
                },
                {
                    "sent": "Our aim is to to align faces that were not previously seen by the detector.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This is somehow related to active constraint local models or active shape models where we get where we use the shape model and the set of local detectors associated which.",
                    "label": 0
                },
                {
                    "sent": "Which 11 mark on the on the model?",
                    "label": 0
                },
                {
                    "sent": "So I'll be showing this video again.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At the end, right now I must continue so.",
                    "label": 0
                },
                {
                    "sent": "Typically, fitting such a model involves 2 steps.",
                    "label": 0
                },
                {
                    "sent": "First we search for each tackle.",
                    "label": 1
                },
                {
                    "sent": "Each detector we perform a local search, producing a response map for for all the landmarks.",
                    "label": 0
                },
                {
                    "sent": "Then there's a.",
                    "label": 0
                },
                {
                    "sent": "Something called the global optimization strategy that aims to find the shape parameters that maximizes all the responses at once.",
                    "label": 1
                },
                {
                    "sent": "So in this work we actually propose a new global optimization strategy using a Bayesian approach, where in fact we use.",
                    "label": 1
                },
                {
                    "sent": "We use the prior distribution to dynamic to encode the dynamically transition of the shape parameters.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a brief brief review.",
                    "label": 0
                },
                {
                    "sent": "This kind of work can be either generative or discriminative.",
                    "label": 0
                },
                {
                    "sent": "The difference is how do we model the texture in them?",
                    "label": 0
                },
                {
                    "sent": "So in this case will be more.",
                    "label": 0
                },
                {
                    "sent": "Gen 2 two.",
                    "label": 0
                },
                {
                    "sent": "It works better on unseen people, so in both cases we actually use the shape model, which is also known as a point distribution model, where we learn from previous annotations the mean them in shape.",
                    "label": 1
                },
                {
                    "sent": "A matrix with the principal components and shape parameters the shipping which is controlled is different motion and we have also the for similarity pose parameters.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Given given vector measurement vector Y, we want to.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to find the best set of shape parameters that maximize these posterior so we can reduce the complexity of this problem by making some assumptions.",
                    "label": 0
                },
                {
                    "sent": "The first assumption could be.",
                    "label": 0
                },
                {
                    "sent": "Assume conditional independence within one marks.",
                    "label": 0
                },
                {
                    "sent": "This can be done by simply by simply scanning each landmark independently.",
                    "label": 0
                },
                {
                    "sent": "And the the product.",
                    "label": 0
                },
                {
                    "sent": "Also, you can assume.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That we are near solution and we actually use the prior to model out the Shepherd meters change.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a little bit in detail, their likelihood likelihood will follow Gaussian farm, so we are aiming to extract from each response map only a single Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So we get Y our observation an over.",
                    "label": 0
                },
                {
                    "sent": "Here we get our uncertainty since we do is, we assume conditional independence within one marks.",
                    "label": 0
                },
                {
                    "sent": "These uncertainties will be a block diagonal matrix with blocks to buy tools.",
                    "label": 0
                },
                {
                    "sent": "So just for notation sake we define this Delta Delta Y which which is simply this difference and.",
                    "label": 0
                },
                {
                    "sent": "In summary, the likelihood followed this a Gaussian, where the mean is function of the shape parameters.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the typical detectors that are used to locate the landmarks are based on solving a linear SVM where the positive examples are patches that are aligned and the negative examples are slightly misaligned examples.",
                    "label": 0
                },
                {
                    "sent": "So we we learn an SVM for each detector and we scan around around that region for in the search phase, although this is.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A good approach.",
                    "label": 0
                },
                {
                    "sent": "We actually use something else that works better.",
                    "label": 0
                },
                {
                    "sent": "Something like something colored Demoss filter.",
                    "label": 0
                },
                {
                    "sent": "So in this video we show the SVM.",
                    "label": 0
                },
                {
                    "sent": "Typical detectors use it in this class of works and the response from the most filter within this case with each case.",
                    "label": 0
                },
                {
                    "sent": "Produce always Gaussian like responses.",
                    "label": 0
                },
                {
                    "sent": "You can see over here we get a lot of confusion between the eyes and the eyebrows and over here we get a strong response.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in brief, the the most filters were proposed in 2010 and the goal is to see that the correlation is the freedom of the input image and the filter in the most filter we aim to find this filter that by setting the output correlation to be Gaussian, so these input images will be our alignment examples, which must be composed with the cosine window which is required for the Fourier transform.",
                    "label": 0
                },
                {
                    "sent": "The solution is given by this.",
                    "label": 0
                },
                {
                    "sent": "And actually, you can see these filters by using the investments form.",
                    "label": 0
                },
                {
                    "sent": "Then the filters look like this.",
                    "label": 0
                },
                {
                    "sent": "And again, this is our response is taken over that location.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So even the filters work.",
                    "label": 0
                },
                {
                    "sent": "Quite well, they are not perfect.",
                    "label": 0
                },
                {
                    "sent": "We get here some results when we had one.",
                    "label": 0
                },
                {
                    "sent": "We have lots of good lots of texture.",
                    "label": 0
                },
                {
                    "sent": "We have a good response like this one but.",
                    "label": 0
                },
                {
                    "sent": "In some other cases we need to use someone something else so and I recall that we are.",
                    "label": 0
                },
                {
                    "sent": "We are aiming to extract only single Gaussian for each response.",
                    "label": 0
                },
                {
                    "sent": "For that we can use one of these three approaches.",
                    "label": 0
                },
                {
                    "sent": "The first approach, which which matches the one user in active shape models is just to select the center of the Gaussian to be the location with maximum intensity of the response and the uncertainty of that response will be proportional to the height of the response.",
                    "label": 0
                },
                {
                    "sent": "It works fine in some cases, but for instance over here we are aiming to look of this by this landmark and the maximum is over there.",
                    "label": 0
                },
                {
                    "sent": "Another approach that could overcome this this problem is to use to approximate the all the response by a full Gaussian.",
                    "label": 0
                },
                {
                    "sent": "But it has also it also have some problems, for instance over here we get two modes and the correct mode is the first one, but the Gaussian response is something in between.",
                    "label": 0
                },
                {
                    "sent": "So you look we lose a lot of accuracy by using this approach.",
                    "label": 0
                },
                {
                    "sent": "Finally, we get.",
                    "label": 0
                },
                {
                    "sent": "We can use something like approximate the full response by a kernel density estimation.",
                    "label": 0
                },
                {
                    "sent": "This can be done by simply using the mean shift algorithm that moves to the nearest.",
                    "label": 0
                },
                {
                    "sent": "Mode of the distribution.",
                    "label": 0
                },
                {
                    "sent": "Then certainty will be just computing the governance around the currently found move.",
                    "label": 0
                },
                {
                    "sent": "For instance, over here we get.",
                    "label": 0
                },
                {
                    "sent": "We get patches that are under occlusion.",
                    "label": 0
                },
                {
                    "sent": "The mean shift will move to the nearest mode and we get some problem with the projector.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "And then suddenly will be quite large where that this allow us to deal with occlusion naturally.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this quick video shows the the main chairmanship landmark updates.",
                    "label": 0
                },
                {
                    "sent": "At each iteration we can see over here that we need to warp the image at each iteration, which is required because the detectors are designed to operate at a given scale and over here we get uncertainty about about the updates given.",
                    "label": 0
                },
                {
                    "sent": "I need to move on.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So about the global alignment.",
                    "label": 0
                },
                {
                    "sent": "So we see that the likelihood follows a Gaussian by now.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that the prior is still is also a Gaussian by the Bayes theorem theorem for Gaussian variables.",
                    "label": 1
                },
                {
                    "sent": "It states that the posterior also follows a Gaussian and has these parameters that are function from the perimeter software from the likelihood and prior.",
                    "label": 0
                },
                {
                    "sent": "This could be a possible solution for the global alignment, but we actually use a second order estimate which is given by this.",
                    "label": 0
                },
                {
                    "sent": "Also, these equations also include this summation that allow us, for instance, to use more than one detector for each one mark, which in general improves the fitting accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So about the prior.",
                    "label": 0
                },
                {
                    "sent": "We see that the prior falls are Gaussian, but.",
                    "label": 0
                },
                {
                    "sent": "We assume that the Gaussian parameters are unknown and by means of recursive Bayesian estimation we can can treat them as random variables.",
                    "label": 0
                },
                {
                    "sent": "So by using the the Bayes theorem theorem you can write this equation where these are the parameters that we want to infer and these these are the shape parameters that are our incoming measures.",
                    "label": 0
                },
                {
                    "sent": "So noticing that.",
                    "label": 0
                },
                {
                    "sent": "The conjugate prior for a Gaussian with unknown mean.",
                    "label": 1
                },
                {
                    "sent": "An unknown governance is something which is.",
                    "label": 1
                },
                {
                    "sent": "This part is this is a Gaussian with Anon mean and non covariance.",
                    "label": 0
                },
                {
                    "sent": "Is normal inverse Wishart distribution.",
                    "label": 0
                },
                {
                    "sent": "This means that if we choose this prior to be a normal inverse Wishart, this ensures that this posterior is also a normal inverse Wishart and this distribution is modeled by these four parameters.",
                    "label": 0
                },
                {
                    "sent": "Over here we can see that, for instance, the mean is something like an average weighted average along each incoming average incoming measures, and the same for the scale matrix.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, but we still need an update for the mean and covariance, and for that we use the expectation of marginal posterior distributions.",
                    "label": 1
                },
                {
                    "sent": "For instance, we stuck by this joint posterior that we see that follows a normal inverse Wishart and we can integrate along Sigma B and this gives the marginal posterior distribution for the mean that follows student distribution and the expectation for this distribution is giving.",
                    "label": 0
                },
                {
                    "sent": "Is given by this.",
                    "label": 0
                },
                {
                    "sent": "You can do the same for integrating along the mean, which gives the posterior distribution for the covariance, which in this case follows inverse Wishart and the expectation for the inverse Wishart is something like this.",
                    "label": 0
                },
                {
                    "sent": "So all of these equations.",
                    "label": 1
                },
                {
                    "sent": "Aim to continuously keep up-to-date the prior, so at incoming each incoming measure updates the prior every time.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the overall algorithm says that we should.",
                    "label": 0
                },
                {
                    "sent": "Precompute the shape model and the Bank of filters.",
                    "label": 0
                },
                {
                    "sent": "We start by warping the image and generate the current shape.",
                    "label": 1
                },
                {
                    "sent": "This shape will give positions to search for using the detectors, and we use.",
                    "label": 0
                },
                {
                    "sent": "We can use one of the tree local approaches to exact a Gaussian, then we.",
                    "label": 1
                },
                {
                    "sent": "But the four parameters of of the joint.",
                    "label": 1
                },
                {
                    "sent": "The joint posterior distribution and then we compute the expectation and get updates for the prior.",
                    "label": 0
                },
                {
                    "sent": "And finally we.",
                    "label": 0
                },
                {
                    "sent": "This is the final step where we do the global optimization step using the estimated current shape parameters and the covariance.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a minor minor modification if you use.",
                    "label": 0
                },
                {
                    "sent": "If we used the.",
                    "label": 0
                },
                {
                    "sent": "The main shift one mark update.",
                    "label": 0
                },
                {
                    "sent": "We still have to to set.",
                    "label": 0
                },
                {
                    "sent": "We still have a free parameter.",
                    "label": 0
                },
                {
                    "sent": "A common approaches to for each local response we use them in shift with a given landmark with a given bandwidth, and then we shrink a bit and go go up.",
                    "label": 0
                },
                {
                    "sent": "Using all the schedule, another approach is to simply move the schedule to upper level, forcing more global steps to happen and more updates to the prior.",
                    "label": 0
                },
                {
                    "sent": "In some cases, this approach works a little better.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So about the result.",
                    "label": 0
                },
                {
                    "sent": "We test this our approach in several data sets, the Umm, the extended M2 VTS database and the bio ID.",
                    "label": 0
                },
                {
                    "sent": "These are performance fitting performance curves where over here we get the amount of RMS error and over here we get the.",
                    "label": 0
                },
                {
                    "sent": "The percentage percentage of image that's converged with the given.",
                    "label": 0
                },
                {
                    "sent": "Ever so as higher is a curve better the method is.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "In all of these evaluation.",
                    "label": 0
                },
                {
                    "sent": "We use always the same detectors and.",
                    "label": 0
                },
                {
                    "sent": "To be fair, we should compare our approach.",
                    "label": 0
                },
                {
                    "sent": "By judging the local by using similar, let me rephrase.",
                    "label": 0
                },
                {
                    "sent": "When I use the local, my approach using taking low is the maximum response I should compare with active shape models.",
                    "label": 0
                },
                {
                    "sent": "If I approximate my responses with full Gaussian, I should compare with constrained quadratic fitting and if I use if I use mean shift I should compare with space constraint in shifts in all the cases we get better results between 10 and 20% better.",
                    "label": 0
                },
                {
                    "sent": "And this is the final line is just is matter that uses 2 detectors.",
                    "label": 0
                },
                {
                    "sent": "The second detector is also a must filter, but built from the magnitude of image gradients.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also perform evaluation in the talking face video.",
                    "label": 0
                },
                {
                    "sent": "This is our result.",
                    "label": 0
                },
                {
                    "sent": "Switches are better and in this case the vertical approach performed a little better than the standard one.",
                    "label": 0
                },
                {
                    "sent": "An over here, which is the best one, is using more than one detector.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the video from from the evaluation.",
                    "label": 0
                },
                {
                    "sent": "I don't have much time to show you, but this is.",
                    "label": 0
                },
                {
                    "sent": "This is part of the preceding, so we can show it can be.",
                    "label": 0
                },
                {
                    "sent": "You can see it in more detail or in my web page, so this is my my my tool.",
                    "label": 0
                },
                {
                    "sent": "This is our methods in this world, the standard method, the method that do erotical search active shape models, the convex quadratic fitting.",
                    "label": 0
                },
                {
                    "sent": "This is a basic version of this one and over here, so space constraint is being shifts.",
                    "label": 0
                },
                {
                    "sent": "You can see in the video that our model is more stable because it uses a second order estimate and.",
                    "label": 0
                },
                {
                    "sent": "So instead let me continue.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is our some images from the faces in the world.",
                    "label": 0
                },
                {
                    "sent": "So we get we can deal with images with a very large amount of occlusion without any special treatment about that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the one.",
                    "label": 0
                },
                {
                    "sent": "Conclusion So we present here a new method Bayesian method to align faces and our main technical contribution is to keep the prior always up to date.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And something is.",
                    "label": 0
                },
                {
                    "sent": "It's all I'll be lifting lifting with the video in the on the beginning, and we can move to the questions.",
                    "label": 0
                }
            ]
        }
    }
}