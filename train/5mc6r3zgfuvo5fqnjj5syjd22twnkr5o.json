{
    "id": "5mc6r3zgfuvo5fqnjj5syjd22twnkr5o",
    "title": "Patch Complexity, Finite Pixel Correlations and Optimal Denoising",
    "info": {
        "author": [
            "Anat Levin, Weizmann Institute of Science"
        ],
        "chairman": [
            "Ramin Zabih, Department of Computer Science, Cornell University",
            "Laurent Itti, University of Southern California"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Color, Texture, Illumination & Reflectance"
        ]
    },
    "url": "http://videolectures.net/eccv2012_levin_denoising/",
    "segmentation": [
        [
            "So is this working there about Patch complexity, final pixel correlation?"
        ],
        [
            "And the optimal denoising so you know the things that image denoising problems, the classical setup you get a noisy image, you want to estimate the clean version.",
            "While using some additional assumptions on on the space Unreal images.",
            "No, I will.",
            "Community really have invested in numerous research effort in this problem and the result is drastically improved during the years.",
            "But since the results the results are not perfect and the question is why?",
            "Is it just because computer vision researchers are not smart enough?",
            "Or maybe there are inherent ambiguities in the problem which won't go away even if we develop perfect natural image piles?",
            "And the main questions that I'd like to tackle in this talk is how much filter can we hope to improve our results if we invest additional use of researching the problem.",
            "So just to illustrate the concept of inherent and certainty."
        ],
        [
            "Talent ambiguity in the data.",
            "So suppose we start with a noisy image.",
            "So we know that the client source could lie anywhere within the noise radii."
        ],
        [
            "Now if we have apply on clean signals and we know that they occupy only a subset of the space, then we can reduce our ambiguity volume.",
            "But no, did the fact that we have a pryo does not mean that we can reach 0 ambiguity, because there could still be multiple clinic SPLA nations for every noisy observation.",
            "So in one round of algorithms that will be the two source and in the second run we can meet the exact same noisy input image, but now this is that also, so this one or any of this.",
            "And what I would like to try to join this talk is to estimate the size of this inherent ambiguity."
        ],
        [
            "So there's some pie or attempts to study the noising limits, but most of them make some assumptions on the distribution and then they study the limits of distributions which which satisfies such assumptions, and it limits the conclusions because it doesn't.",
            "It's not clear if natural image distribution actually satisfy any of these assumptions, and what we would like to try to do here is to study denoising limits without assumptions.",
            "So they insist."
        ],
        [
            "Autistic literature, the concept of the minimum mean squared error of an estimation problem is actually well studied concept and it's equal to the conditional variance which is like the volume of the distribution P of X conditioned on why?",
            "And there is also a hole for the best answer.",
            "The best output of an estimation algorithm.",
            "It should be the conditional mean.",
            "So note that that to actually compute this optimal MSE.",
            "We need to know the exact tool natural image distribution P of X and in practice without estimating it in practice is not such an easy challenge, but if we could compute the MSE for the 2P of X and not with any of the existing approximations.",
            "Then by definition, this is the lowest mean squared error that we can hope to achieve with any future denoising algorithm, and in particular this includes algorithm.",
            "We choose internal image statistics or class specific information, face detection or whatever."
        ],
        [
            "No, in some parts of this talk will study what we call a Patch based denoising algorithm.",
            "So in a Patch based algorithm we can determine the value of a pixel by seeing and using only a support of the pixels around it.",
            "So, for example AAB lateral feature, which averaged over a compact support, is a Patch based algorithm.",
            "But actually, in contrast, nonlocal means which ever had small patches from the same event is effectively using the support the entire image.",
            "So now we can define the optimal minimum Smith code or summation of an algorithm which can use a deep Excel support in the same way.",
            "But now we look at distributions of the pixels, patches and noted distributions of full images.",
            "So.",
            "Now that we've promoted the definition of the MSE, we want to ask if we can compute it."
        ],
        [
            "And the main challenge is that we don't know what is perfect, because despite years of research, we still don't have a good parametric model for natural image distributions.",
            "So what I did was that despite the fact that we don't know what is P of X, we can still sample from it.",
            "Just by collecting many many real images from the web.",
            "And then we can compute the MSE nonparametrically.",
            "So for example, the conditional mean it's just the average of many clean images X sampled from P of X.",
            "Weighted by PFY given X.",
            "And for most noise models, computing peer fly given X is trivial.",
            "So you know, let's steal paper we burned."
        ],
        [
            "Cluster an we computed the MSE nonparametrically for different batch sizes, but in practice we could do it only for small Patch sizes because ESO increase the batch size we go to higher dimension and then due to cost of dimensionality samples are spread farther apart.",
            "And the nonparametric approach is not reliable enough.",
            "So we had some some statistical measure to determine if we can trust the nonparametric approach Allnutt So what o'clock here is peace Now, which is minus 10 log 10 of the embassy as a function of Patch size.",
            "So in practice what we could use a what we could do with the nonparametric approaches to compute the mercy, bound and algorithms which can use a finite support of the pixels.",
            "But to actually compute the inherent."
        ],
        [
            "Found on any denoising algorithm.",
            "We need to compute the MSE within finite support.",
            "Or at least with the support of the full image.",
            "So the question is if there is any rule according to which this curve behave which will allow us to extrapolate it to Infinity."
        ],
        [
            "So in the paper we had two parts and in the first part we attempted to understand the studies.",
            "The complexity of nonparametric algorithms, how much they depend on such Patch size, how hard it is to find neighbors.",
            "So let me just say."
        ],
        [
            "Looks like that so vaguely is the complexity of nonparametric algorithms the accuracy of nonparametric algorithms depends on the fact that you can find enough clean neighbors around every noisy noisy observation.",
            "So to illustrate that.",
            "So here is a noisy image and we query the query that given database.",
            "And here are the clean neighbors we found.",
            "Now if we increase the Patch size, then now not all these neighbors match.",
            "This one does."
        ],
        [
            "Well, this one never.",
            "Maybe this one is this one."
        ],
        [
            "Most of them don't.",
            "And if we fail to increase the batch size and these two neighbors don't match either and were electrifying empty set.",
            "So essentially good neighbors become more aware as soon as we increase the batch size as we go to higher dimension.",
            "But now.",
            "Not all patches are equally hard too much."
        ],
        [
            "And especially if you look at patches from UU regions, you can usually find plenty of neighbors even with wide support."
        ],
        [
            "So in the paper, we've designed a number of empirical experiments in an attempt to study how much can we actually gain by increasing the Patch size.",
            "And essentially, we've observed that there is a loaf diminishing return, and when when an increase in Patch size makes it much harder to find good neighbors, then actually the performance gain due to this wider support is smaller.",
            "And especially for smooth regions in which it's easy to increase the Patch size because it's easy to find good neighbors.",
            "This is this will actually the regions virtually which will gain from a wider support and untextured regions in which good neighbors are actually the regions which will gain less from rider support.",
            "And we justify that in the paper is a mathematical analysis of the correlation.",
            "And and one practical outcome of this is that one way to improve denoising algorithms is to select the support size adaptively."
        ],
        [
            "But now I want to return to the general question that realized which is for any future denoising algorithm, parametric nonparametric heuristic or whatever.",
            "What are the best results that we can hope to achieve?",
            "And for that we want to understand if the how does the MSE converge as a function of Patch size and is there any permit any role which will allow us to extrapolate the results from find support to Infinity?"
        ],
        [
            "So to study that we use the very simplified image formation model.",
            "Is the dead leaves model which is in which an image just an independent collection of a piecewise constant segments.",
            "Now the advantage of this model is that defining the optimal segmentation is very easy is optimal.",
            "Denoising is very easy.",
            "The best thing to do is just too average.",
            "All the noisy observations within each segment.",
            "Now if we combine this model with another very fundamental property of natural images, the fact."
        ],
        [
            "Statistics of scale invariant.",
            "The statistic do not change when you.",
            "Change scale, then we can compute the MSN closed form and we can also compute MSDN closed firmware.",
            "Again, MSCD is the best algorithm.",
            "The best.",
            "The best error of an algorithm which can use a deep Excel support.",
            "So some simple calculation shows that MSD equals to the MSMC within finite support plus a term which could converge like 1 / D O in different words.",
            "They're going to see which we find that support converge to the optimal one with infinite support as a power law.",
            "So we can prove the power law only for the dead leaves."
        ],
        [
            "But in practice it matches very well with the observations on real data.",
            "So to say this, we used the optimal personal that we computed nonparametrically and we plug them here as a function of Patch size.",
            "And you can say that we could fit very well with a power law model.",
            "But now just to convince you that this is not just a smooth curve that you could fit, if any with any public parametric model.",
            "So we also tried an exponential curve which fits the data quite poorly, and the motivation for trying an exponential curve is that this is the outcome of the popular mark of random field Pro.",
            "So if we conjecture that the MSE is the function of Patch size, indeed follows a power law, then we can fit a parametric model to the observation on small Patch size is an.",
            "We can extrapolate it to predict the MSIT Infinity.",
            "And again the Ms 8 Infinity is optimal.",
            "Lowest mean squared error that we can hope to achieve with any future denoising algo."
        ],
        [
            "So if we compare this extrapolated bound with two, the result of existing algorithms, then we can say that there is still some room forward for improvement, but it's modest like the order of 0.6 to 1.2 TB.",
            "Now, of course you should take this extrapolation with a grain of salt.",
            "It may not be that are correct.",
            "But it still provides some ballpark estimate of how much felt filter we can hope to improve if we really invest additional use of researching the problem.",
            "So just."
        ],
        [
            "Summarizes this talk was an attempt to understand the studies and how it and certainty of the denoising problem.",
            "And we had two parts in the first party.",
            "We studied the complexity of nonparametric algorithms and we show that there is essentially a loaf diminishing return and when an increase in Patch size made it much harder to find good neighbors.",
            "Then actually the performance gain due to this wider support is smaller.",
            "And then for any future denoising algorithm, parametric nonparametric and whatever we attempt to understand what is the lowest means code errors that we can hope to achieve.",
            "We invest Additionally of the free searching the problem.",
            "And we showed that the result that the MSA is a function of Patch size follows a power law, and therefore we can extrapolate the MSE that we computed for finite support to Infinity and get some ballpark estimate of the bound within finite support.",
            "M So I'll stop here and I'm happy to take questions.",
            "So this was a very interesting analysis for the mean squared error.",
            "Is there any hope of extending some of these two perceptual error measures or other general error measure?",
            "OK, so that's a very good question in so I think the issue is not really the error measure, but the notion of one that goes back to your talk.",
            "The notion of 111 answer and once we once we understand that there are indeed multiple solutions and what we probably want to do is to sample from the posterior.",
            "And not just to get out to 1, not just to get out the best solution, which means to average overall solution and then like you usually you blur.",
            "So you want one image which will look like a good image and not some image.",
            "You should minimize some error metric.",
            "I think that's probably the way to go.",
            "Is the power law curve has having a boundary.",
            "Like you so you can increase the window size so the does it converge to something which isn't 0, which is until you can get the infinite high.",
            "So the Paolo is a polar curve converge to a finite number, it doesn't get, it doesn't get to Infinity.",
            "I mean you have to ride the math, but that's what it comes out.",
            "How much is your denoising bone tide to the dead leaves model again?",
            "So you're denouncing bound how much is related to the model that you have used, which is the dead leaves model, is it?",
            "No, it doesn't depend on the dead leaves models that that leaves model with just proves apparel automatically.",
            "But the calculations that I've done was Unreal images I mean.",
            "Once we couldn't, we use the public to to understand it to the dead leaves model to understand that there is a parallel.",
            "Then we did the extrapolation with observations on real data.",
            "So that was just to build an intuition.",
            "Hello I remember there is another work in title is denoising that.",
            "And they give us a denoising bound.",
            "So can you give some connection between your work and that bound so?",
            "I think essentially what they did is to develop bounds for specific images and not a new village for for all images.",
            "In I mean I want spoke to them and it seems that the Belpark estimator seems to agree, but it's derived using different tools, so it's and they don't give up, they don't give out exact numbers for.",
            "For the average image, so it's hard to compare.",
            "And I think another issue of this with this work was indeed amount of assumptions that it made on the distribution, which also write some questions on the conclusions.",
            "Coincidentally, I happen to be the author of that paper, but OK, but I won't.",
            "I won't discuss that right now.",
            "I just wanted to ask you if we just put the issue of patches aside and think about denoising as the entire image contributing to every pixels.",
            "Denoising, what would your model say about that?",
            "So again, so in other words, let's say every pixel in the image is a.",
            "Weighted combination of all the other pixels in the image where the weights corresponding to each of those pixels is determined by some method.",
            "Some kernel that tells you similarity so there's no concept of patches anymore.",
            "Does your model include any bounds for that type of denoising where the concept of Patch simply doesn't exist anymore?",
            "In I still didn't get the question, but I mean the idea here was to extrapolate to extrapolate the Patch based results to Infinity, assuming that like the image size is a finite well just, I'm just simply proposing it denoising model where every pixel is estimated as a linear combination of all the pixels in the image and the weights corresponding to that linear combination are somehow calculated.",
            "And there's no.",
            "There's no concept of a Patch, so yes, I definitely think that the this problem formulation includes a suffix that we choose internal image statistics, because I mean like the enemy sees the best result of any algorithm which is the msceit Infinity is a better result of any algorithm which can use the entire image support, and that includes whatever you want to do.",
            "And for example something like nonlocal mean, whichever is over.",
            "Small patches within the same image.",
            "Is included, I mean the best algorithm which can use the entire image support and support can in particular do what you say or can do stuff like nonlocal mean which averaged small repetitions, a internal repetitions within the same image.",
            "It's all included within an algorithm which can use the entire image support and do whatever it once.",
            "OK, I'll ask you some more later.",
            "OK, I'm happy to discuss it.",
            "We're gonna take maybe one last one.",
            "Maybe I missed it, but you're bound includes some condition on the noise model that you use.",
            "So is it just Gaussian additive idea?",
            "OK, in specifically in this talk we in this experiment we used Gaussian IID noise, But in practice I mean all we needed is the ability to compute P of Y given X.",
            "So in practice you can reuse the same methodology and the reruns of the evaluation on any on any noise model just will have to bear in the cluster again, which is not so easy, but.",
            "Until you can do it.",
            "Great, let's thank all the speakers."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So is this working there about Patch complexity, final pixel correlation?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the optimal denoising so you know the things that image denoising problems, the classical setup you get a noisy image, you want to estimate the clean version.",
                    "label": 0
                },
                {
                    "sent": "While using some additional assumptions on on the space Unreal images.",
                    "label": 0
                },
                {
                    "sent": "No, I will.",
                    "label": 0
                },
                {
                    "sent": "Community really have invested in numerous research effort in this problem and the result is drastically improved during the years.",
                    "label": 0
                },
                {
                    "sent": "But since the results the results are not perfect and the question is why?",
                    "label": 0
                },
                {
                    "sent": "Is it just because computer vision researchers are not smart enough?",
                    "label": 0
                },
                {
                    "sent": "Or maybe there are inherent ambiguities in the problem which won't go away even if we develop perfect natural image piles?",
                    "label": 0
                },
                {
                    "sent": "And the main questions that I'd like to tackle in this talk is how much filter can we hope to improve our results if we invest additional use of researching the problem.",
                    "label": 1
                },
                {
                    "sent": "So just to illustrate the concept of inherent and certainty.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talent ambiguity in the data.",
                    "label": 0
                },
                {
                    "sent": "So suppose we start with a noisy image.",
                    "label": 1
                },
                {
                    "sent": "So we know that the client source could lie anywhere within the noise radii.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now if we have apply on clean signals and we know that they occupy only a subset of the space, then we can reduce our ambiguity volume.",
                    "label": 0
                },
                {
                    "sent": "But no, did the fact that we have a pryo does not mean that we can reach 0 ambiguity, because there could still be multiple clinic SPLA nations for every noisy observation.",
                    "label": 0
                },
                {
                    "sent": "So in one round of algorithms that will be the two source and in the second run we can meet the exact same noisy input image, but now this is that also, so this one or any of this.",
                    "label": 0
                },
                {
                    "sent": "And what I would like to try to join this talk is to estimate the size of this inherent ambiguity.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's some pie or attempts to study the noising limits, but most of them make some assumptions on the distribution and then they study the limits of distributions which which satisfies such assumptions, and it limits the conclusions because it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's not clear if natural image distribution actually satisfy any of these assumptions, and what we would like to try to do here is to study denoising limits without assumptions.",
                    "label": 0
                },
                {
                    "sent": "So they insist.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Autistic literature, the concept of the minimum mean squared error of an estimation problem is actually well studied concept and it's equal to the conditional variance which is like the volume of the distribution P of X conditioned on why?",
                    "label": 0
                },
                {
                    "sent": "And there is also a hole for the best answer.",
                    "label": 0
                },
                {
                    "sent": "The best output of an estimation algorithm.",
                    "label": 0
                },
                {
                    "sent": "It should be the conditional mean.",
                    "label": 1
                },
                {
                    "sent": "So note that that to actually compute this optimal MSE.",
                    "label": 1
                },
                {
                    "sent": "We need to know the exact tool natural image distribution P of X and in practice without estimating it in practice is not such an easy challenge, but if we could compute the MSE for the 2P of X and not with any of the existing approximations.",
                    "label": 0
                },
                {
                    "sent": "Then by definition, this is the lowest mean squared error that we can hope to achieve with any future denoising algorithm, and in particular this includes algorithm.",
                    "label": 0
                },
                {
                    "sent": "We choose internal image statistics or class specific information, face detection or whatever.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, in some parts of this talk will study what we call a Patch based denoising algorithm.",
                    "label": 0
                },
                {
                    "sent": "So in a Patch based algorithm we can determine the value of a pixel by seeing and using only a support of the pixels around it.",
                    "label": 1
                },
                {
                    "sent": "So, for example AAB lateral feature, which averaged over a compact support, is a Patch based algorithm.",
                    "label": 0
                },
                {
                    "sent": "But actually, in contrast, nonlocal means which ever had small patches from the same event is effectively using the support the entire image.",
                    "label": 1
                },
                {
                    "sent": "So now we can define the optimal minimum Smith code or summation of an algorithm which can use a deep Excel support in the same way.",
                    "label": 1
                },
                {
                    "sent": "But now we look at distributions of the pixels, patches and noted distributions of full images.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now that we've promoted the definition of the MSE, we want to ask if we can compute it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the main challenge is that we don't know what is perfect, because despite years of research, we still don't have a good parametric model for natural image distributions.",
                    "label": 0
                },
                {
                    "sent": "So what I did was that despite the fact that we don't know what is P of X, we can still sample from it.",
                    "label": 1
                },
                {
                    "sent": "Just by collecting many many real images from the web.",
                    "label": 0
                },
                {
                    "sent": "And then we can compute the MSE nonparametrically.",
                    "label": 0
                },
                {
                    "sent": "So for example, the conditional mean it's just the average of many clean images X sampled from P of X.",
                    "label": 0
                },
                {
                    "sent": "Weighted by PFY given X.",
                    "label": 0
                },
                {
                    "sent": "And for most noise models, computing peer fly given X is trivial.",
                    "label": 0
                },
                {
                    "sent": "So you know, let's steal paper we burned.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cluster an we computed the MSE nonparametrically for different batch sizes, but in practice we could do it only for small Patch sizes because ESO increase the batch size we go to higher dimension and then due to cost of dimensionality samples are spread farther apart.",
                    "label": 0
                },
                {
                    "sent": "And the nonparametric approach is not reliable enough.",
                    "label": 0
                },
                {
                    "sent": "So we had some some statistical measure to determine if we can trust the nonparametric approach Allnutt So what o'clock here is peace Now, which is minus 10 log 10 of the embassy as a function of Patch size.",
                    "label": 1
                },
                {
                    "sent": "So in practice what we could use a what we could do with the nonparametric approaches to compute the mercy, bound and algorithms which can use a finite support of the pixels.",
                    "label": 0
                },
                {
                    "sent": "But to actually compute the inherent.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Found on any denoising algorithm.",
                    "label": 0
                },
                {
                    "sent": "We need to compute the MSE within finite support.",
                    "label": 0
                },
                {
                    "sent": "Or at least with the support of the full image.",
                    "label": 0
                },
                {
                    "sent": "So the question is if there is any rule according to which this curve behave which will allow us to extrapolate it to Infinity.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the paper we had two parts and in the first part we attempted to understand the studies.",
                    "label": 0
                },
                {
                    "sent": "The complexity of nonparametric algorithms, how much they depend on such Patch size, how hard it is to find neighbors.",
                    "label": 0
                },
                {
                    "sent": "So let me just say.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looks like that so vaguely is the complexity of nonparametric algorithms the accuracy of nonparametric algorithms depends on the fact that you can find enough clean neighbors around every noisy noisy observation.",
                    "label": 0
                },
                {
                    "sent": "So to illustrate that.",
                    "label": 0
                },
                {
                    "sent": "So here is a noisy image and we query the query that given database.",
                    "label": 0
                },
                {
                    "sent": "And here are the clean neighbors we found.",
                    "label": 0
                },
                {
                    "sent": "Now if we increase the Patch size, then now not all these neighbors match.",
                    "label": 0
                },
                {
                    "sent": "This one does.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, this one never.",
                    "label": 0
                },
                {
                    "sent": "Maybe this one is this one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most of them don't.",
                    "label": 0
                },
                {
                    "sent": "And if we fail to increase the batch size and these two neighbors don't match either and were electrifying empty set.",
                    "label": 0
                },
                {
                    "sent": "So essentially good neighbors become more aware as soon as we increase the batch size as we go to higher dimension.",
                    "label": 0
                },
                {
                    "sent": "But now.",
                    "label": 0
                },
                {
                    "sent": "Not all patches are equally hard too much.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And especially if you look at patches from UU regions, you can usually find plenty of neighbors even with wide support.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the paper, we've designed a number of empirical experiments in an attempt to study how much can we actually gain by increasing the Patch size.",
                    "label": 0
                },
                {
                    "sent": "And essentially, we've observed that there is a loaf diminishing return, and when when an increase in Patch size makes it much harder to find good neighbors, then actually the performance gain due to this wider support is smaller.",
                    "label": 1
                },
                {
                    "sent": "And especially for smooth regions in which it's easy to increase the Patch size because it's easy to find good neighbors.",
                    "label": 0
                },
                {
                    "sent": "This is this will actually the regions virtually which will gain from a wider support and untextured regions in which good neighbors are actually the regions which will gain less from rider support.",
                    "label": 0
                },
                {
                    "sent": "And we justify that in the paper is a mathematical analysis of the correlation.",
                    "label": 0
                },
                {
                    "sent": "And and one practical outcome of this is that one way to improve denoising algorithms is to select the support size adaptively.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But now I want to return to the general question that realized which is for any future denoising algorithm, parametric nonparametric heuristic or whatever.",
                    "label": 0
                },
                {
                    "sent": "What are the best results that we can hope to achieve?",
                    "label": 0
                },
                {
                    "sent": "And for that we want to understand if the how does the MSE converge as a function of Patch size and is there any permit any role which will allow us to extrapolate the results from find support to Infinity?",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to study that we use the very simplified image formation model.",
                    "label": 0
                },
                {
                    "sent": "Is the dead leaves model which is in which an image just an independent collection of a piecewise constant segments.",
                    "label": 1
                },
                {
                    "sent": "Now the advantage of this model is that defining the optimal segmentation is very easy is optimal.",
                    "label": 0
                },
                {
                    "sent": "Denoising is very easy.",
                    "label": 0
                },
                {
                    "sent": "The best thing to do is just too average.",
                    "label": 1
                },
                {
                    "sent": "All the noisy observations within each segment.",
                    "label": 0
                },
                {
                    "sent": "Now if we combine this model with another very fundamental property of natural images, the fact.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Statistics of scale invariant.",
                    "label": 0
                },
                {
                    "sent": "The statistic do not change when you.",
                    "label": 0
                },
                {
                    "sent": "Change scale, then we can compute the MSN closed form and we can also compute MSDN closed firmware.",
                    "label": 0
                },
                {
                    "sent": "Again, MSCD is the best algorithm.",
                    "label": 0
                },
                {
                    "sent": "The best.",
                    "label": 0
                },
                {
                    "sent": "The best error of an algorithm which can use a deep Excel support.",
                    "label": 0
                },
                {
                    "sent": "So some simple calculation shows that MSD equals to the MSMC within finite support plus a term which could converge like 1 / D O in different words.",
                    "label": 0
                },
                {
                    "sent": "They're going to see which we find that support converge to the optimal one with infinite support as a power law.",
                    "label": 0
                },
                {
                    "sent": "So we can prove the power law only for the dead leaves.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But in practice it matches very well with the observations on real data.",
                    "label": 0
                },
                {
                    "sent": "So to say this, we used the optimal personal that we computed nonparametrically and we plug them here as a function of Patch size.",
                    "label": 0
                },
                {
                    "sent": "And you can say that we could fit very well with a power law model.",
                    "label": 1
                },
                {
                    "sent": "But now just to convince you that this is not just a smooth curve that you could fit, if any with any public parametric model.",
                    "label": 1
                },
                {
                    "sent": "So we also tried an exponential curve which fits the data quite poorly, and the motivation for trying an exponential curve is that this is the outcome of the popular mark of random field Pro.",
                    "label": 0
                },
                {
                    "sent": "So if we conjecture that the MSE is the function of Patch size, indeed follows a power law, then we can fit a parametric model to the observation on small Patch size is an.",
                    "label": 0
                },
                {
                    "sent": "We can extrapolate it to predict the MSIT Infinity.",
                    "label": 0
                },
                {
                    "sent": "And again the Ms 8 Infinity is optimal.",
                    "label": 0
                },
                {
                    "sent": "Lowest mean squared error that we can hope to achieve with any future denoising algo.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we compare this extrapolated bound with two, the result of existing algorithms, then we can say that there is still some room forward for improvement, but it's modest like the order of 0.6 to 1.2 TB.",
                    "label": 0
                },
                {
                    "sent": "Now, of course you should take this extrapolation with a grain of salt.",
                    "label": 0
                },
                {
                    "sent": "It may not be that are correct.",
                    "label": 0
                },
                {
                    "sent": "But it still provides some ballpark estimate of how much felt filter we can hope to improve if we really invest additional use of researching the problem.",
                    "label": 0
                },
                {
                    "sent": "So just.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summarizes this talk was an attempt to understand the studies and how it and certainty of the denoising problem.",
                    "label": 0
                },
                {
                    "sent": "And we had two parts in the first party.",
                    "label": 0
                },
                {
                    "sent": "We studied the complexity of nonparametric algorithms and we show that there is essentially a loaf diminishing return and when an increase in Patch size made it much harder to find good neighbors.",
                    "label": 1
                },
                {
                    "sent": "Then actually the performance gain due to this wider support is smaller.",
                    "label": 0
                },
                {
                    "sent": "And then for any future denoising algorithm, parametric nonparametric and whatever we attempt to understand what is the lowest means code errors that we can hope to achieve.",
                    "label": 0
                },
                {
                    "sent": "We invest Additionally of the free searching the problem.",
                    "label": 0
                },
                {
                    "sent": "And we showed that the result that the MSA is a function of Patch size follows a power law, and therefore we can extrapolate the MSE that we computed for finite support to Infinity and get some ballpark estimate of the bound within finite support.",
                    "label": 1
                },
                {
                    "sent": "M So I'll stop here and I'm happy to take questions.",
                    "label": 0
                },
                {
                    "sent": "So this was a very interesting analysis for the mean squared error.",
                    "label": 0
                },
                {
                    "sent": "Is there any hope of extending some of these two perceptual error measures or other general error measure?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a very good question in so I think the issue is not really the error measure, but the notion of one that goes back to your talk.",
                    "label": 0
                },
                {
                    "sent": "The notion of 111 answer and once we once we understand that there are indeed multiple solutions and what we probably want to do is to sample from the posterior.",
                    "label": 0
                },
                {
                    "sent": "And not just to get out to 1, not just to get out the best solution, which means to average overall solution and then like you usually you blur.",
                    "label": 0
                },
                {
                    "sent": "So you want one image which will look like a good image and not some image.",
                    "label": 0
                },
                {
                    "sent": "You should minimize some error metric.",
                    "label": 0
                },
                {
                    "sent": "I think that's probably the way to go.",
                    "label": 0
                },
                {
                    "sent": "Is the power law curve has having a boundary.",
                    "label": 0
                },
                {
                    "sent": "Like you so you can increase the window size so the does it converge to something which isn't 0, which is until you can get the infinite high.",
                    "label": 0
                },
                {
                    "sent": "So the Paolo is a polar curve converge to a finite number, it doesn't get, it doesn't get to Infinity.",
                    "label": 0
                },
                {
                    "sent": "I mean you have to ride the math, but that's what it comes out.",
                    "label": 0
                },
                {
                    "sent": "How much is your denoising bone tide to the dead leaves model again?",
                    "label": 0
                },
                {
                    "sent": "So you're denouncing bound how much is related to the model that you have used, which is the dead leaves model, is it?",
                    "label": 0
                },
                {
                    "sent": "No, it doesn't depend on the dead leaves models that that leaves model with just proves apparel automatically.",
                    "label": 0
                },
                {
                    "sent": "But the calculations that I've done was Unreal images I mean.",
                    "label": 0
                },
                {
                    "sent": "Once we couldn't, we use the public to to understand it to the dead leaves model to understand that there is a parallel.",
                    "label": 0
                },
                {
                    "sent": "Then we did the extrapolation with observations on real data.",
                    "label": 0
                },
                {
                    "sent": "So that was just to build an intuition.",
                    "label": 0
                },
                {
                    "sent": "Hello I remember there is another work in title is denoising that.",
                    "label": 0
                },
                {
                    "sent": "And they give us a denoising bound.",
                    "label": 0
                },
                {
                    "sent": "So can you give some connection between your work and that bound so?",
                    "label": 0
                },
                {
                    "sent": "I think essentially what they did is to develop bounds for specific images and not a new village for for all images.",
                    "label": 0
                },
                {
                    "sent": "In I mean I want spoke to them and it seems that the Belpark estimator seems to agree, but it's derived using different tools, so it's and they don't give up, they don't give out exact numbers for.",
                    "label": 0
                },
                {
                    "sent": "For the average image, so it's hard to compare.",
                    "label": 0
                },
                {
                    "sent": "And I think another issue of this with this work was indeed amount of assumptions that it made on the distribution, which also write some questions on the conclusions.",
                    "label": 0
                },
                {
                    "sent": "Coincidentally, I happen to be the author of that paper, but OK, but I won't.",
                    "label": 0
                },
                {
                    "sent": "I won't discuss that right now.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to ask you if we just put the issue of patches aside and think about denoising as the entire image contributing to every pixels.",
                    "label": 0
                },
                {
                    "sent": "Denoising, what would your model say about that?",
                    "label": 0
                },
                {
                    "sent": "So again, so in other words, let's say every pixel in the image is a.",
                    "label": 0
                },
                {
                    "sent": "Weighted combination of all the other pixels in the image where the weights corresponding to each of those pixels is determined by some method.",
                    "label": 0
                },
                {
                    "sent": "Some kernel that tells you similarity so there's no concept of patches anymore.",
                    "label": 0
                },
                {
                    "sent": "Does your model include any bounds for that type of denoising where the concept of Patch simply doesn't exist anymore?",
                    "label": 0
                },
                {
                    "sent": "In I still didn't get the question, but I mean the idea here was to extrapolate to extrapolate the Patch based results to Infinity, assuming that like the image size is a finite well just, I'm just simply proposing it denoising model where every pixel is estimated as a linear combination of all the pixels in the image and the weights corresponding to that linear combination are somehow calculated.",
                    "label": 0
                },
                {
                    "sent": "And there's no.",
                    "label": 0
                },
                {
                    "sent": "There's no concept of a Patch, so yes, I definitely think that the this problem formulation includes a suffix that we choose internal image statistics, because I mean like the enemy sees the best result of any algorithm which is the msceit Infinity is a better result of any algorithm which can use the entire image support, and that includes whatever you want to do.",
                    "label": 0
                },
                {
                    "sent": "And for example something like nonlocal mean, whichever is over.",
                    "label": 0
                },
                {
                    "sent": "Small patches within the same image.",
                    "label": 0
                },
                {
                    "sent": "Is included, I mean the best algorithm which can use the entire image support and support can in particular do what you say or can do stuff like nonlocal mean which averaged small repetitions, a internal repetitions within the same image.",
                    "label": 0
                },
                {
                    "sent": "It's all included within an algorithm which can use the entire image support and do whatever it once.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll ask you some more later.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm happy to discuss it.",
                    "label": 0
                },
                {
                    "sent": "We're gonna take maybe one last one.",
                    "label": 0
                },
                {
                    "sent": "Maybe I missed it, but you're bound includes some condition on the noise model that you use.",
                    "label": 0
                },
                {
                    "sent": "So is it just Gaussian additive idea?",
                    "label": 0
                },
                {
                    "sent": "OK, in specifically in this talk we in this experiment we used Gaussian IID noise, But in practice I mean all we needed is the ability to compute P of Y given X.",
                    "label": 0
                },
                {
                    "sent": "So in practice you can reuse the same methodology and the reruns of the evaluation on any on any noise model just will have to bear in the cluster again, which is not so easy, but.",
                    "label": 0
                },
                {
                    "sent": "Until you can do it.",
                    "label": 0
                },
                {
                    "sent": "Great, let's thank all the speakers.",
                    "label": 0
                }
            ]
        }
    }
}