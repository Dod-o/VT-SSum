{
    "id": "wahpwcr55t2vse5cekcqzgsyims7zhmi",
    "title": "JBlas",
    "info": {
        "author": [
            "Mikio Braun, Fraunhofer Institute for Intelligent Analysis and Information Systems"
        ],
        "published": "July 20, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Software"
        ]
    },
    "url": "http://videolectures.net/icml2010_braun_jblas/",
    "segmentation": [
        [
            "So I'll meet you.",
            "Brown and Jay bless is what I'm going to present later on on the posters.",
            "So J Blaz is a fast linear matrix library for Java, right?",
            "And?"
        ],
        [
            "So the big difference.",
            "So they have many libraries out there.",
            "We're also going to hear more about one of those libraries after the spotlights, but the big difference for J. Blaz is that it uses the Fortran code, right?",
            "So I've gone through.",
            "Lot of pain to actually pass or the Fortran code and automatically generate wrapper classes, which means that for large matrixes matrices you practically get native performance.",
            "So on my 2 gigahertz laptop I get something like a 10 gigaflops of single precision.",
            "On matrix matrix come multiplication that nice thing is that actually you can just download a job which works for Linux, Mac OS and Windows and you don't have to do all the native compilation yourself, so that's what my summary.",
            "If you want to know more, please come to my poster."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll meet you.",
                    "label": 0
                },
                {
                    "sent": "Brown and Jay bless is what I'm going to present later on on the posters.",
                    "label": 0
                },
                {
                    "sent": "So J Blaz is a fast linear matrix library for Java, right?",
                    "label": 1
                },
                {
                    "sent": "And?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the big difference.",
                    "label": 0
                },
                {
                    "sent": "So they have many libraries out there.",
                    "label": 0
                },
                {
                    "sent": "We're also going to hear more about one of those libraries after the spotlights, but the big difference for J. Blaz is that it uses the Fortran code, right?",
                    "label": 0
                },
                {
                    "sent": "So I've gone through.",
                    "label": 0
                },
                {
                    "sent": "Lot of pain to actually pass or the Fortran code and automatically generate wrapper classes, which means that for large matrixes matrices you practically get native performance.",
                    "label": 1
                },
                {
                    "sent": "So on my 2 gigahertz laptop I get something like a 10 gigaflops of single precision.",
                    "label": 1
                },
                {
                    "sent": "On matrix matrix come multiplication that nice thing is that actually you can just download a job which works for Linux, Mac OS and Windows and you don't have to do all the native compilation yourself, so that's what my summary.",
                    "label": 0
                },
                {
                    "sent": "If you want to know more, please come to my poster.",
                    "label": 0
                }
            ]
        }
    }
}