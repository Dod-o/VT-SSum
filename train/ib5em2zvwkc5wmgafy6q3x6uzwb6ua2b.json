{
    "id": "ib5em2zvwkc5wmgafy6q3x6uzwb6ua2b",
    "title": "Neural Networks",
    "info": {
        "author": [
            "Hugo Larochelle, Google, Inc."
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_larochelle_neural_networks/",
    "segmentation": [
        [
            "OK so yeah, so I have been tasked to go do an overview on neural networks.",
            "Sort of two parts in it where mostly in the morning I'll talk about things that I think a lot of you are familiar with, but just to make sure everyone's sort of up to speed just out of curiosity.",
            "So who here knows about neural Nets and back problems?",
            "Just raise your hand, alright?",
            "Who has implemented neural networks and random neural network experiments here?",
            "Alright, that's more than most.",
            "Oh wow, that's actually.",
            "Fairly impressive, so yeah, so I think I think.",
            "Most of the heroes I have sliced prefer, but but of course not everyone knows about all of the details, so please make this interactive.",
            "Ask me questions.",
            "Really, the idea is for everyone to be up to speed, and I'm sure if my previous years are any indication that for most questions Yahshua will without prompting answer the questions.",
            "So I think the point is for everyone to catch up.",
            "The other reason might just be that Aaron critical thought it would be nice if I presented for three hours on the topic you all know about, just to see me suffer as you're all being bored, but hopefully I mean this is probably not the main reason, but I know it has non zero probability so well, maybe it's both who knows.",
            "So OK, so let's get started."
        ],
        [
            "So most of these slides are taken from my online course on YouTube, not taught by this much younger version of myself.",
            "If you want to check those out, there's more details on the derivation of background, which I will not do, but it is important to go through that.",
            "That's really what distinguishes real deep learning experts from non deep learning experts.",
            "As far as I'm concerned.",
            "So do go check this out.",
            "Anne."
        ],
        [
            "Well, I'll try to talk about mostly today or the following.",
            "I'll just start by just doing an overview and mostly sending up the notation for web.",
            "Neural Nets are now.",
            "We make predictions with neural Nets, then talk about how we train neural networks with a little bit of discussion and some of the tricks of the trade that people tend to use in practice and then specifically focus on deep neural networks and talk about some perhaps slightly more modern approaches for successfully training neural Nets."
        ],
        [
            "OK, so let's start so we can talk about neural networks without talking about what is a neuron.",
            "So in order."
        ],
        [
            "Actual neuron?",
            "Well, mathematically be the following to compute the value of a neuron will start by computing what I'm going to call the pre activation pre activation is going to be a bias multiple plus the multiplication of the inputs of the neuron multiplied by some weight vector W. So a neuron is paralyzed by its bias and its weight.",
            "You can think of the weight vector as kind of a pattern that this unit is detecting an it's sort of measuring the similarity.",
            "Or how much the pattern fits with the input by doing a dot product with it.",
            "An once we've computed this pre activation which is a linear transformation.",
            "We compute an activation bypassing the pre activation through an activation function which I'm noting G which is unusual and non linearity such as the sigmoid that an age or the rectified linear unit or activation.",
            "So visually it sort of looks like this.",
            "Sometimes I draw it as the bias be being a weight with a constant one, and then you get the other weights WN WD4D dimensional inputs.",
            "If you have a D dimensional input space.",
            "Alright, so that's what an artificial neuron is."
        ],
        [
            "If you had a neuron that takes 2 inputs so that lives in two dimensions.",
            "Input one here and put two here.",
            "You can visually look at the output of that neuron, which is this axis here an it will essentially look at like separating two regions in a linear way, so it's effectively if you use G for the function G for user sigmoid, it's effectively a logistic regression classifier where there's an area with a large value.",
            "Another area with small value and vector W will be perpendicular to the.",
            "Essentially, the decision surface, the line that draws between the positive and negative part, or the two sets of decision regions.",
            "OK, so the angle of W determines the angle of that decision service and the bias sort of will change where in that direction the slope will be varying."
        ],
        [
            "And so that's a single neuron, so we can parametrised a linear classifier with a single neuron.",
            "But of course most problems aren't linearly solvable.",
            "They require a nonlinear decision function.",
            "Well, it turns out like combining several neurons together, we can get nonlinear surface is.",
            "So for instance, if I had a neuron here at a second layer that was taking as input, these two neurons where we have the illustration of the output of neuron on the left on the right.",
            "Well, roughly speaking, if this neuron here was taking the activation of that neuron and then subtracting the activation of that neuron, you would essentially get that surface here.",
            "But with that part.",
            "Being sort of carved out as you're seeing here, OK now I can see that with by combining, these two neurons were getting something that is nonlinear.",
            "Now you have like a restricted area of the input space that has large value with low values on both the left and right side.",
            "And now we."
        ],
        [
            "We can do something similar if we had four neurons where we can sort of carve out at second layer.",
            "Sorry bout that second layer.",
            "A little bump like this.",
            "OK."
        ],
        [
            "And now if we're able to do this by combining one layer of simulated value neurons when he cuts on, imagine you can put bumps at various places of the input space and start carving out or fairly complex classification rule and your 2D input space, and so that's kind of the appeal of artificial neural networks, and using that intuition you can add."
        ],
        [
            "Actually, show mathematically a universal approximation theorem, which says that with a single hidden layer neural network, even with the linear output, we can essentially approximate any continuous function arbitrarily well given enough hidden units.",
            "So if I have enough of these hidden units to construct these little bumps in input space and add them altogether and position them nicely, any function under certain conditions but essentially continuous functions, we can approximate it well enough.",
            "If we allow for enough hidden units in the hidden layer, OK, so that means that if we constrain ourselves to just training neural networks, we can represent a lot of functions.",
            "Potentially all the functions that we need to approximate if we want to design system that learn from data that's learning function that we don't know about that that's instantiated in some data.",
            "Now this says we can represent a lot of different functions with neural Nets, but it doesn't say anything about how do we train these neural Nets.",
            "How do we find these weights?",
            "Up the neurons in the biases OK, and so that we'll talk about a bit later.",
            "Any questions about that part?",
            "Yes Mr banjo.",
            "What does this say about generalization?",
            "Not much until we really talk about learning, which we'll talk about after.",
            "That's not a trick question, just putting me on the spot like that."
        ],
        [
            "Alright, so most of the time, or at least in this presentation I will focus on multilayer neural networks that often called fully connected neural networks, because of course what I discussed before.",
            "So this suggests you could kind of compose a bunch of different neurons in an arbitrary way, but one type of architecture that people often uses this one here.",
            "Well, you have some number of hidden layers, so in this case we have two hidden layers and each hidden layer.",
            "Corresponds to the computation of 1st a pre activation of all the units in that layer, and this is essentially taking the value of the previous layer.",
            "So if it's the previous layer, if that's the input, that's a zero of X would be equal to the input X and otherwise will just be their previous hidden layer.",
            "So you take the previous hidden layer and then multiplied by some weight matrix WK.",
            "So case the index over layers and then you add a bias vector.",
            "So the parameters of my model are essentially of my neural net.",
            "Are these bias vectors at each layer and these weight matrices which contain all the weights between the units in one layer and the layer below?",
            "OK, so AK of X that's going to be my pre activation vector, then I will pass this through an activation function G. Which will put some nonlinearities in my model that allows it to be nonlinear classifier or predictor.",
            "And we do this all the way up till the output layer.",
            "So those two here would be the hidden layers.",
            "This is the input layer, you know there is the output layer and for the output layer often we will use a different activation function depending on what the problem is.",
            "If we're classifying examples and say 10 classes, then we'll use a softmax, which I'll describe in a few minutes.",
            "Any question about that notation, I'll sort of use that quite a bit.",
            "Alright."
        ],
        [
            "OK, so in terms of activation functions, one pretty well known is the sigmoid activation function, which you're seeing here.",
            "It's 1 / 1 plus the exponential of the negative pre activation.",
            "So what it looks like is that it takes it input that can be from its pre activation that can be from negative Infinity to positive infinite and it squashes that.",
            "Between zero and one OK.",
            "So at zero it's equal to 0.5 and as you increase it, it converges to one.",
            "In other."
        ],
        [
            "Function you probably know about this.",
            "The 10 H. It's kind of like the sigmoid instead that it's squashing things between minus one and one instead of between zero and one at 0.",
            "The 10 H is equal to 0.",
            "It outputs 0."
        ],
        [
            "There's also what is probably now by far the most popular activation function, which is the rectified linear activation function.",
            "It is simply the maximum between 0 or the pre activation.",
            "OK, so the function would look something like this, where when the pre activation is negative the activation, so the output of the activation function is 0.",
            "If it's positive, well it's the pre activation itself, so it's linear with a slope of one OK."
        ],
        [
            "And for the output we often use what's known as the softmax activation function.",
            "It is pretty simple, you just take your whole vector of pre activations at that layer, you exponentiate it.",
            "So exponentiated the first dimension all the way to the final dimension in that layer.",
            "So usually we use the use of the output layer.",
            "So I'm using C as the size of that layer where capital sees the number of classes.",
            "So we have one neuron per class.",
            "Then we want to.",
            "Classify and then we take the exponentiated preactivation and then we divide by the sum of all the numerators all the exponentiated pre activations.",
            "OK, So what this means is that the output of the softmax.",
            "Is positive because we exponentiated all pre activation, so it's got to be positive and it also sums to one because we're normalizing it where summing by the divided by the sum of all the numerators.",
            "So we can actually treat that as a distribution over all the classes.",
            "OK, and that's actually formally how we will think of the output of the neural network.",
            "It's giving us.",
            "What is the conditional distribution of the label Y given some input X?",
            "So it's given us the probability belong to.",
            "Each of the possible classes.",
            "And now if we were to classify data using that softmax would just look at what is the neuron, what is the output neuron that's the highest value?",
            "That's effectively according to our neural net.",
            "What is the most likely class given the input and we will assign as a prediction the input to that class?",
            "Yes.",
            "The question is why isn't it called the soft argmax?",
            "That's a very good question.",
            "I actually don't know.",
            "I think it would be better called in softmax.",
            "So the reason why you might want to think of this as a soft argmax is that well, if you had a bunch of numbers and you wanted to identify the.",
            "The unit with the maximum value, so that would be the argmax one way of encoding that might be to have a bunch of zeros and with the one that the corresponding maximizing dimension.",
            "Well, these these values here are all going to be between zero and one, and the dimension that has the highest value is going to be the highest, the closest to one.",
            "OK, so it's kind of a soft version of an argmax, encoded with so-called one hot vectors.",
            "These vectors with a bunch of zeros in a single one.",
            "Other question yes.",
            "It doesn't even matter that they are invertible, because radio is not inverted.",
            "Right?",
            "So the question is whether it matters that the activation functions, some of them aren't invertible, so here it won't, at least in terms of classification, and it's not going to really matter it to some extent, introduces some invariances which might be useful.",
            "There might be types of models like in unsupervised learning.",
            "Sometimes that's an interesting property to have, but in the context of classification here, not really.",
            "Luck.",
            "So.",
            "Yes so.",
            "The universal approximation theory for washing activation function.",
            "Danielle is not just watching it.",
            "So.",
            "Yeah, so yeah I guess the question is so I talked about in Universal approximation Theorem, but at mostly considers quashing activation functions, whereas the real issue isn't upper bounded.",
            "So I'm pretty sure if it's not been done, I'm pretty sure the universal approximation still applies if you ever lose you.",
            "Essentially you can represent piecewise linear functions and with enough pieces you can kind of think that you could arbitrarily approximate any function.",
            "Squashing function right, and you can also combine two relatives to get a sort of hard sigmoid, for instance.",
            "Other questions, yeah.",
            "OK, the question is, can we interpret these probabilities as a confidence into that prediction?",
            "I think technically that is kind of the interpretation we're putting here.",
            "That is, it is our current estimate of what is the probability that this input would belong to that class.",
            "Now, whether these probabilities are so called calibrated that they kind of correspond to at Test time a, you know the actual probability that an input in that area would actually belong to that class is another question, and usually you have a separate process for calibrating these probabilities using a validation set, but that's a good point.",
            "You shouldn't trust these probabilities necessarily, and usually we go through a process that's called calibration, which I'm not discussing here but that.",
            "You can probably find.",
            "For instance, overfitting, yes, you're sort of overconfident.",
            "Yes.",
            "Activation use them separately.",
            "Stations of the model is that.",
            "Does that pull throughs or any way of going back?",
            "Interpreting like the marginal value of the.",
            "Of the parameter.",
            "So let's say the relatively near this kind of Tobit estimator is that that has certain properties before just looking into simply.",
            "But when you stack them, can you still abstract interpretation or not?",
            "So I think, are you asking for instance, if we think of hidden units as modeling probabilities of.",
            "At the internal level of their neural net, whether we.",
            "People who knows a lot about metal, not so just wasn't sure when we're looking at the parameter.",
            "Wait, if I just have that as a simple model.",
            "Those properties broadcast out through the net, so beyond.",
            "Neural Nets in general are very hard to interpret, especially what the different parameters internally mean in terms of what is the behavior of the neural net and the activation of the hidden units themselves.",
            "Beyond, you know, sort of intuitively being pattern detectors, their actual value aren't really easily converted to a probability of something.",
            "So I understand your question correctly, not really the most, the most you can interpret, really.",
            "Is at the output space because it's trying to match real data so that space is interpretable.",
            "It corresponds to assignments to labels, but beyond that internally it's still kind of an open problem to yield some intuition interpretation of what's going on.",
            "Alright, Oh yeah, one last question.",
            "Activate we have seen music.",
            "Why?",
            "Why not something else?",
            "Yeah, so the question is why these activation functions.",
            "I've taken off and an why aren't there some others one so the key thing in activation function does first is introduced nonlinearities.",
            "So this is how you get the nonlinear classifier rectified.",
            "Linear unit is interesting because.",
            "All it does is convert your neural net into piecewise linear function.",
            "Intuitively, you would assume that you know linear function is fairly simple function.",
            "That should be easy to optimize.",
            "Piecewise dinner, maybe somewhat a little bit harder, but not too much.",
            "It has fewer saturations an when we look at the backpropagation algorithm, we also see that revenue potentially helps with problems like.",
            "The gradient of eroding as you're doing backdrop, so that's another thing you want to think about when you think about activation function.",
            "Is it likely to block gradients and make learning difficult?",
            "But we'll talk about that in a bit.",
            "Yes, it's also true that there are a bunch of others exist proposed since then, right?",
            "Like Max out is this another?",
            "They just don't perform.",
            "Viably better than realm.",
            "Yeah, so there are a lot of others that have similar performance and these are kind of each Interestingly different.",
            "They span the fairly interesting space of activation functions and there are others that are sort of close to those with similar performance.",
            "Alright.",
            "Move forward."
        ],
        [
            "Now, in terms of how you would maybe think about implementing a neural network, it's useful to think of it as in terms of a flow graph where you are connecting together a bunch of modules that each perform a small amount of computation.",
            "So, for instance, you could think of the forward pass in a neural net as having a first module that computes the pre activation and this module will take as input the actual input X, but also the parameters for the first layer, the matrix W one, and the bias vector B.",
            "And then we have another module that takes in the preactivation, computes the corresponding non linearity and so on, so forth until you reach the last layer an.",
            "The reason why this is an interesting sort of almost object oriented way of implementing this is that it makes it easy to share code and makes it easy to try various things.",
            "And it turns out as we'll talk later, it also makes it easy to represent the process of computing gradients with respect to a loss function.",
            "And we'll discuss that in a few."
        ],
        [
            "OK, so that covers just essentially making predictions using, say train neural network and having some understanding as to what kind of functions they can represent.",
            "Now can we train them from data?",
            "How do we discover the weights that will allow us to solve some given practical problem?",
            "Now."
        ],
        [
            "Close to do that will do.",
            "Learning an one approach to machine learning is to treat it as an optimization problem.",
            "Specifically what we will do is that we will define some loss function, which I'm noting L that will compare what is the values provided at the output of my neural network with the actual target.",
            "So here this would be comparing the softmax outputs with what is the actual class?",
            "Why that the input X belongs to and sort of taking this sum?",
            "Actually the average?",
            "Of all of these losses, comparing the output with the target.",
            "And instruct, so this is optimizing that is called empirical risk minimization, and the structural version of it is when we add a regularizer.",
            "So when we take a regularizer, I'm noting gamma that looks at the values of my parameters Theta.",
            "So data is just all of the weights W1W2 and so on, and all the biases B on B2 and so on, and so love potentially penalizing certain value and encouraging others.",
            "So here learning will be cast as an optimization.",
            "Let's find the values of all the weights and all the biases that minimize the average loss on my training set.",
            "So these XY pairs are from my training set, plus potentially some regularizer.",
            "Anne.",
            "And I should also say that often this loss function here will not necessarily be exactly the loss function I care about.",
            "So in classification I would care about.",
            "Am I classifying in the right class?",
            "Any given training example?",
            "But this loss function is not differentiable and will rely on gradients for training.",
            "So often we use what is usually referred to as a surrogate loss function.",
            "It's a loss function that's close enough to the thing that actually interests me as the property that is differentiable and I can get gradient to get a signal as to how to change the wins."
        ],
        [
            "And so this is an optimization problem, so we will solve it when an optimization algorithm and you've seen gradient descent, and I will introduce to you a stochastic version of it in the stochastic gradient descent algorithm.",
            "So the way it works is that you see the pseudocode here.",
            "So let's go through all the steps.",
            "We start by initializing our parameters in some way, so I'll discuss initializing session in a bit.",
            "But essentially that means assigning a first value to all of my weights.",
            "And all of my biases in my neural net.",
            "And then for a certain number of iterations or updates, I will go through of epochs.",
            "Sorry, I will go through all my training examples.",
            "My pairs X&Y in my training set.",
            "And now look at what is the direction to make a step in the right direction to minimize my loss.",
            "Four that example, that is, I'm going to look at the negative gradient.",
            "This is nabla here of the loss function for my pair XY.",
            "Given my parameter, This is why did I sort of as an index.",
            "That means the gradient of this with respect to fed up an I.",
            "So essentially per example.",
            "When I want to optimize is the last plus.",
            "The regularizers also need the gradient of the regularizer Omega with respect to my parameters.",
            "OK, so I go in the opposite direction because I'm minimizing so the gradient gives me away of it, gives me an ascent direction, so I'll go the opposite direction to descend and I'll take a step of quota code size.",
            "AA is a step size or often referred to as a learning rate, so I'll just.",
            "This is just a scalar multiplying my vector of direction.",
            "For my update and I add this to my current value of the parameters and it gives me the new value of my parameters and so I do this for all the training examples in my training set and I do this for certain number of so called epochs.",
            "OK, so that stochastic gradient descent can be applied to many problems where you have to minimize some average of a bunch of loss terms, and so here to get the complete algorithm we need to specify what kind of loss function will want to consider when we want to minimize.",
            "We need a procedure for computing this gradient here, so the gradient of the loss with respect to all my parameters.",
            "I need a procedure to compute that we want to compute that efficiently.",
            "Can efficient algorithm need to specify your regularizer if I want one and I need to specify specify a way of initializing my weights so the next few slides would go through each of these steps, yes?",
            "Yeah, so the Gray, the regular gradient descent."
        ],
        [
            "Them would actually look at what is the gradient of this full expression here, so it would be the average gradient over all the training examples plus the gradient of the regularizer.",
            "So that would be great in the sent.",
            "The reason why it's stochastic is that instead of taking the full average where it's actually going to subsample that average, and here we are at the extreme case, we're taking just a single example to get an estimate of the gradient of this full average, so that's why it's stochastic, and there's sort of.",
            "There's one extremely stochastic gradient descent with a single example per update an you can do something a bit better, which is mini batch gradient descent, where you would actually take a small set of 64 examples and compute the average grade and 4060 for example, even though I have maybe 10s of thousands of examples, but stochastically comes from the fact that I need to pick one amongst all of these examples in the average an you sort of do it effectively stochastically by.",
            "You can do this by drawing with replacement.",
            "Or you can do it by just cycling over the examples.",
            "Yes.",
            "Yeah, so I. I don't know if that's an accepted terminology."
        ],
        [
            "But I believe in that park would be over all the examples and then in iteration would be 1 update.",
            "I think of an optimization algorithm.",
            "This might contradict other peoples notation and maybe mine is wrong, but that's the one I will be using and it's my presentation, so I get to call it.",
            "Greece.",
            "Different areas, no.",
            "OK, that's a good question.",
            "So the question is, should we initialize every time we do an Xbox?",
            "So actually no.",
            "So every time we do one epoc most likely will not have finished training the neural network.",
            "An actually in practice and all that we need to see in an example multiple times before it actually meaningfully learned to predict its target given its input.",
            "So re initializing multiple times.",
            "This will be an other outer loop.",
            "Out of this, that is, you would typically run this algorithm multiple times, often in parallel on different machines, where each will initialize differently with a different random seed, for instance.",
            "That's a great question.",
            "Yes.",
            "One thing I think.",
            "When do we stop?",
            "Yeah, we stop when N is reached here.",
            "So now we'll talk about that.",
            "That's a good point.",
            "What is N right?",
            "That's that's a hyperparameter here.",
            "Yes.",
            "No, that's right.",
            "That's why.",
            "Is like I.",
            "This is not exactly the same thing, yes, so I'll talk about how we said that M, But that's a good point, yes.",
            "Yes.",
            "Wait, so what's the question?",
            "What is the difference between doing an update based on a single example versus a batch or mini batch?",
            "So effectively you can think of a single example as a batch of size 1.",
            "An in that case, what you can expect is there's going to be more variance in the estimate, like that number is going to vary a lot around what would have been the number.",
            "If you use all of the training examples.",
            "If you have a mini batch that's not one, but of size 64, well, there's going to be a little bit less variance because you're averaging over 64 example.",
            "And So what this will change is how much variance there is in the estimate of the gradient.",
            "Of the total average loss.",
            "And the idea is that the less variance you have, the more accurate this descent direction will be an the more valuable that step should be towards minimizing your average loss.",
            "Yes.",
            "So can you say again?",
            "Yeah OK, what's the relation between cyber Batch and I guess performance or I'll talk about this in a few slides, but we'll discuss that for sure.",
            "Yes.",
            "Right, so yeah, the question is should we shuffle?",
            "So let's say when we're doing this for loop here.",
            "Overall training example, should we shuffle the example every time?",
            "Also, here I'm sort of not being very specific, but you can imagine that even cycling over examples But actually drawing them independently.",
            "These correspond to different procedures which I believe have different properties in terms of how quickly they converge.",
            "I don't know these properties very well.",
            "I'm sure our friend Simone the back knows a lot, so if you want to.",
            "No more about this.",
            "As to that guy.",
            "They are different procedures.",
            "They yield different.",
            "They have different properties for sure an.",
            "I believe that most of the time people use just cycling because it's kind of convenient.",
            "You don't have to deal with the sampling and whatnot.",
            "Yes.",
            "If there.",
            "Oh but the question is, is there a rule of thumb for choosing the mini batch size so?",
            "Not really.",
            "Usually we take power of two because computers like powers of two.",
            "And.",
            "Then it's different if you have a lot of compute power.",
            "Legitimately, the batch size will have an impact on the generalization performance will talk about why that is a little bit later, but maybe mostly what you care about is just running it for enough iterations for it to work at all, and then time will be the biggest factor.",
            "And then there's a compromise between, essentially in terms of implementations on the computer.",
            "There is sort of a tradeoff in terms of computation in the different number of batches.",
            "So in short, if you sort of tune what the batch sizes, you might go through a full data set in the variable amount of time.",
            "And then you would often sort of optimize for speed for different problems.",
            "This might mean different mini batch size.",
            "So beyond the power of two and then people use often 3264 or 128.",
            "But even then very recently some people have shown that if you have multiple machines you can paralyze the computation of all gradients, which means effectively you can do batch sizes of 1000, so that kind of suggests there isn't a rule of thumb or it's sort of changing as you know, are softwares for parallel.",
            "Distributed computation change.",
            "Yes.",
            "Sorry.",
            "Yeah, so the question of whether actually having noise in the gradient might be a good thing.",
            "And that's definitely true.",
            "I'll postpone that discussion to later, but but it is true and some people have argued actually, that it's quite important to reach good generalization performance, and I'll.",
            "Will have a discussion about, you know, trying to give you some intuition as to why that is, but that's a good point.",
            "This is why the mini batch size really is is a hyperparameter of the learning algorithm.",
            "It's not just a matter of how quickly it runs, it's also a matter of it will impact the solution you'll find in terms of if you have, you know, as much computation as you wanted, it will impact the quality of the solution you will find for sure.",
            "Yes.",
            "Power.",
            "Yeah.",
            "So essentially, that's the power of two is essentially because for practical reasons you it will paralyze better on the GPU and so on so forth.",
            "So in that sense it doesn't really matter, it could be 100, but 128 is going to be going to have nice parallelization properties on the GPU, and so on.",
            "So that's really the reason.",
            "Alright.",
            "Let's move forward.",
            "So OK, so first thing I said we need to pick four things.",
            "The loss function, a way to compute gradients, regularizer and how to initialize."
        ],
        [
            "For the last function, I'll concentrate on classification.",
            "So for instance, think my input is an image of an handwritten digit, like from this data set it can be 012 and so on, up to 9.",
            "So there are 10 classes, so in this case the loss function for classification could be I want to maximize the probability assigned to the correct class Y for some input X.",
            "And for various reasons, including numerical stability, we might as well say maximize the lug probability just automatically gives you nicer gradients.",
            "And because I want to loss, I want to think about minimizing the loss.",
            "Instead, I'll just use the negative log of the probability of the target Y.",
            "According to my neural net.",
            "And what is that?",
            "Well, that's taking the.",
            "So if Y here is just a number from zero to or depending if you count from zero, one from zero to the number of classes minus one.",
            "Well, I'll just take my output layer and I look at the component corresponding to my class and I'll penalize minus the log of that.",
            "OK, so in statistical terms that's called doing maximum likelihood and maximizing the likelihood that the probability assigned by our current parameters to the correct class.",
            "For this example.",
            "OK, so another way of writing it is in this way.",
            "So if you think as the target Y if you think of it as encoding it into one hot vector.",
            "This is kind of like looking at the cross entropy between the one hot vector and the full vector of probabilities.",
            "OK, so sometimes we'll refer to this loss and then a lot of deep learning packages.",
            "It will be referred to as the multinomial cross entropy because it compares a multinomial which essentially A1 hot vector with another multinomial, which is the output of your neural net.",
            "OK, so that's a lot that will consider in this talk and that a lot of people use."
        ],
        [
            "Then we need an algorithm for computing the gradients of my loss with respect to my parameters, and that's the backpropagation algorithm.",
            "As we've established everyone here pretty much knows it, so I'll go quickly.",
            "So essentially the procedure, once we've done our forward path which computes all the hidden layer in the output layer, will start from the variant and then back propagate in the inverse direction all the way from the top layer to the bottom layer.",
            "Effectively with backdrop is doing is essentially exploiting this compositional property of the derivation chain rule.",
            "So what we do is we first compute what is the gradient of my loss and the negative log probability of the correct class with respect to my pre activation and my output layer will do the output layer but the pre activation here for simplicity and it has a very nice gradient.",
            "It's essentially looking at the difference between what is the one hot vector of my class.",
            "So if Y, that's my notation for the vector that puts everything to zero except the component, why?",
            "Which is set to one and it takes the difference between this and the current output.",
            "OK, so if you think of this, this is a bunch of zeros and a single one.",
            "That is, all numbers between zero and one, so all the components are zero, that all the classes that don't correspond to the real target will be subtracted by positive numbers, so that component before the minus here is going to be negative an except for the component that set to 1.",
            "It's going to be subtracting the number that is between zero and one strictly so that other component is going to be necessarily positive.",
            "OK, So what this term is effectively saying is increase the probability or the pre activation of the correct class and decrease the probability of all other classes.",
            "Ann if you already assign zero probabilities that class, you're essentially not going to touch that unit.",
            "But if you assign high probability when it wasn't the correct class, you're going to have a stronger gradient pushing that preactivation down.",
            "That's kind of the intuition for this term here.",
            "And then we're going to go from the top layer all the way to the first one.",
            "We once we have their pre activation of the layer above, we can use that pre activation here to get the gradient with respect to the weight matrix W. It's going to be the dot product.",
            "Actually the outer product between this vector here which can think of as a column vector of the gradient of the loss with respect to their activation.",
            "The layer above times the vector of.",
            "Activations of the layer right below and I'm taking the transpose here, so that's a row vector, so this vector times this vector.",
            "The outer product will give you a matrix of the same size as this W just got a good sanity check to know that this procedure makes sense.",
            "And then forward the biases of that layer.",
            "Actually, the gradient is just going to be what is the gradient of the loss function with respect to the pre activation of that layer?",
            "Then I'm going to propagate the grades downwards towards the layer right below, so I'm going to take what is the gradient of my loss with respect to the activation in the layer above and multiply that by the transpose of my weight matrix for that layer, and that actually turns out to be the gradient of the loss with respect to the activation of the layer below very simple procedure.",
            "And then to get the gradient of the loss with respect to the pre activation at the layer below all I need to do is multiply by.",
            "What is the durative of my activation function for each neuron?",
            "OK, so we're doing this elementwise multiplication with the partial narrative of the activation function for each neuron, and multiplying that element by element with the gradient computed here of the activation.",
            "So once I'm here, I have the gradient of the loss.",
            "With respect to the activation of the layer below so I can go back here and compute the gradient of the weights for the layer below and so on.",
            "So I'm going up towards down the first hidden layer and that's the backpropagation algorithm.",
            "So I'm showing you this here mostly for two reasons.",
            "The first illustrate that it's really just a top down process that has essentially the same complexity as my bottom up process where I'm doing the form fast.",
            "And it's fairly simple.",
            "It's mostly linear operations, an multiplications, and also I ask you to notice this term here, which is that the gradient of the activation is going to be effectively gated by the activation function partial narrative.",
            "So if any of these derivatives are zero, it's going to block the gradient, and it's not going to pass through the neurons below.",
            "OK, an it's this term in not only disarmed, this term can also have some vanishing gradient effect, but this term.",
            "Particular, often referred to as one being responsible for problems with vanishing gradient.",
            "Because effectively if you have saturations of the activation function, some of the grain is going to be multiplied by zero, they're going to be essentially set to 0 and no gradients will pass through the layers below, and they won't be able to learn because they won't get a signal.",
            "They won't get a gradient.",
            "OK."
        ],
        [
            "So if we look at what some of those partial derivatives look like for, say, the sigmoid activation function, it's actually interesting need just the sigmoid itself times 1 minus the sigmoid itself.",
            "OK, so you can sort of write it as a function of the actual sigmoid, which kind of makes sense.",
            "So that means when this is one or when this is zero, either one of these terms is going to be 0, so the product is going to be 0, and indeed the slope here when the sigmoid is close to one or the slope.",
            "Here when it's close to 0.",
            "Is effectively zero.",
            "OK, so the intuition from this graph matches the equation.",
            "Anne."
        ],
        [
            "10 eight should get a same kind of thing, except that now.",
            "So the 10 inches between minus one and one and the partial it would be 1 minus the tenant squared.",
            "OK, so if it's close to minus one, this term will be close to one.",
            "I'm going to get a partial limited that's close to 0."
        ],
        [
            "Ford erelu.",
            "Interestingly, it's super simple.",
            "It's the indicator function of whether the activate the pre activation is larger than zero.",
            "If so, it's one, otherwise it's zero.",
            "So it's really explicitly agate.",
            "It's passing gradients through it, or it's not passing gradients through OK, and it's passing gradients.",
            "It's not changing the gradient, it's just letting pass by multiplying it by 1.",
            "OK, so this is where we can intuitively think that using relatives will have less problems with propagating gradients.",
            "Because yes, sometimes it will shove things to 0, but otherwise, even if there's large values of the Relu, unlike with the sigmoid, you don't get a partial.",
            "If that's zero, the grains will pass as long as you're in the positive slope of revenue.",
            "Yes.",
            "What happens at 00?",
            "You mean this point?",
            "Here we are back propagating a subgradient.",
            "Which is.",
            "Five year 'cause similar is going to Paris means that's not going to be exact definition of what a subgradient is, but essentially we ignore the fact that here there isn't.",
            "The dirt is not the greatness that really defined, but we just use zero and in practice it works.",
            "Alright.",
            "Is that semi satisfying symbol?"
        ],
        [
            "Alright, and now in terms of so you could for any neural network sort of compute all these directives and implement them.",
            "Turns out there's an effectively automatic way of getting this for any new neural network, as long as you use this sort of flow graph inspired implementation and the modules that you use in your flow graph, as long as they allow for not just computing the forward pass which is taking their input and producing outputs, but it can also take what is the gradient.",
            "Of some loss which respected themselves and then propagate what is then the gradient of that same loss with respect to its inputs?",
            "OK, and that's effectively just taking that gradient and then adding the term in the chain rule that corresponds to their own gradient.",
            "Their own jacobian.",
            "OK, so then in this case you can have these.",
            "You can sort of mix and match different modules as long as they both implement the forward pass in the backward pass and then back up is just.",
            "Doing first the first pass like this and then starting at the loss for saying the gradient of the loss with respect to itself to be one and then calling this back propagation function on each module to propagate the gradient to get respect to FX, which will then compute the gradient for the pre activation function, which can then compute the grain respect to all of its inputs.",
            "They wait the biases and the activation function and so on so forth.",
            "OK so.",
            "Torch is an example where this was used pretty explicitly.",
            "You would have a bunch of different modules that would be implemented in this way.",
            "They would have F prop and a B prop function essentially as the part of the module object and the forward pass you would call them in order in the backward pass we would call them in reverse order.",
            "Now we have even more sophisticated approaches that will take the graph and augment it with operations that correspond to going in this inverse order.",
            "So Theano is more less power need that approach.",
            "Tensor flow uses that as well, and then there are other approaches like sorry, torch, autograde.",
            "And then there's now Pytorch also uses that they used to be torch autograde also where you have more of a tape based approach which I suspect you will learn about this week from presumably the Pytorch tutorial for instance."
        ],
        [
            "OK, so that's the backdrop algorithm we mentioned that we might want to use regularizer one regularizer, that a lot of people use is the L2 regularization, which essentially penalizes the sum of the squared of all parameters.",
            "You can do this for the biases, but usually we don't do it.",
            "We don't regularize the biases, only the weights, and effectively.",
            "What this does is encourage weights that aren't too far from zero, and the intuition for why that might make sense is that.",
            "If you have weights that are close to 0, then your function initially is more or less constant, so it's pretty smooth around the input space, so you're essentially saying I want a function that's as smooth as possible, But fits the training data.",
            "So this is on time calls also weight decay, which is another term for this, and I believe I've seen this morning doesn't interpretation as having a Gaussian prior over where the overweights."
        ],
        [
            "And finally the initialization.",
            "So for the biases it's usually pretty simple.",
            "Usually it's 20.",
            "That's not true for the STM.",
            "Forget gate.",
            "For those who knows about, we know about LCMS and you'll learn more about that later this week, but usually the biases are initialized to 0.",
            "Then for the weights, now we can't initialize them all to zero, especially if you have a 10 H activation.",
            "If you think about it and it's not about exercise to do, you can see that effectively what you'll get is a gradient on all weights and biases.",
            "That's going to be exactly 0, so all the weights are not going to change in gradients of zero, and so there's no direction in which you move the parameters.",
            "You also can't initialize all the weights to exactly the same non 0 value because then all the units are at initialization doing exactly the same thing and can also show that as you train them they will continue doing exactly the same thing.",
            "They will all have exactly the same input weights and so will be more or less like having a single neuron at each layer even though we have many of those.",
            "So you need to break that symmetry and so typically we initialize.",
            "Informally, the weights to be somewhat random but close to zero.",
            "OK, an one rule that is often used is this glowing banjo initialization.",
            "So I think many frameworks will now read the global initialization, so it's this case here, so which is essentially uniform between some lower and upper bound B, an with that expression here, which seems kind of strange, but if you look at the duration for it, the idea is that at initialization within initialization like this, you're going to have.",
            "A four 10 H activation function, you're going to have more less equal variance of the activations as you do forward propagation.",
            "So if you have equal variance, that means that the information is propagating well.",
            "There's no vanishing of the activation, and similarly an initialization the gradient that's being back propagated after will also have more or less constant variance, which also suggests that you don't have this vanishing gradient problem.",
            "You're going to get the you know some Watt equivalent in terms of magnitude gradient.",
            "Or learning signal at all layers at initialization, yes.",
            "Space as is after the first operational training.",
            "So the question is whether this behavior of nice flow of information in the forward pass and backward path will maintain.",
            "Just because we initialize this this way we don't know so units could saturate and then suddenly you have weak learning signal for sure.",
            "So that doesn't solve the whole thing, but things you sort of addressed the initialization in terms of flow of information.",
            "That's a good point."
        ],
        [
            "Any other questions?",
            "Yes.",
            "We can have like other sort of cross entropies like JS or KL Divergent.",
            "Beside the cost, right?",
            "So we can afford to make the problem distribution as a loss function, but we can discuss contribution, right?",
            "So I think.",
            "I understand your question is essentially at a higher level, meaning we could imagine other types of loss functions for how we tried to fit our output to the target, and there are definitely other ones which have different properties.",
            "If you're doing maximum margin which is 1 approach for fitting supervised model, you would get a different loss function here.",
            "Then it's possible that in certain situations it works better.",
            "You could in fact also try to just instead of minimizing the negative log probability, you can minimize the negative probability, and some people have argued that that's a better thing to do, and there are interesting things to be said like as you vary the space of loss function, this one is just the most commonly used, but sort of more complicated discussion to be had.",
            "But definitely you shouldn't take this as meaning that this is the best cost function.",
            "It's just the one that's used the most right now.",
            "The.",
            "We single.",
            "Outlook.",
            "Yeah, so the question is, could we have multiple outputs and multiple loss functions?",
            "We could definitely do that so you could have a single output an optimize some weighted average of a bunch of loss functions if you wanted to.",
            "That would sort of corresponds to shaping in some more sophisticated way with the loss function.",
            "Looks like there are certain procedures proposed by some that look a little bit like this an there's perhaps the other thing that you're trying to say, which you might want to predict.",
            "Multiple targets which.",
            "Each have their own loss function that's a form of multitask learning, which I'll discuss a little bit about later on.",
            "But that's also it's just going outside of the simpler framework I'm looking at here, which is single classification, single label case, yeah?",
            "Many different types of Maps so.",
            "Contacts are you mean the loss function or initialization?",
            "Is it limited to fully connected networks?",
            "It was designed for fully connected networks with 10 H activation functions.",
            "People now often use it for any situation, but it might.",
            "You know the theory doesn't tell you that it will be appropriate for that.",
            "Yes, here we can be very naturally extended.",
            "Yeah, you need to adapt.",
            "You get a different initialization.",
            "Scaling factor.",
            "So for different activation function you would get a different.",
            "You know, by this approach suggested initialization.",
            "Which I don't know where they are.",
            "They exist, but it's not in the original paper.",
            "I don't know if you have the reference for as someone derived what they should be for other activation functions.",
            "OK. Somewhere on the web?",
            "But it's doable.",
            "Yes.",
            "Yeah, we'll talk about that in a few minutes.",
            "They are questions.",
            "OK, this one and this one.",
            "Yeah.",
            "Yeah.",
            "Yeah, so I guess the question is, I've talked mostly about vanishing gradient, but you might get exploding gradient.",
            "You might get exploding gradient due to this far OK due to the fact that you always multiplying by this."
        ],
        [
            "Matrix downwards an let's for simplicity, assume that this term is all once.",
            "If this matrix is actually really large, then you might actually get an increase in the gradient propagating.",
            "Then you need to be kind of careful about.",
            "Effectively, what are the size of the entries in there?",
            "So looking essentially at?",
            "What are the Indian values of those matrices here?",
            "An regularization might help.",
            "I think this is an issue that comes much more in recurrent neural networks and I believe that where someone is going to address that is that you, yeah, yeah yeah, we're going to talk about that, but you do need to be careful about this.",
            "The weights become too large then the gradient can explode, can increase in magnitude.",
            "That can also make learning more difficult, so that's a very good point.",
            "Batch normalization yes, and batch normalization I think would also help with that, yes.",
            "Yes.",
            "Yeah, the question is, would it make sense to sort of have multiple different activation functions at various places in the neural network?",
            "I do not know of a convincing demonstration that this really significantly helps you know consistent way.",
            "Part of it is that there are certain activations that you can model pretty well by another layer combining other activations activation functions together.",
            "So a second layer with Relu units could essentially get a.",
            "Hard version of the sigmoid in one layer, and so I think in part because of that there doesn't seem to be much benefit, or at least I'm not aware of anyone showing that there's a lot of benefit and really tuning the activation functions at the level of each individual units.",
            "Maybe there's an algorithm that needs to be discovered that does that effectively, but as far as I know that doesn't really exist.",
            "Alright.",
            "Moving forward."
        ],
        [
            "Shoot I worked on this animation, so let's look at it again.",
            "Anne.",
            "OK, so OK, so that's all the components we need for training one neural network.",
            "Assuming we determine what's the learning rate Alpha, what is the number of epochs?",
            "What is the number of units in the various hidden layers?",
            "How many hidden errors and so on so forth.",
            "But now we need to.",
            "Also we need a procedure for determining those values.",
            "Those are considered as hyperparameters, so hyperparameters are essentially parameters that aren't trained by gradient descent.",
            "They need to be.",
            "Provided to a procedure like gradient descent.",
            "So one approach that people have used for a long time is to perform a form of grid search.",
            "So you would just enumerate all of the values, all of the different hyperparameters, an list out a set of values for each of those.",
            "So the learning rate, maybe you say OK, I want to try 0.1 zero .01 for the number of hidden units.",
            "I want to try 100, five, 100,000, so let's just do two hyperparameters here.",
            "So in grid search you try all combination of any of these values, so that's 2 * 3.",
            "So six different jobs will be running, and then you would for each of these experiments you would look at what is the performance of the resulting train neural network on the validation set.",
            "So the training set validation set to get a sense of how well does that network performance new data.",
            "And then we just pick the neural network and thus the hyperparameters that work best on that validation set.",
            "And that's the network you would evaluate.",
            "Finally, on the test set to report a generalization performance in the paper or so on.",
            "Now the problem with this is that if you have a lot of hyperparameters, another values we want to try that yields an exponentially growing number of configurations to try.",
            "So another approach that actually is much more convenient is random search where against you list out the hyperparameters for each hyperparameter.",
            "You either specify a discrete lists of values you want to try, or you can describe if it's like the learning rate may be described, a distribution over values that you'd like to try, maybe it's uniform.",
            "But with the log distribution from our 0.0012 zero point 1 for instance.",
            "And then you can separately specify how many total configurations I'm willing to try, so maybe that's 50.",
            "And then what you do is just for each experiment you uniformly and stochastically choose for each hyperparameter.",
            "What value going to try separately for each job.",
            "So the first job might be like if I go back to my example 0.1 or 0.01 and then 100 or 500 or 1000 hidden units, I maybe flip a coin at this side.",
            "OK, my first job is going to try 0.1 for the learning rate.",
            "An flip out three sided coin for the number of hidden units and maybe that's 500.",
            "OK, that's one job.",
            "And then I repeat this and that's how I launch my jobs in my experiments.",
            "Ann, what's nice is that it decouples the number of total configurations you try from specifying the range of values you actually want to try out.",
            "The reasons why it's much more efficient in this way.",
            "So imagine for some reason there's one value of one of the hyper parameters that if you pick this value no matter what are the other values.",
            "For the other parameters you pick at, the job is going to crash.",
            "Your maybe the learning rate is too high, and then any configuration of number of hidden units.",
            "They're all going to diverge essentially well in grid search.",
            "That means you're essentially wasting a lot of experiments.",
            "All of those that is using that specific value, whereas in random search, especially if you're considering a large interval of values, then you can kind of hope that we can sort of determine how many experiments with that specific value.",
            "Am I going to try out and maybe favor values that are less likely to crash, for instance?",
            "Also, if you have one experiment in your grid that then wasn't executed or something, this is kind of annoying.",
            "You have a hole in your grid, whereas here it's really all you need to specify is the number experiments you ran, and that's it.",
            "So I hand yes.",
            "Say what?",
            "Generalize in what way?",
            "So.",
            "I'm not exactly what you mean by generalization.",
            "One thing it doesn't do is it doesn't learn from its mistakes, right?",
            "It's essentially not going to learn that you know, after a few runs that high learning rates aren't good and I should try, you know, smaller ones.",
            "There are more sophisticated approaches like those I'm mentioning here, like Bayesian optimization.",
            "Some people coined similar procedures as sequential model based optimization where.",
            "You can think of it as as I'm running more experiments, I'm going to train a model on predicting from a set of hyperparameters.",
            "What is the ultimate performance on the validation set, and now I'm going to use that model to suggest me a new hyperparameter to try out and so that procedure will have better sort of convergence properties like it will find a better solution more rapidly, and some people use that for exploring spaces, but this is already a pretty good procedure that's not easy to be given.",
            "The sophistication of implementing something like this, so this is better, but that's already really really good and random search.",
            "Yes.",
            "Thanks.",
            "Yeah, sure.",
            "Shamelessly, yeah, so you'll talk about that.",
            "That's good, so you have discussion on Bayesian optimization tomorrow morning, afternoon.",
            "Cool.",
            "Yes, so next.",
            "So we use a validation set to evaluate the relative performance of all of these configurations of hyperparameters and but then ultimately we pick the best one and we valid on the test, and then that's where we report in papers and so on.",
            "Alright."
        ],
        [
            "Anne.",
            "Now there's one hyperparameters that we can do something a bit more clever than just trying a bunch of different values and running separate experiments, and that's the number of epochs.",
            "Effectively what we use in practice usually is something known as early stopping.",
            "So what this means is that as your training, you're going to look at the performance of your model every epochs or every excep up on the validation set, and then get a track you know.",
            "Essentially draw curve conceptually of the performance on the validation set as you go, and what we usually expect is that the performance of validation set is going to get better and better and better, and then at one point is going to be an inflection point where it's going to start getting worse.",
            "And in this case, often informally, we say that we're started overfitting, and so at that point an often we sort of wait for a few iterations just to see whether it's just noise in our estimate of validation set performance.",
            "But after a few iterations where it hasn't improved, then we just go back to whichever values of the weights gave us the best validation set performance, and we stopped raining there, and that's the performance we report for that experiment for that run OK.",
            "So it's called early stopping in the sense that if you only look at the training error, you could probably train much longer.",
            "But what we care about, of course, is how well it does.",
            "On new example, it added seen an early stopping.",
            "Does that really, really well an implicitly it also kind of acts as a regularizer in the sense that it will make it difficult for the neural net to train along time and not be stopped, and so not go far away from its initial values of the weights, which are typically close to 0.",
            "So it implicitly also regularizers your procedure, your training procedure, because just to be a bit more concrete, what is effectively going on here is that the training error is always going down 'cause we have an optimization algorithm that works well.",
            "But then the gap between the performance as estimated on the training set and on the validation set so that gets bigger and bigger and bigger.",
            "And because the training set can only go so low at one point the difference becomes so large that you can see this upward trend.",
            "This U shaped curve.",
            "In the validation set performance so far, all other hyperparameters usually use something like random search or Bayesian optimization, but for the number of training updates within a single run, we would use early stopping like this.",
            "Any questions on any of that, yes.",
            "So when we do, we split the training data into training and validation weekend especially so this is a problem I personally faced.",
            "We lose a lot of training data.",
            "So we employ early stopping.",
            "How can we?",
            "How can we use that training data after early stopping this time?",
            "Yeah, so the question is that.",
            "When we so often in certain cases we already have a test set that's identified, especially in research using this sort of agreed upon testing set, but also often there's just a training set and you kind of have to make the decision.",
            "How much do you keep for actual training and how much of that do you keep for validation for selecting hyperparameters and so on?",
            "And what that proportion is is, you know, that's everyone has their favorite number them.",
            "Certain sort of depends from one case to another, and one researcher do another.",
            "If you don't have a lot of training examples, you might really want to use the validation set data also not just for training for figuring out the hyperparameters, but also for influencing the final model in a more substantial way.",
            "One thing you could do so some people do this thing where they add back the validation set into the training set and train a little bit more.",
            "I personally don't like this because I feel like you're effectively at some point you must have looked at the test set like I don't see how you sort of randomly got lucky at stopping at exactly the right point, and I I have not been convinced by most heuristics out their proposal.",
            "You should stop when you reach again the training set performance you had before.",
            "I think you can make up cases where that's going to overfit.",
            "The test set so I don't like that all that much.",
            "I prefer something like you do multiple train validation set splits, so maybe you take 20% eighty from your global training set, so that's five potential splits and you do you train so you find 5 different models for each of these splits that work well on their validation set, and then you assemble them so you have now five models and you average their predictions.",
            "Assembling usually works pretty well and usually improves the performance.",
            "So you'll get some benefit out of that.",
            "Then you will effectively have your whole training procedure.",
            "For example, will have used all of your training examples, so I feel this is sort of less risky of an approach to use and less prone to some form of cheating.",
            "Any questions see you smiling you ever comment on that?",
            "Crowd.",
            "Do that when they're comparing apples and oranges.",
            "You mean so?",
            "I think the point Errol to make is that now often there is an accepted in agreed upon validation set in the paper.",
            "It's not really legitimate to say, Oh my Ensembl works better than this single model reported in the literature.",
            "That's not really impressive like, so don't do that just to be in a state of the art, but in practice, if you really only care about getting the best performance in assembling, ultimately is.",
            "And this is one form is a good approach.",
            "That yes.",
            "Alright, next OK. A few other tricks of the trade.",
            "Yes.",
            "So but so well.",
            "I would argue that optimization algorithm that doesn't.",
            "Fairly consistently decrease the training error isn't much of an optimization algorithm, 'cause that's really what it's meant to be doing.",
            "So now there might be noise.",
            "This is kind of very smooth so that you will see and sometimes you will see curves where like it's actually the trend you know is that it's decreasing always on the training set, but it's bouncing up and down that you might see.",
            "Normally.",
            "You expect that optimization algorithm to do better and better better on the loss.",
            "The average loss possibly regularised average loss.",
            "You do expect that from the optimization algorithm.",
            "Let's have an example.",
            "Maybe you want to.",
            "I see, yeah, so maybe sometimes it'll be flat like it doesn't necessarily always go up.",
            "You will see validation curves that sort of plateau that you might observe this if you have.",
            "If essentially you have so much data that you barely have any overfitting, you might see like these curves being very, very close to one another.",
            "Sort of assuming here that you actually don't have that much training data.",
            "And there's like a generalization gap that you kind of expect.",
            "Yes.",
            "Right so.",
            "I don't think that's an issue, because in both cases they're all sort of equally hyperparameters.",
            "This is kind of a way of doing using smart bookkeeping for exploring more values of the number of iterations.",
            "So I think at least that's the way I view it, and this sends it makes sense to use the validations that also for this, and also as we said, like we don't have want to avoid having multiple validation sets, because each of these data points are pretty valuable and you want to make the most of it and that sort of.",
            "Using it training as another hyperparameter that you're just being a bit smarter in terms of running experiments by doing effectively some bookkeeping.",
            "At least that works well in practice.",
            "That's a good question though.",
            "Alright."
        ],
        [
            "Going forward, so if you have real valued observations, you should consider normalizing your data so that it has mean zero.",
            "An standard deviation of one.",
            "That sort of at least helps having fairly behave gradients at the first layer an fairly behave activations moving forward in the network.",
            "It has often been observed also that it actually speeds up training.",
            "It makes it more effective.",
            "Having constant learning rate, there's really not what most people do.",
            "One simple approach is to actually start with a fairly high learning rate, and then every once in a while dividing it by 2 by 10.",
            "So specifically, you might track the validation set performance, and then once it stops improving you go back right before you started overfitting.",
            "You decrease the learning rate and you continue training a little bit with a small learning rate.",
            "The intuition being that initially.",
            "Since you're very far from the optimum, you can make large jumps because you're pretty far from the optimal, so there's still a long way to go, and the gradient is sort of point, you know, despite the noise in your gradient is pretty much pointing in the direction of the course direction of the solution, but as you get closer and closer, you might want to more slightly adjust the parameters, in which case you want a smaller learning rate.",
            "OK, as you get closer, yes.",
            "So I mean, you definitely don't.",
            "When you have a large learning rate and you might see some affiliation even see some affiliation on the validation set just from the fact that you have finite sample.",
            "It's kind of noisy estimate of the generalization performance, so This is why for early stopping.",
            "For instance, we do this sort of look ahead where you maybe wait for five iterations and check whether your slight increase in validation set will not be offset by a lower decreased later on.",
            "But there's no actual guarantee.",
            "It's sort of roughly you kind of expect it to go down, but especially with large learning rate and might sort of bounce off a little bit.",
            "Anne."
        ],
        [
            "We've talked about mini batch size, so actually in practice we rarely do one example at a time gradient updates.",
            "We actually use a mini batch.",
            "This is much more effective because for fully connected networks essentially we can do things like matrix matrix operations as opposed to multiple matrix vector operations an on the GPU.",
            "Say you can sort of implement that much more efficiently than serially executing in multiple matrix vector operations.",
            "And we'll talk a little bit about some of the generalization implications of using some batch size of variable size.",
            "Also, instead of just using your estimate from your current batch, you can use a thing called momentum in momentum instead of using as the update direction, just the gradient from your current example or current mini batch, so you wouldn't have this here and this would be your dissent direction.",
            "Instead, we sort of mix it with.",
            "A portion of the previous update direction, so the idea here is that if you have a sequence of update directions all going in the same direction, then presumably that's a good direction to exploit.",
            "So you can think of optimization landscape as maybe having being in a sort of plateau.",
            "Where that's we have a very small inclination.",
            "Well, when a momentum like this you might well gain momentum as you're moving in this consistent direction across mini batches.",
            "However, if all of your mini batches kind of disagree about the.",
            "Sign of the direction.",
            "For certain parameters this would help.",
            "Canceling these out between gradients and might allow you to do less bouncing off because of that, so that's one thing that you'll see some people using for designing better optimizers."
        ],
        [
            "And then also one thing that we might want is not a single global learning rate for the step we're taking in a given direction, but actually have one effectively one learning rate by parameter.",
            "So one way we can think of this is to essentially take our dissent direction.",
            "This is, I guess, the grain is that's the ascent direction would go in the opposite side, but taking that vector that gives us an idea of what direction we should move in parameter space.",
            "But then dividing it.",
            "Element wise by some vector that kind of gives us a notion of how sensitive the parameters are in terms of the objective, and so you will possibly read about adigrat in papers where what you're using is essentially a running sum of the square of the gradient.",
            "So what this means is that if a parameter has had a large partial narrative across training, you're going to take the square root of that and you some a lot of large values.",
            "Then you're going to more rapidly start using smaller learning rates for that parameter, whereas if you have a parameter, it's barely being updated, then it's learning is going to stay large until it starts getting meaningful gradient, and then it will start having an effective learning rate that smaller RMS prop is essentially the same idea, except that instead of using the sum of the squared gradient and I should have said, then you actually take the square root of that sum and we had an epsilon for numerical stability or small.",
            "Very small value like 10 to the minus six or something.",
            "So instead of using a sum we use a exponential moving average.",
            "So we take a portion of the current.",
            "Average an we add to this one minus that portion of the current squared gradient.",
            "So that's RMS prop.",
            "So instead of being guaranteed of having a learning rate that always reduces, so that's the property you have here, because this number can only increase as you add more terms.",
            "This one means that the learning rate might sort of decrease the effective learning rate decrease, and then increase again if you get very small gradients for a long time and then might if we resume getting gradients for parameter, it might.",
            "Decrease again, so that's another thing you might see in the literature.",
            "And then there's Adam, which is probably the most popular approach right now, which is essentially RMS prop but with some form of momentum.",
            "An general common wisdom tells us that the practice of most people is that this is actually a pretty robustly successful optimizer.",
            "You don't have to tune, there are hyperparameters, but the defaults tend to work pretty well, so that's not a bad idea to start with this for experimenting.",
            "With a given idea, however, some people have had better performance when, perhaps when they sort of figured out what their algorithm is.",
            "They start using gradient descent with regular momentum and sort of tweaking a schedule for their problem.",
            "Some people have had more success, but fairly marginal but larger success than with Adam, so a sort of good approaches to start with Adam and then really really care about the performance.",
            "Then maybe consider gradient descent with momentum, where you have a control over the schedule and play with those.",
            "Questions yes.",
            "Right so.",
            "I mean, you could definitely add an effective global learning rate here, and also do this thing where you track the validation set performance and then change what that factor is.",
            "I'm sorry some people have played with that.",
            "Then it might be valuable to combine that as well here.",
            "I think with Adam to get pretty good results, you don't really need to do that, but I possibly some people have.",
            "I'm not sure actually have any sort of interesting bits of knowledge about that, yes?",
            "Sailing.",
            "Right, so the question is, by dividing by this elementwise vector, we're really changing the direction of what the gradient is.",
            "That said.",
            "It's it's still like if you did the dot product between this and the original gradient, you would still get a positive angle, so it has that property going for it, right?",
            "So that's why it's not affecting it too much.",
            "It's not going to change the sign, for instance this term is positive, so I'm going to change the sign of the direction an.",
            "I think I'm assuming this is partly why for some of these procedures we can actually prove forms of convergence is that it's actually going still as a positive angle with the gradient.",
            "That's a good point.",
            "And there are.",
            "There was mention of 2nd order approaches which will also have this kind of effect where it's changing the direction and there's still some research and trying to develop better and also scalable.",
            "That's one of the challenges of 2nd order methods, but this is the Atom is a pretty good place to start.",
            "Other questions, yeah.",
            "Learning rate.",
            "He said that.",
            "Yep.",
            "To make a simple get there.",
            "The whole thing.",
            "You mentioned that.",
            "I mean, do we have enough units here?",
            "What can I represent with the unit and this actually?",
            "I mean what is represented?",
            "Yep.",
            "Pastor haha.",
            "Order yeah, so I will talk a little bit about some of the latest experimental observations about.",
            "The interesting relationship between capacity and learning algorithm, which I get a sense you're sort of getting at with your question.",
            "Here I will say that.",
            "First, we'll talk about how non combats this objective is.",
            "So the to answer the question.",
            "OK, there's this universal approximation theorem, but can I actually discover these weights?",
            "Part of the key to that answer is how nonconvex optimization is it crippled with a bunch of really bad local Optima?",
            "Will talk about that in the second half for sure.",
            "Can we see that?",
            "I mean, I guess we sort of, you know, just looking by the fact people are using neural Nets quite a bit and our training fairly large.",
            "No, let's it is clearly not as bad as one might think.",
            "I'll try to add a bit more intuition that is too like what we think is going on, but that's very much an open area research too.",
            "Yes.",
            "There.",
            "Recommended normalized.",
            "Yeah, not much is.",
            "They can have all sorts of different you know.",
            "Like little probabilities, sparse.",
            "Is there anything any practical?",
            "Yeah, the question is.",
            "Is there any interesting normalization we should do with Princess binary data so for binary data in general, just using the binary vector I found to work pretty well with count data there definitely literature saying the information retrieval field where using things like TF IDF.",
            "Waiting, which will change the original waiting.",
            "It's a form of normalization I guess on the input dimensions, which essentially will emphasize the importance of a term that is only found in a few documents.",
            "An isn't very free, but is very frequent.",
            "For instance, there are definitely so fun, since if you were mad in plating bags of words, if your input X is essentially the counts of number of different words in a document form of TF, IDF weighting might be a good normalization to use here.",
            "But for binary data, usually working with just the binary data will work pretty well.",
            "It's not.",
            "I wouldn't say you shouldn't think about whether you should enhance the weight of a very like a one dimension.",
            "That's binary, but very infrequent, specially all the literature on TF.",
            "IDF weighting suggests that sometimes that's valuable, so I would maybe explore that a little bit, but it would start with maybe not doing having to do anything.",
            "OK, I'm almost out of time, so I'm going to do yes, sure.",
            "Which one?",
            "This one.",
            "In practice, I think the verification error.",
            "Yeah.",
            "I wonder how how we can automatically.",
            "Yeah, so the question is how to handle essentially how validation set performance might fluctuate quite a bit and that had this nice move curve that I showed.",
            "Honestly, it's a good question.",
            "I find some people have shown some success in being very patient and waiting for the validation set performance for a long time to not change.",
            "Sometimes it is helpful.",
            "I have to say I don't have a very good sort of like heuristic that works universally universally.",
            "So, but it is.",
            "If you have a lot of punctuation, I would just advise that maybe you might want to sort of wait longer an beyond an automatic rule.",
            "Just looking at it and kind of making a decision just by based on how much it varies compared to other experiments you might have done, does not.",
            "I don't have particularly good advice for that, but I just something to sort of be careful with.",
            "Yeah, yes.",
            "Yep.",
            "I like.",
            "General.",
            "Yeah, so I guess the question is about maybe some heuristics for when we're exploring the number of layers as well as the number of hidden units.",
            "I found in practice what I usually do is actually just assume a constant number of hidden units per layer for fully connected networks we have some evidence that usually this is actually a reasonable assumption.",
            "It's absolutely perfect when it's not too far from optimal.",
            "So then one thing you might want to do is first just figure out a rough idea of how many layers works well by just.",
            "Jointly optimizing the number of layers and the number of hidden units per layer.",
            "So that makes for fewer various.",
            "That's just two numbers that you need to explore.",
            "There's definitely now more more research on trying to explore much more richer architectures using.",
            "Various forms are things that look like Bayesian optimization, but that might use reinforcement learning with RNS and soft.",
            "There are things published I cleared this year, for instance from Google.",
            "What they do this, but that still requires a lot of compute, so I would say are you Ristic, which is assume a fixed number of units per layer and then tuning depth fixed number and the number of layers separately as two different hyperparameters is just two operators, so it's not too bad, it's a good place to start that would say.",
            "But there's still some research to be done in terms of doing going more deeply and tuning the architecture.",
            "Or random search yes, yeah, yeah it gets you most of the way I think.",
            "OK so I am."
        ],
        [
            "Out of time probably, but I want to finish this real quick so one message if you are so usually if you use Tensorflow or Pytorch or other or theano's or libraries that have a bunch of these smaller grained operations as you can build more and more sophisticated neural networks usually don't have to check for your gradients because they have been unit tested and they should be fine if you implement your own module with its own forward and corresponding backdrop or gradient computation procedure.",
            "You should definitely do that and our procedures for doing this, which essentially what you end up doing is you add you essentially approximate the real partial narrative by finite difference by adding some epsilon and subtracting some epsilon, and then dividing by the difference by two epsilon.",
            "So if epsilon goes to zero, that's the actual definition of this partial narrative with a small epsilon you should get a number that is pretty close to the actual partial narrative, so that's a thing you should definitely do if you implemented your own gradients.",
            "And also, before you launch your full blown you know job on some new data set.",
            "I really do recommend that you do small tests on a very very small version of your data set.",
            "So just take the 51st training examples an look at whether it's able to overfit it should any network with reasonable capacity should be able to overfit on 50 examples and so and then you can look at OK, what's going on with my units if I'm not overfitting and reaching perfect performance of 50 examples.",
            "You can look at your units, whether it's saturating an maybe identify all.",
            "That's because I badly initialize certain parameters in my my neural network.",
            "Or maybe it's just my inputs that are taking a scale that's too large and I should normalize them."
        ],
        [
            "If the training error is bouncing up and down a lot, that might give you some indication that your learning rate is too large and you should start with something smaller, and this isn't a replacement for gradient checking, so your gradients might be wrong and you might still be able to overfit so.",
            "These neural networks are pretty resilient to bugs, which is great if we use them in real life.",
            "Not great when you're doing science and trying to understand how things work, so you should really be doing both these things.",
            "If you implemented some of your own gradients.",
            "And I'll stop here, I guess, and then I'll finish with deep learning and then talk about some more recent results in the afternoon.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so yeah, so I have been tasked to go do an overview on neural networks.",
                    "label": 0
                },
                {
                    "sent": "Sort of two parts in it where mostly in the morning I'll talk about things that I think a lot of you are familiar with, but just to make sure everyone's sort of up to speed just out of curiosity.",
                    "label": 0
                },
                {
                    "sent": "So who here knows about neural Nets and back problems?",
                    "label": 0
                },
                {
                    "sent": "Just raise your hand, alright?",
                    "label": 0
                },
                {
                    "sent": "Who has implemented neural networks and random neural network experiments here?",
                    "label": 1
                },
                {
                    "sent": "Alright, that's more than most.",
                    "label": 0
                },
                {
                    "sent": "Oh wow, that's actually.",
                    "label": 0
                },
                {
                    "sent": "Fairly impressive, so yeah, so I think I think.",
                    "label": 0
                },
                {
                    "sent": "Most of the heroes I have sliced prefer, but but of course not everyone knows about all of the details, so please make this interactive.",
                    "label": 0
                },
                {
                    "sent": "Ask me questions.",
                    "label": 0
                },
                {
                    "sent": "Really, the idea is for everyone to be up to speed, and I'm sure if my previous years are any indication that for most questions Yahshua will without prompting answer the questions.",
                    "label": 0
                },
                {
                    "sent": "So I think the point is for everyone to catch up.",
                    "label": 0
                },
                {
                    "sent": "The other reason might just be that Aaron critical thought it would be nice if I presented for three hours on the topic you all know about, just to see me suffer as you're all being bored, but hopefully I mean this is probably not the main reason, but I know it has non zero probability so well, maybe it's both who knows.",
                    "label": 0
                },
                {
                    "sent": "So OK, so let's get started.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So most of these slides are taken from my online course on YouTube, not taught by this much younger version of myself.",
                    "label": 0
                },
                {
                    "sent": "If you want to check those out, there's more details on the derivation of background, which I will not do, but it is important to go through that.",
                    "label": 0
                },
                {
                    "sent": "That's really what distinguishes real deep learning experts from non deep learning experts.",
                    "label": 0
                },
                {
                    "sent": "As far as I'm concerned.",
                    "label": 0
                },
                {
                    "sent": "So do go check this out.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, I'll try to talk about mostly today or the following.",
                    "label": 0
                },
                {
                    "sent": "I'll just start by just doing an overview and mostly sending up the notation for web.",
                    "label": 0
                },
                {
                    "sent": "Neural Nets are now.",
                    "label": 0
                },
                {
                    "sent": "We make predictions with neural Nets, then talk about how we train neural networks with a little bit of discussion and some of the tricks of the trade that people tend to use in practice and then specifically focus on deep neural networks and talk about some perhaps slightly more modern approaches for successfully training neural Nets.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start so we can talk about neural networks without talking about what is a neuron.",
                    "label": 0
                },
                {
                    "sent": "So in order.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actual neuron?",
                    "label": 0
                },
                {
                    "sent": "Well, mathematically be the following to compute the value of a neuron will start by computing what I'm going to call the pre activation pre activation is going to be a bias multiple plus the multiplication of the inputs of the neuron multiplied by some weight vector W. So a neuron is paralyzed by its bias and its weight.",
                    "label": 0
                },
                {
                    "sent": "You can think of the weight vector as kind of a pattern that this unit is detecting an it's sort of measuring the similarity.",
                    "label": 0
                },
                {
                    "sent": "Or how much the pattern fits with the input by doing a dot product with it.",
                    "label": 0
                },
                {
                    "sent": "An once we've computed this pre activation which is a linear transformation.",
                    "label": 0
                },
                {
                    "sent": "We compute an activation bypassing the pre activation through an activation function which I'm noting G which is unusual and non linearity such as the sigmoid that an age or the rectified linear unit or activation.",
                    "label": 0
                },
                {
                    "sent": "So visually it sort of looks like this.",
                    "label": 0
                },
                {
                    "sent": "Sometimes I draw it as the bias be being a weight with a constant one, and then you get the other weights WN WD4D dimensional inputs.",
                    "label": 0
                },
                {
                    "sent": "If you have a D dimensional input space.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's what an artificial neuron is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you had a neuron that takes 2 inputs so that lives in two dimensions.",
                    "label": 0
                },
                {
                    "sent": "Input one here and put two here.",
                    "label": 0
                },
                {
                    "sent": "You can visually look at the output of that neuron, which is this axis here an it will essentially look at like separating two regions in a linear way, so it's effectively if you use G for the function G for user sigmoid, it's effectively a logistic regression classifier where there's an area with a large value.",
                    "label": 0
                },
                {
                    "sent": "Another area with small value and vector W will be perpendicular to the.",
                    "label": 0
                },
                {
                    "sent": "Essentially, the decision surface, the line that draws between the positive and negative part, or the two sets of decision regions.",
                    "label": 0
                },
                {
                    "sent": "OK, so the angle of W determines the angle of that decision service and the bias sort of will change where in that direction the slope will be varying.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so that's a single neuron, so we can parametrised a linear classifier with a single neuron.",
                    "label": 0
                },
                {
                    "sent": "But of course most problems aren't linearly solvable.",
                    "label": 0
                },
                {
                    "sent": "They require a nonlinear decision function.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out like combining several neurons together, we can get nonlinear surface is.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if I had a neuron here at a second layer that was taking as input, these two neurons where we have the illustration of the output of neuron on the left on the right.",
                    "label": 0
                },
                {
                    "sent": "Well, roughly speaking, if this neuron here was taking the activation of that neuron and then subtracting the activation of that neuron, you would essentially get that surface here.",
                    "label": 0
                },
                {
                    "sent": "But with that part.",
                    "label": 0
                },
                {
                    "sent": "Being sort of carved out as you're seeing here, OK now I can see that with by combining, these two neurons were getting something that is nonlinear.",
                    "label": 0
                },
                {
                    "sent": "Now you have like a restricted area of the input space that has large value with low values on both the left and right side.",
                    "label": 0
                },
                {
                    "sent": "And now we.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do something similar if we had four neurons where we can sort of carve out at second layer.",
                    "label": 0
                },
                {
                    "sent": "Sorry bout that second layer.",
                    "label": 0
                },
                {
                    "sent": "A little bump like this.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now if we're able to do this by combining one layer of simulated value neurons when he cuts on, imagine you can put bumps at various places of the input space and start carving out or fairly complex classification rule and your 2D input space, and so that's kind of the appeal of artificial neural networks, and using that intuition you can add.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, show mathematically a universal approximation theorem, which says that with a single hidden layer neural network, even with the linear output, we can essentially approximate any continuous function arbitrarily well given enough hidden units.",
                    "label": 1
                },
                {
                    "sent": "So if I have enough of these hidden units to construct these little bumps in input space and add them altogether and position them nicely, any function under certain conditions but essentially continuous functions, we can approximate it well enough.",
                    "label": 0
                },
                {
                    "sent": "If we allow for enough hidden units in the hidden layer, OK, so that means that if we constrain ourselves to just training neural networks, we can represent a lot of functions.",
                    "label": 0
                },
                {
                    "sent": "Potentially all the functions that we need to approximate if we want to design system that learn from data that's learning function that we don't know about that that's instantiated in some data.",
                    "label": 0
                },
                {
                    "sent": "Now this says we can represent a lot of different functions with neural Nets, but it doesn't say anything about how do we train these neural Nets.",
                    "label": 0
                },
                {
                    "sent": "How do we find these weights?",
                    "label": 0
                },
                {
                    "sent": "Up the neurons in the biases OK, and so that we'll talk about a bit later.",
                    "label": 0
                },
                {
                    "sent": "Any questions about that part?",
                    "label": 0
                },
                {
                    "sent": "Yes Mr banjo.",
                    "label": 0
                },
                {
                    "sent": "What does this say about generalization?",
                    "label": 0
                },
                {
                    "sent": "Not much until we really talk about learning, which we'll talk about after.",
                    "label": 0
                },
                {
                    "sent": "That's not a trick question, just putting me on the spot like that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so most of the time, or at least in this presentation I will focus on multilayer neural networks that often called fully connected neural networks, because of course what I discussed before.",
                    "label": 0
                },
                {
                    "sent": "So this suggests you could kind of compose a bunch of different neurons in an arbitrary way, but one type of architecture that people often uses this one here.",
                    "label": 0
                },
                {
                    "sent": "Well, you have some number of hidden layers, so in this case we have two hidden layers and each hidden layer.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to the computation of 1st a pre activation of all the units in that layer, and this is essentially taking the value of the previous layer.",
                    "label": 0
                },
                {
                    "sent": "So if it's the previous layer, if that's the input, that's a zero of X would be equal to the input X and otherwise will just be their previous hidden layer.",
                    "label": 0
                },
                {
                    "sent": "So you take the previous hidden layer and then multiplied by some weight matrix WK.",
                    "label": 0
                },
                {
                    "sent": "So case the index over layers and then you add a bias vector.",
                    "label": 0
                },
                {
                    "sent": "So the parameters of my model are essentially of my neural net.",
                    "label": 0
                },
                {
                    "sent": "Are these bias vectors at each layer and these weight matrices which contain all the weights between the units in one layer and the layer below?",
                    "label": 0
                },
                {
                    "sent": "OK, so AK of X that's going to be my pre activation vector, then I will pass this through an activation function G. Which will put some nonlinearities in my model that allows it to be nonlinear classifier or predictor.",
                    "label": 0
                },
                {
                    "sent": "And we do this all the way up till the output layer.",
                    "label": 0
                },
                {
                    "sent": "So those two here would be the hidden layers.",
                    "label": 0
                },
                {
                    "sent": "This is the input layer, you know there is the output layer and for the output layer often we will use a different activation function depending on what the problem is.",
                    "label": 0
                },
                {
                    "sent": "If we're classifying examples and say 10 classes, then we'll use a softmax, which I'll describe in a few minutes.",
                    "label": 0
                },
                {
                    "sent": "Any question about that notation, I'll sort of use that quite a bit.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in terms of activation functions, one pretty well known is the sigmoid activation function, which you're seeing here.",
                    "label": 1
                },
                {
                    "sent": "It's 1 / 1 plus the exponential of the negative pre activation.",
                    "label": 1
                },
                {
                    "sent": "So what it looks like is that it takes it input that can be from its pre activation that can be from negative Infinity to positive infinite and it squashes that.",
                    "label": 0
                },
                {
                    "sent": "Between zero and one OK.",
                    "label": 0
                },
                {
                    "sent": "So at zero it's equal to 0.5 and as you increase it, it converges to one.",
                    "label": 0
                },
                {
                    "sent": "In other.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function you probably know about this.",
                    "label": 0
                },
                {
                    "sent": "The 10 H. It's kind of like the sigmoid instead that it's squashing things between minus one and one instead of between zero and one at 0.",
                    "label": 0
                },
                {
                    "sent": "The 10 H is equal to 0.",
                    "label": 0
                },
                {
                    "sent": "It outputs 0.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's also what is probably now by far the most popular activation function, which is the rectified linear activation function.",
                    "label": 1
                },
                {
                    "sent": "It is simply the maximum between 0 or the pre activation.",
                    "label": 0
                },
                {
                    "sent": "OK, so the function would look something like this, where when the pre activation is negative the activation, so the output of the activation function is 0.",
                    "label": 0
                },
                {
                    "sent": "If it's positive, well it's the pre activation itself, so it's linear with a slope of one OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for the output we often use what's known as the softmax activation function.",
                    "label": 1
                },
                {
                    "sent": "It is pretty simple, you just take your whole vector of pre activations at that layer, you exponentiate it.",
                    "label": 0
                },
                {
                    "sent": "So exponentiated the first dimension all the way to the final dimension in that layer.",
                    "label": 1
                },
                {
                    "sent": "So usually we use the use of the output layer.",
                    "label": 1
                },
                {
                    "sent": "So I'm using C as the size of that layer where capital sees the number of classes.",
                    "label": 0
                },
                {
                    "sent": "So we have one neuron per class.",
                    "label": 1
                },
                {
                    "sent": "Then we want to.",
                    "label": 1
                },
                {
                    "sent": "Classify and then we take the exponentiated preactivation and then we divide by the sum of all the numerators all the exponentiated pre activations.",
                    "label": 0
                },
                {
                    "sent": "OK, So what this means is that the output of the softmax.",
                    "label": 0
                },
                {
                    "sent": "Is positive because we exponentiated all pre activation, so it's got to be positive and it also sums to one because we're normalizing it where summing by the divided by the sum of all the numerators.",
                    "label": 0
                },
                {
                    "sent": "So we can actually treat that as a distribution over all the classes.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's actually formally how we will think of the output of the neural network.",
                    "label": 1
                },
                {
                    "sent": "It's giving us.",
                    "label": 0
                },
                {
                    "sent": "What is the conditional distribution of the label Y given some input X?",
                    "label": 0
                },
                {
                    "sent": "So it's given us the probability belong to.",
                    "label": 0
                },
                {
                    "sent": "Each of the possible classes.",
                    "label": 0
                },
                {
                    "sent": "And now if we were to classify data using that softmax would just look at what is the neuron, what is the output neuron that's the highest value?",
                    "label": 0
                },
                {
                    "sent": "That's effectively according to our neural net.",
                    "label": 0
                },
                {
                    "sent": "What is the most likely class given the input and we will assign as a prediction the input to that class?",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The question is why isn't it called the soft argmax?",
                    "label": 0
                },
                {
                    "sent": "That's a very good question.",
                    "label": 0
                },
                {
                    "sent": "I actually don't know.",
                    "label": 0
                },
                {
                    "sent": "I think it would be better called in softmax.",
                    "label": 0
                },
                {
                    "sent": "So the reason why you might want to think of this as a soft argmax is that well, if you had a bunch of numbers and you wanted to identify the.",
                    "label": 0
                },
                {
                    "sent": "The unit with the maximum value, so that would be the argmax one way of encoding that might be to have a bunch of zeros and with the one that the corresponding maximizing dimension.",
                    "label": 0
                },
                {
                    "sent": "Well, these these values here are all going to be between zero and one, and the dimension that has the highest value is going to be the highest, the closest to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's kind of a soft version of an argmax, encoded with so-called one hot vectors.",
                    "label": 0
                },
                {
                    "sent": "These vectors with a bunch of zeros in a single one.",
                    "label": 0
                },
                {
                    "sent": "Other question yes.",
                    "label": 0
                },
                {
                    "sent": "It doesn't even matter that they are invertible, because radio is not inverted.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So the question is whether it matters that the activation functions, some of them aren't invertible, so here it won't, at least in terms of classification, and it's not going to really matter it to some extent, introduces some invariances which might be useful.",
                    "label": 0
                },
                {
                    "sent": "There might be types of models like in unsupervised learning.",
                    "label": 1
                },
                {
                    "sent": "Sometimes that's an interesting property to have, but in the context of classification here, not really.",
                    "label": 0
                },
                {
                    "sent": "Luck.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yes so.",
                    "label": 0
                },
                {
                    "sent": "The universal approximation theory for washing activation function.",
                    "label": 0
                },
                {
                    "sent": "Danielle is not just watching it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah I guess the question is so I talked about in Universal approximation Theorem, but at mostly considers quashing activation functions, whereas the real issue isn't upper bounded.",
                    "label": 0
                },
                {
                    "sent": "So I'm pretty sure if it's not been done, I'm pretty sure the universal approximation still applies if you ever lose you.",
                    "label": 0
                },
                {
                    "sent": "Essentially you can represent piecewise linear functions and with enough pieces you can kind of think that you could arbitrarily approximate any function.",
                    "label": 0
                },
                {
                    "sent": "Squashing function right, and you can also combine two relatives to get a sort of hard sigmoid, for instance.",
                    "label": 0
                },
                {
                    "sent": "Other questions, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, the question is, can we interpret these probabilities as a confidence into that prediction?",
                    "label": 0
                },
                {
                    "sent": "I think technically that is kind of the interpretation we're putting here.",
                    "label": 0
                },
                {
                    "sent": "That is, it is our current estimate of what is the probability that this input would belong to that class.",
                    "label": 0
                },
                {
                    "sent": "Now, whether these probabilities are so called calibrated that they kind of correspond to at Test time a, you know the actual probability that an input in that area would actually belong to that class is another question, and usually you have a separate process for calibrating these probabilities using a validation set, but that's a good point.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't trust these probabilities necessarily, and usually we go through a process that's called calibration, which I'm not discussing here but that.",
                    "label": 0
                },
                {
                    "sent": "You can probably find.",
                    "label": 0
                },
                {
                    "sent": "For instance, overfitting, yes, you're sort of overconfident.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Activation use them separately.",
                    "label": 0
                },
                {
                    "sent": "Stations of the model is that.",
                    "label": 0
                },
                {
                    "sent": "Does that pull throughs or any way of going back?",
                    "label": 1
                },
                {
                    "sent": "Interpreting like the marginal value of the.",
                    "label": 0
                },
                {
                    "sent": "Of the parameter.",
                    "label": 0
                },
                {
                    "sent": "So let's say the relatively near this kind of Tobit estimator is that that has certain properties before just looking into simply.",
                    "label": 0
                },
                {
                    "sent": "But when you stack them, can you still abstract interpretation or not?",
                    "label": 0
                },
                {
                    "sent": "So I think, are you asking for instance, if we think of hidden units as modeling probabilities of.",
                    "label": 0
                },
                {
                    "sent": "At the internal level of their neural net, whether we.",
                    "label": 0
                },
                {
                    "sent": "People who knows a lot about metal, not so just wasn't sure when we're looking at the parameter.",
                    "label": 0
                },
                {
                    "sent": "Wait, if I just have that as a simple model.",
                    "label": 0
                },
                {
                    "sent": "Those properties broadcast out through the net, so beyond.",
                    "label": 0
                },
                {
                    "sent": "Neural Nets in general are very hard to interpret, especially what the different parameters internally mean in terms of what is the behavior of the neural net and the activation of the hidden units themselves.",
                    "label": 0
                },
                {
                    "sent": "Beyond, you know, sort of intuitively being pattern detectors, their actual value aren't really easily converted to a probability of something.",
                    "label": 0
                },
                {
                    "sent": "So I understand your question correctly, not really the most, the most you can interpret, really.",
                    "label": 0
                },
                {
                    "sent": "Is at the output space because it's trying to match real data so that space is interpretable.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to assignments to labels, but beyond that internally it's still kind of an open problem to yield some intuition interpretation of what's going on.",
                    "label": 0
                },
                {
                    "sent": "Alright, Oh yeah, one last question.",
                    "label": 0
                },
                {
                    "sent": "Activate we have seen music.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Why not something else?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is why these activation functions.",
                    "label": 0
                },
                {
                    "sent": "I've taken off and an why aren't there some others one so the key thing in activation function does first is introduced nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "So this is how you get the nonlinear classifier rectified.",
                    "label": 0
                },
                {
                    "sent": "Linear unit is interesting because.",
                    "label": 0
                },
                {
                    "sent": "All it does is convert your neural net into piecewise linear function.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, you would assume that you know linear function is fairly simple function.",
                    "label": 0
                },
                {
                    "sent": "That should be easy to optimize.",
                    "label": 0
                },
                {
                    "sent": "Piecewise dinner, maybe somewhat a little bit harder, but not too much.",
                    "label": 0
                },
                {
                    "sent": "It has fewer saturations an when we look at the backpropagation algorithm, we also see that revenue potentially helps with problems like.",
                    "label": 0
                },
                {
                    "sent": "The gradient of eroding as you're doing backdrop, so that's another thing you want to think about when you think about activation function.",
                    "label": 0
                },
                {
                    "sent": "Is it likely to block gradients and make learning difficult?",
                    "label": 0
                },
                {
                    "sent": "But we'll talk about that in a bit.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's also true that there are a bunch of others exist proposed since then, right?",
                    "label": 0
                },
                {
                    "sent": "Like Max out is this another?",
                    "label": 0
                },
                {
                    "sent": "They just don't perform.",
                    "label": 0
                },
                {
                    "sent": "Viably better than realm.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there are a lot of others that have similar performance and these are kind of each Interestingly different.",
                    "label": 0
                },
                {
                    "sent": "They span the fairly interesting space of activation functions and there are others that are sort of close to those with similar performance.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Move forward.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, in terms of how you would maybe think about implementing a neural network, it's useful to think of it as in terms of a flow graph where you are connecting together a bunch of modules that each perform a small amount of computation.",
                    "label": 0
                },
                {
                    "sent": "So, for instance, you could think of the forward pass in a neural net as having a first module that computes the pre activation and this module will take as input the actual input X, but also the parameters for the first layer, the matrix W one, and the bias vector B.",
                    "label": 0
                },
                {
                    "sent": "And then we have another module that takes in the preactivation, computes the corresponding non linearity and so on, so forth until you reach the last layer an.",
                    "label": 0
                },
                {
                    "sent": "The reason why this is an interesting sort of almost object oriented way of implementing this is that it makes it easy to share code and makes it easy to try various things.",
                    "label": 0
                },
                {
                    "sent": "And it turns out as we'll talk later, it also makes it easy to represent the process of computing gradients with respect to a loss function.",
                    "label": 0
                },
                {
                    "sent": "And we'll discuss that in a few.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that covers just essentially making predictions using, say train neural network and having some understanding as to what kind of functions they can represent.",
                    "label": 0
                },
                {
                    "sent": "Now can we train them from data?",
                    "label": 0
                },
                {
                    "sent": "How do we discover the weights that will allow us to solve some given practical problem?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Close to do that will do.",
                    "label": 0
                },
                {
                    "sent": "Learning an one approach to machine learning is to treat it as an optimization problem.",
                    "label": 1
                },
                {
                    "sent": "Specifically what we will do is that we will define some loss function, which I'm noting L that will compare what is the values provided at the output of my neural network with the actual target.",
                    "label": 0
                },
                {
                    "sent": "So here this would be comparing the softmax outputs with what is the actual class?",
                    "label": 0
                },
                {
                    "sent": "Why that the input X belongs to and sort of taking this sum?",
                    "label": 0
                },
                {
                    "sent": "Actually the average?",
                    "label": 0
                },
                {
                    "sent": "Of all of these losses, comparing the output with the target.",
                    "label": 0
                },
                {
                    "sent": "And instruct, so this is optimizing that is called empirical risk minimization, and the structural version of it is when we add a regularizer.",
                    "label": 1
                },
                {
                    "sent": "So when we take a regularizer, I'm noting gamma that looks at the values of my parameters Theta.",
                    "label": 1
                },
                {
                    "sent": "So data is just all of the weights W1W2 and so on, and all the biases B on B2 and so on, and so love potentially penalizing certain value and encouraging others.",
                    "label": 1
                },
                {
                    "sent": "So here learning will be cast as an optimization.",
                    "label": 0
                },
                {
                    "sent": "Let's find the values of all the weights and all the biases that minimize the average loss on my training set.",
                    "label": 0
                },
                {
                    "sent": "So these XY pairs are from my training set, plus potentially some regularizer.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And I should also say that often this loss function here will not necessarily be exactly the loss function I care about.",
                    "label": 0
                },
                {
                    "sent": "So in classification I would care about.",
                    "label": 0
                },
                {
                    "sent": "Am I classifying in the right class?",
                    "label": 1
                },
                {
                    "sent": "Any given training example?",
                    "label": 0
                },
                {
                    "sent": "But this loss function is not differentiable and will rely on gradients for training.",
                    "label": 1
                },
                {
                    "sent": "So often we use what is usually referred to as a surrogate loss function.",
                    "label": 0
                },
                {
                    "sent": "It's a loss function that's close enough to the thing that actually interests me as the property that is differentiable and I can get gradient to get a signal as to how to change the wins.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this is an optimization problem, so we will solve it when an optimization algorithm and you've seen gradient descent, and I will introduce to you a stochastic version of it in the stochastic gradient descent algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the way it works is that you see the pseudocode here.",
                    "label": 0
                },
                {
                    "sent": "So let's go through all the steps.",
                    "label": 0
                },
                {
                    "sent": "We start by initializing our parameters in some way, so I'll discuss initializing session in a bit.",
                    "label": 0
                },
                {
                    "sent": "But essentially that means assigning a first value to all of my weights.",
                    "label": 0
                },
                {
                    "sent": "And all of my biases in my neural net.",
                    "label": 0
                },
                {
                    "sent": "And then for a certain number of iterations or updates, I will go through of epochs.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I will go through all my training examples.",
                    "label": 0
                },
                {
                    "sent": "My pairs X&Y in my training set.",
                    "label": 0
                },
                {
                    "sent": "And now look at what is the direction to make a step in the right direction to minimize my loss.",
                    "label": 0
                },
                {
                    "sent": "Four that example, that is, I'm going to look at the negative gradient.",
                    "label": 0
                },
                {
                    "sent": "This is nabla here of the loss function for my pair XY.",
                    "label": 0
                },
                {
                    "sent": "Given my parameter, This is why did I sort of as an index.",
                    "label": 0
                },
                {
                    "sent": "That means the gradient of this with respect to fed up an I.",
                    "label": 0
                },
                {
                    "sent": "So essentially per example.",
                    "label": 0
                },
                {
                    "sent": "When I want to optimize is the last plus.",
                    "label": 0
                },
                {
                    "sent": "The regularizers also need the gradient of the regularizer Omega with respect to my parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so I go in the opposite direction because I'm minimizing so the gradient gives me away of it, gives me an ascent direction, so I'll go the opposite direction to descend and I'll take a step of quota code size.",
                    "label": 0
                },
                {
                    "sent": "AA is a step size or often referred to as a learning rate, so I'll just.",
                    "label": 0
                },
                {
                    "sent": "This is just a scalar multiplying my vector of direction.",
                    "label": 0
                },
                {
                    "sent": "For my update and I add this to my current value of the parameters and it gives me the new value of my parameters and so I do this for all the training examples in my training set and I do this for certain number of so called epochs.",
                    "label": 0
                },
                {
                    "sent": "OK, so that stochastic gradient descent can be applied to many problems where you have to minimize some average of a bunch of loss terms, and so here to get the complete algorithm we need to specify what kind of loss function will want to consider when we want to minimize.",
                    "label": 0
                },
                {
                    "sent": "We need a procedure for computing this gradient here, so the gradient of the loss with respect to all my parameters.",
                    "label": 0
                },
                {
                    "sent": "I need a procedure to compute that we want to compute that efficiently.",
                    "label": 0
                },
                {
                    "sent": "Can efficient algorithm need to specify your regularizer if I want one and I need to specify specify a way of initializing my weights so the next few slides would go through each of these steps, yes?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the Gray, the regular gradient descent.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Them would actually look at what is the gradient of this full expression here, so it would be the average gradient over all the training examples plus the gradient of the regularizer.",
                    "label": 0
                },
                {
                    "sent": "So that would be great in the sent.",
                    "label": 0
                },
                {
                    "sent": "The reason why it's stochastic is that instead of taking the full average where it's actually going to subsample that average, and here we are at the extreme case, we're taking just a single example to get an estimate of the gradient of this full average, so that's why it's stochastic, and there's sort of.",
                    "label": 0
                },
                {
                    "sent": "There's one extremely stochastic gradient descent with a single example per update an you can do something a bit better, which is mini batch gradient descent, where you would actually take a small set of 64 examples and compute the average grade and 4060 for example, even though I have maybe 10s of thousands of examples, but stochastically comes from the fact that I need to pick one amongst all of these examples in the average an you sort of do it effectively stochastically by.",
                    "label": 0
                },
                {
                    "sent": "You can do this by drawing with replacement.",
                    "label": 0
                },
                {
                    "sent": "Or you can do it by just cycling over the examples.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I. I don't know if that's an accepted terminology.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I believe in that park would be over all the examples and then in iteration would be 1 update.",
                    "label": 0
                },
                {
                    "sent": "I think of an optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "This might contradict other peoples notation and maybe mine is wrong, but that's the one I will be using and it's my presentation, so I get to call it.",
                    "label": 0
                },
                {
                    "sent": "Greece.",
                    "label": 0
                },
                {
                    "sent": "Different areas, no.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a good question.",
                    "label": 0
                },
                {
                    "sent": "So the question is, should we initialize every time we do an Xbox?",
                    "label": 0
                },
                {
                    "sent": "So actually no.",
                    "label": 0
                },
                {
                    "sent": "So every time we do one epoc most likely will not have finished training the neural network.",
                    "label": 0
                },
                {
                    "sent": "An actually in practice and all that we need to see in an example multiple times before it actually meaningfully learned to predict its target given its input.",
                    "label": 0
                },
                {
                    "sent": "So re initializing multiple times.",
                    "label": 0
                },
                {
                    "sent": "This will be an other outer loop.",
                    "label": 0
                },
                {
                    "sent": "Out of this, that is, you would typically run this algorithm multiple times, often in parallel on different machines, where each will initialize differently with a different random seed, for instance.",
                    "label": 0
                },
                {
                    "sent": "That's a great question.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "One thing I think.",
                    "label": 0
                },
                {
                    "sent": "When do we stop?",
                    "label": 0
                },
                {
                    "sent": "Yeah, we stop when N is reached here.",
                    "label": 0
                },
                {
                    "sent": "So now we'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "That's a good point.",
                    "label": 0
                },
                {
                    "sent": "What is N right?",
                    "label": 0
                },
                {
                    "sent": "That's that's a hyperparameter here.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "No, that's right.",
                    "label": 0
                },
                {
                    "sent": "That's why.",
                    "label": 0
                },
                {
                    "sent": "Is like I.",
                    "label": 0
                },
                {
                    "sent": "This is not exactly the same thing, yes, so I'll talk about how we said that M, But that's a good point, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Wait, so what's the question?",
                    "label": 0
                },
                {
                    "sent": "What is the difference between doing an update based on a single example versus a batch or mini batch?",
                    "label": 0
                },
                {
                    "sent": "So effectively you can think of a single example as a batch of size 1.",
                    "label": 0
                },
                {
                    "sent": "An in that case, what you can expect is there's going to be more variance in the estimate, like that number is going to vary a lot around what would have been the number.",
                    "label": 0
                },
                {
                    "sent": "If you use all of the training examples.",
                    "label": 0
                },
                {
                    "sent": "If you have a mini batch that's not one, but of size 64, well, there's going to be a little bit less variance because you're averaging over 64 example.",
                    "label": 0
                },
                {
                    "sent": "And So what this will change is how much variance there is in the estimate of the gradient.",
                    "label": 0
                },
                {
                    "sent": "Of the total average loss.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that the less variance you have, the more accurate this descent direction will be an the more valuable that step should be towards minimizing your average loss.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So can you say again?",
                    "label": 0
                },
                {
                    "sent": "Yeah OK, what's the relation between cyber Batch and I guess performance or I'll talk about this in a few slides, but we'll discuss that for sure.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Right, so yeah, the question is should we shuffle?",
                    "label": 0
                },
                {
                    "sent": "So let's say when we're doing this for loop here.",
                    "label": 0
                },
                {
                    "sent": "Overall training example, should we shuffle the example every time?",
                    "label": 0
                },
                {
                    "sent": "Also, here I'm sort of not being very specific, but you can imagine that even cycling over examples But actually drawing them independently.",
                    "label": 0
                },
                {
                    "sent": "These correspond to different procedures which I believe have different properties in terms of how quickly they converge.",
                    "label": 0
                },
                {
                    "sent": "I don't know these properties very well.",
                    "label": 0
                },
                {
                    "sent": "I'm sure our friend Simone the back knows a lot, so if you want to.",
                    "label": 0
                },
                {
                    "sent": "No more about this.",
                    "label": 0
                },
                {
                    "sent": "As to that guy.",
                    "label": 0
                },
                {
                    "sent": "They are different procedures.",
                    "label": 0
                },
                {
                    "sent": "They yield different.",
                    "label": 0
                },
                {
                    "sent": "They have different properties for sure an.",
                    "label": 0
                },
                {
                    "sent": "I believe that most of the time people use just cycling because it's kind of convenient.",
                    "label": 0
                },
                {
                    "sent": "You don't have to deal with the sampling and whatnot.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "If there.",
                    "label": 0
                },
                {
                    "sent": "Oh but the question is, is there a rule of thumb for choosing the mini batch size so?",
                    "label": 0
                },
                {
                    "sent": "Not really.",
                    "label": 0
                },
                {
                    "sent": "Usually we take power of two because computers like powers of two.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then it's different if you have a lot of compute power.",
                    "label": 0
                },
                {
                    "sent": "Legitimately, the batch size will have an impact on the generalization performance will talk about why that is a little bit later, but maybe mostly what you care about is just running it for enough iterations for it to work at all, and then time will be the biggest factor.",
                    "label": 0
                },
                {
                    "sent": "And then there's a compromise between, essentially in terms of implementations on the computer.",
                    "label": 0
                },
                {
                    "sent": "There is sort of a tradeoff in terms of computation in the different number of batches.",
                    "label": 0
                },
                {
                    "sent": "So in short, if you sort of tune what the batch sizes, you might go through a full data set in the variable amount of time.",
                    "label": 0
                },
                {
                    "sent": "And then you would often sort of optimize for speed for different problems.",
                    "label": 0
                },
                {
                    "sent": "This might mean different mini batch size.",
                    "label": 0
                },
                {
                    "sent": "So beyond the power of two and then people use often 3264 or 128.",
                    "label": 0
                },
                {
                    "sent": "But even then very recently some people have shown that if you have multiple machines you can paralyze the computation of all gradients, which means effectively you can do batch sizes of 1000, so that kind of suggests there isn't a rule of thumb or it's sort of changing as you know, are softwares for parallel.",
                    "label": 0
                },
                {
                    "sent": "Distributed computation change.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question of whether actually having noise in the gradient might be a good thing.",
                    "label": 0
                },
                {
                    "sent": "And that's definitely true.",
                    "label": 0
                },
                {
                    "sent": "I'll postpone that discussion to later, but but it is true and some people have argued actually, that it's quite important to reach good generalization performance, and I'll.",
                    "label": 0
                },
                {
                    "sent": "Will have a discussion about, you know, trying to give you some intuition as to why that is, but that's a good point.",
                    "label": 0
                },
                {
                    "sent": "This is why the mini batch size really is is a hyperparameter of the learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's not just a matter of how quickly it runs, it's also a matter of it will impact the solution you'll find in terms of if you have, you know, as much computation as you wanted, it will impact the quality of the solution you will find for sure.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Power.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So essentially, that's the power of two is essentially because for practical reasons you it will paralyze better on the GPU and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "So in that sense it doesn't really matter, it could be 100, but 128 is going to be going to have nice parallelization properties on the GPU, and so on.",
                    "label": 0
                },
                {
                    "sent": "So that's really the reason.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Let's move forward.",
                    "label": 0
                },
                {
                    "sent": "So OK, so first thing I said we need to pick four things.",
                    "label": 0
                },
                {
                    "sent": "The loss function, a way to compute gradients, regularizer and how to initialize.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the last function, I'll concentrate on classification.",
                    "label": 0
                },
                {
                    "sent": "So for instance, think my input is an image of an handwritten digit, like from this data set it can be 012 and so on, up to 9.",
                    "label": 0
                },
                {
                    "sent": "So there are 10 classes, so in this case the loss function for classification could be I want to maximize the probability assigned to the correct class Y for some input X.",
                    "label": 0
                },
                {
                    "sent": "And for various reasons, including numerical stability, we might as well say maximize the lug probability just automatically gives you nicer gradients.",
                    "label": 0
                },
                {
                    "sent": "And because I want to loss, I want to think about minimizing the loss.",
                    "label": 0
                },
                {
                    "sent": "Instead, I'll just use the negative log of the probability of the target Y.",
                    "label": 0
                },
                {
                    "sent": "According to my neural net.",
                    "label": 0
                },
                {
                    "sent": "And what is that?",
                    "label": 0
                },
                {
                    "sent": "Well, that's taking the.",
                    "label": 0
                },
                {
                    "sent": "So if Y here is just a number from zero to or depending if you count from zero, one from zero to the number of classes minus one.",
                    "label": 0
                },
                {
                    "sent": "Well, I'll just take my output layer and I look at the component corresponding to my class and I'll penalize minus the log of that.",
                    "label": 0
                },
                {
                    "sent": "OK, so in statistical terms that's called doing maximum likelihood and maximizing the likelihood that the probability assigned by our current parameters to the correct class.",
                    "label": 0
                },
                {
                    "sent": "For this example.",
                    "label": 0
                },
                {
                    "sent": "OK, so another way of writing it is in this way.",
                    "label": 0
                },
                {
                    "sent": "So if you think as the target Y if you think of it as encoding it into one hot vector.",
                    "label": 0
                },
                {
                    "sent": "This is kind of like looking at the cross entropy between the one hot vector and the full vector of probabilities.",
                    "label": 0
                },
                {
                    "sent": "OK, so sometimes we'll refer to this loss and then a lot of deep learning packages.",
                    "label": 0
                },
                {
                    "sent": "It will be referred to as the multinomial cross entropy because it compares a multinomial which essentially A1 hot vector with another multinomial, which is the output of your neural net.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a lot that will consider in this talk and that a lot of people use.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we need an algorithm for computing the gradients of my loss with respect to my parameters, and that's the backpropagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "As we've established everyone here pretty much knows it, so I'll go quickly.",
                    "label": 0
                },
                {
                    "sent": "So essentially the procedure, once we've done our forward path which computes all the hidden layer in the output layer, will start from the variant and then back propagate in the inverse direction all the way from the top layer to the bottom layer.",
                    "label": 0
                },
                {
                    "sent": "Effectively with backdrop is doing is essentially exploiting this compositional property of the derivation chain rule.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we first compute what is the gradient of my loss and the negative log probability of the correct class with respect to my pre activation and my output layer will do the output layer but the pre activation here for simplicity and it has a very nice gradient.",
                    "label": 0
                },
                {
                    "sent": "It's essentially looking at the difference between what is the one hot vector of my class.",
                    "label": 0
                },
                {
                    "sent": "So if Y, that's my notation for the vector that puts everything to zero except the component, why?",
                    "label": 0
                },
                {
                    "sent": "Which is set to one and it takes the difference between this and the current output.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you think of this, this is a bunch of zeros and a single one.",
                    "label": 0
                },
                {
                    "sent": "That is, all numbers between zero and one, so all the components are zero, that all the classes that don't correspond to the real target will be subtracted by positive numbers, so that component before the minus here is going to be negative an except for the component that set to 1.",
                    "label": 0
                },
                {
                    "sent": "It's going to be subtracting the number that is between zero and one strictly so that other component is going to be necessarily positive.",
                    "label": 0
                },
                {
                    "sent": "OK, So what this term is effectively saying is increase the probability or the pre activation of the correct class and decrease the probability of all other classes.",
                    "label": 0
                },
                {
                    "sent": "Ann if you already assign zero probabilities that class, you're essentially not going to touch that unit.",
                    "label": 0
                },
                {
                    "sent": "But if you assign high probability when it wasn't the correct class, you're going to have a stronger gradient pushing that preactivation down.",
                    "label": 0
                },
                {
                    "sent": "That's kind of the intuition for this term here.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to go from the top layer all the way to the first one.",
                    "label": 0
                },
                {
                    "sent": "We once we have their pre activation of the layer above, we can use that pre activation here to get the gradient with respect to the weight matrix W. It's going to be the dot product.",
                    "label": 0
                },
                {
                    "sent": "Actually the outer product between this vector here which can think of as a column vector of the gradient of the loss with respect to their activation.",
                    "label": 0
                },
                {
                    "sent": "The layer above times the vector of.",
                    "label": 0
                },
                {
                    "sent": "Activations of the layer right below and I'm taking the transpose here, so that's a row vector, so this vector times this vector.",
                    "label": 0
                },
                {
                    "sent": "The outer product will give you a matrix of the same size as this W just got a good sanity check to know that this procedure makes sense.",
                    "label": 0
                },
                {
                    "sent": "And then forward the biases of that layer.",
                    "label": 0
                },
                {
                    "sent": "Actually, the gradient is just going to be what is the gradient of the loss function with respect to the pre activation of that layer?",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to propagate the grades downwards towards the layer right below, so I'm going to take what is the gradient of my loss with respect to the activation in the layer above and multiply that by the transpose of my weight matrix for that layer, and that actually turns out to be the gradient of the loss with respect to the activation of the layer below very simple procedure.",
                    "label": 0
                },
                {
                    "sent": "And then to get the gradient of the loss with respect to the pre activation at the layer below all I need to do is multiply by.",
                    "label": 0
                },
                {
                    "sent": "What is the durative of my activation function for each neuron?",
                    "label": 0
                },
                {
                    "sent": "OK, so we're doing this elementwise multiplication with the partial narrative of the activation function for each neuron, and multiplying that element by element with the gradient computed here of the activation.",
                    "label": 0
                },
                {
                    "sent": "So once I'm here, I have the gradient of the loss.",
                    "label": 0
                },
                {
                    "sent": "With respect to the activation of the layer below so I can go back here and compute the gradient of the weights for the layer below and so on.",
                    "label": 0
                },
                {
                    "sent": "So I'm going up towards down the first hidden layer and that's the backpropagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "So I'm showing you this here mostly for two reasons.",
                    "label": 0
                },
                {
                    "sent": "The first illustrate that it's really just a top down process that has essentially the same complexity as my bottom up process where I'm doing the form fast.",
                    "label": 0
                },
                {
                    "sent": "And it's fairly simple.",
                    "label": 0
                },
                {
                    "sent": "It's mostly linear operations, an multiplications, and also I ask you to notice this term here, which is that the gradient of the activation is going to be effectively gated by the activation function partial narrative.",
                    "label": 0
                },
                {
                    "sent": "So if any of these derivatives are zero, it's going to block the gradient, and it's not going to pass through the neurons below.",
                    "label": 0
                },
                {
                    "sent": "OK, an it's this term in not only disarmed, this term can also have some vanishing gradient effect, but this term.",
                    "label": 0
                },
                {
                    "sent": "Particular, often referred to as one being responsible for problems with vanishing gradient.",
                    "label": 0
                },
                {
                    "sent": "Because effectively if you have saturations of the activation function, some of the grain is going to be multiplied by zero, they're going to be essentially set to 0 and no gradients will pass through the layers below, and they won't be able to learn because they won't get a signal.",
                    "label": 0
                },
                {
                    "sent": "They won't get a gradient.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we look at what some of those partial derivatives look like for, say, the sigmoid activation function, it's actually interesting need just the sigmoid itself times 1 minus the sigmoid itself.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can sort of write it as a function of the actual sigmoid, which kind of makes sense.",
                    "label": 0
                },
                {
                    "sent": "So that means when this is one or when this is zero, either one of these terms is going to be 0, so the product is going to be 0, and indeed the slope here when the sigmoid is close to one or the slope.",
                    "label": 0
                },
                {
                    "sent": "Here when it's close to 0.",
                    "label": 0
                },
                {
                    "sent": "Is effectively zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so the intuition from this graph matches the equation.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 eight should get a same kind of thing, except that now.",
                    "label": 0
                },
                {
                    "sent": "So the 10 inches between minus one and one and the partial it would be 1 minus the tenant squared.",
                    "label": 0
                },
                {
                    "sent": "OK, so if it's close to minus one, this term will be close to one.",
                    "label": 0
                },
                {
                    "sent": "I'm going to get a partial limited that's close to 0.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ford erelu.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, it's super simple.",
                    "label": 0
                },
                {
                    "sent": "It's the indicator function of whether the activate the pre activation is larger than zero.",
                    "label": 0
                },
                {
                    "sent": "If so, it's one, otherwise it's zero.",
                    "label": 0
                },
                {
                    "sent": "So it's really explicitly agate.",
                    "label": 0
                },
                {
                    "sent": "It's passing gradients through it, or it's not passing gradients through OK, and it's passing gradients.",
                    "label": 0
                },
                {
                    "sent": "It's not changing the gradient, it's just letting pass by multiplying it by 1.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is where we can intuitively think that using relatives will have less problems with propagating gradients.",
                    "label": 0
                },
                {
                    "sent": "Because yes, sometimes it will shove things to 0, but otherwise, even if there's large values of the Relu, unlike with the sigmoid, you don't get a partial.",
                    "label": 0
                },
                {
                    "sent": "If that's zero, the grains will pass as long as you're in the positive slope of revenue.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What happens at 00?",
                    "label": 0
                },
                {
                    "sent": "You mean this point?",
                    "label": 0
                },
                {
                    "sent": "Here we are back propagating a subgradient.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Five year 'cause similar is going to Paris means that's not going to be exact definition of what a subgradient is, but essentially we ignore the fact that here there isn't.",
                    "label": 0
                },
                {
                    "sent": "The dirt is not the greatness that really defined, but we just use zero and in practice it works.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Is that semi satisfying symbol?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, and now in terms of so you could for any neural network sort of compute all these directives and implement them.",
                    "label": 0
                },
                {
                    "sent": "Turns out there's an effectively automatic way of getting this for any new neural network, as long as you use this sort of flow graph inspired implementation and the modules that you use in your flow graph, as long as they allow for not just computing the forward pass which is taking their input and producing outputs, but it can also take what is the gradient.",
                    "label": 0
                },
                {
                    "sent": "Of some loss which respected themselves and then propagate what is then the gradient of that same loss with respect to its inputs?",
                    "label": 0
                },
                {
                    "sent": "OK, and that's effectively just taking that gradient and then adding the term in the chain rule that corresponds to their own gradient.",
                    "label": 0
                },
                {
                    "sent": "Their own jacobian.",
                    "label": 0
                },
                {
                    "sent": "OK, so then in this case you can have these.",
                    "label": 0
                },
                {
                    "sent": "You can sort of mix and match different modules as long as they both implement the forward pass in the backward pass and then back up is just.",
                    "label": 0
                },
                {
                    "sent": "Doing first the first pass like this and then starting at the loss for saying the gradient of the loss with respect to itself to be one and then calling this back propagation function on each module to propagate the gradient to get respect to FX, which will then compute the gradient for the pre activation function, which can then compute the grain respect to all of its inputs.",
                    "label": 0
                },
                {
                    "sent": "They wait the biases and the activation function and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Torch is an example where this was used pretty explicitly.",
                    "label": 0
                },
                {
                    "sent": "You would have a bunch of different modules that would be implemented in this way.",
                    "label": 0
                },
                {
                    "sent": "They would have F prop and a B prop function essentially as the part of the module object and the forward pass you would call them in order in the backward pass we would call them in reverse order.",
                    "label": 0
                },
                {
                    "sent": "Now we have even more sophisticated approaches that will take the graph and augment it with operations that correspond to going in this inverse order.",
                    "label": 0
                },
                {
                    "sent": "So Theano is more less power need that approach.",
                    "label": 0
                },
                {
                    "sent": "Tensor flow uses that as well, and then there are other approaches like sorry, torch, autograde.",
                    "label": 0
                },
                {
                    "sent": "And then there's now Pytorch also uses that they used to be torch autograde also where you have more of a tape based approach which I suspect you will learn about this week from presumably the Pytorch tutorial for instance.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's the backdrop algorithm we mentioned that we might want to use regularizer one regularizer, that a lot of people use is the L2 regularization, which essentially penalizes the sum of the squared of all parameters.",
                    "label": 1
                },
                {
                    "sent": "You can do this for the biases, but usually we don't do it.",
                    "label": 0
                },
                {
                    "sent": "We don't regularize the biases, only the weights, and effectively.",
                    "label": 1
                },
                {
                    "sent": "What this does is encourage weights that aren't too far from zero, and the intuition for why that might make sense is that.",
                    "label": 0
                },
                {
                    "sent": "If you have weights that are close to 0, then your function initially is more or less constant, so it's pretty smooth around the input space, so you're essentially saying I want a function that's as smooth as possible, But fits the training data.",
                    "label": 0
                },
                {
                    "sent": "So this is on time calls also weight decay, which is another term for this, and I believe I've seen this morning doesn't interpretation as having a Gaussian prior over where the overweights.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally the initialization.",
                    "label": 0
                },
                {
                    "sent": "So for the biases it's usually pretty simple.",
                    "label": 0
                },
                {
                    "sent": "Usually it's 20.",
                    "label": 0
                },
                {
                    "sent": "That's not true for the STM.",
                    "label": 0
                },
                {
                    "sent": "Forget gate.",
                    "label": 0
                },
                {
                    "sent": "For those who knows about, we know about LCMS and you'll learn more about that later this week, but usually the biases are initialized to 0.",
                    "label": 0
                },
                {
                    "sent": "Then for the weights, now we can't initialize them all to zero, especially if you have a 10 H activation.",
                    "label": 0
                },
                {
                    "sent": "If you think about it and it's not about exercise to do, you can see that effectively what you'll get is a gradient on all weights and biases.",
                    "label": 0
                },
                {
                    "sent": "That's going to be exactly 0, so all the weights are not going to change in gradients of zero, and so there's no direction in which you move the parameters.",
                    "label": 0
                },
                {
                    "sent": "You also can't initialize all the weights to exactly the same non 0 value because then all the units are at initialization doing exactly the same thing and can also show that as you train them they will continue doing exactly the same thing.",
                    "label": 0
                },
                {
                    "sent": "They will all have exactly the same input weights and so will be more or less like having a single neuron at each layer even though we have many of those.",
                    "label": 0
                },
                {
                    "sent": "So you need to break that symmetry and so typically we initialize.",
                    "label": 0
                },
                {
                    "sent": "Informally, the weights to be somewhat random but close to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, an one rule that is often used is this glowing banjo initialization.",
                    "label": 0
                },
                {
                    "sent": "So I think many frameworks will now read the global initialization, so it's this case here, so which is essentially uniform between some lower and upper bound B, an with that expression here, which seems kind of strange, but if you look at the duration for it, the idea is that at initialization within initialization like this, you're going to have.",
                    "label": 0
                },
                {
                    "sent": "A four 10 H activation function, you're going to have more less equal variance of the activations as you do forward propagation.",
                    "label": 0
                },
                {
                    "sent": "So if you have equal variance, that means that the information is propagating well.",
                    "label": 0
                },
                {
                    "sent": "There's no vanishing of the activation, and similarly an initialization the gradient that's being back propagated after will also have more or less constant variance, which also suggests that you don't have this vanishing gradient problem.",
                    "label": 0
                },
                {
                    "sent": "You're going to get the you know some Watt equivalent in terms of magnitude gradient.",
                    "label": 0
                },
                {
                    "sent": "Or learning signal at all layers at initialization, yes.",
                    "label": 0
                },
                {
                    "sent": "Space as is after the first operational training.",
                    "label": 0
                },
                {
                    "sent": "So the question is whether this behavior of nice flow of information in the forward pass and backward path will maintain.",
                    "label": 0
                },
                {
                    "sent": "Just because we initialize this this way we don't know so units could saturate and then suddenly you have weak learning signal for sure.",
                    "label": 0
                },
                {
                    "sent": "So that doesn't solve the whole thing, but things you sort of addressed the initialization in terms of flow of information.",
                    "label": 0
                },
                {
                    "sent": "That's a good point.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "We can have like other sort of cross entropies like JS or KL Divergent.",
                    "label": 0
                },
                {
                    "sent": "Beside the cost, right?",
                    "label": 0
                },
                {
                    "sent": "So we can afford to make the problem distribution as a loss function, but we can discuss contribution, right?",
                    "label": 0
                },
                {
                    "sent": "So I think.",
                    "label": 0
                },
                {
                    "sent": "I understand your question is essentially at a higher level, meaning we could imagine other types of loss functions for how we tried to fit our output to the target, and there are definitely other ones which have different properties.",
                    "label": 0
                },
                {
                    "sent": "If you're doing maximum margin which is 1 approach for fitting supervised model, you would get a different loss function here.",
                    "label": 0
                },
                {
                    "sent": "Then it's possible that in certain situations it works better.",
                    "label": 0
                },
                {
                    "sent": "You could in fact also try to just instead of minimizing the negative log probability, you can minimize the negative probability, and some people have argued that that's a better thing to do, and there are interesting things to be said like as you vary the space of loss function, this one is just the most commonly used, but sort of more complicated discussion to be had.",
                    "label": 0
                },
                {
                    "sent": "But definitely you shouldn't take this as meaning that this is the best cost function.",
                    "label": 0
                },
                {
                    "sent": "It's just the one that's used the most right now.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "We single.",
                    "label": 0
                },
                {
                    "sent": "Outlook.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is, could we have multiple outputs and multiple loss functions?",
                    "label": 0
                },
                {
                    "sent": "We could definitely do that so you could have a single output an optimize some weighted average of a bunch of loss functions if you wanted to.",
                    "label": 0
                },
                {
                    "sent": "That would sort of corresponds to shaping in some more sophisticated way with the loss function.",
                    "label": 0
                },
                {
                    "sent": "Looks like there are certain procedures proposed by some that look a little bit like this an there's perhaps the other thing that you're trying to say, which you might want to predict.",
                    "label": 0
                },
                {
                    "sent": "Multiple targets which.",
                    "label": 0
                },
                {
                    "sent": "Each have their own loss function that's a form of multitask learning, which I'll discuss a little bit about later on.",
                    "label": 0
                },
                {
                    "sent": "But that's also it's just going outside of the simpler framework I'm looking at here, which is single classification, single label case, yeah?",
                    "label": 0
                },
                {
                    "sent": "Many different types of Maps so.",
                    "label": 0
                },
                {
                    "sent": "Contacts are you mean the loss function or initialization?",
                    "label": 0
                },
                {
                    "sent": "Is it limited to fully connected networks?",
                    "label": 0
                },
                {
                    "sent": "It was designed for fully connected networks with 10 H activation functions.",
                    "label": 0
                },
                {
                    "sent": "People now often use it for any situation, but it might.",
                    "label": 0
                },
                {
                    "sent": "You know the theory doesn't tell you that it will be appropriate for that.",
                    "label": 0
                },
                {
                    "sent": "Yes, here we can be very naturally extended.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you need to adapt.",
                    "label": 0
                },
                {
                    "sent": "You get a different initialization.",
                    "label": 0
                },
                {
                    "sent": "Scaling factor.",
                    "label": 0
                },
                {
                    "sent": "So for different activation function you would get a different.",
                    "label": 0
                },
                {
                    "sent": "You know, by this approach suggested initialization.",
                    "label": 0
                },
                {
                    "sent": "Which I don't know where they are.",
                    "label": 0
                },
                {
                    "sent": "They exist, but it's not in the original paper.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you have the reference for as someone derived what they should be for other activation functions.",
                    "label": 0
                },
                {
                    "sent": "OK. Somewhere on the web?",
                    "label": 0
                },
                {
                    "sent": "But it's doable.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we'll talk about that in a few minutes.",
                    "label": 0
                },
                {
                    "sent": "They are questions.",
                    "label": 0
                },
                {
                    "sent": "OK, this one and this one.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I guess the question is, I've talked mostly about vanishing gradient, but you might get exploding gradient.",
                    "label": 0
                },
                {
                    "sent": "You might get exploding gradient due to this far OK due to the fact that you always multiplying by this.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matrix downwards an let's for simplicity, assume that this term is all once.",
                    "label": 0
                },
                {
                    "sent": "If this matrix is actually really large, then you might actually get an increase in the gradient propagating.",
                    "label": 0
                },
                {
                    "sent": "Then you need to be kind of careful about.",
                    "label": 0
                },
                {
                    "sent": "Effectively, what are the size of the entries in there?",
                    "label": 0
                },
                {
                    "sent": "So looking essentially at?",
                    "label": 0
                },
                {
                    "sent": "What are the Indian values of those matrices here?",
                    "label": 0
                },
                {
                    "sent": "An regularization might help.",
                    "label": 0
                },
                {
                    "sent": "I think this is an issue that comes much more in recurrent neural networks and I believe that where someone is going to address that is that you, yeah, yeah yeah, we're going to talk about that, but you do need to be careful about this.",
                    "label": 0
                },
                {
                    "sent": "The weights become too large then the gradient can explode, can increase in magnitude.",
                    "label": 0
                },
                {
                    "sent": "That can also make learning more difficult, so that's a very good point.",
                    "label": 0
                },
                {
                    "sent": "Batch normalization yes, and batch normalization I think would also help with that, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the question is, would it make sense to sort of have multiple different activation functions at various places in the neural network?",
                    "label": 0
                },
                {
                    "sent": "I do not know of a convincing demonstration that this really significantly helps you know consistent way.",
                    "label": 0
                },
                {
                    "sent": "Part of it is that there are certain activations that you can model pretty well by another layer combining other activations activation functions together.",
                    "label": 0
                },
                {
                    "sent": "So a second layer with Relu units could essentially get a.",
                    "label": 0
                },
                {
                    "sent": "Hard version of the sigmoid in one layer, and so I think in part because of that there doesn't seem to be much benefit, or at least I'm not aware of anyone showing that there's a lot of benefit and really tuning the activation functions at the level of each individual units.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's an algorithm that needs to be discovered that does that effectively, but as far as I know that doesn't really exist.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Moving forward.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shoot I worked on this animation, so let's look at it again.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, so OK, so that's all the components we need for training one neural network.",
                    "label": 0
                },
                {
                    "sent": "Assuming we determine what's the learning rate Alpha, what is the number of epochs?",
                    "label": 0
                },
                {
                    "sent": "What is the number of units in the various hidden layers?",
                    "label": 0
                },
                {
                    "sent": "How many hidden errors and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "But now we need to.",
                    "label": 0
                },
                {
                    "sent": "Also we need a procedure for determining those values.",
                    "label": 0
                },
                {
                    "sent": "Those are considered as hyperparameters, so hyperparameters are essentially parameters that aren't trained by gradient descent.",
                    "label": 0
                },
                {
                    "sent": "They need to be.",
                    "label": 0
                },
                {
                    "sent": "Provided to a procedure like gradient descent.",
                    "label": 0
                },
                {
                    "sent": "So one approach that people have used for a long time is to perform a form of grid search.",
                    "label": 1
                },
                {
                    "sent": "So you would just enumerate all of the values, all of the different hyperparameters, an list out a set of values for each of those.",
                    "label": 1
                },
                {
                    "sent": "So the learning rate, maybe you say OK, I want to try 0.1 zero .01 for the number of hidden units.",
                    "label": 0
                },
                {
                    "sent": "I want to try 100, five, 100,000, so let's just do two hyperparameters here.",
                    "label": 1
                },
                {
                    "sent": "So in grid search you try all combination of any of these values, so that's 2 * 3.",
                    "label": 0
                },
                {
                    "sent": "So six different jobs will be running, and then you would for each of these experiments you would look at what is the performance of the resulting train neural network on the validation set.",
                    "label": 0
                },
                {
                    "sent": "So the training set validation set to get a sense of how well does that network performance new data.",
                    "label": 0
                },
                {
                    "sent": "And then we just pick the neural network and thus the hyperparameters that work best on that validation set.",
                    "label": 0
                },
                {
                    "sent": "And that's the network you would evaluate.",
                    "label": 0
                },
                {
                    "sent": "Finally, on the test set to report a generalization performance in the paper or so on.",
                    "label": 1
                },
                {
                    "sent": "Now the problem with this is that if you have a lot of hyperparameters, another values we want to try that yields an exponentially growing number of configurations to try.",
                    "label": 0
                },
                {
                    "sent": "So another approach that actually is much more convenient is random search where against you list out the hyperparameters for each hyperparameter.",
                    "label": 0
                },
                {
                    "sent": "You either specify a discrete lists of values you want to try, or you can describe if it's like the learning rate may be described, a distribution over values that you'd like to try, maybe it's uniform.",
                    "label": 1
                },
                {
                    "sent": "But with the log distribution from our 0.0012 zero point 1 for instance.",
                    "label": 0
                },
                {
                    "sent": "And then you can separately specify how many total configurations I'm willing to try, so maybe that's 50.",
                    "label": 0
                },
                {
                    "sent": "And then what you do is just for each experiment you uniformly and stochastically choose for each hyperparameter.",
                    "label": 0
                },
                {
                    "sent": "What value going to try separately for each job.",
                    "label": 0
                },
                {
                    "sent": "So the first job might be like if I go back to my example 0.1 or 0.01 and then 100 or 500 or 1000 hidden units, I maybe flip a coin at this side.",
                    "label": 0
                },
                {
                    "sent": "OK, my first job is going to try 0.1 for the learning rate.",
                    "label": 0
                },
                {
                    "sent": "An flip out three sided coin for the number of hidden units and maybe that's 500.",
                    "label": 0
                },
                {
                    "sent": "OK, that's one job.",
                    "label": 1
                },
                {
                    "sent": "And then I repeat this and that's how I launch my jobs in my experiments.",
                    "label": 0
                },
                {
                    "sent": "Ann, what's nice is that it decouples the number of total configurations you try from specifying the range of values you actually want to try out.",
                    "label": 0
                },
                {
                    "sent": "The reasons why it's much more efficient in this way.",
                    "label": 0
                },
                {
                    "sent": "So imagine for some reason there's one value of one of the hyper parameters that if you pick this value no matter what are the other values.",
                    "label": 0
                },
                {
                    "sent": "For the other parameters you pick at, the job is going to crash.",
                    "label": 0
                },
                {
                    "sent": "Your maybe the learning rate is too high, and then any configuration of number of hidden units.",
                    "label": 0
                },
                {
                    "sent": "They're all going to diverge essentially well in grid search.",
                    "label": 0
                },
                {
                    "sent": "That means you're essentially wasting a lot of experiments.",
                    "label": 0
                },
                {
                    "sent": "All of those that is using that specific value, whereas in random search, especially if you're considering a large interval of values, then you can kind of hope that we can sort of determine how many experiments with that specific value.",
                    "label": 0
                },
                {
                    "sent": "Am I going to try out and maybe favor values that are less likely to crash, for instance?",
                    "label": 0
                },
                {
                    "sent": "Also, if you have one experiment in your grid that then wasn't executed or something, this is kind of annoying.",
                    "label": 0
                },
                {
                    "sent": "You have a hole in your grid, whereas here it's really all you need to specify is the number experiments you ran, and that's it.",
                    "label": 0
                },
                {
                    "sent": "So I hand yes.",
                    "label": 0
                },
                {
                    "sent": "Say what?",
                    "label": 0
                },
                {
                    "sent": "Generalize in what way?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "I'm not exactly what you mean by generalization.",
                    "label": 0
                },
                {
                    "sent": "One thing it doesn't do is it doesn't learn from its mistakes, right?",
                    "label": 1
                },
                {
                    "sent": "It's essentially not going to learn that you know, after a few runs that high learning rates aren't good and I should try, you know, smaller ones.",
                    "label": 0
                },
                {
                    "sent": "There are more sophisticated approaches like those I'm mentioning here, like Bayesian optimization.",
                    "label": 0
                },
                {
                    "sent": "Some people coined similar procedures as sequential model based optimization where.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as as I'm running more experiments, I'm going to train a model on predicting from a set of hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "What is the ultimate performance on the validation set, and now I'm going to use that model to suggest me a new hyperparameter to try out and so that procedure will have better sort of convergence properties like it will find a better solution more rapidly, and some people use that for exploring spaces, but this is already a pretty good procedure that's not easy to be given.",
                    "label": 0
                },
                {
                    "sent": "The sophistication of implementing something like this, so this is better, but that's already really really good and random search.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Shamelessly, yeah, so you'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "That's good, so you have discussion on Bayesian optimization tomorrow morning, afternoon.",
                    "label": 0
                },
                {
                    "sent": "Cool.",
                    "label": 0
                },
                {
                    "sent": "Yes, so next.",
                    "label": 1
                },
                {
                    "sent": "So we use a validation set to evaluate the relative performance of all of these configurations of hyperparameters and but then ultimately we pick the best one and we valid on the test, and then that's where we report in papers and so on.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Now there's one hyperparameters that we can do something a bit more clever than just trying a bunch of different values and running separate experiments, and that's the number of epochs.",
                    "label": 1
                },
                {
                    "sent": "Effectively what we use in practice usually is something known as early stopping.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that as your training, you're going to look at the performance of your model every epochs or every excep up on the validation set, and then get a track you know.",
                    "label": 0
                },
                {
                    "sent": "Essentially draw curve conceptually of the performance on the validation set as you go, and what we usually expect is that the performance of validation set is going to get better and better and better, and then at one point is going to be an inflection point where it's going to start getting worse.",
                    "label": 0
                },
                {
                    "sent": "And in this case, often informally, we say that we're started overfitting, and so at that point an often we sort of wait for a few iterations just to see whether it's just noise in our estimate of validation set performance.",
                    "label": 0
                },
                {
                    "sent": "But after a few iterations where it hasn't improved, then we just go back to whichever values of the weights gave us the best validation set performance, and we stopped raining there, and that's the performance we report for that experiment for that run OK.",
                    "label": 0
                },
                {
                    "sent": "So it's called early stopping in the sense that if you only look at the training error, you could probably train much longer.",
                    "label": 0
                },
                {
                    "sent": "But what we care about, of course, is how well it does.",
                    "label": 0
                },
                {
                    "sent": "On new example, it added seen an early stopping.",
                    "label": 0
                },
                {
                    "sent": "Does that really, really well an implicitly it also kind of acts as a regularizer in the sense that it will make it difficult for the neural net to train along time and not be stopped, and so not go far away from its initial values of the weights, which are typically close to 0.",
                    "label": 0
                },
                {
                    "sent": "So it implicitly also regularizers your procedure, your training procedure, because just to be a bit more concrete, what is effectively going on here is that the training error is always going down 'cause we have an optimization algorithm that works well.",
                    "label": 0
                },
                {
                    "sent": "But then the gap between the performance as estimated on the training set and on the validation set so that gets bigger and bigger and bigger.",
                    "label": 0
                },
                {
                    "sent": "And because the training set can only go so low at one point the difference becomes so large that you can see this upward trend.",
                    "label": 0
                },
                {
                    "sent": "This U shaped curve.",
                    "label": 1
                },
                {
                    "sent": "In the validation set performance so far, all other hyperparameters usually use something like random search or Bayesian optimization, but for the number of training updates within a single run, we would use early stopping like this.",
                    "label": 0
                },
                {
                    "sent": "Any questions on any of that, yes.",
                    "label": 0
                },
                {
                    "sent": "So when we do, we split the training data into training and validation weekend especially so this is a problem I personally faced.",
                    "label": 0
                },
                {
                    "sent": "We lose a lot of training data.",
                    "label": 0
                },
                {
                    "sent": "So we employ early stopping.",
                    "label": 0
                },
                {
                    "sent": "How can we?",
                    "label": 0
                },
                {
                    "sent": "How can we use that training data after early stopping this time?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is that.",
                    "label": 0
                },
                {
                    "sent": "When we so often in certain cases we already have a test set that's identified, especially in research using this sort of agreed upon testing set, but also often there's just a training set and you kind of have to make the decision.",
                    "label": 0
                },
                {
                    "sent": "How much do you keep for actual training and how much of that do you keep for validation for selecting hyperparameters and so on?",
                    "label": 0
                },
                {
                    "sent": "And what that proportion is is, you know, that's everyone has their favorite number them.",
                    "label": 0
                },
                {
                    "sent": "Certain sort of depends from one case to another, and one researcher do another.",
                    "label": 0
                },
                {
                    "sent": "If you don't have a lot of training examples, you might really want to use the validation set data also not just for training for figuring out the hyperparameters, but also for influencing the final model in a more substantial way.",
                    "label": 0
                },
                {
                    "sent": "One thing you could do so some people do this thing where they add back the validation set into the training set and train a little bit more.",
                    "label": 0
                },
                {
                    "sent": "I personally don't like this because I feel like you're effectively at some point you must have looked at the test set like I don't see how you sort of randomly got lucky at stopping at exactly the right point, and I I have not been convinced by most heuristics out their proposal.",
                    "label": 0
                },
                {
                    "sent": "You should stop when you reach again the training set performance you had before.",
                    "label": 0
                },
                {
                    "sent": "I think you can make up cases where that's going to overfit.",
                    "label": 0
                },
                {
                    "sent": "The test set so I don't like that all that much.",
                    "label": 0
                },
                {
                    "sent": "I prefer something like you do multiple train validation set splits, so maybe you take 20% eighty from your global training set, so that's five potential splits and you do you train so you find 5 different models for each of these splits that work well on their validation set, and then you assemble them so you have now five models and you average their predictions.",
                    "label": 0
                },
                {
                    "sent": "Assembling usually works pretty well and usually improves the performance.",
                    "label": 0
                },
                {
                    "sent": "So you'll get some benefit out of that.",
                    "label": 0
                },
                {
                    "sent": "Then you will effectively have your whole training procedure.",
                    "label": 0
                },
                {
                    "sent": "For example, will have used all of your training examples, so I feel this is sort of less risky of an approach to use and less prone to some form of cheating.",
                    "label": 0
                },
                {
                    "sent": "Any questions see you smiling you ever comment on that?",
                    "label": 0
                },
                {
                    "sent": "Crowd.",
                    "label": 0
                },
                {
                    "sent": "Do that when they're comparing apples and oranges.",
                    "label": 0
                },
                {
                    "sent": "You mean so?",
                    "label": 0
                },
                {
                    "sent": "I think the point Errol to make is that now often there is an accepted in agreed upon validation set in the paper.",
                    "label": 0
                },
                {
                    "sent": "It's not really legitimate to say, Oh my Ensembl works better than this single model reported in the literature.",
                    "label": 0
                },
                {
                    "sent": "That's not really impressive like, so don't do that just to be in a state of the art, but in practice, if you really only care about getting the best performance in assembling, ultimately is.",
                    "label": 0
                },
                {
                    "sent": "And this is one form is a good approach.",
                    "label": 0
                },
                {
                    "sent": "That yes.",
                    "label": 0
                },
                {
                    "sent": "Alright, next OK. A few other tricks of the trade.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So but so well.",
                    "label": 0
                },
                {
                    "sent": "I would argue that optimization algorithm that doesn't.",
                    "label": 0
                },
                {
                    "sent": "Fairly consistently decrease the training error isn't much of an optimization algorithm, 'cause that's really what it's meant to be doing.",
                    "label": 0
                },
                {
                    "sent": "So now there might be noise.",
                    "label": 0
                },
                {
                    "sent": "This is kind of very smooth so that you will see and sometimes you will see curves where like it's actually the trend you know is that it's decreasing always on the training set, but it's bouncing up and down that you might see.",
                    "label": 0
                },
                {
                    "sent": "Normally.",
                    "label": 0
                },
                {
                    "sent": "You expect that optimization algorithm to do better and better better on the loss.",
                    "label": 0
                },
                {
                    "sent": "The average loss possibly regularised average loss.",
                    "label": 0
                },
                {
                    "sent": "You do expect that from the optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "Let's have an example.",
                    "label": 0
                },
                {
                    "sent": "Maybe you want to.",
                    "label": 0
                },
                {
                    "sent": "I see, yeah, so maybe sometimes it'll be flat like it doesn't necessarily always go up.",
                    "label": 1
                },
                {
                    "sent": "You will see validation curves that sort of plateau that you might observe this if you have.",
                    "label": 0
                },
                {
                    "sent": "If essentially you have so much data that you barely have any overfitting, you might see like these curves being very, very close to one another.",
                    "label": 0
                },
                {
                    "sent": "Sort of assuming here that you actually don't have that much training data.",
                    "label": 0
                },
                {
                    "sent": "And there's like a generalization gap that you kind of expect.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "I don't think that's an issue, because in both cases they're all sort of equally hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a way of doing using smart bookkeeping for exploring more values of the number of iterations.",
                    "label": 0
                },
                {
                    "sent": "So I think at least that's the way I view it, and this sends it makes sense to use the validations that also for this, and also as we said, like we don't have want to avoid having multiple validation sets, because each of these data points are pretty valuable and you want to make the most of it and that sort of.",
                    "label": 0
                },
                {
                    "sent": "Using it training as another hyperparameter that you're just being a bit smarter in terms of running experiments by doing effectively some bookkeeping.",
                    "label": 0
                },
                {
                    "sent": "At least that works well in practice.",
                    "label": 0
                },
                {
                    "sent": "That's a good question though.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going forward, so if you have real valued observations, you should consider normalizing your data so that it has mean zero.",
                    "label": 1
                },
                {
                    "sent": "An standard deviation of one.",
                    "label": 1
                },
                {
                    "sent": "That sort of at least helps having fairly behave gradients at the first layer an fairly behave activations moving forward in the network.",
                    "label": 0
                },
                {
                    "sent": "It has often been observed also that it actually speeds up training.",
                    "label": 0
                },
                {
                    "sent": "It makes it more effective.",
                    "label": 1
                },
                {
                    "sent": "Having constant learning rate, there's really not what most people do.",
                    "label": 0
                },
                {
                    "sent": "One simple approach is to actually start with a fairly high learning rate, and then every once in a while dividing it by 2 by 10.",
                    "label": 1
                },
                {
                    "sent": "So specifically, you might track the validation set performance, and then once it stops improving you go back right before you started overfitting.",
                    "label": 0
                },
                {
                    "sent": "You decrease the learning rate and you continue training a little bit with a small learning rate.",
                    "label": 1
                },
                {
                    "sent": "The intuition being that initially.",
                    "label": 0
                },
                {
                    "sent": "Since you're very far from the optimum, you can make large jumps because you're pretty far from the optimal, so there's still a long way to go, and the gradient is sort of point, you know, despite the noise in your gradient is pretty much pointing in the direction of the course direction of the solution, but as you get closer and closer, you might want to more slightly adjust the parameters, in which case you want a smaller learning rate.",
                    "label": 1
                },
                {
                    "sent": "OK, as you get closer, yes.",
                    "label": 1
                },
                {
                    "sent": "So I mean, you definitely don't.",
                    "label": 0
                },
                {
                    "sent": "When you have a large learning rate and you might see some affiliation even see some affiliation on the validation set just from the fact that you have finite sample.",
                    "label": 0
                },
                {
                    "sent": "It's kind of noisy estimate of the generalization performance, so This is why for early stopping.",
                    "label": 0
                },
                {
                    "sent": "For instance, we do this sort of look ahead where you maybe wait for five iterations and check whether your slight increase in validation set will not be offset by a lower decreased later on.",
                    "label": 0
                },
                {
                    "sent": "But there's no actual guarantee.",
                    "label": 0
                },
                {
                    "sent": "It's sort of roughly you kind of expect it to go down, but especially with large learning rate and might sort of bounce off a little bit.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've talked about mini batch size, so actually in practice we rarely do one example at a time gradient updates.",
                    "label": 0
                },
                {
                    "sent": "We actually use a mini batch.",
                    "label": 0
                },
                {
                    "sent": "This is much more effective because for fully connected networks essentially we can do things like matrix matrix operations as opposed to multiple matrix vector operations an on the GPU.",
                    "label": 0
                },
                {
                    "sent": "Say you can sort of implement that much more efficiently than serially executing in multiple matrix vector operations.",
                    "label": 0
                },
                {
                    "sent": "And we'll talk a little bit about some of the generalization implications of using some batch size of variable size.",
                    "label": 0
                },
                {
                    "sent": "Also, instead of just using your estimate from your current batch, you can use a thing called momentum in momentum instead of using as the update direction, just the gradient from your current example or current mini batch, so you wouldn't have this here and this would be your dissent direction.",
                    "label": 0
                },
                {
                    "sent": "Instead, we sort of mix it with.",
                    "label": 0
                },
                {
                    "sent": "A portion of the previous update direction, so the idea here is that if you have a sequence of update directions all going in the same direction, then presumably that's a good direction to exploit.",
                    "label": 0
                },
                {
                    "sent": "So you can think of optimization landscape as maybe having being in a sort of plateau.",
                    "label": 0
                },
                {
                    "sent": "Where that's we have a very small inclination.",
                    "label": 0
                },
                {
                    "sent": "Well, when a momentum like this you might well gain momentum as you're moving in this consistent direction across mini batches.",
                    "label": 0
                },
                {
                    "sent": "However, if all of your mini batches kind of disagree about the.",
                    "label": 0
                },
                {
                    "sent": "Sign of the direction.",
                    "label": 0
                },
                {
                    "sent": "For certain parameters this would help.",
                    "label": 0
                },
                {
                    "sent": "Canceling these out between gradients and might allow you to do less bouncing off because of that, so that's one thing that you'll see some people using for designing better optimizers.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then also one thing that we might want is not a single global learning rate for the step we're taking in a given direction, but actually have one effectively one learning rate by parameter.",
                    "label": 0
                },
                {
                    "sent": "So one way we can think of this is to essentially take our dissent direction.",
                    "label": 0
                },
                {
                    "sent": "This is, I guess, the grain is that's the ascent direction would go in the opposite side, but taking that vector that gives us an idea of what direction we should move in parameter space.",
                    "label": 0
                },
                {
                    "sent": "But then dividing it.",
                    "label": 0
                },
                {
                    "sent": "Element wise by some vector that kind of gives us a notion of how sensitive the parameters are in terms of the objective, and so you will possibly read about adigrat in papers where what you're using is essentially a running sum of the square of the gradient.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that if a parameter has had a large partial narrative across training, you're going to take the square root of that and you some a lot of large values.",
                    "label": 0
                },
                {
                    "sent": "Then you're going to more rapidly start using smaller learning rates for that parameter, whereas if you have a parameter, it's barely being updated, then it's learning is going to stay large until it starts getting meaningful gradient, and then it will start having an effective learning rate that smaller RMS prop is essentially the same idea, except that instead of using the sum of the squared gradient and I should have said, then you actually take the square root of that sum and we had an epsilon for numerical stability or small.",
                    "label": 1
                },
                {
                    "sent": "Very small value like 10 to the minus six or something.",
                    "label": 1
                },
                {
                    "sent": "So instead of using a sum we use a exponential moving average.",
                    "label": 0
                },
                {
                    "sent": "So we take a portion of the current.",
                    "label": 0
                },
                {
                    "sent": "Average an we add to this one minus that portion of the current squared gradient.",
                    "label": 0
                },
                {
                    "sent": "So that's RMS prop.",
                    "label": 0
                },
                {
                    "sent": "So instead of being guaranteed of having a learning rate that always reduces, so that's the property you have here, because this number can only increase as you add more terms.",
                    "label": 0
                },
                {
                    "sent": "This one means that the learning rate might sort of decrease the effective learning rate decrease, and then increase again if you get very small gradients for a long time and then might if we resume getting gradients for parameter, it might.",
                    "label": 0
                },
                {
                    "sent": "Decrease again, so that's another thing you might see in the literature.",
                    "label": 0
                },
                {
                    "sent": "And then there's Adam, which is probably the most popular approach right now, which is essentially RMS prop but with some form of momentum.",
                    "label": 0
                },
                {
                    "sent": "An general common wisdom tells us that the practice of most people is that this is actually a pretty robustly successful optimizer.",
                    "label": 0
                },
                {
                    "sent": "You don't have to tune, there are hyperparameters, but the defaults tend to work pretty well, so that's not a bad idea to start with this for experimenting.",
                    "label": 0
                },
                {
                    "sent": "With a given idea, however, some people have had better performance when, perhaps when they sort of figured out what their algorithm is.",
                    "label": 1
                },
                {
                    "sent": "They start using gradient descent with regular momentum and sort of tweaking a schedule for their problem.",
                    "label": 0
                },
                {
                    "sent": "Some people have had more success, but fairly marginal but larger success than with Adam, so a sort of good approaches to start with Adam and then really really care about the performance.",
                    "label": 0
                },
                {
                    "sent": "Then maybe consider gradient descent with momentum, where you have a control over the schedule and play with those.",
                    "label": 0
                },
                {
                    "sent": "Questions yes.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "I mean, you could definitely add an effective global learning rate here, and also do this thing where you track the validation set performance and then change what that factor is.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry some people have played with that.",
                    "label": 0
                },
                {
                    "sent": "Then it might be valuable to combine that as well here.",
                    "label": 0
                },
                {
                    "sent": "I think with Adam to get pretty good results, you don't really need to do that, but I possibly some people have.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure actually have any sort of interesting bits of knowledge about that, yes?",
                    "label": 0
                },
                {
                    "sent": "Sailing.",
                    "label": 0
                },
                {
                    "sent": "Right, so the question is, by dividing by this elementwise vector, we're really changing the direction of what the gradient is.",
                    "label": 0
                },
                {
                    "sent": "That said.",
                    "label": 0
                },
                {
                    "sent": "It's it's still like if you did the dot product between this and the original gradient, you would still get a positive angle, so it has that property going for it, right?",
                    "label": 0
                },
                {
                    "sent": "So that's why it's not affecting it too much.",
                    "label": 0
                },
                {
                    "sent": "It's not going to change the sign, for instance this term is positive, so I'm going to change the sign of the direction an.",
                    "label": 0
                },
                {
                    "sent": "I think I'm assuming this is partly why for some of these procedures we can actually prove forms of convergence is that it's actually going still as a positive angle with the gradient.",
                    "label": 0
                },
                {
                    "sent": "That's a good point.",
                    "label": 0
                },
                {
                    "sent": "And there are.",
                    "label": 0
                },
                {
                    "sent": "There was mention of 2nd order approaches which will also have this kind of effect where it's changing the direction and there's still some research and trying to develop better and also scalable.",
                    "label": 0
                },
                {
                    "sent": "That's one of the challenges of 2nd order methods, but this is the Atom is a pretty good place to start.",
                    "label": 0
                },
                {
                    "sent": "Other questions, yeah.",
                    "label": 0
                },
                {
                    "sent": "Learning rate.",
                    "label": 0
                },
                {
                    "sent": "He said that.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "To make a simple get there.",
                    "label": 0
                },
                {
                    "sent": "The whole thing.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that.",
                    "label": 0
                },
                {
                    "sent": "I mean, do we have enough units here?",
                    "label": 0
                },
                {
                    "sent": "What can I represent with the unit and this actually?",
                    "label": 0
                },
                {
                    "sent": "I mean what is represented?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Pastor haha.",
                    "label": 0
                },
                {
                    "sent": "Order yeah, so I will talk a little bit about some of the latest experimental observations about.",
                    "label": 0
                },
                {
                    "sent": "The interesting relationship between capacity and learning algorithm, which I get a sense you're sort of getting at with your question.",
                    "label": 0
                },
                {
                    "sent": "Here I will say that.",
                    "label": 0
                },
                {
                    "sent": "First, we'll talk about how non combats this objective is.",
                    "label": 0
                },
                {
                    "sent": "So the to answer the question.",
                    "label": 0
                },
                {
                    "sent": "OK, there's this universal approximation theorem, but can I actually discover these weights?",
                    "label": 0
                },
                {
                    "sent": "Part of the key to that answer is how nonconvex optimization is it crippled with a bunch of really bad local Optima?",
                    "label": 0
                },
                {
                    "sent": "Will talk about that in the second half for sure.",
                    "label": 0
                },
                {
                    "sent": "Can we see that?",
                    "label": 0
                },
                {
                    "sent": "I mean, I guess we sort of, you know, just looking by the fact people are using neural Nets quite a bit and our training fairly large.",
                    "label": 0
                },
                {
                    "sent": "No, let's it is clearly not as bad as one might think.",
                    "label": 0
                },
                {
                    "sent": "I'll try to add a bit more intuition that is too like what we think is going on, but that's very much an open area research too.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "Recommended normalized.",
                    "label": 0
                },
                {
                    "sent": "Yeah, not much is.",
                    "label": 0
                },
                {
                    "sent": "They can have all sorts of different you know.",
                    "label": 0
                },
                {
                    "sent": "Like little probabilities, sparse.",
                    "label": 0
                },
                {
                    "sent": "Is there anything any practical?",
                    "label": 0
                },
                {
                    "sent": "Yeah, the question is.",
                    "label": 0
                },
                {
                    "sent": "Is there any interesting normalization we should do with Princess binary data so for binary data in general, just using the binary vector I found to work pretty well with count data there definitely literature saying the information retrieval field where using things like TF IDF.",
                    "label": 0
                },
                {
                    "sent": "Waiting, which will change the original waiting.",
                    "label": 0
                },
                {
                    "sent": "It's a form of normalization I guess on the input dimensions, which essentially will emphasize the importance of a term that is only found in a few documents.",
                    "label": 0
                },
                {
                    "sent": "An isn't very free, but is very frequent.",
                    "label": 0
                },
                {
                    "sent": "For instance, there are definitely so fun, since if you were mad in plating bags of words, if your input X is essentially the counts of number of different words in a document form of TF, IDF weighting might be a good normalization to use here.",
                    "label": 0
                },
                {
                    "sent": "But for binary data, usually working with just the binary data will work pretty well.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say you shouldn't think about whether you should enhance the weight of a very like a one dimension.",
                    "label": 0
                },
                {
                    "sent": "That's binary, but very infrequent, specially all the literature on TF.",
                    "label": 0
                },
                {
                    "sent": "IDF weighting suggests that sometimes that's valuable, so I would maybe explore that a little bit, but it would start with maybe not doing having to do anything.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm almost out of time, so I'm going to do yes, sure.",
                    "label": 0
                },
                {
                    "sent": "Which one?",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "In practice, I think the verification error.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I wonder how how we can automatically.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is how to handle essentially how validation set performance might fluctuate quite a bit and that had this nice move curve that I showed.",
                    "label": 0
                },
                {
                    "sent": "Honestly, it's a good question.",
                    "label": 0
                },
                {
                    "sent": "I find some people have shown some success in being very patient and waiting for the validation set performance for a long time to not change.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it is helpful.",
                    "label": 0
                },
                {
                    "sent": "I have to say I don't have a very good sort of like heuristic that works universally universally.",
                    "label": 0
                },
                {
                    "sent": "So, but it is.",
                    "label": 0
                },
                {
                    "sent": "If you have a lot of punctuation, I would just advise that maybe you might want to sort of wait longer an beyond an automatic rule.",
                    "label": 0
                },
                {
                    "sent": "Just looking at it and kind of making a decision just by based on how much it varies compared to other experiments you might have done, does not.",
                    "label": 0
                },
                {
                    "sent": "I don't have particularly good advice for that, but I just something to sort of be careful with.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "I like.",
                    "label": 0
                },
                {
                    "sent": "General.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I guess the question is about maybe some heuristics for when we're exploring the number of layers as well as the number of hidden units.",
                    "label": 0
                },
                {
                    "sent": "I found in practice what I usually do is actually just assume a constant number of hidden units per layer for fully connected networks we have some evidence that usually this is actually a reasonable assumption.",
                    "label": 0
                },
                {
                    "sent": "It's absolutely perfect when it's not too far from optimal.",
                    "label": 0
                },
                {
                    "sent": "So then one thing you might want to do is first just figure out a rough idea of how many layers works well by just.",
                    "label": 0
                },
                {
                    "sent": "Jointly optimizing the number of layers and the number of hidden units per layer.",
                    "label": 0
                },
                {
                    "sent": "So that makes for fewer various.",
                    "label": 0
                },
                {
                    "sent": "That's just two numbers that you need to explore.",
                    "label": 0
                },
                {
                    "sent": "There's definitely now more more research on trying to explore much more richer architectures using.",
                    "label": 0
                },
                {
                    "sent": "Various forms are things that look like Bayesian optimization, but that might use reinforcement learning with RNS and soft.",
                    "label": 0
                },
                {
                    "sent": "There are things published I cleared this year, for instance from Google.",
                    "label": 0
                },
                {
                    "sent": "What they do this, but that still requires a lot of compute, so I would say are you Ristic, which is assume a fixed number of units per layer and then tuning depth fixed number and the number of layers separately as two different hyperparameters is just two operators, so it's not too bad, it's a good place to start that would say.",
                    "label": 0
                },
                {
                    "sent": "But there's still some research to be done in terms of doing going more deeply and tuning the architecture.",
                    "label": 0
                },
                {
                    "sent": "Or random search yes, yeah, yeah it gets you most of the way I think.",
                    "label": 0
                },
                {
                    "sent": "OK so I am.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out of time probably, but I want to finish this real quick so one message if you are so usually if you use Tensorflow or Pytorch or other or theano's or libraries that have a bunch of these smaller grained operations as you can build more and more sophisticated neural networks usually don't have to check for your gradients because they have been unit tested and they should be fine if you implement your own module with its own forward and corresponding backdrop or gradient computation procedure.",
                    "label": 0
                },
                {
                    "sent": "You should definitely do that and our procedures for doing this, which essentially what you end up doing is you add you essentially approximate the real partial narrative by finite difference by adding some epsilon and subtracting some epsilon, and then dividing by the difference by two epsilon.",
                    "label": 0
                },
                {
                    "sent": "So if epsilon goes to zero, that's the actual definition of this partial narrative with a small epsilon you should get a number that is pretty close to the actual partial narrative, so that's a thing you should definitely do if you implemented your own gradients.",
                    "label": 0
                },
                {
                    "sent": "And also, before you launch your full blown you know job on some new data set.",
                    "label": 0
                },
                {
                    "sent": "I really do recommend that you do small tests on a very very small version of your data set.",
                    "label": 0
                },
                {
                    "sent": "So just take the 51st training examples an look at whether it's able to overfit it should any network with reasonable capacity should be able to overfit on 50 examples and so and then you can look at OK, what's going on with my units if I'm not overfitting and reaching perfect performance of 50 examples.",
                    "label": 0
                },
                {
                    "sent": "You can look at your units, whether it's saturating an maybe identify all.",
                    "label": 0
                },
                {
                    "sent": "That's because I badly initialize certain parameters in my my neural network.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it's just my inputs that are taking a scale that's too large and I should normalize them.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If the training error is bouncing up and down a lot, that might give you some indication that your learning rate is too large and you should start with something smaller, and this isn't a replacement for gradient checking, so your gradients might be wrong and you might still be able to overfit so.",
                    "label": 1
                },
                {
                    "sent": "These neural networks are pretty resilient to bugs, which is great if we use them in real life.",
                    "label": 0
                },
                {
                    "sent": "Not great when you're doing science and trying to understand how things work, so you should really be doing both these things.",
                    "label": 1
                },
                {
                    "sent": "If you implemented some of your own gradients.",
                    "label": 0
                },
                {
                    "sent": "And I'll stop here, I guess, and then I'll finish with deep learning and then talk about some more recent results in the afternoon.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}