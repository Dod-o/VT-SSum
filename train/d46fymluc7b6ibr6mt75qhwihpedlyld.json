{
    "id": "d46fymluc7b6ibr6mt75qhwihpedlyld",
    "title": "Presentation of Adobe Omniture, the Challenge, and announcement of the final results",
    "info": {
        "author": [
            "Louis Dorard, Department of Computer Science, University College London",
            "Chris Wright, Adobe Systems Incorporated"
        ],
        "published": "July 25, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Software and Tools"
        ]
    },
    "url": "http://videolectures.net/explorationexploitation2011_dorard_wright_pascal/",
    "segmentation": [
        [
            "My name is Chris right?",
            "I work for Adobe, and because Adobe contributed this data, I'll be."
        ],
        [
            "Going through that this product testing Target 1 to one and then the description of how the data was pulled, created and then some applied components to the modeling within testing target.",
            "So just kind of like differences between data we see and then actual data in addition to some business constraints that we see in the applied setting so."
        ],
        [
            "So testing Target 1 to one is part of Adobe's online marketing suite and the goal is to pair the each individual user to the optimal content so the one to one part of it is rather than having buckets for types of users you really are taking each individual user and trying to pick the perfect content for them.",
            "And there's two components to how testing Target 1 to one handles that.",
            "The first is the specific user.",
            "Targeted information and then it bundles that with the generalized Population wide information so it takes the targeted user information and combines it with trends that we're seeing for content as a whole throughout the population, and it learns dynamically with minimum human analysis needed."
        ],
        [
            "So this is an example of an end result.",
            "So once we've gone through a user has requested a page and we've gone through all the modeling, they'll be served this an in the multi armed bandit situation or terminology.",
            "This would be like the optimal lever that was chosen, so with the highest probability of.",
            "In this case conversion, and so you can see there's multiple boxes here.",
            "So like where the place where those boxes are placed in which boxes are chosen to be placed there?",
            "Things like that are part of that."
        ],
        [
            "So.",
            "Um?",
            "Once the desert visitor makes the request, we start gathering variables and so the first component of that is.",
            "We check to see in our offline data if we've seen this user before, and so all kinds of performance metrics that we may have in our historical data, we pulled in tide to that user, and if not, we can also use temporal variables.",
            "So time of day, Day of week, recency, frequency, environmental variables in this IP address, Geo demographic like psychological kind of components, country of origin.",
            "And then also refer variables so referring domain affiliates, natural search bookmarks, things like that."
        ],
        [
            "So once we have that information, we go through and generate variable response rates for each univariate response.",
            "And then we apply that to.",
            "The user information so.",
            "This is just some examples.",
            "There's hundreds of variables in most cases, but there's just some examples of variables we would mark can use in our in our model, so that's the first step."
        ],
        [
            "And then we would go through and also generate response rates for the interacting terms and bundle that together."
        ],
        [
            "And then the third component is the generalized content response and so the idea here is that.",
            "There's going to be content that is nonstationary, that you know has a time component to it.",
            "So for like an example of this would be some content that we referred to tax tax service or and then you know as the tax due date approached that would wane in popularity.",
            "And then after that it wouldn't be relevant anymore and we wouldn't want to be serving it.",
            "But if we overfit to the user, the idea is that we might not be able to capture that and so we have this generalized content response so.",
            "Yeah, and then we'll go into more."
        ],
        [
            "How that's calculated?",
            "OK so.",
            "Once we go through and mark the user information with the targeting components, we have two different kinds of serve groups that will use and.",
            "To kind of align it with this talk, we call it test and target, but you guys probably know better as exploration and exploitation.",
            "So we have this first testing serve group, which a small percentage of what is served to the user is purely for testing and so this is preset.",
            "But rather than serving them, the optimal content will serve them a random server for the purpose of exploration.",
            "And so there's a couple reasons we do this.",
            "One of 'em is it creates baseline performance for modeling and report.",
            "Excuse me reporting and provides relative response rates independent of user profile.",
            "So this is again so as to not overfit to that particular user profile.",
            "But to have a more generalized idea of how the population is trending and that again is the generalized response rates.",
            "And then the other served."
        ],
        [
            "Is the targeted service group, so this is the Sean targeted content based on values in the user's profile.",
            "So the recipe with the highest predicted likelihood of responses is served.",
            "Recipe you could say lever or arm in the multi arm bandit situation and then in addition to this in the initial phases of a campaign, we actually do explore to understand those targeting components.",
            "So when we when we have no information about user variables will actually serve them.",
            "Randomly as well."
        ],
        [
            "OK, so this is an example of the UI that our sales and our clients would see and so here you'll see the targeted traffic and tested traffic and the comparison and you can see conversion rate and lift and general confidence and average order value revenue.",
            "So these are like different kinds of success metrics in this in this study, in the data that we gave to the challenge it was just 01 so.",
            "Convert or not convert, but at testing target the advertiser can choose between various different types of success metrics, so it's not always you know, 01 binary can be continuous on varying amounts of scales."
        ],
        [
            "So I cut off a little bit, but description of data, so the this was clickthrough data, so 01 data collected for a single client between June 2009 in April 2010, so around a year and it was sampled.",
            "So we stratified sampling at .1 for negative responses because in a lot of the data we see it's not positive response rates aren't around 1%.",
            "It's actually much much lower than that.",
            "So to provide for a richer data set we.",
            "We sampled on the negatives so as to produce a data set that would have 1% positive response rate and then we did some campaign merging to create 6 campaign groups and that was by in the data set there were six to choose from.",
            "And then the data was then categorized into template ranges so that responder and non responder would have variable one between .3 and .6 variable to between 6:00 and 8:00.",
            "And then we used those above templates to randomly generate the data set within each and it was they were uniform.",
            "They were generated using the uniform distribution just within those templates so.",
            "That was how the data was created."
        ],
        [
            "And so some differences that we see in actual data is in actual data.",
            "We see nonstationary levers like I mentioned before with content that is changing overtime.",
            "It isn't stationary.",
            "In addition, we have multiple success metrics, so it's not just conversion 01, but we have revenue per visit, average order value, and a couple others.",
            "And then smaller positive response rates.",
            "So depending on how advertisers define conversions or which success metrics they choose, response rates can fall well below 1%.",
            "So."
        ],
        [
            "Oh OK, so this is an interesting thing that when I first came on I thought was kind of strange was before we actually do any of the modeling.",
            "We have to send it through our business constraint engine, which is basically set so that if there are any kind of.",
            "And you know advertiser specific constraints that you can't serve two advertisers on the same page next to each other, or anything like that.",
            "Those combinations actually have to be removed pre modeling and so all of those run through and some examples are.",
            "So if you push a particular offer to ensure a minimum maximum number of service when you have like a new product launch.",
            "If you want to serve it a lot so that you can have a lot of reach, or for business partitioning if an advertiser wants to see a certain amount on the homepage, or experience exclusions when it's just two campaigns can't be served side by side.",
            "Whether it's competitive or for other reasons and then.",
            "Another constraint in the applied setting is exploration versus exploitation.",
            "So when I interact with sales teams or advertisers, they in general don't like the exploration side of things because it's just not revenue producing and they really cringe at the thought of giving away the optimal surf.",
            "So that's one thing we have to kind of push back on a lot and then these effects all come with an opportunity cost, but it's just how things work I guess in that setting."
        ],
        [
            "So.",
            "And then in conclusion, exploration and exploitation balance is a daily concern.",
            "So we're constantly interacting with our clients, advertisers, discussion of you know what the right percentages and finding kind of going to them with our science and having them come back with what they're comfortable with for exploration and the actual data is much larger and sometimes messier than the Pascal data, and that we process it in real time.",
            "And so I think that.",
            "A lot of situations we can actually find better signal than a set data set that would be handed out in the way that it was for this challenge, so."
        ],
        [
            "OK, and that's it."
        ],
        [
            "Sorry, so we given visitor profile night car.",
            "Sorry I don't even have the slides up there.",
            "There we go.",
            "So for a given visitor V. Have to choose which piece of content we want to display on the web page, and let's say there's any options, so we have to like choose one of these options to like present to the visitor and we want that guys interested enough to like click and to learn more or whatever.",
            "So we want to maximize engagement which is measured by clicks.",
            "An IF we sort formalize that.",
            "It's like we have N visitor an option index pairs in input, and the algorithm has to output the index.",
            "Of the pair for which click is most likely.",
            "And the challenge is about the challenge was about finding good algorithms to do that.",
            "The thing is, we can't really evaluate algorithms live because we don't want to impact users experience.",
            "So we are using the data provided by Adobe."
        ],
        [
            "And the beta was the data consisted of about, I think 20,000,000 records where you would have a visitor feature vector and an option index and a click indicator that would tell you whether or not the person clicked when presented that particular piece of content.",
            "Note that all options have the same overall clickthrough rate, so it's not like you could have used bandit algorithms where arms would be the option index, and then you would have tried tonight.",
            "Look for the the index that has overall the highest clickthrough rates we really wanted to push people to use the visitor information.",
            "The problem though, is that it's not that easy to evaluate algorithms.",
            "What we should do is that we should ask for a given visitor feature vector.",
            "We should ask the algorithm which option do you think we should present and then.",
            "We should evaluate that, but in the data we're going to have like for a given visitor, we're going.",
            "The data says that this visitor was presented, for instance, option number 2.",
            "And then we have observed what this visitor does when presented option #2.",
            "But then the algorithm says for this visit.",
            "So you should present option #3 where you don't have that in the data you have only observed how the user or the visitor reacts to option #2.",
            "So you know what you do then how should you evaluate the algorithm.",
            "So you could.",
            "I guess you could just you know reject.",
            "This, but there's a."
        ],
        [
            "It's not clear how to evaluate algorithms, and I'm sure we come back to that in the discussion section because the participants have come up with with other ideas too for other challenges.",
            "But anyway, for this particular task that we considered, we tried to stick to the previous formulation as much as possible, so we still have a batch of six visits, option pairs, and we still want to get the index of the pair that's most likely to be associated to click, but The thing is.",
            "The visitor is not fixed anymore.",
            "These batches of visits, option pairs, we get them from the data, so we just take them in chronological order.",
            "Take the first 6 and the following six in the following six, and so on and so on.",
            "And.",
            "Then we look up, so we ask the algorithm what's the index of the most likely to be associated to click.",
            "If there was indeed a click, then the algorithm gets a reward of 1.",
            "And the algorithm only observes the behavior of the visitor.",
            "That's in the independent.",
            "It selected when presented the option again in that pair, so it only observes this bit of the reward.",
            "It doesn't observe all the rewards for the batch or batches, so it can see that this double objective is learning the mapping from visitor option to reward at the same time you want to you want to get more rewards.",
            "So you've got this learning and optimization objectives.",
            "Hence exploration exploitation.",
            "Maybe a couple of remarks before moving on to the next slide.",
            "So again, all the visitors in any given batch are different and they've never been seen before.",
            "An all options might not be represented.",
            "In any given batch, and there can be several clicks or no click at all.",
            "Anne miss.",
            "Writes an again because the click through rates are the same overall for each option we really need to use the visitor features if we want to make better predictions than random because, like the monthly unbend, it is just going to perform like randomly."
        ],
        [
            "They will have the same main rewards.",
            "The way that we evaluated algorithms was that we asked people to write them in Java and then compile it and then submit the Java Archive to our server so people would log in.",
            "And they would upload their click predicted jar and during Phase one this would like instantly launch the evaluations of the algorithms on the on the data.",
            "So we used.",
            "15% of the whole data for phase one and thing is that people didn't know anything about the data when it started, but they could like submit a first version.",
            "Get this callback, submit something else, try a different idea, and then get this score.",
            "Actually, the feedback that was given to them where the logs here where you would have for each batch.",
            "For each iteration you'll be given the reward that the algorithm got the time expense and the memory.",
            "Also that was used.",
            "On the leaderboard was alive, so you know as soon as the evaluations will be finished, it would update the leaderboard and so on.",
            "An phase two was.",
            "So for phase two, we used up most of the day.",
            "Today 85% of the datasets.",
            "But then people could only submit once, but they had the phase one.",
            "Data would given given it to them so that they could not manually tune their algorithms.",
            "On their own, with that face one data, but then they could only submit once and then we run the algorithms again on the whole of the data.",
            "I mean on the 85% of the data the phase two.",
            "So that's the result."
        ],
        [
            "To present now quickbird about the resources that we had, actually, all the evaluations were done on the grid engine that we've got a UCL and we allowed 100 milliseconds per batch, which is sort of this kind of time you would allow for, like the latency you would allow for.",
            "I guess we're serving for deciding what to serve 2.",
            "So visitor and then we had each node.",
            "On the grid engine had 4 gigabytes of memory, could have requested more, but then they would have taken more time to get available nodes and then we have to divide the Java virtual machine memory by two is actually we needed to keep a copy of the click predictor instance in case the computations would run for more than 100 milliseconds would just stop it and then just to make sure that you know you would, you wouldn't have like 1/2 of dated model.",
            "We would revert back to the previous one.",
            "And one more thing regarding the time, 100 milliseconds, so that's both for choosing which option to present.",
            "I mean which visit option you want to try and false updating your model based on previous."
        ],
        [
            "Observation as the Phase one leaderboard."
        ],
        [
            "I have also grouped by teams.",
            "And there's also."
        ],
        [
            "Chart here so you can see that it's.",
            "And the top three are performing right?",
            "Significantly better than random."
        ],
        [
            "If you zoom in on the top three, where in reality seems to be like a clear winner."
        ],
        [
            "And now onto the phase two results and you expect it afternoon.",
            "Um, so the random was.",
            "Was this as a baseline?",
            "I'm just writing with the random words that some UN monton University slogan.",
            "Number three was the CNS team.",
            "There not here today, but yeah, they didn't do bad.",
            "And now the top two, so it's going to be between.",
            "Orange Labs in an area where is inria OK.",
            "Number two was.",
            "Orange labs one area, so I think they deserve and approves.",
            "So let's nations the winners."
        ],
        [
            "It's actually the same order as we had for phase one."
        ],
        [
            "So SNR is.",
            "Orange Labs in INRIA what we've got here in yellow is actually the performance.",
            "The sorry, the performance they would have got if they had submitted the algorithm that they submit it at the end of Phase One.",
            "So at the end of Phase one, they received the data, then they tune their algorithms and then they made another submission which.",
            "Which are referred to as the Phase two submission and you can see that they got a slight increase in performance."
        ],
        [
            "Just wanted to introduce the notion of uplift, which is the score of the algorithm divided by the score of the.",
            "Random algorithm minus one so that the uplift is 0% if you're not using.",
            "If you're doing random, I said if you're not using this feature, but if you're doing random, it's in Europe.",
            "Sent an inner ear, got 106."
        ],
        [
            "Once I've broken down the results by participants have also displayed the uplift and also the time that was taken by the algorithms to run."
        ],
        [
            "It's not really clear weather, like for instance #2 beat #3 and #3 beat #4 'cause you know the it's likely that the algorithms are stochastic and also.",
            "Although batches are presented in the same order, the elements within the batch may have been presented in different orders that different launches of their Java virtual machines are different, which is of.",
            "For each phase."
        ],
        [
            "Evaluation and.",
            "Last slide on the resource is again.",
            "If if we had 100 milliseconds for batch, given the number of batches we had, we could have run for 78 hours and then re algorithm only took three hours 40 minutes I guess.",
            "Now you know it might be because the amount of data that was given to the amount of memory, so that was available was a bit.",
            "Small, so there wasn't much to compute on.",
            "I mean, I don't know 20 gigabytes of data.",
            "You could only store 1.75.",
            "It might have been this.",
            "Maybe that you know people would have been able to exploit their confessional budget abit more if they would have had more things to compute on right?",
            "And that's it for the for the challenge presentation."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Chris right?",
                    "label": 0
                },
                {
                    "sent": "I work for Adobe, and because Adobe contributed this data, I'll be.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going through that this product testing Target 1 to one and then the description of how the data was pulled, created and then some applied components to the modeling within testing target.",
                    "label": 0
                },
                {
                    "sent": "So just kind of like differences between data we see and then actual data in addition to some business constraints that we see in the applied setting so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So testing Target 1 to one is part of Adobe's online marketing suite and the goal is to pair the each individual user to the optimal content so the one to one part of it is rather than having buckets for types of users you really are taking each individual user and trying to pick the perfect content for them.",
                    "label": 1
                },
                {
                    "sent": "And there's two components to how testing Target 1 to one handles that.",
                    "label": 0
                },
                {
                    "sent": "The first is the specific user.",
                    "label": 0
                },
                {
                    "sent": "Targeted information and then it bundles that with the generalized Population wide information so it takes the targeted user information and combines it with trends that we're seeing for content as a whole throughout the population, and it learns dynamically with minimum human analysis needed.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example of an end result.",
                    "label": 0
                },
                {
                    "sent": "So once we've gone through a user has requested a page and we've gone through all the modeling, they'll be served this an in the multi armed bandit situation or terminology.",
                    "label": 0
                },
                {
                    "sent": "This would be like the optimal lever that was chosen, so with the highest probability of.",
                    "label": 0
                },
                {
                    "sent": "In this case conversion, and so you can see there's multiple boxes here.",
                    "label": 0
                },
                {
                    "sent": "So like where the place where those boxes are placed in which boxes are chosen to be placed there?",
                    "label": 0
                },
                {
                    "sent": "Things like that are part of that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Once the desert visitor makes the request, we start gathering variables and so the first component of that is.",
                    "label": 0
                },
                {
                    "sent": "We check to see in our offline data if we've seen this user before, and so all kinds of performance metrics that we may have in our historical data, we pulled in tide to that user, and if not, we can also use temporal variables.",
                    "label": 0
                },
                {
                    "sent": "So time of day, Day of week, recency, frequency, environmental variables in this IP address, Geo demographic like psychological kind of components, country of origin.",
                    "label": 1
                },
                {
                    "sent": "And then also refer variables so referring domain affiliates, natural search bookmarks, things like that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So once we have that information, we go through and generate variable response rates for each univariate response.",
                    "label": 1
                },
                {
                    "sent": "And then we apply that to.",
                    "label": 0
                },
                {
                    "sent": "The user information so.",
                    "label": 0
                },
                {
                    "sent": "This is just some examples.",
                    "label": 0
                },
                {
                    "sent": "There's hundreds of variables in most cases, but there's just some examples of variables we would mark can use in our in our model, so that's the first step.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we would go through and also generate response rates for the interacting terms and bundle that together.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then the third component is the generalized content response and so the idea here is that.",
                    "label": 1
                },
                {
                    "sent": "There's going to be content that is nonstationary, that you know has a time component to it.",
                    "label": 0
                },
                {
                    "sent": "So for like an example of this would be some content that we referred to tax tax service or and then you know as the tax due date approached that would wane in popularity.",
                    "label": 0
                },
                {
                    "sent": "And then after that it wouldn't be relevant anymore and we wouldn't want to be serving it.",
                    "label": 0
                },
                {
                    "sent": "But if we overfit to the user, the idea is that we might not be able to capture that and so we have this generalized content response so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and then we'll go into more.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How that's calculated?",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Once we go through and mark the user information with the targeting components, we have two different kinds of serve groups that will use and.",
                    "label": 0
                },
                {
                    "sent": "To kind of align it with this talk, we call it test and target, but you guys probably know better as exploration and exploitation.",
                    "label": 0
                },
                {
                    "sent": "So we have this first testing serve group, which a small percentage of what is served to the user is purely for testing and so this is preset.",
                    "label": 1
                },
                {
                    "sent": "But rather than serving them, the optimal content will serve them a random server for the purpose of exploration.",
                    "label": 0
                },
                {
                    "sent": "And so there's a couple reasons we do this.",
                    "label": 1
                },
                {
                    "sent": "One of 'em is it creates baseline performance for modeling and report.",
                    "label": 1
                },
                {
                    "sent": "Excuse me reporting and provides relative response rates independent of user profile.",
                    "label": 0
                },
                {
                    "sent": "So this is again so as to not overfit to that particular user profile.",
                    "label": 0
                },
                {
                    "sent": "But to have a more generalized idea of how the population is trending and that again is the generalized response rates.",
                    "label": 0
                },
                {
                    "sent": "And then the other served.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the targeted service group, so this is the Sean targeted content based on values in the user's profile.",
                    "label": 1
                },
                {
                    "sent": "So the recipe with the highest predicted likelihood of responses is served.",
                    "label": 0
                },
                {
                    "sent": "Recipe you could say lever or arm in the multi arm bandit situation and then in addition to this in the initial phases of a campaign, we actually do explore to understand those targeting components.",
                    "label": 0
                },
                {
                    "sent": "So when we when we have no information about user variables will actually serve them.",
                    "label": 0
                },
                {
                    "sent": "Randomly as well.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is an example of the UI that our sales and our clients would see and so here you'll see the targeted traffic and tested traffic and the comparison and you can see conversion rate and lift and general confidence and average order value revenue.",
                    "label": 0
                },
                {
                    "sent": "So these are like different kinds of success metrics in this in this study, in the data that we gave to the challenge it was just 01 so.",
                    "label": 0
                },
                {
                    "sent": "Convert or not convert, but at testing target the advertiser can choose between various different types of success metrics, so it's not always you know, 01 binary can be continuous on varying amounts of scales.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I cut off a little bit, but description of data, so the this was clickthrough data, so 01 data collected for a single client between June 2009 in April 2010, so around a year and it was sampled.",
                    "label": 1
                },
                {
                    "sent": "So we stratified sampling at .1 for negative responses because in a lot of the data we see it's not positive response rates aren't around 1%.",
                    "label": 1
                },
                {
                    "sent": "It's actually much much lower than that.",
                    "label": 0
                },
                {
                    "sent": "So to provide for a richer data set we.",
                    "label": 1
                },
                {
                    "sent": "We sampled on the negatives so as to produce a data set that would have 1% positive response rate and then we did some campaign merging to create 6 campaign groups and that was by in the data set there were six to choose from.",
                    "label": 0
                },
                {
                    "sent": "And then the data was then categorized into template ranges so that responder and non responder would have variable one between .3 and .6 variable to between 6:00 and 8:00.",
                    "label": 1
                },
                {
                    "sent": "And then we used those above templates to randomly generate the data set within each and it was they were uniform.",
                    "label": 0
                },
                {
                    "sent": "They were generated using the uniform distribution just within those templates so.",
                    "label": 0
                },
                {
                    "sent": "That was how the data was created.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so some differences that we see in actual data is in actual data.",
                    "label": 0
                },
                {
                    "sent": "We see nonstationary levers like I mentioned before with content that is changing overtime.",
                    "label": 0
                },
                {
                    "sent": "It isn't stationary.",
                    "label": 0
                },
                {
                    "sent": "In addition, we have multiple success metrics, so it's not just conversion 01, but we have revenue per visit, average order value, and a couple others.",
                    "label": 1
                },
                {
                    "sent": "And then smaller positive response rates.",
                    "label": 1
                },
                {
                    "sent": "So depending on how advertisers define conversions or which success metrics they choose, response rates can fall well below 1%.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh OK, so this is an interesting thing that when I first came on I thought was kind of strange was before we actually do any of the modeling.",
                    "label": 0
                },
                {
                    "sent": "We have to send it through our business constraint engine, which is basically set so that if there are any kind of.",
                    "label": 0
                },
                {
                    "sent": "And you know advertiser specific constraints that you can't serve two advertisers on the same page next to each other, or anything like that.",
                    "label": 0
                },
                {
                    "sent": "Those combinations actually have to be removed pre modeling and so all of those run through and some examples are.",
                    "label": 0
                },
                {
                    "sent": "So if you push a particular offer to ensure a minimum maximum number of service when you have like a new product launch.",
                    "label": 1
                },
                {
                    "sent": "If you want to serve it a lot so that you can have a lot of reach, or for business partitioning if an advertiser wants to see a certain amount on the homepage, or experience exclusions when it's just two campaigns can't be served side by side.",
                    "label": 1
                },
                {
                    "sent": "Whether it's competitive or for other reasons and then.",
                    "label": 0
                },
                {
                    "sent": "Another constraint in the applied setting is exploration versus exploitation.",
                    "label": 1
                },
                {
                    "sent": "So when I interact with sales teams or advertisers, they in general don't like the exploration side of things because it's just not revenue producing and they really cringe at the thought of giving away the optimal surf.",
                    "label": 0
                },
                {
                    "sent": "So that's one thing we have to kind of push back on a lot and then these effects all come with an opportunity cost, but it's just how things work I guess in that setting.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And then in conclusion, exploration and exploitation balance is a daily concern.",
                    "label": 1
                },
                {
                    "sent": "So we're constantly interacting with our clients, advertisers, discussion of you know what the right percentages and finding kind of going to them with our science and having them come back with what they're comfortable with for exploration and the actual data is much larger and sometimes messier than the Pascal data, and that we process it in real time.",
                    "label": 0
                },
                {
                    "sent": "And so I think that.",
                    "label": 0
                },
                {
                    "sent": "A lot of situations we can actually find better signal than a set data set that would be handed out in the way that it was for this challenge, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and that's it.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry, so we given visitor profile night car.",
                    "label": 0
                },
                {
                    "sent": "Sorry I don't even have the slides up there.",
                    "label": 0
                },
                {
                    "sent": "There we go.",
                    "label": 0
                },
                {
                    "sent": "So for a given visitor V. Have to choose which piece of content we want to display on the web page, and let's say there's any options, so we have to like choose one of these options to like present to the visitor and we want that guys interested enough to like click and to learn more or whatever.",
                    "label": 0
                },
                {
                    "sent": "So we want to maximize engagement which is measured by clicks.",
                    "label": 0
                },
                {
                    "sent": "An IF we sort formalize that.",
                    "label": 0
                },
                {
                    "sent": "It's like we have N visitor an option index pairs in input, and the algorithm has to output the index.",
                    "label": 0
                },
                {
                    "sent": "Of the pair for which click is most likely.",
                    "label": 1
                },
                {
                    "sent": "And the challenge is about the challenge was about finding good algorithms to do that.",
                    "label": 0
                },
                {
                    "sent": "The thing is, we can't really evaluate algorithms live because we don't want to impact users experience.",
                    "label": 0
                },
                {
                    "sent": "So we are using the data provided by Adobe.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the beta was the data consisted of about, I think 20,000,000 records where you would have a visitor feature vector and an option index and a click indicator that would tell you whether or not the person clicked when presented that particular piece of content.",
                    "label": 1
                },
                {
                    "sent": "Note that all options have the same overall clickthrough rate, so it's not like you could have used bandit algorithms where arms would be the option index, and then you would have tried tonight.",
                    "label": 0
                },
                {
                    "sent": "Look for the the index that has overall the highest clickthrough rates we really wanted to push people to use the visitor information.",
                    "label": 0
                },
                {
                    "sent": "The problem though, is that it's not that easy to evaluate algorithms.",
                    "label": 0
                },
                {
                    "sent": "What we should do is that we should ask for a given visitor feature vector.",
                    "label": 0
                },
                {
                    "sent": "We should ask the algorithm which option do you think we should present and then.",
                    "label": 0
                },
                {
                    "sent": "We should evaluate that, but in the data we're going to have like for a given visitor, we're going.",
                    "label": 1
                },
                {
                    "sent": "The data says that this visitor was presented, for instance, option number 2.",
                    "label": 0
                },
                {
                    "sent": "And then we have observed what this visitor does when presented option #2.",
                    "label": 0
                },
                {
                    "sent": "But then the algorithm says for this visit.",
                    "label": 0
                },
                {
                    "sent": "So you should present option #3 where you don't have that in the data you have only observed how the user or the visitor reacts to option #2.",
                    "label": 0
                },
                {
                    "sent": "So you know what you do then how should you evaluate the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you could.",
                    "label": 0
                },
                {
                    "sent": "I guess you could just you know reject.",
                    "label": 0
                },
                {
                    "sent": "This, but there's a.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's not clear how to evaluate algorithms, and I'm sure we come back to that in the discussion section because the participants have come up with with other ideas too for other challenges.",
                    "label": 0
                },
                {
                    "sent": "But anyway, for this particular task that we considered, we tried to stick to the previous formulation as much as possible, so we still have a batch of six visits, option pairs, and we still want to get the index of the pair that's most likely to be associated to click, but The thing is.",
                    "label": 0
                },
                {
                    "sent": "The visitor is not fixed anymore.",
                    "label": 0
                },
                {
                    "sent": "These batches of visits, option pairs, we get them from the data, so we just take them in chronological order.",
                    "label": 0
                },
                {
                    "sent": "Take the first 6 and the following six in the following six, and so on and so on.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then we look up, so we ask the algorithm what's the index of the most likely to be associated to click.",
                    "label": 1
                },
                {
                    "sent": "If there was indeed a click, then the algorithm gets a reward of 1.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm only observes the behavior of the visitor.",
                    "label": 0
                },
                {
                    "sent": "That's in the independent.",
                    "label": 0
                },
                {
                    "sent": "It selected when presented the option again in that pair, so it only observes this bit of the reward.",
                    "label": 0
                },
                {
                    "sent": "It doesn't observe all the rewards for the batch or batches, so it can see that this double objective is learning the mapping from visitor option to reward at the same time you want to you want to get more rewards.",
                    "label": 0
                },
                {
                    "sent": "So you've got this learning and optimization objectives.",
                    "label": 0
                },
                {
                    "sent": "Hence exploration exploitation.",
                    "label": 0
                },
                {
                    "sent": "Maybe a couple of remarks before moving on to the next slide.",
                    "label": 0
                },
                {
                    "sent": "So again, all the visitors in any given batch are different and they've never been seen before.",
                    "label": 0
                },
                {
                    "sent": "An all options might not be represented.",
                    "label": 0
                },
                {
                    "sent": "In any given batch, and there can be several clicks or no click at all.",
                    "label": 0
                },
                {
                    "sent": "Anne miss.",
                    "label": 0
                },
                {
                    "sent": "Writes an again because the click through rates are the same overall for each option we really need to use the visitor features if we want to make better predictions than random because, like the monthly unbend, it is just going to perform like randomly.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They will have the same main rewards.",
                    "label": 0
                },
                {
                    "sent": "The way that we evaluated algorithms was that we asked people to write them in Java and then compile it and then submit the Java Archive to our server so people would log in.",
                    "label": 0
                },
                {
                    "sent": "And they would upload their click predicted jar and during Phase one this would like instantly launch the evaluations of the algorithms on the on the data.",
                    "label": 0
                },
                {
                    "sent": "So we used.",
                    "label": 0
                },
                {
                    "sent": "15% of the whole data for phase one and thing is that people didn't know anything about the data when it started, but they could like submit a first version.",
                    "label": 1
                },
                {
                    "sent": "Get this callback, submit something else, try a different idea, and then get this score.",
                    "label": 0
                },
                {
                    "sent": "Actually, the feedback that was given to them where the logs here where you would have for each batch.",
                    "label": 1
                },
                {
                    "sent": "For each iteration you'll be given the reward that the algorithm got the time expense and the memory.",
                    "label": 0
                },
                {
                    "sent": "Also that was used.",
                    "label": 0
                },
                {
                    "sent": "On the leaderboard was alive, so you know as soon as the evaluations will be finished, it would update the leaderboard and so on.",
                    "label": 0
                },
                {
                    "sent": "An phase two was.",
                    "label": 0
                },
                {
                    "sent": "So for phase two, we used up most of the day.",
                    "label": 0
                },
                {
                    "sent": "Today 85% of the datasets.",
                    "label": 0
                },
                {
                    "sent": "But then people could only submit once, but they had the phase one.",
                    "label": 0
                },
                {
                    "sent": "Data would given given it to them so that they could not manually tune their algorithms.",
                    "label": 0
                },
                {
                    "sent": "On their own, with that face one data, but then they could only submit once and then we run the algorithms again on the whole of the data.",
                    "label": 0
                },
                {
                    "sent": "I mean on the 85% of the data the phase two.",
                    "label": 0
                },
                {
                    "sent": "So that's the result.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To present now quickbird about the resources that we had, actually, all the evaluations were done on the grid engine that we've got a UCL and we allowed 100 milliseconds per batch, which is sort of this kind of time you would allow for, like the latency you would allow for.",
                    "label": 0
                },
                {
                    "sent": "I guess we're serving for deciding what to serve 2.",
                    "label": 0
                },
                {
                    "sent": "So visitor and then we had each node.",
                    "label": 0
                },
                {
                    "sent": "On the grid engine had 4 gigabytes of memory, could have requested more, but then they would have taken more time to get available nodes and then we have to divide the Java virtual machine memory by two is actually we needed to keep a copy of the click predictor instance in case the computations would run for more than 100 milliseconds would just stop it and then just to make sure that you know you would, you wouldn't have like 1/2 of dated model.",
                    "label": 0
                },
                {
                    "sent": "We would revert back to the previous one.",
                    "label": 0
                },
                {
                    "sent": "And one more thing regarding the time, 100 milliseconds, so that's both for choosing which option to present.",
                    "label": 0
                },
                {
                    "sent": "I mean which visit option you want to try and false updating your model based on previous.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observation as the Phase one leaderboard.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have also grouped by teams.",
                    "label": 0
                },
                {
                    "sent": "And there's also.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chart here so you can see that it's.",
                    "label": 0
                },
                {
                    "sent": "And the top three are performing right?",
                    "label": 0
                },
                {
                    "sent": "Significantly better than random.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you zoom in on the top three, where in reality seems to be like a clear winner.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now onto the phase two results and you expect it afternoon.",
                    "label": 0
                },
                {
                    "sent": "Um, so the random was.",
                    "label": 0
                },
                {
                    "sent": "Was this as a baseline?",
                    "label": 0
                },
                {
                    "sent": "I'm just writing with the random words that some UN monton University slogan.",
                    "label": 0
                },
                {
                    "sent": "Number three was the CNS team.",
                    "label": 0
                },
                {
                    "sent": "There not here today, but yeah, they didn't do bad.",
                    "label": 0
                },
                {
                    "sent": "And now the top two, so it's going to be between.",
                    "label": 0
                },
                {
                    "sent": "Orange Labs in an area where is inria OK.",
                    "label": 1
                },
                {
                    "sent": "Number two was.",
                    "label": 0
                },
                {
                    "sent": "Orange labs one area, so I think they deserve and approves.",
                    "label": 0
                },
                {
                    "sent": "So let's nations the winners.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's actually the same order as we had for phase one.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So SNR is.",
                    "label": 0
                },
                {
                    "sent": "Orange Labs in INRIA what we've got here in yellow is actually the performance.",
                    "label": 0
                },
                {
                    "sent": "The sorry, the performance they would have got if they had submitted the algorithm that they submit it at the end of Phase One.",
                    "label": 0
                },
                {
                    "sent": "So at the end of Phase one, they received the data, then they tune their algorithms and then they made another submission which.",
                    "label": 0
                },
                {
                    "sent": "Which are referred to as the Phase two submission and you can see that they got a slight increase in performance.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just wanted to introduce the notion of uplift, which is the score of the algorithm divided by the score of the.",
                    "label": 1
                },
                {
                    "sent": "Random algorithm minus one so that the uplift is 0% if you're not using.",
                    "label": 0
                },
                {
                    "sent": "If you're doing random, I said if you're not using this feature, but if you're doing random, it's in Europe.",
                    "label": 0
                },
                {
                    "sent": "Sent an inner ear, got 106.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once I've broken down the results by participants have also displayed the uplift and also the time that was taken by the algorithms to run.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's not really clear weather, like for instance #2 beat #3 and #3 beat #4 'cause you know the it's likely that the algorithms are stochastic and also.",
                    "label": 0
                },
                {
                    "sent": "Although batches are presented in the same order, the elements within the batch may have been presented in different orders that different launches of their Java virtual machines are different, which is of.",
                    "label": 1
                },
                {
                    "sent": "For each phase.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evaluation and.",
                    "label": 0
                },
                {
                    "sent": "Last slide on the resource is again.",
                    "label": 0
                },
                {
                    "sent": "If if we had 100 milliseconds for batch, given the number of batches we had, we could have run for 78 hours and then re algorithm only took three hours 40 minutes I guess.",
                    "label": 1
                },
                {
                    "sent": "Now you know it might be because the amount of data that was given to the amount of memory, so that was available was a bit.",
                    "label": 1
                },
                {
                    "sent": "Small, so there wasn't much to compute on.",
                    "label": 0
                },
                {
                    "sent": "I mean, I don't know 20 gigabytes of data.",
                    "label": 0
                },
                {
                    "sent": "You could only store 1.75.",
                    "label": 0
                },
                {
                    "sent": "It might have been this.",
                    "label": 0
                },
                {
                    "sent": "Maybe that you know people would have been able to exploit their confessional budget abit more if they would have had more things to compute on right?",
                    "label": 0
                },
                {
                    "sent": "And that's it for the for the challenge presentation.",
                    "label": 0
                }
            ]
        }
    }
}