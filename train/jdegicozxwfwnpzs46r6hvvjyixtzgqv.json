{
    "id": "jdegicozxwfwnpzs46r6hvvjyixtzgqv",
    "title": "Learning shared representations for object recognition",
    "info": {
        "author": [
            "Antonio Torralba, Center for Future Civic Media, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "July 2006",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/oh06_torralba_lsror/",
    "segmentation": [
        [
            "So this will be a very specific problem in which multi task learning can be very interesting.",
            "So the first thing so because I don't know if I will have enough time to finish.",
            "So I want to make sure that I mentioned the collaborators.",
            "So the first is Alexander is relative.",
            "Now postdoc at Berkeley.",
            "Kevin Murphy."
        ],
        [
            "And so this thing is because now that there is not a lot of money for grants, we are forced to use very cheap setups for vision.",
            "So other liver professor at MIT and Bill Freeman, also professor at MIT.",
            "So what I'm going to do first, I'm going to give a."
        ],
        [
            "There's more overview of object recognition.",
            "The current state of the art, and also some review of multitask learning applied to object recognition.",
            "And then I will talk talk a little bit about my own work, but I'll try to give you an overview of what is going on on the field and also pointers to data sets and so on, so you can.",
            "You can apply your algorithms to this problem.",
            "So the classical approach in object detection, at least the one that is the most successful today, is just take a picture.",
            "And if you want to detect a particular object, let's say your screens.",
            "But they are going to do is train a classifier.",
            "Just back from this image all possible patches at all possible locations on all possible scales.",
            "For each Patch you apply your classifier that you train with examples of screens and background samples, and your classifier is just going to put all the screens in one side or the background samples on the other side.",
            "Very classical approach and it worked very well, especially because there had been a lot of advancements in machine learning that allowed to learn these functions very, very efficiently and very very finely tuned because there are a lot of patches here.",
            "And only three of them correspond to screens, so it has to be a very selective function.",
            "So the success of this kind of approaches has been especially."
        ],
        [
            "Useful to solve this problem of face detection, which has received a lot of interest and it's a problem that you can say that today it works and by work I mean that you can sell this product and somebody will pay for it.",
            "So there are a lot of approaches, a lot of people that have been working on this.",
            "And the problem with this is that it created in computer vision that."
        ],
        [
            "Single class class 8 So everybody was working on face detection an the only thing that you could do to get a paper published was basically object face detection and they didn't care at all about other objects then.",
            "So this created what I call so."
        ],
        [
            "Thing is also the fact at some point some people wanted to apply this to multiclass.",
            "So what to do?",
            "OK, something that works very well for one class.",
            "Let's do it for any classes.",
            "So you want to detect faces at different orientations, train one classifier for every orientation.",
            "Or you want to detect different objects.",
            "Well, train one classifier for each different object or different views of a car.",
            "One different classifier for every different viewpoint of a car.",
            "So very good.",
            "So this leads to the problem of the head in the what I call the head in the coffee beans problem, which is what computer vision is trying to."
        ],
        [
            "Today, so I want you to solve this problem.",
            "So can you find ahead."
        ],
        [
            "In this image.",
            "Wells is anybody finding it?",
            "Yeah yeah OK, it takes some time.",
            "You can see that you cannot solve this problem in real time, but we are asking computers to do this now.",
            "If anybody hasn't seen it yet, here it is the head."
        ],
        [
            "So this is what we ask computers to do when we're trying detector for face detection, so you can see how frustrating is the life of an object detector today, sorry.",
            "Yeah, yeah so, but this is the only thing that detectors can do today, So what is an image for object detector today is just a collection of coffee beans so distractors that are trying to make your life as hard as possible.",
            "Within all these factors there is 1 sample of your target and you have to solve this problem.",
            "But this is far from being the real problem that vision has to solve.",
            "Normally things are more strict rated and done this and you have all sorts of other kinds of objects that you will also like to detect and there are contextual relationships between them.",
            "And so on.",
            "So this is not the real problem that we should be solving, although it's nice that some people can actually solve this thing, and so here are some symptoms that have this approach."
        ],
        [
            "So the single class approach.",
            "First imagine that you're trying to detect pedestrians.",
            "This is a classical output of a state of the art pedestrian detector, so here is a pedestrian and you take the pedestrian.",
            "And here there is a false alarm.",
            "OK, well, it looks kind of pedestrian, so we have one, but it could crash kind of arms and so on.",
            "So you can understand why it makes a mistake here.",
            "But look what happens on the image.",
            "It doesn't make any sense, is not on the ground.",
            "It doesn't relate to this other person here at all, so this wouldn't be a mistake that anybody will make.",
            "Here there is a keyboard detector, so here is a correct detection.",
            "Here is a keyboard that was not detected here.",
            "There are a bunch of false alarms and actually you take this Patch here and you compare it to this color detected keyboard.",
            "Well, they're very similar.",
            "It's very hard to say that this is a keyboard unless you put it on context, sorry.",
            "It is not a keyboard.",
            "OK, it's difficult to say it is not a keyboard.",
            "Thank you."
        ],
        [
            "So here are the results.",
            "A bunch of images here.",
            "Again just running a state of the art keyboard detector.",
            "So these are images in which the detector says there is low probability of having a keyboard.",
            "Here there are images in which the detector says there is a high probability of having a keyboard, just some logistic regression applied to boosted classifier so.",
            "OK, here this one keyboard here.",
            "There are some keyboards, but here there are images in which the system thinks that is a keyboard present, but there is of course no keyboard present, but even even more is this are St since that is not it couldn't be a keyboard here, it doesn't make any sense.",
            "Now here there are images with low probability, but so many of them are actually office in, so it's likely that there is a keyboard somewhere here, but we are not seeing it.",
            "Lips.",
            "So."
        ],
        [
            "So in an image like this one, there are a lot of objects and we are interested in detecting all these objects and not just one.",
            "So in this image we know that there is a keyboard present even though it's very difficult to see it now.",
            "But here there must be a keyboard.",
            "An innocent like this one within or there is no keyboard, but in fact there is a keyboard here.",
            "But systems don't make even this kind of mistakes.",
            "They don't care about these things."
        ],
        [
            "Another symptom is the object representations that are arrive.",
            "So imagine that your goal is to detect this one way sign this particular viewpoint.",
            "You are not even interested in different viewpoints of the one way sign.",
            "So what is the best representation that you should use so that you can detect this traffic sign?",
            "So if you're only interested in detecting this object, so maybe something like template matching is going already to work so OK, you could have some part based representation of the object, because maybe there is some ability of the.",
            "That you want to be robust to it, so you don't want to have just one unique template, but you want to have some parts that are relative to some reference frame of the subject so that they allowed for some small distortions.",
            "And indeed, if you just such a representation, you reach very high detection rates, because this is a very regular object, very easy to detect.",
            "But the problem is when you look at this part, some of them are very specific, like this arrow here is very specific to this object.",
            "It's very unlikely that this this part here is going to be useful for any other thing than detecting this one way sign.",
            "And in fact, this has been something that's happening."
        ],
        [
            "Any object detection algorithms, like when people interested in detecting cars, the representations that they obtain, are parts of cars and that happened in many, many cases or faces the parts that you obtain that are ideal to detect faces are again parts of faces, and so this all these parts are very specific to this object, so it's very unlikely that these things are going to be helpful.",
            "Helpful for other objects.",
            "So.",
            "Another"
        ],
        [
            "Anthem also is that if you want to take many different object classes and you train the independent classifiers for each one, well, what is going to happen is that as you increase the number of classes, the complexity of the overall multiclass classifier is just going to increase linearly.",
            "So the number of features that you need increases linearly with the number of classes.",
            "Nothing surprising there.",
            "And of course you wouldn't do something like that.",
            "But this is, this is something that people have been doing actually.",
            "So there are a lot of possibilities."
        ],
        [
            "For research and.",
            "In multi class object detection that I'm not really very well explored yet and.",
            "The community is that everybody is specializes in detecting this type of object and that says yes.",
            "Trying to do well.",
            "I wouldn't say nobody I'm going to.",
            "I'm going to review, but if you want to so today things are beginning to change.",
            "But few years ago, if you wanted something something more than a poster, it will be better than you do something like single class of detection.",
            "But today things are changing and now it's possible to begin to work on multiclass, and indeed there are some papers that are starting to do that, but still because it's a very recent thing.",
            "There are a lot of things that are unexplored and many things that people have been talking about here could be introduced into the community, and I think it will be very useful I think.",
            "Taking images, all those things about what typing images taking like I say appears in those images they have.",
            "They can deal with hundreds or thousands of classes.",
            "You mean like image indexing and so on.",
            "Again, there's a group working on those.",
            "There are some kind of concept networks of what you're basically you have images they put to put towards an image.",
            "Yes yes yes yes yes but but I'm talking in object recognition, so those things are more about putting just some global labels to the images.",
            "Yes.",
            "Yeah, so I will make the distinction between them having an image and you have to say that is present or not.",
            "There are several things that you can do to solve that problem that don't require doing detection and there is some work on that on on solving that problem and there are some techniques that just multiclass classifiers and so on, but they don't really explore the problem then the benefit of the fact that you are actually training a multiclass classifier an what is the benefit of doing so, they're just using it, they don't, they don't show that by doing this.",
            "Actually you do better.",
            "So I was from idea, that's why I know there's proof they have this concept network of your what can Co occur also seems like oh they're just in context and so on you mean.",
            "There on your possible occurrence or the relationship location of your object, yes, yes.",
            "So that's another way of so this will fall in this section here.",
            "Can't someone obvious?",
            "And there are some works.",
            "I'm going to say that there is known about this.",
            "There are some things I have been doing.",
            "Some things we have been doing this stuff and there is other groups that have been doing something.",
            "It is not the dominant line of research, that's what I mean.",
            "And most of the research has been devoted to single class of detection.",
            "Despite that, this is probably the real problem that you want to solve.",
            "This is what I'm trying to say.",
            "Maybe if I can that so it's not mainline.",
            "But let's say search image search would actually benefits yes.",
            "Maybe start one main line of research with returns most of the minus this bottom part there.",
            "Yes, so here that is all image indexing and so on can fit here, although there is always in many cases there is a strong disconnect between research and image indexing and object detection and the fact that you could put the two together an there are few words that try to do that.",
            "But most of the time image indexing is just image indexing and they just try to find an image with Flowers and so on and they don't really exploit that match the context.",
            "Relationship so they don't make a big deal out of it, but what they do basically they do collaborative filtering.",
            "Yes yes yes.",
            "So I'm going to focus most on the on the program object detection.",
            "So what is the face in the same match and where it's at sharing this image?",
            "And so on.",
            "And that problem also benefits a lot from multi task learning.",
            "And there are some works on it and I will review some of dawn of those, but there are not that many in.",
            "So the question here is how to build efficient representation for object recognition that benefit from the fact that you have many classes and just one.",
            "How can you achieve better generalization by the fact that you have many other object classes?",
            "What are these commonalities within the different objects?",
            "They may be interesting by themselves, so if we want to learn something about how objects are formed or how the visual system represents objects, this commonalities within objects may have some interest by themselves.",
            "So let me first just give you some pointers to data sets so you'll have the slides on the web I guess.",
            "So you can look at this links and this is not an exhaustive list of all the data sets that exist.",
            "There are many, many different data sets for object detection and most of them, so here I separated them in data sets for object localization.",
            "So those are data sets that have big images in which objects are small.",
            "So the real problem is to detect where the object is in the image.",
            "Then there is database for object recognition that are closer to problems of just attaching labels to an image you don't really need to locate the object.",
            "The object is normally generally big, so you just have to say what are the labels that are attached to that object, similar to what IBM people is doing.",
            "And then there are a set of online annotation tools.",
            "There are some collections and I you should look at this Pascal data set in which they have now 10 object classes and I'm going to describe just very briefly the data set that we have.",
            "That is the label mean data set.",
            "But you could check this other data sets on the web so that we build because we were interested in ingesting really many many object classes an there are not good data sets for, not for that yet.",
            "So we created this annotation tool that is online so anybody can go to the data set and label images.",
            "So this was built also in collaboration with Bryon Russell, a graduate student at MIT with Bill Freeman.",
            "So this data set now has a lot of objects, so let me show you first image of the annotation tool.",
            "So if you go to the website you will find something that looks like this and when you have an image and you can trace polygonal boundaries around the object and then will bubble, will show up and it will ask you what's the number the name of the object and you are free to introduce whatever you want.",
            "Anybody is free to go there and to do it, and we had a lot of people going and labeling objects, so now there are like 88,000.",
            "So since this is like was made.",
            "And there have been about 10,000 new objects labeled by just people on the web, and it's amazing that Despite that.",
            "People are given no instructions, so the only instructions is this.",
            "There are no constraints on what people can do.",
            "People behaves quite consistently an the quality of the labels is quite good.",
            "Sometimes there are some accidents like people just labeling something random or labeling somebody.",
            "Parts that were not meant to be labeled.",
            "But there are not that.",
            "I can show you some examples.",
            "So here are some statistics of.",
            "The data set now, so these are examples of images labeled.",
            "The images are very big and they have like several.",
            "There are five megapixels 3 megapixel images, so this is the average quality of three different objects which are among the most difficult objects to level, like trees and cars and share some people.",
            "You represent an object edges, yes, so here the representation of the object is just a polygonal boundary, so just this tunnel outline.",
            "So if there are holes, this is not captured here yet.",
            "Although.",
            "So if there is occlusion then there are multiple ways of handling this and whoever is labeling it is free to decide what is going to do.",
            "So you may have labels that are overlapping, like in this case.",
            "It's difficult to see here, but the road the cars are a little bit overlapping with the road segment, so it is relatively easy to add some depth ordering and just decide which is in front of what so that you know what is including what.",
            "And so there are about 90,000 objects labeled now and there are like 2000 distinct object names and there are multiple levels levels of labeling that have since labeled.",
            "There are objects that are parts.",
            "So on and that is it is freely available, so you can download it anytime and there is also a MATLAB toolbox that goes with this that allows you to query to stack segmentations and so on.",
            "So expect the datasets for training classifiers.",
            "How do you do that?",
            "If you want to?",
            "Vented the images spots.",
            "If you want to use your data set.",
            "So so OK.",
            "So one of the fences from here are you because the hardest part is to get the labeling done.",
            "After that you can.",
            "You can select images and create some benchmark.",
            "So we haven't done that yet.",
            "And the reason is that the idea behind this data set was to create a data set in which people can play with it and have their own idea.",
            "So we don't want to impose.",
            "OK here is the problem you want to solve.",
            "Here is the 20 object classes that you have to work with.",
            "No here there are 2000 objects and you could pick whatever you want.",
            "And you can make your own selection of images and then you're free to pose them, because all of these images are taken by us, so they are Copyright free and you can just make their own benchmark.",
            "So I think that does at this point is maybe the most interesting way of going.",
            "Test is detectors without these big images are labeled.",
            "If you also want to provide a data set which is used by different people, different groups algorithm, you want to provide the same yes.",
            "So so when you do decide to just portion of the data set and you make a publication, you can say OK, here is the portion of the data set that I just here is the results I got and how people can compare to you.",
            "But they are not forced to just only that data set.",
            "They could in principle leverage the data here to.",
            "Construct a different data set.",
            "So so quickly like query and then obtain pointers to images, yes?",
            "According to the polygonally.",
            "1st, it's around the car, so yeah, so I can extract regards to pay with yes.",
            "So the MATLAB toolbox has query tools you can say OK, give me all the images that have cars and buildings and it will give you pointers to all these images and they will give you the polygons too.",
            "So here is so the online tool allows you also to do queries just to get a sense of what is there.",
            "So this is an example of images label so it's semi labeled as some images are more labeled and others and so on so.",
            "Algorithms have to be robust to deal with.",
            "Maybe objects that are missing that are not labeled and this is an example of Quirino here is just querying for dogs, so these are examples of dogs and dogs are there are 20, but then cars there I think like 1515 hundred cars labeled and so on.",
            "Who yeah well when do connect?",
            "Yeah people.",
            "Vision algorithm know know know know.",
            "Oops.",
            "They are not normalized, so the number of this reference point can be.",
            "In what do you mean normalize?",
            "Or that person is always labeled with the same points in the same location, you mean that?",
            "Oh yeah, no.",
            "No different polygons are going to have different number of points.",
            "So in many cases, many algorithms are only interested in bounding boxes, so I struck Ting abandoned box from here is very easy Ann in most of the cases.",
            "So independently of how detailed was the Polygon, the bounding box is always very accurate, but Furthermore it allows you to have a more detailed segmentation is not.",
            "I mean this is the average quality Sojourner going to get much better than this, although there are some people that are extremely, I don't know on drugs or something and they give you like.",
            "40 points to level up person and in some other cases like this is really important to have something more like a segmentation because abandoned boxes is not tight enough.",
            "But people abandon box in many cases is good enough.",
            "OK so also like if you go to my website there is a link to.",
            "I'm another set of tools that you can use for object recognition, and it implements most of the things that I'm going to talk about well, but only for single class objects.",
            "But the representations that I will talk about our implemented here, and this was part of a class with failure Fergus, so there are a lot of slides and a lot of code, well documented specially is good.",
            "I think for people that is starting like steel and so on.",
            "So.",
            "So now that we have many of the classes, what do we do with them?",
            "So we are going to have many different object classes, many different viewpoints, and also we're going to have things like a styles and lighting conditions and so on that we may be interested in knowing.",
            "So what do we do?",
            "We build a classifier for each one or we try to build this multiclass classifier in a more efficient way.",
            "So.",
            "Just ensure representation for objects, so some of the questions will be is learning the object class.",
            "1000 is easier than learning the first object class.",
            "In principle the answer should be yes, although in most of the cases until now the answer was just the same.",
            "It doesn't matter how many classes you know.",
            "So then is how can we transfer knowledge from one object to another?",
            "And are the share properties between different objects interested by themselves?",
            "For instance, here you have this will cheer is sharing properties from chairs an bikes and but the part that they share also meaningful by themselves, so that maybe there is something more that you can do by sharing parts between objects.",
            "So I'm going to review some of the things that have been done on multi task learning, especially applied to vision.",
            "So this is not a review.",
            "Or multi task learning, but just some of the things that had some vision applications that I thought contains some interesting insights, so it's not an exhaustive review either, so maybe one of the first papers is this paperwork Carvana, in which he does is he says OK if you want to solve end tasks you could train in principle one neural network for each task independently.",
            "Or you could train a neural network that is that has multiple outputs.",
            "Ann, the hidden units are share.",
            "So what can you do with that?",
            "It does this by do anything, and the answer is that yes it does by you and so they had a very simple, very simple visual application that is.",
            "Coming back soon, yeah, but he's he's he's only aware of the practical work, not theoretical work.",
            "So now I'm so I'm not going to review the multi task learning community.",
            "There is a lot of work and I'm just going to mention some vision applications.",
            "OK, because.",
            "Kohana people gotta lot of attention but the idea is just yes.",
            "Yes, so but they had vision applications on them OK?",
            "Yeah, so this is what I meant.",
            "I'm only going to review some of the papers with vision applications, so of course there is a lot of theoretical work and so on.",
            "I'm not going to enter their non specialist on.",
            "Yes yes.",
            "So yes yes.",
            "So one community that had a lot of that make use of multi task learning very heavily was always the character recognition community.",
            "Although the problem is so tight that.",
            "They fall again, almost in the same problem that people working only faces is the fact that, OK, they transfer knowledge within objects, but they are just so comes the objectives or constraints that you cannot really learn much about.",
            "General Object Recognition is OK, you will do great on character recognition, but you apply those systems to general recognition and it doesn't work.",
            "It doesn't perform that well because you are missing many of the other features that are important to recognize objects, not just some pieces of characters and so on.",
            "So so here in in Carvana his paper he tried to detect doorknobs.",
            "So what he said it is OK, your primary task is to that door knobs, but you could.",
            "You could design other tasks that are not the one that you want to solve, but that are related and I think this is an interesting idea in object recognition community in the fact that OK, you want to detect faces, but there are many other tasks that maybe are related with face detection that you could also try try to train your classifier to do and that will help you to do better on face detection.",
            "Even if your task is just to do face detection.",
            "So some of the tasks that he define is.",
            "Like telling what is the horizontal localization of the doorknob.",
            "This is the primary task to sign in.",
            "If the door is single or double to say, where is the center of the door to say what is the width of the door, and so on.",
            "So a number of tasks that The thing is not really that you want to solve, but probably some of the features that you need to solve.",
            "These tasks are also useful to detect the doorknob.",
            "And in fact, then machines is when you just this additional tasks to do better in the doorknob detection.",
            "So another work is Sebastian Thrun and again so one of the things that he wants to do is to learn invariances.",
            "So here are the variances that he wants to learn is translation invariants.",
            "So he's training different objects you want to detect different objects and the final task there.",
            "Real goal is to differentiate between shoes and glasses.",
            "But at the beginning you are not going to train the system to do that.",
            "You trained assistant to the tech to recognize a bottle, a box hat, and so on, and so the internal structure of the network again is just another network, so it's nothing new from the machine.",
            "Learning viewpoint is just some of the ideas that emerge from that, so the network the only thing that is doing is learning this invariants defined, the translation doesn't matter, and again, it shows that we're sharing.",
            "It helps, so you need less training samples to get the same performances, and so on.",
            "And I guess this is sensitive to.",
            "The choice of their task that your trainer.",
            "I mean yes, yes, very unlucky.",
            "We get asked him something very specific to this task that doesn't generalize to other tasks.",
            "Yes, yes, yeah, you have to choose the task appropriately given the structure that you are going to use so that it works.",
            "Otherwise your paper gets rejected.",
            "Which is the final goal?",
            "So one thing that happens is so these papers were mostly from the machine learning community.",
            "Trying to do some vision and what normally happens at least one of the impressions that has people in computer vision is that when machine learning does vision is always very simple toy problems, very happy problems and computer vision.",
            "We are much better in finding very very good data sets that are also very hacky, but you don't notice.",
            "So we have problems that look more interesting maybe.",
            "So here is another paper, but Eric Miller at all.",
            "This is computer vision people.",
            "So here what they try to do in this case is character recognition an what they say is that any character that you see written is actually the result of a generative processing, which you have latent image.",
            "That is one of the characters in a Canonical reference frame plus a transformation.",
            "The transformation is shared across all characters, so any character can follow.",
            "The same set of transformations, and the only thing that makes a distinction between one character or another, is this latent image.",
            "So if.",
            "Yes, yeah.",
            "And so the only thing that you have to learn here is if you learn all the set of transformations.",
            "Let's say from the first 5 characters you can then learn the other five from just one training sample, because as soon as you have that, you can look at what is the most likely transform.",
            "You put that character as a latent image and then now you can generate any other instance of the character.",
            "Of course you have a little more of examples.",
            "You can get a better image of the latent image, but.",
            "Is going to work with very few training samples and so here what is shared is the set of transformations and again here the information is actually very simple ones, they're just done with this flow fields to have question.",
            "But for transformations is kind of a low right?",
            "Just distortion all those, yeah.",
            "That there's another way to do that.",
            "We should just using set classification more like them while they call related to a thing called multi instance learning.",
            "So essentially you want to say this is a zero for all the transformations foremost and you can read the kernel, understand where whatever.",
            "But essentially you are sending stuff.",
            "And the other that seems to be more relevant in today's that yeah you can.",
            "You can do many things an I mean it's also learning the manifold.",
            "Now you have a set of parallel manifolds and the only thing that you need to know is the displacement between them.",
            "I mean there are a lot of things that you could do or just learning the distance and the offset between the objects.",
            "So you could do many things.",
            "This is some early things Ann.",
            "This is computer vision, people doing machine learning.",
            "So don't take them very seriously.",
            "Kind of a translator transformation kind of known.",
            "Yes, you can do those things.",
            "I mean that this set of transformations you could define it a priority.",
            "Yes, yeah.",
            "OK. With the shooter exactly.",
            "For executive situations, no collection of potential transformations, and then you are trying.",
            "Difference and the difference.",
            "Yes yes yeah no.",
            "When I heard you talking this is exactly this.",
            "And of course I mean this is the set of transformations here maybe trivial so impressive would have to find this a priority and the only thing that you need to know maybe is what is the variance and how strong this what is the displacement that you are allowed.",
            "Now you could do something like that here.",
            "They tried to do something more general and they apply this also to color transformation.",
            "So they applied this framework to something else.",
            "Then just character recognition, in which case the transformations are less known.",
            "But as always the more inside you have about the problem and the more.",
            "Constraint The problem is is more likely that you are able to define these things up.",
            "Really, you don't have to learn them, and if we knew exactly what's the process to generate object, maybe there will be no learning whatsoever.",
            "Just put their the basic axioms and don't have to train your system.",
            "What was the idea that the other day that we formed by?",
            "The idea here.",
            "Oh, here he is also learning some invariances.",
            "But here the invariances just translation and the problem is in many cases what happens is when you have a problem.",
            "That is toy a toy plane like this one and it's too simple.",
            "Maybe the invariances the system is learning have nothing to do with invariants that you really need to solve the problem.",
            "For instance here because the background is always this great thing.",
            "Maybe what is just learning is block tracking.",
            "So where is the blob is not going to solve any real problem like that.",
            "But because the problem was very toy.",
            "It gets a solution that seems to do being doing something, but no problem has been really been solved here, but the idea is that sometimes the idea is what matters.",
            "Somebody can find a better architecture that is going to solve the real problem.",
            "Once you have the intuition that you need to do.",
            "In and then there is a lot of work in biology and models of biological visual system in which.",
            "When you try to detect recognize many of the classes, of course the visual system has this hierarchy of different levels of processing that is shared across different objects.",
            "So all this work in psychology and in biology and modeling, the human visual system are also using this shared architectures to learn multiple object classes.",
            "But in general, again.",
            "They normally don't make any claim about what is the benefit of having something like that, so one clear benefit is the fact that it's going to be more efficient, not just features do not have this linear increase in the computational cost, but another benefit is the fact that there is some knowledge that gets transferred to one object on another, and that's normally not mentioning the papers, so they are not aware, despite the architecture is probably already doing it.",
            "And although people is beginning to get conscious of this fact now in the computer vision community.",
            "So another very common representation for objects is what is called the constellation model, in which an object is represented by a collection of parts and this model was probably introduced by Fischler Anish Lager, although there were some other previous work, but this one is the one that got really attention, and basically if you want to represent the phase, whether you have you have a set of seven parts, they are connected by Springs to tell you that there is some flexibility in the locations of the different objects.",
            "In so here, like four faces, well, you can have, so this is what we just investments here is work by Fergus yet pronounce sermon in which they model of just also using exactly the same structure.",
            "And there are a bunch of algorithms that are based on this idea.",
            "So an object is represented by a collection of parts that have flexible positions and this representation also can use multitask techniques from multi task learning.",
            "So maybe one of the.",
            "First papers to choose this kind of architecture for paper based modeling of objects was work by Ferguson Perona, in which what they do is they have a constellation model for representing objects, let's say faces.",
            "So face is going to be represented by three parts.",
            "This is just a toy example, three parts and the relative location of the parts may change from image to image.",
            "But what is interesting is that the way that you are going to learn the configuration.",
            "So at the beginning the system is just given a bunch of faces and the system doesn't know where the faces are or where the parts are.",
            "But he knows about many, many other object classes, and this is going to be used to learn a prior distribution on what are the parameters for the model and the parameters are going to be what are respected locations of the parts relative to the center location of the object and what are going to be.",
            "What is going to be the appearance of every part.",
            "Let's say some PC components.",
            "Exactly what they think is in some cameras when they have to do a site on the power show, anything that is they have some kind of stuff.",
            "They train the train detector on lots of images and get some priority as to where it should be brighter and version.",
            "I think that Canon has some system of its type.",
            "Maybe you know more than me.",
            "No, I don't.",
            "Yeah, I don't know whether the what they do there and decide on exposure, yeah?",
            "Yeah, I don't know.",
            "I have a question.",
            "OK so basically here but they are using the other objects to constrain what is the space of possible model parameters.",
            "So now they're going to just this prior to learn a model for the face and they expect this model to be not too far away from what you will expect just from the statistics of objects.",
            "And so here are some examples of how do they learn a model of a piano.",
            "So here there is parts detected on the image and this is the model that they obtained for the piano when they train only with one.",
            "Training sample, so in this case this is the location of the parts.",
            "They constrain the model to have only four parts.",
            "And what happens here is that this thing here.",
            "This location is very very close to the expected.",
            "The mean of all the other objects.",
            "So here now this model is driven just by the prior as gentle.",
            "There's more and more training samples.",
            "The model begins to get more specific to this object and it's just regular eyes a little bit by the by the player I'll finally with 15 training samples you get this different model that is maybe.",
            "More close to what do we expect to find in the piano and respect to find this?",
            "And these are some performance plots in which they compare what happens as you increase the number of training samples.",
            "What is the performance server that you get?",
            "This is when you have this project on the model parameters and this is when you train each model independently.",
            "And then find that they converge much faster when they had this prior again, this project is a very weak, very weak sharing.",
            "Now because the only thing that can communicate, communicate information from one object to another is this expected space of parameters?",
            "Now what is the more likely parameters that you may have from other objects and all the objects are constrained by this prior in the same way?",
            "Maybe you want to have models that are a little bit richer than that, and then there is also work by cramp, given an ammit in which they try to do against character detection and what they're going to do is they're going to train a classifier.",
            "They use some variant of boosting in which they're going to train of just incrementally, so they start with one object, they select all the features that they need to detect that of that character on the image, and then they're going to train a second character and what they're going to do is they're going to try to reduce.",
            "As many features from the first one as possible, and then for the third character, they're going to try to train.",
            "Try to reduce as many characters parts from the 1st and the 2nd character, and so on and what they find is as you increase, the number of classes that you have, this kind of logarithmic growth of the number of features that you need then.",
            "But again, in this paper they don't really make any claim about the fact that.",
            "Not just, it's not just giving you an an improvement in the complexity of their classifier.",
            "The fact that you don't increase linearly is also the fact that you are actually learning faster because the features that you pre selected are better features.",
            "I mean they just just Ingredion have a lower threshold for the.",
            "Just like in boosting, just half a Dictionary of possible features answer the best one incrementally.",
            "Just a greedy procedure to select features have a bias in favor of the existing features.",
            "Yes, so first, yeah, they have a threshold, so the first they select as many features as they can from the previous detectors to reach until they reach on convergence and then they begin adding new features.",
            "So then there is also work by Bart and Shima Newman, in which.",
            "They just patches and let's say that they are.",
            "They have a detector that is able to detect horses, so these are different patches that are good for detecting horses just in just some normalized correlation with the image.",
            "And now you want to take dogs, but you only have one training sample.",
            "So from that training sample you construct a lot of patches, but you don't know which ones are going to be good.",
            "So what they do is they take the horse patches and they look for doc patches that are similar to horse patches that were useful for detecting horses.",
            "And what they claim is that these patches are going to be better for detecting also dogs.",
            "Of course this will only work if there is some similarity between these two objects, but they report some improvement in performances by doing that by doing that done by just training with one training sample, which is very poor.",
            "To distinguish between dogs and horses, OK then.",
            "There is some mixture, but it is still better that you have just one training sample.",
            "I don't know if they make a straight comparison on that, but I have some later results that will talk about that too.",
            "But normally when you share a lot of structure between different tasks, what you get is you improve every independent task, but you get some confusion between the tasks, yeah?",
            "The user feature is that they just use a matching type of.",
            "Every feature, so every feature is just is a mask that you are going to just for doing much.",
            "Normalized correlation with the image applies on threshold.",
            "Different scalings or different?",
            "Yes yes, then to get to get a scaling variance as well as translation invariants, you do it by just comparing the Patch.",
            "The Patch with all possible locations and all possible scales.",
            "In this case, they don't play with orientation, but you could do that, but then it will be really slow.",
            "On this ship feature is different from what you're saying.",
            "Here are more or less in the line.",
            "Sift well, see features is another way of representing some local information.",
            "Here they just patches, but they could have just asked descriptors.",
            "Yes, yeah.",
            "So this if descriptor is basically there are two parts now.",
            "One that is detection of the interest point you are going to look at an image and the text.",
            "Some parts of the image that looks interesting.",
            "I'll actually talk about them later and then a structural representation of that location here.",
            "What they do is as well as the representation they just patches and save descriptors used the SIFT descriptor.",
            "Is nice properties like invariants on the rotation scale in life?",
            "Well, they don't have invariants in rotation.",
            "They have they have because of normalization, no, there's not inviting rotation becaused you still have divide its patching 4 by 4.",
            "So you want to have invariants in rotation.",
            "You have to normalize first the Patch locally in the detection process.",
            "The representation itself is not rotation invariant.",
            "This is a little bit rotation invariant, but it should rotate like 45 degrees is not the same descriptor anymore.",
            "Water, not this one.",
            "This one here.",
            "Each Patch has a reference frame, so each Patch is relative to the center of the object.",
            "I'm going to talk a little.",
            "I'm going to clarify this in a moment, so it's not a bag of words.",
            "So here is a very simple way of doing multiclass learning.",
            "One is OK, you can train just a bunch of independent classifiers, or you could have just a classifier that looks like this and what you have some features that are shared across all different tasks.",
            "And then you have some other features that are more and more specific, and so these are very simple, simple thing to do.",
            "So here I'm going just very briefly describe some some boosting approach to solve that problem.",
            "Now boosting is just given just building a classifier just in an additive model.",
            "Each function here is this weak learner an in computer vision.",
            "Normally each of these functions is going to be 1 feature, something that you can compute independently of how do you compute the other features.",
            "Let's say this could be represented by 1 Patch and then the result of applying normalized correlation with the image will give you the output of this classifier plus a threshold and so on.",
            "An OK boosting of the message.",
            "This potential loss.",
            "I'm not going to enter in any of these details.",
            "You already know all this things, probably an.",
            "The reason why boosting has been very useful in computer vision is that it's very simple.",
            "It provides a very efficient algorithm for doing sparse feature selection, although you could use other things, But this was very easy to implement.",
            "It doesn't require any external optimization tool on computer vision.",
            "People lies a lot these things because they understand what they are doing then still has performances that are compatible to more sophisticated techniques such as supervector machines and so on and.",
            "So here is 1 example of what will be a part based object detector just in patches.",
            "So let's say that you want to take the car.",
            "Your model could be this one.",
            "You have a collection of patches that are have some displacement relative to the center of the object and so every Patch.",
            "The way that you are going to detect account on the images.",
            "Just take this Patch.",
            "You apply normalized correlation with the image.",
            "Deployed the threshold and whatever point had a value above the threshold is going to vote for the presence of the object in this location, and so the same thing for the other patches.",
            "Or if you want to take the screen.",
            "So this could be a possible representation for a screen.",
            "There are a lot of different week detectors that you could use is not just patches that are sick features and there are a lot of different things that people have been.",
            "Justin and it actually makes a big difference when you use.",
            "So there is a lot of research and just trying to find what is the best kind of leak detector that you could use.",
            "Aren't states so probably depends from which institution are coming?",
            "Or is there any real evaluation which features attacked?",
            "Are these people doing evaluations?",
            "Systematic evaluations?",
            "An like people in Oxford like under system and groups or Cordelia Smith jump owns.",
            "These people are doing systematic evaluation of detectors and representations.",
            "That was the message the message is that there are a bunch of that work more or less the same.",
            "And that it doesn't matter.",
            "So as soon as this kind of reasonable so.",
            "So maybe now, the things that begin to work better, it's just it's fragments.",
            "So run some edge cutting edge detector and then just some transfer.",
            "This towns but just wanna fragment not on the entire silhouette and then vote for the center.",
            "Dustin seems to be the best.",
            "Sorry is that more interest point so it is containing the geometry is so interest point can also be used.",
            "So there are two parts when you try to detect features.",
            "1st is to the site in which locations of the image you want to apply the feature and then apply the feature whatever it is that you choose.",
            "What you could do it densely.",
            "So the interest point, operate operators or the region of interest detectors.",
            "They only talk about how do you are going to choose pre selected locations in the image in which are going to apply your operator.",
            "But then now you can plug their whatever features you want.",
            "There could be an edge fragment.",
            "What it could be, some self descriptor or one Patch.",
            "So I'm question is this the best way to do the object recognition?",
            "At this point people think this is the way you think is the best for Justin.",
            "Just patches, patches and this kind of.",
            "Well.",
            "I don't think this is necessarily the best.",
            "If you extract edges, I think it was a little bit better, but whenever it's just this kind of boosted classifiers or things like that, it's very difficult to beat today and there are more sophisticated algorithms and I will talk about some of them.",
            "I wanna graduation yeah well that's very similar.",
            "You could just tell one to get a sparse.",
            "Disadvantage of the advantage here is that there is 10 lines of Matlab.",
            "That's the only advantage.",
            "Prism depends on situation, right?",
            "In your situation, doesn't stream.",
            "You still have to use credit, which generally depends.",
            "Sometimes it's lower, sometimes faster.",
            "But in this case I kind of don't quite a season as well for the training.",
            "So in runtime the bottleneck is the computation of the features is not really.",
            "How do you combine them on in training?",
            "Then it make make.",
            "It may make a difference what the optimization you're using is, but even this this algorithm just takes with many many object classes takes 3 hours, is not that bad.",
            "And it is all in Matlab, so if you optimize the code, it could be really fast.",
            "So not, it's not a big deal.",
            "Recommendations, but rather than just using boosting, I think people is mostly just in boosting for a moment.",
            "I'm not L1 because L1 requires just in some optimization toolbox.",
            "No, you could know they know how to do it, but that's why you're going to call something else.",
            "So what is really important here?",
            "Many times this was the representation.",
            "Just going to Deuces people is making an effort in trying to find what are the best features.",
            "But then the second algorithm that reduce after that.",
            "Sometimes it doesn't make it really difference and I think that it may begin to make a difference when you have many classes.",
            "So now if you begin to think about transferring knowledge between different objects then it will begin to be an important issue.",
            "But I think that in the single class H. And maybe it wasn't that that a big deal, and in fact, like the Supervector machines, which are kind of complicated.",
            "Then you have L2 norm which kind of gives the same results and so on, so.",
            "It's not very clear what can you do with better machine learning at this level, and in fact like for character recognition, some of the best algorithms are just nearest neighbors, have the right features and apply nearest neighbors and it gets almost the best performances, sorry.",
            "The 1st oh.",
            "Nearest neighbors for character recognition.",
            "There are not many characters, is not very slow, is actually quite fast.",
            "There's not a problem.",
            "The bottleneck is computing the feature.",
            "So once you have the features, the dimensionality of the space is not that high, so you can do anything you want.",
            "Well, but in character recognition, if you have the right invariances, the training data is not that large.",
            "This year this I recall one nearest neighbor, not even kind of oh, it's yeah.",
            "One nearest neighbors is already probably recently this.",
            "This community of people from this community said one nearest every unbeatable for many many practical cases.",
            "So there was.",
            "I mean, there is the world by John Raccoon that has.",
            "That may be the best character recognition today, but then there was Jitendra Malik's group, which apply the shape context, which is just a small variant of C features.",
            "Plus I one years neighbor and it almost got the same performance is really the difference was.",
            "I think that like on May might make something like 50 false 50 classification errors in a data set of many 1000 characters.",
            "So it's really on the noise level.",
            "Now comparing the two algorithms and maybe the other one is just making five more errors, so it's not significant and is 1 years neighbor not 12 layer neural network.",
            "So representation may be very important, so this is just an example of how that after one week that software will work.",
            "Just take one Patch.",
            "Big Data label deficit which you press translators?",
            "Yes yes yes.",
            "So in that case is not talking at all about multitask transfer and so any any of that in terms of the size of the training data.",
            "It needs a big training data set, yeah, but if you have it and it's there.",
            "Yeah.",
            "So of course another another tool will give you a more compressed representation of the training set, but part of that is giving you something else.",
            "What is just compressing the data set?",
            "But when you want to transfer it to other tasks, yes, I agree.",
            "I mean concentration is one of the places we have the most.",
            "The largest data sets of label data.",
            "Yeah, yeah, I think that for multiclass problems, having good representations that really compressed your data so they just track what is important that can be transferred from the object is going to make a big difference because now what you want to say is OK, how the classification performance is involved when you have only one training sample and not a million training samples.",
            "And in that case having the right algorithm is going to be critical, but in the single class H. Or just in this kind of approaching classification classifiers, it was not.",
            "It was not a goal.",
            "Nobody was thinking of solving that problem because it was not necessary.",
            "So here is just an example of a screen detection, just in a boosted classifier.",
            "So this will be just in the first feature, just some corner, and doing normalized correlation with the image.",
            "This is just a single scale applying address called.",
            "This is the output of the classifier for the first feature.",
            "Then you apply the second feature and you combine it with the 1st and so on and at the end you get something that begins to detect the screen.",
            "So I just called this.",
            "You have a kind of reliable detection of the screen.",
            "And this is the classical approach.",
            "So now you can just multiclass boosting, which is just a very simple, very simple thing to do an, but I'm going to show is that Despite that, this is a very simple thing, very simple way of transferring knowledge between different objects is just.",
            "It's already given interesting results.",
            "So here is just again classical multiclass cost function, in which is some the error, the cost for every class and then this is George Multiclass classifier.",
            "OK, again just an additive model, so we're just going to add weak classifiers that now are multi class in what the structure of these classifiers.",
            "What is going to be is going to be just a single a single stamp that can be shared across different classes.",
            "So instead of being a different classifier for every class, you force that a single at a single iteration, the classifier that we are going to add is the same classifier across all the classes that share that feature.",
            "And the only thing you have to decide is which classes are going to use that feature.",
            "And so the algorithm is very simple, is a greedy algorithm, just like boosting.",
            "In fact, this is just a standard boosting in which you have a Dictionary of features from which you can select the next one, and you have to select what is the best feature and the best set of object classes for which this is.",
            "This feature is going to apply.",
            "Then, once you have chosen that feature and applied over weight, all the samples and run the next iteration just standard boosting.",
            "So here is an example of a feature that is very specific.",
            "So let's say that you have these five of the classes.",
            "This is your background class.",
            "The important task here is to discriminate any of these classes against the background.",
            "Because this is a really difficult task, you want to detect an object, and the most important finished first to detect that object, and it's more difficult to discriminate that object against the background than to say that these two different objects are different.",
            "So here is you have this feature.",
            "This feature is very specific to face is so if you look at the distributions of the responses of this feature of face patches or background patches you get a very clear separation of the two is still not a very good detector because this thing here because there are a lot of background patches.",
            "This is small.",
            "At the farmers here is actually very, very large and but this feature is so specific to face is that it doesn't separate at all.",
            "Any of the other classes.",
            "So this feature is not useful for anything else done.",
            "Discriminating faces against the background, so here.",
            "So here there is another feature that is very generic is just a piece of an edge in a particular location relative to the object center.",
            "So this object, this feature is very generic.",
            "It's not going to be good to discriminate almost any object against the background, but when you apply it, what you get is that there is some separation between phases of the background is not as good as before, but it still is quite good.",
            "But what is interesting is that there is also some separation of other objects against the background, so this feature is useful for at least these three objects.",
            "And it's not just full at all for pedestrians and traffic lights, so for some.",
            "Size of the set of background that you will display here.",
            "So the background here.",
            "Well, this is a related.",
            "This is a weighted histogram, but there are at the beginning there are like 5000 samples or background patches and maybe 100 samples for every object.",
            "For fitting at this stage, no, no.",
            "Well, this is some intermediate stage of the boosting algorithm.",
            "So this is two different representations that you get if you choose specific features, you will say that the best way of representing the face is just in patches of faces.",
            "But if your task is to detect many object classes, I'm not just faces.",
            "The best representation is actually something that may look like this is just a collection of edge fragments and each one has a particular coordinate relative to the center of the object.",
            "So this is not just a collection of random.",
            "Edges, but they are located already in the relative location respect ifying them and this is the representation that you get for one way signs and this will be the representation that you get if you train.",
            "If you train a single detector to discriminate, one way signs against the background, so these are two different representations and they will give you different conclusions.",
            "So you try to understand what is the best representation for objects.",
            "If you are only looking at single object classes, you will think that this is the best representation, but if you think of the multi class of the problem then this will be the best representation.",
            "Just in this kind of architecture and so This is why it is important also to look at multi class objects becausw jamais tray.",
            "You may get different conclusions about what are the best.",
            "Presentation for objects.",
            "So this is an example of features that are learned just in this iterative boosting.",
            "This boosting algorithm with shared features.",
            "So here we train the algorithm to discriminate among.",
            "To detect 20 object classes against the background.",
            "And these are the features that got selected by the algorithm, sorted by the degree of sharing that they had.",
            "So in this matrix are white entry means that this feature is just by by this object.",
            "So here is a feature that is just by almost all there just by for some reason just the can is not yours.",
            "But this is just noise.",
            "And then as you go to the right you have features that are only used by maybe 3 objects or four or so.",
            "So these are very specific specific features, and in fact when you look at the features that are more share what you get.",
            "If you put them in, if you draw the image that they're drawing, it seems to look like just the outline of a generic object is something that is kind of center on the Patch, and that's destructive that is shared across all possible objects that are well located, well, well bounded by a bounding box, and so another way of saying so here is.",
            "Just the first thing is the fact that when you just share representations, of course efficiency is going to be improved.",
            "So as you increase the number of object classes, this is the number of features that you need to reach a particular average performance, and so this linear growth is what happens if you just train all the objects independently.",
            "So this is nothing surprising here, and this is the increasing complexity that you get when you share features, so you get a growth that is kind of logarithmic, and this growth has been observed by other works in the past.",
            "And so here you don't have the complexity of the classifier that grows linearly with the number of the classes but logarithmically.",
            "So this is important, but the most well, yeah.",
            "There is another way to get to error correcting code.",
            "Yeah, Erica, error correcting codes will also.",
            "It will also give you this kind of behavior.",
            "Yeah yeah, I'm not saying that this is the only way of getting this at all, but I'm saying is when you have this share representations, you get this kind of behaviors.",
            "And whatever the whatever the algorithm reduces, you could just multilayer network anything.",
            "It doesn't matter.",
            "You will get distance.",
            "In fact there are results that been even in the biology community when they do modeling.",
            "They try to to study how many neurons do you need to represent objects and they also show that when you have this distributed representations, you have a logarithmic growth on the number of networks that you need.",
            "So it's the same thing it doesn't, and in that case is a completely different structure.",
            "An empirical is that is empirical.",
            "It is empirical.",
            "Sorry in the case of.",
            "Well, but but but the finish is going to the pen a lot on the task that you're solving.",
            "If they're completely unrelated and their features are completely unmatched, probably therefore is going to be a very badly.",
            "I'm going to show some results about how the the tasks that you're trying to solve influenced this result.",
            "Also, another thing is if you look at the number of features that you need to detect one single object class.",
            "So when you train the objects independently for reaching some level of performance is June 8th six patches, so you need six parts to represent the object.",
            "But when you use as features, the features that were given by the algorithm, the share features you need many more and in fact the more of the classes you have, the more features you need per class.",
            "And the reason is that because they become more and more generic, they're less and less informative for every single class.",
            "So you need more of them.",
            "But that's also expected.",
            "This on the daughter cells.",
            "Of course one way also.",
            "I've seen that things make sense is run some clustering algorithm just in some distance between the objects based on the number of features that they share.",
            "So in this graph the more features are shared by by by two objects, the closer they are going to be, so you can see that most of the things make sense like a bottle and a person.",
            "If you don't think about the scale just in a normalized frame, they look very similar or a poster on a computer screen.",
            "They are very similar to.",
            "So this is also a way of visualizing that the Sheriff structure that you're learning makes sense, but this.",
            "Saying something is.",
            "Is putting objects by the similarities putting together?",
            "Agreed that you would say, well, this really nicely reflects your understanding.",
            "Well, I think I will be very surprised if the screen was nearby the car side.",
            "I think you could say that something is going wrong, but it's not the case.",
            "Now the screen is nearby the poster, which seems.",
            "Very reasonable thing to do now.",
            "Both are square, sorry.",
            "The trash, so yeah, yeah so here here you have like in this cluster here?",
            "Yes no yes at all levels it makes sense.",
            "So here, like in this cluster, now is almost vertical stuff.",
            "Now that has kind of square boundaries.",
            "And here you have this stop sign and then do not enter sign.",
            "Here you have things that are mostly horizontal.",
            "Here there are things that are mostly vertical, so it makes kind of sense.",
            "So you can do the same thing for multi view of the direction you want to take different views of objects.",
            "So you could also think that instead of training one different detector for every viewpoint, you could just try to share features between them, so you will have features that are kind of viewing Varian and then there will be other features that are more view specific.",
            "So the structure of the sharing is going to depend on the groups of symmetry that that object has.",
            "Then there are some interesting things that could be explored are well.",
            "I'm going to skip here, so this is an example of.",
            "What is the best generalization that you can get as you increase the number of training samples?",
            "So there are two situations here.",
            "Two different tasks.",
            "In the first case, do you wanna learn multiclass object detector that has to discriminate?",
            "Has to detect these 12 object classes.",
            "They are unrelated, they're just pick up random and the task is to detect each object class against the background.",
            "So it's a detection task.",
            "In here the task is to detect different viewpoints of the same object.",
            "In both cases there are 12.",
            "Classes, but here they are visually different.",
            "Here there are more more related, so when you train independent classifiers for each task, as you increase the number of training samples, OK in both cases you get better performances as expected.",
            "So in blue is what you get if you train the classifiers independently and in red is what you get if you train the classifiers jointly.",
            "So here there is some sharing, so there is some better generalization is not very strong because the objects are very unrelated.",
            "So here basically what you get is that the number of training samples that you need.",
            "To get the same generalization the same performance.",
            "Then when you train the classes independently is Janet half the amount of data data for training.",
            "That means that more or less there is always one class that has something that you could share an and would benefit a little bit from it, but you are only improving a factor of two.",
            "The amount of training samples that you need in the case of different viewpoints, there are a lot of similarities like viewpoints that are nearby are going to share a lot of structure.",
            "And or like this angle and this angle, they are almost identical.",
            "So there is a lot of sharing to be done and hear what you find is that you need five times less training data.",
            "If you are training this jointly, which is actually maybe very natural for most of the people working on machine learning.",
            "But in computer vision this is not something that people have been exploiting at all, and so I think there is a lot of things that you could try on computer vision because there are a lot of things that are not.",
            "Not explore and that are obvious.",
            "Then, so this is just some standard results from one of the data sets.",
            "This is the Pascal collection for car detection.",
            "This is a multi view task and the different lines here are different precision recalls for different algorithms.",
            "Here in Black is the performances that we get when we train a classifier with one classifier per viewpoint with only one training sample.",
            "So it behaves very badly, although there are some algorithms that are about the same level and they just.",
            "50 training samples.",
            "So I wonder what they did?",
            "In blue, here is the same same thing, but now with shared features.",
            "So now we train jointly, but again only one training sample per class.",
            "And now the performances are actually among the best ones.",
            "So there is only one here that is really much better.",
            "So this performance is obtained with just one training samples and I think the other algorithms are just in 50.",
            "So here in green is what you get when you use 50 training samples, but again independently trained in training every every classifier and in red is what you get if you turn all the classifiers jointly.",
            "So you get very very good performances and there is a big benefit from the fact that you are turning all these things jointly.",
            "So again, not the more related to task, the stronger the sharing is going to be.",
            "So here if you are interested in doing emotion recognition but also face detection at the same time, So what you could do is to build a detector for every emotion and this detector.",
            "What is going to do is going to do face detection, an emotional recognition at the same time, and these are the features, the features that we obtain when we run this multiclass boosting algorithm and what we get is that the first features are.",
            "Totally generic, they're shared across all different emotions.",
            "These features are just doing face detection.",
            "They don't do any.",
            "Emotional recognition because they are there is no discrimination information between the different classes and at some point you begin to have some features that are good for some emotions but not for others.",
            "And those are the features that now contribute to emotion recognition.",
            "You don't know that.",
            "I mean they might have different weights, no?",
            "No, here we forced the ways to be the same, so there is.",
            "There is absolutely no information that is discriminants for each.",
            "Yeah, everything is shared.",
            "So when when one feature is shared across different classes it shares the threshold the weights.",
            "Under the feet on the Patch, everything is there.",
            "In one question will be OK. How many things do you want to share?",
            "You want to share only the path you want to share, the weights you want to share the thresholds.",
            "Market share is normal is better when you have very very few training samples, but you may lose something.",
            "There is another I don't know how long.",
            "How much time do I have?",
            "I can't finish here.",
            "Sorry.",
            "OK, what do you want me to do?",
            "OK, so so we're going to stop here or I can just say that another thing that has a lot of has been widely just now in computer vision.",
            "Is this topic models like LDA?",
            "Which also provides a natural way of sharing information across documents.",
            "Now the topics are these things that are shared and is something that is now exploit in computer vision.",
            "So there is some we have done some work on this.",
            "Other people have been doing some work on it so I just put the pointer there.",
            "Thank you.",
            "What's the performance for this emotion detection for the motion detection?",
            "Well, the face detection, so the part that is doing face detection is a state of the art because it's just patches and but the recognition is about.",
            "In this data set is like 70% correct, but we haven't done.",
            "We haven't done.",
            "It is no, it's a real data set, but it's an excellent.",
            "Pictures well is real people, but it's very prototypical, so I think if you had to recognize this 16 emotions, even people, we will have problems making fine distinctions within them, and so I don't want to make any claims.",
            "That means I don't want to say anything just 70% with this data set, which doesn't really mean anything then.",
            "If I don't give you the details of the data set.",
            "To have kind of hierarchy of this emotions from this gorgeous flats, it is.",
            "Yeah it is.",
            "Yeah no no and in fact the fact that you are learning this share features is already giving you kind of hierarchy in in the sense that you don't know how finally partition the space like in the case of multi view you could imagine Whitewell views.",
            "Why not 24?",
            "OK it doesn't matter, you can just as many as you want if you just too many they will share more information and therefore.",
            "The classifier doesn't get penalized because you make a bad choice, but you still feel then that might be bad.",
            "Questions.",
            "How do you do in the location of the object manager?",
            "The box yeah here is only what I talk is only bounding boxes.",
            "Vacation also need to look at the correct box, yes.",
            "Yeah, so so from sorry.",
            "Crack balls.",
            "Exactly the same.",
            "Oh, how do you evaluate the performance?",
            "How do you evaluate that?",
            "OK, so normally what people is doing now that was part of the Pascal competition in object detection is is you have to bounding boxes.",
            "You look at the ratio between the overlapping area and the total area of the two bounding boxes and the ratio between the two should be larger than .5 some arbitrary.",
            "Quiet.",
            "So in order to compare different algorithms, think it would be useful to have datasets and those available online or.",
            "Well, all those data sets are unlabeled, may.",
            "So I haven't.",
            "I haven't cleaned it up.",
            "I don't have now benchmark that you could do this without.",
            "I should do that soon, but I haven't done it yet.",
            "So yeah, so this Pascal competition I think was part of the.",
            "You could count and you pass competition is that God is offering lots of competitions, nothing.",
            "The division, but we'd be happy to do more than one.",
            "Well, I'm speaking out of turn, but I mean there are people within Pascal would sort of coordinate changes, and I'm sure they would be very happy to consider doing challenge.",
            "Let's say on the motion detector.",
            "Very interesting problem.",
            "Also for the showcase.",
            "Yes, I think it certainly is in line with our mission statement.",
            "The deck and emotions, but I think so.",
            "I think the goal of this total was to encourage you to look at these data sets because that is how an opportunity for doing a lot of things here, because there is not that much richer research on the computer vision Community jet done on this things, but it's going to change very soon.",
            "So just do it really fast.",
            "In two years they will matter.",
            "Somebody will do it.",
            "There is also a group that's not working on this idea of the vacant models for.",
            "Image.",
            "Analysis, I believe.",
            "Sammy Benjamin.",
            "Project yes.",
            "Another online.",
            "Nothing else.",
            "There should be a web page on the Pascal thing.",
            "I'll check it out.",
            "So what happened with this old fashion?",
            "Probably old-fashioned computer vision, wherever it was trying to search geometry in this deep stuff.",
            "So is this just coming back?",
            "He's coming back.",
            "He's coming back.",
            "So this means that it disappears.",
            "In the meantime, yes, I think so many times in computer vision will happen.",
            "Many of the ideas were there very early.",
            "But then they realize that they lack the algorithms they like the computer power.",
            "And they like the training the training sets.",
            "So I think that was one of the big Show Stoppers at very early times.",
            "So there are some papers that have very nice ideas and there is only one image they test only on one image.",
            "And there are many papers like that an many times where you think, OK, why context?",
            "I mean, everybody has been thinking about context on the past.",
            "Then why didn't work or why is that now people is coming back like if it was something new and the reason is because nobody really managed to make it work.",
            "So probability statistical models at the time were very.",
            "They were not very well known by the computer community, Computer Vision, Community, an everything will be really a slow an nothing will really work.",
            "Now you have all this convex things and begins to be nice, but it wasn't.",
            "This coming back now when I bought for how.",
            "Open Facebook, sorry for sure.",
            "Let's say you presented this.",
            "Set of approaches which well in some ways shallow.",
            "Just this shovel features and then you.",
            "Yes, just playing with this stuff and then something comes out so the geometry stuff with this stuff.",
            "In what way is it coming back?",
            "So one thing is to build in 3D models of scenes and then knowing that the objects are going to be inside now and you have this really relationship between the objects an so like this face which showed before, which is kind of class of models.",
            "So so.",
            "Talk about database model of objects so you can have part based models or just have 3D.",
            "Now the parts are going to be located on for the man.",
            "And we had a paper on CPR.",
            "Now that is exactly doing that in which you learn that tables are these flat surfaces.",
            "Their screens have this corners that are in particular the configuration and so on.",
            "And you learn all that unsupervised and there are other work in which they try to do exact matching of objects, knowing that there are 3D.",
            "So you may have different viewpoints and now you try to find what is the corresponding view that you have.",
            "Maybe some of the most interesting things we're trying to do 3D models of scenes.",
            "So instead of trying to reason of still instead of trying to solve this coffee beans, head on the coffee beans problem.",
            "Really thinking that this thing has meaning on here.",
            "Now you have this plane that is slanted like that, so just picked all the heads to be in a particular arrangement so I don't need to run my detector everywhere.",
            "I know where faces are going to be here, so why to run just an exhaustive train detector?",
            "And you do that, sorry.",
            "The coffee bean exactly.",
            "So this is not a coffee beans image.",
            "You know it has meaning and it has a pretty strong regularity.",
            "And all of them are driven by 3D structure.",
            "So these things are coming back.",
            "Questions.",
            "So let's think."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this will be a very specific problem in which multi task learning can be very interesting.",
                    "label": 0
                },
                {
                    "sent": "So the first thing so because I don't know if I will have enough time to finish.",
                    "label": 0
                },
                {
                    "sent": "So I want to make sure that I mentioned the collaborators.",
                    "label": 0
                },
                {
                    "sent": "So the first is Alexander is relative.",
                    "label": 0
                },
                {
                    "sent": "Now postdoc at Berkeley.",
                    "label": 0
                },
                {
                    "sent": "Kevin Murphy.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this thing is because now that there is not a lot of money for grants, we are forced to use very cheap setups for vision.",
                    "label": 0
                },
                {
                    "sent": "So other liver professor at MIT and Bill Freeman, also professor at MIT.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do first, I'm going to give a.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's more overview of object recognition.",
                    "label": 0
                },
                {
                    "sent": "The current state of the art, and also some review of multitask learning applied to object recognition.",
                    "label": 0
                },
                {
                    "sent": "And then I will talk talk a little bit about my own work, but I'll try to give you an overview of what is going on on the field and also pointers to data sets and so on, so you can.",
                    "label": 0
                },
                {
                    "sent": "You can apply your algorithms to this problem.",
                    "label": 0
                },
                {
                    "sent": "So the classical approach in object detection, at least the one that is the most successful today, is just take a picture.",
                    "label": 0
                },
                {
                    "sent": "And if you want to detect a particular object, let's say your screens.",
                    "label": 0
                },
                {
                    "sent": "But they are going to do is train a classifier.",
                    "label": 0
                },
                {
                    "sent": "Just back from this image all possible patches at all possible locations on all possible scales.",
                    "label": 0
                },
                {
                    "sent": "For each Patch you apply your classifier that you train with examples of screens and background samples, and your classifier is just going to put all the screens in one side or the background samples on the other side.",
                    "label": 0
                },
                {
                    "sent": "Very classical approach and it worked very well, especially because there had been a lot of advancements in machine learning that allowed to learn these functions very, very efficiently and very very finely tuned because there are a lot of patches here.",
                    "label": 0
                },
                {
                    "sent": "And only three of them correspond to screens, so it has to be a very selective function.",
                    "label": 0
                },
                {
                    "sent": "So the success of this kind of approaches has been especially.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Useful to solve this problem of face detection, which has received a lot of interest and it's a problem that you can say that today it works and by work I mean that you can sell this product and somebody will pay for it.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of approaches, a lot of people that have been working on this.",
                    "label": 0
                },
                {
                    "sent": "And the problem with this is that it created in computer vision that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single class class 8 So everybody was working on face detection an the only thing that you could do to get a paper published was basically object face detection and they didn't care at all about other objects then.",
                    "label": 0
                },
                {
                    "sent": "So this created what I call so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing is also the fact at some point some people wanted to apply this to multiclass.",
                    "label": 0
                },
                {
                    "sent": "So what to do?",
                    "label": 0
                },
                {
                    "sent": "OK, something that works very well for one class.",
                    "label": 0
                },
                {
                    "sent": "Let's do it for any classes.",
                    "label": 0
                },
                {
                    "sent": "So you want to detect faces at different orientations, train one classifier for every orientation.",
                    "label": 0
                },
                {
                    "sent": "Or you want to detect different objects.",
                    "label": 0
                },
                {
                    "sent": "Well, train one classifier for each different object or different views of a car.",
                    "label": 0
                },
                {
                    "sent": "One different classifier for every different viewpoint of a car.",
                    "label": 0
                },
                {
                    "sent": "So very good.",
                    "label": 0
                },
                {
                    "sent": "So this leads to the problem of the head in the what I call the head in the coffee beans problem, which is what computer vision is trying to.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today, so I want you to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "So can you find ahead.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this image.",
                    "label": 0
                },
                {
                    "sent": "Wells is anybody finding it?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah OK, it takes some time.",
                    "label": 0
                },
                {
                    "sent": "You can see that you cannot solve this problem in real time, but we are asking computers to do this now.",
                    "label": 0
                },
                {
                    "sent": "If anybody hasn't seen it yet, here it is the head.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what we ask computers to do when we're trying detector for face detection, so you can see how frustrating is the life of an object detector today, sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah so, but this is the only thing that detectors can do today, So what is an image for object detector today is just a collection of coffee beans so distractors that are trying to make your life as hard as possible.",
                    "label": 0
                },
                {
                    "sent": "Within all these factors there is 1 sample of your target and you have to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "But this is far from being the real problem that vision has to solve.",
                    "label": 0
                },
                {
                    "sent": "Normally things are more strict rated and done this and you have all sorts of other kinds of objects that you will also like to detect and there are contextual relationships between them.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So this is not the real problem that we should be solving, although it's nice that some people can actually solve this thing, and so here are some symptoms that have this approach.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the single class approach.",
                    "label": 0
                },
                {
                    "sent": "First imagine that you're trying to detect pedestrians.",
                    "label": 0
                },
                {
                    "sent": "This is a classical output of a state of the art pedestrian detector, so here is a pedestrian and you take the pedestrian.",
                    "label": 0
                },
                {
                    "sent": "And here there is a false alarm.",
                    "label": 0
                },
                {
                    "sent": "OK, well, it looks kind of pedestrian, so we have one, but it could crash kind of arms and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can understand why it makes a mistake here.",
                    "label": 0
                },
                {
                    "sent": "But look what happens on the image.",
                    "label": 0
                },
                {
                    "sent": "It doesn't make any sense, is not on the ground.",
                    "label": 0
                },
                {
                    "sent": "It doesn't relate to this other person here at all, so this wouldn't be a mistake that anybody will make.",
                    "label": 0
                },
                {
                    "sent": "Here there is a keyboard detector, so here is a correct detection.",
                    "label": 0
                },
                {
                    "sent": "Here is a keyboard that was not detected here.",
                    "label": 0
                },
                {
                    "sent": "There are a bunch of false alarms and actually you take this Patch here and you compare it to this color detected keyboard.",
                    "label": 0
                },
                {
                    "sent": "Well, they're very similar.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to say that this is a keyboard unless you put it on context, sorry.",
                    "label": 0
                },
                {
                    "sent": "It is not a keyboard.",
                    "label": 0
                },
                {
                    "sent": "OK, it's difficult to say it is not a keyboard.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results.",
                    "label": 0
                },
                {
                    "sent": "A bunch of images here.",
                    "label": 0
                },
                {
                    "sent": "Again just running a state of the art keyboard detector.",
                    "label": 0
                },
                {
                    "sent": "So these are images in which the detector says there is low probability of having a keyboard.",
                    "label": 1
                },
                {
                    "sent": "Here there are images in which the detector says there is a high probability of having a keyboard, just some logistic regression applied to boosted classifier so.",
                    "label": 0
                },
                {
                    "sent": "OK, here this one keyboard here.",
                    "label": 0
                },
                {
                    "sent": "There are some keyboards, but here there are images in which the system thinks that is a keyboard present, but there is of course no keyboard present, but even even more is this are St since that is not it couldn't be a keyboard here, it doesn't make any sense.",
                    "label": 0
                },
                {
                    "sent": "Now here there are images with low probability, but so many of them are actually office in, so it's likely that there is a keyboard somewhere here, but we are not seeing it.",
                    "label": 0
                },
                {
                    "sent": "Lips.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in an image like this one, there are a lot of objects and we are interested in detecting all these objects and not just one.",
                    "label": 0
                },
                {
                    "sent": "So in this image we know that there is a keyboard present even though it's very difficult to see it now.",
                    "label": 1
                },
                {
                    "sent": "But here there must be a keyboard.",
                    "label": 1
                },
                {
                    "sent": "An innocent like this one within or there is no keyboard, but in fact there is a keyboard here.",
                    "label": 0
                },
                {
                    "sent": "But systems don't make even this kind of mistakes.",
                    "label": 0
                },
                {
                    "sent": "They don't care about these things.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another symptom is the object representations that are arrive.",
                    "label": 0
                },
                {
                    "sent": "So imagine that your goal is to detect this one way sign this particular viewpoint.",
                    "label": 0
                },
                {
                    "sent": "You are not even interested in different viewpoints of the one way sign.",
                    "label": 0
                },
                {
                    "sent": "So what is the best representation that you should use so that you can detect this traffic sign?",
                    "label": 0
                },
                {
                    "sent": "So if you're only interested in detecting this object, so maybe something like template matching is going already to work so OK, you could have some part based representation of the object, because maybe there is some ability of the.",
                    "label": 0
                },
                {
                    "sent": "That you want to be robust to it, so you don't want to have just one unique template, but you want to have some parts that are relative to some reference frame of the subject so that they allowed for some small distortions.",
                    "label": 0
                },
                {
                    "sent": "And indeed, if you just such a representation, you reach very high detection rates, because this is a very regular object, very easy to detect.",
                    "label": 0
                },
                {
                    "sent": "But the problem is when you look at this part, some of them are very specific, like this arrow here is very specific to this object.",
                    "label": 0
                },
                {
                    "sent": "It's very unlikely that this this part here is going to be useful for any other thing than detecting this one way sign.",
                    "label": 0
                },
                {
                    "sent": "And in fact, this has been something that's happening.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any object detection algorithms, like when people interested in detecting cars, the representations that they obtain, are parts of cars and that happened in many, many cases or faces the parts that you obtain that are ideal to detect faces are again parts of faces, and so this all these parts are very specific to this object, so it's very unlikely that these things are going to be helpful.",
                    "label": 0
                },
                {
                    "sent": "Helpful for other objects.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Another",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anthem also is that if you want to take many different object classes and you train the independent classifiers for each one, well, what is going to happen is that as you increase the number of classes, the complexity of the overall multiclass classifier is just going to increase linearly.",
                    "label": 0
                },
                {
                    "sent": "So the number of features that you need increases linearly with the number of classes.",
                    "label": 1
                },
                {
                    "sent": "Nothing surprising there.",
                    "label": 0
                },
                {
                    "sent": "And of course you wouldn't do something like that.",
                    "label": 0
                },
                {
                    "sent": "But this is, this is something that people have been doing actually.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of possibilities.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For research and.",
                    "label": 0
                },
                {
                    "sent": "In multi class object detection that I'm not really very well explored yet and.",
                    "label": 0
                },
                {
                    "sent": "The community is that everybody is specializes in detecting this type of object and that says yes.",
                    "label": 0
                },
                {
                    "sent": "Trying to do well.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say nobody I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to review, but if you want to so today things are beginning to change.",
                    "label": 0
                },
                {
                    "sent": "But few years ago, if you wanted something something more than a poster, it will be better than you do something like single class of detection.",
                    "label": 0
                },
                {
                    "sent": "But today things are changing and now it's possible to begin to work on multiclass, and indeed there are some papers that are starting to do that, but still because it's a very recent thing.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of things that are unexplored and many things that people have been talking about here could be introduced into the community, and I think it will be very useful I think.",
                    "label": 0
                },
                {
                    "sent": "Taking images, all those things about what typing images taking like I say appears in those images they have.",
                    "label": 0
                },
                {
                    "sent": "They can deal with hundreds or thousands of classes.",
                    "label": 0
                },
                {
                    "sent": "You mean like image indexing and so on.",
                    "label": 0
                },
                {
                    "sent": "Again, there's a group working on those.",
                    "label": 0
                },
                {
                    "sent": "There are some kind of concept networks of what you're basically you have images they put to put towards an image.",
                    "label": 0
                },
                {
                    "sent": "Yes yes yes yes yes but but I'm talking in object recognition, so those things are more about putting just some global labels to the images.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I will make the distinction between them having an image and you have to say that is present or not.",
                    "label": 0
                },
                {
                    "sent": "There are several things that you can do to solve that problem that don't require doing detection and there is some work on that on on solving that problem and there are some techniques that just multiclass classifiers and so on, but they don't really explore the problem then the benefit of the fact that you are actually training a multiclass classifier an what is the benefit of doing so, they're just using it, they don't, they don't show that by doing this.",
                    "label": 0
                },
                {
                    "sent": "Actually you do better.",
                    "label": 0
                },
                {
                    "sent": "So I was from idea, that's why I know there's proof they have this concept network of your what can Co occur also seems like oh they're just in context and so on you mean.",
                    "label": 0
                },
                {
                    "sent": "There on your possible occurrence or the relationship location of your object, yes, yes.",
                    "label": 0
                },
                {
                    "sent": "So that's another way of so this will fall in this section here.",
                    "label": 0
                },
                {
                    "sent": "Can't someone obvious?",
                    "label": 0
                },
                {
                    "sent": "And there are some works.",
                    "label": 0
                },
                {
                    "sent": "I'm going to say that there is known about this.",
                    "label": 0
                },
                {
                    "sent": "There are some things I have been doing.",
                    "label": 0
                },
                {
                    "sent": "Some things we have been doing this stuff and there is other groups that have been doing something.",
                    "label": 0
                },
                {
                    "sent": "It is not the dominant line of research, that's what I mean.",
                    "label": 0
                },
                {
                    "sent": "And most of the research has been devoted to single class of detection.",
                    "label": 0
                },
                {
                    "sent": "Despite that, this is probably the real problem that you want to solve.",
                    "label": 0
                },
                {
                    "sent": "This is what I'm trying to say.",
                    "label": 0
                },
                {
                    "sent": "Maybe if I can that so it's not mainline.",
                    "label": 0
                },
                {
                    "sent": "But let's say search image search would actually benefits yes.",
                    "label": 0
                },
                {
                    "sent": "Maybe start one main line of research with returns most of the minus this bottom part there.",
                    "label": 0
                },
                {
                    "sent": "Yes, so here that is all image indexing and so on can fit here, although there is always in many cases there is a strong disconnect between research and image indexing and object detection and the fact that you could put the two together an there are few words that try to do that.",
                    "label": 0
                },
                {
                    "sent": "But most of the time image indexing is just image indexing and they just try to find an image with Flowers and so on and they don't really exploit that match the context.",
                    "label": 0
                },
                {
                    "sent": "Relationship so they don't make a big deal out of it, but what they do basically they do collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "Yes yes yes.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to focus most on the on the program object detection.",
                    "label": 1
                },
                {
                    "sent": "So what is the face in the same match and where it's at sharing this image?",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And that problem also benefits a lot from multi task learning.",
                    "label": 0
                },
                {
                    "sent": "And there are some works on it and I will review some of dawn of those, but there are not that many in.",
                    "label": 0
                },
                {
                    "sent": "So the question here is how to build efficient representation for object recognition that benefit from the fact that you have many classes and just one.",
                    "label": 1
                },
                {
                    "sent": "How can you achieve better generalization by the fact that you have many other object classes?",
                    "label": 0
                },
                {
                    "sent": "What are these commonalities within the different objects?",
                    "label": 0
                },
                {
                    "sent": "They may be interesting by themselves, so if we want to learn something about how objects are formed or how the visual system represents objects, this commonalities within objects may have some interest by themselves.",
                    "label": 0
                },
                {
                    "sent": "So let me first just give you some pointers to data sets so you'll have the slides on the web I guess.",
                    "label": 0
                },
                {
                    "sent": "So you can look at this links and this is not an exhaustive list of all the data sets that exist.",
                    "label": 0
                },
                {
                    "sent": "There are many, many different data sets for object detection and most of them, so here I separated them in data sets for object localization.",
                    "label": 0
                },
                {
                    "sent": "So those are data sets that have big images in which objects are small.",
                    "label": 0
                },
                {
                    "sent": "So the real problem is to detect where the object is in the image.",
                    "label": 0
                },
                {
                    "sent": "Then there is database for object recognition that are closer to problems of just attaching labels to an image you don't really need to locate the object.",
                    "label": 0
                },
                {
                    "sent": "The object is normally generally big, so you just have to say what are the labels that are attached to that object, similar to what IBM people is doing.",
                    "label": 0
                },
                {
                    "sent": "And then there are a set of online annotation tools.",
                    "label": 0
                },
                {
                    "sent": "There are some collections and I you should look at this Pascal data set in which they have now 10 object classes and I'm going to describe just very briefly the data set that we have.",
                    "label": 0
                },
                {
                    "sent": "That is the label mean data set.",
                    "label": 0
                },
                {
                    "sent": "But you could check this other data sets on the web so that we build because we were interested in ingesting really many many object classes an there are not good data sets for, not for that yet.",
                    "label": 0
                },
                {
                    "sent": "So we created this annotation tool that is online so anybody can go to the data set and label images.",
                    "label": 0
                },
                {
                    "sent": "So this was built also in collaboration with Bryon Russell, a graduate student at MIT with Bill Freeman.",
                    "label": 0
                },
                {
                    "sent": "So this data set now has a lot of objects, so let me show you first image of the annotation tool.",
                    "label": 0
                },
                {
                    "sent": "So if you go to the website you will find something that looks like this and when you have an image and you can trace polygonal boundaries around the object and then will bubble, will show up and it will ask you what's the number the name of the object and you are free to introduce whatever you want.",
                    "label": 0
                },
                {
                    "sent": "Anybody is free to go there and to do it, and we had a lot of people going and labeling objects, so now there are like 88,000.",
                    "label": 0
                },
                {
                    "sent": "So since this is like was made.",
                    "label": 0
                },
                {
                    "sent": "And there have been about 10,000 new objects labeled by just people on the web, and it's amazing that Despite that.",
                    "label": 0
                },
                {
                    "sent": "People are given no instructions, so the only instructions is this.",
                    "label": 0
                },
                {
                    "sent": "There are no constraints on what people can do.",
                    "label": 0
                },
                {
                    "sent": "People behaves quite consistently an the quality of the labels is quite good.",
                    "label": 0
                },
                {
                    "sent": "Sometimes there are some accidents like people just labeling something random or labeling somebody.",
                    "label": 0
                },
                {
                    "sent": "Parts that were not meant to be labeled.",
                    "label": 0
                },
                {
                    "sent": "But there are not that.",
                    "label": 0
                },
                {
                    "sent": "I can show you some examples.",
                    "label": 0
                },
                {
                    "sent": "So here are some statistics of.",
                    "label": 0
                },
                {
                    "sent": "The data set now, so these are examples of images labeled.",
                    "label": 0
                },
                {
                    "sent": "The images are very big and they have like several.",
                    "label": 0
                },
                {
                    "sent": "There are five megapixels 3 megapixel images, so this is the average quality of three different objects which are among the most difficult objects to level, like trees and cars and share some people.",
                    "label": 0
                },
                {
                    "sent": "You represent an object edges, yes, so here the representation of the object is just a polygonal boundary, so just this tunnel outline.",
                    "label": 0
                },
                {
                    "sent": "So if there are holes, this is not captured here yet.",
                    "label": 0
                },
                {
                    "sent": "Although.",
                    "label": 0
                },
                {
                    "sent": "So if there is occlusion then there are multiple ways of handling this and whoever is labeling it is free to decide what is going to do.",
                    "label": 0
                },
                {
                    "sent": "So you may have labels that are overlapping, like in this case.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to see here, but the road the cars are a little bit overlapping with the road segment, so it is relatively easy to add some depth ordering and just decide which is in front of what so that you know what is including what.",
                    "label": 0
                },
                {
                    "sent": "And so there are about 90,000 objects labeled now and there are like 2000 distinct object names and there are multiple levels levels of labeling that have since labeled.",
                    "label": 0
                },
                {
                    "sent": "There are objects that are parts.",
                    "label": 0
                },
                {
                    "sent": "So on and that is it is freely available, so you can download it anytime and there is also a MATLAB toolbox that goes with this that allows you to query to stack segmentations and so on.",
                    "label": 0
                },
                {
                    "sent": "So expect the datasets for training classifiers.",
                    "label": 0
                },
                {
                    "sent": "How do you do that?",
                    "label": 0
                },
                {
                    "sent": "If you want to?",
                    "label": 0
                },
                {
                    "sent": "Vented the images spots.",
                    "label": 0
                },
                {
                    "sent": "If you want to use your data set.",
                    "label": 0
                },
                {
                    "sent": "So so OK.",
                    "label": 0
                },
                {
                    "sent": "So one of the fences from here are you because the hardest part is to get the labeling done.",
                    "label": 0
                },
                {
                    "sent": "After that you can.",
                    "label": 0
                },
                {
                    "sent": "You can select images and create some benchmark.",
                    "label": 0
                },
                {
                    "sent": "So we haven't done that yet.",
                    "label": 0
                },
                {
                    "sent": "And the reason is that the idea behind this data set was to create a data set in which people can play with it and have their own idea.",
                    "label": 0
                },
                {
                    "sent": "So we don't want to impose.",
                    "label": 0
                },
                {
                    "sent": "OK here is the problem you want to solve.",
                    "label": 0
                },
                {
                    "sent": "Here is the 20 object classes that you have to work with.",
                    "label": 0
                },
                {
                    "sent": "No here there are 2000 objects and you could pick whatever you want.",
                    "label": 0
                },
                {
                    "sent": "And you can make your own selection of images and then you're free to pose them, because all of these images are taken by us, so they are Copyright free and you can just make their own benchmark.",
                    "label": 0
                },
                {
                    "sent": "So I think that does at this point is maybe the most interesting way of going.",
                    "label": 0
                },
                {
                    "sent": "Test is detectors without these big images are labeled.",
                    "label": 0
                },
                {
                    "sent": "If you also want to provide a data set which is used by different people, different groups algorithm, you want to provide the same yes.",
                    "label": 0
                },
                {
                    "sent": "So so when you do decide to just portion of the data set and you make a publication, you can say OK, here is the portion of the data set that I just here is the results I got and how people can compare to you.",
                    "label": 0
                },
                {
                    "sent": "But they are not forced to just only that data set.",
                    "label": 0
                },
                {
                    "sent": "They could in principle leverage the data here to.",
                    "label": 0
                },
                {
                    "sent": "Construct a different data set.",
                    "label": 0
                },
                {
                    "sent": "So so quickly like query and then obtain pointers to images, yes?",
                    "label": 0
                },
                {
                    "sent": "According to the polygonally.",
                    "label": 0
                },
                {
                    "sent": "1st, it's around the car, so yeah, so I can extract regards to pay with yes.",
                    "label": 0
                },
                {
                    "sent": "So the MATLAB toolbox has query tools you can say OK, give me all the images that have cars and buildings and it will give you pointers to all these images and they will give you the polygons too.",
                    "label": 0
                },
                {
                    "sent": "So here is so the online tool allows you also to do queries just to get a sense of what is there.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of images label so it's semi labeled as some images are more labeled and others and so on so.",
                    "label": 0
                },
                {
                    "sent": "Algorithms have to be robust to deal with.",
                    "label": 0
                },
                {
                    "sent": "Maybe objects that are missing that are not labeled and this is an example of Quirino here is just querying for dogs, so these are examples of dogs and dogs are there are 20, but then cars there I think like 1515 hundred cars labeled and so on.",
                    "label": 0
                },
                {
                    "sent": "Who yeah well when do connect?",
                    "label": 0
                },
                {
                    "sent": "Yeah people.",
                    "label": 0
                },
                {
                    "sent": "Vision algorithm know know know know.",
                    "label": 0
                },
                {
                    "sent": "Oops.",
                    "label": 0
                },
                {
                    "sent": "They are not normalized, so the number of this reference point can be.",
                    "label": 0
                },
                {
                    "sent": "In what do you mean normalize?",
                    "label": 0
                },
                {
                    "sent": "Or that person is always labeled with the same points in the same location, you mean that?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, no.",
                    "label": 0
                },
                {
                    "sent": "No different polygons are going to have different number of points.",
                    "label": 0
                },
                {
                    "sent": "So in many cases, many algorithms are only interested in bounding boxes, so I struck Ting abandoned box from here is very easy Ann in most of the cases.",
                    "label": 0
                },
                {
                    "sent": "So independently of how detailed was the Polygon, the bounding box is always very accurate, but Furthermore it allows you to have a more detailed segmentation is not.",
                    "label": 0
                },
                {
                    "sent": "I mean this is the average quality Sojourner going to get much better than this, although there are some people that are extremely, I don't know on drugs or something and they give you like.",
                    "label": 0
                },
                {
                    "sent": "40 points to level up person and in some other cases like this is really important to have something more like a segmentation because abandoned boxes is not tight enough.",
                    "label": 0
                },
                {
                    "sent": "But people abandon box in many cases is good enough.",
                    "label": 0
                },
                {
                    "sent": "OK so also like if you go to my website there is a link to.",
                    "label": 0
                },
                {
                    "sent": "I'm another set of tools that you can use for object recognition, and it implements most of the things that I'm going to talk about well, but only for single class objects.",
                    "label": 0
                },
                {
                    "sent": "But the representations that I will talk about our implemented here, and this was part of a class with failure Fergus, so there are a lot of slides and a lot of code, well documented specially is good.",
                    "label": 0
                },
                {
                    "sent": "I think for people that is starting like steel and so on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So now that we have many of the classes, what do we do with them?",
                    "label": 0
                },
                {
                    "sent": "So we are going to have many different object classes, many different viewpoints, and also we're going to have things like a styles and lighting conditions and so on that we may be interested in knowing.",
                    "label": 0
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We build a classifier for each one or we try to build this multiclass classifier in a more efficient way.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just ensure representation for objects, so some of the questions will be is learning the object class.",
                    "label": 0
                },
                {
                    "sent": "1000 is easier than learning the first object class.",
                    "label": 0
                },
                {
                    "sent": "In principle the answer should be yes, although in most of the cases until now the answer was just the same.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter how many classes you know.",
                    "label": 1
                },
                {
                    "sent": "So then is how can we transfer knowledge from one object to another?",
                    "label": 0
                },
                {
                    "sent": "And are the share properties between different objects interested by themselves?",
                    "label": 0
                },
                {
                    "sent": "For instance, here you have this will cheer is sharing properties from chairs an bikes and but the part that they share also meaningful by themselves, so that maybe there is something more that you can do by sharing parts between objects.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to review some of the things that have been done on multi task learning, especially applied to vision.",
                    "label": 0
                },
                {
                    "sent": "So this is not a review.",
                    "label": 0
                },
                {
                    "sent": "Or multi task learning, but just some of the things that had some vision applications that I thought contains some interesting insights, so it's not an exhaustive review either, so maybe one of the first papers is this paperwork Carvana, in which he does is he says OK if you want to solve end tasks you could train in principle one neural network for each task independently.",
                    "label": 0
                },
                {
                    "sent": "Or you could train a neural network that is that has multiple outputs.",
                    "label": 0
                },
                {
                    "sent": "Ann, the hidden units are share.",
                    "label": 0
                },
                {
                    "sent": "So what can you do with that?",
                    "label": 0
                },
                {
                    "sent": "It does this by do anything, and the answer is that yes it does by you and so they had a very simple, very simple visual application that is.",
                    "label": 0
                },
                {
                    "sent": "Coming back soon, yeah, but he's he's he's only aware of the practical work, not theoretical work.",
                    "label": 0
                },
                {
                    "sent": "So now I'm so I'm not going to review the multi task learning community.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of work and I'm just going to mention some vision applications.",
                    "label": 0
                },
                {
                    "sent": "OK, because.",
                    "label": 0
                },
                {
                    "sent": "Kohana people gotta lot of attention but the idea is just yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, so but they had vision applications on them OK?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is what I meant.",
                    "label": 0
                },
                {
                    "sent": "I'm only going to review some of the papers with vision applications, so of course there is a lot of theoretical work and so on.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to enter their non specialist on.",
                    "label": 0
                },
                {
                    "sent": "Yes yes.",
                    "label": 0
                },
                {
                    "sent": "So yes yes.",
                    "label": 0
                },
                {
                    "sent": "So one community that had a lot of that make use of multi task learning very heavily was always the character recognition community.",
                    "label": 0
                },
                {
                    "sent": "Although the problem is so tight that.",
                    "label": 0
                },
                {
                    "sent": "They fall again, almost in the same problem that people working only faces is the fact that, OK, they transfer knowledge within objects, but they are just so comes the objectives or constraints that you cannot really learn much about.",
                    "label": 0
                },
                {
                    "sent": "General Object Recognition is OK, you will do great on character recognition, but you apply those systems to general recognition and it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "It doesn't perform that well because you are missing many of the other features that are important to recognize objects, not just some pieces of characters and so on.",
                    "label": 0
                },
                {
                    "sent": "So so here in in Carvana his paper he tried to detect doorknobs.",
                    "label": 0
                },
                {
                    "sent": "So what he said it is OK, your primary task is to that door knobs, but you could.",
                    "label": 0
                },
                {
                    "sent": "You could design other tasks that are not the one that you want to solve, but that are related and I think this is an interesting idea in object recognition community in the fact that OK, you want to detect faces, but there are many other tasks that maybe are related with face detection that you could also try try to train your classifier to do and that will help you to do better on face detection.",
                    "label": 0
                },
                {
                    "sent": "Even if your task is just to do face detection.",
                    "label": 0
                },
                {
                    "sent": "So some of the tasks that he define is.",
                    "label": 0
                },
                {
                    "sent": "Like telling what is the horizontal localization of the doorknob.",
                    "label": 0
                },
                {
                    "sent": "This is the primary task to sign in.",
                    "label": 0
                },
                {
                    "sent": "If the door is single or double to say, where is the center of the door to say what is the width of the door, and so on.",
                    "label": 0
                },
                {
                    "sent": "So a number of tasks that The thing is not really that you want to solve, but probably some of the features that you need to solve.",
                    "label": 0
                },
                {
                    "sent": "These tasks are also useful to detect the doorknob.",
                    "label": 0
                },
                {
                    "sent": "And in fact, then machines is when you just this additional tasks to do better in the doorknob detection.",
                    "label": 0
                },
                {
                    "sent": "So another work is Sebastian Thrun and again so one of the things that he wants to do is to learn invariances.",
                    "label": 0
                },
                {
                    "sent": "So here are the variances that he wants to learn is translation invariants.",
                    "label": 0
                },
                {
                    "sent": "So he's training different objects you want to detect different objects and the final task there.",
                    "label": 0
                },
                {
                    "sent": "Real goal is to differentiate between shoes and glasses.",
                    "label": 0
                },
                {
                    "sent": "But at the beginning you are not going to train the system to do that.",
                    "label": 0
                },
                {
                    "sent": "You trained assistant to the tech to recognize a bottle, a box hat, and so on, and so the internal structure of the network again is just another network, so it's nothing new from the machine.",
                    "label": 0
                },
                {
                    "sent": "Learning viewpoint is just some of the ideas that emerge from that, so the network the only thing that is doing is learning this invariants defined, the translation doesn't matter, and again, it shows that we're sharing.",
                    "label": 0
                },
                {
                    "sent": "It helps, so you need less training samples to get the same performances, and so on.",
                    "label": 0
                },
                {
                    "sent": "And I guess this is sensitive to.",
                    "label": 0
                },
                {
                    "sent": "The choice of their task that your trainer.",
                    "label": 0
                },
                {
                    "sent": "I mean yes, yes, very unlucky.",
                    "label": 0
                },
                {
                    "sent": "We get asked him something very specific to this task that doesn't generalize to other tasks.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, yeah, you have to choose the task appropriately given the structure that you are going to use so that it works.",
                    "label": 0
                },
                {
                    "sent": "Otherwise your paper gets rejected.",
                    "label": 0
                },
                {
                    "sent": "Which is the final goal?",
                    "label": 0
                },
                {
                    "sent": "So one thing that happens is so these papers were mostly from the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "Trying to do some vision and what normally happens at least one of the impressions that has people in computer vision is that when machine learning does vision is always very simple toy problems, very happy problems and computer vision.",
                    "label": 0
                },
                {
                    "sent": "We are much better in finding very very good data sets that are also very hacky, but you don't notice.",
                    "label": 0
                },
                {
                    "sent": "So we have problems that look more interesting maybe.",
                    "label": 0
                },
                {
                    "sent": "So here is another paper, but Eric Miller at all.",
                    "label": 0
                },
                {
                    "sent": "This is computer vision people.",
                    "label": 0
                },
                {
                    "sent": "So here what they try to do in this case is character recognition an what they say is that any character that you see written is actually the result of a generative processing, which you have latent image.",
                    "label": 0
                },
                {
                    "sent": "That is one of the characters in a Canonical reference frame plus a transformation.",
                    "label": 0
                },
                {
                    "sent": "The transformation is shared across all characters, so any character can follow.",
                    "label": 0
                },
                {
                    "sent": "The same set of transformations, and the only thing that makes a distinction between one character or another, is this latent image.",
                    "label": 0
                },
                {
                    "sent": "So if.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "And so the only thing that you have to learn here is if you learn all the set of transformations.",
                    "label": 0
                },
                {
                    "sent": "Let's say from the first 5 characters you can then learn the other five from just one training sample, because as soon as you have that, you can look at what is the most likely transform.",
                    "label": 0
                },
                {
                    "sent": "You put that character as a latent image and then now you can generate any other instance of the character.",
                    "label": 0
                },
                {
                    "sent": "Of course you have a little more of examples.",
                    "label": 0
                },
                {
                    "sent": "You can get a better image of the latent image, but.",
                    "label": 0
                },
                {
                    "sent": "Is going to work with very few training samples and so here what is shared is the set of transformations and again here the information is actually very simple ones, they're just done with this flow fields to have question.",
                    "label": 0
                },
                {
                    "sent": "But for transformations is kind of a low right?",
                    "label": 0
                },
                {
                    "sent": "Just distortion all those, yeah.",
                    "label": 0
                },
                {
                    "sent": "That there's another way to do that.",
                    "label": 0
                },
                {
                    "sent": "We should just using set classification more like them while they call related to a thing called multi instance learning.",
                    "label": 0
                },
                {
                    "sent": "So essentially you want to say this is a zero for all the transformations foremost and you can read the kernel, understand where whatever.",
                    "label": 0
                },
                {
                    "sent": "But essentially you are sending stuff.",
                    "label": 0
                },
                {
                    "sent": "And the other that seems to be more relevant in today's that yeah you can.",
                    "label": 0
                },
                {
                    "sent": "You can do many things an I mean it's also learning the manifold.",
                    "label": 0
                },
                {
                    "sent": "Now you have a set of parallel manifolds and the only thing that you need to know is the displacement between them.",
                    "label": 0
                },
                {
                    "sent": "I mean there are a lot of things that you could do or just learning the distance and the offset between the objects.",
                    "label": 0
                },
                {
                    "sent": "So you could do many things.",
                    "label": 0
                },
                {
                    "sent": "This is some early things Ann.",
                    "label": 0
                },
                {
                    "sent": "This is computer vision, people doing machine learning.",
                    "label": 0
                },
                {
                    "sent": "So don't take them very seriously.",
                    "label": 0
                },
                {
                    "sent": "Kind of a translator transformation kind of known.",
                    "label": 0
                },
                {
                    "sent": "Yes, you can do those things.",
                    "label": 0
                },
                {
                    "sent": "I mean that this set of transformations you could define it a priority.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK. With the shooter exactly.",
                    "label": 0
                },
                {
                    "sent": "For executive situations, no collection of potential transformations, and then you are trying.",
                    "label": 0
                },
                {
                    "sent": "Difference and the difference.",
                    "label": 0
                },
                {
                    "sent": "Yes yes yeah no.",
                    "label": 0
                },
                {
                    "sent": "When I heard you talking this is exactly this.",
                    "label": 0
                },
                {
                    "sent": "And of course I mean this is the set of transformations here maybe trivial so impressive would have to find this a priority and the only thing that you need to know maybe is what is the variance and how strong this what is the displacement that you are allowed.",
                    "label": 0
                },
                {
                    "sent": "Now you could do something like that here.",
                    "label": 0
                },
                {
                    "sent": "They tried to do something more general and they apply this also to color transformation.",
                    "label": 0
                },
                {
                    "sent": "So they applied this framework to something else.",
                    "label": 0
                },
                {
                    "sent": "Then just character recognition, in which case the transformations are less known.",
                    "label": 0
                },
                {
                    "sent": "But as always the more inside you have about the problem and the more.",
                    "label": 0
                },
                {
                    "sent": "Constraint The problem is is more likely that you are able to define these things up.",
                    "label": 0
                },
                {
                    "sent": "Really, you don't have to learn them, and if we knew exactly what's the process to generate object, maybe there will be no learning whatsoever.",
                    "label": 0
                },
                {
                    "sent": "Just put their the basic axioms and don't have to train your system.",
                    "label": 0
                },
                {
                    "sent": "What was the idea that the other day that we formed by?",
                    "label": 0
                },
                {
                    "sent": "The idea here.",
                    "label": 0
                },
                {
                    "sent": "Oh, here he is also learning some invariances.",
                    "label": 0
                },
                {
                    "sent": "But here the invariances just translation and the problem is in many cases what happens is when you have a problem.",
                    "label": 0
                },
                {
                    "sent": "That is toy a toy plane like this one and it's too simple.",
                    "label": 0
                },
                {
                    "sent": "Maybe the invariances the system is learning have nothing to do with invariants that you really need to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "For instance here because the background is always this great thing.",
                    "label": 0
                },
                {
                    "sent": "Maybe what is just learning is block tracking.",
                    "label": 0
                },
                {
                    "sent": "So where is the blob is not going to solve any real problem like that.",
                    "label": 0
                },
                {
                    "sent": "But because the problem was very toy.",
                    "label": 0
                },
                {
                    "sent": "It gets a solution that seems to do being doing something, but no problem has been really been solved here, but the idea is that sometimes the idea is what matters.",
                    "label": 0
                },
                {
                    "sent": "Somebody can find a better architecture that is going to solve the real problem.",
                    "label": 0
                },
                {
                    "sent": "Once you have the intuition that you need to do.",
                    "label": 0
                },
                {
                    "sent": "In and then there is a lot of work in biology and models of biological visual system in which.",
                    "label": 0
                },
                {
                    "sent": "When you try to detect recognize many of the classes, of course the visual system has this hierarchy of different levels of processing that is shared across different objects.",
                    "label": 0
                },
                {
                    "sent": "So all this work in psychology and in biology and modeling, the human visual system are also using this shared architectures to learn multiple object classes.",
                    "label": 0
                },
                {
                    "sent": "But in general, again.",
                    "label": 0
                },
                {
                    "sent": "They normally don't make any claim about what is the benefit of having something like that, so one clear benefit is the fact that it's going to be more efficient, not just features do not have this linear increase in the computational cost, but another benefit is the fact that there is some knowledge that gets transferred to one object on another, and that's normally not mentioning the papers, so they are not aware, despite the architecture is probably already doing it.",
                    "label": 0
                },
                {
                    "sent": "And although people is beginning to get conscious of this fact now in the computer vision community.",
                    "label": 0
                },
                {
                    "sent": "So another very common representation for objects is what is called the constellation model, in which an object is represented by a collection of parts and this model was probably introduced by Fischler Anish Lager, although there were some other previous work, but this one is the one that got really attention, and basically if you want to represent the phase, whether you have you have a set of seven parts, they are connected by Springs to tell you that there is some flexibility in the locations of the different objects.",
                    "label": 0
                },
                {
                    "sent": "In so here, like four faces, well, you can have, so this is what we just investments here is work by Fergus yet pronounce sermon in which they model of just also using exactly the same structure.",
                    "label": 0
                },
                {
                    "sent": "And there are a bunch of algorithms that are based on this idea.",
                    "label": 0
                },
                {
                    "sent": "So an object is represented by a collection of parts that have flexible positions and this representation also can use multitask techniques from multi task learning.",
                    "label": 0
                },
                {
                    "sent": "So maybe one of the.",
                    "label": 0
                },
                {
                    "sent": "First papers to choose this kind of architecture for paper based modeling of objects was work by Ferguson Perona, in which what they do is they have a constellation model for representing objects, let's say faces.",
                    "label": 0
                },
                {
                    "sent": "So face is going to be represented by three parts.",
                    "label": 0
                },
                {
                    "sent": "This is just a toy example, three parts and the relative location of the parts may change from image to image.",
                    "label": 0
                },
                {
                    "sent": "But what is interesting is that the way that you are going to learn the configuration.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning the system is just given a bunch of faces and the system doesn't know where the faces are or where the parts are.",
                    "label": 0
                },
                {
                    "sent": "But he knows about many, many other object classes, and this is going to be used to learn a prior distribution on what are the parameters for the model and the parameters are going to be what are respected locations of the parts relative to the center location of the object and what are going to be.",
                    "label": 0
                },
                {
                    "sent": "What is going to be the appearance of every part.",
                    "label": 0
                },
                {
                    "sent": "Let's say some PC components.",
                    "label": 0
                },
                {
                    "sent": "Exactly what they think is in some cameras when they have to do a site on the power show, anything that is they have some kind of stuff.",
                    "label": 0
                },
                {
                    "sent": "They train the train detector on lots of images and get some priority as to where it should be brighter and version.",
                    "label": 0
                },
                {
                    "sent": "I think that Canon has some system of its type.",
                    "label": 0
                },
                {
                    "sent": "Maybe you know more than me.",
                    "label": 0
                },
                {
                    "sent": "No, I don't.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't know whether the what they do there and decide on exposure, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I have a question.",
                    "label": 0
                },
                {
                    "sent": "OK so basically here but they are using the other objects to constrain what is the space of possible model parameters.",
                    "label": 0
                },
                {
                    "sent": "So now they're going to just this prior to learn a model for the face and they expect this model to be not too far away from what you will expect just from the statistics of objects.",
                    "label": 0
                },
                {
                    "sent": "And so here are some examples of how do they learn a model of a piano.",
                    "label": 0
                },
                {
                    "sent": "So here there is parts detected on the image and this is the model that they obtained for the piano when they train only with one.",
                    "label": 0
                },
                {
                    "sent": "Training sample, so in this case this is the location of the parts.",
                    "label": 0
                },
                {
                    "sent": "They constrain the model to have only four parts.",
                    "label": 0
                },
                {
                    "sent": "And what happens here is that this thing here.",
                    "label": 0
                },
                {
                    "sent": "This location is very very close to the expected.",
                    "label": 0
                },
                {
                    "sent": "The mean of all the other objects.",
                    "label": 0
                },
                {
                    "sent": "So here now this model is driven just by the prior as gentle.",
                    "label": 0
                },
                {
                    "sent": "There's more and more training samples.",
                    "label": 0
                },
                {
                    "sent": "The model begins to get more specific to this object and it's just regular eyes a little bit by the by the player I'll finally with 15 training samples you get this different model that is maybe.",
                    "label": 0
                },
                {
                    "sent": "More close to what do we expect to find in the piano and respect to find this?",
                    "label": 0
                },
                {
                    "sent": "And these are some performance plots in which they compare what happens as you increase the number of training samples.",
                    "label": 0
                },
                {
                    "sent": "What is the performance server that you get?",
                    "label": 0
                },
                {
                    "sent": "This is when you have this project on the model parameters and this is when you train each model independently.",
                    "label": 0
                },
                {
                    "sent": "And then find that they converge much faster when they had this prior again, this project is a very weak, very weak sharing.",
                    "label": 0
                },
                {
                    "sent": "Now because the only thing that can communicate, communicate information from one object to another is this expected space of parameters?",
                    "label": 0
                },
                {
                    "sent": "Now what is the more likely parameters that you may have from other objects and all the objects are constrained by this prior in the same way?",
                    "label": 0
                },
                {
                    "sent": "Maybe you want to have models that are a little bit richer than that, and then there is also work by cramp, given an ammit in which they try to do against character detection and what they're going to do is they're going to train a classifier.",
                    "label": 0
                },
                {
                    "sent": "They use some variant of boosting in which they're going to train of just incrementally, so they start with one object, they select all the features that they need to detect that of that character on the image, and then they're going to train a second character and what they're going to do is they're going to try to reduce.",
                    "label": 0
                },
                {
                    "sent": "As many features from the first one as possible, and then for the third character, they're going to try to train.",
                    "label": 0
                },
                {
                    "sent": "Try to reduce as many characters parts from the 1st and the 2nd character, and so on and what they find is as you increase, the number of classes that you have, this kind of logarithmic growth of the number of features that you need then.",
                    "label": 0
                },
                {
                    "sent": "But again, in this paper they don't really make any claim about the fact that.",
                    "label": 0
                },
                {
                    "sent": "Not just, it's not just giving you an an improvement in the complexity of their classifier.",
                    "label": 0
                },
                {
                    "sent": "The fact that you don't increase linearly is also the fact that you are actually learning faster because the features that you pre selected are better features.",
                    "label": 0
                },
                {
                    "sent": "I mean they just just Ingredion have a lower threshold for the.",
                    "label": 0
                },
                {
                    "sent": "Just like in boosting, just half a Dictionary of possible features answer the best one incrementally.",
                    "label": 0
                },
                {
                    "sent": "Just a greedy procedure to select features have a bias in favor of the existing features.",
                    "label": 0
                },
                {
                    "sent": "Yes, so first, yeah, they have a threshold, so the first they select as many features as they can from the previous detectors to reach until they reach on convergence and then they begin adding new features.",
                    "label": 0
                },
                {
                    "sent": "So then there is also work by Bart and Shima Newman, in which.",
                    "label": 0
                },
                {
                    "sent": "They just patches and let's say that they are.",
                    "label": 0
                },
                {
                    "sent": "They have a detector that is able to detect horses, so these are different patches that are good for detecting horses just in just some normalized correlation with the image.",
                    "label": 0
                },
                {
                    "sent": "And now you want to take dogs, but you only have one training sample.",
                    "label": 0
                },
                {
                    "sent": "So from that training sample you construct a lot of patches, but you don't know which ones are going to be good.",
                    "label": 0
                },
                {
                    "sent": "So what they do is they take the horse patches and they look for doc patches that are similar to horse patches that were useful for detecting horses.",
                    "label": 0
                },
                {
                    "sent": "And what they claim is that these patches are going to be better for detecting also dogs.",
                    "label": 0
                },
                {
                    "sent": "Of course this will only work if there is some similarity between these two objects, but they report some improvement in performances by doing that by doing that done by just training with one training sample, which is very poor.",
                    "label": 0
                },
                {
                    "sent": "To distinguish between dogs and horses, OK then.",
                    "label": 0
                },
                {
                    "sent": "There is some mixture, but it is still better that you have just one training sample.",
                    "label": 0
                },
                {
                    "sent": "I don't know if they make a straight comparison on that, but I have some later results that will talk about that too.",
                    "label": 0
                },
                {
                    "sent": "But normally when you share a lot of structure between different tasks, what you get is you improve every independent task, but you get some confusion between the tasks, yeah?",
                    "label": 0
                },
                {
                    "sent": "The user feature is that they just use a matching type of.",
                    "label": 0
                },
                {
                    "sent": "Every feature, so every feature is just is a mask that you are going to just for doing much.",
                    "label": 0
                },
                {
                    "sent": "Normalized correlation with the image applies on threshold.",
                    "label": 0
                },
                {
                    "sent": "Different scalings or different?",
                    "label": 0
                },
                {
                    "sent": "Yes yes, then to get to get a scaling variance as well as translation invariants, you do it by just comparing the Patch.",
                    "label": 0
                },
                {
                    "sent": "The Patch with all possible locations and all possible scales.",
                    "label": 0
                },
                {
                    "sent": "In this case, they don't play with orientation, but you could do that, but then it will be really slow.",
                    "label": 0
                },
                {
                    "sent": "On this ship feature is different from what you're saying.",
                    "label": 0
                },
                {
                    "sent": "Here are more or less in the line.",
                    "label": 0
                },
                {
                    "sent": "Sift well, see features is another way of representing some local information.",
                    "label": 0
                },
                {
                    "sent": "Here they just patches, but they could have just asked descriptors.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "So this if descriptor is basically there are two parts now.",
                    "label": 0
                },
                {
                    "sent": "One that is detection of the interest point you are going to look at an image and the text.",
                    "label": 0
                },
                {
                    "sent": "Some parts of the image that looks interesting.",
                    "label": 0
                },
                {
                    "sent": "I'll actually talk about them later and then a structural representation of that location here.",
                    "label": 0
                },
                {
                    "sent": "What they do is as well as the representation they just patches and save descriptors used the SIFT descriptor.",
                    "label": 0
                },
                {
                    "sent": "Is nice properties like invariants on the rotation scale in life?",
                    "label": 0
                },
                {
                    "sent": "Well, they don't have invariants in rotation.",
                    "label": 0
                },
                {
                    "sent": "They have they have because of normalization, no, there's not inviting rotation becaused you still have divide its patching 4 by 4.",
                    "label": 0
                },
                {
                    "sent": "So you want to have invariants in rotation.",
                    "label": 0
                },
                {
                    "sent": "You have to normalize first the Patch locally in the detection process.",
                    "label": 0
                },
                {
                    "sent": "The representation itself is not rotation invariant.",
                    "label": 0
                },
                {
                    "sent": "This is a little bit rotation invariant, but it should rotate like 45 degrees is not the same descriptor anymore.",
                    "label": 0
                },
                {
                    "sent": "Water, not this one.",
                    "label": 0
                },
                {
                    "sent": "This one here.",
                    "label": 0
                },
                {
                    "sent": "Each Patch has a reference frame, so each Patch is relative to the center of the object.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk a little.",
                    "label": 0
                },
                {
                    "sent": "I'm going to clarify this in a moment, so it's not a bag of words.",
                    "label": 0
                },
                {
                    "sent": "So here is a very simple way of doing multiclass learning.",
                    "label": 0
                },
                {
                    "sent": "One is OK, you can train just a bunch of independent classifiers, or you could have just a classifier that looks like this and what you have some features that are shared across all different tasks.",
                    "label": 0
                },
                {
                    "sent": "And then you have some other features that are more and more specific, and so these are very simple, simple thing to do.",
                    "label": 0
                },
                {
                    "sent": "So here I'm going just very briefly describe some some boosting approach to solve that problem.",
                    "label": 0
                },
                {
                    "sent": "Now boosting is just given just building a classifier just in an additive model.",
                    "label": 0
                },
                {
                    "sent": "Each function here is this weak learner an in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Normally each of these functions is going to be 1 feature, something that you can compute independently of how do you compute the other features.",
                    "label": 0
                },
                {
                    "sent": "Let's say this could be represented by 1 Patch and then the result of applying normalized correlation with the image will give you the output of this classifier plus a threshold and so on.",
                    "label": 0
                },
                {
                    "sent": "An OK boosting of the message.",
                    "label": 0
                },
                {
                    "sent": "This potential loss.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to enter in any of these details.",
                    "label": 0
                },
                {
                    "sent": "You already know all this things, probably an.",
                    "label": 0
                },
                {
                    "sent": "The reason why boosting has been very useful in computer vision is that it's very simple.",
                    "label": 0
                },
                {
                    "sent": "It provides a very efficient algorithm for doing sparse feature selection, although you could use other things, But this was very easy to implement.",
                    "label": 0
                },
                {
                    "sent": "It doesn't require any external optimization tool on computer vision.",
                    "label": 0
                },
                {
                    "sent": "People lies a lot these things because they understand what they are doing then still has performances that are compatible to more sophisticated techniques such as supervector machines and so on and.",
                    "label": 0
                },
                {
                    "sent": "So here is 1 example of what will be a part based object detector just in patches.",
                    "label": 0
                },
                {
                    "sent": "So let's say that you want to take the car.",
                    "label": 0
                },
                {
                    "sent": "Your model could be this one.",
                    "label": 0
                },
                {
                    "sent": "You have a collection of patches that are have some displacement relative to the center of the object and so every Patch.",
                    "label": 0
                },
                {
                    "sent": "The way that you are going to detect account on the images.",
                    "label": 0
                },
                {
                    "sent": "Just take this Patch.",
                    "label": 0
                },
                {
                    "sent": "You apply normalized correlation with the image.",
                    "label": 0
                },
                {
                    "sent": "Deployed the threshold and whatever point had a value above the threshold is going to vote for the presence of the object in this location, and so the same thing for the other patches.",
                    "label": 0
                },
                {
                    "sent": "Or if you want to take the screen.",
                    "label": 0
                },
                {
                    "sent": "So this could be a possible representation for a screen.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of different week detectors that you could use is not just patches that are sick features and there are a lot of different things that people have been.",
                    "label": 0
                },
                {
                    "sent": "Justin and it actually makes a big difference when you use.",
                    "label": 0
                },
                {
                    "sent": "So there is a lot of research and just trying to find what is the best kind of leak detector that you could use.",
                    "label": 0
                },
                {
                    "sent": "Aren't states so probably depends from which institution are coming?",
                    "label": 0
                },
                {
                    "sent": "Or is there any real evaluation which features attacked?",
                    "label": 0
                },
                {
                    "sent": "Are these people doing evaluations?",
                    "label": 0
                },
                {
                    "sent": "Systematic evaluations?",
                    "label": 0
                },
                {
                    "sent": "An like people in Oxford like under system and groups or Cordelia Smith jump owns.",
                    "label": 0
                },
                {
                    "sent": "These people are doing systematic evaluation of detectors and representations.",
                    "label": 0
                },
                {
                    "sent": "That was the message the message is that there are a bunch of that work more or less the same.",
                    "label": 0
                },
                {
                    "sent": "And that it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So as soon as this kind of reasonable so.",
                    "label": 0
                },
                {
                    "sent": "So maybe now, the things that begin to work better, it's just it's fragments.",
                    "label": 0
                },
                {
                    "sent": "So run some edge cutting edge detector and then just some transfer.",
                    "label": 0
                },
                {
                    "sent": "This towns but just wanna fragment not on the entire silhouette and then vote for the center.",
                    "label": 0
                },
                {
                    "sent": "Dustin seems to be the best.",
                    "label": 0
                },
                {
                    "sent": "Sorry is that more interest point so it is containing the geometry is so interest point can also be used.",
                    "label": 0
                },
                {
                    "sent": "So there are two parts when you try to detect features.",
                    "label": 0
                },
                {
                    "sent": "1st is to the site in which locations of the image you want to apply the feature and then apply the feature whatever it is that you choose.",
                    "label": 0
                },
                {
                    "sent": "What you could do it densely.",
                    "label": 0
                },
                {
                    "sent": "So the interest point, operate operators or the region of interest detectors.",
                    "label": 0
                },
                {
                    "sent": "They only talk about how do you are going to choose pre selected locations in the image in which are going to apply your operator.",
                    "label": 0
                },
                {
                    "sent": "But then now you can plug their whatever features you want.",
                    "label": 0
                },
                {
                    "sent": "There could be an edge fragment.",
                    "label": 0
                },
                {
                    "sent": "What it could be, some self descriptor or one Patch.",
                    "label": 0
                },
                {
                    "sent": "So I'm question is this the best way to do the object recognition?",
                    "label": 0
                },
                {
                    "sent": "At this point people think this is the way you think is the best for Justin.",
                    "label": 0
                },
                {
                    "sent": "Just patches, patches and this kind of.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "I don't think this is necessarily the best.",
                    "label": 0
                },
                {
                    "sent": "If you extract edges, I think it was a little bit better, but whenever it's just this kind of boosted classifiers or things like that, it's very difficult to beat today and there are more sophisticated algorithms and I will talk about some of them.",
                    "label": 0
                },
                {
                    "sent": "I wanna graduation yeah well that's very similar.",
                    "label": 0
                },
                {
                    "sent": "You could just tell one to get a sparse.",
                    "label": 0
                },
                {
                    "sent": "Disadvantage of the advantage here is that there is 10 lines of Matlab.",
                    "label": 0
                },
                {
                    "sent": "That's the only advantage.",
                    "label": 0
                },
                {
                    "sent": "Prism depends on situation, right?",
                    "label": 0
                },
                {
                    "sent": "In your situation, doesn't stream.",
                    "label": 0
                },
                {
                    "sent": "You still have to use credit, which generally depends.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's lower, sometimes faster.",
                    "label": 0
                },
                {
                    "sent": "But in this case I kind of don't quite a season as well for the training.",
                    "label": 0
                },
                {
                    "sent": "So in runtime the bottleneck is the computation of the features is not really.",
                    "label": 0
                },
                {
                    "sent": "How do you combine them on in training?",
                    "label": 0
                },
                {
                    "sent": "Then it make make.",
                    "label": 0
                },
                {
                    "sent": "It may make a difference what the optimization you're using is, but even this this algorithm just takes with many many object classes takes 3 hours, is not that bad.",
                    "label": 0
                },
                {
                    "sent": "And it is all in Matlab, so if you optimize the code, it could be really fast.",
                    "label": 0
                },
                {
                    "sent": "So not, it's not a big deal.",
                    "label": 0
                },
                {
                    "sent": "Recommendations, but rather than just using boosting, I think people is mostly just in boosting for a moment.",
                    "label": 0
                },
                {
                    "sent": "I'm not L1 because L1 requires just in some optimization toolbox.",
                    "label": 0
                },
                {
                    "sent": "No, you could know they know how to do it, but that's why you're going to call something else.",
                    "label": 0
                },
                {
                    "sent": "So what is really important here?",
                    "label": 0
                },
                {
                    "sent": "Many times this was the representation.",
                    "label": 0
                },
                {
                    "sent": "Just going to Deuces people is making an effort in trying to find what are the best features.",
                    "label": 0
                },
                {
                    "sent": "But then the second algorithm that reduce after that.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it doesn't make it really difference and I think that it may begin to make a difference when you have many classes.",
                    "label": 0
                },
                {
                    "sent": "So now if you begin to think about transferring knowledge between different objects then it will begin to be an important issue.",
                    "label": 0
                },
                {
                    "sent": "But I think that in the single class H. And maybe it wasn't that that a big deal, and in fact, like the Supervector machines, which are kind of complicated.",
                    "label": 0
                },
                {
                    "sent": "Then you have L2 norm which kind of gives the same results and so on, so.",
                    "label": 0
                },
                {
                    "sent": "It's not very clear what can you do with better machine learning at this level, and in fact like for character recognition, some of the best algorithms are just nearest neighbors, have the right features and apply nearest neighbors and it gets almost the best performances, sorry.",
                    "label": 0
                },
                {
                    "sent": "The 1st oh.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbors for character recognition.",
                    "label": 0
                },
                {
                    "sent": "There are not many characters, is not very slow, is actually quite fast.",
                    "label": 0
                },
                {
                    "sent": "There's not a problem.",
                    "label": 0
                },
                {
                    "sent": "The bottleneck is computing the feature.",
                    "label": 0
                },
                {
                    "sent": "So once you have the features, the dimensionality of the space is not that high, so you can do anything you want.",
                    "label": 0
                },
                {
                    "sent": "Well, but in character recognition, if you have the right invariances, the training data is not that large.",
                    "label": 0
                },
                {
                    "sent": "This year this I recall one nearest neighbor, not even kind of oh, it's yeah.",
                    "label": 0
                },
                {
                    "sent": "One nearest neighbors is already probably recently this.",
                    "label": 0
                },
                {
                    "sent": "This community of people from this community said one nearest every unbeatable for many many practical cases.",
                    "label": 0
                },
                {
                    "sent": "So there was.",
                    "label": 0
                },
                {
                    "sent": "I mean, there is the world by John Raccoon that has.",
                    "label": 0
                },
                {
                    "sent": "That may be the best character recognition today, but then there was Jitendra Malik's group, which apply the shape context, which is just a small variant of C features.",
                    "label": 0
                },
                {
                    "sent": "Plus I one years neighbor and it almost got the same performance is really the difference was.",
                    "label": 0
                },
                {
                    "sent": "I think that like on May might make something like 50 false 50 classification errors in a data set of many 1000 characters.",
                    "label": 0
                },
                {
                    "sent": "So it's really on the noise level.",
                    "label": 0
                },
                {
                    "sent": "Now comparing the two algorithms and maybe the other one is just making five more errors, so it's not significant and is 1 years neighbor not 12 layer neural network.",
                    "label": 0
                },
                {
                    "sent": "So representation may be very important, so this is just an example of how that after one week that software will work.",
                    "label": 0
                },
                {
                    "sent": "Just take one Patch.",
                    "label": 0
                },
                {
                    "sent": "Big Data label deficit which you press translators?",
                    "label": 0
                },
                {
                    "sent": "Yes yes yes.",
                    "label": 0
                },
                {
                    "sent": "So in that case is not talking at all about multitask transfer and so any any of that in terms of the size of the training data.",
                    "label": 0
                },
                {
                    "sent": "It needs a big training data set, yeah, but if you have it and it's there.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So of course another another tool will give you a more compressed representation of the training set, but part of that is giving you something else.",
                    "label": 0
                },
                {
                    "sent": "What is just compressing the data set?",
                    "label": 0
                },
                {
                    "sent": "But when you want to transfer it to other tasks, yes, I agree.",
                    "label": 0
                },
                {
                    "sent": "I mean concentration is one of the places we have the most.",
                    "label": 0
                },
                {
                    "sent": "The largest data sets of label data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, I think that for multiclass problems, having good representations that really compressed your data so they just track what is important that can be transferred from the object is going to make a big difference because now what you want to say is OK, how the classification performance is involved when you have only one training sample and not a million training samples.",
                    "label": 0
                },
                {
                    "sent": "And in that case having the right algorithm is going to be critical, but in the single class H. Or just in this kind of approaching classification classifiers, it was not.",
                    "label": 0
                },
                {
                    "sent": "It was not a goal.",
                    "label": 0
                },
                {
                    "sent": "Nobody was thinking of solving that problem because it was not necessary.",
                    "label": 0
                },
                {
                    "sent": "So here is just an example of a screen detection, just in a boosted classifier.",
                    "label": 0
                },
                {
                    "sent": "So this will be just in the first feature, just some corner, and doing normalized correlation with the image.",
                    "label": 0
                },
                {
                    "sent": "This is just a single scale applying address called.",
                    "label": 0
                },
                {
                    "sent": "This is the output of the classifier for the first feature.",
                    "label": 0
                },
                {
                    "sent": "Then you apply the second feature and you combine it with the 1st and so on and at the end you get something that begins to detect the screen.",
                    "label": 0
                },
                {
                    "sent": "So I just called this.",
                    "label": 0
                },
                {
                    "sent": "You have a kind of reliable detection of the screen.",
                    "label": 0
                },
                {
                    "sent": "And this is the classical approach.",
                    "label": 0
                },
                {
                    "sent": "So now you can just multiclass boosting, which is just a very simple, very simple thing to do an, but I'm going to show is that Despite that, this is a very simple thing, very simple way of transferring knowledge between different objects is just.",
                    "label": 0
                },
                {
                    "sent": "It's already given interesting results.",
                    "label": 0
                },
                {
                    "sent": "So here is just again classical multiclass cost function, in which is some the error, the cost for every class and then this is George Multiclass classifier.",
                    "label": 0
                },
                {
                    "sent": "OK, again just an additive model, so we're just going to add weak classifiers that now are multi class in what the structure of these classifiers.",
                    "label": 0
                },
                {
                    "sent": "What is going to be is going to be just a single a single stamp that can be shared across different classes.",
                    "label": 0
                },
                {
                    "sent": "So instead of being a different classifier for every class, you force that a single at a single iteration, the classifier that we are going to add is the same classifier across all the classes that share that feature.",
                    "label": 0
                },
                {
                    "sent": "And the only thing you have to decide is which classes are going to use that feature.",
                    "label": 0
                },
                {
                    "sent": "And so the algorithm is very simple, is a greedy algorithm, just like boosting.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is just a standard boosting in which you have a Dictionary of features from which you can select the next one, and you have to select what is the best feature and the best set of object classes for which this is.",
                    "label": 0
                },
                {
                    "sent": "This feature is going to apply.",
                    "label": 0
                },
                {
                    "sent": "Then, once you have chosen that feature and applied over weight, all the samples and run the next iteration just standard boosting.",
                    "label": 0
                },
                {
                    "sent": "So here is an example of a feature that is very specific.",
                    "label": 0
                },
                {
                    "sent": "So let's say that you have these five of the classes.",
                    "label": 0
                },
                {
                    "sent": "This is your background class.",
                    "label": 0
                },
                {
                    "sent": "The important task here is to discriminate any of these classes against the background.",
                    "label": 0
                },
                {
                    "sent": "Because this is a really difficult task, you want to detect an object, and the most important finished first to detect that object, and it's more difficult to discriminate that object against the background than to say that these two different objects are different.",
                    "label": 0
                },
                {
                    "sent": "So here is you have this feature.",
                    "label": 0
                },
                {
                    "sent": "This feature is very specific to face is so if you look at the distributions of the responses of this feature of face patches or background patches you get a very clear separation of the two is still not a very good detector because this thing here because there are a lot of background patches.",
                    "label": 0
                },
                {
                    "sent": "This is small.",
                    "label": 0
                },
                {
                    "sent": "At the farmers here is actually very, very large and but this feature is so specific to face is that it doesn't separate at all.",
                    "label": 0
                },
                {
                    "sent": "Any of the other classes.",
                    "label": 0
                },
                {
                    "sent": "So this feature is not useful for anything else done.",
                    "label": 0
                },
                {
                    "sent": "Discriminating faces against the background, so here.",
                    "label": 0
                },
                {
                    "sent": "So here there is another feature that is very generic is just a piece of an edge in a particular location relative to the object center.",
                    "label": 0
                },
                {
                    "sent": "So this object, this feature is very generic.",
                    "label": 0
                },
                {
                    "sent": "It's not going to be good to discriminate almost any object against the background, but when you apply it, what you get is that there is some separation between phases of the background is not as good as before, but it still is quite good.",
                    "label": 0
                },
                {
                    "sent": "But what is interesting is that there is also some separation of other objects against the background, so this feature is useful for at least these three objects.",
                    "label": 0
                },
                {
                    "sent": "And it's not just full at all for pedestrians and traffic lights, so for some.",
                    "label": 0
                },
                {
                    "sent": "Size of the set of background that you will display here.",
                    "label": 0
                },
                {
                    "sent": "So the background here.",
                    "label": 0
                },
                {
                    "sent": "Well, this is a related.",
                    "label": 0
                },
                {
                    "sent": "This is a weighted histogram, but there are at the beginning there are like 5000 samples or background patches and maybe 100 samples for every object.",
                    "label": 0
                },
                {
                    "sent": "For fitting at this stage, no, no.",
                    "label": 0
                },
                {
                    "sent": "Well, this is some intermediate stage of the boosting algorithm.",
                    "label": 0
                },
                {
                    "sent": "So this is two different representations that you get if you choose specific features, you will say that the best way of representing the face is just in patches of faces.",
                    "label": 0
                },
                {
                    "sent": "But if your task is to detect many object classes, I'm not just faces.",
                    "label": 0
                },
                {
                    "sent": "The best representation is actually something that may look like this is just a collection of edge fragments and each one has a particular coordinate relative to the center of the object.",
                    "label": 0
                },
                {
                    "sent": "So this is not just a collection of random.",
                    "label": 0
                },
                {
                    "sent": "Edges, but they are located already in the relative location respect ifying them and this is the representation that you get for one way signs and this will be the representation that you get if you train.",
                    "label": 0
                },
                {
                    "sent": "If you train a single detector to discriminate, one way signs against the background, so these are two different representations and they will give you different conclusions.",
                    "label": 0
                },
                {
                    "sent": "So you try to understand what is the best representation for objects.",
                    "label": 0
                },
                {
                    "sent": "If you are only looking at single object classes, you will think that this is the best representation, but if you think of the multi class of the problem then this will be the best representation.",
                    "label": 0
                },
                {
                    "sent": "Just in this kind of architecture and so This is why it is important also to look at multi class objects becausw jamais tray.",
                    "label": 0
                },
                {
                    "sent": "You may get different conclusions about what are the best.",
                    "label": 0
                },
                {
                    "sent": "Presentation for objects.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of features that are learned just in this iterative boosting.",
                    "label": 0
                },
                {
                    "sent": "This boosting algorithm with shared features.",
                    "label": 0
                },
                {
                    "sent": "So here we train the algorithm to discriminate among.",
                    "label": 0
                },
                {
                    "sent": "To detect 20 object classes against the background.",
                    "label": 0
                },
                {
                    "sent": "And these are the features that got selected by the algorithm, sorted by the degree of sharing that they had.",
                    "label": 0
                },
                {
                    "sent": "So in this matrix are white entry means that this feature is just by by this object.",
                    "label": 0
                },
                {
                    "sent": "So here is a feature that is just by almost all there just by for some reason just the can is not yours.",
                    "label": 0
                },
                {
                    "sent": "But this is just noise.",
                    "label": 0
                },
                {
                    "sent": "And then as you go to the right you have features that are only used by maybe 3 objects or four or so.",
                    "label": 0
                },
                {
                    "sent": "So these are very specific specific features, and in fact when you look at the features that are more share what you get.",
                    "label": 0
                },
                {
                    "sent": "If you put them in, if you draw the image that they're drawing, it seems to look like just the outline of a generic object is something that is kind of center on the Patch, and that's destructive that is shared across all possible objects that are well located, well, well bounded by a bounding box, and so another way of saying so here is.",
                    "label": 0
                },
                {
                    "sent": "Just the first thing is the fact that when you just share representations, of course efficiency is going to be improved.",
                    "label": 0
                },
                {
                    "sent": "So as you increase the number of object classes, this is the number of features that you need to reach a particular average performance, and so this linear growth is what happens if you just train all the objects independently.",
                    "label": 0
                },
                {
                    "sent": "So this is nothing surprising here, and this is the increasing complexity that you get when you share features, so you get a growth that is kind of logarithmic, and this growth has been observed by other works in the past.",
                    "label": 0
                },
                {
                    "sent": "And so here you don't have the complexity of the classifier that grows linearly with the number of the classes but logarithmically.",
                    "label": 0
                },
                {
                    "sent": "So this is important, but the most well, yeah.",
                    "label": 0
                },
                {
                    "sent": "There is another way to get to error correcting code.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Erica, error correcting codes will also.",
                    "label": 0
                },
                {
                    "sent": "It will also give you this kind of behavior.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, I'm not saying that this is the only way of getting this at all, but I'm saying is when you have this share representations, you get this kind of behaviors.",
                    "label": 0
                },
                {
                    "sent": "And whatever the whatever the algorithm reduces, you could just multilayer network anything.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "You will get distance.",
                    "label": 0
                },
                {
                    "sent": "In fact there are results that been even in the biology community when they do modeling.",
                    "label": 0
                },
                {
                    "sent": "They try to to study how many neurons do you need to represent objects and they also show that when you have this distributed representations, you have a logarithmic growth on the number of networks that you need.",
                    "label": 0
                },
                {
                    "sent": "So it's the same thing it doesn't, and in that case is a completely different structure.",
                    "label": 0
                },
                {
                    "sent": "An empirical is that is empirical.",
                    "label": 0
                },
                {
                    "sent": "It is empirical.",
                    "label": 0
                },
                {
                    "sent": "Sorry in the case of.",
                    "label": 0
                },
                {
                    "sent": "Well, but but but the finish is going to the pen a lot on the task that you're solving.",
                    "label": 0
                },
                {
                    "sent": "If they're completely unrelated and their features are completely unmatched, probably therefore is going to be a very badly.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show some results about how the the tasks that you're trying to solve influenced this result.",
                    "label": 0
                },
                {
                    "sent": "Also, another thing is if you look at the number of features that you need to detect one single object class.",
                    "label": 0
                },
                {
                    "sent": "So when you train the objects independently for reaching some level of performance is June 8th six patches, so you need six parts to represent the object.",
                    "label": 0
                },
                {
                    "sent": "But when you use as features, the features that were given by the algorithm, the share features you need many more and in fact the more of the classes you have, the more features you need per class.",
                    "label": 0
                },
                {
                    "sent": "And the reason is that because they become more and more generic, they're less and less informative for every single class.",
                    "label": 0
                },
                {
                    "sent": "So you need more of them.",
                    "label": 0
                },
                {
                    "sent": "But that's also expected.",
                    "label": 0
                },
                {
                    "sent": "This on the daughter cells.",
                    "label": 0
                },
                {
                    "sent": "Of course one way also.",
                    "label": 0
                },
                {
                    "sent": "I've seen that things make sense is run some clustering algorithm just in some distance between the objects based on the number of features that they share.",
                    "label": 0
                },
                {
                    "sent": "So in this graph the more features are shared by by by two objects, the closer they are going to be, so you can see that most of the things make sense like a bottle and a person.",
                    "label": 0
                },
                {
                    "sent": "If you don't think about the scale just in a normalized frame, they look very similar or a poster on a computer screen.",
                    "label": 0
                },
                {
                    "sent": "They are very similar to.",
                    "label": 0
                },
                {
                    "sent": "So this is also a way of visualizing that the Sheriff structure that you're learning makes sense, but this.",
                    "label": 0
                },
                {
                    "sent": "Saying something is.",
                    "label": 0
                },
                {
                    "sent": "Is putting objects by the similarities putting together?",
                    "label": 0
                },
                {
                    "sent": "Agreed that you would say, well, this really nicely reflects your understanding.",
                    "label": 0
                },
                {
                    "sent": "Well, I think I will be very surprised if the screen was nearby the car side.",
                    "label": 0
                },
                {
                    "sent": "I think you could say that something is going wrong, but it's not the case.",
                    "label": 0
                },
                {
                    "sent": "Now the screen is nearby the poster, which seems.",
                    "label": 0
                },
                {
                    "sent": "Very reasonable thing to do now.",
                    "label": 0
                },
                {
                    "sent": "Both are square, sorry.",
                    "label": 0
                },
                {
                    "sent": "The trash, so yeah, yeah so here here you have like in this cluster here?",
                    "label": 0
                },
                {
                    "sent": "Yes no yes at all levels it makes sense.",
                    "label": 0
                },
                {
                    "sent": "So here, like in this cluster, now is almost vertical stuff.",
                    "label": 0
                },
                {
                    "sent": "Now that has kind of square boundaries.",
                    "label": 0
                },
                {
                    "sent": "And here you have this stop sign and then do not enter sign.",
                    "label": 0
                },
                {
                    "sent": "Here you have things that are mostly horizontal.",
                    "label": 0
                },
                {
                    "sent": "Here there are things that are mostly vertical, so it makes kind of sense.",
                    "label": 0
                },
                {
                    "sent": "So you can do the same thing for multi view of the direction you want to take different views of objects.",
                    "label": 0
                },
                {
                    "sent": "So you could also think that instead of training one different detector for every viewpoint, you could just try to share features between them, so you will have features that are kind of viewing Varian and then there will be other features that are more view specific.",
                    "label": 0
                },
                {
                    "sent": "So the structure of the sharing is going to depend on the groups of symmetry that that object has.",
                    "label": 0
                },
                {
                    "sent": "Then there are some interesting things that could be explored are well.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip here, so this is an example of.",
                    "label": 0
                },
                {
                    "sent": "What is the best generalization that you can get as you increase the number of training samples?",
                    "label": 0
                },
                {
                    "sent": "So there are two situations here.",
                    "label": 1
                },
                {
                    "sent": "Two different tasks.",
                    "label": 0
                },
                {
                    "sent": "In the first case, do you wanna learn multiclass object detector that has to discriminate?",
                    "label": 0
                },
                {
                    "sent": "Has to detect these 12 object classes.",
                    "label": 0
                },
                {
                    "sent": "They are unrelated, they're just pick up random and the task is to detect each object class against the background.",
                    "label": 0
                },
                {
                    "sent": "So it's a detection task.",
                    "label": 0
                },
                {
                    "sent": "In here the task is to detect different viewpoints of the same object.",
                    "label": 0
                },
                {
                    "sent": "In both cases there are 12.",
                    "label": 0
                },
                {
                    "sent": "Classes, but here they are visually different.",
                    "label": 0
                },
                {
                    "sent": "Here there are more more related, so when you train independent classifiers for each task, as you increase the number of training samples, OK in both cases you get better performances as expected.",
                    "label": 0
                },
                {
                    "sent": "So in blue is what you get if you train the classifiers independently and in red is what you get if you train the classifiers jointly.",
                    "label": 0
                },
                {
                    "sent": "So here there is some sharing, so there is some better generalization is not very strong because the objects are very unrelated.",
                    "label": 0
                },
                {
                    "sent": "So here basically what you get is that the number of training samples that you need.",
                    "label": 0
                },
                {
                    "sent": "To get the same generalization the same performance.",
                    "label": 0
                },
                {
                    "sent": "Then when you train the classes independently is Janet half the amount of data data for training.",
                    "label": 0
                },
                {
                    "sent": "That means that more or less there is always one class that has something that you could share an and would benefit a little bit from it, but you are only improving a factor of two.",
                    "label": 0
                },
                {
                    "sent": "The amount of training samples that you need in the case of different viewpoints, there are a lot of similarities like viewpoints that are nearby are going to share a lot of structure.",
                    "label": 0
                },
                {
                    "sent": "And or like this angle and this angle, they are almost identical.",
                    "label": 0
                },
                {
                    "sent": "So there is a lot of sharing to be done and hear what you find is that you need five times less training data.",
                    "label": 0
                },
                {
                    "sent": "If you are training this jointly, which is actually maybe very natural for most of the people working on machine learning.",
                    "label": 0
                },
                {
                    "sent": "But in computer vision this is not something that people have been exploiting at all, and so I think there is a lot of things that you could try on computer vision because there are a lot of things that are not.",
                    "label": 0
                },
                {
                    "sent": "Not explore and that are obvious.",
                    "label": 0
                },
                {
                    "sent": "Then, so this is just some standard results from one of the data sets.",
                    "label": 0
                },
                {
                    "sent": "This is the Pascal collection for car detection.",
                    "label": 0
                },
                {
                    "sent": "This is a multi view task and the different lines here are different precision recalls for different algorithms.",
                    "label": 0
                },
                {
                    "sent": "Here in Black is the performances that we get when we train a classifier with one classifier per viewpoint with only one training sample.",
                    "label": 0
                },
                {
                    "sent": "So it behaves very badly, although there are some algorithms that are about the same level and they just.",
                    "label": 0
                },
                {
                    "sent": "50 training samples.",
                    "label": 0
                },
                {
                    "sent": "So I wonder what they did?",
                    "label": 0
                },
                {
                    "sent": "In blue, here is the same same thing, but now with shared features.",
                    "label": 0
                },
                {
                    "sent": "So now we train jointly, but again only one training sample per class.",
                    "label": 0
                },
                {
                    "sent": "And now the performances are actually among the best ones.",
                    "label": 0
                },
                {
                    "sent": "So there is only one here that is really much better.",
                    "label": 0
                },
                {
                    "sent": "So this performance is obtained with just one training samples and I think the other algorithms are just in 50.",
                    "label": 0
                },
                {
                    "sent": "So here in green is what you get when you use 50 training samples, but again independently trained in training every every classifier and in red is what you get if you turn all the classifiers jointly.",
                    "label": 0
                },
                {
                    "sent": "So you get very very good performances and there is a big benefit from the fact that you are turning all these things jointly.",
                    "label": 0
                },
                {
                    "sent": "So again, not the more related to task, the stronger the sharing is going to be.",
                    "label": 0
                },
                {
                    "sent": "So here if you are interested in doing emotion recognition but also face detection at the same time, So what you could do is to build a detector for every emotion and this detector.",
                    "label": 0
                },
                {
                    "sent": "What is going to do is going to do face detection, an emotional recognition at the same time, and these are the features, the features that we obtain when we run this multiclass boosting algorithm and what we get is that the first features are.",
                    "label": 0
                },
                {
                    "sent": "Totally generic, they're shared across all different emotions.",
                    "label": 0
                },
                {
                    "sent": "These features are just doing face detection.",
                    "label": 0
                },
                {
                    "sent": "They don't do any.",
                    "label": 0
                },
                {
                    "sent": "Emotional recognition because they are there is no discrimination information between the different classes and at some point you begin to have some features that are good for some emotions but not for others.",
                    "label": 0
                },
                {
                    "sent": "And those are the features that now contribute to emotion recognition.",
                    "label": 0
                },
                {
                    "sent": "You don't know that.",
                    "label": 0
                },
                {
                    "sent": "I mean they might have different weights, no?",
                    "label": 0
                },
                {
                    "sent": "No, here we forced the ways to be the same, so there is.",
                    "label": 0
                },
                {
                    "sent": "There is absolutely no information that is discriminants for each.",
                    "label": 0
                },
                {
                    "sent": "Yeah, everything is shared.",
                    "label": 0
                },
                {
                    "sent": "So when when one feature is shared across different classes it shares the threshold the weights.",
                    "label": 0
                },
                {
                    "sent": "Under the feet on the Patch, everything is there.",
                    "label": 0
                },
                {
                    "sent": "In one question will be OK. How many things do you want to share?",
                    "label": 0
                },
                {
                    "sent": "You want to share only the path you want to share, the weights you want to share the thresholds.",
                    "label": 0
                },
                {
                    "sent": "Market share is normal is better when you have very very few training samples, but you may lose something.",
                    "label": 0
                },
                {
                    "sent": "There is another I don't know how long.",
                    "label": 0
                },
                {
                    "sent": "How much time do I have?",
                    "label": 0
                },
                {
                    "sent": "I can't finish here.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, what do you want me to do?",
                    "label": 0
                },
                {
                    "sent": "OK, so so we're going to stop here or I can just say that another thing that has a lot of has been widely just now in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Is this topic models like LDA?",
                    "label": 0
                },
                {
                    "sent": "Which also provides a natural way of sharing information across documents.",
                    "label": 0
                },
                {
                    "sent": "Now the topics are these things that are shared and is something that is now exploit in computer vision.",
                    "label": 0
                },
                {
                    "sent": "So there is some we have done some work on this.",
                    "label": 0
                },
                {
                    "sent": "Other people have been doing some work on it so I just put the pointer there.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "What's the performance for this emotion detection for the motion detection?",
                    "label": 0
                },
                {
                    "sent": "Well, the face detection, so the part that is doing face detection is a state of the art because it's just patches and but the recognition is about.",
                    "label": 0
                },
                {
                    "sent": "In this data set is like 70% correct, but we haven't done.",
                    "label": 0
                },
                {
                    "sent": "We haven't done.",
                    "label": 0
                },
                {
                    "sent": "It is no, it's a real data set, but it's an excellent.",
                    "label": 0
                },
                {
                    "sent": "Pictures well is real people, but it's very prototypical, so I think if you had to recognize this 16 emotions, even people, we will have problems making fine distinctions within them, and so I don't want to make any claims.",
                    "label": 0
                },
                {
                    "sent": "That means I don't want to say anything just 70% with this data set, which doesn't really mean anything then.",
                    "label": 0
                },
                {
                    "sent": "If I don't give you the details of the data set.",
                    "label": 0
                },
                {
                    "sent": "To have kind of hierarchy of this emotions from this gorgeous flats, it is.",
                    "label": 0
                },
                {
                    "sent": "Yeah it is.",
                    "label": 0
                },
                {
                    "sent": "Yeah no no and in fact the fact that you are learning this share features is already giving you kind of hierarchy in in the sense that you don't know how finally partition the space like in the case of multi view you could imagine Whitewell views.",
                    "label": 0
                },
                {
                    "sent": "Why not 24?",
                    "label": 0
                },
                {
                    "sent": "OK it doesn't matter, you can just as many as you want if you just too many they will share more information and therefore.",
                    "label": 0
                },
                {
                    "sent": "The classifier doesn't get penalized because you make a bad choice, but you still feel then that might be bad.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "How do you do in the location of the object manager?",
                    "label": 0
                },
                {
                    "sent": "The box yeah here is only what I talk is only bounding boxes.",
                    "label": 0
                },
                {
                    "sent": "Vacation also need to look at the correct box, yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so from sorry.",
                    "label": 0
                },
                {
                    "sent": "Crack balls.",
                    "label": 0
                },
                {
                    "sent": "Exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Oh, how do you evaluate the performance?",
                    "label": 0
                },
                {
                    "sent": "How do you evaluate that?",
                    "label": 0
                },
                {
                    "sent": "OK, so normally what people is doing now that was part of the Pascal competition in object detection is is you have to bounding boxes.",
                    "label": 0
                },
                {
                    "sent": "You look at the ratio between the overlapping area and the total area of the two bounding boxes and the ratio between the two should be larger than .5 some arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Quiet.",
                    "label": 0
                },
                {
                    "sent": "So in order to compare different algorithms, think it would be useful to have datasets and those available online or.",
                    "label": 0
                },
                {
                    "sent": "Well, all those data sets are unlabeled, may.",
                    "label": 0
                },
                {
                    "sent": "So I haven't.",
                    "label": 0
                },
                {
                    "sent": "I haven't cleaned it up.",
                    "label": 0
                },
                {
                    "sent": "I don't have now benchmark that you could do this without.",
                    "label": 0
                },
                {
                    "sent": "I should do that soon, but I haven't done it yet.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so this Pascal competition I think was part of the.",
                    "label": 0
                },
                {
                    "sent": "You could count and you pass competition is that God is offering lots of competitions, nothing.",
                    "label": 0
                },
                {
                    "sent": "The division, but we'd be happy to do more than one.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm speaking out of turn, but I mean there are people within Pascal would sort of coordinate changes, and I'm sure they would be very happy to consider doing challenge.",
                    "label": 0
                },
                {
                    "sent": "Let's say on the motion detector.",
                    "label": 0
                },
                {
                    "sent": "Very interesting problem.",
                    "label": 0
                },
                {
                    "sent": "Also for the showcase.",
                    "label": 0
                },
                {
                    "sent": "Yes, I think it certainly is in line with our mission statement.",
                    "label": 0
                },
                {
                    "sent": "The deck and emotions, but I think so.",
                    "label": 0
                },
                {
                    "sent": "I think the goal of this total was to encourage you to look at these data sets because that is how an opportunity for doing a lot of things here, because there is not that much richer research on the computer vision Community jet done on this things, but it's going to change very soon.",
                    "label": 0
                },
                {
                    "sent": "So just do it really fast.",
                    "label": 0
                },
                {
                    "sent": "In two years they will matter.",
                    "label": 0
                },
                {
                    "sent": "Somebody will do it.",
                    "label": 0
                },
                {
                    "sent": "There is also a group that's not working on this idea of the vacant models for.",
                    "label": 0
                },
                {
                    "sent": "Image.",
                    "label": 0
                },
                {
                    "sent": "Analysis, I believe.",
                    "label": 0
                },
                {
                    "sent": "Sammy Benjamin.",
                    "label": 0
                },
                {
                    "sent": "Project yes.",
                    "label": 0
                },
                {
                    "sent": "Another online.",
                    "label": 0
                },
                {
                    "sent": "Nothing else.",
                    "label": 0
                },
                {
                    "sent": "There should be a web page on the Pascal thing.",
                    "label": 0
                },
                {
                    "sent": "I'll check it out.",
                    "label": 0
                },
                {
                    "sent": "So what happened with this old fashion?",
                    "label": 0
                },
                {
                    "sent": "Probably old-fashioned computer vision, wherever it was trying to search geometry in this deep stuff.",
                    "label": 0
                },
                {
                    "sent": "So is this just coming back?",
                    "label": 0
                },
                {
                    "sent": "He's coming back.",
                    "label": 0
                },
                {
                    "sent": "He's coming back.",
                    "label": 0
                },
                {
                    "sent": "So this means that it disappears.",
                    "label": 0
                },
                {
                    "sent": "In the meantime, yes, I think so many times in computer vision will happen.",
                    "label": 0
                },
                {
                    "sent": "Many of the ideas were there very early.",
                    "label": 0
                },
                {
                    "sent": "But then they realize that they lack the algorithms they like the computer power.",
                    "label": 0
                },
                {
                    "sent": "And they like the training the training sets.",
                    "label": 0
                },
                {
                    "sent": "So I think that was one of the big Show Stoppers at very early times.",
                    "label": 0
                },
                {
                    "sent": "So there are some papers that have very nice ideas and there is only one image they test only on one image.",
                    "label": 0
                },
                {
                    "sent": "And there are many papers like that an many times where you think, OK, why context?",
                    "label": 0
                },
                {
                    "sent": "I mean, everybody has been thinking about context on the past.",
                    "label": 0
                },
                {
                    "sent": "Then why didn't work or why is that now people is coming back like if it was something new and the reason is because nobody really managed to make it work.",
                    "label": 0
                },
                {
                    "sent": "So probability statistical models at the time were very.",
                    "label": 0
                },
                {
                    "sent": "They were not very well known by the computer community, Computer Vision, Community, an everything will be really a slow an nothing will really work.",
                    "label": 0
                },
                {
                    "sent": "Now you have all this convex things and begins to be nice, but it wasn't.",
                    "label": 0
                },
                {
                    "sent": "This coming back now when I bought for how.",
                    "label": 0
                },
                {
                    "sent": "Open Facebook, sorry for sure.",
                    "label": 0
                },
                {
                    "sent": "Let's say you presented this.",
                    "label": 0
                },
                {
                    "sent": "Set of approaches which well in some ways shallow.",
                    "label": 0
                },
                {
                    "sent": "Just this shovel features and then you.",
                    "label": 0
                },
                {
                    "sent": "Yes, just playing with this stuff and then something comes out so the geometry stuff with this stuff.",
                    "label": 0
                },
                {
                    "sent": "In what way is it coming back?",
                    "label": 0
                },
                {
                    "sent": "So one thing is to build in 3D models of scenes and then knowing that the objects are going to be inside now and you have this really relationship between the objects an so like this face which showed before, which is kind of class of models.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "Talk about database model of objects so you can have part based models or just have 3D.",
                    "label": 0
                },
                {
                    "sent": "Now the parts are going to be located on for the man.",
                    "label": 0
                },
                {
                    "sent": "And we had a paper on CPR.",
                    "label": 0
                },
                {
                    "sent": "Now that is exactly doing that in which you learn that tables are these flat surfaces.",
                    "label": 0
                },
                {
                    "sent": "Their screens have this corners that are in particular the configuration and so on.",
                    "label": 0
                },
                {
                    "sent": "And you learn all that unsupervised and there are other work in which they try to do exact matching of objects, knowing that there are 3D.",
                    "label": 0
                },
                {
                    "sent": "So you may have different viewpoints and now you try to find what is the corresponding view that you have.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of the most interesting things we're trying to do 3D models of scenes.",
                    "label": 0
                },
                {
                    "sent": "So instead of trying to reason of still instead of trying to solve this coffee beans, head on the coffee beans problem.",
                    "label": 0
                },
                {
                    "sent": "Really thinking that this thing has meaning on here.",
                    "label": 0
                },
                {
                    "sent": "Now you have this plane that is slanted like that, so just picked all the heads to be in a particular arrangement so I don't need to run my detector everywhere.",
                    "label": 0
                },
                {
                    "sent": "I know where faces are going to be here, so why to run just an exhaustive train detector?",
                    "label": 0
                },
                {
                    "sent": "And you do that, sorry.",
                    "label": 0
                },
                {
                    "sent": "The coffee bean exactly.",
                    "label": 0
                },
                {
                    "sent": "So this is not a coffee beans image.",
                    "label": 0
                },
                {
                    "sent": "You know it has meaning and it has a pretty strong regularity.",
                    "label": 0
                },
                {
                    "sent": "And all of them are driven by 3D structure.",
                    "label": 0
                },
                {
                    "sent": "So these things are coming back.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "So let's think.",
                    "label": 0
                }
            ]
        }
    }
}