{
    "id": "xppxq2aq66oxopsxxkbwapcwhefb5qk2",
    "title": "Learning Bayesian networks from postgenomic data with an improved structure MCMC sampling scheme",
    "info": {
        "author": [
            "Dirk Husmeier, School of Mathematics and Statistics, University of Glasgow"
        ],
        "published": "April 17, 2008",
        "recorded": "March 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/licsb08_husmeier_lbn/",
    "segmentation": [
        [
            "Well I'm sister Paula Gee.",
            "We're typically interested in relative network signaling pathways as well, sort of illustrated in this cartoon plot at the top and."
        ],
        [
            "Well, we don't know usually what these pathways look like if we don't have sort of sort of understanding of what this system, then one attempt is to, well, run high throughput experiments.",
            "Get post genomic data, and then put that through some machine learning methodology or some statistical inference procedure to infer."
        ],
        [
            "Structure and one of the methodologies that has been recently widely used is the Bayesian networks.",
            "So, in a nutshell, based networks are in marriage between graph theory and probability theory, so the graph theory part gives us a very abstract, simplified representation of the essential features of a pathway.",
            "So we've got notes that we present the proteins RNA genes.",
            "I've got directed edges, they indicate interactions between these components.",
            "Now these graphs at the feature that they are directed acyclic graphs and that basically sort of the gateway to probability theory because of that.",
            "Because of that feature, we've got a unique method to score these structures in light of the data computing."
        ],
        [
            "Likelihood, so we've got a method to look at the likelihood we can put in prior knowledge to get the posterior probability, and then we can.",
            "But first look for the high scoring structure M. Or if you got noise in the data we like here, you will also want to indentify.",
            "So you thought typical sort of variance uncertainty and sample structures from the."
        ],
        [
            "Your distribution.",
            "No, in principle that can be done."
        ],
        [
            "With MCMC, bear in mind that this distribution can't be computed in closed form because of the."
        ],
        [
            "Motivation factor, but you can set up a Markov chain in principle that converges to that distribution in distribution."
        ],
        [
            "The problem is that we've got a super exponential increase in the complexity, so the number of structures, including super exponentially with the number of now."
        ],
        [
            "So if you set up a standard Markov chain in structure space where you make local changes to the network, you might well Flippen edge, remove an edge at a new edge, then that is unlikely to give you reasonable convergence and mixing.",
            "Answer."
        ],
        [
            "For that reason.",
            "We are looking for one more sophisticated methods that exploits on the intrinsic modularity's that we have in the system.",
            "One of the methods that was proposed in 2004 by frequent color is autumn."
        ],
        [
            "AMC and here we use a slightly different paradigm and that we look at the structure.",
            "The possibility of this structure for this use two different symbols at G or M refers to the structure for model or graph.",
            "So we can factorize that into the following contribution.",
            "They've got individual contributions from the nodes, so some score function, individual contributions from the nodes, and then we've got the parents in here.",
            "So you're not familiar with or if you're not familiar with the networks, so parent is a note that has an edge feeding into your target node.",
            "So if we have an edge from A to B.",
            "Is the parent and be as a child, so we got the parents in here and the data, and then it sort of modular structure looks like a modular structure.",
            "It looks as though we can decompose the whole system into something that looks like sort of over ideal gas, but if it wasn't ideal gas, we could now sample the product configurations forgiven.",
            "Note where conditioning on the data by just taking the local score partition function to normalize that.",
            "Well, unfortunately things aren't that easy because we have got interactions between the nodes because if you know get in you parent configuration then where you might have a directed cycle at the whole structure is not valid.",
            "For that reason, the idea that: frequent came up with is that a condition on a node order, but that means give note K can only take those nodes as parents that are on the left of that order.",
            "So if you have J on the left of K, we can have directed edge from J2K but not from K to J.",
            "Conditioning on this order.",
            "Ann, you automatically make sure that the system is modular because you can't get any directed cycles and all you basically can center or the parent configurations simultaneously in polynomial time.",
            "And, well, we don't have to resort to MCMC simulation.",
            "Only problem with that is that we don't know what the great order."
        ],
        [
            "Yes, and that's why the approach no proposed order treatment is.",
            "But it's a new MCMC scheme set up in order space.",
            "So what we want to do is we get the probability of the data given the order that can be computed in full."
        ],
        [
            "Only time again and then rather doing a structure in MC simulation its structure space.",
            "We have sort of modifications that will apply to the network structure.",
            "They are then always accepted or rejected with the according to them."
        ],
        [
            "Please fix things, will you know?",
            "Set up an MCMC simulation in order space.",
            "So for example, swapping to a."
        ],
        [
            "And then also accepting or rejecting that according to this then that Metropolis Haste."
        ],
        [
            "Well, and then you can show that we get much, much better mixing and convergence.",
            "Your plot taken from their paper.",
            "So that was for network with 37 nodes with structure MCMC, you see that's typical trace plots measuring, say, the marginal likelihood.",
            "In this case well.",
            "You can heavily on the initialization with mixing and convergence problems, but if you do then order space where everything much better.",
            "Considerable improvement in the mixing and the convergence and the reason is basically that because you're modifying, you're averaging over many structures you have likely what services in order space that is much smoother."
        ],
        [
            "So that's a good nice, but there's a problem with the approach that we have a systematic distortion."
        ],
        [
            "Of the prior distribution, and here's a simple illustration where that comes from.",
            "What we want to do is we want to specify the prior distribution in structure space.",
            "Say we go to a database like keg, give information about structures.",
            "Information on structures not on orders.",
            "But because we are living in order space now, we have what we can specify is the distribution of the structure given the order.",
            "But then after marginalized over the orders that basically gives us another distortion.",
            "But let's assume that this is."
        ],
        [
            "Uniform or we have a uniform distribution over the orders, and we assume that this distribution is uniform, meaning that given an order, you say that all valid structures are equally likely.",
            "And we start with this order and then that isn't a valid structure because a precedes B, so we can't be a pro."
        ],
        [
            "No way, but these two structures.",
            "Well, they are possible that the same."
        ],
        [
            "Pretty.",
            "You do the same for this order.",
            "I know you're just mad."
        ],
        [
            "Lies about the orders.",
            "I realized that you're getting distribution that is no longer uniform, so this marginalization over the orders gives you distortion and your pride distribution is not the same as the prior distribution conditioned on the order.",
            "Oh, that is usually not a problem in many applications where you have a lot of data and where the influence is heavily driven, heavily influenced by the likelihood term, but insists aladji quite often, we have a situation that the number of experimental conditions is limited.",
            "The likelihood term isn't that strong, so we want to draw on the prior, so having such a distortion effect is certainly sort of unbounded effect we want."
        ],
        [
            "Something about it?",
            "So that is not the motivation for this presentation.",
            "So our objective is to get a sampler that is as efficient as or MCMC in terms of convergence and mixing, but avoid."
        ],
        [
            "Is that systematic bias?",
            "So first idea is.",
            "We do the same as with or MCMC.",
            "We look at the parents of a given node.",
            "If the local score with the partition function you forget about the order into exactly the same.",
            "Problem with that is we get now sort of high scoring parent configurations but they might lead to directed cycles.",
            "So we can say we identify the parents of these directed cycles, then we often them, as the name suggests that means we just remove all the perms.",
            "And then we sample new parents for these orphaned parents.",
            "Subject today is simplicity."
        ],
        [
            "Sprint.",
            "Illustration.",
            "Select a note sample."
        ],
        [
            "Open configuration."
        ],
        [
            "From that distribution.",
            "We've got two directed cycles.",
            "We offer these notes.",
            "And sample new parent configurations for these.",
            "Well, I called the blue parents subject to the security constraint.",
            "So what is the?"
        ],
        [
            "Problem with this approach.",
            "The problem is that this move isn't reversible, because here you're targeting one node was.",
            "Here we are targeting two nodes.",
            "You would have to set up a complementary conjugate move to get back to the original configuration to get reverse ability, which is an essential essential feature for proving or having assurance that the Markov chain will converge to the correct distribution.",
            "Now the problem is that we could set something up, but it has to go.",
            "Novia is structure with two directed cycles.",
            "That is an invalid structure.",
            "So the problem with this whole approach is an is it becomes pretty messy to workout nor the equations of feet and balance to do like the Hastings vector to make sure that this move that you've enabled design converges to the correct."
        ],
        [
            "Fusion.",
            "So that's why we are stepping back and modify it such that the proposal mechanism becomes slightly simplified.",
            "We identify a pair of nodes.",
            "We often both notes.",
            "And then.",
            "We have two constraints for getting the new parents.",
            "First the cyclicity constraint obviously, but also that the edge gets reversed.",
            "So effectively we're flipping the edge and getting new parent configurations for the two nodes involved.",
            "So that looks like the proposal scheme from order MCMC, but rather conditioning on the order of air conditioning on these two constraints.",
            "Basically city and River."
        ],
        [
            "Sing the edge.",
            "So it is tradition.",
            "You take a note.",
            "Select mode in Edge or from the two nodes.",
            "Select the new parent configurations for these nodes subject to the constraint that we don't get directed cycles and at the edge direction get flipped and reduce.",
            "Import this one."
        ],
        [
            "And then it's easy to show that this is reversible if you know take that as the starting."
        ],
        [
            "Point integration.",
            "Do the same again.",
            "Select the edge.",
            "Often the two notes get your parent configurations.",
            "Again, subject to the simplicity constraint, and then this edge gets flipped and we're back where we started from."
        ],
        [
            "Well that is all very trivial.",
            "If they're forcing optimization algorithm.",
            "In fact, it would be trivial and they wouldn't be giving the talk here.",
            "Women with the challenges that we're not doing optimization with doing sampling and you have to show that the conditional detailed balance is valid and you have to work with the Hastings factor which goes into the Metropolis Hastings acceptance rule that is moderately with mathematical challenges.",
            "And."
        ],
        [
            "This 20 minutes I don't have the time to go into the mathematical details, just sort of the whole take home message.",
            "You get an expression of for the acceptance probability in the metropolis facing steps that depends on various partition functions that you have to compute.",
            "These partition functions make the algorithm more complex computation more expensive, but not more expensive as or MCMC.",
            "So one step of the MCMC procedure is as expensive, roughly as or MCMC as a rule of thumb about 10 times as expensive."
        ],
        [
            "Structure, infancy.",
            "And so another thing they have to worry about is to install the city.",
            "We also have to make sure that the move is not irreducible.",
            "Well, that is able usable, but that move is not irreducible cause if you well to take two nodes equal 3 structures, once you're in that domain, but only flipping between these two configurations, you're not getting there.",
            "But there's a simple theorem that if you take a mixture of transition kernels, you mix and an exotic one with an exotic transition kernel, you get an exotic transition kernel, so all we have to do is we have to mix that move with a move that is organic, and so at each step of the MCMC procedure, you know switch randomly between standard structure MCMC, which is usable, and the new scheme, and that gives us now."
        ],
        [
            "Property corner.",
            "So for evaluation we have to address 3 things, either method but unbiased.",
            "And to improve in that aspect on MCMC, how about convergence mixing?",
            "And how about the network reconstruction accuracy?",
            "Time do I have?"
        ],
        [
            "10 minutes."
        ],
        [
            "Yeah, so analytical comparison.",
            "First thing is when we take sort of.",
            "Create data from next awful noise XOR.",
            "Look at three nodes and you can enumerate all the possible structures."
        ],
        [
            "It is straightforward to compute now the correct posterior disk."
        ],
        [
            "Bution that you get from the date."
        ],
        [
            "Generated from the noise X or and we also can compute the Markov transition kernel analytically for structure MCMC for the new scheme, we just set up North of the Markov chain.",
            "We can look at the whole evolution of the whole probability distribution and compute the carbon fiber divergences between the distribution in the."
        ],
        [
            "The correct distribution and so these are the results that we get for different sample sizes.",
            "In the bottom we show the results that they allow for the extra computational overheads that we have in the computation of the partition functions and the new scheme is the black line.",
            "The dash dotted lines are different versions of structure MCMC, and you find a much faster convergence analytic."
        ],
        [
            "So that is good news, but it's rather simple system.",
            "We haven't considered order MCMC yet to consider or MCMC into go to bigger SSD."
        ],
        [
            "Hambino do a empirical comparison.",
            "If you say I say you take a standard network used in the machine learning community for benchmarking purposes, about 37 loads, 46 directed edges and we compare now these different MCMC schemes and under same the same computational costs.",
            "And.",
            "One of the methods to actually get a feel for what the convergence is is to rerun them twice with two different initializations, compute the marginal posterior probabilities of these edges, and then there's."
        ],
        [
            "Drop them against each other for convergence.",
            "You should not have any dependence on the initialization, so all these entries should be on the diagonal line.",
            "Any deviation from that indicate."
        ],
        [
            "Problems with convergence and.",
            "These are results for different sample sizes for structuring CMC for MCMC and the new scheme.",
            "But the data set is small well.",
            "There's so much information in the data, the likelihood is sort of smooth structuring teams.",
            "He doesn't have a problem, but then as the data set gets larger, no convergence and mixing problems occurs.",
            "You see now that you have more and more off diagonal entries, we're sort of the new schema nor MCMC."
        ],
        [
            "Basically show similar convergence properties and you can go now to higher numbers of data points and you basically find the same behavior similar between the new schema or MCMC iteration of structure MCMC."
        ],
        [
            "So structure MCMC has conversion."
        ],
        [
            "Mixing problems, what does that mean in terms of Internet?"
        ],
        [
            "Book inference well, because we know what the correct network structure is we cannot compute, but how well we learn it.",
            "And we do that for different.",
            "Data set sizes from 25 to 100.",
            "These are different to work values for different thresholds for the false positive rate, either take the whole curve or basically focusing more on the left because usually are more interested in values for loss, low false positive rates, so these are the three methods order and revenue CMC shown improvement as the data set gets larger, well, that's what we expect because before more information, so the reconstruction accuracy should increase should improve.",
            "But order structure MCMC well as various lower indicating convergence problems because the likelihood surface gets more rugged with more convergence and mixing problems."
        ],
        [
            "So upshot instruction team Seattle problems.",
            "We know that already knew that already before, or MCMC and reference EMC shows."
        ],
        [
            "Convergent indexing properties.",
            "But how about the bias?"
        ],
        [
            "Booty.",
            "No, the main motivation for this."
        ],
        [
            "Work.",
            "And here we looked at two.",
            "Well standard machine learning datasets from UCI repository.",
            "We restrict the analysis to five nodes so we can get a complete numeration of all the structures you get the true posterior probabilities of the individual edge features, the marginal posterior probabilities for the different directed edges, and then we compute the difference between the correct values and those."
        ],
        [
            "To get with these sampling schemes and so these are the rules for play and vote different.",
            "Sample sizes so the three diagrams stacked on top of each other or MCMC structuring.",
            "See the new method sandwiched in between and.",
            "Here we are measuring the deviation between the estimated marginal posterior probabilities and that rules with structure MCMC.",
            "They don't have a systematic deviation.",
            "There might be only about 5 nodes, so we can run that through convergence.",
            "We also have the same good news for our method without MCMC.",
            "Deviations and that is not a convergence problem.",
            "That is a systematic problem due to the distortion of the prior knowledge that you get as a consequence of marginal."
        ],
        [
            "Lordis so.",
            "Is finally in."
        ],
        [
            "Sample that is more related to systems prodigy.",
            "We look at the rough part with so that is in regular network involving 21 phosphorylated proteins and phospholipids.",
            "That's related to the mammalian immune system, so for the regulation of this pathway has been implicated in carcinogenesis for that reason, alot of studies have been done on this path.",
            "With there's a lot of knowledge available in the."
        ],
        [
            "Political literature.",
            "And."
        ],
        [
            "We take this data.",
            "Flow cytometry experiment's current offer sucks and coauthors, where they take a laser and shoot a laser, then onto the cells, get the fluorescence signal, and from that they get a indication of the protein concentrations at in different cells."
        ],
        [
            "And."
        ],
        [
            "It's probably knowledge we take well networks extracted from."
        ],
        [
            "Cake.",
            "So prior knowledge is then included.",
            "Your method, first proposed by a group of Japanese."
        ],
        [
            "Researchers to modern coauthors, so where the network where can be represented as a binary matrix.",
            "So Gij is where the edge from I2J is either not one indicating the presence or absence of the edge, and the prior knowledge is sort of a value between order one indicating sort of you believe so, with the absence of an edge, or whether you have the edge and again the properties are used to different symbols, the other P for prime knowledge of B for belief."
        ],
        [
            "Answer You cannot measure the discrepancy between the network and the prior knowledge just by looking at the differences.",
            "And from that we get a prior distribution of the standard Gibbs form."
        ],
        [
            "No, you take two different forms of prior knowledge at first from check into the entrance is that go into the prior knowledge matrix or just the relative frequencies of the edges.",
            "Extra take it took all the half.",
            "Space out of cake and then just counted the number of times that certain edges were found in these networks and so they already frequency is sort of the prior knowledge that goes into the prior knowledge design matrix and we also take the Goldston it next for network published about sex at all.",
            "Now that looks a little bit like looking for the solution with the solution already in mind right here.",
            "The upshot of the objective is not to actually see, but how much we learn.",
            "We want to see what sort of distortion do we get with MCMC and to what extent can be actually alleviate that.",
            "Or compensate that so we take the truth goes to the network and then associate these edges with different confidence scores, right?",
            "Have a high confidence intermediate confidence or low confidence."
        ],
        [
            "And.",
            "Yeah, so these are the results that we get.",
            "These are the oroak scores for cake.",
            "The problem cake and for different."
        ],
        [
            "No prior knowledge matrices obtained from the true network with different code."
        ],
        [
            "Levels and well, OK, and for sort of strong prior knowledge.",
            "We do not find any significant difference in the OR values and that might be too surprising in that.",
            "Bear in mind that the orc value the Roc curve is determined by the ordering of the edges.",
            "The ordering well defined by the model.",
            "Posterior probabilities of these edges.",
            "So we might have a distortion that might not need to different ordering, so it might not be.",
            "The opposite over built in the ropes course.",
            "As the product gets weaker, the distortion effect is stronger, and here with the knobs of a significant deterioration with order empty as a consequence of the distortion of the prior knowledge and signific."
        ],
        [
            "And improvement at the pier."
        ],
        [
            "Nought point nought one significance level.",
            "And yeah, so."
        ],
        [
            "Upshot of all of this is that, well.",
            "Learning sort of Bayesian networks from.",
            "For tsunami data, but it's usually applied to systems that you don't have much prior knowledge where you will actually want to learn about interactions.",
            "Well, one of the Senate methods, Bayesian learning scheme one, requires a well setting up of a complex Markov chain regardless immolation, to ultimately sample from the correct distribution, but with structuring CMC that is to slow where you have too much mixing and convergence problems or MCM principle gives a much better convergence and mixing but has problems.",
            "Well, with systematic distortion of the prior as a consequence of marginalizing over orders, and so we set up a scheme that is in some ways similar in that it uses proposal mechanisms that are similar to or MCMC.",
            "But going back to the original paradigm of doing that in structure space, and so the mathematical challenge here was to actually work out the equations of dependence and derive the Hastings factor consistently.",
            "But the result is that we get mixing that is as good as far South without MCMC.",
            "And we have indications that we have.",
            "We get exclusive reconstruction accuracy that is better the consequence of avoiding the systematic bias.",
            "And this is.",
            "Matt extortion of prior knowledge and therefore there seems to be a scheme that well is useful, might offer useful tool for approaches that aim to integrate systematically.",
            "Integrate prior knowledge, say derived from tech, from other pathway databases.",
            "Between these order updates.",
            "The structure updates and your new update.",
            "You said it was 10 times more computationally expensive.",
            "But I mean once the local exploration, yeah.",
            "Just try it.",
            "Random value basically set.",
            "The parameters are basically coin coin can be biased and weather parameter can be optimized in the burning.",
            "I mean you can go for target value of sale for about 30% of acceptance rate and he basically said that sort of threshold to that level such that you get an optimal value in the burn in.",
            "So that basically is sort of free parameter that determines how fast the mixing is.",
            "Yes, Sir, I'm one of the things about ordering same saving is that in some situations that actually gives an intrusive effects of prior uniform prior structures.",
            "Now obviously here you've got information which is of the sort that you're saying.",
            "Well, I have some certainty about a directed edge between knows, which in a certain says put some constraints on the order.",
            "Is there any way other other methods that I could use that people are using in terms of?",
            "And almost incorporating those those edge information is data in order.",
            "Ordering some seeds sort of Roach you're looking for.",
            "So you're looking for a set of, including prior knowledge, but trying to do that in order space rather than instruction.",
            "We believe this uniform.",
            "Surprise, something that we don't want to use.",
            "We want to do something that's more informative and.",
            "Doing as you're using information on the back of.",
            "Structure which is yeah.",
            "To introduce that information is beautiful.",
            "Well, usually very important information.",
            "The project solution instructor space norms in space.",
            "But if you have something like sort of well, a gene coding phone on a then influencing protein then obviously you have information about the order.",
            "But if you're basically looking for jeans then we don't really have any reliable information on the order now.",
            "Argue that you're saying right?",
            "Well, that is basically some people took the line that we're seeing, right?",
            "We can already specify the structure of the prior infrastructure space anyway, because we should be specifying that in this space of equivalence classes, which is not the same as the structure space, however, so my line is that we break up these equality symmetry between the equivalence classes by bringing in prior knowledge, and that is in some way by incorporating prior knowledge in some way to get slightly more out of the Bayesian network that we interpret them in some way as a causal graph.",
            "Although this sort of speaking that is not correct, but.",
            "Use a sort of prior knowledge to break the symmetry in the equivalence classes, and really taking that, ultimately interpreting that as a causal graph.",
            "You could get even further that use interventional data when you are there.",
            "The better basis for interpreting that as a causal graph, and we have prior knowledge about the cause of structures.",
            "So with respect to think on that basis, we can justify that you're saying right that is really what we want to do.",
            "That is where the prior knowledge is with the orders.",
            "That is much more complex than much more difficult.",
            "This is.",
            "Order yeah, that is correct.",
            "I mean alright, so you're saying that?",
            "OK, there might be sort of latent variables involved, or you might have prior knowledge that is an activator like transcription factor activated transcriptional regulator and then sort of that should be in the order precede or the jeans that are sort of downstream in the process and sort of OK.",
            "I take it that sort of partial knowledge about the order is available.",
            "You can obviously specify that straightforwardly instructor space.",
            "Correctly, so you're saying that were quickly.",
            "If you looking for a hybrid scheme that you will do specify that you specify a prior in order space, but that really needs to basically have to complete sufficient coverage, not only sort of true, some regulators and some downstream regulated genes, but if you only have partial coverage, then as a consequence of marginalizing over orders, but you don't really have any prior knowledge, you're getting a distortion effect in again.",
            "And if you basically avoid the distortion effect, why not do that?",
            "Why we're actually trying to do that in structure space?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well I'm sister Paula Gee.",
                    "label": 0
                },
                {
                    "sent": "We're typically interested in relative network signaling pathways as well, sort of illustrated in this cartoon plot at the top and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, we don't know usually what these pathways look like if we don't have sort of sort of understanding of what this system, then one attempt is to, well, run high throughput experiments.",
                    "label": 0
                },
                {
                    "sent": "Get post genomic data, and then put that through some machine learning methodology or some statistical inference procedure to infer.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Structure and one of the methodologies that has been recently widely used is the Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "So, in a nutshell, based networks are in marriage between graph theory and probability theory, so the graph theory part gives us a very abstract, simplified representation of the essential features of a pathway.",
                    "label": 0
                },
                {
                    "sent": "So we've got notes that we present the proteins RNA genes.",
                    "label": 0
                },
                {
                    "sent": "I've got directed edges, they indicate interactions between these components.",
                    "label": 0
                },
                {
                    "sent": "Now these graphs at the feature that they are directed acyclic graphs and that basically sort of the gateway to probability theory because of that.",
                    "label": 0
                },
                {
                    "sent": "Because of that feature, we've got a unique method to score these structures in light of the data computing.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Likelihood, so we've got a method to look at the likelihood we can put in prior knowledge to get the posterior probability, and then we can.",
                    "label": 0
                },
                {
                    "sent": "But first look for the high scoring structure M. Or if you got noise in the data we like here, you will also want to indentify.",
                    "label": 0
                },
                {
                    "sent": "So you thought typical sort of variance uncertainty and sample structures from the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your distribution.",
                    "label": 0
                },
                {
                    "sent": "No, in principle that can be done.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With MCMC, bear in mind that this distribution can't be computed in closed form because of the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Motivation factor, but you can set up a Markov chain in principle that converges to that distribution in distribution.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is that we've got a super exponential increase in the complexity, so the number of structures, including super exponentially with the number of now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you set up a standard Markov chain in structure space where you make local changes to the network, you might well Flippen edge, remove an edge at a new edge, then that is unlikely to give you reasonable convergence and mixing.",
                    "label": 0
                },
                {
                    "sent": "Answer.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For that reason.",
                    "label": 0
                },
                {
                    "sent": "We are looking for one more sophisticated methods that exploits on the intrinsic modularity's that we have in the system.",
                    "label": 0
                },
                {
                    "sent": "One of the methods that was proposed in 2004 by frequent color is autumn.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "AMC and here we use a slightly different paradigm and that we look at the structure.",
                    "label": 0
                },
                {
                    "sent": "The possibility of this structure for this use two different symbols at G or M refers to the structure for model or graph.",
                    "label": 0
                },
                {
                    "sent": "So we can factorize that into the following contribution.",
                    "label": 0
                },
                {
                    "sent": "They've got individual contributions from the nodes, so some score function, individual contributions from the nodes, and then we've got the parents in here.",
                    "label": 0
                },
                {
                    "sent": "So you're not familiar with or if you're not familiar with the networks, so parent is a note that has an edge feeding into your target node.",
                    "label": 0
                },
                {
                    "sent": "So if we have an edge from A to B.",
                    "label": 0
                },
                {
                    "sent": "Is the parent and be as a child, so we got the parents in here and the data, and then it sort of modular structure looks like a modular structure.",
                    "label": 0
                },
                {
                    "sent": "It looks as though we can decompose the whole system into something that looks like sort of over ideal gas, but if it wasn't ideal gas, we could now sample the product configurations forgiven.",
                    "label": 0
                },
                {
                    "sent": "Note where conditioning on the data by just taking the local score partition function to normalize that.",
                    "label": 0
                },
                {
                    "sent": "Well, unfortunately things aren't that easy because we have got interactions between the nodes because if you know get in you parent configuration then where you might have a directed cycle at the whole structure is not valid.",
                    "label": 0
                },
                {
                    "sent": "For that reason, the idea that: frequent came up with is that a condition on a node order, but that means give note K can only take those nodes as parents that are on the left of that order.",
                    "label": 0
                },
                {
                    "sent": "So if you have J on the left of K, we can have directed edge from J2K but not from K to J.",
                    "label": 0
                },
                {
                    "sent": "Conditioning on this order.",
                    "label": 0
                },
                {
                    "sent": "Ann, you automatically make sure that the system is modular because you can't get any directed cycles and all you basically can center or the parent configurations simultaneously in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "And, well, we don't have to resort to MCMC simulation.",
                    "label": 0
                },
                {
                    "sent": "Only problem with that is that we don't know what the great order.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, and that's why the approach no proposed order treatment is.",
                    "label": 0
                },
                {
                    "sent": "But it's a new MCMC scheme set up in order space.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is we get the probability of the data given the order that can be computed in full.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only time again and then rather doing a structure in MC simulation its structure space.",
                    "label": 0
                },
                {
                    "sent": "We have sort of modifications that will apply to the network structure.",
                    "label": 0
                },
                {
                    "sent": "They are then always accepted or rejected with the according to them.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Please fix things, will you know?",
                    "label": 0
                },
                {
                    "sent": "Set up an MCMC simulation in order space.",
                    "label": 0
                },
                {
                    "sent": "So for example, swapping to a.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then also accepting or rejecting that according to this then that Metropolis Haste.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, and then you can show that we get much, much better mixing and convergence.",
                    "label": 0
                },
                {
                    "sent": "Your plot taken from their paper.",
                    "label": 0
                },
                {
                    "sent": "So that was for network with 37 nodes with structure MCMC, you see that's typical trace plots measuring, say, the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "In this case well.",
                    "label": 0
                },
                {
                    "sent": "You can heavily on the initialization with mixing and convergence problems, but if you do then order space where everything much better.",
                    "label": 0
                },
                {
                    "sent": "Considerable improvement in the mixing and the convergence and the reason is basically that because you're modifying, you're averaging over many structures you have likely what services in order space that is much smoother.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's a good nice, but there's a problem with the approach that we have a systematic distortion.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the prior distribution, and here's a simple illustration where that comes from.",
                    "label": 1
                },
                {
                    "sent": "What we want to do is we want to specify the prior distribution in structure space.",
                    "label": 0
                },
                {
                    "sent": "Say we go to a database like keg, give information about structures.",
                    "label": 0
                },
                {
                    "sent": "Information on structures not on orders.",
                    "label": 0
                },
                {
                    "sent": "But because we are living in order space now, we have what we can specify is the distribution of the structure given the order.",
                    "label": 0
                },
                {
                    "sent": "But then after marginalized over the orders that basically gives us another distortion.",
                    "label": 0
                },
                {
                    "sent": "But let's assume that this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uniform or we have a uniform distribution over the orders, and we assume that this distribution is uniform, meaning that given an order, you say that all valid structures are equally likely.",
                    "label": 0
                },
                {
                    "sent": "And we start with this order and then that isn't a valid structure because a precedes B, so we can't be a pro.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No way, but these two structures.",
                    "label": 0
                },
                {
                    "sent": "Well, they are possible that the same.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty.",
                    "label": 0
                },
                {
                    "sent": "You do the same for this order.",
                    "label": 0
                },
                {
                    "sent": "I know you're just mad.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lies about the orders.",
                    "label": 0
                },
                {
                    "sent": "I realized that you're getting distribution that is no longer uniform, so this marginalization over the orders gives you distortion and your pride distribution is not the same as the prior distribution conditioned on the order.",
                    "label": 0
                },
                {
                    "sent": "Oh, that is usually not a problem in many applications where you have a lot of data and where the influence is heavily driven, heavily influenced by the likelihood term, but insists aladji quite often, we have a situation that the number of experimental conditions is limited.",
                    "label": 0
                },
                {
                    "sent": "The likelihood term isn't that strong, so we want to draw on the prior, so having such a distortion effect is certainly sort of unbounded effect we want.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something about it?",
                    "label": 0
                },
                {
                    "sent": "So that is not the motivation for this presentation.",
                    "label": 0
                },
                {
                    "sent": "So our objective is to get a sampler that is as efficient as or MCMC in terms of convergence and mixing, but avoid.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that systematic bias?",
                    "label": 0
                },
                {
                    "sent": "So first idea is.",
                    "label": 0
                },
                {
                    "sent": "We do the same as with or MCMC.",
                    "label": 0
                },
                {
                    "sent": "We look at the parents of a given node.",
                    "label": 0
                },
                {
                    "sent": "If the local score with the partition function you forget about the order into exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Problem with that is we get now sort of high scoring parent configurations but they might lead to directed cycles.",
                    "label": 0
                },
                {
                    "sent": "So we can say we identify the parents of these directed cycles, then we often them, as the name suggests that means we just remove all the perms.",
                    "label": 0
                },
                {
                    "sent": "And then we sample new parents for these orphaned parents.",
                    "label": 0
                },
                {
                    "sent": "Subject today is simplicity.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sprint.",
                    "label": 0
                },
                {
                    "sent": "Illustration.",
                    "label": 0
                },
                {
                    "sent": "Select a note sample.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Open configuration.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From that distribution.",
                    "label": 0
                },
                {
                    "sent": "We've got two directed cycles.",
                    "label": 1
                },
                {
                    "sent": "We offer these notes.",
                    "label": 0
                },
                {
                    "sent": "And sample new parent configurations for these.",
                    "label": 1
                },
                {
                    "sent": "Well, I called the blue parents subject to the security constraint.",
                    "label": 0
                },
                {
                    "sent": "So what is the?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem with this approach.",
                    "label": 0
                },
                {
                    "sent": "The problem is that this move isn't reversible, because here you're targeting one node was.",
                    "label": 0
                },
                {
                    "sent": "Here we are targeting two nodes.",
                    "label": 0
                },
                {
                    "sent": "You would have to set up a complementary conjugate move to get back to the original configuration to get reverse ability, which is an essential essential feature for proving or having assurance that the Markov chain will converge to the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is that we could set something up, but it has to go.",
                    "label": 0
                },
                {
                    "sent": "Novia is structure with two directed cycles.",
                    "label": 1
                },
                {
                    "sent": "That is an invalid structure.",
                    "label": 0
                },
                {
                    "sent": "So the problem with this whole approach is an is it becomes pretty messy to workout nor the equations of feet and balance to do like the Hastings vector to make sure that this move that you've enabled design converges to the correct.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fusion.",
                    "label": 0
                },
                {
                    "sent": "So that's why we are stepping back and modify it such that the proposal mechanism becomes slightly simplified.",
                    "label": 0
                },
                {
                    "sent": "We identify a pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "We often both notes.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We have two constraints for getting the new parents.",
                    "label": 0
                },
                {
                    "sent": "First the cyclicity constraint obviously, but also that the edge gets reversed.",
                    "label": 0
                },
                {
                    "sent": "So effectively we're flipping the edge and getting new parent configurations for the two nodes involved.",
                    "label": 0
                },
                {
                    "sent": "So that looks like the proposal scheme from order MCMC, but rather conditioning on the order of air conditioning on these two constraints.",
                    "label": 0
                },
                {
                    "sent": "Basically city and River.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sing the edge.",
                    "label": 0
                },
                {
                    "sent": "So it is tradition.",
                    "label": 0
                },
                {
                    "sent": "You take a note.",
                    "label": 0
                },
                {
                    "sent": "Select mode in Edge or from the two nodes.",
                    "label": 1
                },
                {
                    "sent": "Select the new parent configurations for these nodes subject to the constraint that we don't get directed cycles and at the edge direction get flipped and reduce.",
                    "label": 1
                },
                {
                    "sent": "Import this one.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then it's easy to show that this is reversible if you know take that as the starting.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Point integration.",
                    "label": 0
                },
                {
                    "sent": "Do the same again.",
                    "label": 0
                },
                {
                    "sent": "Select the edge.",
                    "label": 0
                },
                {
                    "sent": "Often the two notes get your parent configurations.",
                    "label": 0
                },
                {
                    "sent": "Again, subject to the simplicity constraint, and then this edge gets flipped and we're back where we started from.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well that is all very trivial.",
                    "label": 0
                },
                {
                    "sent": "If they're forcing optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "In fact, it would be trivial and they wouldn't be giving the talk here.",
                    "label": 0
                },
                {
                    "sent": "Women with the challenges that we're not doing optimization with doing sampling and you have to show that the conditional detailed balance is valid and you have to work with the Hastings factor which goes into the Metropolis Hastings acceptance rule that is moderately with mathematical challenges.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This 20 minutes I don't have the time to go into the mathematical details, just sort of the whole take home message.",
                    "label": 0
                },
                {
                    "sent": "You get an expression of for the acceptance probability in the metropolis facing steps that depends on various partition functions that you have to compute.",
                    "label": 1
                },
                {
                    "sent": "These partition functions make the algorithm more complex computation more expensive, but not more expensive as or MCMC.",
                    "label": 0
                },
                {
                    "sent": "So one step of the MCMC procedure is as expensive, roughly as or MCMC as a rule of thumb about 10 times as expensive.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Structure, infancy.",
                    "label": 0
                },
                {
                    "sent": "And so another thing they have to worry about is to install the city.",
                    "label": 0
                },
                {
                    "sent": "We also have to make sure that the move is not irreducible.",
                    "label": 0
                },
                {
                    "sent": "Well, that is able usable, but that move is not irreducible cause if you well to take two nodes equal 3 structures, once you're in that domain, but only flipping between these two configurations, you're not getting there.",
                    "label": 0
                },
                {
                    "sent": "But there's a simple theorem that if you take a mixture of transition kernels, you mix and an exotic one with an exotic transition kernel, you get an exotic transition kernel, so all we have to do is we have to mix that move with a move that is organic, and so at each step of the MCMC procedure, you know switch randomly between standard structure MCMC, which is usable, and the new scheme, and that gives us now.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Property corner.",
                    "label": 0
                },
                {
                    "sent": "So for evaluation we have to address 3 things, either method but unbiased.",
                    "label": 0
                },
                {
                    "sent": "And to improve in that aspect on MCMC, how about convergence mixing?",
                    "label": 0
                },
                {
                    "sent": "And how about the network reconstruction accuracy?",
                    "label": 0
                },
                {
                    "sent": "Time do I have?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 minutes.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so analytical comparison.",
                    "label": 0
                },
                {
                    "sent": "First thing is when we take sort of.",
                    "label": 0
                },
                {
                    "sent": "Create data from next awful noise XOR.",
                    "label": 0
                },
                {
                    "sent": "Look at three nodes and you can enumerate all the possible structures.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is straightforward to compute now the correct posterior disk.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bution that you get from the date.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generated from the noise X or and we also can compute the Markov transition kernel analytically for structure MCMC for the new scheme, we just set up North of the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "We can look at the whole evolution of the whole probability distribution and compute the carbon fiber divergences between the distribution in the.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The correct distribution and so these are the results that we get for different sample sizes.",
                    "label": 0
                },
                {
                    "sent": "In the bottom we show the results that they allow for the extra computational overheads that we have in the computation of the partition functions and the new scheme is the black line.",
                    "label": 1
                },
                {
                    "sent": "The dash dotted lines are different versions of structure MCMC, and you find a much faster convergence analytic.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that is good news, but it's rather simple system.",
                    "label": 0
                },
                {
                    "sent": "We haven't considered order MCMC yet to consider or MCMC into go to bigger SSD.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hambino do a empirical comparison.",
                    "label": 1
                },
                {
                    "sent": "If you say I say you take a standard network used in the machine learning community for benchmarking purposes, about 37 loads, 46 directed edges and we compare now these different MCMC schemes and under same the same computational costs.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "One of the methods to actually get a feel for what the convergence is is to rerun them twice with two different initializations, compute the marginal posterior probabilities of these edges, and then there's.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Drop them against each other for convergence.",
                    "label": 0
                },
                {
                    "sent": "You should not have any dependence on the initialization, so all these entries should be on the diagonal line.",
                    "label": 0
                },
                {
                    "sent": "Any deviation from that indicate.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems with convergence and.",
                    "label": 0
                },
                {
                    "sent": "These are results for different sample sizes for structuring CMC for MCMC and the new scheme.",
                    "label": 0
                },
                {
                    "sent": "But the data set is small well.",
                    "label": 0
                },
                {
                    "sent": "There's so much information in the data, the likelihood is sort of smooth structuring teams.",
                    "label": 0
                },
                {
                    "sent": "He doesn't have a problem, but then as the data set gets larger, no convergence and mixing problems occurs.",
                    "label": 0
                },
                {
                    "sent": "You see now that you have more and more off diagonal entries, we're sort of the new schema nor MCMC.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically show similar convergence properties and you can go now to higher numbers of data points and you basically find the same behavior similar between the new schema or MCMC iteration of structure MCMC.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So structure MCMC has conversion.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mixing problems, what does that mean in terms of Internet?",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Book inference well, because we know what the correct network structure is we cannot compute, but how well we learn it.",
                    "label": 0
                },
                {
                    "sent": "And we do that for different.",
                    "label": 0
                },
                {
                    "sent": "Data set sizes from 25 to 100.",
                    "label": 0
                },
                {
                    "sent": "These are different to work values for different thresholds for the false positive rate, either take the whole curve or basically focusing more on the left because usually are more interested in values for loss, low false positive rates, so these are the three methods order and revenue CMC shown improvement as the data set gets larger, well, that's what we expect because before more information, so the reconstruction accuracy should increase should improve.",
                    "label": 0
                },
                {
                    "sent": "But order structure MCMC well as various lower indicating convergence problems because the likelihood surface gets more rugged with more convergence and mixing problems.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So upshot instruction team Seattle problems.",
                    "label": 0
                },
                {
                    "sent": "We know that already knew that already before, or MCMC and reference EMC shows.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convergent indexing properties.",
                    "label": 0
                },
                {
                    "sent": "But how about the bias?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Booty.",
                    "label": 0
                },
                {
                    "sent": "No, the main motivation for this.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "And here we looked at two.",
                    "label": 0
                },
                {
                    "sent": "Well standard machine learning datasets from UCI repository.",
                    "label": 0
                },
                {
                    "sent": "We restrict the analysis to five nodes so we can get a complete numeration of all the structures you get the true posterior probabilities of the individual edge features, the marginal posterior probabilities for the different directed edges, and then we compute the difference between the correct values and those.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To get with these sampling schemes and so these are the rules for play and vote different.",
                    "label": 1
                },
                {
                    "sent": "Sample sizes so the three diagrams stacked on top of each other or MCMC structuring.",
                    "label": 0
                },
                {
                    "sent": "See the new method sandwiched in between and.",
                    "label": 0
                },
                {
                    "sent": "Here we are measuring the deviation between the estimated marginal posterior probabilities and that rules with structure MCMC.",
                    "label": 1
                },
                {
                    "sent": "They don't have a systematic deviation.",
                    "label": 1
                },
                {
                    "sent": "There might be only about 5 nodes, so we can run that through convergence.",
                    "label": 1
                },
                {
                    "sent": "We also have the same good news for our method without MCMC.",
                    "label": 0
                },
                {
                    "sent": "Deviations and that is not a convergence problem.",
                    "label": 0
                },
                {
                    "sent": "That is a systematic problem due to the distortion of the prior knowledge that you get as a consequence of marginal.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lordis so.",
                    "label": 0
                },
                {
                    "sent": "Is finally in.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample that is more related to systems prodigy.",
                    "label": 0
                },
                {
                    "sent": "We look at the rough part with so that is in regular network involving 21 phosphorylated proteins and phospholipids.",
                    "label": 0
                },
                {
                    "sent": "That's related to the mammalian immune system, so for the regulation of this pathway has been implicated in carcinogenesis for that reason, alot of studies have been done on this path.",
                    "label": 0
                },
                {
                    "sent": "With there's a lot of knowledge available in the.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Political literature.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We take this data.",
                    "label": 0
                },
                {
                    "sent": "Flow cytometry experiment's current offer sucks and coauthors, where they take a laser and shoot a laser, then onto the cells, get the fluorescence signal, and from that they get a indication of the protein concentrations at in different cells.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's probably knowledge we take well networks extracted from.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cake.",
                    "label": 0
                },
                {
                    "sent": "So prior knowledge is then included.",
                    "label": 0
                },
                {
                    "sent": "Your method, first proposed by a group of Japanese.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Researchers to modern coauthors, so where the network where can be represented as a binary matrix.",
                    "label": 0
                },
                {
                    "sent": "So Gij is where the edge from I2J is either not one indicating the presence or absence of the edge, and the prior knowledge is sort of a value between order one indicating sort of you believe so, with the absence of an edge, or whether you have the edge and again the properties are used to different symbols, the other P for prime knowledge of B for belief.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Answer You cannot measure the discrepancy between the network and the prior knowledge just by looking at the differences.",
                    "label": 0
                },
                {
                    "sent": "And from that we get a prior distribution of the standard Gibbs form.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, you take two different forms of prior knowledge at first from check into the entrance is that go into the prior knowledge matrix or just the relative frequencies of the edges.",
                    "label": 0
                },
                {
                    "sent": "Extra take it took all the half.",
                    "label": 0
                },
                {
                    "sent": "Space out of cake and then just counted the number of times that certain edges were found in these networks and so they already frequency is sort of the prior knowledge that goes into the prior knowledge design matrix and we also take the Goldston it next for network published about sex at all.",
                    "label": 0
                },
                {
                    "sent": "Now that looks a little bit like looking for the solution with the solution already in mind right here.",
                    "label": 0
                },
                {
                    "sent": "The upshot of the objective is not to actually see, but how much we learn.",
                    "label": 0
                },
                {
                    "sent": "We want to see what sort of distortion do we get with MCMC and to what extent can be actually alleviate that.",
                    "label": 0
                },
                {
                    "sent": "Or compensate that so we take the truth goes to the network and then associate these edges with different confidence scores, right?",
                    "label": 0
                },
                {
                    "sent": "Have a high confidence intermediate confidence or low confidence.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so these are the results that we get.",
                    "label": 0
                },
                {
                    "sent": "These are the oroak scores for cake.",
                    "label": 0
                },
                {
                    "sent": "The problem cake and for different.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No prior knowledge matrices obtained from the true network with different code.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Levels and well, OK, and for sort of strong prior knowledge.",
                    "label": 1
                },
                {
                    "sent": "We do not find any significant difference in the OR values and that might be too surprising in that.",
                    "label": 0
                },
                {
                    "sent": "Bear in mind that the orc value the Roc curve is determined by the ordering of the edges.",
                    "label": 0
                },
                {
                    "sent": "The ordering well defined by the model.",
                    "label": 0
                },
                {
                    "sent": "Posterior probabilities of these edges.",
                    "label": 0
                },
                {
                    "sent": "So we might have a distortion that might not need to different ordering, so it might not be.",
                    "label": 0
                },
                {
                    "sent": "The opposite over built in the ropes course.",
                    "label": 0
                },
                {
                    "sent": "As the product gets weaker, the distortion effect is stronger, and here with the knobs of a significant deterioration with order empty as a consequence of the distortion of the prior knowledge and signific.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And improvement at the pier.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nought point nought one significance level.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Upshot of all of this is that, well.",
                    "label": 0
                },
                {
                    "sent": "Learning sort of Bayesian networks from.",
                    "label": 0
                },
                {
                    "sent": "For tsunami data, but it's usually applied to systems that you don't have much prior knowledge where you will actually want to learn about interactions.",
                    "label": 0
                },
                {
                    "sent": "Well, one of the Senate methods, Bayesian learning scheme one, requires a well setting up of a complex Markov chain regardless immolation, to ultimately sample from the correct distribution, but with structuring CMC that is to slow where you have too much mixing and convergence problems or MCM principle gives a much better convergence and mixing but has problems.",
                    "label": 0
                },
                {
                    "sent": "Well, with systematic distortion of the prior as a consequence of marginalizing over orders, and so we set up a scheme that is in some ways similar in that it uses proposal mechanisms that are similar to or MCMC.",
                    "label": 0
                },
                {
                    "sent": "But going back to the original paradigm of doing that in structure space, and so the mathematical challenge here was to actually work out the equations of dependence and derive the Hastings factor consistently.",
                    "label": 0
                },
                {
                    "sent": "But the result is that we get mixing that is as good as far South without MCMC.",
                    "label": 0
                },
                {
                    "sent": "And we have indications that we have.",
                    "label": 0
                },
                {
                    "sent": "We get exclusive reconstruction accuracy that is better the consequence of avoiding the systematic bias.",
                    "label": 0
                },
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "Matt extortion of prior knowledge and therefore there seems to be a scheme that well is useful, might offer useful tool for approaches that aim to integrate systematically.",
                    "label": 0
                },
                {
                    "sent": "Integrate prior knowledge, say derived from tech, from other pathway databases.",
                    "label": 0
                },
                {
                    "sent": "Between these order updates.",
                    "label": 0
                },
                {
                    "sent": "The structure updates and your new update.",
                    "label": 0
                },
                {
                    "sent": "You said it was 10 times more computationally expensive.",
                    "label": 0
                },
                {
                    "sent": "But I mean once the local exploration, yeah.",
                    "label": 0
                },
                {
                    "sent": "Just try it.",
                    "label": 0
                },
                {
                    "sent": "Random value basically set.",
                    "label": 0
                },
                {
                    "sent": "The parameters are basically coin coin can be biased and weather parameter can be optimized in the burning.",
                    "label": 0
                },
                {
                    "sent": "I mean you can go for target value of sale for about 30% of acceptance rate and he basically said that sort of threshold to that level such that you get an optimal value in the burn in.",
                    "label": 0
                },
                {
                    "sent": "So that basically is sort of free parameter that determines how fast the mixing is.",
                    "label": 0
                },
                {
                    "sent": "Yes, Sir, I'm one of the things about ordering same saving is that in some situations that actually gives an intrusive effects of prior uniform prior structures.",
                    "label": 0
                },
                {
                    "sent": "Now obviously here you've got information which is of the sort that you're saying.",
                    "label": 0
                },
                {
                    "sent": "Well, I have some certainty about a directed edge between knows, which in a certain says put some constraints on the order.",
                    "label": 0
                },
                {
                    "sent": "Is there any way other other methods that I could use that people are using in terms of?",
                    "label": 0
                },
                {
                    "sent": "And almost incorporating those those edge information is data in order.",
                    "label": 0
                },
                {
                    "sent": "Ordering some seeds sort of Roach you're looking for.",
                    "label": 0
                },
                {
                    "sent": "So you're looking for a set of, including prior knowledge, but trying to do that in order space rather than instruction.",
                    "label": 0
                },
                {
                    "sent": "We believe this uniform.",
                    "label": 0
                },
                {
                    "sent": "Surprise, something that we don't want to use.",
                    "label": 0
                },
                {
                    "sent": "We want to do something that's more informative and.",
                    "label": 0
                },
                {
                    "sent": "Doing as you're using information on the back of.",
                    "label": 0
                },
                {
                    "sent": "Structure which is yeah.",
                    "label": 0
                },
                {
                    "sent": "To introduce that information is beautiful.",
                    "label": 0
                },
                {
                    "sent": "Well, usually very important information.",
                    "label": 0
                },
                {
                    "sent": "The project solution instructor space norms in space.",
                    "label": 0
                },
                {
                    "sent": "But if you have something like sort of well, a gene coding phone on a then influencing protein then obviously you have information about the order.",
                    "label": 0
                },
                {
                    "sent": "But if you're basically looking for jeans then we don't really have any reliable information on the order now.",
                    "label": 0
                },
                {
                    "sent": "Argue that you're saying right?",
                    "label": 0
                },
                {
                    "sent": "Well, that is basically some people took the line that we're seeing, right?",
                    "label": 0
                },
                {
                    "sent": "We can already specify the structure of the prior infrastructure space anyway, because we should be specifying that in this space of equivalence classes, which is not the same as the structure space, however, so my line is that we break up these equality symmetry between the equivalence classes by bringing in prior knowledge, and that is in some way by incorporating prior knowledge in some way to get slightly more out of the Bayesian network that we interpret them in some way as a causal graph.",
                    "label": 0
                },
                {
                    "sent": "Although this sort of speaking that is not correct, but.",
                    "label": 0
                },
                {
                    "sent": "Use a sort of prior knowledge to break the symmetry in the equivalence classes, and really taking that, ultimately interpreting that as a causal graph.",
                    "label": 0
                },
                {
                    "sent": "You could get even further that use interventional data when you are there.",
                    "label": 0
                },
                {
                    "sent": "The better basis for interpreting that as a causal graph, and we have prior knowledge about the cause of structures.",
                    "label": 0
                },
                {
                    "sent": "So with respect to think on that basis, we can justify that you're saying right that is really what we want to do.",
                    "label": 0
                },
                {
                    "sent": "That is where the prior knowledge is with the orders.",
                    "label": 0
                },
                {
                    "sent": "That is much more complex than much more difficult.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "Order yeah, that is correct.",
                    "label": 0
                },
                {
                    "sent": "I mean alright, so you're saying that?",
                    "label": 0
                },
                {
                    "sent": "OK, there might be sort of latent variables involved, or you might have prior knowledge that is an activator like transcription factor activated transcriptional regulator and then sort of that should be in the order precede or the jeans that are sort of downstream in the process and sort of OK.",
                    "label": 0
                },
                {
                    "sent": "I take it that sort of partial knowledge about the order is available.",
                    "label": 0
                },
                {
                    "sent": "You can obviously specify that straightforwardly instructor space.",
                    "label": 0
                },
                {
                    "sent": "Correctly, so you're saying that were quickly.",
                    "label": 0
                },
                {
                    "sent": "If you looking for a hybrid scheme that you will do specify that you specify a prior in order space, but that really needs to basically have to complete sufficient coverage, not only sort of true, some regulators and some downstream regulated genes, but if you only have partial coverage, then as a consequence of marginalizing over orders, but you don't really have any prior knowledge, you're getting a distortion effect in again.",
                    "label": 0
                },
                {
                    "sent": "And if you basically avoid the distortion effect, why not do that?",
                    "label": 0
                },
                {
                    "sent": "Why we're actually trying to do that in structure space?",
                    "label": 0
                }
            ]
        }
    }
}