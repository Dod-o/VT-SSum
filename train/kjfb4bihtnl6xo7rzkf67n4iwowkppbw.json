{
    "id": "kjfb4bihtnl6xo7rzkf67n4iwowkppbw",
    "title": "Phase transition in the family of p-resistances",
    "info": {
        "author": [
            "Morteza Alamgir, Max Planck Institute for Intelligent Systems, Max Planck Institute"
        ],
        "published": "Sept. 6, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Mathematics->Graph Theory",
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/nips2011_alamgir_resistances/",
    "segmentation": [
        [
            "So graphs are present in many machine learning problems and in many of these problems, implicitly or explicitly we need some."
        ],
        [
            "Kind of distance measure between nodes of the graph and the resistance.",
            "Distance is one such distance measure, so the resistance distance is somehow related to the number of different passes between two nodes in a graph, or we can reformulate it as a minimum L2 norm of all the unit flows between SNT.",
            "So the advantage is that in small graph it tends to work.",
            "So this means that if the two nodes are in the same cluster, there are many passes between them and their distances are small.",
            "But if they are in different clusters there are fewer pass between them and the distance is large.",
            "But unfortunately as showed in last NIPS enlargement with graphs, this distance doesn't work anymore, so it's converged too.",
            "Trivial limit switches some of immerse degrees of two nodes.",
            "Now the question is how?",
            "Fix this."
        ],
        [
            "Problem.",
            "The intuition is that we need to penalize long passes and we do that by defining the peer resistance as the minimum P norm of all unit flows between SNT.",
            "So we can see that in this great example, as P gets smaller, the flow gets concentrated around the shortest path.",
            "So we can prove that what happens for different piece if we fix our graph for P = 1.",
            "This distance gives us the shortest path distance, which is a global measure on the graph for P equal to two.",
            "It gives us some standard resistance distance, which is proved that to be a local measure on the graph and four P goes to Infinity is related to the esteeming cut.",
            "No, another question happens.",
            "Is that where this change of behavior happens.",
            "So at P = 1 we have something global and peer call to.",
            "We have something local, so if we change P when this change happens."
        ],
        [
            "And in our main term we show that for large random geometric graphs in Rd, if we choose peace smaller than 1 + 1 or D -- 1, then the global contribution dominates the local 1.",
            "So we get a meaningful distance.",
            "But if P is larger than 1 + 1 / D -- 2 and all global information manage is, so the distance is useless.",
            "In our paper we also show the exact relation to semi supervised learning problem with Laplacian regularization.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So graphs are present in many machine learning problems and in many of these problems, implicitly or explicitly we need some.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kind of distance measure between nodes of the graph and the resistance.",
                    "label": 0
                },
                {
                    "sent": "Distance is one such distance measure, so the resistance distance is somehow related to the number of different passes between two nodes in a graph, or we can reformulate it as a minimum L2 norm of all the unit flows between SNT.",
                    "label": 1
                },
                {
                    "sent": "So the advantage is that in small graph it tends to work.",
                    "label": 0
                },
                {
                    "sent": "So this means that if the two nodes are in the same cluster, there are many passes between them and their distances are small.",
                    "label": 0
                },
                {
                    "sent": "But if they are in different clusters there are fewer pass between them and the distance is large.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately as showed in last NIPS enlargement with graphs, this distance doesn't work anymore, so it's converged too.",
                    "label": 1
                },
                {
                    "sent": "Trivial limit switches some of immerse degrees of two nodes.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how?",
                    "label": 0
                },
                {
                    "sent": "Fix this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "The intuition is that we need to penalize long passes and we do that by defining the peer resistance as the minimum P norm of all unit flows between SNT.",
                    "label": 0
                },
                {
                    "sent": "So we can see that in this great example, as P gets smaller, the flow gets concentrated around the shortest path.",
                    "label": 0
                },
                {
                    "sent": "So we can prove that what happens for different piece if we fix our graph for P = 1.",
                    "label": 1
                },
                {
                    "sent": "This distance gives us the shortest path distance, which is a global measure on the graph for P equal to two.",
                    "label": 0
                },
                {
                    "sent": "It gives us some standard resistance distance, which is proved that to be a local measure on the graph and four P goes to Infinity is related to the esteeming cut.",
                    "label": 1
                },
                {
                    "sent": "No, another question happens.",
                    "label": 0
                },
                {
                    "sent": "Is that where this change of behavior happens.",
                    "label": 0
                },
                {
                    "sent": "So at P = 1 we have something global and peer call to.",
                    "label": 0
                },
                {
                    "sent": "We have something local, so if we change P when this change happens.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in our main term we show that for large random geometric graphs in Rd, if we choose peace smaller than 1 + 1 or D -- 1, then the global contribution dominates the local 1.",
                    "label": 1
                },
                {
                    "sent": "So we get a meaningful distance.",
                    "label": 0
                },
                {
                    "sent": "But if P is larger than 1 + 1 / D -- 2 and all global information manage is, so the distance is useless.",
                    "label": 0
                },
                {
                    "sent": "In our paper we also show the exact relation to semi supervised learning problem with Laplacian regularization.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}