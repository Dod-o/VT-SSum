{
    "id": "2thhvszcuhb4fathfddwsxackkxhlpkt",
    "title": "Machine learning for cognitive science 1: What is machine learning?",
    "info": {
        "author": [
            "Neil D. Lawrence, Department of Computer Science, University of Sheffield"
        ],
        "published": "June 15, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss2010_lawrence_mlfcs/",
    "segmentation": [
        [
            "Welcome you all here.",
            "There was a short period a few weeks ago when we're all very concerned that volcanic ash might knock the whole meeting into smithereens, but here we all are little later after having never sorted out our navigational challenges and expected.",
            "But we're all here.",
            "The technical things are almost all working.",
            "We haven't quite got the speaker mic source it out, but that's coming.",
            "Full location, delightful to see you all here.",
            "I really hope it's going to be exciting and fun meeting.",
            "I'm looking forward to it so I just want to do literally 2 minutes introduction.",
            "It could even be less.",
            "And then I'm going to hand over to Neil.",
            "First of all, this is a chance is to thank our sponsors.",
            "Thank you very much to thank our sponsors Pascal, who have very generously supported this summer school in cognitive science and machine learning.",
            "The purpose of the meeting is to bring together the two communities of cognitive scientists and machine learners, and for that reason we've broken the the meeting up into two parts.",
            "So one is primarily tutorial, but I don't think that will be sort of dull.",
            "Tutorial actually sort of exciting and fun and a chance to revisit things.",
            "1/2 understood.",
            "That's what we're hoping tutorial and the idea of that is to bring people in cognitive science up to speed, at least to some degree with what has been happening in machine learning and Conversely.",
            "To give people with a background in machine learning, some sense of what cognitive Sciences get up to.",
            "And then in the second part, after a rest day on Sunday, then we'll talk about specific topics and those specific topics are.",
            "Up on the next slide, I think.",
            "Yeah, they are perception classification language and thought and decision and action and they will roughly correspond to the days the 2nd three days of the meeting, but not quite due to various speaker complications.",
            "Let me just pop back again actually to the the.",
            "Goals of the meeting so clearly there is a tutorial element to it and what we want to give each side of the field offensive.",
            "What's going on in the other, to give a sense of some of the state of the art developments in both areas, particularly the interface in the in the second half.",
            "And of course to discuss and explore interconnections between the two fields.",
            "And we would hope lead to exciting, interesting pieces of research in future, perhaps some of which might be might fit within the remit of Pascal.",
            "Others won't, but the objective of this meeting, more than anything, is to try to harness the insights machine learning for the purposes of understanding the mind, and Conversely to harness what we know about the mind to improve and enrich models of machine learning.",
            "So without further ado.",
            "Let's go and I hand over certain Neil Lawrence is going to take the first session."
        ],
        [
            "OK, so I guess the.",
            "First thing that you need to do when giving a presentation is to know your audience.",
            "I don't know cognitive scientists that well, and I thought damn, I'm also going to be speaking first so I don't even have a.",
            "Can't even adjust the quality of my level, of which I picked things to the audience, but I thought, well, I know a couple of cognitive scientists I know Josh Tenenbaum, and I know Tom Griffiths, so maybe I should be pitching my talk level at them.",
            "But then they know more about machine learning than I do, so I.",
            "Thought that probably wasn't a good idea, so I decided that they were exceptional cognitive scientists and that I would try and pitch my introduction to machine learning well.",
            "In some sense, more of a personal history of what I think machine learning's origins are, and perhaps a justification of why cognitive science and machine learning should be closer than they are.",
            "And to try and explain why I think that it's important that machine learning learns a lot from cognitive science, just as I think many people feel like Nick that cognitive science can learn from machine learning, so."
        ],
        [
            "I'm going to give a bit of motivation for.",
            "What I see as what machine learning is and how it's different, and then I'm really going to cover a couple of the areas I'm not going to cover reinforcement learning because Chris Watkins is going to also get the second part of this talk, but the way I'd like to do that is rather than giving what would be a sort of a modern perspective on how we think of these things, try and give something that I think reflects some of the history of where machine learning came from and what we thought of these algorithms perhaps.",
            "20 years ago, although I wasn't machine learning 20 years ago I was in machine learning 13 years ago and there was still some memory of that then.",
            "So OK, what is the motivation of machine learning?",
            "So I think this is important.",
            "We are interested in getting computers to learn from data.",
            "So and our computers with the ability to learn from data and this is important because there's things like data from sensors, so there's lots of things like.",
            "Measuring multiple sensor arrays and trying to combine data from multiple sensors.",
            "the Internet experiments.",
            "I work a lot and computational biology and we expect to be able to combine these things to get a computer to make some sort of sensible decision.",
            "This is very vague.",
            "But we traditionally split up machine learning and categorize it in several different ways, so.",
            "We think of supervised learning and that's one of the things I'll talk about.",
            "In particular, we might think of classification regression.",
            "Now, I think when I came into machine learning, these were still considered sort of big problems.",
            "How do you classify things?"
        ],
        [
            "How do you do a good regression algorithm?",
            "One of the differences I'd say between machine learning in 1997 and machine learning today is I think if you have a standard classification setup in terms of sort of vectorial input in class labels, we sort of know how to do that.",
            "And the same for regression.",
            "So in some ways I almost see these is they're not resolved because there's lots of interesting extensions which you need to look at, but the pure classification regression formats I'll talk about today.",
            "I tend to think of it as fairly well covered.",
            "Then there's also unsupervised learning, so unsupervised learning classification regression.",
            "You typically have inputs and some outputs, some targets, and you want to learn a mapping between them.",
            "In unsupervised learning, you just have some data and you want to sort of uncover some structure in that data, and my particular interest is dimensionality reduction in that area.",
            "That's probably the area I do most work on in machine learning, but there's other things such as clustering.",
            "Finally, this is the most difficult one.",
            "I tend to think of these as I think I understand these and how they work.",
            "Actually, this is the most interesting thing, probably.",
            "Reinforcement learning, so learning from delayed feedback.",
            "So you've got some sort of tasks.",
            "You're getting some feedback, perhaps from your environment doing planning how you're going to do things that I think really the bit that I know least about in machine learning, but Fortunately we've gotta an expert here in Chris Watkins who's going to talk a bit about that, and I think that, but I think that this is one of the areas where there's hopefully going to be most advances in the future.",
            "So I'm going to give you sort of what I think of as a personal history of machine learning, and I've sort of put Rosenblatt Subotnick because I think that reflects the journey machine learning's been on certainly well before I was around.",
            "And since I've been around as well so.",
            "I think that this is interesting origins of machine learning is coming out of things very closely related to Congress."
        ],
        [
            "Science so early connection this research so we call ourselves machine learning today, but I think there was a time when I certainly didn't think of machine learning as being a term that apply to me.",
            "We were doing neural networks and we were the neural networks community and our main conference was the neural information processing systems.",
            "We also went to HTML.",
            "The International Conference on Machine Learning, but that had all sorts of other things there, which we weren't so interested in necessarily.",
            "So we were really interested in these connectionist models.",
            "These neural networks, certainly that's what got me interested in doing machine learning.",
            "I did mechanical engineering degree and then I went and worked on oil rigs for awhile, and then I thought what do I want to do?",
            "Research in and I thought I want to know how the brain works and I thought I wanted to neural networks.",
            "That was 1996, so I think a big motivational example and some things I guess what the earliest sort of connection is.",
            "Research where you can pull together.",
            "Computing and learning."
        ],
        [
            "It would perhaps be Rosenblatt's perceptron.",
            "So I'm going to talk a little bit about the fitting of the perceptron, but importantly, it was based on a really simple model of a neuron from 1943, and it had a learning algorithm for how that neuron worked."
        ],
        [
            "Now later machine learning research, though, has gone from that.",
            "Those sort of simple, perhaps neurally inspired models to theoretical foundations of such models.",
            "Such questions as their capacity to learn.",
            "I think a real sort of example of that is, you know, Batmix work on statistical learning theory.",
            "It's not the path I follow, but it's extremely theoretical, very mathematical, and it doesn't really care whether the learning algorithm has any basis in the brain.",
            "It's just about learning algorithms."
        ],
        [
            "My personal view is that machine learning benefited really greatly by incorporating lots of ideas from psychology, but not being afraid to incorporate rigorous theories.",
            "So, and I do credit in particular when I think about the people that were around sort of before I was around, I look at the community before I was around.",
            "I tend to think of people like Mike Jordan, Jeff Hinton.",
            "They were in this parallel distributed processing research group, sort of, I guess in the early 80s, and that was very, I guess psychologically based.",
            "What's the algorithms they came out with were inspired by thinking about how the brain could work.",
            "But I think he's very impressive, so it's easy to sort of, say, well, we're going to do something on computers and we're going to be inspired by the brain.",
            "And we're going to do sort of learning.",
            "Or you could sort of look at more recent things like simlife and genetic algorithms.",
            "All these different things inspired by evolution.",
            "Let's do let's do what evolution does.",
            "I think machine learning in some sense is slightly different because I think it's been far less afraid of very, very strong theory, and very very strong mathematics, and very.",
            "Open to receiving that, and I think a lot of the credit of that goes to people like Mike Jordan and Jeff Hinton who early on when physicists theoretical physicists came in and said, Oh well, the model you've got of the brain is actually a spin glass and you can do this sort of analysis.",
            "They didn't run away saying that's just theory we are interested in the results.",
            "They embrace that, and those people are still in the community today, and I think that you really see that reflected in the machine learning community.",
            "The diversity from people who are very interested in just the theory.",
            "I have no concerns about whether this is what humans do, may not even have any concerns about whether their models work in particular applications to people who are only interested in applications have no concerns about whether this is how humans learn to people that are interested in humans learning, and it basically has covered all those things, and I think it's very important that it continues to cover all those things 'cause it benefits from that mix of people.",
            "And this is a lot about what I think.",
            "This of the summer school is about is partially about remaking that connection.",
            "So one of the things that's happened is.",
            "Machine learning people get accused of just doing lousy statistics.",
            "Because one of the results of these sort of research is is the work we did does work well on things that are traditionally considered to be statistical applications, so."
        ],
        [
            "Early machine learning, I think was viewed with some skepticism by statisticians because."
        ],
        [
            "They saw it as sort of sloppy statistics.",
            "Now I'm glad to say that.",
            "Modern machine learning and statistics interact to both communities benefit, so if if I go and visit so recently we had Chris Holmes visit a grouping.",
            "Manchester, he's leading Bayesian statistician.",
            "You know Ann and Chris Holmes and I when we're talking about the applications we're interested in, we have entirely overlapping ideas.",
            "We think very much the same thing we use very similar models, very similar techniques.",
            "Some of those techniques are now coming from the machine learning community, in particular variational methods, and I must admit that I was falling into the trap at one stage of thinking.",
            "Well, is machine learning just an extension of statistics?",
            "Are we just sort of modern statistics people with?",
            "Perhaps sexier?",
            "Applications in video and stuff like that?",
            "And I guess I started getting persuaded by that argument.",
            "I'm going to offend people.",
            "Maybe when I say some of the things I'll say, but I'll continue anyway.",
            "Don't feel too offended if you're a statistician.",
            "Statistics this, I didn't really feel super comfortable with this.",
            "'cause to me, statistics was the most boring part of all maths.",
            "I remember sort of doing maths at the age of 16 and statistics was let's sum up these numbers and compute their mean OK and I could remember that.",
            "But then I could never remember the proper formula for the standard deviation right?",
            "And it didn't seem that interesting.",
            "You couldn't, you know no one was telling me where it was coming from.",
            "They just said compute the standard deviation of this data just arrived this it seemed very mechanical.",
            "Anyone could do it.",
            "Anyone in the class?",
            "He wasn't good at maths could do this stuff and I didn't understand what the motivation was I avoided.",
            "Statistical courses like the plague.",
            "I mean I is so uninterested in doing any statistical courses so this dawning realization of machine learning being an extension of statistics came as something of a personal blow, so.",
            "Having said that though, I've managed to reason my way out of that, and maybe that that's what."
        ],
        [
            "Well I'm giving you is my personal justification for what we're going on and why it's different from statistics.",
            "And actually why modern statistics is not anything to do with what we think of as traditional statistics and and what you think of as being taught about means and variances.",
            "I think modern research in statistics is close to machine learning, mainly because it isn't traditional statistics, it's something quite different so.",
            "I guess my Paul on the road to Damascus or where it was going moment was a dinner for lunch.",
            "In fact I had with Tony O'hagan and Zubin Ghahramani and several other people.",
            "But these were the two people said the things that made a big impression on me.",
            "That was part of a nips workshop we had Tony O'hagan over the Gaussian Process Workshop in the NIPS conference is about three or four years ago.",
            "Is organized by column wiki, then Zoom in and the conversation went like this.",
            "Tony said he's leading statistician Gaussian processes.",
            "He said, as a statistician I will words this effect.",
            "I don't believe that you can analyze data without human being involved, so I have a set of tools I know about these different tools of principal component analysis.",
            "I have hypothesis testing.",
            "I have whatever someone comes with data, I apply these tools.",
            "I use my intelligence to decide which tool to apply.",
            "And then I analyze the data and I come to a conclusion about what's in the data and I think you know, I completely agree with that.",
            "I think you know if you're going to do serious data analysis, that's completely what I'm doing.",
            "And I was, you know, my heart sunk.",
            "It looks like I'm a statistician.",
            "But then zoom in came to my rescue and he said yes.",
            "But unless you believe the human is doing something that you can't do on a computer, then you have to believe that whatever process the human is going through.",
            "To pull all these tools in and apply them all to the data we can do on the computer as well.",
            "I think God yes, of course.",
            "That's right, there's no ghost in the machine is basically what he's saying, so there's nothing that the humans doing that we can't do, and that is the fundamental difference between a machine learning person and I start decision.",
            "I think, because fundamentally, if you're in machine learning, you believe the end goal is to remove the human from the equation.",
            "You believe that whatever that process is, which we are using, which we can justify to other humans.",
            "The process we've used to analyze the data that you can deal with that as well.",
            "Now, fundamentally, we can't do that.",
            "At the moment, we don't have the right algorithms.",
            "You know, it's great that we can't, because if we could, we'd all be out of work.",
            "We can't do that and so at the moment the temporary solution is to do what the statisticians do.",
            "So that's why our jobs look similar because we're doing similar things.",
            "But the end goal is to get the human out of the loop as well, which is a very very challenging thing.",
            "You know, I kind of think.",
            "I just don't think we're anywhere near it anyway."
        ],
        [
            "So for the moment the two fields overlap very very strongly.",
            "Because of this, but they are not the same field and I think it is a massive mistake to fall into the trap of thinking they are the same field because you just fall into doing what the statisticians are doing.",
            "That's fine, you can do what the sessions are doing, but you don't need machine learning to do that.",
            "If you're going to be a different field, you have to understand why you're there, and I think it's very important that we there an.",
            "I think it's important that we continue talking to other fields like cognitive science.",
            "And use that incorporate ideas from other fields to push this along."
        ],
        [
            "So this summer, schools reflecting that we have a lot to learn from cognitive science.",
            "I think one of the things I worry about statistics is.",
            "If you don't look to humans, you can fall in fall into some traps."
        ],
        [
            "So mathematical formalisms are very, very important, right?",
            "They're very important, and that's what I'll hope to show in the rest of the talk.",
            "Justify why mathematical formalisms are massively important, and the mathematical formalization of a lot of what we do in machine learning has pushed us forward dramatically has really made massive leaps over the last 10 years, but my feeling is to an extent a lot of advances, about 10 years.",
            "Well, say 15 years, I should say.",
            "So I came into the field, but a lot of the advances of that came in the first 10 years of that, and I think a lot of what we're doing is dotting I's and crossing T's at the moment.",
            "So I worried that we're becoming a bit too obsessed with magical formalisms, and this is the reason why that can be a problem.",
            "So this is really stupid idea that aerodynamically a bumblebee can't fly, and then the answer is, well, the bumblebee doesn't know that, so he flies through the force of his heart or something like that.",
            "Let me see that crap, isn't it?",
            "I mean aerodynamically Bumblebee can fly.",
            "You can see a bumblebee flying.",
            "You can see examples of it all the time.",
            "So what does this mean?",
            "It means the mathematical formalism you are using to model what happens aerodynamically does not apply in the bees case.",
            "It applies to jet aircraft, it applies to jumbo jets.",
            "It applies to fighter jets, but it doesn't apply to what the bumblebee is doing.",
            "So it's clearly a limitation of the model rather than a fact.",
            "Now the problem is you can get these two things confused because the first thing you do is you say, well, this is the situation.",
            "In real life I can't model everything in that, so I'll have a mathematical idealization and I'll study that.",
            "But then you can spend so long studying that that when you actually look back at the situation in real life, you say it yourself well.",
            "Impossible things.",
            "Things that happen are impossible and we hear examples of that things like, well, it's impossible for human, you know, the vision problem is impossible because of the curse of dimensionality.",
            "Well, the vision problem isn't impossible because you're doing it all the time.",
            "It's difficult, but you know we're just doing it wrong when we do it on computers and we see advances in that direction as well.",
            "So I think it's very dangerous to get lossed in pure mathematical formalisms, because you forget that there are things going on that humans can do.",
            "For example, that we want to recreate, and that's why this link.",
            "You know, I think that there's there's a really interesting example of that, and it's with good reason.",
            "So statisticians will tell you that you can't, or Pearson, I think said, and a lot of statisticians will say this that you can't infer causality from data.",
            "And I think for early statistics it was quite important that this concept existed.",
            "But you know why do humans have a concept of causality then?",
            "If you can't infer it from data?",
            "I mean data is just what we see and do, and causality is a really important aspect of that.",
            "So you can get a little bit lost if you will start proving these things in demonstrating these things and lose sight of what's actually really going on and what you really want to achieve."
        ],
        [
            "So mathematical foundations are very important, though they still under help us understand the capabilities of their algorithms, and I think that.",
            "You know, This is why this summer school is important because you have to actually keep in touch with both of these things.",
            "It's really hard now.",
            "I think to come into machine learning as an undergraduate.",
            "Well as a graduating undergraduate as a grad student, compared to how it was when I came in.",
            "So when I came in.",
            "The math you needed to know was very complex thing known as the chain rule, and you needed to know that to derive an advanced algorithm known as backpropagation.",
            "I still use the chain rule.",
            "It's still quite useful, but I do an enormous number of other things and you know when I think about what I'm trying to get my students to do and what I expect them to know quite quickly on.",
            "It is far more than I knew when I came into machine learning in terms of, say, linear algebra, probability theory.",
            "In other areas you'd be talking about functional analysis.",
            "It's very complicated and that makes it tough because I don't think it's the case that the undergraduate programs.",
            "Pushing people further than they used to, so there's a steep learning curve to come into machine learning, but it's important that people know that.",
            "So.",
            "Well, that's already sort of."
        ],
        [
            "It's in that point.",
            "Humans give us the inspiration, though.",
            "To go beyond these mathematical formalism.",
            "So it's important we don't get lost in the more advanced mathematics that we are doing.",
            "I mean, sometimes I think so.",
            "I'm in a computer science Department, but sometimes I feel that it would be more appropriate to be in applied math Department because, you know, I don't see much difference between what applied mathematicians are doing and what we do.",
            "The main differences.",
            "Perhaps we consider a broader range of problems, and it takes me a lot longer to workout the math and some applied math."
        ],
        [
            "Rotations.",
            "OK, so.",
            "Back to this question in statistics, so early statistics had really wanted statistics about an early statistics, and I think you have to understand this origin to see why it's different from machine learning.",
            "They had great success with this idea of a statistical proof, and I think this is a really important concept.",
            "You mustn't forget this concept, but one must also ignore it as well.",
            "In some sense in terms of looking for the future because it's there and it's dumb.",
            "So there's a question.",
            "I compute the mean of two tables of numbers, which is a statistic, right?",
            "So that's what baseball statistics are like.",
            "And that's what it's really about studying statistics.",
            "They are different.",
            "Does this prove anything?",
            "Does this mean anything?",
            "And this is what people were interested in?",
            "They were social scientists, early social scientists.",
            "They were measuring poverty in Manchester, comparing it to poverty in London and saying, is the poverty different?",
            "They didn't want to use models, they just wanted to sum up numbers and compute answers.",
            "So the answer was depends what statistics discovered is, it depends on how those numbers are generated, whether they are randomized and what big different, how big the differences between these two numbers.",
            "That lead to hypothesis testing, but this is really restrictive because the questions you could then ask about your data that you can answer with the statistical proof are really, really limiting and what's really interesting is people actually think that that that's not on to what people think.",
            "The philosophy of science is, so if you work in biology, people will tell you your what's your hypothesis, but then they say hypothesis they mean what's your simple question that you can answer with the statistic if you read Popper.",
            "He's not talking about that, he talks about hypothesis is a much more complex thing that often you could not answer with a simple statistic.",
            "So that can have a really limiting affected on science as well, but there were many successes in in this, and there are things that we we take for granted today.",
            "The fact that we fertilize crops correctly.",
            "The fact that you can get consistently brewed beer, right?",
            "You know they couldn't do that before statistical tests were invented.",
            "They invented statistical test to do that, but there are many open questions we've already mentioned one causality, so by summary about the difference in machine learning and statistics is."
        ],
        [
            "He's my favorite statistician actually because he worked for Guinness, so I don't know the full story that I don't want to read it in case my version of the story is wrong.",
            "My version of the story is Guinness was very far sighted.",
            "They employed statisticians and they understood how to brew beer consistently, and this was one of the key guys in doing and also growing hops, fertilizing hops.",
            "He published under the name of student, 'cause he wasn't allowed to publish working for Guinness and.",
            "Perhaps he's the reason why Guinness is one of the largest Brewers today.",
            "That's that's my thought about it, but then I think there's another aspect to it.",
            "He's very clearly.",
            "I like him a lot, and I'm English, so I feel I can say this.",
            "He's an Edwardian English gentleman, right?",
            "So Edwardian English gentlemen have a certain reputation, and I think it's best encapsulated by, you know, the Edwardian attitude towards sex is very much that it's a functional thing, right?",
            "There's no pleasure to be had in it.",
            "It's just about reproduction.",
            "Most statisticians were Edwardian English gentleman, right?",
            "I think their attitude to data is almost very similar, that it's a very functional thing.",
            "There's no fun to be had it out, it's just about statistical proofs.",
            "I think we can go beyond that now.",
            "We can have a lot of pleasure, but we can't.",
            "We don't necessarily always get the reproduction element there when we have the pleasure.",
            "OK, so that's my sort of background to machine learning.",
            "I think that was the that was all inspired by the sort of title of the talk, which I guess I was given, which is what is machine learning."
        ],
        [
            "I have no idea about my timing, whether I've got too much material too little so.",
            "I'll either end early or stop in the middle, but what I want to talk about now is some specific examples in machine learning, but going through from the sort of history side so supervised learning almost seems to be like the initial in 1997.",
            "That was the main say that was the big open question is still in machine learning, in particular classify."
        ],
        [
            "Station, I guess because statistics focused less on classification and we were interested in sort of high dimensional datasets in particular examples."
        ],
        [
            "Where you've got some set of inputs X and targets Y.",
            "And you're interested in whether inputs belong to a certain class.",
            "So you've got some class label.",
            "Why I an it's either a yes or or no.",
            "We can think of these inputs as features, and this was, I think, in 97.",
            "This was still a really big sort of challenge and.",
            "Well, this is one of the reasons why so classifying handwritten digits from binary images.",
            "This was.",
            "This is still we still do this all the time, even though I think it's broadly a solved problem.",
            "But we use it.",
            "We like to use it as an example.",
            "So AT&T had worked extensively on using neural networks to classify binary images of digits to help classify zip codes automatically.",
            "So you could have automatic Postal sorting systems and Bell Labs were very involved in the machine learning community.",
            "People like Yammer, kunan, Lynette.",
            "Had these very performance systems using convolutional neural networks and stochastic gradient descent methods.",
            "When I came in 90, Seven was about the time where Bernard had visited Bell Labs and worked very hard on demonstrating how well the support vector machine worked on these problems and how you could apply it to these very large systems.",
            "I think that's a key moment because, OK, we then had to tolerate about five years of thousands of papers about kernel methods as results, but you know, I think the end conclusion from that is in some sense this problem is solved now that.",
            "You know, and you know it, pains me to say it.",
            "'cause I'm a sort of Bayesian guy, but the support vector machine is excellent algorithmics solution for doing standard classification.",
            "And if you look into lots of application errors you see that, see that still."
        ],
        [
            "And some of those application areas we're not seeing.",
            "If this doesn't use SVM's, I think this is using Viola Jones type methods, but detecting faces and images so you know it's kind of.",
            "I remember seeing Viola Jones is paper at NIPS where they had a video camera and people moving in front of it and the video camera was real time putting boxes around peoples heads and identifying where their faces were.",
            "That was a staggering moment.",
            "I don't.",
            "I'm not so staggered when my digital camera does it today, probably using similar algorithms.",
            "So another success who detected.",
            "Who are detected Facebook belongs to?",
            "So I've spent ages playing with Picasa, 'cause actually categorizes who each faces, so these things are very much out there in application now, but they were sort of things people were interested in.",
            "When I started getting in machine learning, so then the classifying types of cancer given gene expression, data categorization of different document types.",
            "So for example different."
        ],
        [
            "Types of news article on the Internet.",
            "So the perception I mentioned earlier an it's a fun algorithm because I like, well, I don't really know what people teach in cognitive science today, but I was thinking that you can sort of think about the perception without even worrying about the math.",
            "So I decided to sort of sort of do that and."
        ],
        [
            "There is actually, I think it's a remarkably effective and fast classifier even today if you use the kernel version of it."
        ],
        [
            "So Perceptron algorithm the idea is.",
            "So you take these features and you multiply them by some weights and you sum them all up.",
            "And then there's two ways of saying this.",
            "You can either add a buyer so you can say, well, is this some greater than a bias, whichever way around, but I've added the bias here and then said, well is the answer greater than zero?",
            "So if the answer is greater than zero, so I'm then writing that as an inner product here.",
            "Then we assume it's Class 1.",
            "Otherwise if the answer is less or equal to 0, then we assume it's class minus one.",
            "So the question is obvious.",
            "How do you find these weights?",
            "So you've got this setup and you've got a linear algorithm where you're multiplying doing the inner product to find the answer, and then you're thresholding it too.",
            "Give an answer as to what the class."
        ],
        [
            "The data point is, so here's an algorithm I'm not sure about initialization for perceptrons.",
            "How people do that, but I just came up with an initialization of my own.",
            "So here's an algorithm for finding the weights.",
            "So select a random data point so you've got some data set of points.",
            "You just choose one data point at random, and then you ensure that point is correctly classified by setting these weights to whatever the label is times X whatever the input was.",
            "OK, so why does that ensure it's classified?",
            "Because that ensures it's correctly classified because basically.",
            "This thing is the sign of W transpose X, which if we substitute our value for W in as YXI then that just gives us the sign of why I times X transpose XI.",
            "Now that is always going to be positive X transpose XI.",
            "So basically this is just the sign of why I so it's just the label, so that's a way of ensuring so I'm trying to invent an algorithm and the way I'm inventing the algorithm is I'm saying, well, I didn't invent this, but I'm trying to go through a process of inventing as if I'm inventing it.",
            "And the initialization, I'm ensuring the initialization sets takes a random data point in classifiers that data point correctly.",
            "Now I'm going to iterate 'cause there's still going to be other points that aren't classified correctly, and what I'm going to do to iterate is.",
            "Add a misclassified point, forget the increment KR, remove that bit, but forgot to remove that section so taken you misclassified point right.",
            "So now we've got some other match misclassified point, and then what we do is we add.",
            "So this thing we set it to.",
            "Here we add some portion of this to our existing wait.",
            "Yeah, so we basically take the existing weight and then this is the portion we call this a learning rate, and then some proportion of this why I XI we add it now if.",
            "The point in doing this is if this this argument here still holds.",
            "So if this declining rate is large enough, what will happen is we'll be back to this situation.",
            "This term will dominate if there's learning rate is large enough yet, so there's obviously if we make a really large learning rate, will classify that knew datapoint correctly.",
            "Now, if we don't want to just classify the new data point correctly and ignore the old one, so we find some balance where we reduce this learning rate to certain levels.",
            "So we've got some combination of the data points, yeah?",
            "And by doing that this, hopefully this new data point might be correctly classified or the decision boundary will move towards that and then will repeat this until there's no more."
        ],
        [
            "Classified points I've got a little demo of that.",
            "So if I can see it correctly.",
            "So.",
            "Iteration one, we've got a simple data set.",
            "And what we're going to do is we select a data point for our initialization."
        ],
        [
            "And then what we do is."
        ],
        [
            "We, for the first iteration, so we assume the."
        ],
        [
            "These are uninitialized for the first iterations.",
            "We set the wet.",
            "They we set the weight vector to that data point multiplied by Y.",
            "Now this is a positive.",
            "This is the positive class.",
            "This is the NGE."
        ],
        [
            "In class, So what that means is that actually we set that weight vector to exactly the data point and this is a common way of showing decision boundaries.",
            "You show the line of decision and then the weight vector is always at a normal direction to that line.",
            "In this case, it's pointing at the data point we selected so that data point will now be correctly classified.",
            "Yeah, but as guaranteed by the initialization, the other thing is of course it is also correctly classified a bunch of other data points because they are in a similar Asian, but there's some other things incorrectly classified, so all these are now being said to be positive and all these are being said to be negative.",
            "In fact, only these data points."
        ],
        [
            "So we now find.",
            "And you incorrectly class."
        ],
        [
            "Find data point."
        ],
        [
            "We've got our car."
        ],
        [
            "Weights."
        ],
        [
            "But it's incorrect classification.",
            "We adjust the weight vector."
        ],
        [
            "With the new data points, so we add that proportion.",
            "Of that new data point."
        ],
        [
            "Now because if you look at where that vector is from the origin.",
            "So I'm purposely chose the decision boundary to go through the origin so that this works.",
            "You can see this vector.",
            "This data point here basically is a vector pointing in this direction from the origin.",
            "So when we add that that new data point, we're going to add some component of that vector to this point here and so we'll see a new decision."
        ],
        [
            "And with the points in this direction, yeah.",
            "So actually flips around and now there was a partial component of that original vector being added here and we now."
        ],
        [
            "Pointing in this direction.",
            "OK, so we selected you incorrectly classified data points, so I think there's a green one.",
            "It should be.",
            "I can't see it from this angle.",
            "Yeah, so one of the negative data points is is now the incorrectly classified data points on the positive side of the decision boundary.",
            "So we do the same thing again, but this time we're going to be subtracting."
        ],
        [
            "The sign of."
        ],
        [
            "Data point."
        ],
        [
            "Is nge?"
        ],
        [
            "Jeff so this sign of this 58 datapoint is negative.",
            "So actually sub."
        ],
        [
            "Acting that vector component off but only a little bit of it.",
            "And now all the data is correctly classified, so we're done.",
            "Now, that's actually a remarkably fast classification algorithm for data sets of this type, and.",
            "It is true that the perception algorithm does Kent converge very quickly if the data is fully separated.",
            "I'm not going to talk about what happens if the data isn't separated, but basically there's proofs about if you set up your learning rate.",
            "If you reduce your learning rate at a certain what value you will converge towards something in the limit of large data, which is the optimal decision boundary.",
            "see I think the really nice thing about this algorithm is that I mean I think Rosenblatt's book is 1963, but he was using it in the 50s and he was had a course on.",
            "How the brain works where he used to sit on it.",
            "Why was?",
            "Because.",
            "Yeah.",
            "Good question.",
            "No, not what I'm not really equipped to ask answer.",
            "Actually I had this diagram in, so it's a threshold like that and one of the things in machine learning that well, one of the things in the next community that we knew is that if you could draw your algorithm with a circle and a bunch of interconnecting lines, that meant it was like the brain.",
            "So the idea was that you had your input X1X 2X3.",
            "W1W2 W 3 and then you were this was input from another neuron or a sensor.",
            "So in this case it's obviously this is.",
            "I mean we did multilayer perceptrons as well and they were quite effective algorithms, but this in this case you would have to think of it as some sort of visual sensor.",
            "So this is some input from the retina and then you whatever the size of this input, the model of the neuron is that you're summing up these inputs and then you're firing.",
            "When that sum reaches a certain threshold and you, I think you would write this threshold in here be Now this was not Rosenblatt's model of a neuron, it was McCulloch and Pitts, but it's McCulloch and Pitts in 1943, so it's quite an old model so you know.",
            "I actually was quite excited by this type of model and the major innovation for the multilayer perceptrons was instead of this being a threshold, we turned this into a smooth function, which meant you could do differentiation and you can make multiple layered versions of this, so you would have another input layer here.",
            "And then basically you put the whole thing together so you got some input and you would feed forward through and make your classification and very much I was inspired to come into.",
            "Machine learning.",
            "Because of these models, I think a big disappointment for me was I actually worked out so there was a problem with this multilayer perceptron idea.",
            "Because if you got multi layered version so I should turn on.",
            "This one I'm overweight, so if you do multi layered versions of maybe you can hear me.",
            "OK good if you do multi layered versions of this.",
            "If you've got threshold units there was this problem of how you work out, what the responsibility for the error here is because you your objective function was discontinuous so you couldn't compute gradients and I think it's published in AI stats in 1999.",
            "I worked out an algorithm for doing that and I was very excited 'cause it.",
            "It was written as a big open problem in machine learning.",
            "How you do that?",
            "Multi layered networks of these linear threshold units.",
            "When I published it, no one cared because it wasn't an interesting problem because we moved beyond that that model in two ways.",
            "One no one thought of it as a realistic model of the brain.",
            "And two no one thought of it is a practically useful way of doing classification.",
            "So in some sense we can see that now, but I think if we go back to say, the early 50s and we look at Rosenblatt's work with early computers, what you see is he's got.",
            "An extremely fast way of doing classification.",
            "That was published was based on a model of a neuron that was published.",
            "You know less than a decade ago as the way the brain works.",
            "I think that would be at the time would be considered a very exciting thing.",
            "So now we can look back on it and say, yeah, not really how the brain works, but it's got some interesting aspects.",
            "And the reason I wanted to talk about it here is because it's this interesting aspect of learning of that you've got something that you need to adapt.",
            "So in that case.",
            "These weights here and what you're adapting those weights according to is what you observe to be the class.",
            "What you talk about your supervision signal is, and what your input signal is, right?",
            "So and then there were, I think, examples of similar models."
        ],
        [
            "We're based on very simple learning rules, Hebbian learning type rules which you know again, I don't know much about, but I understand one point with you know it was taken very seriously in cognitive science, so you reinforce connections where you see things on together at the same time and those sort of models include things like the Hopfield network and Boltzmann machines, which are making a big comeback at the moment."
        ],
        [
            "So.",
            "OK, so.",
            "I don't want to talk much more about that learning rule or what the objective function is, but what I want to do is to talk about something I spent more time working on, which is regression.",
            "So it's less connected to the brain, but I'm going to follow a similar path of trying to show you a regression.",
            "We know how to do regression.",
            "Regression was invented by sort of physicists around the turn of the 19th century for fitting physical models of the universe to observations of where the planets work.",
            "It was reinvented by Galton, who called it regression statistician in sort of the turn of the 20th century."
        ],
        [
            "And it's basically the same.",
            "A different type of supervised learning, but the the target now has a real value given some set of inputs.",
            "So one of my favorite datasets on this is predicting the quality of meat given spectral measurements.",
            "This is tekkit or data, so you've got some sort of set of spectral measurements and you want to predict they measure to meet and you want to predict what the quality of that meat was radiocarbon dating.",
            "So the C-14 calibration curve, so you predict age of an object given its radiocarbon age, because the C-14 quantity in the.",
            "Atmosphere hasn't been decaying, changing constantly as the radiocarbon age suggests.",
            "Sort of machine learning example.",
            "I think this is true.",
            "This is something called TD Gammon, which is a really early reinforcement learning approach to playing backgammon, which was big famous success in the machine learning community.",
            "But I think the competing approach to TD Gammon when it was released, or maybe even the best performing backgammon player currently is you basically get.",
            "Expert backgammon players to score the quality of a bunch of different moves, so they give us some sort of score, and then you train the computer to learn this mapping that the backgammon player is has provided, and then you get the computer to recreate that.",
            "You could also consider that for something like go so these are complex games, you can't explore the whole state space of these games, you can't do in the way you do chest, so this is a way of doing learning.",
            "I should say that I mean they're good examples of what was.",
            "I would say the main approach to artificial intelligence applications from a machine learning perspective up until the turn of the 21st century, which was very much that if someone comes to you with a problem.",
            "Something that needs to be solved.",
            "You have to work out how you can convert that problem into a classification problem or a regression problem, and then you fit that as a component and you take your favorite regression or classification approach and then you use that to solve their problem.",
            "Now think that that's.",
            "It's it's an engineering approach that is perfectly valid and people will continue to use it today, and you know the main and they'll continue to use things like support vector machines instead of neural networks if they're up to speed, but it can't be the right way of solving all these artificial intelligence problems to just workout a way of making it a classification of regression.",
            "There has to be something deeper, and I think that's where reinforcement learning comes in, so these are examples of where that's being done.",
            "You basically workout how you can convert, go playing into a regression problem by making the computer recreate expert opinion.",
            "On these moves."
        ],
        [
            "OK, so predicting now real value of Y given X and I know we're going to look at really simple value of regression, so our prediction will be F of X is just MX plus C. So linear, sorry, one dimensional input, 1 dimensional output and will also define an error.",
            "So the error is Delta Yi.",
            "Is the difference between our prediction?",
            "And the actually observed value of the regression.",
            "So we can look at."
        ],
        [
            "Things like this and we can come up with potentially an algorithm I want to do it in the same way we did the perceptron.",
            "We can add a portion of this error to the bias.",
            "So what we're going to say is that you initialize your bias some way and then what you do is you take one of these learning rates and then you add some portion of your error to whatever your biases, right?",
            "So here's your error defined now by substituting F of X into here.",
            "So what's going to happen if we do this for the bias so there's two components to the regression, there's a slope and a by an intercept or bias, so it's where this goes through the Y axis.",
            "If you set X to 0, then this is just see.",
            "So we want to set the Intercept.",
            "So that's basically moving the line up and down, so for positive error, see and therefore F of X become larger under this learning rule.",
            "So if we if we got a positive error here, then basically this learning rules says make see larger.",
            "And corresponding that makes F of X larger.",
            "But this makes the error smaller.",
            "Yeah, so that changes the error in the right direction, so for negative error see it becomes smaller.",
            "An error magnitude also becomes smaller, so the magnitude of this error will reduce if we change."
        ],
        [
            "Change it in this way.",
            "We can do the same.",
            "We can try and come up with a learning rule for the slope and we can here we have to consider 4 cases because X can have a negative input and you can go through all of these cases and show that the error will become smaller in each of these cases.",
            "If we apply this learning rule, I think that this is very for me.",
            "This is certainly an.",
            "It was an attractive way of thinking about learning rules.",
            "When I when I first started in machine learning.",
            "You can see that something sensible is happening and if you have interpretations for these as connections in the brain, which there is no term interpretation here, you can see how those connections are changing, but you can see even for this simple case it's becoming quite complicated to write down the justification of the learning rule.",
            "I've come up with.",
            "I don't think anyone's invented this learning rule in this way of trying to justify it, but you know you can try and justify it.",
            "You can look at learning."
        ],
        [
            "Doesn't say what they're doing."
        ],
        [
            "So if we apply that we can."
        ],
        [
            "Present data points compute the current error and change."
        ],
        [
            "Estimate of airmen seacore."
        ],
        [
            "Into those presenting."
        ],
        [
            "One data point at."
        ],
        [
            "Time."
        ],
        [
            "And this is."
        ],
        [
            "An interesting way of work."
        ],
        [
            "And we were very into this in machine learning."
        ],
        [
            "I think maybe we should get more into it."
        ],
        [
            "Um?"
        ],
        [
            "As we go through."
        ],
        [
            "In each data point."
        ],
        [
            "We changed the error slow."
        ],
        [
            "Early."
        ],
        [
            "And the regression."
        ],
        [
            "Comes more accurate."
        ],
        [
            "Why will we into this?",
            "Because it's sort of adaptive learning scenario, right?",
            "We called it online learning in those days, but I think now you call it stochastic gradient descent because if you say online people think you're on the Internet.",
            "So."
        ],
        [
            "So.",
            "What we?"
        ],
        [
            "Interesting doings present."
        ],
        [
            "Each of these dates."
        ],
        [
            "Points one at a time."
        ],
        [
            "I'm an N."
        ],
        [
            "Only converging to."
        ],
        [
            "Awards"
        ],
        [
            "A solution now it takes more iterations."
        ],
        [
            "This example and the perceptron, so we're already iteration 10."
        ],
        [
            "Then I'm jumping through this."
        ],
        [
            "Iteration 20."
        ],
        [
            "30"
        ],
        [
            "40"
        ],
        [
            "50"
        ],
        [
            "60"
        ],
        [
            "She OK 70 and I've got some convergence criteria and it's converged around 70, so that's a way of estimating that linear regression.",
            "Now there's much much quicker ways of doing that, but I wanted to show you that because it's similar to this perception idea that presenting a data point and then you're."
        ],
        [
            "Testing your gradient and so on so forth.",
            "Now I wanted to use this opportunity to enter into and add something in.",
            "It's a simple concept.",
            "It certainly seems simple.",
            "When I wrote it down, but it took us a while to see things.",
            "Perhaps in this way in learning, statisticians have used this for a long time, so there's a problem with those of regression things.",
            "There's a problem with the learning rule as well, but I'll come back to that sort of more in the next session.",
            "But there's a problem with these linear regressions.",
            "This X may not be linear related to why, so I think that this is true, and maybe anyone who knows.",
            "Better than I can correct me if I'm wrong, but you know, I think in the brain you don't really take the pixels of what you see coming in and multiply them by an inner product and threshold them before you pass them to other parts of the brain.",
            "What you actually do is use to process them in some way and.",
            "One way of making things so this is a linear relationship.",
            "We've been looking at, but what we're really interested very often is nonlinear functions of X.",
            "So one way of making a nonlinear function for model is by introducing basis functions.",
            "So what is the basis function?",
            "So it's a way of taking those inputs and then representing them by a nonlinear function in the input space.",
            "So you just have a bunch of these, and then you sum up linear combinations of those.",
            "Now an example of that might be.",
            "I understand there's some evidence that when you process in the visual cortex, very low level processing the Gabor basis is used, which is a particular way of.",
            "So if you're looking at an image you don't do high level processing.",
            "As far as I understand, on the pixels you basically extract features from the image and maybe those features are edge like features or whatever orientation features and then you do processing on those.",
            "The extraction of those features could be seen as basis functions.",
            "We can also we think about basis functions as very general classes of functions.",
            "But in signal processing people would be very interested in things like the Fourier basis.",
            "So transforming your data into a frequency space, but that has a basis function perspective that you can.",
            "Where your basis functions would be sines and cosines, and so, and I think in the visual cortex, you might say Gabor."
        ],
        [
            "Wavelets of these basis functions, but let's look at an example and one that is a.",
            "Often favored for regression, although I'm not sure it's a particularly good way of doing regression myself, but would be to use a polynomial basis."
        ],
        [
            "So what you do is say OK. One way of making this nonlinear is to have."
        ],
        [
            "The sum of a polynomial basis where we basically got three basis function."
        ],
        [
            "One is a constant one."
        ],
        [
            "Is linearly increasing and one is a quadratic OK?",
            "So we can add up these three things by waiting them to come up with functions that will look like a somova offset, linear, and."
        ],
        [
            "And a quadratic, so that's our F of X.",
            "And here I've set W 1 to be .87.",
            "So there's this thing is being weighted by .87 W 2.",
            "The linear term is being weighted by minus .38, and W 3 is being weighted by minus two.",
            "So you basically see that quadratic form is inverted because it's heavily weighted in a negative direction.",
            "There's some decreasing linear trend coming from the negative weight of that.",
            "And there's some positive offset pulling the thing up a bit, so that's the sort of function and nonlinear fun."
        ],
        [
            "And that can come from these basic constructions, and you can do different functions."
        ],
        [
            "As you do different weights."
        ],
        [
            "OK, so here's a basis I prefer, and I think one that we're quite interested in machine learning.",
            "We use it quite a lot.",
            "And I don't know how much introduction to kernel methods Bernard is going to do, but you can see kernel methods as examples of these types of bases too, but just with infinite basis functions.",
            "So it's a local basis.",
            "I like local basis because they have this local effect, so when they are weighted up, you know their effect is."
        ],
        [
            "Only in this region, the problem with these bases is there global and basically if you if you need to pull this thing down to affect the point here your affect over here is massive right?",
            "So for example if you got a slight nonlinearity then you can flip the thing one way or the other by pulling points up and down in this region.",
            "But you get an enormous effect over there.",
            "Yeah, and in fact polynomials as you go outside this region minus one to one polynomials become very badly behaved because you get squares of.",
            "Too cute and if you add in extra terms, cubes and so and so forth, you get really wild behaviors so."
        ],
        [
            "Have to be very careful with polynomial basis, but this is an alternative basis and it's often called the radial basis or the Gaussian basis, and you basically just have a bunch of functions like this that should be factor of half there.",
            "I don't know why."
        ],
        [
            "Are you up there?",
            "So."
        ],
        [
            "Sorry, that's alright 'cause it's 'cause of the length scale, so I'm waiting with the length scale in here.",
            "So I've got these lengthscale which controls the width of these basis functions and then what we're seeing here is 1 basis."
        ],
        [
            "There and then we've got another basis, which is shifted.",
            "So each of these basis is located in a different place, so this one is located at.",
            "Minus one thing and."
        ],
        [
            "It was located at 0 and then this one is located at plus one.",
            "So you've got these things.",
            "You can sort of move around."
        ],
        [
            "And then you can compute nonlinear functions by linear weighting of these things.",
            "Now this is very much.",
            "Like what we talked about before with this multilayer perceptron, and indeed that's what people were doing is.",
            "They were putting in additional basis and optimizing over the parameters of these bases here so that we can think of a weighted sum of these basis.",
            "You can think of the basis being the input here, but in this case the bases are these sort of local inputs.",
            "If they were global basis, you might sort of claim that there was some cognitive interpretation so you can wait."
        ],
        [
            "These things in different ways and come up with different functions and then the nice thing is you can go through the algorithm we had before without any sort of replacement in terms."
        ],
        [
            "If we just replace.",
            "The key aspect.",
            "OK, so the whole of kernel methods.",
            "Is based on the observation."
        ],
        [
            "In some sense that you can just view Fi as a new set of inputs so you can replace X with FI and then you can apply any algorithm replacing X with FI.",
            "So this is a fixed basis, but kernel methods is about infinite basis where you can do that.",
            "So basically we can."
        ],
        [
            "My algorithm as before, and I think it even it looks nicer in this case 'cause what happens is you can see that as you."
        ],
        [
            "Then to data point you adjust.",
            "According to the basis.",
            "Sponsor that data point to the basis so this data point computing across all those different bases it's responding more to the basis around minus one.",
            "Then it's the basis at zero and the base is at one so that."
        ],
        [
            "We're getting from 5."
        ],
        [
            "Four and it."
        ],
        [
            "We see is as we are."
        ],
        [
            "The weights that."
        ],
        [
            "We sort of pull up."
        ],
        [
            "One down in the different."
        ],
        [
            "Directions to you and up."
        ],
        [
            "Bring your function around."
        ],
        [
            "Yeah, this is not all."
        ],
        [
            "Good way to do regret."
        ],
        [
            "But you can sort of see the idea."
        ],
        [
            "These learning rules that as you observe."
        ],
        [
            "One point."
        ],
        [
            "At a time."
        ],
        [
            "After another."
        ],
        [
            "Yoostar"
        ],
        [
            "Pulling in different."
        ],
        [
            "Actions now."
        ],
        [
            "This law"
        ],
        [
            "Adding rule is cool."
        ],
        [
            "Old."
        ],
        [
            "Stochastic gradient."
        ],
        [
            "Percent."
        ],
        [
            "Um?"
        ],
        [
            "With these datasets, it's absolutely."
        ],
        [
            "Yeah, pointless."
        ],
        [
            "Using it because you can fit these datasets using."
        ],
        [
            "A quadratic for, well, one equation in one go, but as your basis set sizes increase or as your data set gets very large, then these stochastic gradient descent algorithms become quite important in machine learning, and they're just making a really big comeback because.",
            "What we did do is we went down the road of optimizing these problems and I'll talk about that in a second.",
            "What I mean by that, but we found for large datasets that this these sort of algorithms stochastic gradient descent algorithms."
        ],
        [
            "Work very well."
        ],
        [
            "So.",
            "All I talked about in terms of justifying what the learning rule there I think is.",
            "Not how you should be doing machine learning.",
            "You should not be writing down learning rules and saying this is how we do learning what you need to do is think in terms of error functions and I think that the cost function and what you're minimizing is what you're often really interested in.",
            "But the big split in machine learning.",
            "That's, for example, differentiates the work from Bernard from the work of me from work of media, from work from my work.",
            "Is is how you interpret this cost function.",
            "Whether you interpret this cost function probabilistically, which is what I'll talk about in my next session, or whether you interpret this function as an actual cost that you're paying, and then the big split is whether you're interested in clever ways of optimizing the cost function you've written down.",
            "Or why they're interested in trying to deal with the nasty probabilistic model you've written down, and that's what most of machine learning has been about.",
            "I would say, since say, 1997.",
            "So here's the cost function that would work for regression, so it's called this number squares."
        ],
        [
            "Yeah, I'm sure you've seen it before.",
            "So defining."
        ],
        [
            "The basic function is a vector."
        ],
        [
            "We can actually compute."
        ],
        [
            "The gradient of."
        ],
        [
            "This so that just gives us the ability to write that."
        ],
        [
            "In a product we can compute the gradient of this error function with respect to these."
        ],
        [
            "Weights.",
            "So learning is basically the minimization of the cost function.",
            "So what we were seeing before is I'm trying to claim is is minimizing these cost functions, and at the minimum the gradient is 0.",
            "So what we do is we compute the gradient of this cost function where we've got some error expressed in this form, just as we had before, and it has that form."
        ],
        [
            "Now, what's interesting is we can then do CPS descent, so this is a standard early optimization approach, and the basic idea is you've got some surface, some error surface prescribed by this cost function, and you want to send it by going in the steepest direction at all times.",
            "So you compute the gradient of this error function and then you change W at every step by moving in the steepest downhill direction.",
            "So if you're at W, you look at the steepest direction and then you change your position.",
            "According to what that gradient is, you descend the gradient.",
            "So if you can think of a Valley, if you keep doing that, you will eventually reach a minimum.",
            "It could be a low."
        ],
        [
            "Call minima.",
            "And it could be quite slow."
        ],
        [
            "Note converge as well so.",
            "On that regression problem earlier, this is what that error surface looks like.",
            "So you've got this quadratic error surface because it's a quadratic problem and it's linear.",
            "Well, it's quadratic in the W, so you see, this is a 2 dimensional sort of surface, but it's a parabola parabola, and I'm showing contours there."
        ],
        [
            "If you start with someone."
        ],
        [
            "Socialization?"
        ],
        [
            "As you"
        ],
        [
            "Do your learn."
        ],
        [
            "Thing if you just."
        ],
        [
            "Doing steepest descent."
        ],
        [
            "Right you go."
        ],
        [
            "Down."
        ],
        [
            "The Valley."
        ],
        [
            "Now those."
        ],
        [
            "Castec those."
        ],
        [
            "Algorithms?"
        ],
        [
            "I was showing you before.",
            "This is the steepest descent algorithm.",
            "Those algorithms are showing you before if you substitute in the gradient of the objective."
        ],
        [
            "Dare the directors agent."
        ],
        [
            "Getting objective you can.",
            "Then you get this factor of two, which is just some factor of the."
        ],
        [
            "How to find the objective function which you can combine in the learn?"
        ],
        [
            "Going rate."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome you all here.",
                    "label": 0
                },
                {
                    "sent": "There was a short period a few weeks ago when we're all very concerned that volcanic ash might knock the whole meeting into smithereens, but here we all are little later after having never sorted out our navigational challenges and expected.",
                    "label": 0
                },
                {
                    "sent": "But we're all here.",
                    "label": 0
                },
                {
                    "sent": "The technical things are almost all working.",
                    "label": 0
                },
                {
                    "sent": "We haven't quite got the speaker mic source it out, but that's coming.",
                    "label": 0
                },
                {
                    "sent": "Full location, delightful to see you all here.",
                    "label": 0
                },
                {
                    "sent": "I really hope it's going to be exciting and fun meeting.",
                    "label": 0
                },
                {
                    "sent": "I'm looking forward to it so I just want to do literally 2 minutes introduction.",
                    "label": 0
                },
                {
                    "sent": "It could even be less.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to hand over to Neil.",
                    "label": 1
                },
                {
                    "sent": "First of all, this is a chance is to thank our sponsors.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much to thank our sponsors Pascal, who have very generously supported this summer school in cognitive science and machine learning.",
                    "label": 1
                },
                {
                    "sent": "The purpose of the meeting is to bring together the two communities of cognitive scientists and machine learners, and for that reason we've broken the the meeting up into two parts.",
                    "label": 0
                },
                {
                    "sent": "So one is primarily tutorial, but I don't think that will be sort of dull.",
                    "label": 0
                },
                {
                    "sent": "Tutorial actually sort of exciting and fun and a chance to revisit things.",
                    "label": 0
                },
                {
                    "sent": "1/2 understood.",
                    "label": 0
                },
                {
                    "sent": "That's what we're hoping tutorial and the idea of that is to bring people in cognitive science up to speed, at least to some degree with what has been happening in machine learning and Conversely.",
                    "label": 0
                },
                {
                    "sent": "To give people with a background in machine learning, some sense of what cognitive Sciences get up to.",
                    "label": 0
                },
                {
                    "sent": "And then in the second part, after a rest day on Sunday, then we'll talk about specific topics and those specific topics are.",
                    "label": 0
                },
                {
                    "sent": "Up on the next slide, I think.",
                    "label": 0
                },
                {
                    "sent": "Yeah, they are perception classification language and thought and decision and action and they will roughly correspond to the days the 2nd three days of the meeting, but not quite due to various speaker complications.",
                    "label": 0
                },
                {
                    "sent": "Let me just pop back again actually to the the.",
                    "label": 0
                },
                {
                    "sent": "Goals of the meeting so clearly there is a tutorial element to it and what we want to give each side of the field offensive.",
                    "label": 0
                },
                {
                    "sent": "What's going on in the other, to give a sense of some of the state of the art developments in both areas, particularly the interface in the in the second half.",
                    "label": 0
                },
                {
                    "sent": "And of course to discuss and explore interconnections between the two fields.",
                    "label": 0
                },
                {
                    "sent": "And we would hope lead to exciting, interesting pieces of research in future, perhaps some of which might be might fit within the remit of Pascal.",
                    "label": 0
                },
                {
                    "sent": "Others won't, but the objective of this meeting, more than anything, is to try to harness the insights machine learning for the purposes of understanding the mind, and Conversely to harness what we know about the mind to improve and enrich models of machine learning.",
                    "label": 0
                },
                {
                    "sent": "So without further ado.",
                    "label": 0
                },
                {
                    "sent": "Let's go and I hand over certain Neil Lawrence is going to take the first session.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I guess the.",
                    "label": 0
                },
                {
                    "sent": "First thing that you need to do when giving a presentation is to know your audience.",
                    "label": 0
                },
                {
                    "sent": "I don't know cognitive scientists that well, and I thought damn, I'm also going to be speaking first so I don't even have a.",
                    "label": 0
                },
                {
                    "sent": "Can't even adjust the quality of my level, of which I picked things to the audience, but I thought, well, I know a couple of cognitive scientists I know Josh Tenenbaum, and I know Tom Griffiths, so maybe I should be pitching my talk level at them.",
                    "label": 0
                },
                {
                    "sent": "But then they know more about machine learning than I do, so I.",
                    "label": 0
                },
                {
                    "sent": "Thought that probably wasn't a good idea, so I decided that they were exceptional cognitive scientists and that I would try and pitch my introduction to machine learning well.",
                    "label": 0
                },
                {
                    "sent": "In some sense, more of a personal history of what I think machine learning's origins are, and perhaps a justification of why cognitive science and machine learning should be closer than they are.",
                    "label": 0
                },
                {
                    "sent": "And to try and explain why I think that it's important that machine learning learns a lot from cognitive science, just as I think many people feel like Nick that cognitive science can learn from machine learning, so.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to give a bit of motivation for.",
                    "label": 0
                },
                {
                    "sent": "What I see as what machine learning is and how it's different, and then I'm really going to cover a couple of the areas I'm not going to cover reinforcement learning because Chris Watkins is going to also get the second part of this talk, but the way I'd like to do that is rather than giving what would be a sort of a modern perspective on how we think of these things, try and give something that I think reflects some of the history of where machine learning came from and what we thought of these algorithms perhaps.",
                    "label": 0
                },
                {
                    "sent": "20 years ago, although I wasn't machine learning 20 years ago I was in machine learning 13 years ago and there was still some memory of that then.",
                    "label": 0
                },
                {
                    "sent": "So OK, what is the motivation of machine learning?",
                    "label": 0
                },
                {
                    "sent": "So I think this is important.",
                    "label": 0
                },
                {
                    "sent": "We are interested in getting computers to learn from data.",
                    "label": 0
                },
                {
                    "sent": "So and our computers with the ability to learn from data and this is important because there's things like data from sensors, so there's lots of things like.",
                    "label": 0
                },
                {
                    "sent": "Measuring multiple sensor arrays and trying to combine data from multiple sensors.",
                    "label": 0
                },
                {
                    "sent": "the Internet experiments.",
                    "label": 0
                },
                {
                    "sent": "I work a lot and computational biology and we expect to be able to combine these things to get a computer to make some sort of sensible decision.",
                    "label": 0
                },
                {
                    "sent": "This is very vague.",
                    "label": 0
                },
                {
                    "sent": "But we traditionally split up machine learning and categorize it in several different ways, so.",
                    "label": 0
                },
                {
                    "sent": "We think of supervised learning and that's one of the things I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "In particular, we might think of classification regression.",
                    "label": 0
                },
                {
                    "sent": "Now, I think when I came into machine learning, these were still considered sort of big problems.",
                    "label": 0
                },
                {
                    "sent": "How do you classify things?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do you do a good regression algorithm?",
                    "label": 0
                },
                {
                    "sent": "One of the differences I'd say between machine learning in 1997 and machine learning today is I think if you have a standard classification setup in terms of sort of vectorial input in class labels, we sort of know how to do that.",
                    "label": 0
                },
                {
                    "sent": "And the same for regression.",
                    "label": 0
                },
                {
                    "sent": "So in some ways I almost see these is they're not resolved because there's lots of interesting extensions which you need to look at, but the pure classification regression formats I'll talk about today.",
                    "label": 0
                },
                {
                    "sent": "I tend to think of it as fairly well covered.",
                    "label": 0
                },
                {
                    "sent": "Then there's also unsupervised learning, so unsupervised learning classification regression.",
                    "label": 1
                },
                {
                    "sent": "You typically have inputs and some outputs, some targets, and you want to learn a mapping between them.",
                    "label": 0
                },
                {
                    "sent": "In unsupervised learning, you just have some data and you want to sort of uncover some structure in that data, and my particular interest is dimensionality reduction in that area.",
                    "label": 0
                },
                {
                    "sent": "That's probably the area I do most work on in machine learning, but there's other things such as clustering.",
                    "label": 0
                },
                {
                    "sent": "Finally, this is the most difficult one.",
                    "label": 0
                },
                {
                    "sent": "I tend to think of these as I think I understand these and how they work.",
                    "label": 0
                },
                {
                    "sent": "Actually, this is the most interesting thing, probably.",
                    "label": 0
                },
                {
                    "sent": "Reinforcement learning, so learning from delayed feedback.",
                    "label": 1
                },
                {
                    "sent": "So you've got some sort of tasks.",
                    "label": 0
                },
                {
                    "sent": "You're getting some feedback, perhaps from your environment doing planning how you're going to do things that I think really the bit that I know least about in machine learning, but Fortunately we've gotta an expert here in Chris Watkins who's going to talk a bit about that, and I think that, but I think that this is one of the areas where there's hopefully going to be most advances in the future.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to give you sort of what I think of as a personal history of machine learning, and I've sort of put Rosenblatt Subotnick because I think that reflects the journey machine learning's been on certainly well before I was around.",
                    "label": 0
                },
                {
                    "sent": "And since I've been around as well so.",
                    "label": 0
                },
                {
                    "sent": "I think that this is interesting origins of machine learning is coming out of things very closely related to Congress.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Science so early connection this research so we call ourselves machine learning today, but I think there was a time when I certainly didn't think of machine learning as being a term that apply to me.",
                    "label": 1
                },
                {
                    "sent": "We were doing neural networks and we were the neural networks community and our main conference was the neural information processing systems.",
                    "label": 0
                },
                {
                    "sent": "We also went to HTML.",
                    "label": 0
                },
                {
                    "sent": "The International Conference on Machine Learning, but that had all sorts of other things there, which we weren't so interested in necessarily.",
                    "label": 0
                },
                {
                    "sent": "So we were really interested in these connectionist models.",
                    "label": 1
                },
                {
                    "sent": "These neural networks, certainly that's what got me interested in doing machine learning.",
                    "label": 1
                },
                {
                    "sent": "I did mechanical engineering degree and then I went and worked on oil rigs for awhile, and then I thought what do I want to do?",
                    "label": 0
                },
                {
                    "sent": "Research in and I thought I want to know how the brain works and I thought I wanted to neural networks.",
                    "label": 0
                },
                {
                    "sent": "That was 1996, so I think a big motivational example and some things I guess what the earliest sort of connection is.",
                    "label": 0
                },
                {
                    "sent": "Research where you can pull together.",
                    "label": 0
                },
                {
                    "sent": "Computing and learning.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It would perhaps be Rosenblatt's perceptron.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk a little bit about the fitting of the perceptron, but importantly, it was based on a really simple model of a neuron from 1943, and it had a learning algorithm for how that neuron worked.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now later machine learning research, though, has gone from that.",
                    "label": 1
                },
                {
                    "sent": "Those sort of simple, perhaps neurally inspired models to theoretical foundations of such models.",
                    "label": 1
                },
                {
                    "sent": "Such questions as their capacity to learn.",
                    "label": 0
                },
                {
                    "sent": "I think a real sort of example of that is, you know, Batmix work on statistical learning theory.",
                    "label": 0
                },
                {
                    "sent": "It's not the path I follow, but it's extremely theoretical, very mathematical, and it doesn't really care whether the learning algorithm has any basis in the brain.",
                    "label": 0
                },
                {
                    "sent": "It's just about learning algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My personal view is that machine learning benefited really greatly by incorporating lots of ideas from psychology, but not being afraid to incorporate rigorous theories.",
                    "label": 1
                },
                {
                    "sent": "So, and I do credit in particular when I think about the people that were around sort of before I was around, I look at the community before I was around.",
                    "label": 0
                },
                {
                    "sent": "I tend to think of people like Mike Jordan, Jeff Hinton.",
                    "label": 0
                },
                {
                    "sent": "They were in this parallel distributed processing research group, sort of, I guess in the early 80s, and that was very, I guess psychologically based.",
                    "label": 0
                },
                {
                    "sent": "What's the algorithms they came out with were inspired by thinking about how the brain could work.",
                    "label": 0
                },
                {
                    "sent": "But I think he's very impressive, so it's easy to sort of, say, well, we're going to do something on computers and we're going to be inspired by the brain.",
                    "label": 0
                },
                {
                    "sent": "And we're going to do sort of learning.",
                    "label": 0
                },
                {
                    "sent": "Or you could sort of look at more recent things like simlife and genetic algorithms.",
                    "label": 0
                },
                {
                    "sent": "All these different things inspired by evolution.",
                    "label": 0
                },
                {
                    "sent": "Let's do let's do what evolution does.",
                    "label": 0
                },
                {
                    "sent": "I think machine learning in some sense is slightly different because I think it's been far less afraid of very, very strong theory, and very very strong mathematics, and very.",
                    "label": 0
                },
                {
                    "sent": "Open to receiving that, and I think a lot of the credit of that goes to people like Mike Jordan and Jeff Hinton who early on when physicists theoretical physicists came in and said, Oh well, the model you've got of the brain is actually a spin glass and you can do this sort of analysis.",
                    "label": 0
                },
                {
                    "sent": "They didn't run away saying that's just theory we are interested in the results.",
                    "label": 0
                },
                {
                    "sent": "They embrace that, and those people are still in the community today, and I think that you really see that reflected in the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "The diversity from people who are very interested in just the theory.",
                    "label": 0
                },
                {
                    "sent": "I have no concerns about whether this is what humans do, may not even have any concerns about whether their models work in particular applications to people who are only interested in applications have no concerns about whether this is how humans learn to people that are interested in humans learning, and it basically has covered all those things, and I think it's very important that it continues to cover all those things 'cause it benefits from that mix of people.",
                    "label": 0
                },
                {
                    "sent": "And this is a lot about what I think.",
                    "label": 0
                },
                {
                    "sent": "This of the summer school is about is partially about remaking that connection.",
                    "label": 0
                },
                {
                    "sent": "So one of the things that's happened is.",
                    "label": 0
                },
                {
                    "sent": "Machine learning people get accused of just doing lousy statistics.",
                    "label": 0
                },
                {
                    "sent": "Because one of the results of these sort of research is is the work we did does work well on things that are traditionally considered to be statistical applications, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Early machine learning, I think was viewed with some skepticism by statisticians because.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They saw it as sort of sloppy statistics.",
                    "label": 0
                },
                {
                    "sent": "Now I'm glad to say that.",
                    "label": 0
                },
                {
                    "sent": "Modern machine learning and statistics interact to both communities benefit, so if if I go and visit so recently we had Chris Holmes visit a grouping.",
                    "label": 1
                },
                {
                    "sent": "Manchester, he's leading Bayesian statistician.",
                    "label": 0
                },
                {
                    "sent": "You know Ann and Chris Holmes and I when we're talking about the applications we're interested in, we have entirely overlapping ideas.",
                    "label": 0
                },
                {
                    "sent": "We think very much the same thing we use very similar models, very similar techniques.",
                    "label": 0
                },
                {
                    "sent": "Some of those techniques are now coming from the machine learning community, in particular variational methods, and I must admit that I was falling into the trap at one stage of thinking.",
                    "label": 1
                },
                {
                    "sent": "Well, is machine learning just an extension of statistics?",
                    "label": 0
                },
                {
                    "sent": "Are we just sort of modern statistics people with?",
                    "label": 0
                },
                {
                    "sent": "Perhaps sexier?",
                    "label": 0
                },
                {
                    "sent": "Applications in video and stuff like that?",
                    "label": 0
                },
                {
                    "sent": "And I guess I started getting persuaded by that argument.",
                    "label": 0
                },
                {
                    "sent": "I'm going to offend people.",
                    "label": 0
                },
                {
                    "sent": "Maybe when I say some of the things I'll say, but I'll continue anyway.",
                    "label": 0
                },
                {
                    "sent": "Don't feel too offended if you're a statistician.",
                    "label": 0
                },
                {
                    "sent": "Statistics this, I didn't really feel super comfortable with this.",
                    "label": 0
                },
                {
                    "sent": "'cause to me, statistics was the most boring part of all maths.",
                    "label": 0
                },
                {
                    "sent": "I remember sort of doing maths at the age of 16 and statistics was let's sum up these numbers and compute their mean OK and I could remember that.",
                    "label": 1
                },
                {
                    "sent": "But then I could never remember the proper formula for the standard deviation right?",
                    "label": 0
                },
                {
                    "sent": "And it didn't seem that interesting.",
                    "label": 0
                },
                {
                    "sent": "You couldn't, you know no one was telling me where it was coming from.",
                    "label": 0
                },
                {
                    "sent": "They just said compute the standard deviation of this data just arrived this it seemed very mechanical.",
                    "label": 0
                },
                {
                    "sent": "Anyone could do it.",
                    "label": 0
                },
                {
                    "sent": "Anyone in the class?",
                    "label": 0
                },
                {
                    "sent": "He wasn't good at maths could do this stuff and I didn't understand what the motivation was I avoided.",
                    "label": 0
                },
                {
                    "sent": "Statistical courses like the plague.",
                    "label": 0
                },
                {
                    "sent": "I mean I is so uninterested in doing any statistical courses so this dawning realization of machine learning being an extension of statistics came as something of a personal blow, so.",
                    "label": 0
                },
                {
                    "sent": "Having said that though, I've managed to reason my way out of that, and maybe that that's what.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well I'm giving you is my personal justification for what we're going on and why it's different from statistics.",
                    "label": 0
                },
                {
                    "sent": "And actually why modern statistics is not anything to do with what we think of as traditional statistics and and what you think of as being taught about means and variances.",
                    "label": 0
                },
                {
                    "sent": "I think modern research in statistics is close to machine learning, mainly because it isn't traditional statistics, it's something quite different so.",
                    "label": 1
                },
                {
                    "sent": "I guess my Paul on the road to Damascus or where it was going moment was a dinner for lunch.",
                    "label": 0
                },
                {
                    "sent": "In fact I had with Tony O'hagan and Zubin Ghahramani and several other people.",
                    "label": 0
                },
                {
                    "sent": "But these were the two people said the things that made a big impression on me.",
                    "label": 0
                },
                {
                    "sent": "That was part of a nips workshop we had Tony O'hagan over the Gaussian Process Workshop in the NIPS conference is about three or four years ago.",
                    "label": 0
                },
                {
                    "sent": "Is organized by column wiki, then Zoom in and the conversation went like this.",
                    "label": 0
                },
                {
                    "sent": "Tony said he's leading statistician Gaussian processes.",
                    "label": 0
                },
                {
                    "sent": "He said, as a statistician I will words this effect.",
                    "label": 0
                },
                {
                    "sent": "I don't believe that you can analyze data without human being involved, so I have a set of tools I know about these different tools of principal component analysis.",
                    "label": 0
                },
                {
                    "sent": "I have hypothesis testing.",
                    "label": 0
                },
                {
                    "sent": "I have whatever someone comes with data, I apply these tools.",
                    "label": 0
                },
                {
                    "sent": "I use my intelligence to decide which tool to apply.",
                    "label": 0
                },
                {
                    "sent": "And then I analyze the data and I come to a conclusion about what's in the data and I think you know, I completely agree with that.",
                    "label": 0
                },
                {
                    "sent": "I think you know if you're going to do serious data analysis, that's completely what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "And I was, you know, my heart sunk.",
                    "label": 0
                },
                {
                    "sent": "It looks like I'm a statistician.",
                    "label": 0
                },
                {
                    "sent": "But then zoom in came to my rescue and he said yes.",
                    "label": 0
                },
                {
                    "sent": "But unless you believe the human is doing something that you can't do on a computer, then you have to believe that whatever process the human is going through.",
                    "label": 0
                },
                {
                    "sent": "To pull all these tools in and apply them all to the data we can do on the computer as well.",
                    "label": 0
                },
                {
                    "sent": "I think God yes, of course.",
                    "label": 0
                },
                {
                    "sent": "That's right, there's no ghost in the machine is basically what he's saying, so there's nothing that the humans doing that we can't do, and that is the fundamental difference between a machine learning person and I start decision.",
                    "label": 1
                },
                {
                    "sent": "I think, because fundamentally, if you're in machine learning, you believe the end goal is to remove the human from the equation.",
                    "label": 1
                },
                {
                    "sent": "You believe that whatever that process is, which we are using, which we can justify to other humans.",
                    "label": 0
                },
                {
                    "sent": "The process we've used to analyze the data that you can deal with that as well.",
                    "label": 0
                },
                {
                    "sent": "Now, fundamentally, we can't do that.",
                    "label": 0
                },
                {
                    "sent": "At the moment, we don't have the right algorithms.",
                    "label": 0
                },
                {
                    "sent": "You know, it's great that we can't, because if we could, we'd all be out of work.",
                    "label": 0
                },
                {
                    "sent": "We can't do that and so at the moment the temporary solution is to do what the statisticians do.",
                    "label": 0
                },
                {
                    "sent": "So that's why our jobs look similar because we're doing similar things.",
                    "label": 0
                },
                {
                    "sent": "But the end goal is to get the human out of the loop as well, which is a very very challenging thing.",
                    "label": 0
                },
                {
                    "sent": "You know, I kind of think.",
                    "label": 0
                },
                {
                    "sent": "I just don't think we're anywhere near it anyway.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the moment the two fields overlap very very strongly.",
                    "label": 1
                },
                {
                    "sent": "Because of this, but they are not the same field and I think it is a massive mistake to fall into the trap of thinking they are the same field because you just fall into doing what the statisticians are doing.",
                    "label": 1
                },
                {
                    "sent": "That's fine, you can do what the sessions are doing, but you don't need machine learning to do that.",
                    "label": 0
                },
                {
                    "sent": "If you're going to be a different field, you have to understand why you're there, and I think it's very important that we there an.",
                    "label": 0
                },
                {
                    "sent": "I think it's important that we continue talking to other fields like cognitive science.",
                    "label": 0
                },
                {
                    "sent": "And use that incorporate ideas from other fields to push this along.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this summer, schools reflecting that we have a lot to learn from cognitive science.",
                    "label": 1
                },
                {
                    "sent": "I think one of the things I worry about statistics is.",
                    "label": 0
                },
                {
                    "sent": "If you don't look to humans, you can fall in fall into some traps.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So mathematical formalisms are very, very important, right?",
                    "label": 1
                },
                {
                    "sent": "They're very important, and that's what I'll hope to show in the rest of the talk.",
                    "label": 1
                },
                {
                    "sent": "Justify why mathematical formalisms are massively important, and the mathematical formalization of a lot of what we do in machine learning has pushed us forward dramatically has really made massive leaps over the last 10 years, but my feeling is to an extent a lot of advances, about 10 years.",
                    "label": 0
                },
                {
                    "sent": "Well, say 15 years, I should say.",
                    "label": 0
                },
                {
                    "sent": "So I came into the field, but a lot of the advances of that came in the first 10 years of that, and I think a lot of what we're doing is dotting I's and crossing T's at the moment.",
                    "label": 0
                },
                {
                    "sent": "So I worried that we're becoming a bit too obsessed with magical formalisms, and this is the reason why that can be a problem.",
                    "label": 0
                },
                {
                    "sent": "So this is really stupid idea that aerodynamically a bumblebee can't fly, and then the answer is, well, the bumblebee doesn't know that, so he flies through the force of his heart or something like that.",
                    "label": 0
                },
                {
                    "sent": "Let me see that crap, isn't it?",
                    "label": 0
                },
                {
                    "sent": "I mean aerodynamically Bumblebee can fly.",
                    "label": 0
                },
                {
                    "sent": "You can see a bumblebee flying.",
                    "label": 0
                },
                {
                    "sent": "You can see examples of it all the time.",
                    "label": 0
                },
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "It means the mathematical formalism you are using to model what happens aerodynamically does not apply in the bees case.",
                    "label": 0
                },
                {
                    "sent": "It applies to jet aircraft, it applies to jumbo jets.",
                    "label": 0
                },
                {
                    "sent": "It applies to fighter jets, but it doesn't apply to what the bumblebee is doing.",
                    "label": 0
                },
                {
                    "sent": "So it's clearly a limitation of the model rather than a fact.",
                    "label": 1
                },
                {
                    "sent": "Now the problem is you can get these two things confused because the first thing you do is you say, well, this is the situation.",
                    "label": 0
                },
                {
                    "sent": "In real life I can't model everything in that, so I'll have a mathematical idealization and I'll study that.",
                    "label": 0
                },
                {
                    "sent": "But then you can spend so long studying that that when you actually look back at the situation in real life, you say it yourself well.",
                    "label": 0
                },
                {
                    "sent": "Impossible things.",
                    "label": 0
                },
                {
                    "sent": "Things that happen are impossible and we hear examples of that things like, well, it's impossible for human, you know, the vision problem is impossible because of the curse of dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Well, the vision problem isn't impossible because you're doing it all the time.",
                    "label": 0
                },
                {
                    "sent": "It's difficult, but you know we're just doing it wrong when we do it on computers and we see advances in that direction as well.",
                    "label": 0
                },
                {
                    "sent": "So I think it's very dangerous to get lossed in pure mathematical formalisms, because you forget that there are things going on that humans can do.",
                    "label": 0
                },
                {
                    "sent": "For example, that we want to recreate, and that's why this link.",
                    "label": 0
                },
                {
                    "sent": "You know, I think that there's there's a really interesting example of that, and it's with good reason.",
                    "label": 0
                },
                {
                    "sent": "So statisticians will tell you that you can't, or Pearson, I think said, and a lot of statisticians will say this that you can't infer causality from data.",
                    "label": 0
                },
                {
                    "sent": "And I think for early statistics it was quite important that this concept existed.",
                    "label": 0
                },
                {
                    "sent": "But you know why do humans have a concept of causality then?",
                    "label": 0
                },
                {
                    "sent": "If you can't infer it from data?",
                    "label": 0
                },
                {
                    "sent": "I mean data is just what we see and do, and causality is a really important aspect of that.",
                    "label": 0
                },
                {
                    "sent": "So you can get a little bit lost if you will start proving these things in demonstrating these things and lose sight of what's actually really going on and what you really want to achieve.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So mathematical foundations are very important, though they still under help us understand the capabilities of their algorithms, and I think that.",
                    "label": 1
                },
                {
                    "sent": "You know, This is why this summer school is important because you have to actually keep in touch with both of these things.",
                    "label": 0
                },
                {
                    "sent": "It's really hard now.",
                    "label": 1
                },
                {
                    "sent": "I think to come into machine learning as an undergraduate.",
                    "label": 0
                },
                {
                    "sent": "Well as a graduating undergraduate as a grad student, compared to how it was when I came in.",
                    "label": 0
                },
                {
                    "sent": "So when I came in.",
                    "label": 0
                },
                {
                    "sent": "The math you needed to know was very complex thing known as the chain rule, and you needed to know that to derive an advanced algorithm known as backpropagation.",
                    "label": 0
                },
                {
                    "sent": "I still use the chain rule.",
                    "label": 0
                },
                {
                    "sent": "It's still quite useful, but I do an enormous number of other things and you know when I think about what I'm trying to get my students to do and what I expect them to know quite quickly on.",
                    "label": 0
                },
                {
                    "sent": "It is far more than I knew when I came into machine learning in terms of, say, linear algebra, probability theory.",
                    "label": 0
                },
                {
                    "sent": "In other areas you'd be talking about functional analysis.",
                    "label": 0
                },
                {
                    "sent": "It's very complicated and that makes it tough because I don't think it's the case that the undergraduate programs.",
                    "label": 0
                },
                {
                    "sent": "Pushing people further than they used to, so there's a steep learning curve to come into machine learning, but it's important that people know that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, that's already sort of.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's in that point.",
                    "label": 0
                },
                {
                    "sent": "Humans give us the inspiration, though.",
                    "label": 0
                },
                {
                    "sent": "To go beyond these mathematical formalism.",
                    "label": 0
                },
                {
                    "sent": "So it's important we don't get lost in the more advanced mathematics that we are doing.",
                    "label": 0
                },
                {
                    "sent": "I mean, sometimes I think so.",
                    "label": 0
                },
                {
                    "sent": "I'm in a computer science Department, but sometimes I feel that it would be more appropriate to be in applied math Department because, you know, I don't see much difference between what applied mathematicians are doing and what we do.",
                    "label": 0
                },
                {
                    "sent": "The main differences.",
                    "label": 0
                },
                {
                    "sent": "Perhaps we consider a broader range of problems, and it takes me a lot longer to workout the math and some applied math.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rotations.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Back to this question in statistics, so early statistics had really wanted statistics about an early statistics, and I think you have to understand this origin to see why it's different from machine learning.",
                    "label": 0
                },
                {
                    "sent": "They had great success with this idea of a statistical proof, and I think this is a really important concept.",
                    "label": 1
                },
                {
                    "sent": "You mustn't forget this concept, but one must also ignore it as well.",
                    "label": 0
                },
                {
                    "sent": "In some sense in terms of looking for the future because it's there and it's dumb.",
                    "label": 0
                },
                {
                    "sent": "So there's a question.",
                    "label": 0
                },
                {
                    "sent": "I compute the mean of two tables of numbers, which is a statistic, right?",
                    "label": 1
                },
                {
                    "sent": "So that's what baseball statistics are like.",
                    "label": 0
                },
                {
                    "sent": "And that's what it's really about studying statistics.",
                    "label": 0
                },
                {
                    "sent": "They are different.",
                    "label": 0
                },
                {
                    "sent": "Does this prove anything?",
                    "label": 0
                },
                {
                    "sent": "Does this mean anything?",
                    "label": 0
                },
                {
                    "sent": "And this is what people were interested in?",
                    "label": 0
                },
                {
                    "sent": "They were social scientists, early social scientists.",
                    "label": 0
                },
                {
                    "sent": "They were measuring poverty in Manchester, comparing it to poverty in London and saying, is the poverty different?",
                    "label": 1
                },
                {
                    "sent": "They didn't want to use models, they just wanted to sum up numbers and compute answers.",
                    "label": 0
                },
                {
                    "sent": "So the answer was depends what statistics discovered is, it depends on how those numbers are generated, whether they are randomized and what big different, how big the differences between these two numbers.",
                    "label": 1
                },
                {
                    "sent": "That lead to hypothesis testing, but this is really restrictive because the questions you could then ask about your data that you can answer with the statistical proof are really, really limiting and what's really interesting is people actually think that that that's not on to what people think.",
                    "label": 0
                },
                {
                    "sent": "The philosophy of science is, so if you work in biology, people will tell you your what's your hypothesis, but then they say hypothesis they mean what's your simple question that you can answer with the statistic if you read Popper.",
                    "label": 0
                },
                {
                    "sent": "He's not talking about that, he talks about hypothesis is a much more complex thing that often you could not answer with a simple statistic.",
                    "label": 0
                },
                {
                    "sent": "So that can have a really limiting affected on science as well, but there were many successes in in this, and there are things that we we take for granted today.",
                    "label": 1
                },
                {
                    "sent": "The fact that we fertilize crops correctly.",
                    "label": 0
                },
                {
                    "sent": "The fact that you can get consistently brewed beer, right?",
                    "label": 0
                },
                {
                    "sent": "You know they couldn't do that before statistical tests were invented.",
                    "label": 0
                },
                {
                    "sent": "They invented statistical test to do that, but there are many open questions we've already mentioned one causality, so by summary about the difference in machine learning and statistics is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He's my favorite statistician actually because he worked for Guinness, so I don't know the full story that I don't want to read it in case my version of the story is wrong.",
                    "label": 0
                },
                {
                    "sent": "My version of the story is Guinness was very far sighted.",
                    "label": 0
                },
                {
                    "sent": "They employed statisticians and they understood how to brew beer consistently, and this was one of the key guys in doing and also growing hops, fertilizing hops.",
                    "label": 0
                },
                {
                    "sent": "He published under the name of student, 'cause he wasn't allowed to publish working for Guinness and.",
                    "label": 0
                },
                {
                    "sent": "Perhaps he's the reason why Guinness is one of the largest Brewers today.",
                    "label": 0
                },
                {
                    "sent": "That's that's my thought about it, but then I think there's another aspect to it.",
                    "label": 0
                },
                {
                    "sent": "He's very clearly.",
                    "label": 0
                },
                {
                    "sent": "I like him a lot, and I'm English, so I feel I can say this.",
                    "label": 0
                },
                {
                    "sent": "He's an Edwardian English gentleman, right?",
                    "label": 0
                },
                {
                    "sent": "So Edwardian English gentlemen have a certain reputation, and I think it's best encapsulated by, you know, the Edwardian attitude towards sex is very much that it's a functional thing, right?",
                    "label": 0
                },
                {
                    "sent": "There's no pleasure to be had in it.",
                    "label": 0
                },
                {
                    "sent": "It's just about reproduction.",
                    "label": 0
                },
                {
                    "sent": "Most statisticians were Edwardian English gentleman, right?",
                    "label": 1
                },
                {
                    "sent": "I think their attitude to data is almost very similar, that it's a very functional thing.",
                    "label": 0
                },
                {
                    "sent": "There's no fun to be had it out, it's just about statistical proofs.",
                    "label": 0
                },
                {
                    "sent": "I think we can go beyond that now.",
                    "label": 0
                },
                {
                    "sent": "We can have a lot of pleasure, but we can't.",
                    "label": 0
                },
                {
                    "sent": "We don't necessarily always get the reproduction element there when we have the pleasure.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's my sort of background to machine learning.",
                    "label": 0
                },
                {
                    "sent": "I think that was the that was all inspired by the sort of title of the talk, which I guess I was given, which is what is machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have no idea about my timing, whether I've got too much material too little so.",
                    "label": 0
                },
                {
                    "sent": "I'll either end early or stop in the middle, but what I want to talk about now is some specific examples in machine learning, but going through from the sort of history side so supervised learning almost seems to be like the initial in 1997.",
                    "label": 0
                },
                {
                    "sent": "That was the main say that was the big open question is still in machine learning, in particular classify.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station, I guess because statistics focused less on classification and we were interested in sort of high dimensional datasets in particular examples.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where you've got some set of inputs X and targets Y.",
                    "label": 0
                },
                {
                    "sent": "And you're interested in whether inputs belong to a certain class.",
                    "label": 0
                },
                {
                    "sent": "So you've got some class label.",
                    "label": 1
                },
                {
                    "sent": "Why I an it's either a yes or or no.",
                    "label": 0
                },
                {
                    "sent": "We can think of these inputs as features, and this was, I think, in 97.",
                    "label": 0
                },
                {
                    "sent": "This was still a really big sort of challenge and.",
                    "label": 0
                },
                {
                    "sent": "Well, this is one of the reasons why so classifying handwritten digits from binary images.",
                    "label": 0
                },
                {
                    "sent": "This was.",
                    "label": 0
                },
                {
                    "sent": "This is still we still do this all the time, even though I think it's broadly a solved problem.",
                    "label": 0
                },
                {
                    "sent": "But we use it.",
                    "label": 0
                },
                {
                    "sent": "We like to use it as an example.",
                    "label": 0
                },
                {
                    "sent": "So AT&T had worked extensively on using neural networks to classify binary images of digits to help classify zip codes automatically.",
                    "label": 0
                },
                {
                    "sent": "So you could have automatic Postal sorting systems and Bell Labs were very involved in the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "People like Yammer, kunan, Lynette.",
                    "label": 0
                },
                {
                    "sent": "Had these very performance systems using convolutional neural networks and stochastic gradient descent methods.",
                    "label": 0
                },
                {
                    "sent": "When I came in 90, Seven was about the time where Bernard had visited Bell Labs and worked very hard on demonstrating how well the support vector machine worked on these problems and how you could apply it to these very large systems.",
                    "label": 0
                },
                {
                    "sent": "I think that's a key moment because, OK, we then had to tolerate about five years of thousands of papers about kernel methods as results, but you know, I think the end conclusion from that is in some sense this problem is solved now that.",
                    "label": 0
                },
                {
                    "sent": "You know, and you know it, pains me to say it.",
                    "label": 0
                },
                {
                    "sent": "'cause I'm a sort of Bayesian guy, but the support vector machine is excellent algorithmics solution for doing standard classification.",
                    "label": 0
                },
                {
                    "sent": "And if you look into lots of application errors you see that, see that still.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And some of those application areas we're not seeing.",
                    "label": 0
                },
                {
                    "sent": "If this doesn't use SVM's, I think this is using Viola Jones type methods, but detecting faces and images so you know it's kind of.",
                    "label": 0
                },
                {
                    "sent": "I remember seeing Viola Jones is paper at NIPS where they had a video camera and people moving in front of it and the video camera was real time putting boxes around peoples heads and identifying where their faces were.",
                    "label": 0
                },
                {
                    "sent": "That was a staggering moment.",
                    "label": 0
                },
                {
                    "sent": "I don't.",
                    "label": 0
                },
                {
                    "sent": "I'm not so staggered when my digital camera does it today, probably using similar algorithms.",
                    "label": 0
                },
                {
                    "sent": "So another success who detected.",
                    "label": 0
                },
                {
                    "sent": "Who are detected Facebook belongs to?",
                    "label": 1
                },
                {
                    "sent": "So I've spent ages playing with Picasa, 'cause actually categorizes who each faces, so these things are very much out there in application now, but they were sort of things people were interested in.",
                    "label": 0
                },
                {
                    "sent": "When I started getting in machine learning, so then the classifying types of cancer given gene expression, data categorization of different document types.",
                    "label": 1
                },
                {
                    "sent": "So for example different.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Types of news article on the Internet.",
                    "label": 0
                },
                {
                    "sent": "So the perception I mentioned earlier an it's a fun algorithm because I like, well, I don't really know what people teach in cognitive science today, but I was thinking that you can sort of think about the perception without even worrying about the math.",
                    "label": 0
                },
                {
                    "sent": "So I decided to sort of sort of do that and.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is actually, I think it's a remarkably effective and fast classifier even today if you use the kernel version of it.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Perceptron algorithm the idea is.",
                    "label": 0
                },
                {
                    "sent": "So you take these features and you multiply them by some weights and you sum them all up.",
                    "label": 0
                },
                {
                    "sent": "And then there's two ways of saying this.",
                    "label": 0
                },
                {
                    "sent": "You can either add a buyer so you can say, well, is this some greater than a bias, whichever way around, but I've added the bias here and then said, well is the answer greater than zero?",
                    "label": 0
                },
                {
                    "sent": "So if the answer is greater than zero, so I'm then writing that as an inner product here.",
                    "label": 0
                },
                {
                    "sent": "Then we assume it's Class 1.",
                    "label": 0
                },
                {
                    "sent": "Otherwise if the answer is less or equal to 0, then we assume it's class minus one.",
                    "label": 0
                },
                {
                    "sent": "So the question is obvious.",
                    "label": 0
                },
                {
                    "sent": "How do you find these weights?",
                    "label": 0
                },
                {
                    "sent": "So you've got this setup and you've got a linear algorithm where you're multiplying doing the inner product to find the answer, and then you're thresholding it too.",
                    "label": 0
                },
                {
                    "sent": "Give an answer as to what the class.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data point is, so here's an algorithm I'm not sure about initialization for perceptrons.",
                    "label": 0
                },
                {
                    "sent": "How people do that, but I just came up with an initialization of my own.",
                    "label": 0
                },
                {
                    "sent": "So here's an algorithm for finding the weights.",
                    "label": 0
                },
                {
                    "sent": "So select a random data point so you've got some data set of points.",
                    "label": 1
                },
                {
                    "sent": "You just choose one data point at random, and then you ensure that point is correctly classified by setting these weights to whatever the label is times X whatever the input was.",
                    "label": 1
                },
                {
                    "sent": "OK, so why does that ensure it's classified?",
                    "label": 0
                },
                {
                    "sent": "Because that ensures it's correctly classified because basically.",
                    "label": 0
                },
                {
                    "sent": "This thing is the sign of W transpose X, which if we substitute our value for W in as YXI then that just gives us the sign of why I times X transpose XI.",
                    "label": 0
                },
                {
                    "sent": "Now that is always going to be positive X transpose XI.",
                    "label": 0
                },
                {
                    "sent": "So basically this is just the sign of why I so it's just the label, so that's a way of ensuring so I'm trying to invent an algorithm and the way I'm inventing the algorithm is I'm saying, well, I didn't invent this, but I'm trying to go through a process of inventing as if I'm inventing it.",
                    "label": 1
                },
                {
                    "sent": "And the initialization, I'm ensuring the initialization sets takes a random data point in classifiers that data point correctly.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to iterate 'cause there's still going to be other points that aren't classified correctly, and what I'm going to do to iterate is.",
                    "label": 0
                },
                {
                    "sent": "Add a misclassified point, forget the increment KR, remove that bit, but forgot to remove that section so taken you misclassified point right.",
                    "label": 0
                },
                {
                    "sent": "So now we've got some other match misclassified point, and then what we do is we add.",
                    "label": 0
                },
                {
                    "sent": "So this thing we set it to.",
                    "label": 0
                },
                {
                    "sent": "Here we add some portion of this to our existing wait.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we basically take the existing weight and then this is the portion we call this a learning rate, and then some proportion of this why I XI we add it now if.",
                    "label": 1
                },
                {
                    "sent": "The point in doing this is if this this argument here still holds.",
                    "label": 0
                },
                {
                    "sent": "So if this declining rate is large enough, what will happen is we'll be back to this situation.",
                    "label": 0
                },
                {
                    "sent": "This term will dominate if there's learning rate is large enough yet, so there's obviously if we make a really large learning rate, will classify that knew datapoint correctly.",
                    "label": 0
                },
                {
                    "sent": "Now, if we don't want to just classify the new data point correctly and ignore the old one, so we find some balance where we reduce this learning rate to certain levels.",
                    "label": 0
                },
                {
                    "sent": "So we've got some combination of the data points, yeah?",
                    "label": 0
                },
                {
                    "sent": "And by doing that this, hopefully this new data point might be correctly classified or the decision boundary will move towards that and then will repeat this until there's no more.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classified points I've got a little demo of that.",
                    "label": 0
                },
                {
                    "sent": "So if I can see it correctly.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Iteration one, we've got a simple data set.",
                    "label": 0
                },
                {
                    "sent": "And what we're going to do is we select a data point for our initialization.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then what we do is.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We, for the first iteration, so we assume the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are uninitialized for the first iterations.",
                    "label": 0
                },
                {
                    "sent": "We set the wet.",
                    "label": 0
                },
                {
                    "sent": "They we set the weight vector to that data point multiplied by Y.",
                    "label": 1
                },
                {
                    "sent": "Now this is a positive.",
                    "label": 0
                },
                {
                    "sent": "This is the positive class.",
                    "label": 0
                },
                {
                    "sent": "This is the NGE.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In class, So what that means is that actually we set that weight vector to exactly the data point and this is a common way of showing decision boundaries.",
                    "label": 1
                },
                {
                    "sent": "You show the line of decision and then the weight vector is always at a normal direction to that line.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's pointing at the data point we selected so that data point will now be correctly classified.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but as guaranteed by the initialization, the other thing is of course it is also correctly classified a bunch of other data points because they are in a similar Asian, but there's some other things incorrectly classified, so all these are now being said to be positive and all these are being said to be negative.",
                    "label": 0
                },
                {
                    "sent": "In fact, only these data points.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we now find.",
                    "label": 0
                },
                {
                    "sent": "And you incorrectly class.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find data point.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've got our car.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Weights.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it's incorrect classification.",
                    "label": 0
                },
                {
                    "sent": "We adjust the weight vector.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the new data points, so we add that proportion.",
                    "label": 0
                },
                {
                    "sent": "Of that new data point.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now because if you look at where that vector is from the origin.",
                    "label": 0
                },
                {
                    "sent": "So I'm purposely chose the decision boundary to go through the origin so that this works.",
                    "label": 0
                },
                {
                    "sent": "You can see this vector.",
                    "label": 0
                },
                {
                    "sent": "This data point here basically is a vector pointing in this direction from the origin.",
                    "label": 0
                },
                {
                    "sent": "So when we add that that new data point, we're going to add some component of that vector to this point here and so we'll see a new decision.",
                    "label": 1
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with the points in this direction, yeah.",
                    "label": 0
                },
                {
                    "sent": "So actually flips around and now there was a partial component of that original vector being added here and we now.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pointing in this direction.",
                    "label": 0
                },
                {
                    "sent": "OK, so we selected you incorrectly classified data points, so I think there's a green one.",
                    "label": 1
                },
                {
                    "sent": "It should be.",
                    "label": 0
                },
                {
                    "sent": "I can't see it from this angle.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so one of the negative data points is is now the incorrectly classified data points on the positive side of the decision boundary.",
                    "label": 0
                },
                {
                    "sent": "So we do the same thing again, but this time we're going to be subtracting.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The sign of.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data point.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is nge?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jeff so this sign of this 58 datapoint is negative.",
                    "label": 0
                },
                {
                    "sent": "So actually sub.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Acting that vector component off but only a little bit of it.",
                    "label": 0
                },
                {
                    "sent": "And now all the data is correctly classified, so we're done.",
                    "label": 0
                },
                {
                    "sent": "Now, that's actually a remarkably fast classification algorithm for data sets of this type, and.",
                    "label": 0
                },
                {
                    "sent": "It is true that the perception algorithm does Kent converge very quickly if the data is fully separated.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk about what happens if the data isn't separated, but basically there's proofs about if you set up your learning rate.",
                    "label": 0
                },
                {
                    "sent": "If you reduce your learning rate at a certain what value you will converge towards something in the limit of large data, which is the optimal decision boundary.",
                    "label": 0
                },
                {
                    "sent": "see I think the really nice thing about this algorithm is that I mean I think Rosenblatt's book is 1963, but he was using it in the 50s and he was had a course on.",
                    "label": 0
                },
                {
                    "sent": "How the brain works where he used to sit on it.",
                    "label": 0
                },
                {
                    "sent": "Why was?",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Good question.",
                    "label": 0
                },
                {
                    "sent": "No, not what I'm not really equipped to ask answer.",
                    "label": 0
                },
                {
                    "sent": "Actually I had this diagram in, so it's a threshold like that and one of the things in machine learning that well, one of the things in the next community that we knew is that if you could draw your algorithm with a circle and a bunch of interconnecting lines, that meant it was like the brain.",
                    "label": 0
                },
                {
                    "sent": "So the idea was that you had your input X1X 2X3.",
                    "label": 0
                },
                {
                    "sent": "W1W2 W 3 and then you were this was input from another neuron or a sensor.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's obviously this is.",
                    "label": 0
                },
                {
                    "sent": "I mean we did multilayer perceptrons as well and they were quite effective algorithms, but this in this case you would have to think of it as some sort of visual sensor.",
                    "label": 0
                },
                {
                    "sent": "So this is some input from the retina and then you whatever the size of this input, the model of the neuron is that you're summing up these inputs and then you're firing.",
                    "label": 0
                },
                {
                    "sent": "When that sum reaches a certain threshold and you, I think you would write this threshold in here be Now this was not Rosenblatt's model of a neuron, it was McCulloch and Pitts, but it's McCulloch and Pitts in 1943, so it's quite an old model so you know.",
                    "label": 0
                },
                {
                    "sent": "I actually was quite excited by this type of model and the major innovation for the multilayer perceptrons was instead of this being a threshold, we turned this into a smooth function, which meant you could do differentiation and you can make multiple layered versions of this, so you would have another input layer here.",
                    "label": 0
                },
                {
                    "sent": "And then basically you put the whole thing together so you got some input and you would feed forward through and make your classification and very much I was inspired to come into.",
                    "label": 0
                },
                {
                    "sent": "Machine learning.",
                    "label": 0
                },
                {
                    "sent": "Because of these models, I think a big disappointment for me was I actually worked out so there was a problem with this multilayer perceptron idea.",
                    "label": 0
                },
                {
                    "sent": "Because if you got multi layered version so I should turn on.",
                    "label": 0
                },
                {
                    "sent": "This one I'm overweight, so if you do multi layered versions of maybe you can hear me.",
                    "label": 0
                },
                {
                    "sent": "OK good if you do multi layered versions of this.",
                    "label": 0
                },
                {
                    "sent": "If you've got threshold units there was this problem of how you work out, what the responsibility for the error here is because you your objective function was discontinuous so you couldn't compute gradients and I think it's published in AI stats in 1999.",
                    "label": 0
                },
                {
                    "sent": "I worked out an algorithm for doing that and I was very excited 'cause it.",
                    "label": 0
                },
                {
                    "sent": "It was written as a big open problem in machine learning.",
                    "label": 0
                },
                {
                    "sent": "How you do that?",
                    "label": 0
                },
                {
                    "sent": "Multi layered networks of these linear threshold units.",
                    "label": 0
                },
                {
                    "sent": "When I published it, no one cared because it wasn't an interesting problem because we moved beyond that that model in two ways.",
                    "label": 0
                },
                {
                    "sent": "One no one thought of it as a realistic model of the brain.",
                    "label": 0
                },
                {
                    "sent": "And two no one thought of it is a practically useful way of doing classification.",
                    "label": 0
                },
                {
                    "sent": "So in some sense we can see that now, but I think if we go back to say, the early 50s and we look at Rosenblatt's work with early computers, what you see is he's got.",
                    "label": 0
                },
                {
                    "sent": "An extremely fast way of doing classification.",
                    "label": 0
                },
                {
                    "sent": "That was published was based on a model of a neuron that was published.",
                    "label": 0
                },
                {
                    "sent": "You know less than a decade ago as the way the brain works.",
                    "label": 0
                },
                {
                    "sent": "I think that would be at the time would be considered a very exciting thing.",
                    "label": 0
                },
                {
                    "sent": "So now we can look back on it and say, yeah, not really how the brain works, but it's got some interesting aspects.",
                    "label": 0
                },
                {
                    "sent": "And the reason I wanted to talk about it here is because it's this interesting aspect of learning of that you've got something that you need to adapt.",
                    "label": 0
                },
                {
                    "sent": "So in that case.",
                    "label": 0
                },
                {
                    "sent": "These weights here and what you're adapting those weights according to is what you observe to be the class.",
                    "label": 0
                },
                {
                    "sent": "What you talk about your supervision signal is, and what your input signal is, right?",
                    "label": 0
                },
                {
                    "sent": "So and then there were, I think, examples of similar models.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're based on very simple learning rules, Hebbian learning type rules which you know again, I don't know much about, but I understand one point with you know it was taken very seriously in cognitive science, so you reinforce connections where you see things on together at the same time and those sort of models include things like the Hopfield network and Boltzmann machines, which are making a big comeback at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I don't want to talk much more about that learning rule or what the objective function is, but what I want to do is to talk about something I spent more time working on, which is regression.",
                    "label": 0
                },
                {
                    "sent": "So it's less connected to the brain, but I'm going to follow a similar path of trying to show you a regression.",
                    "label": 0
                },
                {
                    "sent": "We know how to do regression.",
                    "label": 0
                },
                {
                    "sent": "Regression was invented by sort of physicists around the turn of the 19th century for fitting physical models of the universe to observations of where the planets work.",
                    "label": 0
                },
                {
                    "sent": "It was reinvented by Galton, who called it regression statistician in sort of the turn of the 20th century.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's basically the same.",
                    "label": 0
                },
                {
                    "sent": "A different type of supervised learning, but the the target now has a real value given some set of inputs.",
                    "label": 0
                },
                {
                    "sent": "So one of my favorite datasets on this is predicting the quality of meat given spectral measurements.",
                    "label": 0
                },
                {
                    "sent": "This is tekkit or data, so you've got some sort of set of spectral measurements and you want to predict they measure to meet and you want to predict what the quality of that meat was radiocarbon dating.",
                    "label": 0
                },
                {
                    "sent": "So the C-14 calibration curve, so you predict age of an object given its radiocarbon age, because the C-14 quantity in the.",
                    "label": 0
                },
                {
                    "sent": "Atmosphere hasn't been decaying, changing constantly as the radiocarbon age suggests.",
                    "label": 0
                },
                {
                    "sent": "Sort of machine learning example.",
                    "label": 0
                },
                {
                    "sent": "I think this is true.",
                    "label": 0
                },
                {
                    "sent": "This is something called TD Gammon, which is a really early reinforcement learning approach to playing backgammon, which was big famous success in the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "But I think the competing approach to TD Gammon when it was released, or maybe even the best performing backgammon player currently is you basically get.",
                    "label": 0
                },
                {
                    "sent": "Expert backgammon players to score the quality of a bunch of different moves, so they give us some sort of score, and then you train the computer to learn this mapping that the backgammon player is has provided, and then you get the computer to recreate that.",
                    "label": 0
                },
                {
                    "sent": "You could also consider that for something like go so these are complex games, you can't explore the whole state space of these games, you can't do in the way you do chest, so this is a way of doing learning.",
                    "label": 0
                },
                {
                    "sent": "I should say that I mean they're good examples of what was.",
                    "label": 0
                },
                {
                    "sent": "I would say the main approach to artificial intelligence applications from a machine learning perspective up until the turn of the 21st century, which was very much that if someone comes to you with a problem.",
                    "label": 0
                },
                {
                    "sent": "Something that needs to be solved.",
                    "label": 0
                },
                {
                    "sent": "You have to work out how you can convert that problem into a classification problem or a regression problem, and then you fit that as a component and you take your favorite regression or classification approach and then you use that to solve their problem.",
                    "label": 0
                },
                {
                    "sent": "Now think that that's.",
                    "label": 0
                },
                {
                    "sent": "It's it's an engineering approach that is perfectly valid and people will continue to use it today, and you know the main and they'll continue to use things like support vector machines instead of neural networks if they're up to speed, but it can't be the right way of solving all these artificial intelligence problems to just workout a way of making it a classification of regression.",
                    "label": 0
                },
                {
                    "sent": "There has to be something deeper, and I think that's where reinforcement learning comes in, so these are examples of where that's being done.",
                    "label": 0
                },
                {
                    "sent": "You basically workout how you can convert, go playing into a regression problem by making the computer recreate expert opinion.",
                    "label": 0
                },
                {
                    "sent": "On these moves.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so predicting now real value of Y given X and I know we're going to look at really simple value of regression, so our prediction will be F of X is just MX plus C. So linear, sorry, one dimensional input, 1 dimensional output and will also define an error.",
                    "label": 0
                },
                {
                    "sent": "So the error is Delta Yi.",
                    "label": 0
                },
                {
                    "sent": "Is the difference between our prediction?",
                    "label": 0
                },
                {
                    "sent": "And the actually observed value of the regression.",
                    "label": 0
                },
                {
                    "sent": "So we can look at.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things like this and we can come up with potentially an algorithm I want to do it in the same way we did the perceptron.",
                    "label": 0
                },
                {
                    "sent": "We can add a portion of this error to the bias.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to say is that you initialize your bias some way and then what you do is you take one of these learning rates and then you add some portion of your error to whatever your biases, right?",
                    "label": 0
                },
                {
                    "sent": "So here's your error defined now by substituting F of X into here.",
                    "label": 0
                },
                {
                    "sent": "So what's going to happen if we do this for the bias so there's two components to the regression, there's a slope and a by an intercept or bias, so it's where this goes through the Y axis.",
                    "label": 0
                },
                {
                    "sent": "If you set X to 0, then this is just see.",
                    "label": 0
                },
                {
                    "sent": "So we want to set the Intercept.",
                    "label": 0
                },
                {
                    "sent": "So that's basically moving the line up and down, so for positive error, see and therefore F of X become larger under this learning rule.",
                    "label": 0
                },
                {
                    "sent": "So if we if we got a positive error here, then basically this learning rules says make see larger.",
                    "label": 0
                },
                {
                    "sent": "And corresponding that makes F of X larger.",
                    "label": 0
                },
                {
                    "sent": "But this makes the error smaller.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that changes the error in the right direction, so for negative error see it becomes smaller.",
                    "label": 0
                },
                {
                    "sent": "An error magnitude also becomes smaller, so the magnitude of this error will reduce if we change.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Change it in this way.",
                    "label": 0
                },
                {
                    "sent": "We can do the same.",
                    "label": 0
                },
                {
                    "sent": "We can try and come up with a learning rule for the slope and we can here we have to consider 4 cases because X can have a negative input and you can go through all of these cases and show that the error will become smaller in each of these cases.",
                    "label": 1
                },
                {
                    "sent": "If we apply this learning rule, I think that this is very for me.",
                    "label": 0
                },
                {
                    "sent": "This is certainly an.",
                    "label": 0
                },
                {
                    "sent": "It was an attractive way of thinking about learning rules.",
                    "label": 0
                },
                {
                    "sent": "When I when I first started in machine learning.",
                    "label": 0
                },
                {
                    "sent": "You can see that something sensible is happening and if you have interpretations for these as connections in the brain, which there is no term interpretation here, you can see how those connections are changing, but you can see even for this simple case it's becoming quite complicated to write down the justification of the learning rule.",
                    "label": 0
                },
                {
                    "sent": "I've come up with.",
                    "label": 0
                },
                {
                    "sent": "I don't think anyone's invented this learning rule in this way of trying to justify it, but you know you can try and justify it.",
                    "label": 0
                },
                {
                    "sent": "You can look at learning.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doesn't say what they're doing.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we apply that we can.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Present data points compute the current error and change.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estimate of airmen seacore.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into those presenting.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One data point at.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An interesting way of work.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we were very into this in machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think maybe we should get more into it.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we go through.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In each data point.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We changed the error slow.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Early.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the regression.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comes more accurate.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why will we into this?",
                    "label": 0
                },
                {
                    "sent": "Because it's sort of adaptive learning scenario, right?",
                    "label": 0
                },
                {
                    "sent": "We called it online learning in those days, but I think now you call it stochastic gradient descent because if you say online people think you're on the Internet.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What we?",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting doings present.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each of these dates.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Points one at a time.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm an N.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only converging to.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Awards",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A solution now it takes more iterations.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This example and the perceptron, so we're already iteration 10.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I'm jumping through this.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Iteration 20.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "30",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "40",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "50",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "60",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She OK 70 and I've got some convergence criteria and it's converged around 70, so that's a way of estimating that linear regression.",
                    "label": 0
                },
                {
                    "sent": "Now there's much much quicker ways of doing that, but I wanted to show you that because it's similar to this perception idea that presenting a data point and then you're.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Testing your gradient and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "Now I wanted to use this opportunity to enter into and add something in.",
                    "label": 0
                },
                {
                    "sent": "It's a simple concept.",
                    "label": 0
                },
                {
                    "sent": "It certainly seems simple.",
                    "label": 0
                },
                {
                    "sent": "When I wrote it down, but it took us a while to see things.",
                    "label": 0
                },
                {
                    "sent": "Perhaps in this way in learning, statisticians have used this for a long time, so there's a problem with those of regression things.",
                    "label": 0
                },
                {
                    "sent": "There's a problem with the learning rule as well, but I'll come back to that sort of more in the next session.",
                    "label": 0
                },
                {
                    "sent": "But there's a problem with these linear regressions.",
                    "label": 0
                },
                {
                    "sent": "This X may not be linear related to why, so I think that this is true, and maybe anyone who knows.",
                    "label": 0
                },
                {
                    "sent": "Better than I can correct me if I'm wrong, but you know, I think in the brain you don't really take the pixels of what you see coming in and multiply them by an inner product and threshold them before you pass them to other parts of the brain.",
                    "label": 0
                },
                {
                    "sent": "What you actually do is use to process them in some way and.",
                    "label": 0
                },
                {
                    "sent": "One way of making things so this is a linear relationship.",
                    "label": 0
                },
                {
                    "sent": "We've been looking at, but what we're really interested very often is nonlinear functions of X.",
                    "label": 0
                },
                {
                    "sent": "So one way of making a nonlinear function for model is by introducing basis functions.",
                    "label": 0
                },
                {
                    "sent": "So what is the basis function?",
                    "label": 0
                },
                {
                    "sent": "So it's a way of taking those inputs and then representing them by a nonlinear function in the input space.",
                    "label": 0
                },
                {
                    "sent": "So you just have a bunch of these, and then you sum up linear combinations of those.",
                    "label": 0
                },
                {
                    "sent": "Now an example of that might be.",
                    "label": 0
                },
                {
                    "sent": "I understand there's some evidence that when you process in the visual cortex, very low level processing the Gabor basis is used, which is a particular way of.",
                    "label": 0
                },
                {
                    "sent": "So if you're looking at an image you don't do high level processing.",
                    "label": 0
                },
                {
                    "sent": "As far as I understand, on the pixels you basically extract features from the image and maybe those features are edge like features or whatever orientation features and then you do processing on those.",
                    "label": 0
                },
                {
                    "sent": "The extraction of those features could be seen as basis functions.",
                    "label": 0
                },
                {
                    "sent": "We can also we think about basis functions as very general classes of functions.",
                    "label": 0
                },
                {
                    "sent": "But in signal processing people would be very interested in things like the Fourier basis.",
                    "label": 0
                },
                {
                    "sent": "So transforming your data into a frequency space, but that has a basis function perspective that you can.",
                    "label": 0
                },
                {
                    "sent": "Where your basis functions would be sines and cosines, and so, and I think in the visual cortex, you might say Gabor.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wavelets of these basis functions, but let's look at an example and one that is a.",
                    "label": 0
                },
                {
                    "sent": "Often favored for regression, although I'm not sure it's a particularly good way of doing regression myself, but would be to use a polynomial basis.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what you do is say OK. One way of making this nonlinear is to have.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The sum of a polynomial basis where we basically got three basis function.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One is a constant one.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is linearly increasing and one is a quadratic OK?",
                    "label": 0
                },
                {
                    "sent": "So we can add up these three things by waiting them to come up with functions that will look like a somova offset, linear, and.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a quadratic, so that's our F of X.",
                    "label": 0
                },
                {
                    "sent": "And here I've set W 1 to be .87.",
                    "label": 0
                },
                {
                    "sent": "So there's this thing is being weighted by .87 W 2.",
                    "label": 0
                },
                {
                    "sent": "The linear term is being weighted by minus .38, and W 3 is being weighted by minus two.",
                    "label": 0
                },
                {
                    "sent": "So you basically see that quadratic form is inverted because it's heavily weighted in a negative direction.",
                    "label": 0
                },
                {
                    "sent": "There's some decreasing linear trend coming from the negative weight of that.",
                    "label": 0
                },
                {
                    "sent": "And there's some positive offset pulling the thing up a bit, so that's the sort of function and nonlinear fun.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that can come from these basic constructions, and you can do different functions.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you do different weights.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's a basis I prefer, and I think one that we're quite interested in machine learning.",
                    "label": 0
                },
                {
                    "sent": "We use it quite a lot.",
                    "label": 0
                },
                {
                    "sent": "And I don't know how much introduction to kernel methods Bernard is going to do, but you can see kernel methods as examples of these types of bases too, but just with infinite basis functions.",
                    "label": 0
                },
                {
                    "sent": "So it's a local basis.",
                    "label": 0
                },
                {
                    "sent": "I like local basis because they have this local effect, so when they are weighted up, you know their effect is.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only in this region, the problem with these bases is there global and basically if you if you need to pull this thing down to affect the point here your affect over here is massive right?",
                    "label": 0
                },
                {
                    "sent": "So for example if you got a slight nonlinearity then you can flip the thing one way or the other by pulling points up and down in this region.",
                    "label": 0
                },
                {
                    "sent": "But you get an enormous effect over there.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and in fact polynomials as you go outside this region minus one to one polynomials become very badly behaved because you get squares of.",
                    "label": 0
                },
                {
                    "sent": "Too cute and if you add in extra terms, cubes and so and so forth, you get really wild behaviors so.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have to be very careful with polynomial basis, but this is an alternative basis and it's often called the radial basis or the Gaussian basis, and you basically just have a bunch of functions like this that should be factor of half there.",
                    "label": 0
                },
                {
                    "sent": "I don't know why.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are you up there?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, that's alright 'cause it's 'cause of the length scale, so I'm waiting with the length scale in here.",
                    "label": 0
                },
                {
                    "sent": "So I've got these lengthscale which controls the width of these basis functions and then what we're seeing here is 1 basis.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There and then we've got another basis, which is shifted.",
                    "label": 0
                },
                {
                    "sent": "So each of these basis is located in a different place, so this one is located at.",
                    "label": 0
                },
                {
                    "sent": "Minus one thing and.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It was located at 0 and then this one is located at plus one.",
                    "label": 0
                },
                {
                    "sent": "So you've got these things.",
                    "label": 0
                },
                {
                    "sent": "You can sort of move around.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can compute nonlinear functions by linear weighting of these things.",
                    "label": 0
                },
                {
                    "sent": "Now this is very much.",
                    "label": 0
                },
                {
                    "sent": "Like what we talked about before with this multilayer perceptron, and indeed that's what people were doing is.",
                    "label": 0
                },
                {
                    "sent": "They were putting in additional basis and optimizing over the parameters of these bases here so that we can think of a weighted sum of these basis.",
                    "label": 0
                },
                {
                    "sent": "You can think of the basis being the input here, but in this case the bases are these sort of local inputs.",
                    "label": 0
                },
                {
                    "sent": "If they were global basis, you might sort of claim that there was some cognitive interpretation so you can wait.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These things in different ways and come up with different functions and then the nice thing is you can go through the algorithm we had before without any sort of replacement in terms.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we just replace.",
                    "label": 0
                },
                {
                    "sent": "The key aspect.",
                    "label": 0
                },
                {
                    "sent": "OK, so the whole of kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Is based on the observation.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some sense that you can just view Fi as a new set of inputs so you can replace X with FI and then you can apply any algorithm replacing X with FI.",
                    "label": 0
                },
                {
                    "sent": "So this is a fixed basis, but kernel methods is about infinite basis where you can do that.",
                    "label": 0
                },
                {
                    "sent": "So basically we can.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My algorithm as before, and I think it even it looks nicer in this case 'cause what happens is you can see that as you.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then to data point you adjust.",
                    "label": 0
                },
                {
                    "sent": "According to the basis.",
                    "label": 0
                },
                {
                    "sent": "Sponsor that data point to the basis so this data point computing across all those different bases it's responding more to the basis around minus one.",
                    "label": 0
                },
                {
                    "sent": "Then it's the basis at zero and the base is at one so that.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're getting from 5.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four and it.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We see is as we are.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The weights that.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We sort of pull up.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One down in the different.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Directions to you and up.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bring your function around.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, this is not all.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good way to do regret.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you can sort of see the idea.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These learning rules that as you observe.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One point.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At a time.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After another.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yoostar",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pulling in different.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actions now.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This law",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding rule is cool.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Old.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stochastic gradient.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Percent.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With these datasets, it's absolutely.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, pointless.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using it because you can fit these datasets using.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A quadratic for, well, one equation in one go, but as your basis set sizes increase or as your data set gets very large, then these stochastic gradient descent algorithms become quite important in machine learning, and they're just making a really big comeback because.",
                    "label": 0
                },
                {
                    "sent": "What we did do is we went down the road of optimizing these problems and I'll talk about that in a second.",
                    "label": 0
                },
                {
                    "sent": "What I mean by that, but we found for large datasets that this these sort of algorithms stochastic gradient descent algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work very well.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "All I talked about in terms of justifying what the learning rule there I think is.",
                    "label": 0
                },
                {
                    "sent": "Not how you should be doing machine learning.",
                    "label": 0
                },
                {
                    "sent": "You should not be writing down learning rules and saying this is how we do learning what you need to do is think in terms of error functions and I think that the cost function and what you're minimizing is what you're often really interested in.",
                    "label": 0
                },
                {
                    "sent": "But the big split in machine learning.",
                    "label": 0
                },
                {
                    "sent": "That's, for example, differentiates the work from Bernard from the work of me from work of media, from work from my work.",
                    "label": 0
                },
                {
                    "sent": "Is is how you interpret this cost function.",
                    "label": 0
                },
                {
                    "sent": "Whether you interpret this cost function probabilistically, which is what I'll talk about in my next session, or whether you interpret this function as an actual cost that you're paying, and then the big split is whether you're interested in clever ways of optimizing the cost function you've written down.",
                    "label": 0
                },
                {
                    "sent": "Or why they're interested in trying to deal with the nasty probabilistic model you've written down, and that's what most of machine learning has been about.",
                    "label": 0
                },
                {
                    "sent": "I would say, since say, 1997.",
                    "label": 0
                },
                {
                    "sent": "So here's the cost function that would work for regression, so it's called this number squares.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I'm sure you've seen it before.",
                    "label": 0
                },
                {
                    "sent": "So defining.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The basic function is a vector.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can actually compute.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The gradient of.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This so that just gives us the ability to write that.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a product we can compute the gradient of this error function with respect to these.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Weights.",
                    "label": 0
                },
                {
                    "sent": "So learning is basically the minimization of the cost function.",
                    "label": 0
                },
                {
                    "sent": "So what we were seeing before is I'm trying to claim is is minimizing these cost functions, and at the minimum the gradient is 0.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we compute the gradient of this cost function where we've got some error expressed in this form, just as we had before, and it has that form.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, what's interesting is we can then do CPS descent, so this is a standard early optimization approach, and the basic idea is you've got some surface, some error surface prescribed by this cost function, and you want to send it by going in the steepest direction at all times.",
                    "label": 0
                },
                {
                    "sent": "So you compute the gradient of this error function and then you change W at every step by moving in the steepest downhill direction.",
                    "label": 0
                },
                {
                    "sent": "So if you're at W, you look at the steepest direction and then you change your position.",
                    "label": 0
                },
                {
                    "sent": "According to what that gradient is, you descend the gradient.",
                    "label": 0
                },
                {
                    "sent": "So if you can think of a Valley, if you keep doing that, you will eventually reach a minimum.",
                    "label": 0
                },
                {
                    "sent": "It could be a low.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Call minima.",
                    "label": 0
                },
                {
                    "sent": "And it could be quite slow.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Note converge as well so.",
                    "label": 0
                },
                {
                    "sent": "On that regression problem earlier, this is what that error surface looks like.",
                    "label": 0
                },
                {
                    "sent": "So you've got this quadratic error surface because it's a quadratic problem and it's linear.",
                    "label": 0
                },
                {
                    "sent": "Well, it's quadratic in the W, so you see, this is a 2 dimensional sort of surface, but it's a parabola parabola, and I'm showing contours there.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you start with someone.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Socialization?",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do your learn.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing if you just.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing steepest descent.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right you go.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Down.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Valley.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now those.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Castec those.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithms?",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I was showing you before.",
                    "label": 0
                },
                {
                    "sent": "This is the steepest descent algorithm.",
                    "label": 0
                },
                {
                    "sent": "Those algorithms are showing you before if you substitute in the gradient of the objective.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dare the directors agent.",
                    "label": 0
                }
            ]
        },
        "clip_166": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Getting objective you can.",
                    "label": 0
                },
                {
                    "sent": "Then you get this factor of two, which is just some factor of the.",
                    "label": 0
                }
            ]
        },
        "clip_167": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How to find the objective function which you can combine in the learn?",
                    "label": 0
                }
            ]
        },
        "clip_168": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going rate.",
                    "label": 0
                }
            ]
        }
    }
}