{
    "id": "46xr4zwj5xsndub6m3qxssn5ou3l6sjs",
    "title": "Canonicalizing Knowledge Base Literals",
    "info": {
        "author": [
            "Jiaoyan Chen, Department of Computer Science, University of Oxford"
        ],
        "published": "Nov. 27, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_chen_knowledge_base_literals/",
    "segmentation": [
        [
            "I'm going to present our work, not tonight.",
            "They not visuals.",
            "This is a work in operation with another from City University of College and."
        ],
        [
            "What is little assertions, little assertions are those other things that used in literals instead of instead of semantically annotated, semantically typed entities as the object of."
        ],
        [
            "As the object of the property here, then here's an example.",
            "River Temps passes Aray Isler of dogs.",
            "Here's object Islip dogs actually represent an entity, but it is not an formally expressed entity such literal or such entity mentions where weekends semantics or knowledge base 'cause it is not connected to any type, or it is not connected to any properties or or entities.",
            "So actually in oil ontologists we actually.",
            "Actually, the data properties an object properties are disjoint, so this will not happen, but.",
            "A model knowledge bases like DB pedia.",
            "Actually the this this constraint actually is not respected.",
            "So we can say such little assertion in many places such as knowledge base from extract from encyclopedias or other graph transform from tabular data or 1 two RDF graphs online or.",
            "Rough evolve, we can say such literal assertions and during the process of larger capture we can also see some such literals.",
            "The generator problem is to canonicalize."
        ],
        [
            "With our surgeon.",
            "Given a large base and affect our little assertions of a specific property pay, we want to normalize the literal by two steps.",
            "First, we want to identify the type of the literal.",
            "The type here means the set of the.",
            "Classes of the entity is represented by this literal, and then we also want to determine if such an corresponding entity exist in the knowledge base.",
            "I need to mention that we use machine learning, but we do not assume any menu annotation or some external annotation to train the model.",
            "There are some related work.",
            "A piece of related work about semantic annotation of knowledge based entities, such as the classification of entities.",
            "Well, another paper is about."
        ],
        [
            "The semantic annotation of noun phrases outside, not very such as those come from the web tables.",
            "In both cases, the context of the annotation target is different from the literal in this study, while the closest related work maybe is.",
            "If I cannot generate enough proposed in 2016, they proposed Folkestone matching based methods first extractor."
        ],
        [
            "Focus turn from the literal by utilizing grammatical structure analysis and then match these folks.",
            "Turn to the class and then to the entity.",
            "But such matching actually ignores the ignore the context meaning of the word that because it only relies on the laxity in the Meanwhile, this method ignores the literal context, such as the literal associated property and subject.",
            "Let's"
        ],
        [
            "Let me introduce the method.",
            "The method is our pipeline to increase 3 three steps.",
            "First we want to get candidate classes.",
            "Here.",
            "In this step we want to ensure that the candidate class has a high rate of high record.",
            "Then for each class we train our classifier.",
            "While for training the classifier we extract samples from the knowledge base and finally in the first step we.",
            "Make it a prediction and make the typing an."
        ],
        [
            "At the same time, we want to find the entity matching first candidate classes.",
            "Candid class come from two sources.",
            "The first sources those property classes of those property objects and the second class.",
            "The second sources.",
            "Classes of those top K entities matched by the literal here match means we can use.",
            "For example, we can use some natural index to get some similar, lexically similar entities.",
            "Take the PDF for example.",
            "We can directly use local service which uses an index which is based on the.",
            "And the label and anchor text.",
            "But here we need to ensure high risk high record.",
            "So we we match the entity not only by the whole little, but also by its other phrases.",
            "This can help us ensure that the correct matches matches are not missed."
        ],
        [
            "In model training, we actually train one binary classifier for each class.",
            "From the candidate class.",
            "Phone to train the cars we need to get the samples.",
            "Actually 1 sample actually is an assertion whose objects annotated by a binary fund label.",
            "We divide samples into two kinds.",
            "One is particularly samples and another is.",
            "General samples why?",
            "For particular samples we ensure that object comes from the little match the entities.",
            "Why, for example we we actually we do not need to.",
            "We do not have to get the entity from the literal match.",
            "The entity.",
            "It can be an arbitrary entity from the knowledge base.",
            "While"
        ],
        [
            "We also need to do next some playing in a sampling.",
            "We actually extract object from the instance of some sibling class of the Class C. But but of course we should also ensure that the extract the instance is not an is not an instance of the Class C that mean negative.",
            "Actually, we find the particular sample usually have a small size, but they have a close data distribution with regard to the prediction target.",
            "But in contrast, the general sample users usually have a larger larger size, so our solution is preaching the model by the general samples and fine tune the model by particular samples.",
            "This cannot only deal with the sample shortage problem, but also can raise the problem."
        ],
        [
            "Adoption.",
            "At the same time, in real application, we can pretend all the other class file for all the classes in the knowledge base and one you data set from 4 four focalization.",
            "We can actually fine tune the class size of the candidate classes.",
            "This actually save a lot of time in online application.",
            "Then classify we are neural network architecture that is composed of bidirectional recurrent neural networks and an attention layer.",
            "Let's say say more details in this picture."
        ],
        [
            "In the input layer we abstract directly extract labels from the subject property an object and then we concatenate these.",
            "These are the labels into a sequence.",
            "Of course we should fix the size of the the subject label and predict label and object label.",
            "Then we encode each word each word.",
            "Introverted laptop.",
            "And next we learn we attached a recurrent neural networks to learn a new representation of the of the world.",
            "While this representation will consider the curation of surrounding words into consideration.",
            "For each word.",
            "Other than learning, actually takes in two directions.",
            "1 recurrent neural network.",
            "Learn from the feed forward direction while another learn from the backward direction and then the new representations to representation are concatenated for each word and we also Attack Attack an attention layer which learns important ways of different words.",
            "And also they combine the combined the other ways of combining the vectors of the of each word with their important ways to get a new vector here important ways is very useful.",
            "For example here actually.",
            "Arianne ocelot.",
            "Play that, play an important role in determine whether this little.",
            "Belong to a place or an area.",
            "Finally we.",
            "Yes, actually the attention weight can also give some justification or explanation about the prediction why this is predicted as an place or an Arabic 'cause this one.",
            "This world at his word have very high importance.",
            "And finally, we step photoconductive layer.",
            "Analogical logistic regression layer.",
            "They make it as a class file.",
            "Um?",
            "So improve."
        ],
        [
            "Ocean was quite predicted for each class and with previous cloud predicted scores.",
            "We need to make the type decision.",
            "We propose 22 solutions while the independent typing.",
            "This is very simple.",
            "If a class score is exceeds the threshold, this class is selected while hierarchical typing is a bit complicated.",
            "Consider the class hierarchy into consideration in making the decision.",
            "It first calculate a hierarchical score for each class."
        ],
        [
            "That actually is the maximum of the scores of itself and all its descendants, and then it select selects those class whose hierarchy score satisfies two conditions.",
            "First it should exceed the threshold.",
            "Then it should have a large enough order forms over though over any of its disjoint candidate classes.",
            "So let's use this example assumes the threshold is 0.5.",
            "We have a candidate class place zero point.",
            "Eight person which is disjoint with place there the score is 0.75.",
            "Then we actually will exclude a person because person is disjoint with place, but it promises not is not higher than place.",
            "Well if we replace person by park.",
            "Then both place and park will be caped 'cause they are not disjoint so.",
            "Then with the types we finally do entity matching.",
            "Here we adopt A very simple solution.",
            "We just to keep the literal match the entities that instance of at least one of the predicted types.",
            "So briefly, we just use that I predict type to do to act as a constraint."
        ],
        [
            "Final evaluation.",
            "We used to this that's why is real real literal set called are light and another thing separator set.",
            "Other electrolyte is based on the properties and literal provide proposed by our baseline related work and it's light is manually created by us by replacing the object entity objects by their labels.",
            "Here are some statistics we may come back again and.",
            "Evaluation we first analyze the impact of the framework components like how the classifier, whether the class architecture makes effect or whether independent typing and hierarch tapping make effect.",
            "And then we evaluated overall typing result in competition with the baselines.",
            "Finally, we report some entity matching results.",
            "I.",
            "1st."
        ],
        [
            "I will I will escape the impact of the component, but directly jump to the typing results.",
            "We adopted.",
            "Three baselines, generated actually has been introduced before, but we extended this method by relaxed entity matching an entity.",
            "Look up.",
            "Simply get the look up by local.",
            "Get entity by look up and then do voting.",
            "But we not only get one entity, but multiple entities.",
            "We find that our method can outperform those two baselines becausw.",
            "That that is expected because they just consider the literal itself, but we consider the subject property and another another baseline is proxy range estimation.",
            "We actually get the objects of the object of that property, and we get the classes of these objects and we use our voting strategy to get the data.",
            "Get a score for each club each class.",
            "And our method can be higher than this baseline.",
            "This is this.",
            "Actually I think it can be explained because we use DB pedia for experiment.",
            "But indeed actually many relation assertions actually do not respect the constraint of property range.",
            "So so this better line.",
            "The performance is impacted.",
            "We also compared to 222 benchmarks, but the result is better on synthetic little like little because it has less number of types in average and also realize of course is much noisy.",
            "It sometimes sometimes they may even contact two entities or some.",
            "Yes, for example, the sea of dog.",
            "Actually sometimes people in London will say Dog Island Dog died in London than it is become quite ambiguous."
        ],
        [
            "Then entity matching, we simply compare matching by pure luck up and matching by look up and filtering by proper filtering by predictive type, and we find the filtering can not only increase the.",
            "Correct matches the number of correct matching matches, but also the precision.",
            "So here currently we only consider only use vlookup to estimate the candid entities we want to use most of skated approach in the future.",
            "But one thing I should mention that is very important is if no entity is matched, we can create a new entity an annotated with the project type to correct this knowledge base."
        ],
        [
            "Um?",
            "Let me conclude and we propose a framework for canonicalizing little assertions, with both typing an empty matching.",
            "First, we utilize attentive by recurrent neural network for utilizing the little context and then we extract samples automatically from the knowledge base to learn the new network.",
            "We also propose a hierarchical typing solution which actually performs well and you can find the results in the paper.",
            "But after this researcher after this study, we find many problems are challenger.",
            "Many challenges remaining first is how to get related entities with a high Rico, especially when the little is very ambiguous or even wrong.",
            "The example I mentioned is dog islands of Dog Island, Dog Island in London, but actually the former members, Iceland of all dogs.",
            "The second challenge is how to make a more robust correction.",
            "In the knowledge base.",
            "For example, how to deal with an inconsistent collection collection if the matching and matching is causing constant?",
            "Should we just ignore it or we should feed that inconsistent back to the prediction?",
            "And then how to ensure the assertion truth?",
            "Maybe we should use?"
        ],
        [
            "Semantic embedding or graph convolution neural network to check whether the entered metric finally cause the true two triple or round triple.",
            "And I guess this will make the correction of the little more robust.",
            "Yes, thanks for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to present our work, not tonight.",
                    "label": 0
                },
                {
                    "sent": "They not visuals.",
                    "label": 0
                },
                {
                    "sent": "This is a work in operation with another from City University of College and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is little assertions, little assertions are those other things that used in literals instead of instead of semantically annotated, semantically typed entities as the object of.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As the object of the property here, then here's an example.",
                    "label": 1
                },
                {
                    "sent": "River Temps passes Aray Isler of dogs.",
                    "label": 0
                },
                {
                    "sent": "Here's object Islip dogs actually represent an entity, but it is not an formally expressed entity such literal or such entity mentions where weekends semantics or knowledge base 'cause it is not connected to any type, or it is not connected to any properties or or entities.",
                    "label": 0
                },
                {
                    "sent": "So actually in oil ontologists we actually.",
                    "label": 0
                },
                {
                    "sent": "Actually, the data properties an object properties are disjoint, so this will not happen, but.",
                    "label": 0
                },
                {
                    "sent": "A model knowledge bases like DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Actually the this this constraint actually is not respected.",
                    "label": 0
                },
                {
                    "sent": "So we can say such little assertion in many places such as knowledge base from extract from encyclopedias or other graph transform from tabular data or 1 two RDF graphs online or.",
                    "label": 1
                },
                {
                    "sent": "Rough evolve, we can say such literal assertions and during the process of larger capture we can also see some such literals.",
                    "label": 0
                },
                {
                    "sent": "The generator problem is to canonicalize.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With our surgeon.",
                    "label": 0
                },
                {
                    "sent": "Given a large base and affect our little assertions of a specific property pay, we want to normalize the literal by two steps.",
                    "label": 1
                },
                {
                    "sent": "First, we want to identify the type of the literal.",
                    "label": 0
                },
                {
                    "sent": "The type here means the set of the.",
                    "label": 1
                },
                {
                    "sent": "Classes of the entity is represented by this literal, and then we also want to determine if such an corresponding entity exist in the knowledge base.",
                    "label": 1
                },
                {
                    "sent": "I need to mention that we use machine learning, but we do not assume any menu annotation or some external annotation to train the model.",
                    "label": 0
                },
                {
                    "sent": "There are some related work.",
                    "label": 0
                },
                {
                    "sent": "A piece of related work about semantic annotation of knowledge based entities, such as the classification of entities.",
                    "label": 0
                },
                {
                    "sent": "Well, another paper is about.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The semantic annotation of noun phrases outside, not very such as those come from the web tables.",
                    "label": 0
                },
                {
                    "sent": "In both cases, the context of the annotation target is different from the literal in this study, while the closest related work maybe is.",
                    "label": 1
                },
                {
                    "sent": "If I cannot generate enough proposed in 2016, they proposed Folkestone matching based methods first extractor.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Focus turn from the literal by utilizing grammatical structure analysis and then match these folks.",
                    "label": 0
                },
                {
                    "sent": "Turn to the class and then to the entity.",
                    "label": 0
                },
                {
                    "sent": "But such matching actually ignores the ignore the context meaning of the word that because it only relies on the laxity in the Meanwhile, this method ignores the literal context, such as the literal associated property and subject.",
                    "label": 0
                },
                {
                    "sent": "Let's",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me introduce the method.",
                    "label": 0
                },
                {
                    "sent": "The method is our pipeline to increase 3 three steps.",
                    "label": 0
                },
                {
                    "sent": "First we want to get candidate classes.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "In this step we want to ensure that the candidate class has a high rate of high record.",
                    "label": 0
                },
                {
                    "sent": "Then for each class we train our classifier.",
                    "label": 0
                },
                {
                    "sent": "While for training the classifier we extract samples from the knowledge base and finally in the first step we.",
                    "label": 0
                },
                {
                    "sent": "Make it a prediction and make the typing an.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the same time, we want to find the entity matching first candidate classes.",
                    "label": 0
                },
                {
                    "sent": "Candid class come from two sources.",
                    "label": 0
                },
                {
                    "sent": "The first sources those property classes of those property objects and the second class.",
                    "label": 0
                },
                {
                    "sent": "The second sources.",
                    "label": 0
                },
                {
                    "sent": "Classes of those top K entities matched by the literal here match means we can use.",
                    "label": 0
                },
                {
                    "sent": "For example, we can use some natural index to get some similar, lexically similar entities.",
                    "label": 0
                },
                {
                    "sent": "Take the PDF for example.",
                    "label": 0
                },
                {
                    "sent": "We can directly use local service which uses an index which is based on the.",
                    "label": 0
                },
                {
                    "sent": "And the label and anchor text.",
                    "label": 0
                },
                {
                    "sent": "But here we need to ensure high risk high record.",
                    "label": 0
                },
                {
                    "sent": "So we we match the entity not only by the whole little, but also by its other phrases.",
                    "label": 0
                },
                {
                    "sent": "This can help us ensure that the correct matches matches are not missed.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In model training, we actually train one binary classifier for each class.",
                    "label": 1
                },
                {
                    "sent": "From the candidate class.",
                    "label": 0
                },
                {
                    "sent": "Phone to train the cars we need to get the samples.",
                    "label": 1
                },
                {
                    "sent": "Actually 1 sample actually is an assertion whose objects annotated by a binary fund label.",
                    "label": 0
                },
                {
                    "sent": "We divide samples into two kinds.",
                    "label": 0
                },
                {
                    "sent": "One is particularly samples and another is.",
                    "label": 0
                },
                {
                    "sent": "General samples why?",
                    "label": 0
                },
                {
                    "sent": "For particular samples we ensure that object comes from the little match the entities.",
                    "label": 0
                },
                {
                    "sent": "Why, for example we we actually we do not need to.",
                    "label": 0
                },
                {
                    "sent": "We do not have to get the entity from the literal match.",
                    "label": 1
                },
                {
                    "sent": "The entity.",
                    "label": 0
                },
                {
                    "sent": "It can be an arbitrary entity from the knowledge base.",
                    "label": 1
                },
                {
                    "sent": "While",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also need to do next some playing in a sampling.",
                    "label": 0
                },
                {
                    "sent": "We actually extract object from the instance of some sibling class of the Class C. But but of course we should also ensure that the extract the instance is not an is not an instance of the Class C that mean negative.",
                    "label": 0
                },
                {
                    "sent": "Actually, we find the particular sample usually have a small size, but they have a close data distribution with regard to the prediction target.",
                    "label": 0
                },
                {
                    "sent": "But in contrast, the general sample users usually have a larger larger size, so our solution is preaching the model by the general samples and fine tune the model by particular samples.",
                    "label": 0
                },
                {
                    "sent": "This cannot only deal with the sample shortage problem, but also can raise the problem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adoption.",
                    "label": 0
                },
                {
                    "sent": "At the same time, in real application, we can pretend all the other class file for all the classes in the knowledge base and one you data set from 4 four focalization.",
                    "label": 0
                },
                {
                    "sent": "We can actually fine tune the class size of the candidate classes.",
                    "label": 0
                },
                {
                    "sent": "This actually save a lot of time in online application.",
                    "label": 0
                },
                {
                    "sent": "Then classify we are neural network architecture that is composed of bidirectional recurrent neural networks and an attention layer.",
                    "label": 0
                },
                {
                    "sent": "Let's say say more details in this picture.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the input layer we abstract directly extract labels from the subject property an object and then we concatenate these.",
                    "label": 0
                },
                {
                    "sent": "These are the labels into a sequence.",
                    "label": 0
                },
                {
                    "sent": "Of course we should fix the size of the the subject label and predict label and object label.",
                    "label": 0
                },
                {
                    "sent": "Then we encode each word each word.",
                    "label": 0
                },
                {
                    "sent": "Introverted laptop.",
                    "label": 0
                },
                {
                    "sent": "And next we learn we attached a recurrent neural networks to learn a new representation of the of the world.",
                    "label": 0
                },
                {
                    "sent": "While this representation will consider the curation of surrounding words into consideration.",
                    "label": 0
                },
                {
                    "sent": "For each word.",
                    "label": 0
                },
                {
                    "sent": "Other than learning, actually takes in two directions.",
                    "label": 0
                },
                {
                    "sent": "1 recurrent neural network.",
                    "label": 0
                },
                {
                    "sent": "Learn from the feed forward direction while another learn from the backward direction and then the new representations to representation are concatenated for each word and we also Attack Attack an attention layer which learns important ways of different words.",
                    "label": 0
                },
                {
                    "sent": "And also they combine the combined the other ways of combining the vectors of the of each word with their important ways to get a new vector here important ways is very useful.",
                    "label": 0
                },
                {
                    "sent": "For example here actually.",
                    "label": 0
                },
                {
                    "sent": "Arianne ocelot.",
                    "label": 0
                },
                {
                    "sent": "Play that, play an important role in determine whether this little.",
                    "label": 0
                },
                {
                    "sent": "Belong to a place or an area.",
                    "label": 0
                },
                {
                    "sent": "Finally we.",
                    "label": 0
                },
                {
                    "sent": "Yes, actually the attention weight can also give some justification or explanation about the prediction why this is predicted as an place or an Arabic 'cause this one.",
                    "label": 0
                },
                {
                    "sent": "This world at his word have very high importance.",
                    "label": 0
                },
                {
                    "sent": "And finally, we step photoconductive layer.",
                    "label": 0
                },
                {
                    "sent": "Analogical logistic regression layer.",
                    "label": 0
                },
                {
                    "sent": "They make it as a class file.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So improve.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ocean was quite predicted for each class and with previous cloud predicted scores.",
                    "label": 0
                },
                {
                    "sent": "We need to make the type decision.",
                    "label": 0
                },
                {
                    "sent": "We propose 22 solutions while the independent typing.",
                    "label": 0
                },
                {
                    "sent": "This is very simple.",
                    "label": 0
                },
                {
                    "sent": "If a class score is exceeds the threshold, this class is selected while hierarchical typing is a bit complicated.",
                    "label": 0
                },
                {
                    "sent": "Consider the class hierarchy into consideration in making the decision.",
                    "label": 0
                },
                {
                    "sent": "It first calculate a hierarchical score for each class.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That actually is the maximum of the scores of itself and all its descendants, and then it select selects those class whose hierarchy score satisfies two conditions.",
                    "label": 0
                },
                {
                    "sent": "First it should exceed the threshold.",
                    "label": 0
                },
                {
                    "sent": "Then it should have a large enough order forms over though over any of its disjoint candidate classes.",
                    "label": 0
                },
                {
                    "sent": "So let's use this example assumes the threshold is 0.5.",
                    "label": 0
                },
                {
                    "sent": "We have a candidate class place zero point.",
                    "label": 0
                },
                {
                    "sent": "Eight person which is disjoint with place there the score is 0.75.",
                    "label": 0
                },
                {
                    "sent": "Then we actually will exclude a person because person is disjoint with place, but it promises not is not higher than place.",
                    "label": 0
                },
                {
                    "sent": "Well if we replace person by park.",
                    "label": 0
                },
                {
                    "sent": "Then both place and park will be caped 'cause they are not disjoint so.",
                    "label": 0
                },
                {
                    "sent": "Then with the types we finally do entity matching.",
                    "label": 0
                },
                {
                    "sent": "Here we adopt A very simple solution.",
                    "label": 0
                },
                {
                    "sent": "We just to keep the literal match the entities that instance of at least one of the predicted types.",
                    "label": 0
                },
                {
                    "sent": "So briefly, we just use that I predict type to do to act as a constraint.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Final evaluation.",
                    "label": 0
                },
                {
                    "sent": "We used to this that's why is real real literal set called are light and another thing separator set.",
                    "label": 0
                },
                {
                    "sent": "Other electrolyte is based on the properties and literal provide proposed by our baseline related work and it's light is manually created by us by replacing the object entity objects by their labels.",
                    "label": 0
                },
                {
                    "sent": "Here are some statistics we may come back again and.",
                    "label": 0
                },
                {
                    "sent": "Evaluation we first analyze the impact of the framework components like how the classifier, whether the class architecture makes effect or whether independent typing and hierarch tapping make effect.",
                    "label": 0
                },
                {
                    "sent": "And then we evaluated overall typing result in competition with the baselines.",
                    "label": 0
                },
                {
                    "sent": "Finally, we report some entity matching results.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will I will escape the impact of the component, but directly jump to the typing results.",
                    "label": 0
                },
                {
                    "sent": "We adopted.",
                    "label": 0
                },
                {
                    "sent": "Three baselines, generated actually has been introduced before, but we extended this method by relaxed entity matching an entity.",
                    "label": 0
                },
                {
                    "sent": "Look up.",
                    "label": 0
                },
                {
                    "sent": "Simply get the look up by local.",
                    "label": 0
                },
                {
                    "sent": "Get entity by look up and then do voting.",
                    "label": 0
                },
                {
                    "sent": "But we not only get one entity, but multiple entities.",
                    "label": 0
                },
                {
                    "sent": "We find that our method can outperform those two baselines becausw.",
                    "label": 0
                },
                {
                    "sent": "That that is expected because they just consider the literal itself, but we consider the subject property and another another baseline is proxy range estimation.",
                    "label": 0
                },
                {
                    "sent": "We actually get the objects of the object of that property, and we get the classes of these objects and we use our voting strategy to get the data.",
                    "label": 0
                },
                {
                    "sent": "Get a score for each club each class.",
                    "label": 0
                },
                {
                    "sent": "And our method can be higher than this baseline.",
                    "label": 0
                },
                {
                    "sent": "This is this.",
                    "label": 0
                },
                {
                    "sent": "Actually I think it can be explained because we use DB pedia for experiment.",
                    "label": 0
                },
                {
                    "sent": "But indeed actually many relation assertions actually do not respect the constraint of property range.",
                    "label": 0
                },
                {
                    "sent": "So so this better line.",
                    "label": 0
                },
                {
                    "sent": "The performance is impacted.",
                    "label": 0
                },
                {
                    "sent": "We also compared to 222 benchmarks, but the result is better on synthetic little like little because it has less number of types in average and also realize of course is much noisy.",
                    "label": 0
                },
                {
                    "sent": "It sometimes sometimes they may even contact two entities or some.",
                    "label": 0
                },
                {
                    "sent": "Yes, for example, the sea of dog.",
                    "label": 0
                },
                {
                    "sent": "Actually sometimes people in London will say Dog Island Dog died in London than it is become quite ambiguous.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then entity matching, we simply compare matching by pure luck up and matching by look up and filtering by proper filtering by predictive type, and we find the filtering can not only increase the.",
                    "label": 0
                },
                {
                    "sent": "Correct matches the number of correct matching matches, but also the precision.",
                    "label": 0
                },
                {
                    "sent": "So here currently we only consider only use vlookup to estimate the candid entities we want to use most of skated approach in the future.",
                    "label": 0
                },
                {
                    "sent": "But one thing I should mention that is very important is if no entity is matched, we can create a new entity an annotated with the project type to correct this knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Let me conclude and we propose a framework for canonicalizing little assertions, with both typing an empty matching.",
                    "label": 0
                },
                {
                    "sent": "First, we utilize attentive by recurrent neural network for utilizing the little context and then we extract samples automatically from the knowledge base to learn the new network.",
                    "label": 0
                },
                {
                    "sent": "We also propose a hierarchical typing solution which actually performs well and you can find the results in the paper.",
                    "label": 0
                },
                {
                    "sent": "But after this researcher after this study, we find many problems are challenger.",
                    "label": 0
                },
                {
                    "sent": "Many challenges remaining first is how to get related entities with a high Rico, especially when the little is very ambiguous or even wrong.",
                    "label": 1
                },
                {
                    "sent": "The example I mentioned is dog islands of Dog Island, Dog Island in London, but actually the former members, Iceland of all dogs.",
                    "label": 0
                },
                {
                    "sent": "The second challenge is how to make a more robust correction.",
                    "label": 0
                },
                {
                    "sent": "In the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "For example, how to deal with an inconsistent collection collection if the matching and matching is causing constant?",
                    "label": 0
                },
                {
                    "sent": "Should we just ignore it or we should feed that inconsistent back to the prediction?",
                    "label": 0
                },
                {
                    "sent": "And then how to ensure the assertion truth?",
                    "label": 0
                },
                {
                    "sent": "Maybe we should use?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Semantic embedding or graph convolution neural network to check whether the entered metric finally cause the true two triple or round triple.",
                    "label": 0
                },
                {
                    "sent": "And I guess this will make the correction of the little more robust.",
                    "label": 0
                },
                {
                    "sent": "Yes, thanks for your attention.",
                    "label": 1
                }
            ]
        }
    }
}