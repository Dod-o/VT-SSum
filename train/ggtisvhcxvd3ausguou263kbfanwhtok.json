{
    "id": "ggtisvhcxvd3ausguou263kbfanwhtok",
    "title": "Community Detection in Graphs through Correlation",
    "info": {
        "author": [
            "Lian Duan, New Jersey Institute of Technology"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_duan_community_detection/",
    "segmentation": [
        [
            "Good morning everyone.",
            "Thanks for joining our talk.",
            "I started this work when I was a student with Doctor Nick in the University of Iowa and my student answered my friends.",
            "Having also contribute to this work.",
            "So I'm thankful for their well will help.",
            "So."
        ],
        [
            "So our topic is Community detection.",
            "First we need to understand what it is and why we need to do that.",
            "In social network, people talk to each other in biology, protein interact with each other.",
            "They both can be represented as nodes, like this graph.",
            "They interact with each other, but the nodes in this graph they don't randomly connect to each other.",
            "So nodes each node has more high pop probability.",
            "To connect the nodes with the same function, if we can find these community structures that help us to understand the modularity of each.",
            "Pot."
        ],
        [
            "Yeah.",
            "So.",
            "There's a lot of work has been proposed, like card based, spectrum based, etc.",
            "None of these can be dominant.",
            "This problem is hard 'cause it involves two objectives.",
            "We want more connection within each community and less connection across different community, different methods.",
            "They just try to strike a different balance between these two objectives."
        ],
        [
            "So the improvement on this work that can be categorized into like feature selection, objective function or search procedure for us, we only focus on improving this modularity function."
        ],
        [
            "If we want to improve that.",
            "So the first question, what's the problem of it?",
            "And the biggest problem for modularity is resolution problem.",
            "If we think about this graph, they have K. NCLEX connected like a ring.",
            "If we use modularity based methods they cannot find 5 communities.",
            "In fact the ground truth should be 10 because they have the tendency to find the large community so every two were merged and there are some like the multiresolution methods have been proposed but they also have the problem because how further should we go they can.",
            "Further, divide the detector community, but they also have other problems trying to merge small community and split large community."
        ],
        [
            "So since they have this problem, is there any other way we can solve this resolution problem?",
            "When we check modularity based methods we find.",
            "They try to find the structure that the number of internal edge is greater than expected under the assumption of random partition.",
            "If we check the items that correlated items that mining they try to find the items that occur more than expected under the assumption of item set independence, we can see they have the connection with each other.",
            "So in this.",
            "Well, in our work we will try to prove mathematically the modularity function is identical to the leverage function in itemset mining.",
            "By making use of the research progress in itemset mining, then we can use their research to improve our work in Community detection."
        ],
        [
            "In the following I will just briefly introduce some basic concepts between these two area and then make the connection of it so for correlated items that suppose we have item set with M items.",
            "In any transaction, the true probability in fact is support the probability of the transaction contains the item set S and the expected probability is a product of single item support.",
            "So a lot of.",
            "Correlation function has been proposed, but they can be generalized as a function of these TP and EP.",
            "So Chi Square probability ratio and so for leverage is TP minus YP."
        ],
        [
            "And here is a toy example.",
            "So suppose we have 5 transactions and the item set is beef and chicken, then transaction 1, four and five contain both items.",
            "Then the true probabilities 3 / 5 and four transaction contains beef and three contains chicken.",
            "So the expected probability is 4 / 5 * 3 / 5 and use that function.",
            "You can calculate the leverage score."
        ],
        [
            "For more generic function, the original mass format look like this.",
            "Apparently it's way different from any of these previous.",
            "Correlation function so in the following we're going to try to transform this function and make the connection to the previous one."
        ],
        [
            "Suppose we have the graph.",
            "We already partitioned this to help partitions and then if Ki is a node degree and Ki internal, is the node in the number of nodes in the same group of the node I that are connected to the node I so we can see for this green partition.",
            "The number some of the node degree is 2 + 2 + 3 for the node 123, so it's 2 + 2 + 3 and the internal sum of internal is 2 + 2 + 2.",
            "And the total number of edges.",
            "Here you can count, so it's overall it's 10."
        ],
        [
            "And if we transfer this undirected graph to double it directed graph, mathematically they are represented by the same matrix, so it's purely identical.",
            "If I just randomly choose an edge from this AA directed graph.",
            "So what is the probability for us to choose an edge within the green partition?",
            "Then there are six edge there, so it's 6 out of 20.",
            "Similarly, if we randomly choose an edge from this graph, what is the probability for this edge?",
            "They started from the green partition.",
            "All these six edges plus another 1 from 3 to 4.",
            "An overall it's seven, so 7 out of 20.",
            "Edges.",
            "That's a probability for the edge.",
            "Start from the green partition.",
            "Same for if we randomly choose edge, the edge ended in the green partition is 7 out of 20.",
            "If the if the edge started from the green partition is independent from the edge ended in the green partition, then the expected edge with both sides in the green partition should be 7.",
            "20 * 7.",
            "Out of 20.",
            "So."
        ],
        [
            "For generalization, as we can see.",
            "So if we randomly select an edge from this doubly directly graph, the true probability of the edge in this group is calculated by formula like this one and the expected probability of the edge in this group is also calculated by this function.",
            "So that's that's the true probability and expected probability we can."
        ],
        [
            "App.",
            "And then when we have this partition so when we check this is a modularity function, we define the partial modularity function.",
            "The only difference between these two is the number I in the modular function that I belongs to the whole graph and in the partial modularity function the I only belongs to that group, so the whole modularity function is the sum of all these part."
        ],
        [
            "So modularity function and we if we transfer this partial modularity function, the detail should you can find it in the paper so we can find it's look like this one and combined with the previous inference we have, we can see these partial modularity function.",
            "In fact is TP minus EP.",
            "The true probability of an edge in this graph minus the expected probability."
        ],
        [
            "In this graph, and we compare with the items and mining.",
            "These leverage function.",
            "In fact, it is the true probability of the transaction contains the item set minus the expected probability of the transaction contains these items and S they are just.",
            "Exactly identical so we can see there are a lot of correlation function in items and mining there can be.",
            "Function of TP and EP so we can make use of any of these function to replace the original modularity function.",
            "And we end up have a lot of modularity function."
        ],
        [
            "So now the problem is, since we have so many, which one do they retrieve the same results if not?",
            "What's up?"
        ],
        [
            "Difference.",
            "And we do the upper bound analysis to try to find the difference.",
            "So there is a correlation property.",
            "So the correlation function will monotonically increase with a decrease of.",
            "EP NTP, how much?",
            "OK, OK.",
            "So.",
            "With a given group we have the fixed TP as we can see.",
            "The lowest EP we could have.",
            "Is by using this math formula cause no degree Ki must be greater or equal to internal.",
            "So if the TP is fixed, the lowest number of EP should be TP square."
        ],
        [
            "And if we check these upper bound function we can see different functions have different shape and for probability ratio.",
            "As we can see, when they are approaching to 0 then the upper bound will increase to Infinity, which means they have favor to very small community and for leverage they favor large community.",
            "Almost half size of the whole graph, followed by likelihood ratio."
        ],
        [
            "Chi Square and probability ratio."
        ],
        [
            "So in the following we will do the experiment to validate our finding and we do that in both real life data set and simulated."
        ],
        [
            "Data set in real life datasets.",
            "We have the karate club.",
            "They have two equal size community and community football.",
            "They have 12 equal sized mid-size commit."
        ],
        [
            "And we can see for this karate if they have only two large community leverage the oringinal.",
            "Modularity function is good, but if we have several small size then likelihood ratio could be better."
        ],
        [
            "And we also do that in simulated datasets and we control several parameter.",
            "Like the minimum community sites on the community structure, if the minimal community sizes smaller, they have a lot of small community, only few large community and if the minimal community size is large, then this network only have large communities."
        ],
        [
            "We only use a minimal normalized mutual information to do check the performance, as we can see.",
            "No matter how we tune the parameter, the performance of probability ratio and Chi Square is almost the same .5 only the likelihood ratio oringinal modularity function represented as leverage.",
            "They're going to change, but.",
            "The generally speaking likelihood ratio is good, but when the community structure is very clear and they're only large community size, then the leverage is good, then likelihood ratio otherwise."
        ],
        [
            "Likelihood ratio could be more robust, and if we check the number of detected group we can see now except likelihood ratio, none of them will react to.",
            "To the not the parameter change."
        ],
        [
            "So that's the conclusion we make.",
            "The connection between the community detection on itemset mining and likelihood ratio could be more robust, and for the other two they just stick to the BIOS, whatever they have.",
            "OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "Thanks for joining our talk.",
                    "label": 0
                },
                {
                    "sent": "I started this work when I was a student with Doctor Nick in the University of Iowa and my student answered my friends.",
                    "label": 1
                },
                {
                    "sent": "Having also contribute to this work.",
                    "label": 0
                },
                {
                    "sent": "So I'm thankful for their well will help.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our topic is Community detection.",
                    "label": 1
                },
                {
                    "sent": "First we need to understand what it is and why we need to do that.",
                    "label": 0
                },
                {
                    "sent": "In social network, people talk to each other in biology, protein interact with each other.",
                    "label": 0
                },
                {
                    "sent": "They both can be represented as nodes, like this graph.",
                    "label": 0
                },
                {
                    "sent": "They interact with each other, but the nodes in this graph they don't randomly connect to each other.",
                    "label": 0
                },
                {
                    "sent": "So nodes each node has more high pop probability.",
                    "label": 0
                },
                {
                    "sent": "To connect the nodes with the same function, if we can find these community structures that help us to understand the modularity of each.",
                    "label": 0
                },
                {
                    "sent": "Pot.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of work has been proposed, like card based, spectrum based, etc.",
                    "label": 0
                },
                {
                    "sent": "None of these can be dominant.",
                    "label": 0
                },
                {
                    "sent": "This problem is hard 'cause it involves two objectives.",
                    "label": 0
                },
                {
                    "sent": "We want more connection within each community and less connection across different community, different methods.",
                    "label": 1
                },
                {
                    "sent": "They just try to strike a different balance between these two objectives.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the improvement on this work that can be categorized into like feature selection, objective function or search procedure for us, we only focus on improving this modularity function.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we want to improve that.",
                    "label": 0
                },
                {
                    "sent": "So the first question, what's the problem of it?",
                    "label": 0
                },
                {
                    "sent": "And the biggest problem for modularity is resolution problem.",
                    "label": 0
                },
                {
                    "sent": "If we think about this graph, they have K. NCLEX connected like a ring.",
                    "label": 0
                },
                {
                    "sent": "If we use modularity based methods they cannot find 5 communities.",
                    "label": 0
                },
                {
                    "sent": "In fact the ground truth should be 10 because they have the tendency to find the large community so every two were merged and there are some like the multiresolution methods have been proposed but they also have the problem because how further should we go they can.",
                    "label": 0
                },
                {
                    "sent": "Further, divide the detector community, but they also have other problems trying to merge small community and split large community.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So since they have this problem, is there any other way we can solve this resolution problem?",
                    "label": 0
                },
                {
                    "sent": "When we check modularity based methods we find.",
                    "label": 0
                },
                {
                    "sent": "They try to find the structure that the number of internal edge is greater than expected under the assumption of random partition.",
                    "label": 1
                },
                {
                    "sent": "If we check the items that correlated items that mining they try to find the items that occur more than expected under the assumption of item set independence, we can see they have the connection with each other.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                },
                {
                    "sent": "Well, in our work we will try to prove mathematically the modularity function is identical to the leverage function in itemset mining.",
                    "label": 0
                },
                {
                    "sent": "By making use of the research progress in itemset mining, then we can use their research to improve our work in Community detection.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the following I will just briefly introduce some basic concepts between these two area and then make the connection of it so for correlated items that suppose we have item set with M items.",
                    "label": 0
                },
                {
                    "sent": "In any transaction, the true probability in fact is support the probability of the transaction contains the item set S and the expected probability is a product of single item support.",
                    "label": 1
                },
                {
                    "sent": "So a lot of.",
                    "label": 0
                },
                {
                    "sent": "Correlation function has been proposed, but they can be generalized as a function of these TP and EP.",
                    "label": 1
                },
                {
                    "sent": "So Chi Square probability ratio and so for leverage is TP minus YP.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here is a toy example.",
                    "label": 0
                },
                {
                    "sent": "So suppose we have 5 transactions and the item set is beef and chicken, then transaction 1, four and five contain both items.",
                    "label": 0
                },
                {
                    "sent": "Then the true probabilities 3 / 5 and four transaction contains beef and three contains chicken.",
                    "label": 1
                },
                {
                    "sent": "So the expected probability is 4 / 5 * 3 / 5 and use that function.",
                    "label": 1
                },
                {
                    "sent": "You can calculate the leverage score.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For more generic function, the original mass format look like this.",
                    "label": 0
                },
                {
                    "sent": "Apparently it's way different from any of these previous.",
                    "label": 0
                },
                {
                    "sent": "Correlation function so in the following we're going to try to transform this function and make the connection to the previous one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suppose we have the graph.",
                    "label": 0
                },
                {
                    "sent": "We already partitioned this to help partitions and then if Ki is a node degree and Ki internal, is the node in the number of nodes in the same group of the node I that are connected to the node I so we can see for this green partition.",
                    "label": 1
                },
                {
                    "sent": "The number some of the node degree is 2 + 2 + 3 for the node 123, so it's 2 + 2 + 3 and the internal sum of internal is 2 + 2 + 2.",
                    "label": 0
                },
                {
                    "sent": "And the total number of edges.",
                    "label": 0
                },
                {
                    "sent": "Here you can count, so it's overall it's 10.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we transfer this undirected graph to double it directed graph, mathematically they are represented by the same matrix, so it's purely identical.",
                    "label": 0
                },
                {
                    "sent": "If I just randomly choose an edge from this AA directed graph.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability for us to choose an edge within the green partition?",
                    "label": 1
                },
                {
                    "sent": "Then there are six edge there, so it's 6 out of 20.",
                    "label": 0
                },
                {
                    "sent": "Similarly, if we randomly choose an edge from this graph, what is the probability for this edge?",
                    "label": 0
                },
                {
                    "sent": "They started from the green partition.",
                    "label": 0
                },
                {
                    "sent": "All these six edges plus another 1 from 3 to 4.",
                    "label": 0
                },
                {
                    "sent": "An overall it's seven, so 7 out of 20.",
                    "label": 0
                },
                {
                    "sent": "Edges.",
                    "label": 1
                },
                {
                    "sent": "That's a probability for the edge.",
                    "label": 0
                },
                {
                    "sent": "Start from the green partition.",
                    "label": 0
                },
                {
                    "sent": "Same for if we randomly choose edge, the edge ended in the green partition is 7 out of 20.",
                    "label": 0
                },
                {
                    "sent": "If the if the edge started from the green partition is independent from the edge ended in the green partition, then the expected edge with both sides in the green partition should be 7.",
                    "label": 1
                },
                {
                    "sent": "20 * 7.",
                    "label": 0
                },
                {
                    "sent": "Out of 20.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For generalization, as we can see.",
                    "label": 0
                },
                {
                    "sent": "So if we randomly select an edge from this doubly directly graph, the true probability of the edge in this group is calculated by formula like this one and the expected probability of the edge in this group is also calculated by this function.",
                    "label": 1
                },
                {
                    "sent": "So that's that's the true probability and expected probability we can.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "App.",
                    "label": 0
                },
                {
                    "sent": "And then when we have this partition so when we check this is a modularity function, we define the partial modularity function.",
                    "label": 1
                },
                {
                    "sent": "The only difference between these two is the number I in the modular function that I belongs to the whole graph and in the partial modularity function the I only belongs to that group, so the whole modularity function is the sum of all these part.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So modularity function and we if we transfer this partial modularity function, the detail should you can find it in the paper so we can find it's look like this one and combined with the previous inference we have, we can see these partial modularity function.",
                    "label": 0
                },
                {
                    "sent": "In fact is TP minus EP.",
                    "label": 0
                },
                {
                    "sent": "The true probability of an edge in this graph minus the expected probability.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this graph, and we compare with the items and mining.",
                    "label": 0
                },
                {
                    "sent": "These leverage function.",
                    "label": 0
                },
                {
                    "sent": "In fact, it is the true probability of the transaction contains the item set minus the expected probability of the transaction contains these items and S they are just.",
                    "label": 0
                },
                {
                    "sent": "Exactly identical so we can see there are a lot of correlation function in items and mining there can be.",
                    "label": 1
                },
                {
                    "sent": "Function of TP and EP so we can make use of any of these function to replace the original modularity function.",
                    "label": 1
                },
                {
                    "sent": "And we end up have a lot of modularity function.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the problem is, since we have so many, which one do they retrieve the same results if not?",
                    "label": 0
                },
                {
                    "sent": "What's up?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Difference.",
                    "label": 0
                },
                {
                    "sent": "And we do the upper bound analysis to try to find the difference.",
                    "label": 1
                },
                {
                    "sent": "So there is a correlation property.",
                    "label": 0
                },
                {
                    "sent": "So the correlation function will monotonically increase with a decrease of.",
                    "label": 1
                },
                {
                    "sent": "EP NTP, how much?",
                    "label": 0
                },
                {
                    "sent": "OK, OK.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "With a given group we have the fixed TP as we can see.",
                    "label": 0
                },
                {
                    "sent": "The lowest EP we could have.",
                    "label": 0
                },
                {
                    "sent": "Is by using this math formula cause no degree Ki must be greater or equal to internal.",
                    "label": 0
                },
                {
                    "sent": "So if the TP is fixed, the lowest number of EP should be TP square.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we check these upper bound function we can see different functions have different shape and for probability ratio.",
                    "label": 1
                },
                {
                    "sent": "As we can see, when they are approaching to 0 then the upper bound will increase to Infinity, which means they have favor to very small community and for leverage they favor large community.",
                    "label": 0
                },
                {
                    "sent": "Almost half size of the whole graph, followed by likelihood ratio.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chi Square and probability ratio.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the following we will do the experiment to validate our finding and we do that in both real life data set and simulated.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data set in real life datasets.",
                    "label": 1
                },
                {
                    "sent": "We have the karate club.",
                    "label": 1
                },
                {
                    "sent": "They have two equal size community and community football.",
                    "label": 0
                },
                {
                    "sent": "They have 12 equal sized mid-size commit.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can see for this karate if they have only two large community leverage the oringinal.",
                    "label": 0
                },
                {
                    "sent": "Modularity function is good, but if we have several small size then likelihood ratio could be better.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also do that in simulated datasets and we control several parameter.",
                    "label": 0
                },
                {
                    "sent": "Like the minimum community sites on the community structure, if the minimal community sizes smaller, they have a lot of small community, only few large community and if the minimal community size is large, then this network only have large communities.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We only use a minimal normalized mutual information to do check the performance, as we can see.",
                    "label": 0
                },
                {
                    "sent": "No matter how we tune the parameter, the performance of probability ratio and Chi Square is almost the same .5 only the likelihood ratio oringinal modularity function represented as leverage.",
                    "label": 1
                },
                {
                    "sent": "They're going to change, but.",
                    "label": 1
                },
                {
                    "sent": "The generally speaking likelihood ratio is good, but when the community structure is very clear and they're only large community size, then the leverage is good, then likelihood ratio otherwise.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Likelihood ratio could be more robust, and if we check the number of detected group we can see now except likelihood ratio, none of them will react to.",
                    "label": 0
                },
                {
                    "sent": "To the not the parameter change.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the conclusion we make.",
                    "label": 0
                },
                {
                    "sent": "The connection between the community detection on itemset mining and likelihood ratio could be more robust, and for the other two they just stick to the BIOS, whatever they have.",
                    "label": 1
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        }
    }
}