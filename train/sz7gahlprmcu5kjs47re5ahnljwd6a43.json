{
    "id": "sz7gahlprmcu5kjs47re5ahnljwd6a43",
    "title": "PerTurbo: a new classification algorithm based on the spectrum perturbations of the Laplace-Beltrami operator",
    "info": {
        "author": [
            "Thomas Burger, University of South Brittany"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Classification"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_burger_perturbo/",
    "segmentation": [
        [
            "So I'll present a new classification algorithm that we called virtual Bo.",
            "So once again, with respect to names we made, well, kind of involuntary play words because we learned afterward that in Spanish.",
            "About taboo, Meanwhile I am insane or I am disturbed which was not voluntary."
        ],
        [
            "Um?",
            "We focused on supervised classification problem and more precisely we wanted to tackle these classification problem from manifold learning POV.",
            "And more precisely, in geometric point of view, as it appeared that processing a manifold in dimensional space is roughly equivalent to processing a surface 3D space when you're involving in computer graphics.",
            "So we got some inspiration from the main results of computer graphics and the main.",
            "Our main contribution is to transpose all these results from computer graphics due to machine learning."
        ],
        [
            "To classification.",
            "So here is the outline of the presentation.",
            "1st, I'll give some insights on computer graphics, then I'll explain how to transfer all these results from computer graphics to machine learning into classification more precisely.",
            "And of course afterward the derived algorithm give experimental results and so on."
        ],
        [
            "So the main problem in computer graphics is.",
            "Is to built or create beautiful images which are as well as quick as possible and to do so.",
            "Computer graphics scientists often copy real world objects, so they use a scanner and with the laser they simple.",
            "The object of interest with millions and millions of points and then thanks to these clouds they can reconstruct the surface an.",
            "Of course, when it comes to storing this image.",
            "In the memory this million of points are somehow difficult to deal with, so they'd like to reduce the number of points.",
            "And of course to do so they like only to keep all the points which are informative and to remove the others."
        ],
        [
            "So if we keep the same image, for instance, we have this woman.",
            "On the forehead or above the chest, the surface is rather smooth or regular in the topology is not that complex, so you naturally guess that it's not necessary to add new simple points and the graph, because they wouldn't bring any additional information.",
            "On the contrary, nearby the year, the topology rather complex an if you had some new points, maybe it will help to have a smoother surface, or at least surface which is.",
            "More realistic, so stressed the need for metric to quantify the interest of the point when you when you edit or remove it in as it will modify the surface."
        ],
        [
            "More formally, the surface of the object of interest well can be assumed to be a remaining manifold, which means that its surface, which can be differentiated everywhere.",
            "And it is known that such a surface can be correct.",
            "Erised by the spectrum of an operator which is called the.",
            "Let's build from your richer and the spectrum is completely defines the manifold.",
            "So the level from your parrot or I won't give all the details, but roughly it corresponds to the location of the function, but applied to remaining manifold.",
            "So it's an operator which quantify the curvature of the surface.",
            "The main problem is that the surface is yet unknown.",
            "On what we got are the samples, so it's impossible to."
        ],
        [
            "Apply the Laplace Beltrami operator on the surface of the surface is in no.",
            "Fortunately, there is very good and known approximation for the less Beltrami operator an how does it work?",
            "Well?",
            "It's simply the gram matrix of all the symbols fitted with the Goshen dissimilarity measure an it has been established that the spectrum of this proxy that we call K can be used to efficiently characterize the surface of the real object and that the perturbation of the spectrum of this matrix K. Is proportional to the amount of.",
            "Deformation of the surface.",
            "So here is the metric that we are looking for."
        ],
        [
            "So now all these background knowledge in computer graphics can be applied in machine learning.",
            "To do so, we mainly rely on 2."
        ],
        [
            "Ideas?",
            "The first one is simply to compare class in a classification problem to a surface in a computer graphics problem.",
            "So so far we've seen that the bill to Bashan of this proxy K, is really interested, quantify the interest of a new sample in this comparison between class and the surface.",
            "What does mean?"
        ],
        [
            "This perturbation of the proxy.",
            "So in a statistical or machine learning context, is it possible to give an interpretation to this proxy into its perturbation?",
            "To us the answer is yes and here."
        ],
        [
            "Is a small intuition on it, so I simple some points with with a Gaussian distribution and here I computed the estimation of the distribution.",
            "So I just estimated the mean, the variance.",
            "Anne now."
        ],
        [
            "So am I add a new simple.",
            "So here is a blue store.",
            "If I re estimate the distribution, then of course the mean and the variance will shift.",
            "Because of these new sample, now if I remove this simple."
        ],
        [
            "Another one, which is another player here.",
            "Obviously the distribution is a shift, but it's much more proportion than with the previous sample."
        ],
        [
            "Which finally implement that similarity to the perturbation of KK.",
            "The perturbation of a new simple is much more important.",
            "If these simple is an outlier than if it belongs to the class.",
            "So here are is this intuition be behind the idea that a computer class to the surface?"
        ],
        [
            "The second ID.",
            "Is to consider a class ways manifold learning.",
            "Well most of the time in mental learning.",
            "All the data sets are considered to belong to the same manifold, which means that all the classes are embedded in the same manifold.",
            "Here we decide to compare a single class to single surface, which means that for each class we've got the dedicated manifold and dedicated manifold.",
            "It can be characterized independently from the others.",
            "So for each class L we got, now the matrix KL to approximate the corresponding manifold.",
            "With these two ideas."
        ],
        [
            "We can add some remarks.",
            "The proxy for the left has been from.",
            "Your parents are well, I introduced it a great metrics fitted with the Goshen dissimilarity measure.",
            "Another way to present it is just to say, well, it's a classical gram metric metrics with an equation that product, but in the Goshen reproducing kernel it will space.",
            "So this approximation of the last bit from your printer can be understood as a kernel trick.",
            "So here are the classical notations for Kindle tricks so.",
            "X&OR is being put in feature Space, 5 is the mapping from X to ZTL in the state of training.",
            "Examples from for the manyfold MLR for class L here.",
            "Also, it's already degree metrics.",
            "An ex TLD is a new simple that we have met classifying."
        ],
        [
            "Now in the generalized space, let US project the new sample X 5X Field onto the manifold, or equivalently, onto the subspace spanned by 5 of TL.",
            "Rather than actually we got two components, one which is coplanar and the other which is orthogonal to the manifold."
        ],
        [
            "The test results from computer graphics that we're going to use.",
            "Is that the perturbation of the proxy of the lead from you operator?",
            "Mainly comes from the orthogonal components this.",
            "It's possible, thanks to the properties of the Goshen Journal to rewrite a fair perturbation measure as such here.",
            "So now."
        ],
        [
            "So if we write as capital Phi, the metrics whose columns are the elements of Phi of TL, then the projector over the manifold or the subspace spanned by the training example is given by the formula here.",
            "An with this projector, it's possible to compute the complainer components."
        ],
        [
            "So I'll skip all the computation, of course."
        ],
        [
            "Because, well, they're in the paper.",
            "But these from Likins be written, such as here."
        ],
        [
            "Which is interesting is that here we got the inverse of our proxy.",
            "And here we."
        ],
        [
            "Art vectors, which are finally the same vectors but one is the transpose of the other."
        ],
        [
            "And then the our perturbation measure 4 by.",
            "The simple text tiled onto the manifold L just read as here.",
            "And so this is our perturbation measure."
        ],
        [
            "And just to illustrate it, here are two figures.",
            "So in the most one we got.",
            "A manifold which simply is a spiral.",
            "An we compute so this is manifold Milan we compute for edge pixel of the images.",
            "Perturbation involved by this Pixel Ann recorded according to the amount of perturbation.",
            "So if we had a pixel just.",
            "On a training example, then there's no perturbation, and the further it is, the more the perturbation.",
            "And on the right figure it's exactly the same.",
            "But we only change Sigma, which is the variance of the Gaussian kernel.",
            "So from this measure, it's really simple to derive."
        ],
        [
            "Classification algorithm.",
            "During the training step, we simply gather all the training example for each class we compute the corresponding graph metrics in the kernel space and we invert these metrics."
        ],
        [
            "Then during the testing step.",
            "We compute the dissimilarity of the new test sample that we are classifying for each.",
            "Manyfold associate each class.",
            "And then we associate the simple to the class, which was the least perturbated baby junction of the simple to the manifold."
        ],
        [
            "Here is a small illustration yet.",
            "So on the left we got a classification problem with two classes which are intermingled spirals.",
            "A red one in blue on an.",
            "Once again we classified all the pixels of the image according to this algorithm and all the red ones would have been classified in the red spiral, and Conversely for the blue.",
            "Anne.",
            "Here the picture is exactly the same, but instead of to intermingle, spiroid or spiral we considered three normally distribution classes.",
            "So here."
        ],
        [
            "Algorithm now for."
        ],
        [
            "Experiments of course.",
            "We just did as simulated as well as real datasets so that the relatives came from the UCI machine learning repository.",
            "We compared our algorithm to several algorithms of the state of the art which.",
            "There's VMS, so here in the presentation I'll talk only about as because they were the best from all the reference algorithm.",
            "Of course we are fully optimized.",
            "The perimeter and hyperparameters of the SVM to buy cross validation to make sure that the comparison is no lose with respect to our method.",
            "And we just also several version of portable, so I won't go in in the details because it would be a bit long.",
            "Anne."
        ],
        [
            "In roughly from creative point of view, it appears that the performances of the table are similar to that of SVM.",
            "A bit less interesting when there are a lot of missing values or there are a lot of binary variables because in such a case the approximation of class by your surface is with artificial.",
            "But on the other end it was more efficient when we got more than two classes.",
            "It also appears that depending on the problem, the best version of Turbo is not always the same, so it means that there's still some improvements in research carry on."
        ],
        [
            "More precisely, here are the data set that we worked on.",
            "So here are the simulated data set with a lot of class and a lot of variables and of components.",
            "An below we got all the classical UCI machine learning datasets such as Ionosphere, diabites and so on.",
            "Anne."
        ],
        [
            "Here are the results, so I won't go through all the accuracy rates.",
            "I Simply put the green bullets.",
            "When a portable is better and a red one, when it seems better?",
            "And it appears that the performance are roughly similar.",
            "So I did not compute insignificant C test because I do not claim that one algorithm is better than the other, so I do not put back into question the null hypothesis and then.",
            "Hypothesis test wouldn't bring anything."
        ],
        [
            "As for future work."
        ],
        [
            "Our main focus is active learning.",
            "In fact, it appears that it's really easy to compute the border between the classes with these algorithms, as it's simply the set of points for which the perturbation of the two least perturbated classes is the same.",
            "An the consequence it's also releasing."
        ],
        [
            "Able to define a small area around the border.",
            "And then to query in this area.",
            "That's this.",
            "We've got a very efficient active learning policy.",
            "An we apply this active learning policy.",
            "Unbeatable, but otherwise as well."
        ],
        [
            "Other algorithms such as KNN here and it appears that the this active learning policies efficient, so I haven't much Riddle than what appear here because it's preliminary yet, but it sounds interesting."
        ],
        [
            "An there are a lot of other links to do with other algorithms, so for instance, when the proxy of the matrix is not invertible, then we need to compute absolute inverse.",
            "Which opened the door to all the metrics regularization techniques.",
            "It also appear that the spectrum of K is exactly the same as the metrics which is considered in graph Laplacian Eigen map.",
            "So this method also provide kind of a projection method for graduation again map.",
            "The the perturbation measure that we use is also really really similar to some of the melanomas distance kernel space that as long proposed few years ago, we didn't success in making a strong link yet, but it's work in progress.",
            "And finally, we'd like to study the various parameters and the various versions of the algorithm.",
            "So there are very, very few.",
            "I'm interested in actually the only one is the variance of the Gaussian kernel, but nonetheless we'd like to investigate that a bit more in order to have a better understanding of the behavior of the algorithm."
        ],
        [
            "So."
        ],
        [
            "So that's it.",
            "You conclude them.",
            "I would say that to build the classification algorithm inspired by computer graphic results.",
            "With very few parameters to tune and the performance of which are similar to that of SVM, and there are a lot of perspective because I told you it's just a work in progress, but we found the 1st result rather appealing."
        ],
        [
            "Thank you for attention and thank you for having coming so soon in the morning.",
            "Questions.",
            "Go ahead.",
            "Yeah, so you approached the performance wise VM and you also told that in multi classification setting you achieve Tiger curacy but you don't show.",
            "Do."
        ],
        [
            "He's so probably you can facilitate this aspect in your presentation.",
            "That is much.",
            "Yeah, I do for now.",
            "These reasons are just plain memory, so I can't claim that our algorithm is better.",
            "It's just kind of attendance is that we've put that when there are a lot of classes.",
            "It appears to be a bit."
        ],
        [
            "Better an, On the contrary, when there are missing values or lot of binary variables, and then it's less efficient.",
            "But well, it's not really established yet, it's it's just well.",
            "Observation by now.",
            "What I only say is that."
        ],
        [
            "Roughly, the performances are equivalent, so here for instance.",
            "We are far better because of the binary variables or missing values, but on some others were better thanks to the fact that there is a lot of classes, so this is just a primary observation.",
            "OK thanks.",
            "Other questions, yes, compared to SVM, how does your algorithm scale to large data?",
            "The main problem.",
            "Rely in the training step."
        ],
        [
            "Here, because we've got to invert metrics.",
            "So if you begin time, I guess yeah, so if we got a huge amount of training set then.",
            "These can be.",
            "This can be quite long.",
            "But there is a lot of techniques used in computer graphics to shorten these computation because well, in computer graphics they also need to invert this.",
            "This type of metrics an you get that when."
        ],
        [
            "Or dealing with that many samples, then is becoming intractable, so there are some.",
            "It's possible to perform some local approximation using only the close of samples to the region that you're interested in, so we haven't investigated how to shorten the computation time, but.",
            "Will have to do it.",
            "Yeah, because if you use approximations the accuracy will suffer.",
            "It depends.",
            "Well if we just simple around on a restricted area then yeah the accuracy will suffer.",
            "But it's also possible to resample.",
            "The manifold.",
            "So that all the regions are represented, but with the number of samples which varies according to the complexity of the topology.",
            "And this resampling does not need any.",
            "It doesn't need to inverse matrix.",
            "So then it's possible to have less examples, but which represents in a better way the manifold.",
            "So then we expect that the accuracy will suffer to match.",
            "Other questions.",
            "Well, let's thank the speaker again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll present a new classification algorithm that we called virtual Bo.",
                    "label": 1
                },
                {
                    "sent": "So once again, with respect to names we made, well, kind of involuntary play words because we learned afterward that in Spanish.",
                    "label": 0
                },
                {
                    "sent": "About taboo, Meanwhile I am insane or I am disturbed which was not voluntary.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We focused on supervised classification problem and more precisely we wanted to tackle these classification problem from manifold learning POV.",
                    "label": 1
                },
                {
                    "sent": "And more precisely, in geometric point of view, as it appeared that processing a manifold in dimensional space is roughly equivalent to processing a surface 3D space when you're involving in computer graphics.",
                    "label": 1
                },
                {
                    "sent": "So we got some inspiration from the main results of computer graphics and the main.",
                    "label": 0
                },
                {
                    "sent": "Our main contribution is to transpose all these results from computer graphics due to machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To classification.",
                    "label": 0
                },
                {
                    "sent": "So here is the outline of the presentation.",
                    "label": 0
                },
                {
                    "sent": "1st, I'll give some insights on computer graphics, then I'll explain how to transfer all these results from computer graphics to machine learning into classification more precisely.",
                    "label": 1
                },
                {
                    "sent": "And of course afterward the derived algorithm give experimental results and so on.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main problem in computer graphics is.",
                    "label": 1
                },
                {
                    "sent": "Is to built or create beautiful images which are as well as quick as possible and to do so.",
                    "label": 0
                },
                {
                    "sent": "Computer graphics scientists often copy real world objects, so they use a scanner and with the laser they simple.",
                    "label": 0
                },
                {
                    "sent": "The object of interest with millions and millions of points and then thanks to these clouds they can reconstruct the surface an.",
                    "label": 0
                },
                {
                    "sent": "Of course, when it comes to storing this image.",
                    "label": 1
                },
                {
                    "sent": "In the memory this million of points are somehow difficult to deal with, so they'd like to reduce the number of points.",
                    "label": 0
                },
                {
                    "sent": "And of course to do so they like only to keep all the points which are informative and to remove the others.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we keep the same image, for instance, we have this woman.",
                    "label": 0
                },
                {
                    "sent": "On the forehead or above the chest, the surface is rather smooth or regular in the topology is not that complex, so you naturally guess that it's not necessary to add new simple points and the graph, because they wouldn't bring any additional information.",
                    "label": 0
                },
                {
                    "sent": "On the contrary, nearby the year, the topology rather complex an if you had some new points, maybe it will help to have a smoother surface, or at least surface which is.",
                    "label": 0
                },
                {
                    "sent": "More realistic, so stressed the need for metric to quantify the interest of the point when you when you edit or remove it in as it will modify the surface.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More formally, the surface of the object of interest well can be assumed to be a remaining manifold, which means that its surface, which can be differentiated everywhere.",
                    "label": 1
                },
                {
                    "sent": "And it is known that such a surface can be correct.",
                    "label": 1
                },
                {
                    "sent": "Erised by the spectrum of an operator which is called the.",
                    "label": 1
                },
                {
                    "sent": "Let's build from your richer and the spectrum is completely defines the manifold.",
                    "label": 0
                },
                {
                    "sent": "So the level from your parrot or I won't give all the details, but roughly it corresponds to the location of the function, but applied to remaining manifold.",
                    "label": 1
                },
                {
                    "sent": "So it's an operator which quantify the curvature of the surface.",
                    "label": 0
                },
                {
                    "sent": "The main problem is that the surface is yet unknown.",
                    "label": 0
                },
                {
                    "sent": "On what we got are the samples, so it's impossible to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apply the Laplace Beltrami operator on the surface of the surface is in no.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, there is very good and known approximation for the less Beltrami operator an how does it work?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "It's simply the gram matrix of all the symbols fitted with the Goshen dissimilarity measure an it has been established that the spectrum of this proxy that we call K can be used to efficiently characterize the surface of the real object and that the perturbation of the spectrum of this matrix K. Is proportional to the amount of.",
                    "label": 1
                },
                {
                    "sent": "Deformation of the surface.",
                    "label": 0
                },
                {
                    "sent": "So here is the metric that we are looking for.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now all these background knowledge in computer graphics can be applied in machine learning.",
                    "label": 0
                },
                {
                    "sent": "To do so, we mainly rely on 2.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ideas?",
                    "label": 0
                },
                {
                    "sent": "The first one is simply to compare class in a classification problem to a surface in a computer graphics problem.",
                    "label": 1
                },
                {
                    "sent": "So so far we've seen that the bill to Bashan of this proxy K, is really interested, quantify the interest of a new sample in this comparison between class and the surface.",
                    "label": 0
                },
                {
                    "sent": "What does mean?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This perturbation of the proxy.",
                    "label": 0
                },
                {
                    "sent": "So in a statistical or machine learning context, is it possible to give an interpretation to this proxy into its perturbation?",
                    "label": 0
                },
                {
                    "sent": "To us the answer is yes and here.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a small intuition on it, so I simple some points with with a Gaussian distribution and here I computed the estimation of the distribution.",
                    "label": 0
                },
                {
                    "sent": "So I just estimated the mean, the variance.",
                    "label": 0
                },
                {
                    "sent": "Anne now.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So am I add a new simple.",
                    "label": 0
                },
                {
                    "sent": "So here is a blue store.",
                    "label": 0
                },
                {
                    "sent": "If I re estimate the distribution, then of course the mean and the variance will shift.",
                    "label": 0
                },
                {
                    "sent": "Because of these new sample, now if I remove this simple.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another one, which is another player here.",
                    "label": 0
                },
                {
                    "sent": "Obviously the distribution is a shift, but it's much more proportion than with the previous sample.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which finally implement that similarity to the perturbation of KK.",
                    "label": 0
                },
                {
                    "sent": "The perturbation of a new simple is much more important.",
                    "label": 1
                },
                {
                    "sent": "If these simple is an outlier than if it belongs to the class.",
                    "label": 0
                },
                {
                    "sent": "So here are is this intuition be behind the idea that a computer class to the surface?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second ID.",
                    "label": 0
                },
                {
                    "sent": "Is to consider a class ways manifold learning.",
                    "label": 1
                },
                {
                    "sent": "Well most of the time in mental learning.",
                    "label": 0
                },
                {
                    "sent": "All the data sets are considered to belong to the same manifold, which means that all the classes are embedded in the same manifold.",
                    "label": 0
                },
                {
                    "sent": "Here we decide to compare a single class to single surface, which means that for each class we've got the dedicated manifold and dedicated manifold.",
                    "label": 1
                },
                {
                    "sent": "It can be characterized independently from the others.",
                    "label": 0
                },
                {
                    "sent": "So for each class L we got, now the matrix KL to approximate the corresponding manifold.",
                    "label": 0
                },
                {
                    "sent": "With these two ideas.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can add some remarks.",
                    "label": 0
                },
                {
                    "sent": "The proxy for the left has been from.",
                    "label": 0
                },
                {
                    "sent": "Your parents are well, I introduced it a great metrics fitted with the Goshen dissimilarity measure.",
                    "label": 0
                },
                {
                    "sent": "Another way to present it is just to say, well, it's a classical gram metric metrics with an equation that product, but in the Goshen reproducing kernel it will space.",
                    "label": 0
                },
                {
                    "sent": "So this approximation of the last bit from your printer can be understood as a kernel trick.",
                    "label": 0
                },
                {
                    "sent": "So here are the classical notations for Kindle tricks so.",
                    "label": 0
                },
                {
                    "sent": "X&OR is being put in feature Space, 5 is the mapping from X to ZTL in the state of training.",
                    "label": 1
                },
                {
                    "sent": "Examples from for the manyfold MLR for class L here.",
                    "label": 0
                },
                {
                    "sent": "Also, it's already degree metrics.",
                    "label": 0
                },
                {
                    "sent": "An ex TLD is a new simple that we have met classifying.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in the generalized space, let US project the new sample X 5X Field onto the manifold, or equivalently, onto the subspace spanned by 5 of TL.",
                    "label": 0
                },
                {
                    "sent": "Rather than actually we got two components, one which is coplanar and the other which is orthogonal to the manifold.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The test results from computer graphics that we're going to use.",
                    "label": 0
                },
                {
                    "sent": "Is that the perturbation of the proxy of the lead from you operator?",
                    "label": 1
                },
                {
                    "sent": "Mainly comes from the orthogonal components this.",
                    "label": 0
                },
                {
                    "sent": "It's possible, thanks to the properties of the Goshen Journal to rewrite a fair perturbation measure as such here.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we write as capital Phi, the metrics whose columns are the elements of Phi of TL, then the projector over the manifold or the subspace spanned by the training example is given by the formula here.",
                    "label": 0
                },
                {
                    "sent": "An with this projector, it's possible to compute the complainer components.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll skip all the computation, of course.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because, well, they're in the paper.",
                    "label": 0
                },
                {
                    "sent": "But these from Likins be written, such as here.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is interesting is that here we got the inverse of our proxy.",
                    "label": 0
                },
                {
                    "sent": "And here we.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Art vectors, which are finally the same vectors but one is the transpose of the other.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the our perturbation measure 4 by.",
                    "label": 0
                },
                {
                    "sent": "The simple text tiled onto the manifold L just read as here.",
                    "label": 0
                },
                {
                    "sent": "And so this is our perturbation measure.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And just to illustrate it, here are two figures.",
                    "label": 0
                },
                {
                    "sent": "So in the most one we got.",
                    "label": 1
                },
                {
                    "sent": "A manifold which simply is a spiral.",
                    "label": 0
                },
                {
                    "sent": "An we compute so this is manifold Milan we compute for edge pixel of the images.",
                    "label": 0
                },
                {
                    "sent": "Perturbation involved by this Pixel Ann recorded according to the amount of perturbation.",
                    "label": 0
                },
                {
                    "sent": "So if we had a pixel just.",
                    "label": 0
                },
                {
                    "sent": "On a training example, then there's no perturbation, and the further it is, the more the perturbation.",
                    "label": 0
                },
                {
                    "sent": "And on the right figure it's exactly the same.",
                    "label": 1
                },
                {
                    "sent": "But we only change Sigma, which is the variance of the Gaussian kernel.",
                    "label": 0
                },
                {
                    "sent": "So from this measure, it's really simple to derive.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classification algorithm.",
                    "label": 0
                },
                {
                    "sent": "During the training step, we simply gather all the training example for each class we compute the corresponding graph metrics in the kernel space and we invert these metrics.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then during the testing step.",
                    "label": 1
                },
                {
                    "sent": "We compute the dissimilarity of the new test sample that we are classifying for each.",
                    "label": 1
                },
                {
                    "sent": "Manyfold associate each class.",
                    "label": 1
                },
                {
                    "sent": "And then we associate the simple to the class, which was the least perturbated baby junction of the simple to the manifold.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is a small illustration yet.",
                    "label": 0
                },
                {
                    "sent": "So on the left we got a classification problem with two classes which are intermingled spirals.",
                    "label": 0
                },
                {
                    "sent": "A red one in blue on an.",
                    "label": 0
                },
                {
                    "sent": "Once again we classified all the pixels of the image according to this algorithm and all the red ones would have been classified in the red spiral, and Conversely for the blue.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Here the picture is exactly the same, but instead of to intermingle, spiroid or spiral we considered three normally distribution classes.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithm now for.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experiments of course.",
                    "label": 0
                },
                {
                    "sent": "We just did as simulated as well as real datasets so that the relatives came from the UCI machine learning repository.",
                    "label": 1
                },
                {
                    "sent": "We compared our algorithm to several algorithms of the state of the art which.",
                    "label": 1
                },
                {
                    "sent": "There's VMS, so here in the presentation I'll talk only about as because they were the best from all the reference algorithm.",
                    "label": 0
                },
                {
                    "sent": "Of course we are fully optimized.",
                    "label": 0
                },
                {
                    "sent": "The perimeter and hyperparameters of the SVM to buy cross validation to make sure that the comparison is no lose with respect to our method.",
                    "label": 0
                },
                {
                    "sent": "And we just also several version of portable, so I won't go in in the details because it would be a bit long.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In roughly from creative point of view, it appears that the performances of the table are similar to that of SVM.",
                    "label": 1
                },
                {
                    "sent": "A bit less interesting when there are a lot of missing values or there are a lot of binary variables because in such a case the approximation of class by your surface is with artificial.",
                    "label": 0
                },
                {
                    "sent": "But on the other end it was more efficient when we got more than two classes.",
                    "label": 0
                },
                {
                    "sent": "It also appears that depending on the problem, the best version of Turbo is not always the same, so it means that there's still some improvements in research carry on.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More precisely, here are the data set that we worked on.",
                    "label": 0
                },
                {
                    "sent": "So here are the simulated data set with a lot of class and a lot of variables and of components.",
                    "label": 0
                },
                {
                    "sent": "An below we got all the classical UCI machine learning datasets such as Ionosphere, diabites and so on.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are the results, so I won't go through all the accuracy rates.",
                    "label": 0
                },
                {
                    "sent": "I Simply put the green bullets.",
                    "label": 0
                },
                {
                    "sent": "When a portable is better and a red one, when it seems better?",
                    "label": 0
                },
                {
                    "sent": "And it appears that the performance are roughly similar.",
                    "label": 0
                },
                {
                    "sent": "So I did not compute insignificant C test because I do not claim that one algorithm is better than the other, so I do not put back into question the null hypothesis and then.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis test wouldn't bring anything.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As for future work.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our main focus is active learning.",
                    "label": 1
                },
                {
                    "sent": "In fact, it appears that it's really easy to compute the border between the classes with these algorithms, as it's simply the set of points for which the perturbation of the two least perturbated classes is the same.",
                    "label": 1
                },
                {
                    "sent": "An the consequence it's also releasing.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Able to define a small area around the border.",
                    "label": 0
                },
                {
                    "sent": "And then to query in this area.",
                    "label": 1
                },
                {
                    "sent": "That's this.",
                    "label": 1
                },
                {
                    "sent": "We've got a very efficient active learning policy.",
                    "label": 0
                },
                {
                    "sent": "An we apply this active learning policy.",
                    "label": 1
                },
                {
                    "sent": "Unbeatable, but otherwise as well.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other algorithms such as KNN here and it appears that the this active learning policies efficient, so I haven't much Riddle than what appear here because it's preliminary yet, but it sounds interesting.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An there are a lot of other links to do with other algorithms, so for instance, when the proxy of the matrix is not invertible, then we need to compute absolute inverse.",
                    "label": 0
                },
                {
                    "sent": "Which opened the door to all the metrics regularization techniques.",
                    "label": 0
                },
                {
                    "sent": "It also appear that the spectrum of K is exactly the same as the metrics which is considered in graph Laplacian Eigen map.",
                    "label": 1
                },
                {
                    "sent": "So this method also provide kind of a projection method for graduation again map.",
                    "label": 1
                },
                {
                    "sent": "The the perturbation measure that we use is also really really similar to some of the melanomas distance kernel space that as long proposed few years ago, we didn't success in making a strong link yet, but it's work in progress.",
                    "label": 1
                },
                {
                    "sent": "And finally, we'd like to study the various parameters and the various versions of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So there are very, very few.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in actually the only one is the variance of the Gaussian kernel, but nonetheless we'd like to investigate that a bit more in order to have a better understanding of the behavior of the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "You conclude them.",
                    "label": 0
                },
                {
                    "sent": "I would say that to build the classification algorithm inspired by computer graphic results.",
                    "label": 1
                },
                {
                    "sent": "With very few parameters to tune and the performance of which are similar to that of SVM, and there are a lot of perspective because I told you it's just a work in progress, but we found the 1st result rather appealing.",
                    "label": 1
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you for attention and thank you for having coming so soon in the morning.",
                    "label": 1
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Go ahead.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you approached the performance wise VM and you also told that in multi classification setting you achieve Tiger curacy but you don't show.",
                    "label": 0
                },
                {
                    "sent": "Do.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He's so probably you can facilitate this aspect in your presentation.",
                    "label": 0
                },
                {
                    "sent": "That is much.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I do for now.",
                    "label": 0
                },
                {
                    "sent": "These reasons are just plain memory, so I can't claim that our algorithm is better.",
                    "label": 0
                },
                {
                    "sent": "It's just kind of attendance is that we've put that when there are a lot of classes.",
                    "label": 0
                },
                {
                    "sent": "It appears to be a bit.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Better an, On the contrary, when there are missing values or lot of binary variables, and then it's less efficient.",
                    "label": 0
                },
                {
                    "sent": "But well, it's not really established yet, it's it's just well.",
                    "label": 0
                },
                {
                    "sent": "Observation by now.",
                    "label": 0
                },
                {
                    "sent": "What I only say is that.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Roughly, the performances are equivalent, so here for instance.",
                    "label": 0
                },
                {
                    "sent": "We are far better because of the binary variables or missing values, but on some others were better thanks to the fact that there is a lot of classes, so this is just a primary observation.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                },
                {
                    "sent": "Other questions, yes, compared to SVM, how does your algorithm scale to large data?",
                    "label": 0
                },
                {
                    "sent": "The main problem.",
                    "label": 0
                },
                {
                    "sent": "Rely in the training step.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, because we've got to invert metrics.",
                    "label": 0
                },
                {
                    "sent": "So if you begin time, I guess yeah, so if we got a huge amount of training set then.",
                    "label": 0
                },
                {
                    "sent": "These can be.",
                    "label": 0
                },
                {
                    "sent": "This can be quite long.",
                    "label": 0
                },
                {
                    "sent": "But there is a lot of techniques used in computer graphics to shorten these computation because well, in computer graphics they also need to invert this.",
                    "label": 0
                },
                {
                    "sent": "This type of metrics an you get that when.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or dealing with that many samples, then is becoming intractable, so there are some.",
                    "label": 0
                },
                {
                    "sent": "It's possible to perform some local approximation using only the close of samples to the region that you're interested in, so we haven't investigated how to shorten the computation time, but.",
                    "label": 0
                },
                {
                    "sent": "Will have to do it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because if you use approximations the accuracy will suffer.",
                    "label": 0
                },
                {
                    "sent": "It depends.",
                    "label": 0
                },
                {
                    "sent": "Well if we just simple around on a restricted area then yeah the accuracy will suffer.",
                    "label": 0
                },
                {
                    "sent": "But it's also possible to resample.",
                    "label": 0
                },
                {
                    "sent": "The manifold.",
                    "label": 0
                },
                {
                    "sent": "So that all the regions are represented, but with the number of samples which varies according to the complexity of the topology.",
                    "label": 0
                },
                {
                    "sent": "And this resampling does not need any.",
                    "label": 0
                },
                {
                    "sent": "It doesn't need to inverse matrix.",
                    "label": 0
                },
                {
                    "sent": "So then it's possible to have less examples, but which represents in a better way the manifold.",
                    "label": 0
                },
                {
                    "sent": "So then we expect that the accuracy will suffer to match.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "Well, let's thank the speaker again, thank you.",
                    "label": 1
                }
            ]
        }
    }
}