{
    "id": "fhvzekx3z32hbmbp6c6tpei6po2dj2qd",
    "title": "Personal Name Classification in Web Queries",
    "info": {
        "author": [
            "Dou Shen, Baidu, Inc."
        ],
        "published": "Feb. 25, 2008",
        "recorded": "February 2008",
        "category": [
            "Top->Computer Science->Web Search",
            "Top->Computer Science->Search Engines",
            "Top->Computer Science->Information Retrieval"
        ]
    },
    "url": "http://videolectures.net/wsdm08_shen_pncwq/",
    "segmentation": [
        [
            "Then here's the introduction.",
            "The goal of this work is to detect whether a web queries the personal name without referring to any other contextual information purely based on this query.",
            "So the motivation is because we have some observations, firstly 2 to 4% of daily web queries or personal names, and this number is almost doubled for the jumping queries.",
            "But jumping query I mean the users are not satisfied with the search results in a search engine and then jump to another search engine to try the query again.",
            "Certainly mostly you.",
            "There's 10 to test a search engine by their names, so I'm afraid everybody in this room have tried their names using search engine more than once I think.",
            "So it's very important to get better resource for people names.",
            "So it is clear that once we know a web queries of people name, we can use some specific strategies for these names to get a better search results.",
            "Actually, the people named Classifier can also be used in other applications.",
            "For example it can be used in paid search or sponge search.",
            "For example, once we know Toby Walker is so people name in the query.",
            "So we should not return the advertisement like wheeled walkers sale because Walker here has nothing to do with working anymore.",
            "The user is not interested in the advertisement at all.",
            "Another application is query suggestion.",
            "So once we know of queries people name then we can show some profile based information as the query suggestion.",
            "Say once we know Tom Cruise in the query then we can show some movies.",
            "Some of his movies as the query suggestion."
        ],
        [
            "So actually there's some work related to this paper.",
            "The first group is how to improve personal name search, so those via this study is some specific strategies for people named search, and they concluded that.",
            "The strategy for personal name should be different from the general queries.",
            "Another group of people is when and his colleagues.",
            "This study that person resolution system to improve the people search performance.",
            "Both of these work.",
            "They assume that we already know whether a web queries that people name or not.",
            "However, this is not easy actually.",
            "A second group of the work is people name extraction and recognition.",
            "So as a special case of named Entity people name extraction has been widely studied in the documents and web pages an emails.",
            "However our work is.",
            "Different from their work because we are going to rely on the query alone so we do not have much contextual information.",
            "So second group of work is web query enrichment, so we know you really a web query is very short, only two to three terms on average, so we need to find a way to enrich the web queries.",
            "So then we can precisely query one possible ways to use clickthrough rate.",
            "Click through data, enrich the web queries and other ways to use web search to enriched query.",
            "But we are not going to enrich the web query considering the efficiency issue."
        ],
        [
            "So here's the overview of our solution.",
            "It contains two stages.",
            "The first stage is offline training, so here, given some candidate first name or last name dictionaries, somehow we're going to find the probability of each term in the condensed candidate dictionary to be a people named term with this probabilistic dictionaries we can get an online class fire by using some personal name grammars and then calculated the probability of a query to be a name term."
        ],
        [
            "So here's a big picture of how of the offline training.",
            "I mean how to get the probabilistic additional dictionaries.",
            "So firstly we need to get some.",
            "Candidate dictionaries.",
            "And then somehow we get the context of each term in the dictionary and then using some way to estimate the probability of each term to be a name term."
        ],
        [
            "So before we go to the details of the offline training, lies explained several terminology.",
            "What is candidate dictionaries?",
            "By Candy dictionary I mean.",
            "Or the potential terms which can be named terms even some.",
            "Say Flowers rose.",
            "They also can be people name, right?",
            "So the second term is term context by current times I mean the context information for a term.",
            "Let's take Walker as an example or the right terms.",
            "The contextual information for the Walker.",
            "So four name term context.",
            "I mean, once we know a term is the people named term, then the contextual information for that term, I call it name, term, context.",
            "The final one is named context.",
            "This is the contact information for people name, so we're going to use these terms to define the way to find out the probability of a term to be a name term.",
            "So we tried four ways to estimate the probability one is relative frequency, another one is contextual context probability.",
            "The third highest currents in search snippets and final one is currently in background."
        ],
        [
            "So for the relative frequency we need to collect at site of names and then from this names we get the relative frequency for each term.",
            "For example, John show up 100 times in the names well to be shop just 10 times.",
            "Then we say OK the probability for John is 10 times higher than to be.",
            "The second solution is context probability.",
            "Here we have a simple assumption.",
            "So if a term.",
            "Username term then is term context should be named context.",
            "So with this basic assumption, we can change the unigram model over some name context.",
            "So we're going to show how to get the name context later.",
            "Now given a term, we first get his name is term context through search engines and then we calculate the probability of the term context using the trained model.",
            "Then we using this probability to show the property of this term to be a name term."
        ],
        [
            "So certain method is using the currency information in the search snippets.",
            "So given the term we get the term context through search engines.",
            "And at the end, among these search engine search results, we identify the name, term, context using some rules.",
            "For example, we need to check whether this term is followed by a last name term, whether this term is followed by her first name term and then a last name term, or whether this term is followed by a special case of verbs, such as did side announced acclaimed?",
            "So actually we have several more juice shown in the paper.",
            "So often knowing the name, term, context and the term context, we can ask to make that improbability of the retail between the number of name, term, context and the number of Tim context.",
            "Please note that we use last name terms and first name terms here to define the name, term, context.",
            "So it means that we have to know some terms which are already known to be first name or last name.",
            "So we assume we have such a small dictionary.",
            "We called its Golden dictionaries.",
            "So we are going to study the effect of the Golden Dictionaries in the experiments."
        ],
        [
            "The final.",
            "Method to estimate this probability is Co occurrence based in the backgrounds.",
            "So this method is similar to the service meet search snippet method but we didn't get the term context search engine.",
            "We get the term context from background files.",
            "This is for the time efficient issue."
        ],
        [
            "How would we get to the probabilistic dictionaries?",
            "Which means for each term in the dictionary we have a probability to show whether this term is going to be a name term.",
            "Then we can build a online classifier using some grammars.",
            "Given a query, we first pass this query using the grammars and then we calculate the probability of this query to be a name term using this geometric average.",
            "Here we use a small tricks.",
            "So we gave the probability of a title term and a suffix term.",
            "To be a name term as one.",
            "So in this case we're going to.",
            "Increase the probability of a query to be a name term once it contains some suffix and titles in the right place."
        ],
        [
            "Chen so here's the name class for a personal name.",
            "Grammars we used.",
            "So we define a people name.",
            "Started by an optional title and then followed by first name and then followed by an optional middle name and their last name.",
            "And finally I'm optional suffix similar we can define the title suffix, first name, middle name and last name.",
            "So it's clear that this grammar is for the US names, but it's not hard to extend this grammars to handle the non USA."
        ],
        [
            "So we tested our Masters through several experiments.",
            "This is the data side we used for the dictionaries week, like this 3 cans of dictionaries.",
            "The first one is DB LP, so we collect the author names from the DB RP.",
            "I'm afraid everybody is.",
            "Everyone's name is in this dictionary here, so another one is the sensor state with its collected from the website from the Census Bureau, they listed the Hot first name and last name, so the third one is the web page, which is kind of telephone book.",
            "So Please note we among these three dictionaries.",
            "Sensors is the smallest dictionary, but it is the purist.",
            "But for the Whitepages dictionary, it is the largest.",
            "However, it contains a lot of noise, such as.",
            "Office College Department.",
            "So we somehow need to use the method to estimate the probability to remove the noise.",
            "For the name context, we selected the top 2000 personal names from the web page and then submitted to Live Search to get 10 million name context for the term context, we submit 2 million candid terms to search engine and get 8 million term context.",
            "In order to test the performance of the classifier, we use the validation.",
            "This slide, which contains 2000 queries, among which there are 181 names.",
            "So we use the test data site with 10,000 queries, among which we have 232 names.",
            "To test the accuracy."
        ],
        [
            "We compare our method with two cans of baselines.",
            "The first one is dictionary based look up.",
            "So given the query we first pass this query using the grammars and then we check whether each term in the query shows up in the.",
            "Corresponding dictionaries, the second group of methods supervised method.",
            "We tried SVM and logistic regression as the classifiers.",
            "And then we design a bunch of features such as the length of the query, whether the query contains the title term.",
            "Whether the query contains the suffix term and the probability of each term in the query to be a first name term and the probability of term being generated by correction level.",
            "Background model twin over first name terms and some other features shown in the paper."
        ],
        [
            "So here this table.",
            "This table showed a comparison between different measures.",
            "The first reliance is our measure ended, the segments realizes the dictionary based look up and the last two lines.",
            "In supervised method, the four measured the DRP.",
            "Sensors in WP.",
            "They indicate that what kinds of Candida dictionaries we use.",
            "So for all these three method we use the Co occurrence information in the search snippets to estimate the probability and we use the sensors dictionary as the Golden Dictionary.",
            "So from this table we can see that the Prob dot sensors.",
            "This is my third.",
            "Can achieve the best precision and this my third can achieve the best recall.",
            "However the best F1 is achieved using this method.",
            "I mean using sensors of the Golden Dictionary and using web page is the candidate dictionary so the smallest and poorest dictionary is Golden and the largest is the candidate dictionary.",
            "We can also see that the image of this method is much higher than the supervised method.",
            "But more than 8%."
        ],
        [
            "So in this in this table we show that four different ways to calculate that improbabilities.",
            "For the first 2 methods we use WP.",
            "The Webpages dictionary is the Candies dictionary and using sensors is the Golden Dictionary.",
            "The from this table we can see that this method can achieve the best precision, recall and F1 does this because we can get more useful information from the search engine for each term."
        ],
        [
            "So this speaker showed the combination comparison comparison between different combination of Golden Dictionary Zancan dictionaries.",
            "So I'd like to remind you we use the Golden Dictionary to define the name term contact which is used to estimate the probability.",
            "From this figure we can see that using sensors, dictionaries as the Golden Dictionary and using Whitepages dictionary is the candidate we can achieve the best results.",
            "Actually comparing this combination with others, we can come to the conclusion tonight.",
            "Once we have a good Golden dictionary and a large candy addiction rate, we tend to have better results."
        ],
        [
            "Then we need to say OK, how can we get a better Golden dictionary?",
            "One way is to enlarge the Golden Dictionary so that we can define much more named Tim context without introducing noise.",
            "So this table show the results of enlarging the Golden dictionaries.",
            "Here we use the Sensors dictionary, an expansions as the Golden Dictionary, and then we use the web pages as the candidate dictionaries.",
            "This column shows the results of using sensors, the original Sensors Dictionary is the Golden Dictionary and for the column want column Five.",
            "We enrich the Golden Dictionary by trying to assign each time by selecting the top terms from the candidate dictionaries which has the largest probability to be a name term.",
            "So here we use the cooccurrence information in the search snippets to estimate the probability.",
            "The front of this table we can see that by enlarging the Golden Dictionary we can somehow improve the one measurement.",
            "However, if we enlarge the dictionary too much, the payments is going down."
        ],
        [
            "So another way to improve the classification result is to enlarge the candidate candidate dictionaries.",
            "So here we talk.",
            "Sensors data is the Golden Dictionary and we start from the sensor data as the Candid dictionary, an increase the candid dictionary.",
            "So the details of the method to enlarge the candid dictionaries given in the paper.",
            "So here for the.",
            "Add.",
            "We use bigram, the Co occurrence information in the background to estimate the probability.",
            "Here we do not use the search engine because it's going to take a lot of time.",
            "So we can see that increasing the candid dictionary can actually improve that.",
            "Performance, however, over in large is going to.",
            "Is not going to help anymore."
        ],
        [
            "So here's the concluding.",
            "Any future work.",
            "So in this paper we put forward easy but effective method for personal name classification in web queries.",
            "It is very effective considering that we only use the query information alone.",
            "And we exploit the measures of enlarging Golden dictionaries and candied ignorance.",
            "So with this method, we can build a comfortable classifier even we do not have large enough Golden dictionary and candid dictionary.",
            "So in the future, instead of using some Jews to define the name, term, context, we are going to use some.",
            "Named entity recognition algorithms.",
            "So we also hope to validate the contribution of personal name classification too.",
            "Web search in advertising.",
            "The final.",
            "We also hope to extend the classifier to handle some non US name."
        ],
        [
            "Here's the reference."
        ],
        [
            "Thanks.",
            "Do you have any questions for?",
            "Speaker.",
            "Sure.",
            "So I worry about the test set that right now when we're thinking about name queries, we're thinking about the name queries we're currently getting, and I'm thinking in the fullness of time, the problem is not going to be.",
            "How to find famous people in academics and the problem is going to be more like telephone directory.",
            "Look up that is, I want to find one of my neighbors and I'm wondering if the problem would be fundamentally different.",
            "So, for example, if I want to find Ian Anderson.",
            "Right now you probably would get me the guy on the, you know, the the band leader or the famous one, but there's probably many in every city and I might be looking for the one of my neighbors and I wonder if that would even change the problem of what is and what is not a name.",
            "That is, if I used as a test set the things that are in the phone book as opposed to the queries, how how much this work do you think would change?",
            "Anne.",
            "So let's talk, I mean.",
            "First, let's answer that question.",
            "So we need to care about that our neighbors.",
            "So in that case we still need to know whether queries are people name.",
            "So if we hope to build a long list of dictionaries, contain our potential names, and that dictionary will be very large considering the combination of all the first name and last name, there are potential names, so it's not easy to cover all the names in one dictionary, so we need.",
            "We still need to use this way to detect whether web queries.",
            "People name.",
            "And actually this function can be used.",
            "And the combined with the local search, I think to improve the performance, say to find out the neighbors.",
            "So once you know of queries that people name and then you can check the local search and then you can get information about your neighbors.",
            "So let me think about just a problem of, say, distinguishing a persons name from a city name.",
            "And if you just build larger dictionaries like, I could concatenate a bunch of phone books, but that would probably include most of the city names of the world, so that's probably not a good answer.",
            "Anne.",
            "So actually I think for the city names people names, maybe there and some other product names.",
            "Maybe we can design different classifiers for each type of.",
            "Entities.",
            "Did I answer the question?",
            "I'm not sure whether I catch it correctly.",
            "OK, anyone else?",
            "So.",
            "How well do the function things like titles and suffixes like?",
            "How well does that actually work?",
            "Is one really the right probability there?",
            "Yeah, maybe one is just I mean so as it's said that I still little trick is not well proved anyway so bad Tim.",
            "Once we know there's a tarasoff axina query is much more.",
            "Probably there's going to be a name term, so we using this to risk the probability.",
            "Thank you, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then here's the introduction.",
                    "label": 0
                },
                {
                    "sent": "The goal of this work is to detect whether a web queries the personal name without referring to any other contextual information purely based on this query.",
                    "label": 1
                },
                {
                    "sent": "So the motivation is because we have some observations, firstly 2 to 4% of daily web queries or personal names, and this number is almost doubled for the jumping queries.",
                    "label": 0
                },
                {
                    "sent": "But jumping query I mean the users are not satisfied with the search results in a search engine and then jump to another search engine to try the query again.",
                    "label": 0
                },
                {
                    "sent": "Certainly mostly you.",
                    "label": 1
                },
                {
                    "sent": "There's 10 to test a search engine by their names, so I'm afraid everybody in this room have tried their names using search engine more than once I think.",
                    "label": 0
                },
                {
                    "sent": "So it's very important to get better resource for people names.",
                    "label": 0
                },
                {
                    "sent": "So it is clear that once we know a web queries of people name, we can use some specific strategies for these names to get a better search results.",
                    "label": 0
                },
                {
                    "sent": "Actually, the people named Classifier can also be used in other applications.",
                    "label": 0
                },
                {
                    "sent": "For example it can be used in paid search or sponge search.",
                    "label": 0
                },
                {
                    "sent": "For example, once we know Toby Walker is so people name in the query.",
                    "label": 0
                },
                {
                    "sent": "So we should not return the advertisement like wheeled walkers sale because Walker here has nothing to do with working anymore.",
                    "label": 1
                },
                {
                    "sent": "The user is not interested in the advertisement at all.",
                    "label": 0
                },
                {
                    "sent": "Another application is query suggestion.",
                    "label": 0
                },
                {
                    "sent": "So once we know of queries people name then we can show some profile based information as the query suggestion.",
                    "label": 0
                },
                {
                    "sent": "Say once we know Tom Cruise in the query then we can show some movies.",
                    "label": 0
                },
                {
                    "sent": "Some of his movies as the query suggestion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So actually there's some work related to this paper.",
                    "label": 0
                },
                {
                    "sent": "The first group is how to improve personal name search, so those via this study is some specific strategies for people named search, and they concluded that.",
                    "label": 1
                },
                {
                    "sent": "The strategy for personal name should be different from the general queries.",
                    "label": 0
                },
                {
                    "sent": "Another group of people is when and his colleagues.",
                    "label": 0
                },
                {
                    "sent": "This study that person resolution system to improve the people search performance.",
                    "label": 1
                },
                {
                    "sent": "Both of these work.",
                    "label": 0
                },
                {
                    "sent": "They assume that we already know whether a web queries that people name or not.",
                    "label": 0
                },
                {
                    "sent": "However, this is not easy actually.",
                    "label": 0
                },
                {
                    "sent": "A second group of the work is people name extraction and recognition.",
                    "label": 0
                },
                {
                    "sent": "So as a special case of named Entity people name extraction has been widely studied in the documents and web pages an emails.",
                    "label": 1
                },
                {
                    "sent": "However our work is.",
                    "label": 0
                },
                {
                    "sent": "Different from their work because we are going to rely on the query alone so we do not have much contextual information.",
                    "label": 0
                },
                {
                    "sent": "So second group of work is web query enrichment, so we know you really a web query is very short, only two to three terms on average, so we need to find a way to enrich the web queries.",
                    "label": 0
                },
                {
                    "sent": "So then we can precisely query one possible ways to use clickthrough rate.",
                    "label": 0
                },
                {
                    "sent": "Click through data, enrich the web queries and other ways to use web search to enriched query.",
                    "label": 0
                },
                {
                    "sent": "But we are not going to enrich the web query considering the efficiency issue.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the overview of our solution.",
                    "label": 1
                },
                {
                    "sent": "It contains two stages.",
                    "label": 0
                },
                {
                    "sent": "The first stage is offline training, so here, given some candidate first name or last name dictionaries, somehow we're going to find the probability of each term in the condensed candidate dictionary to be a people named term with this probabilistic dictionaries we can get an online class fire by using some personal name grammars and then calculated the probability of a query to be a name term.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a big picture of how of the offline training.",
                    "label": 0
                },
                {
                    "sent": "I mean how to get the probabilistic additional dictionaries.",
                    "label": 0
                },
                {
                    "sent": "So firstly we need to get some.",
                    "label": 0
                },
                {
                    "sent": "Candidate dictionaries.",
                    "label": 0
                },
                {
                    "sent": "And then somehow we get the context of each term in the dictionary and then using some way to estimate the probability of each term to be a name term.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before we go to the details of the offline training, lies explained several terminology.",
                    "label": 0
                },
                {
                    "sent": "What is candidate dictionaries?",
                    "label": 0
                },
                {
                    "sent": "By Candy dictionary I mean.",
                    "label": 0
                },
                {
                    "sent": "Or the potential terms which can be named terms even some.",
                    "label": 0
                },
                {
                    "sent": "Say Flowers rose.",
                    "label": 0
                },
                {
                    "sent": "They also can be people name, right?",
                    "label": 0
                },
                {
                    "sent": "So the second term is term context by current times I mean the context information for a term.",
                    "label": 0
                },
                {
                    "sent": "Let's take Walker as an example or the right terms.",
                    "label": 0
                },
                {
                    "sent": "The contextual information for the Walker.",
                    "label": 0
                },
                {
                    "sent": "So four name term context.",
                    "label": 1
                },
                {
                    "sent": "I mean, once we know a term is the people named term, then the contextual information for that term, I call it name, term, context.",
                    "label": 0
                },
                {
                    "sent": "The final one is named context.",
                    "label": 0
                },
                {
                    "sent": "This is the contact information for people name, so we're going to use these terms to define the way to find out the probability of a term to be a name term.",
                    "label": 1
                },
                {
                    "sent": "So we tried four ways to estimate the probability one is relative frequency, another one is contextual context probability.",
                    "label": 1
                },
                {
                    "sent": "The third highest currents in search snippets and final one is currently in background.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the relative frequency we need to collect at site of names and then from this names we get the relative frequency for each term.",
                    "label": 1
                },
                {
                    "sent": "For example, John show up 100 times in the names well to be shop just 10 times.",
                    "label": 0
                },
                {
                    "sent": "Then we say OK the probability for John is 10 times higher than to be.",
                    "label": 0
                },
                {
                    "sent": "The second solution is context probability.",
                    "label": 0
                },
                {
                    "sent": "Here we have a simple assumption.",
                    "label": 0
                },
                {
                    "sent": "So if a term.",
                    "label": 0
                },
                {
                    "sent": "Username term then is term context should be named context.",
                    "label": 1
                },
                {
                    "sent": "So with this basic assumption, we can change the unigram model over some name context.",
                    "label": 0
                },
                {
                    "sent": "So we're going to show how to get the name context later.",
                    "label": 0
                },
                {
                    "sent": "Now given a term, we first get his name is term context through search engines and then we calculate the probability of the term context using the trained model.",
                    "label": 1
                },
                {
                    "sent": "Then we using this probability to show the property of this term to be a name term.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So certain method is using the currency information in the search snippets.",
                    "label": 0
                },
                {
                    "sent": "So given the term we get the term context through search engines.",
                    "label": 1
                },
                {
                    "sent": "And at the end, among these search engine search results, we identify the name, term, context using some rules.",
                    "label": 0
                },
                {
                    "sent": "For example, we need to check whether this term is followed by a last name term, whether this term is followed by her first name term and then a last name term, or whether this term is followed by a special case of verbs, such as did side announced acclaimed?",
                    "label": 1
                },
                {
                    "sent": "So actually we have several more juice shown in the paper.",
                    "label": 0
                },
                {
                    "sent": "So often knowing the name, term, context and the term context, we can ask to make that improbability of the retail between the number of name, term, context and the number of Tim context.",
                    "label": 0
                },
                {
                    "sent": "Please note that we use last name terms and first name terms here to define the name, term, context.",
                    "label": 0
                },
                {
                    "sent": "So it means that we have to know some terms which are already known to be first name or last name.",
                    "label": 1
                },
                {
                    "sent": "So we assume we have such a small dictionary.",
                    "label": 0
                },
                {
                    "sent": "We called its Golden dictionaries.",
                    "label": 0
                },
                {
                    "sent": "So we are going to study the effect of the Golden Dictionaries in the experiments.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The final.",
                    "label": 0
                },
                {
                    "sent": "Method to estimate this probability is Co occurrence based in the backgrounds.",
                    "label": 0
                },
                {
                    "sent": "So this method is similar to the service meet search snippet method but we didn't get the term context search engine.",
                    "label": 0
                },
                {
                    "sent": "We get the term context from background files.",
                    "label": 1
                },
                {
                    "sent": "This is for the time efficient issue.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How would we get to the probabilistic dictionaries?",
                    "label": 0
                },
                {
                    "sent": "Which means for each term in the dictionary we have a probability to show whether this term is going to be a name term.",
                    "label": 0
                },
                {
                    "sent": "Then we can build a online classifier using some grammars.",
                    "label": 1
                },
                {
                    "sent": "Given a query, we first pass this query using the grammars and then we calculate the probability of this query to be a name term using this geometric average.",
                    "label": 0
                },
                {
                    "sent": "Here we use a small tricks.",
                    "label": 0
                },
                {
                    "sent": "So we gave the probability of a title term and a suffix term.",
                    "label": 0
                },
                {
                    "sent": "To be a name term as one.",
                    "label": 0
                },
                {
                    "sent": "So in this case we're going to.",
                    "label": 0
                },
                {
                    "sent": "Increase the probability of a query to be a name term once it contains some suffix and titles in the right place.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chen so here's the name class for a personal name.",
                    "label": 1
                },
                {
                    "sent": "Grammars we used.",
                    "label": 0
                },
                {
                    "sent": "So we define a people name.",
                    "label": 0
                },
                {
                    "sent": "Started by an optional title and then followed by first name and then followed by an optional middle name and their last name.",
                    "label": 1
                },
                {
                    "sent": "And finally I'm optional suffix similar we can define the title suffix, first name, middle name and last name.",
                    "label": 1
                },
                {
                    "sent": "So it's clear that this grammar is for the US names, but it's not hard to extend this grammars to handle the non USA.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we tested our Masters through several experiments.",
                    "label": 0
                },
                {
                    "sent": "This is the data side we used for the dictionaries week, like this 3 cans of dictionaries.",
                    "label": 0
                },
                {
                    "sent": "The first one is DB LP, so we collect the author names from the DB RP.",
                    "label": 0
                },
                {
                    "sent": "I'm afraid everybody is.",
                    "label": 0
                },
                {
                    "sent": "Everyone's name is in this dictionary here, so another one is the sensor state with its collected from the website from the Census Bureau, they listed the Hot first name and last name, so the third one is the web page, which is kind of telephone book.",
                    "label": 0
                },
                {
                    "sent": "So Please note we among these three dictionaries.",
                    "label": 0
                },
                {
                    "sent": "Sensors is the smallest dictionary, but it is the purist.",
                    "label": 0
                },
                {
                    "sent": "But for the Whitepages dictionary, it is the largest.",
                    "label": 0
                },
                {
                    "sent": "However, it contains a lot of noise, such as.",
                    "label": 0
                },
                {
                    "sent": "Office College Department.",
                    "label": 0
                },
                {
                    "sent": "So we somehow need to use the method to estimate the probability to remove the noise.",
                    "label": 0
                },
                {
                    "sent": "For the name context, we selected the top 2000 personal names from the web page and then submitted to Live Search to get 10 million name context for the term context, we submit 2 million candid terms to search engine and get 8 million term context.",
                    "label": 1
                },
                {
                    "sent": "In order to test the performance of the classifier, we use the validation.",
                    "label": 1
                },
                {
                    "sent": "This slide, which contains 2000 queries, among which there are 181 names.",
                    "label": 1
                },
                {
                    "sent": "So we use the test data site with 10,000 queries, among which we have 232 names.",
                    "label": 0
                },
                {
                    "sent": "To test the accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We compare our method with two cans of baselines.",
                    "label": 0
                },
                {
                    "sent": "The first one is dictionary based look up.",
                    "label": 0
                },
                {
                    "sent": "So given the query we first pass this query using the grammars and then we check whether each term in the query shows up in the.",
                    "label": 0
                },
                {
                    "sent": "Corresponding dictionaries, the second group of methods supervised method.",
                    "label": 0
                },
                {
                    "sent": "We tried SVM and logistic regression as the classifiers.",
                    "label": 0
                },
                {
                    "sent": "And then we design a bunch of features such as the length of the query, whether the query contains the title term.",
                    "label": 1
                },
                {
                    "sent": "Whether the query contains the suffix term and the probability of each term in the query to be a first name term and the probability of term being generated by correction level.",
                    "label": 1
                },
                {
                    "sent": "Background model twin over first name terms and some other features shown in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here this table.",
                    "label": 0
                },
                {
                    "sent": "This table showed a comparison between different measures.",
                    "label": 0
                },
                {
                    "sent": "The first reliance is our measure ended, the segments realizes the dictionary based look up and the last two lines.",
                    "label": 1
                },
                {
                    "sent": "In supervised method, the four measured the DRP.",
                    "label": 0
                },
                {
                    "sent": "Sensors in WP.",
                    "label": 0
                },
                {
                    "sent": "They indicate that what kinds of Candida dictionaries we use.",
                    "label": 0
                },
                {
                    "sent": "So for all these three method we use the Co occurrence information in the search snippets to estimate the probability and we use the sensors dictionary as the Golden Dictionary.",
                    "label": 0
                },
                {
                    "sent": "So from this table we can see that the Prob dot sensors.",
                    "label": 0
                },
                {
                    "sent": "This is my third.",
                    "label": 0
                },
                {
                    "sent": "Can achieve the best precision and this my third can achieve the best recall.",
                    "label": 0
                },
                {
                    "sent": "However the best F1 is achieved using this method.",
                    "label": 0
                },
                {
                    "sent": "I mean using sensors of the Golden Dictionary and using web page is the candidate dictionary so the smallest and poorest dictionary is Golden and the largest is the candidate dictionary.",
                    "label": 0
                },
                {
                    "sent": "We can also see that the image of this method is much higher than the supervised method.",
                    "label": 0
                },
                {
                    "sent": "But more than 8%.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this in this table we show that four different ways to calculate that improbabilities.",
                    "label": 1
                },
                {
                    "sent": "For the first 2 methods we use WP.",
                    "label": 0
                },
                {
                    "sent": "The Webpages dictionary is the Candies dictionary and using sensors is the Golden Dictionary.",
                    "label": 0
                },
                {
                    "sent": "The from this table we can see that this method can achieve the best precision, recall and F1 does this because we can get more useful information from the search engine for each term.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this speaker showed the combination comparison comparison between different combination of Golden Dictionary Zancan dictionaries.",
                    "label": 1
                },
                {
                    "sent": "So I'd like to remind you we use the Golden Dictionary to define the name term contact which is used to estimate the probability.",
                    "label": 0
                },
                {
                    "sent": "From this figure we can see that using sensors, dictionaries as the Golden Dictionary and using Whitepages dictionary is the candidate we can achieve the best results.",
                    "label": 0
                },
                {
                    "sent": "Actually comparing this combination with others, we can come to the conclusion tonight.",
                    "label": 0
                },
                {
                    "sent": "Once we have a good Golden dictionary and a large candy addiction rate, we tend to have better results.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we need to say OK, how can we get a better Golden dictionary?",
                    "label": 0
                },
                {
                    "sent": "One way is to enlarge the Golden Dictionary so that we can define much more named Tim context without introducing noise.",
                    "label": 0
                },
                {
                    "sent": "So this table show the results of enlarging the Golden dictionaries.",
                    "label": 1
                },
                {
                    "sent": "Here we use the Sensors dictionary, an expansions as the Golden Dictionary, and then we use the web pages as the candidate dictionaries.",
                    "label": 0
                },
                {
                    "sent": "This column shows the results of using sensors, the original Sensors Dictionary is the Golden Dictionary and for the column want column Five.",
                    "label": 0
                },
                {
                    "sent": "We enrich the Golden Dictionary by trying to assign each time by selecting the top terms from the candidate dictionaries which has the largest probability to be a name term.",
                    "label": 0
                },
                {
                    "sent": "So here we use the cooccurrence information in the search snippets to estimate the probability.",
                    "label": 0
                },
                {
                    "sent": "The front of this table we can see that by enlarging the Golden Dictionary we can somehow improve the one measurement.",
                    "label": 0
                },
                {
                    "sent": "However, if we enlarge the dictionary too much, the payments is going down.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another way to improve the classification result is to enlarge the candidate candidate dictionaries.",
                    "label": 1
                },
                {
                    "sent": "So here we talk.",
                    "label": 0
                },
                {
                    "sent": "Sensors data is the Golden Dictionary and we start from the sensor data as the Candid dictionary, an increase the candid dictionary.",
                    "label": 0
                },
                {
                    "sent": "So the details of the method to enlarge the candid dictionaries given in the paper.",
                    "label": 0
                },
                {
                    "sent": "So here for the.",
                    "label": 0
                },
                {
                    "sent": "Add.",
                    "label": 0
                },
                {
                    "sent": "We use bigram, the Co occurrence information in the background to estimate the probability.",
                    "label": 0
                },
                {
                    "sent": "Here we do not use the search engine because it's going to take a lot of time.",
                    "label": 0
                },
                {
                    "sent": "So we can see that increasing the candid dictionary can actually improve that.",
                    "label": 0
                },
                {
                    "sent": "Performance, however, over in large is going to.",
                    "label": 0
                },
                {
                    "sent": "Is not going to help anymore.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the concluding.",
                    "label": 0
                },
                {
                    "sent": "Any future work.",
                    "label": 0
                },
                {
                    "sent": "So in this paper we put forward easy but effective method for personal name classification in web queries.",
                    "label": 1
                },
                {
                    "sent": "It is very effective considering that we only use the query information alone.",
                    "label": 1
                },
                {
                    "sent": "And we exploit the measures of enlarging Golden dictionaries and candied ignorance.",
                    "label": 0
                },
                {
                    "sent": "So with this method, we can build a comfortable classifier even we do not have large enough Golden dictionary and candid dictionary.",
                    "label": 0
                },
                {
                    "sent": "So in the future, instead of using some Jews to define the name, term, context, we are going to use some.",
                    "label": 0
                },
                {
                    "sent": "Named entity recognition algorithms.",
                    "label": 1
                },
                {
                    "sent": "So we also hope to validate the contribution of personal name classification too.",
                    "label": 0
                },
                {
                    "sent": "Web search in advertising.",
                    "label": 0
                },
                {
                    "sent": "The final.",
                    "label": 0
                },
                {
                    "sent": "We also hope to extend the classifier to handle some non US name.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's the reference.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Do you have any questions for?",
                    "label": 0
                },
                {
                    "sent": "Speaker.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "So I worry about the test set that right now when we're thinking about name queries, we're thinking about the name queries we're currently getting, and I'm thinking in the fullness of time, the problem is not going to be.",
                    "label": 0
                },
                {
                    "sent": "How to find famous people in academics and the problem is going to be more like telephone directory.",
                    "label": 0
                },
                {
                    "sent": "Look up that is, I want to find one of my neighbors and I'm wondering if the problem would be fundamentally different.",
                    "label": 0
                },
                {
                    "sent": "So, for example, if I want to find Ian Anderson.",
                    "label": 0
                },
                {
                    "sent": "Right now you probably would get me the guy on the, you know, the the band leader or the famous one, but there's probably many in every city and I might be looking for the one of my neighbors and I wonder if that would even change the problem of what is and what is not a name.",
                    "label": 0
                },
                {
                    "sent": "That is, if I used as a test set the things that are in the phone book as opposed to the queries, how how much this work do you think would change?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So let's talk, I mean.",
                    "label": 0
                },
                {
                    "sent": "First, let's answer that question.",
                    "label": 0
                },
                {
                    "sent": "So we need to care about that our neighbors.",
                    "label": 0
                },
                {
                    "sent": "So in that case we still need to know whether queries are people name.",
                    "label": 0
                },
                {
                    "sent": "So if we hope to build a long list of dictionaries, contain our potential names, and that dictionary will be very large considering the combination of all the first name and last name, there are potential names, so it's not easy to cover all the names in one dictionary, so we need.",
                    "label": 0
                },
                {
                    "sent": "We still need to use this way to detect whether web queries.",
                    "label": 0
                },
                {
                    "sent": "People name.",
                    "label": 0
                },
                {
                    "sent": "And actually this function can be used.",
                    "label": 0
                },
                {
                    "sent": "And the combined with the local search, I think to improve the performance, say to find out the neighbors.",
                    "label": 0
                },
                {
                    "sent": "So once you know of queries that people name and then you can check the local search and then you can get information about your neighbors.",
                    "label": 0
                },
                {
                    "sent": "So let me think about just a problem of, say, distinguishing a persons name from a city name.",
                    "label": 0
                },
                {
                    "sent": "And if you just build larger dictionaries like, I could concatenate a bunch of phone books, but that would probably include most of the city names of the world, so that's probably not a good answer.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So actually I think for the city names people names, maybe there and some other product names.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can design different classifiers for each type of.",
                    "label": 0
                },
                {
                    "sent": "Entities.",
                    "label": 0
                },
                {
                    "sent": "Did I answer the question?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether I catch it correctly.",
                    "label": 0
                },
                {
                    "sent": "OK, anyone else?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How well do the function things like titles and suffixes like?",
                    "label": 0
                },
                {
                    "sent": "How well does that actually work?",
                    "label": 0
                },
                {
                    "sent": "Is one really the right probability there?",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe one is just I mean so as it's said that I still little trick is not well proved anyway so bad Tim.",
                    "label": 0
                },
                {
                    "sent": "Once we know there's a tarasoff axina query is much more.",
                    "label": 0
                },
                {
                    "sent": "Probably there's going to be a name term, so we using this to risk the probability.",
                    "label": 0
                },
                {
                    "sent": "Thank you, thanks.",
                    "label": 0
                }
            ]
        }
    }
}