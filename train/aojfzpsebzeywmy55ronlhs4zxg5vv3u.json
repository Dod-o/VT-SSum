{
    "id": "aojfzpsebzeywmy55ronlhs4zxg5vv3u",
    "title": "Traffic Sign Recognition Using Discriminative Local Features",
    "info": {
        "author": [
            "Andrzej Ruta, Brunel University"
        ],
        "published": "Oct. 8, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ida07_ruta_tsr/",
    "segmentation": [
        [
            "The subject of my presentation today is a traffic sign recognition using discriminative local features, which as you might guess, is a purely machine vision related problem.",
            "My name is Andre Delta and the work has been conducted under the supervision of Doctor Young Million Professor who will you?"
        ],
        [
            "Rapid look in the agenda.",
            "I will start with the formulation of the problem and introduced the discuss the main characteristics.",
            "In the second part I will concentrate on something that we think is our primary contribution this work.",
            "Which is the novel image representation based on the.",
            "Discriminative, local regions.",
            "If time allows in the second part, I'll try to outline the main functional modules of our prototype recognition traffic sign recognition system in which we incorporate our novel algorithms and a few words of conclusion at the very end."
        ],
        [
            "So.",
            "As the scheme illustrates actual problem to solve seems to be quite straightforward, namely, if we ask if we imagine a human driving a car.",
            "And a camera which is mounted in front of the windscreen.",
            "Then whenever a Rd sign emerges in the scene, our recognition system.",
            "Based on the.",
            "Video input from the camera is expected to.",
            "Detect and correctly recognize Rd sign and obviously produce an output, some kind of meaningful signal so that the so that the driver can react properly just sign.",
            "So we know the input we more or less know the output.",
            "Several important points to consider when dealing with such a problem are the following first.",
            "A huge a priori knowledge is available about the traffic science because full specifications are given in terms of the template images, one can easily down download such images from the Internet, for example.",
            "Another point is that we should be aware of many factors, potentially severely degrading performance of a system like this, and these are very illumination, uneven motion of a car, sudden light reflection.",
            "And various other kinds of noise from different sources.",
            "Also, the real time performance requirement is quite critical in this at this point because they emphasize we are not here consent with just still camera images, but a video sequences, which means the processing must be fast enough and the cost of high cost of false positives and false negatives is something that does not require too much explanation here I think.",
            "We know that the well human driver's life is at stake."
        ],
        [
            "In this case.",
            "I was starting point to define image novel image representation.",
            "Is the discretisation of color palette in the images?",
            "We should take we should know that whenever our objects of interest are logically composed of just several colors, it is practical to discretize, collapse the color palette into several distinct, meaningful colors.",
            "This not only helps to helps reduce computation, but also helps to avoid ambiguities whenever.",
            "Whenever real life image of an object is compared to the template already containing just clean and sparse colors.",
            "We've got we're facing two scenarios in fact.",
            "First we need to discretize colors in the clean template images.",
            "But this image is already in fact container clean, distinct colors.",
            "So in this case we're just aiming at changing the physical representation of an image from, let's say 24 bit bitmap into just two bits encoding relevant colors.",
            "And it can be done by any available technique.",
            "Literally very simple ones like for example thresholding in Hue, saturation value, color space.",
            "When we when we have real life images, natural images problem is slightly more demanding.",
            "Our idea to discretize color in such images is to model each distinct color, which with a Gaussian mixture.",
            "How do we do that?",
            "Basically we use as training data.",
            "Pre labeled pixels from the training sample.",
            "Training traffic video sequences from the regions.",
            "Speaking the signs, we simply pick the pixels with already known color, so this is purely a supervised training.",
            "We initialize our Gaussian mixtures for each color.",
            "Randomly and run an EM algorithm until convergence.",
            "To refine our estimation.",
            "We repeat this procedure several times for different initializations of Goshen components.",
            "And for also for different numbers of such components and in the end we pick the most likely most best model in the meaning of highest mean data likelihood.",
            "Once we've got model trained, we can make an online assignment of color to RGB pixels.",
            "By just picking the best model, meaning that most model that would most likely generate such a test RGB pixel."
        ],
        [
            "This is the sample output from such a discretization.",
            "In the upper row you can see natural images extracted from the real frames from the real video.",
            "In the lower row you can see the result of discretization using in Goshen mixture models.",
            "You can also see that the background fragments are masked out already.",
            "So results are quite accurate."
        ],
        [
            "Let's now define color distance transform.",
            "Basically, distance transform is a tool used popularly in the area of computer vision too.",
            "This is defined for binary images and used to define for each image location, a kind of.",
            "What distance to the nearest feature pixel that is that true when pixel with a value through the binary image?",
            "The problem is that we don't have binary image, but rather 2 bit image with up to four colors encoded.",
            "So the trick we use is just.",
            "To treat each distinct color to treat pixels of that color as feature, pixels and pixels of any other color as non feature pixels.",
            "This way we obtain.",
            "Different binary images independently and for each of them we calculate the standard distance trance formula in a well known way.",
            "The chunk for metric popular approximation to the Euclidean distance is used as a measure distance map metrics here.",
            "Please have a look at the example output on the left you can see in the original image of a template Rd sign.",
            "Quite well known.",
            "I think the color distance transform corresponding to the black color white color and red color, respectively can be seen on the right.",
            "So as we can see, the CDT defines the kind of smooth distance measure.",
            "Which as we as we will, as it will be shown, can be used effectively in the task of template matching."
        ],
        [
            "Now the.",
            "Let's introduce the notion of local regions in the local dissimilarity.",
            "Imagine we've got.",
            "Template image of a Rd sign like this.",
            "We just cover it with a grid regular grid, subdividing the image into smaller subregions.",
            "Now let's concentrate on a small region like this.",
            "We can now introduce several quantities characterizing the local similarity between the two images.",
            "With respect to a single region, OS, or over a set containing multiple regions.",
            "Definitions are quite obvious actually.",
            "They are just the average is some sort.",
            "What calls for explanation is.",
            "Is the meaning of DCDT.",
            "Actually, the computer to know to get value of DCT for pixel of coordinates C&T we need a discrete color representation of image I the the.",
            "Color distance transform image of.",
            "Of image and we simply check the color of the pixel in I.",
            "Then we refer to the appropriate color distance transform corresponding to that color in J and we pick the appropriate value.",
            "In other words, we.",
            "Big."
        ],
        [
            "Appropriate value from the images from from the correct appropriate images.",
            "One of these."
        ],
        [
            "The other notions are just defined on top of the first one, and the weights in the second in the third case are used to denote that some regions might be more important to us for some reason."
        ],
        [
            "Now.",
            "Our main goal is to be able to correctly classify them unknown image exchange.",
            "Coming from the input video we've got.",
            "Category available.",
            "Templates roadsigns TI and we want to determine this class by maximizing the posterior term like this we can see here model parameters Theta I which the indexes to denote that the model parameters are different for different classes.",
            "So important to realize that the first parameter is a kind of indexing variable which determines.",
            "Subset of regions to be used the best characterizes given class.",
            "And WI is there is a vector of weights corresponding to these regions.",
            "In order to learn the best model parameters, we define kind of objective function with which we want to maximize.",
            "And now is this important to realize what such a maximization means, it simply means that we aim at retrieving for a given class such a compact and small number of local regions.",
            "Within which that particular class looks possibly the most different from all other classes.",
            "Which we want to recognize.",
            "So we want to capture as much dissimilarity as possible within a compact representation."
        ],
        [
            "The implementation of that.",
            "The training we should say.",
            "Contains the elements of a technique known as forward feature selection for what selection and I will explain it in using just a few figures.",
            "Imagine we've got our target class, let's call it.",
            "TII will target template image and all other classes TJS.",
            "We make individually comparison between T and all the TJ's.",
            "Now for each of such comparisons we obtain a kind of dissimilarity map by evaluating the similarity within each possible region, and from that we obtain a ranking of this region.",
            "So we just sort them according to the decreasing similarity.",
            "What we do we first pick the first most dissimilar region, remember.",
            "Similarity for it.",
            "Then we fix that region and at the same time we.",
            "Remove it from the pool of available regions so that it can be selected again.",
            "And we continue doing this same thing.",
            "We picked the second most dissimilar region again.",
            "Remember this similarity.",
            "And calculate the average similarity.",
            "Between images being compared.",
            "Over the region set consisting just added regions and all previously added regions.",
            "So in this case it is a two element set.",
            "We continue like this.",
            "Until yeah and that is the point, we should introduce some kind of stop criterion because.",
            "Otherwise we would select eventually every region which is not our goal.",
            "We want representation to be compact.",
            "And well to define the sub criterion we introduce.",
            "That threshold, which we call the similarity threshold, is that TD.",
            "What does that condition?",
            "Meanwhile we just stop adding new regions to our region set.",
            "When the average dissimilarity over our current region set goes below some fixed percentage of the most highest possible dissimilarity.",
            "Highest possible dissimilarity is that the similarity, which is obvious because the regions are ranked sorted."
        ],
        [
            "And this slide illustrates how the target representation is assembled from each individual comparisons we obtain kind of rankings.",
            "The numbers here illustrate quality or the similarity of the regions.",
            "As we can see in the 1st and 3rd comparison for four regions were selected before meeting this top condition here 5.",
            "We just finally do merging of these ranks.",
            "Like this?",
            "So the procedure is indeed very simple.",
            "Whenever, whenever a region was selected at least once, it is just transferred to the target region set.",
            "With its rank, if that region was selected multiple number of times, then then the regions are, the ranks are merged with this sound.",
            "And finally, we can normalize these weights by.",
            "To the range between 01, these are our regional weights.",
            "Higher weight, obviously it means that the more discriminative power given the region has.",
            "Because it captures the larger amount of the similarity between our target class and the other classes.",
            "This is the sample output.",
            "The brighter regions here, here.",
            "Denote these regions which were assigned to the highest weights.",
            "As we can see, most of the regions are zero or black and they are not selected at all.",
            "It is important not to realize one fact that the procedure is indeed run independently for each class, which yields somehow completely independent representation, and it induces also independent classifiers.",
            "Meaning that.",
            "Each of these classifiers is somehow trained to recognize that one particular class, but.",
            "Because of the way the similarity threshold was introduced.",
            "We can make a following statement, namely.",
            "Decisions made made by such independent classifiers can be made directly compatible because the similarity threshold guarantees that the same amount of the similarity is captured in each individual model.",
            "So this is something that.",
            "Several other techniques, like principal component analysis, can't do because the dimensionality is fixed.",
            "Here it is not fixed.",
            "Number of discriminative regions might differ, and in fact it differs.",
            "However the same in terms of the similarity.",
            "The same amount is captured in each model.",
            "In conclusion, we think that because of that because of that conclusion, we can now apply a very simple.",
            "Classification technique based on the minimum distance."
        ],
        [
            "Map.",
            "Just a few words about the hour traffic sign recognition system."
        ],
        [
            "Very briefly.",
            "Basically, it consists on several several modules.",
            "However, image representation is something most important to us.",
            "Obviously some image processing is done within the system too, which is intended to mainly to identify the regions of interest and plus to highlight the relevant features for the detector, which is color basically on edges.",
            "The detection module makes use of a recently published technique of law and bounds.",
            "Which is a kind of generalization of circular Hough transform.",
            "While learning computer vision, it is designed in such a clever way that is able to detect all instances of equiangular polygons and the road signs are indeed instances of such polygons, even including circles that can be considered as such.",
            "The tracking isn't.",
            "Another module is used to reduce computation.",
            "We just employ here a common filter, assuming very strong.",
            "Map motion assumptions, namely, that the car is moving with a constant velocity along the optical axis of the camera, and so the tracking is done in purely geometrical fashion.",
            "And in fact, what is struck is the local search region.",
            "But within such a region.",
            "Signed this already detected is again detected but locally.",
            "So the same login bars detector does the whole work.",
            "And in terms of the representation, as I said.",
            "The discriminative region model or representation is trained independently for each for each sign, just based on the on the template images, nothing more.",
            "And this similarity threshold is tuned individually to each side category.",
            "We distinguish between four categories.",
            "Corresponding to warning signs, the caution cautionary signs, information, signs, signs giving orders and prohibitions."
        ],
        [
            "Just one more slide about classification.",
            "We use a maximum likelihood approach and by.",
            "By making somewhat very strong assumptions that the similarity within local regions or is Gaussian distributed, and.",
            "And independent of one another, we convert it into minimization of distance, but as a distance metric we use our our average dissimilarity weighted dissimilarity over the region set SDSD these parameters as the end.",
            "As in W. These learned in the training stage.",
            "So in summing up classification runs.",
            "But you know template matching fashion, but template matching with respect to the individual representation class specific representations.",
            "We do a simple temporal integration by assuming also that.",
            "Observations are independent in consecutive frames, so we just minimizing the accumulated distance."
        ],
        [
            "And just a.",
            "Results.",
            "Real life data was used as a test data for sign categories.",
            "The numbers here correspond to the numbers of classes in each category.",
            "So in total we have 135, which is a pretty large game of science.",
            "In terms of the classification performance in a best settings of.",
            "The similarity threshold.",
            "93.5 correct classification rate was achieved."
        ],
        [
            "The also here we can see a sample, just screenshots from a video at 30 frames per second it was tracing the House."
        ],
        [
            "Detection works.",
            "But maybe I will not explain it day of this."
        ],
        [
            "Why?",
            "Because we're short of time.",
            "And conclusions my still.",
            "Current solution is may be decent for Academy purposes, but if you wanted to, for example, sell it as a commercial product, we would have to make more effort.",
            "To eliminate certain occurrences, undesirable ones, large game of science, recognized performance is OK compatible to the state of the art.",
            "Recently published our main contribution.",
            "Here is a representation of roadsigns through discriminative local regions, which seems to have quite a lot of advantages over alternative feature selection methods.",
            "Further work is planned in several independent directions, but.",
            "Let's stop at this point."
        ],
        [
            "Thank you very much for your time.",
            "We have time for some questions.",
            "How do you deal with the difference in distance between the object sending and camera?",
            "Do you scale the image or you just take several examples for different distances?",
            "Uh, well actually common filter.",
            "I mentioned this tracking the object location, tracking the local search region overtime.",
            "But then also the variety parameters from the common filter can be used to roughly to estimate the size of our object.",
            "So this is an indication for the for the shape detector of, sorry.",
            "Exactly, yeah.",
            "Quick question.",
            "Can talk once you detect object detection itself from detection.",
            "So if you need to compare yes exactly, I mentioned it earlier.",
            "Something with the scale which may be different, scaling position, well intentioned scale once the object is detected, this rescaled to common size.",
            "We assume some common size.",
            "How do you do any different?",
            "This lies in the in the way the regular Polygon detects detector works, which is quite out of the scope of the of the presentation, but it can deal with multiple sizes.",
            "Polygon polygons, however the tracking is only as I mentioned, is only used to track overtime.",
            "The search region.",
            "It does not directly affect the detection results.",
            "OK, let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The subject of my presentation today is a traffic sign recognition using discriminative local features, which as you might guess, is a purely machine vision related problem.",
                    "label": 0
                },
                {
                    "sent": "My name is Andre Delta and the work has been conducted under the supervision of Doctor Young Million Professor who will you?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rapid look in the agenda.",
                    "label": 0
                },
                {
                    "sent": "I will start with the formulation of the problem and introduced the discuss the main characteristics.",
                    "label": 0
                },
                {
                    "sent": "In the second part I will concentrate on something that we think is our primary contribution this work.",
                    "label": 0
                },
                {
                    "sent": "Which is the novel image representation based on the.",
                    "label": 1
                },
                {
                    "sent": "Discriminative, local regions.",
                    "label": 0
                },
                {
                    "sent": "If time allows in the second part, I'll try to outline the main functional modules of our prototype recognition traffic sign recognition system in which we incorporate our novel algorithms and a few words of conclusion at the very end.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As the scheme illustrates actual problem to solve seems to be quite straightforward, namely, if we ask if we imagine a human driving a car.",
                    "label": 0
                },
                {
                    "sent": "And a camera which is mounted in front of the windscreen.",
                    "label": 0
                },
                {
                    "sent": "Then whenever a Rd sign emerges in the scene, our recognition system.",
                    "label": 0
                },
                {
                    "sent": "Based on the.",
                    "label": 0
                },
                {
                    "sent": "Video input from the camera is expected to.",
                    "label": 0
                },
                {
                    "sent": "Detect and correctly recognize Rd sign and obviously produce an output, some kind of meaningful signal so that the so that the driver can react properly just sign.",
                    "label": 0
                },
                {
                    "sent": "So we know the input we more or less know the output.",
                    "label": 0
                },
                {
                    "sent": "Several important points to consider when dealing with such a problem are the following first.",
                    "label": 1
                },
                {
                    "sent": "A huge a priori knowledge is available about the traffic science because full specifications are given in terms of the template images, one can easily down download such images from the Internet, for example.",
                    "label": 1
                },
                {
                    "sent": "Another point is that we should be aware of many factors, potentially severely degrading performance of a system like this, and these are very illumination, uneven motion of a car, sudden light reflection.",
                    "label": 1
                },
                {
                    "sent": "And various other kinds of noise from different sources.",
                    "label": 0
                },
                {
                    "sent": "Also, the real time performance requirement is quite critical in this at this point because they emphasize we are not here consent with just still camera images, but a video sequences, which means the processing must be fast enough and the cost of high cost of false positives and false negatives is something that does not require too much explanation here I think.",
                    "label": 0
                },
                {
                    "sent": "We know that the well human driver's life is at stake.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "I was starting point to define image novel image representation.",
                    "label": 0
                },
                {
                    "sent": "Is the discretisation of color palette in the images?",
                    "label": 0
                },
                {
                    "sent": "We should take we should know that whenever our objects of interest are logically composed of just several colors, it is practical to discretize, collapse the color palette into several distinct, meaningful colors.",
                    "label": 0
                },
                {
                    "sent": "This not only helps to helps reduce computation, but also helps to avoid ambiguities whenever.",
                    "label": 0
                },
                {
                    "sent": "Whenever real life image of an object is compared to the template already containing just clean and sparse colors.",
                    "label": 0
                },
                {
                    "sent": "We've got we're facing two scenarios in fact.",
                    "label": 0
                },
                {
                    "sent": "First we need to discretize colors in the clean template images.",
                    "label": 1
                },
                {
                    "sent": "But this image is already in fact container clean, distinct colors.",
                    "label": 0
                },
                {
                    "sent": "So in this case we're just aiming at changing the physical representation of an image from, let's say 24 bit bitmap into just two bits encoding relevant colors.",
                    "label": 0
                },
                {
                    "sent": "And it can be done by any available technique.",
                    "label": 0
                },
                {
                    "sent": "Literally very simple ones like for example thresholding in Hue, saturation value, color space.",
                    "label": 0
                },
                {
                    "sent": "When we when we have real life images, natural images problem is slightly more demanding.",
                    "label": 1
                },
                {
                    "sent": "Our idea to discretize color in such images is to model each distinct color, which with a Gaussian mixture.",
                    "label": 0
                },
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "Basically we use as training data.",
                    "label": 0
                },
                {
                    "sent": "Pre labeled pixels from the training sample.",
                    "label": 0
                },
                {
                    "sent": "Training traffic video sequences from the regions.",
                    "label": 0
                },
                {
                    "sent": "Speaking the signs, we simply pick the pixels with already known color, so this is purely a supervised training.",
                    "label": 0
                },
                {
                    "sent": "We initialize our Gaussian mixtures for each color.",
                    "label": 0
                },
                {
                    "sent": "Randomly and run an EM algorithm until convergence.",
                    "label": 0
                },
                {
                    "sent": "To refine our estimation.",
                    "label": 0
                },
                {
                    "sent": "We repeat this procedure several times for different initializations of Goshen components.",
                    "label": 0
                },
                {
                    "sent": "And for also for different numbers of such components and in the end we pick the most likely most best model in the meaning of highest mean data likelihood.",
                    "label": 0
                },
                {
                    "sent": "Once we've got model trained, we can make an online assignment of color to RGB pixels.",
                    "label": 0
                },
                {
                    "sent": "By just picking the best model, meaning that most model that would most likely generate such a test RGB pixel.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the sample output from such a discretization.",
                    "label": 0
                },
                {
                    "sent": "In the upper row you can see natural images extracted from the real frames from the real video.",
                    "label": 0
                },
                {
                    "sent": "In the lower row you can see the result of discretization using in Goshen mixture models.",
                    "label": 0
                },
                {
                    "sent": "You can also see that the background fragments are masked out already.",
                    "label": 0
                },
                {
                    "sent": "So results are quite accurate.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's now define color distance transform.",
                    "label": 1
                },
                {
                    "sent": "Basically, distance transform is a tool used popularly in the area of computer vision too.",
                    "label": 0
                },
                {
                    "sent": "This is defined for binary images and used to define for each image location, a kind of.",
                    "label": 0
                },
                {
                    "sent": "What distance to the nearest feature pixel that is that true when pixel with a value through the binary image?",
                    "label": 1
                },
                {
                    "sent": "The problem is that we don't have binary image, but rather 2 bit image with up to four colors encoded.",
                    "label": 0
                },
                {
                    "sent": "So the trick we use is just.",
                    "label": 0
                },
                {
                    "sent": "To treat each distinct color to treat pixels of that color as feature, pixels and pixels of any other color as non feature pixels.",
                    "label": 1
                },
                {
                    "sent": "This way we obtain.",
                    "label": 0
                },
                {
                    "sent": "Different binary images independently and for each of them we calculate the standard distance trance formula in a well known way.",
                    "label": 1
                },
                {
                    "sent": "The chunk for metric popular approximation to the Euclidean distance is used as a measure distance map metrics here.",
                    "label": 0
                },
                {
                    "sent": "Please have a look at the example output on the left you can see in the original image of a template Rd sign.",
                    "label": 0
                },
                {
                    "sent": "Quite well known.",
                    "label": 0
                },
                {
                    "sent": "I think the color distance transform corresponding to the black color white color and red color, respectively can be seen on the right.",
                    "label": 0
                },
                {
                    "sent": "So as we can see, the CDT defines the kind of smooth distance measure.",
                    "label": 0
                },
                {
                    "sent": "Which as we as we will, as it will be shown, can be used effectively in the task of template matching.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the.",
                    "label": 0
                },
                {
                    "sent": "Let's introduce the notion of local regions in the local dissimilarity.",
                    "label": 0
                },
                {
                    "sent": "Imagine we've got.",
                    "label": 0
                },
                {
                    "sent": "Template image of a Rd sign like this.",
                    "label": 0
                },
                {
                    "sent": "We just cover it with a grid regular grid, subdividing the image into smaller subregions.",
                    "label": 0
                },
                {
                    "sent": "Now let's concentrate on a small region like this.",
                    "label": 0
                },
                {
                    "sent": "We can now introduce several quantities characterizing the local similarity between the two images.",
                    "label": 0
                },
                {
                    "sent": "With respect to a single region, OS, or over a set containing multiple regions.",
                    "label": 0
                },
                {
                    "sent": "Definitions are quite obvious actually.",
                    "label": 0
                },
                {
                    "sent": "They are just the average is some sort.",
                    "label": 0
                },
                {
                    "sent": "What calls for explanation is.",
                    "label": 0
                },
                {
                    "sent": "Is the meaning of DCDT.",
                    "label": 0
                },
                {
                    "sent": "Actually, the computer to know to get value of DCT for pixel of coordinates C&T we need a discrete color representation of image I the the.",
                    "label": 0
                },
                {
                    "sent": "Color distance transform image of.",
                    "label": 0
                },
                {
                    "sent": "Of image and we simply check the color of the pixel in I.",
                    "label": 0
                },
                {
                    "sent": "Then we refer to the appropriate color distance transform corresponding to that color in J and we pick the appropriate value.",
                    "label": 0
                },
                {
                    "sent": "In other words, we.",
                    "label": 0
                },
                {
                    "sent": "Big.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Appropriate value from the images from from the correct appropriate images.",
                    "label": 0
                },
                {
                    "sent": "One of these.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other notions are just defined on top of the first one, and the weights in the second in the third case are used to denote that some regions might be more important to us for some reason.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Our main goal is to be able to correctly classify them unknown image exchange.",
                    "label": 0
                },
                {
                    "sent": "Coming from the input video we've got.",
                    "label": 0
                },
                {
                    "sent": "Category available.",
                    "label": 0
                },
                {
                    "sent": "Templates roadsigns TI and we want to determine this class by maximizing the posterior term like this we can see here model parameters Theta I which the indexes to denote that the model parameters are different for different classes.",
                    "label": 0
                },
                {
                    "sent": "So important to realize that the first parameter is a kind of indexing variable which determines.",
                    "label": 0
                },
                {
                    "sent": "Subset of regions to be used the best characterizes given class.",
                    "label": 1
                },
                {
                    "sent": "And WI is there is a vector of weights corresponding to these regions.",
                    "label": 0
                },
                {
                    "sent": "In order to learn the best model parameters, we define kind of objective function with which we want to maximize.",
                    "label": 1
                },
                {
                    "sent": "And now is this important to realize what such a maximization means, it simply means that we aim at retrieving for a given class such a compact and small number of local regions.",
                    "label": 0
                },
                {
                    "sent": "Within which that particular class looks possibly the most different from all other classes.",
                    "label": 0
                },
                {
                    "sent": "Which we want to recognize.",
                    "label": 0
                },
                {
                    "sent": "So we want to capture as much dissimilarity as possible within a compact representation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The implementation of that.",
                    "label": 0
                },
                {
                    "sent": "The training we should say.",
                    "label": 0
                },
                {
                    "sent": "Contains the elements of a technique known as forward feature selection for what selection and I will explain it in using just a few figures.",
                    "label": 0
                },
                {
                    "sent": "Imagine we've got our target class, let's call it.",
                    "label": 1
                },
                {
                    "sent": "TII will target template image and all other classes TJS.",
                    "label": 1
                },
                {
                    "sent": "We make individually comparison between T and all the TJ's.",
                    "label": 0
                },
                {
                    "sent": "Now for each of such comparisons we obtain a kind of dissimilarity map by evaluating the similarity within each possible region, and from that we obtain a ranking of this region.",
                    "label": 1
                },
                {
                    "sent": "So we just sort them according to the decreasing similarity.",
                    "label": 0
                },
                {
                    "sent": "What we do we first pick the first most dissimilar region, remember.",
                    "label": 0
                },
                {
                    "sent": "Similarity for it.",
                    "label": 0
                },
                {
                    "sent": "Then we fix that region and at the same time we.",
                    "label": 0
                },
                {
                    "sent": "Remove it from the pool of available regions so that it can be selected again.",
                    "label": 0
                },
                {
                    "sent": "And we continue doing this same thing.",
                    "label": 0
                },
                {
                    "sent": "We picked the second most dissimilar region again.",
                    "label": 0
                },
                {
                    "sent": "Remember this similarity.",
                    "label": 0
                },
                {
                    "sent": "And calculate the average similarity.",
                    "label": 0
                },
                {
                    "sent": "Between images being compared.",
                    "label": 0
                },
                {
                    "sent": "Over the region set consisting just added regions and all previously added regions.",
                    "label": 0
                },
                {
                    "sent": "So in this case it is a two element set.",
                    "label": 0
                },
                {
                    "sent": "We continue like this.",
                    "label": 0
                },
                {
                    "sent": "Until yeah and that is the point, we should introduce some kind of stop criterion because.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we would select eventually every region which is not our goal.",
                    "label": 0
                },
                {
                    "sent": "We want representation to be compact.",
                    "label": 0
                },
                {
                    "sent": "And well to define the sub criterion we introduce.",
                    "label": 0
                },
                {
                    "sent": "That threshold, which we call the similarity threshold, is that TD.",
                    "label": 0
                },
                {
                    "sent": "What does that condition?",
                    "label": 0
                },
                {
                    "sent": "Meanwhile we just stop adding new regions to our region set.",
                    "label": 0
                },
                {
                    "sent": "When the average dissimilarity over our current region set goes below some fixed percentage of the most highest possible dissimilarity.",
                    "label": 0
                },
                {
                    "sent": "Highest possible dissimilarity is that the similarity, which is obvious because the regions are ranked sorted.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this slide illustrates how the target representation is assembled from each individual comparisons we obtain kind of rankings.",
                    "label": 0
                },
                {
                    "sent": "The numbers here illustrate quality or the similarity of the regions.",
                    "label": 0
                },
                {
                    "sent": "As we can see in the 1st and 3rd comparison for four regions were selected before meeting this top condition here 5.",
                    "label": 0
                },
                {
                    "sent": "We just finally do merging of these ranks.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "So the procedure is indeed very simple.",
                    "label": 0
                },
                {
                    "sent": "Whenever, whenever a region was selected at least once, it is just transferred to the target region set.",
                    "label": 0
                },
                {
                    "sent": "With its rank, if that region was selected multiple number of times, then then the regions are, the ranks are merged with this sound.",
                    "label": 0
                },
                {
                    "sent": "And finally, we can normalize these weights by.",
                    "label": 1
                },
                {
                    "sent": "To the range between 01, these are our regional weights.",
                    "label": 0
                },
                {
                    "sent": "Higher weight, obviously it means that the more discriminative power given the region has.",
                    "label": 0
                },
                {
                    "sent": "Because it captures the larger amount of the similarity between our target class and the other classes.",
                    "label": 0
                },
                {
                    "sent": "This is the sample output.",
                    "label": 1
                },
                {
                    "sent": "The brighter regions here, here.",
                    "label": 0
                },
                {
                    "sent": "Denote these regions which were assigned to the highest weights.",
                    "label": 0
                },
                {
                    "sent": "As we can see, most of the regions are zero or black and they are not selected at all.",
                    "label": 0
                },
                {
                    "sent": "It is important not to realize one fact that the procedure is indeed run independently for each class, which yields somehow completely independent representation, and it induces also independent classifiers.",
                    "label": 0
                },
                {
                    "sent": "Meaning that.",
                    "label": 0
                },
                {
                    "sent": "Each of these classifiers is somehow trained to recognize that one particular class, but.",
                    "label": 0
                },
                {
                    "sent": "Because of the way the similarity threshold was introduced.",
                    "label": 0
                },
                {
                    "sent": "We can make a following statement, namely.",
                    "label": 0
                },
                {
                    "sent": "Decisions made made by such independent classifiers can be made directly compatible because the similarity threshold guarantees that the same amount of the similarity is captured in each individual model.",
                    "label": 0
                },
                {
                    "sent": "So this is something that.",
                    "label": 0
                },
                {
                    "sent": "Several other techniques, like principal component analysis, can't do because the dimensionality is fixed.",
                    "label": 0
                },
                {
                    "sent": "Here it is not fixed.",
                    "label": 0
                },
                {
                    "sent": "Number of discriminative regions might differ, and in fact it differs.",
                    "label": 0
                },
                {
                    "sent": "However the same in terms of the similarity.",
                    "label": 0
                },
                {
                    "sent": "The same amount is captured in each model.",
                    "label": 0
                },
                {
                    "sent": "In conclusion, we think that because of that because of that conclusion, we can now apply a very simple.",
                    "label": 0
                },
                {
                    "sent": "Classification technique based on the minimum distance.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Map.",
                    "label": 0
                },
                {
                    "sent": "Just a few words about the hour traffic sign recognition system.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very briefly.",
                    "label": 0
                },
                {
                    "sent": "Basically, it consists on several several modules.",
                    "label": 0
                },
                {
                    "sent": "However, image representation is something most important to us.",
                    "label": 0
                },
                {
                    "sent": "Obviously some image processing is done within the system too, which is intended to mainly to identify the regions of interest and plus to highlight the relevant features for the detector, which is color basically on edges.",
                    "label": 1
                },
                {
                    "sent": "The detection module makes use of a recently published technique of law and bounds.",
                    "label": 0
                },
                {
                    "sent": "Which is a kind of generalization of circular Hough transform.",
                    "label": 0
                },
                {
                    "sent": "While learning computer vision, it is designed in such a clever way that is able to detect all instances of equiangular polygons and the road signs are indeed instances of such polygons, even including circles that can be considered as such.",
                    "label": 0
                },
                {
                    "sent": "The tracking isn't.",
                    "label": 0
                },
                {
                    "sent": "Another module is used to reduce computation.",
                    "label": 0
                },
                {
                    "sent": "We just employ here a common filter, assuming very strong.",
                    "label": 0
                },
                {
                    "sent": "Map motion assumptions, namely, that the car is moving with a constant velocity along the optical axis of the camera, and so the tracking is done in purely geometrical fashion.",
                    "label": 0
                },
                {
                    "sent": "And in fact, what is struck is the local search region.",
                    "label": 1
                },
                {
                    "sent": "But within such a region.",
                    "label": 0
                },
                {
                    "sent": "Signed this already detected is again detected but locally.",
                    "label": 0
                },
                {
                    "sent": "So the same login bars detector does the whole work.",
                    "label": 0
                },
                {
                    "sent": "And in terms of the representation, as I said.",
                    "label": 0
                },
                {
                    "sent": "The discriminative region model or representation is trained independently for each for each sign, just based on the on the template images, nothing more.",
                    "label": 1
                },
                {
                    "sent": "And this similarity threshold is tuned individually to each side category.",
                    "label": 0
                },
                {
                    "sent": "We distinguish between four categories.",
                    "label": 0
                },
                {
                    "sent": "Corresponding to warning signs, the caution cautionary signs, information, signs, signs giving orders and prohibitions.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just one more slide about classification.",
                    "label": 0
                },
                {
                    "sent": "We use a maximum likelihood approach and by.",
                    "label": 1
                },
                {
                    "sent": "By making somewhat very strong assumptions that the similarity within local regions or is Gaussian distributed, and.",
                    "label": 0
                },
                {
                    "sent": "And independent of one another, we convert it into minimization of distance, but as a distance metric we use our our average dissimilarity weighted dissimilarity over the region set SDSD these parameters as the end.",
                    "label": 0
                },
                {
                    "sent": "As in W. These learned in the training stage.",
                    "label": 1
                },
                {
                    "sent": "So in summing up classification runs.",
                    "label": 0
                },
                {
                    "sent": "But you know template matching fashion, but template matching with respect to the individual representation class specific representations.",
                    "label": 0
                },
                {
                    "sent": "We do a simple temporal integration by assuming also that.",
                    "label": 0
                },
                {
                    "sent": "Observations are independent in consecutive frames, so we just minimizing the accumulated distance.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just a.",
                    "label": 0
                },
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "Real life data was used as a test data for sign categories.",
                    "label": 0
                },
                {
                    "sent": "The numbers here correspond to the numbers of classes in each category.",
                    "label": 0
                },
                {
                    "sent": "So in total we have 135, which is a pretty large game of science.",
                    "label": 0
                },
                {
                    "sent": "In terms of the classification performance in a best settings of.",
                    "label": 0
                },
                {
                    "sent": "The similarity threshold.",
                    "label": 0
                },
                {
                    "sent": "93.5 correct classification rate was achieved.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The also here we can see a sample, just screenshots from a video at 30 frames per second it was tracing the House.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Detection works.",
                    "label": 0
                },
                {
                    "sent": "But maybe I will not explain it day of this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because we're short of time.",
                    "label": 0
                },
                {
                    "sent": "And conclusions my still.",
                    "label": 0
                },
                {
                    "sent": "Current solution is may be decent for Academy purposes, but if you wanted to, for example, sell it as a commercial product, we would have to make more effort.",
                    "label": 0
                },
                {
                    "sent": "To eliminate certain occurrences, undesirable ones, large game of science, recognized performance is OK compatible to the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Recently published our main contribution.",
                    "label": 1
                },
                {
                    "sent": "Here is a representation of roadsigns through discriminative local regions, which seems to have quite a lot of advantages over alternative feature selection methods.",
                    "label": 1
                },
                {
                    "sent": "Further work is planned in several independent directions, but.",
                    "label": 0
                },
                {
                    "sent": "Let's stop at this point.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your time.",
                    "label": 1
                },
                {
                    "sent": "We have time for some questions.",
                    "label": 0
                },
                {
                    "sent": "How do you deal with the difference in distance between the object sending and camera?",
                    "label": 0
                },
                {
                    "sent": "Do you scale the image or you just take several examples for different distances?",
                    "label": 0
                },
                {
                    "sent": "Uh, well actually common filter.",
                    "label": 0
                },
                {
                    "sent": "I mentioned this tracking the object location, tracking the local search region overtime.",
                    "label": 0
                },
                {
                    "sent": "But then also the variety parameters from the common filter can be used to roughly to estimate the size of our object.",
                    "label": 0
                },
                {
                    "sent": "So this is an indication for the for the shape detector of, sorry.",
                    "label": 0
                },
                {
                    "sent": "Exactly, yeah.",
                    "label": 0
                },
                {
                    "sent": "Quick question.",
                    "label": 0
                },
                {
                    "sent": "Can talk once you detect object detection itself from detection.",
                    "label": 0
                },
                {
                    "sent": "So if you need to compare yes exactly, I mentioned it earlier.",
                    "label": 0
                },
                {
                    "sent": "Something with the scale which may be different, scaling position, well intentioned scale once the object is detected, this rescaled to common size.",
                    "label": 0
                },
                {
                    "sent": "We assume some common size.",
                    "label": 0
                },
                {
                    "sent": "How do you do any different?",
                    "label": 0
                },
                {
                    "sent": "This lies in the in the way the regular Polygon detects detector works, which is quite out of the scope of the of the presentation, but it can deal with multiple sizes.",
                    "label": 0
                },
                {
                    "sent": "Polygon polygons, however the tracking is only as I mentioned, is only used to track overtime.",
                    "label": 0
                },
                {
                    "sent": "The search region.",
                    "label": 0
                },
                {
                    "sent": "It does not directly affect the detection results.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}