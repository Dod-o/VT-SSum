{
    "id": "7hdctxermnaoay6m25gny3h5kodguhn4",
    "title": "Monte Carlo Simulation for Statistical Inference, Model Selection and Decision Making",
    "info": {
        "author": [
            "Nando de Freitas, Department of Computer Science, University of British Columbia"
        ],
        "published": "March 13, 2008",
        "recorded": "March 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss08au_freitas_asm/",
    "segmentation": [
        [
            "Alright, so.",
            "Well, I've got until.",
            "9:30 and then question myself, OK?",
            "Also want coffee.",
            "So I'm gonna start this with a movie.",
            "George OK, thanks.",
            "The people at the back.",
            "Can you hear me Saba?",
            "Yeah girl.",
            "Um?",
            "Let me run start with the.",
            "So up to now, what we've seen is an introduction to machine learning, but there was this whirlwind tour that markets it yesterday and then there was a good analysis of the different kinds of data that arise.",
            "In practice.",
            "It Alex showed you.",
            "My part of this summer school is going to be more on computation computation for specific kind of models, and as we go for the next 2 days it will be more clear what kind of models this type of computation is useful for.",
            "It's not useful for everything, and so part of this will be that you get an idea when you can use these.",
            "Methadone and went you shouldn't try.",
            "It's all going to be based on sampling and simulation and so on.",
            "So quite often the goal of that is to do.",
            "It's obviously to do machine learning.",
            "It's obviously to compute parameters to solve integrals.",
            "To compute these normalization constants that Marcus was talking about yesterday.",
            "But quite often it will be just as a simulation device.",
            "Simulation is important because if I want to kind of.",
            "Do a task like go to Sydney if I'm trying to decide what to do this weekend.",
            "I can kind of simulate in my head how fun it will be once I'm in Sydney and it's Mardi Gras and all that.",
            "And that kind of gives me that allows me to make decisions, and that's actually how prices in fact do come into this sort of thinking.",
            "I want to make a decision in the future.",
            "I have some prior knowledge in my head of state of knowledge in my head, and from that around simulations into the future.",
            "So we're going to see a bit of that, and that's sort of that will be a preamble for WhatsApp is going to talk about later when he starts talking about reinforcement learning.",
            "OK, so.",
            "Yes.",
            "Clear indication that we sample.",
            "So who seen this video before?",
            "If you've seen it before, stick white.",
            "I have a video.",
            "It's there's two pictures in this video.",
            "I'm sort of flashing between one and the other, and there is a difference between the two.",
            "How many people have seen the difference so far?",
            "And once you see it, please don't.",
            "Announce it.",
            "To the rest three people, I'll give you a few more minutes.",
            "It's quite a lot of number of pixels with respect to the image.",
            "How many people have it?",
            "It's great that you guys are waking up.",
            "It is tough getting up in the morning.",
            "Oh, that motion seems to be helping.",
            "How many people have it now?",
            "For those who haven't seen it, what do airplanes need in order to fly?",
            "And just in case you haven't quite figured it out.",
            "OK, so this is a phenomenon called change blindness in psychology an it's it happens with images.",
            "It happens in the visual cortex, in the visual field.",
            "Start in the visual cortex.",
            "But it's it's characteristic of human minds and brains, and how we work.",
            "We sample the world.",
            "The reason why you don't see it is because we never see this image.",
            "This is an illusion.",
            "We believe we sing it, but we don't we sampling it.",
            "And we only extract from it what we need and we do a reconstruction in our head.",
            "So when you believe you're seeing the whole thing.",
            "And the same is true for a type of argument.",
            "So if you're into a, you know in a fight with your boyfriend or so on, and you think you're right and so on.",
            "You might just not be seeing the whole picture.",
            "You're living these details.",
            "And that's probably more familiar.",
            "Um?",
            "You know it's some theorists of cognition.",
            "Now it's about there being a conscious and are being subconscious processes and you just basically governing this subconscious processes so that the conscious seems to have control and a good understanding of what's going on.",
            "No, it says something mechanism that's keeping things in control.",
            "This is again like Alex said yesterday.",
            "Please don't take this into a projecting that any of the methods I'll talk about here.",
            "Describe how the brain works.",
            "It's more something is important.",
            "It's useful for humans.",
            "Whenever you have limited capacity to process something humans don't have, or droppers for that matter, the capacity to persist the whole visual field.",
            "You focus on certain areas of the space.",
            "Alright, so that's the interest, so this is what I plan to."
        ],
        [
            "So for the next 6 hours.",
            "Minus coffee, I'm gonna go for sampling methods give you a bit of a historical background or where they come from.",
            "Is that you learn a lot about that from the history, and it's a good way to introduce so basic algorithms, rejection, sampling, important sampling, how many people here have heard of guess excluding market introduction yesterday had heard of rejection sampling before?",
            "Important sampling.",
            "MSMC OK, So what are you guys doing here?",
            "Go to the beach.",
            "Um?",
            "So I'm going to go with that particle filtering.",
            "How many robots this year?",
            "How many people doing robotics?",
            "Can you guys?",
            "So I'm going to introduce some basic algorithms that it's good to know them because they're introductory.",
            "They give you an idea of how this whole thing works, but we don't usually use them.",
            "Algorithms to deal with data that is non ID systems are evolving overtime.",
            "And then the sort of more hardcore algorithms that have a big name.",
            "And.",
            "In the last part of the course, I will focus on.",
            "Trying to do like what's currently so this would be all introduction, a way to catch up with what people do.",
            "This would be kind of more like what's what are people researching now.",
            "I this is sort of more dodgy."
        ],
        [
            "OK.",
            "So let's start.",
            "Think markets kind of did a bit of this yesterday.",
            "What's the probability that if you wait to throw a dart at this board, and assuming that there's some sort of force that attracted to this square?",
            "What would be the probability that it hits the red area?",
            "Someone we should have like cookies for.",
            "You gotta you know that sun tanning lotion.",
            "That's how we should have given it.",
            "Are you there?",
            "He has a box of cookies.",
            "OK for a box of cookies.",
            "OK, 141 cookie.",
            "Come on.",
            "It's one cookie.",
            "I know it's embarrassingly easy.",
            "But it's worth a cookie Marcus.",
            "Would you like a cookie?",
            "Will give you a cookie for trying.",
            "Stuff, thank you.",
            "Whoever said, Dad, you know?"
        ],
        [
            "How to claim your cookie.",
            "OK next one.",
            "The lady over there has a cookie."
        ],
        [
            "This guy.",
            "You got to cook.",
            "That deserves a cookie.",
            "OK, here can tell me if a strategy to do this.",
            "Huh?",
            "Try and see.",
            "This is usually an easy one before.",
            "Before we do Riemann integration.",
            "Or we break the thing in squares.",
            "We count the number of red squares, divide by the total number of squares, and that gives you the probability of this.",
            "And so these guys introduced this yesterday.",
            "And the problem is that here you need.",
            "You need to end well.",
            "You need end by end points if you're gonna go and do this helps make sure that with the previous one.",
            "Then by Anne.",
            "If you are in 3D.",
            "You're gonna need.",
            "To do a cube.",
            "And so you'll need an by and by and.",
            "So you need Ncube.",
            "OK, yeah you need an square.",
            "So the problem being that as you go up in dimension.",
            "You increase with powers of dimension.",
            "And so this method will not scale.",
            "Having said that, a lot of people do adaptive grids, so the grid size changes and.",
            "The coding is just very nasty, but you know some people work in six dimensions and so on.",
            "And these adaptive grids actually can actually work pretty well.",
            "So it's more, I think of more matter of software engineering then.",
            "Oh I mean you go for the volume to the surface so.",
            "Go to the end to the D -- 1.",
            "With the.",
            "With adaptive grid.",
            "That way, but.",
            "Five or so, but it is 10 who cares about intercultural?",
            "No, I agree with you.",
            "Yeah, now I'm totally with you, that's why."
        ],
        [
            "Do this.",
            "Yeah, throw darts at the board.",
            "Close your eyes products.",
            "And then you count the number of dots that fall inside divided by the total number of dark.",
            "So 3 / 4 / 7.",
            "So number of dots in that area divided by number dot in the box and that gives you an estimate of the area.",
            "Gives you an estimate of the probability that you will hit this.",
            "OK, probabilities and areas.",
            "Kind of the same thing.",
            "OK. Probability is a way of measuring things, measuring events.",
            "Um?"
        ],
        [
            "OK so first Montecarlo started with Guinness.",
            "And the 1700s guy called.",
            "William Gospel visit.",
            "He published he was working for Guinness.",
            "An he published a paper in those days 17 I think with 1700s this is the student T paper about the student T distribution and what he used to figure out the characteristics of the student T distribution with Monte Carlo simulation.",
            "So that would be sort of one of the first published works or Monte Carlo simulation, though the Greeks already has some Montecarlo ways of getting pie and so on, so it all starts with Guinness research."
        ],
        [
            "Center um, but what it really took off was motivated by two things that happen at the same time.",
            "The fashionable 40s, when actually there were more women in computer science in those days.",
            "Cancel the wedding charge of the ENIAC.",
            "And the drive was this the drivers to you know nuclear power people wanted to simulate.",
            "Samples and examples.",
            "In this case we're actually knew turns and so on, and people wanted to compute properties of this nutrient.",
            "Where is the diffusion time of this thing going through a tube 'cause you need to have that right in order to build a nuclear device.",
            "Right at the same time is when computer start appearing.",
            "When this is being done an when, like the ENIAC, is moved from the East Coast to Los Alamos.",
            "And they did that in order to run this Monte Carlo simulations.",
            "That's where the computer started and clarify Neumann for Neumann.",
            "The famous phenomenon of game theory and computer science, the computer architecture started as one of these programmers.",
            "One of these people that keeps wiring these things, and it was a very tedious task.",
            "And for Norman actually designed the modern computer architecture to.",
            "Kind of sidestepped this technical problem.",
            "And be able to design Monte Carlo simulators.",
            "Important sampling was invented by for Neumann.",
            "I've seen the original letter whether he describes it and he actually writes the pseudocode with with numbers.",
            "You know with line numbers for the code.",
            "And that's the first modern program ever written.",
            "In fact, at the bottom he even says I have reason to believe that a computer will one day be able to understand this.",
            "So there was dust days.",
            "That's when most things were developed, like the particle filters we're going to talk about today.",
            "They were developed in those days.",
            "There was in 1949 the 1st paper introduced the idea.",
            "An idea that was sort of this discovered I rediscovered in the 90s by many people actually started there."
        ],
        [
            "And they were very smart people here at this stage.",
            "Enrico Fermi had his own way of doing Monte Carlo integration.",
            "He had a computer called a firm yak.",
            "Nick Metropolis Stanislav William, the famous mathematician, was working with this with the guy called Metropolis, so we'll hear more about.",
            "And Metropolis actually decide to cut also construct a machine.",
            "So we had the ENIAC, the firm Yakan.",
            "He decided to construct the maniac.",
            "Thought that would be the end of acronyms in computer science.",
            "These other guys metropoles for nine months for me."
        ],
        [
            "Canola.",
            "OK, So what can we do with this stuff?",
            "So that's a sort of the history.",
            "I'm so simulation is one of those things and we're going to see quite a bit of that, not only these days not.",
            "But please.",
            "What can I do?",
            "Not so much for neutron diffusion time simulation, but more to do with you know, animation and so on.",
            "These methods can be used for optimization, though I have to say when it comes to optimization, there's lots of competitors out there, so you should think twice before you adopt A month car logarithm for optimization.",
            "Because if the state space is discrete, is the guys that do combinatorial optimization have come up with lots of good techniques?",
            "If you can map it as a continuous problem, then Alex today will discuss a bunch of very good techniques that you could use instead.",
            "But then we get to the problem of integration.",
            "An an integration is the computational problem in Bayesian stats.",
            "If you could do integration in high dimensions based on stats would be feasible and would be the method of choice.",
            "Well, maybe.",
            "Um?",
            "Everything you do in basin integration will require solving integrals, and we're going to come to that, and the same is true when you do game theory.",
            "When you need to compute best response to in order to get to Nash equilibrium.",
            "Computing volumes are in high dimensions also of interest.",
            "So it's a related problem.",
            "If you want to compute eigenfunctions of integral operators, then again.",
            "Computing eigenvectors you can do it and you can solve differential equations in integral form.",
            "So if you can have a good integration method, you can compute all the standing waves.",
            "Of a particle in a box or around the Atom, and you can, you know, build lasers and do all these quantum things.",
            "You can also study physical properties of objects, statistical properties of materials, and so on.",
            "And basically I think that last line I put there is it's all about Monte Carlo's.",
            "In this setting is all about counting lots very quickly."
        ],
        [
            "So here's an example of how you can use it for simulation.",
            "This comes from a SIGGRAPH paper of chenyan foresight.",
            "If I can get this to run.",
            "Oh, hang on.",
            "Sorry about that.",
            "I'm having a bit of technical difficulty with this today.",
            "Let me just fire it here.",
            "So this is a Monte Carlo simulation of dice.",
            "You know, like in the casino.",
            "Anne.",
            "And yeah, some people already laughing said so the the idea is to try to make things that are realistic that look realistic.",
            "So that looks like it's real dice in a computer program, but at the same time you have full control of the thing.",
            "So in particular, we observe it.",
            "Carefully, the one goes to a one.",
            "The two will go to a 2.",
            "The three will go to a three, and so on, so it's like if you're designing computer games, you want to create realistic settings and you want to at the same time have control of these.",
            "You know, some people in the graphics literature have been doing this, and there's quite a few more examples.",
            "I'm just showing you one.",
            "We're gonna be more interested with using Monte Carlo to the machine learning 'cause it's the machine learning summer school.",
            "And so here the idea is, you know we were trying to come up with some sort of model of the world.",
            "Yeah, I'm using A tag to describe the world of horses.",
            "Anne.",
            "And we would like to do something as good as this so.",
            "Let me give you now.",
            "Serve for another cookie another few cookies, another game.",
            "Um?",
            "There's a bunch of things here.",
            "An I have highlighted three of the two first.",
            "OK, there's one too far here, another one here, and this is 1/3 too far.",
            "OK, so for the cookie.",
            "OK, hang on.",
            "I ask this questions.",
            "He got sick sorry.",
            "Cooking ones left.",
            "That's a good question.",
            "Why does it will come back to that?",
            "Can someone tell me?",
            "And let's use the index here.",
            "This will be a rose.",
            "This will be column, so this is 2 one this is 3, one versus 3 two.",
            "Can one point out where there is a 2 for?",
            "34 oh sorry, this guy.",
            "How many people agree that this is a TOFA?",
            "How many people think it's not a tofa?",
            "OK, so whoever put that candidate gets a cookie, OK, another one.",
            "For sex, how many people agree?",
            "Disagree.",
            "OK. How about let me pick one?",
            "My current I I I. Alright, this guy.",
            "How many people think that?",
            "I think these guys are too for how many people think it is.",
            "This is how much faith you have in me.",
            "Who doesn't think this is a true fact?",
            "What about the two full with like a baby, two for growing on top?",
            "OK, so there there sort of was played to quite a few people chose not to vote.",
            "I have no clue a tattoo face.",
            "All I know is I can take a bunch of abstract symbols.",
            "I can tell you what are two first.",
            "And very quickly in this, you actually made pretty strong opinions of water too far worse than what it was not, and sometimes.",
            "And also it was subjective, so some people didn't pick on those same features.",
            "This kind of very fast learning, very kind of abstraction, is what?",
            "So that's what we would like to build given day to be able to do these induction.",
            "What Josh Tenenbaum calls them the induction leaps.",
            "So we very quickly learn what something is."
        ],
        [
            "So you've seen base rule.",
            "So the idea is we want to learn this.",
            "Given the data D we want to learn these hypothesis and base rule provides us with a mechanism for that.",
            "As long as we have a prior model of a hypothesis and we have the data and this is the sort of simulation I used for my class.",
            "The sheep plus.",
            "Where you know a child might have a distribution indicating you know according to the height of this density, how likely something is to be a sheep.",
            "And so there's a few goats there, because God's kind of cookies have arrived.",
            "Who I'll just handle who 21?",
            "Alright, so the guy for asking the question there.",
            "This will come in handy when the coffee arrives.",
            "Who else claimed the coskey?",
            "User one.",
            "OK, so go to kind of like shape.",
            "You might have that initial belief.",
            "Then here comes the data someone actually gives you the label sheep for these guys.",
            "OK, so now you have a label that ties the blue thing they had the the measurement model.",
            "And why there's noise?",
            "Well, because your parents say there's a ship over there and you kind of look over there and there's trees and there's grass you gotta figure out which the sheep is.",
            "An if you see enough instances you soon any you know you have a good primer on how your parents think.",
            "You soon start, figure out what they're going on about.",
            "And so you had that prior shape.",
            "You have a new observation that brings in data the data being the tag shape.",
            "And with that you now get a posterior which is, you know, kind of nicely.",
            "And, um.",
            "I will be using a lot of graphical models which you'll hear more about next week and the way to represent this model.",
            "That probabilistic model works with this graph.",
            "You had a brief introduction to this yesterday, so no, that is unshaded is something we want to learn.",
            "The arrow indicates the conditional probability P of the given H. A note by itself that's unshaded is just a marginal probability P of H. And then this whole thing denotes the joint of PFD komaj.",
            "It's just a graphical way of representing this.",
            "And here are some examples of this sort of thing.",
            "And there's one more thing I needed to say there.",
            "This all seems easy.",
            "The trick is.",
            "To do this integral.",
            "You need to do the normalization to notice distribution.",
            "So if you have many hypothesis, many alternative hypothesis could be huge, and this is usually a combinatorial integral.",
            "It's sort of very high dimensional.",
            "Continuous integral.",
            "For Bayesian inference, there's no optimization.",
            "It's all about computing this integral.",
            "It's an integration problems, not an optimization problem.",
            "Here's another example that I got from Kevin Murphy.",
            "You have a language model.",
            "Probability of words in a language you have a likelihood that indicates how sounds are produced given the words, and we know how to do speech synthesis synthesis pretty well in computers, so we have good models of that and given sounds, we try to infer words.",
            "So speech recognition.",
            "Recognize speech.",
            "Wreck Beach is a nudist beach in Vancouver and just wondering why Kevin Murphy came up with that example.",
            "Um, here's another example.",
            "Computer vision.",
            "You have a belief beliefs about the world, the properties of the world, and so on.",
            "How light comes to your eyes, how it gets reflected in objects and so on.",
            "Maybe some properties of objects.",
            "Pixels I guess not pixels, but contours and so on.",
            "And you also know there's computer graphics that tells you, given a model, how you generate how you render images.",
            "So you have an observation model, and then from that observation model you try to do computer vision to decide what the world is about given an image of the world.",
            "Again, an integration problem in this sort of abstract setting.",
            "But now it's not only about learning and abstraction, it's about.",
            "You usually learn an abstraction with a purpose in mind.",
            "Like Marcus mentioned yesterday.",
            "And this is the sort of not all people with actually believe this.",
            "This is the utilitarian view.",
            "In philosophy we do everything with the utility in mind.",
            "Let's look at the another example.",
            "We saw one yesterday, but just recap.",
            "Assume that we first learn a population model and we do a density very trivial density estimate like.",
            "We saw yesterday.",
            "You basically just count how many people are healthy, how many people have cancer in the population and that gives.",
            "That's kind of a way of learning.",
            "A probability that describes the population in general.",
            "This will be a more complex model, but the methodology is the same.",
            "Once you have that, you also can learn a reward model, reward model.",
            "Actually subway, you're going to talk about that.",
            "Saba, Yahoo.",
            "Reading email.",
            "No.",
            "How do you pronounce it?",
            "Java OK, you're going to talk about inverse.",
            "Not OK, he's not, but if you need to know more about this, talk to him.",
            "He'll be around.",
            "Learning the rewards is actually very tough problem.",
            "You know, usually we have an objective function optimizing, but there's such objective function come from that in itself is quite a challenging problem.",
            "But let's assume we have learned that you're saying Java's latest algorithm that he's not going to talk to us about, and we know that if a patient is healthy, and this might also be decided by a bunch of people doing policy making, you know your politicians and your current government.",
            "Might decide that if you're healthy.",
            "Annual receive no treatment and there's no cost to the nation.",
            "If you're have cancer in your receive no treatment, then will you die and that's kind of a loss of resources to the nation.",
            "If you are healthy in your receive treatment.",
            "You lose your hair and that's minus 30 cost.",
            "An if you have cancer.",
            "And you do receive treatment.",
            "Well, you survived, but it's still.",
            "You know it's tough going through this.",
            "No.",
            "The principle of expected utility, which is not the axiom, is not here expected utility.",
            "I don't have time to go into it, but it comes from actually the work of for Neumann and Morgenstern in the 40s, again.",
            "And it's about choice is something that comes from choice theory, where in about combining individual preferences, how to come up with a voting scheme that makes everyone happy.",
            "That if you know obvious things in preferences, if you prefer it to be and you prefer B to C, then you should prefer A to C. And then there's five more for more axioms.",
            "Which seems to be a better unassailable.",
            "And then you try to find a function that a social choice function that satisfies all those axioms.",
            "An what arises is this thing called the expected utility.",
            "So it's rational in that sense, if you wanna play.",
            "A game like in game theory and you wanna do?",
            "Arrive at the Nash equilibrium.",
            "Then what Nash proved is that Chief you maximize this quantity.",
            "Each player maximizes quantity, they'll converge to the Nash equilibrium.",
            "So in that setting it's called best response.",
            "The idea of expected utility is.",
            "Or this is also called average case analysis?",
            "As opposed to worst case.",
            "In average case analysis you assume.",
            "That you want to come up with some action you wanna come up with some decision as to how to best treat, decide whether to treat people or not.",
            "And the way you do it is you wait the reward according to it according to the probability that that thing might happen.",
            "So you take those averages and then you maximize.",
            "You find the action that maximizes that average.",
            "And as a homework exercise beach exercise, you can check out that in this case you get these numbers if you actually expand those.",
            "So just basically plug these numbers here.",
            "And you'll get those and then you get the decision.",
            "So it's this is more or less how the whole thing happens.",
            "In the end you have reward models, objective models you might have to learn they might be parameterized, in which case you're learning something about it.",
            "These guys might be parameterized as well.",
            "You're learning something about it at the end of the day we want to reach.",
            "Make a decision.",
            "And this type of graphical model is represented with an influence diagram that.",
            "Again, we have the data model.",
            "We have the unknown quantity.",
            "We have the data.",
            "This is a probabilistic model, but now we have this sort of diamond nodes that indicate rewards.",
            "Then we have the action.",
            "The square nodes are indicate decisions.",
            "And we're going to see the a bit more of this tomorrow.",
            "How many of you have used Stuart Russell's book?",
            "AI.",
            "OK, so that's a sort of preferred approach to introduce decision theory in this book.",
            "Um, so again.",
            "The point of this whole thing being that.",
            "If we want to solve this problem, if we want to do this, all rational decision making the trick here is to solve an integral.",
            "This interval in general will be very huge.",
            "That's going to be a combinatorial sum.",
            "It's actually more than that.",
            "It's a combinatorial sum, and it has a Max operator 'cause over 'cause what you're trying to do is you find the best action the best response, so there's Max some.",
            "So you have the Max problem, the optimization problem.",
            "You have the same problem, which is just integration problem and the maximum and the maximum in many cases is easier under some problem 'cause you can do branch and bound something that I'll get you soon.",
            "So one way to do going back to learning one way to do learning we've seen, is to do maximization.",
            "And this is actually in fact for most settings when you're working on the web when you just want one solution.",
            "This might be the best thing to do.",
            "Um?",
            "Where you basically just maximize the likelihood times the prior or in log space to some of their logs.",
            "So the idea being that you learn this in the training data.",
            "An once you have an estimate of the training data to computer prediction for the new observation.",
            "Given an input.",
            "You just plug in.",
            "Your best estimate, the map estimate, or if you have no prior to maximum likelihood estimate or other estimates, there are the things you can do.",
            "There's lots of worst case estimates where instead of taking the average of what could happen, you actually expect the worst was going to happen and you prepare yourself for the worst case.",
            "So it's a sort of adversarial setting.",
            "An they young Liqun has a lot of interesting algorithms.",
            "Alex is also been working on those.",
            "So again, we have a graph.",
            "This is the parameter learning according to this parameter.",
            "These observations are independent.",
            "If you knew this guy, this will be independent.",
            "So think of Theta as.",
            "Um?",
            "Rain and this means the grass is wet.",
            "Let me try to come out.",
            "I hate it when I try to come up with examples that make sense.",
            "The sprinkler.",
            "Is that the sprinkler one?",
            "When you have rain?",
            "You wanna know if you know this variable?",
            "Then you know it's independent of that.",
            "This is cloudy.",
            "Hang on, let me just bring those examples here, 'cause they're very useful.",
            "So no graphical model.",
            "You might have something that if you have a variable that's the variable that say rain, and let's say the train.",
            "Is either true or false?",
            "Um?",
            "Actually, let's put clouds.",
            "Here.",
            "Clouds, rain and then wet.",
            "Now, if you want to know.",
            "Actually, let's not make it through yet.",
            "If you want to know whether you're going to get so, the conditional independence here and let me use just the word CR.",
            "CRNW did the notice, so this whole thing describes the joint distribution of PFW, R, C, and it's factorized as P of W given R. Times piov are given C * P FC.",
            "And independence assumption here is, given that it's raining.",
            "You you know whether you're wet or not.",
            "So if you're outside and it's raining, then you know you will get wet.",
            "You don't need to know whether there's clouds.",
            "In order to know that you're going to get wet.",
            "OK, so given.",
            "So in other words, wet is independent.",
            "Of clouds given rain.",
            "So that's independent.",
            "Given.",
            "So that's one situation.",
            "Another situation that arises.",
            "And you'll see all this more in the graphical models literature, but I'm just trying to kind of.",
            "But that give you a quick introduction so that.",
            "More or less understand the semantics there.",
            "Another example that might arise is this where you have.",
            "Um and I couldn't just come up with an example.",
            "No, I said that you're wet again and then there's a sprinkler.",
            "Um?",
            "That's probably a bad example, but again here.",
            "Rain causes you to get wet.",
            "Or let's say rain.",
            "Causes the frogs to come out.",
            "OK. Again, if it rains, chances are she'll get wet.",
            "If you happen to be outside on the grass.",
            "If if it doesn't rain, then chances are that you'll be dry.",
            "My inference about whether I'm wet or not does not depend on frogs.",
            "In particular, wet is independent.",
            "Whether you get wet is independent of whether there are frogs or not.",
            "If it's given that it's raining, given that you know.",
            "The value of the variable rate.",
            "OK.",
            "Otherwise, I mean you're out there in the grass and suppose you could not tell whether it's raining or not.",
            "Then you would have the.",
            "You would probably look at the frogs if you knew the frogs come out when it's raining, that would give you an idea of whether you would get wet or not.",
            "But if you know that it's raining that you don't need to look at the at the frogs in order to know that you're wet.",
            "And that's the semantics that this is kind of captured.",
            "The parameter, in other words, has given this parameter.",
            "There's enough information here to generate.",
            "All this.",
            "Data so the parameter is a sufficient statistic for the data.",
            "Is sufficient.",
            "It describes everything there is about that data.",
            "That's the assumption.",
            "And that's more or less what this graph encodes.",
            "It's also encoding how the observations are arising.",
            "So we've observed this.",
            "How we infer a new one.",
            "So it's a graphical model way of representing set classification or regression problem.",
            "The important thing in this setting is you do things by, you know, map estimation.",
            "For a Bayesian, you start with base rule.",
            "You keep this guy the marginal.",
            "And recall that the.",
            "The the the marginal again.",
            "Is the integral of PO.",
            "The given theater times P of theater.",
            "Overfit.",
            "And.",
            "In order to make a prediction, you use this quantity.",
            "The evidence that we saw this predictive distribution, and the predictive for Bayesian.",
            "If you want to compute the prediction, you average.",
            "Overall, the data according to the posterior.",
            "OK, so the idea being that.",
            "Kind of to make it you wanna compute P of Y star given X star.",
            "Comedi you want a prediction based on all your data?",
            "What should the prediction before and you guy X star?",
            "You don't need to know about the parameters to make this prediction.",
            "Because all you want is you want the integral of P of Y star, theater given X star.",
            "Call Maddie over teach.",
            "OK.",
            "So whenever you don't know a variable you marginalise, let's.",
            "That's straight from the axioms of probability.",
            "And.",
            "Then we use conditional.",
            "The conditional independence implied by the graph and the condition independence implied by the graph.",
            "So if we expand this now using conditional probability.",
            "You know what?",
            "Let me bring you a clean slide for this.",
            "I wish I knew how to bring a slide.",
            "Actually, let me do it on the board.",
            "So we want to make a prediction P of Y star foreign you data input text are given our past data which included a bunch of records, XY pairs and that's the integral of P of Y star.",
            "Given X star, D. , whoops.",
            "Forgot the feet.",
            ", theater given X star.",
            "Comedi except star.",
            "The theater.",
            "And now we can expand this guy using conditional probability as P of Y star.",
            "Given theater, X star, D. Times, P of theater given X star committee.",
            "The theater.",
            "OK.",
            "So the rule that I'm using here.",
            "Is that PFA?",
            "From the rules of probability, is the integral of PFA&B of AB.",
            "And the role that I'm using here is P of A&B.",
            "Is equal to PFB given a.",
            "Times B of A.",
            "Marginal set session and conditioning.",
            "And the next thing is, I exploited semantics of my model an according to my model White Star given X star.",
            "Is an given feature is independent of the so it's the same Mr. Frog situation?",
            "These guys are frogs.",
            "This is your getting wet.",
            "Given that you know the state of the world, whether it's raining or not, you no longer depend on this.",
            "So the information of your data is being summarized by the theater so I can drop that so I can just write this as P of Y star.",
            "Given X star, D. Sorry, feet.",
            "Times.",
            "PIA feature and stays the same.",
            "OK.",
            "I'm sorry I should be to also given the.",
            "Your first teacher from the not from extra.",
            "So exploiting the conditional dependence of our model.",
            "We arrive at the way of making a prediction.",
            "So, and this was basically saying is you take every possible prediction that you could have every possible sort of likelihood model.",
            "And you waited according to how probable that model is.",
            "Maximum likelihood.",
            "Does the following.",
            "Assume that P of feature.",
            "Given D. Can be modeled.",
            "By a Delta function, a Delta functions are functions as a spike at one specific value, an theater map.",
            "So it's a function that looks like this.",
            "He has a spike at theater map.",
            "Now a property.",
            "So we'll leave this as base.",
            "And then in the ML what you do is Europe.",
            "You use the same stuff.",
            "But you replace this distribution by the approximation, which is, you believe, only a single value, one single truth, and that truth is for the specific value of the parameters that you've obtained by optimization.",
            "So you plug the Delta function there.",
            "And then the property of the Dirac function is when you multiply, when you convolve it with any function, it's just equivalent evaluating the function at that point, so you get.",
            "The solution of the integral gets solved automatically.",
            "And so you get what we had in the previous slide.",
            "Which was.",
            "This guy.",
            "So you replace the integral by open optimization problem.",
            "But the inverse problem you're solving is still one of integration.",
            "So one way to solve an integral is to.",
            "Pick one value that happens to be a value that you believe in and stick with it.",
            "There's a problem with this that sometimes there isn't one single value.",
            "That's obviously the best one, and there's several values or things are sort of flat.",
            "And in that case.",
            "You need to."
        ],
        [
            "The full solution.",
            "So let me try to summarize.",
            "In Bayesian stats, there's several ways in which integrals arise.",
            "When you need to compute the posterior distribution.",
            "You need to normalize.",
            "You need to compute this thing.",
            "The normalization constant that sometimes people refer to as the reference or the partition function.",
            "You need to do marginalization.",
            "You might have several variables in your model, but you only care about a subset of them.",
            "So you need to do this sort of thing the inference task.",
            "Which is if you have a model with lots of variables, how quickly you draw an inference about one specific variable.",
            "And sometimes you're also interested in expectations.",
            "You just care about the actually.",
            "Sometimes you care about the map answer or the mean, and so on.",
            "If you could just about the map, then optimization kind of makes more sense.",
            "No, you don't.",
            "Sometimes you just need a reconstructed image.",
            "You don't need all the possible reconstructed images according to their probability.",
            "So in that case you silly to be doing this type of analysis.",
            "Um?",
            "So that's how integrals arising in basin starts and decision theory in a simulation, and what we're going to do for the next couple of hours after coffee is trying to figure out ways of solving this integrals.",
            "Questions before I go to coffee.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "Well, I've got until.",
                    "label": 0
                },
                {
                    "sent": "9:30 and then question myself, OK?",
                    "label": 0
                },
                {
                    "sent": "Also want coffee.",
                    "label": 0
                },
                {
                    "sent": "So I'm gonna start this with a movie.",
                    "label": 0
                },
                {
                    "sent": "George OK, thanks.",
                    "label": 0
                },
                {
                    "sent": "The people at the back.",
                    "label": 0
                },
                {
                    "sent": "Can you hear me Saba?",
                    "label": 0
                },
                {
                    "sent": "Yeah girl.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Let me run start with the.",
                    "label": 0
                },
                {
                    "sent": "So up to now, what we've seen is an introduction to machine learning, but there was this whirlwind tour that markets it yesterday and then there was a good analysis of the different kinds of data that arise.",
                    "label": 0
                },
                {
                    "sent": "In practice.",
                    "label": 0
                },
                {
                    "sent": "It Alex showed you.",
                    "label": 0
                },
                {
                    "sent": "My part of this summer school is going to be more on computation computation for specific kind of models, and as we go for the next 2 days it will be more clear what kind of models this type of computation is useful for.",
                    "label": 0
                },
                {
                    "sent": "It's not useful for everything, and so part of this will be that you get an idea when you can use these.",
                    "label": 0
                },
                {
                    "sent": "Methadone and went you shouldn't try.",
                    "label": 0
                },
                {
                    "sent": "It's all going to be based on sampling and simulation and so on.",
                    "label": 0
                },
                {
                    "sent": "So quite often the goal of that is to do.",
                    "label": 0
                },
                {
                    "sent": "It's obviously to do machine learning.",
                    "label": 1
                },
                {
                    "sent": "It's obviously to compute parameters to solve integrals.",
                    "label": 0
                },
                {
                    "sent": "To compute these normalization constants that Marcus was talking about yesterday.",
                    "label": 0
                },
                {
                    "sent": "But quite often it will be just as a simulation device.",
                    "label": 0
                },
                {
                    "sent": "Simulation is important because if I want to kind of.",
                    "label": 0
                },
                {
                    "sent": "Do a task like go to Sydney if I'm trying to decide what to do this weekend.",
                    "label": 0
                },
                {
                    "sent": "I can kind of simulate in my head how fun it will be once I'm in Sydney and it's Mardi Gras and all that.",
                    "label": 0
                },
                {
                    "sent": "And that kind of gives me that allows me to make decisions, and that's actually how prices in fact do come into this sort of thinking.",
                    "label": 0
                },
                {
                    "sent": "I want to make a decision in the future.",
                    "label": 0
                },
                {
                    "sent": "I have some prior knowledge in my head of state of knowledge in my head, and from that around simulations into the future.",
                    "label": 0
                },
                {
                    "sent": "So we're going to see a bit of that, and that's sort of that will be a preamble for WhatsApp is going to talk about later when he starts talking about reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Clear indication that we sample.",
                    "label": 0
                },
                {
                    "sent": "So who seen this video before?",
                    "label": 0
                },
                {
                    "sent": "If you've seen it before, stick white.",
                    "label": 0
                },
                {
                    "sent": "I have a video.",
                    "label": 0
                },
                {
                    "sent": "It's there's two pictures in this video.",
                    "label": 0
                },
                {
                    "sent": "I'm sort of flashing between one and the other, and there is a difference between the two.",
                    "label": 0
                },
                {
                    "sent": "How many people have seen the difference so far?",
                    "label": 0
                },
                {
                    "sent": "And once you see it, please don't.",
                    "label": 0
                },
                {
                    "sent": "Announce it.",
                    "label": 0
                },
                {
                    "sent": "To the rest three people, I'll give you a few more minutes.",
                    "label": 0
                },
                {
                    "sent": "It's quite a lot of number of pixels with respect to the image.",
                    "label": 0
                },
                {
                    "sent": "How many people have it?",
                    "label": 0
                },
                {
                    "sent": "It's great that you guys are waking up.",
                    "label": 0
                },
                {
                    "sent": "It is tough getting up in the morning.",
                    "label": 0
                },
                {
                    "sent": "Oh, that motion seems to be helping.",
                    "label": 0
                },
                {
                    "sent": "How many people have it now?",
                    "label": 0
                },
                {
                    "sent": "For those who haven't seen it, what do airplanes need in order to fly?",
                    "label": 0
                },
                {
                    "sent": "And just in case you haven't quite figured it out.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a phenomenon called change blindness in psychology an it's it happens with images.",
                    "label": 0
                },
                {
                    "sent": "It happens in the visual cortex, in the visual field.",
                    "label": 0
                },
                {
                    "sent": "Start in the visual cortex.",
                    "label": 0
                },
                {
                    "sent": "But it's it's characteristic of human minds and brains, and how we work.",
                    "label": 0
                },
                {
                    "sent": "We sample the world.",
                    "label": 0
                },
                {
                    "sent": "The reason why you don't see it is because we never see this image.",
                    "label": 0
                },
                {
                    "sent": "This is an illusion.",
                    "label": 0
                },
                {
                    "sent": "We believe we sing it, but we don't we sampling it.",
                    "label": 0
                },
                {
                    "sent": "And we only extract from it what we need and we do a reconstruction in our head.",
                    "label": 0
                },
                {
                    "sent": "So when you believe you're seeing the whole thing.",
                    "label": 0
                },
                {
                    "sent": "And the same is true for a type of argument.",
                    "label": 0
                },
                {
                    "sent": "So if you're into a, you know in a fight with your boyfriend or so on, and you think you're right and so on.",
                    "label": 0
                },
                {
                    "sent": "You might just not be seeing the whole picture.",
                    "label": 0
                },
                {
                    "sent": "You're living these details.",
                    "label": 0
                },
                {
                    "sent": "And that's probably more familiar.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You know it's some theorists of cognition.",
                    "label": 0
                },
                {
                    "sent": "Now it's about there being a conscious and are being subconscious processes and you just basically governing this subconscious processes so that the conscious seems to have control and a good understanding of what's going on.",
                    "label": 0
                },
                {
                    "sent": "No, it says something mechanism that's keeping things in control.",
                    "label": 0
                },
                {
                    "sent": "This is again like Alex said yesterday.",
                    "label": 0
                },
                {
                    "sent": "Please don't take this into a projecting that any of the methods I'll talk about here.",
                    "label": 0
                },
                {
                    "sent": "Describe how the brain works.",
                    "label": 0
                },
                {
                    "sent": "It's more something is important.",
                    "label": 0
                },
                {
                    "sent": "It's useful for humans.",
                    "label": 0
                },
                {
                    "sent": "Whenever you have limited capacity to process something humans don't have, or droppers for that matter, the capacity to persist the whole visual field.",
                    "label": 0
                },
                {
                    "sent": "You focus on certain areas of the space.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's the interest, so this is what I plan to.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the next 6 hours.",
                    "label": 0
                },
                {
                    "sent": "Minus coffee, I'm gonna go for sampling methods give you a bit of a historical background or where they come from.",
                    "label": 0
                },
                {
                    "sent": "Is that you learn a lot about that from the history, and it's a good way to introduce so basic algorithms, rejection, sampling, important sampling, how many people here have heard of guess excluding market introduction yesterday had heard of rejection sampling before?",
                    "label": 1
                },
                {
                    "sent": "Important sampling.",
                    "label": 0
                },
                {
                    "sent": "MSMC OK, So what are you guys doing here?",
                    "label": 0
                },
                {
                    "sent": "Go to the beach.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to go with that particle filtering.",
                    "label": 0
                },
                {
                    "sent": "How many robots this year?",
                    "label": 0
                },
                {
                    "sent": "How many people doing robotics?",
                    "label": 0
                },
                {
                    "sent": "Can you guys?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to introduce some basic algorithms that it's good to know them because they're introductory.",
                    "label": 0
                },
                {
                    "sent": "They give you an idea of how this whole thing works, but we don't usually use them.",
                    "label": 0
                },
                {
                    "sent": "Algorithms to deal with data that is non ID systems are evolving overtime.",
                    "label": 0
                },
                {
                    "sent": "And then the sort of more hardcore algorithms that have a big name.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In the last part of the course, I will focus on.",
                    "label": 0
                },
                {
                    "sent": "Trying to do like what's currently so this would be all introduction, a way to catch up with what people do.",
                    "label": 0
                },
                {
                    "sent": "This would be kind of more like what's what are people researching now.",
                    "label": 0
                },
                {
                    "sent": "I this is sort of more dodgy.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's start.",
                    "label": 0
                },
                {
                    "sent": "Think markets kind of did a bit of this yesterday.",
                    "label": 0
                },
                {
                    "sent": "What's the probability that if you wait to throw a dart at this board, and assuming that there's some sort of force that attracted to this square?",
                    "label": 0
                },
                {
                    "sent": "What would be the probability that it hits the red area?",
                    "label": 0
                },
                {
                    "sent": "Someone we should have like cookies for.",
                    "label": 0
                },
                {
                    "sent": "You gotta you know that sun tanning lotion.",
                    "label": 0
                },
                {
                    "sent": "That's how we should have given it.",
                    "label": 0
                },
                {
                    "sent": "Are you there?",
                    "label": 0
                },
                {
                    "sent": "He has a box of cookies.",
                    "label": 0
                },
                {
                    "sent": "OK for a box of cookies.",
                    "label": 0
                },
                {
                    "sent": "OK, 141 cookie.",
                    "label": 0
                },
                {
                    "sent": "Come on.",
                    "label": 0
                },
                {
                    "sent": "It's one cookie.",
                    "label": 0
                },
                {
                    "sent": "I know it's embarrassingly easy.",
                    "label": 0
                },
                {
                    "sent": "But it's worth a cookie Marcus.",
                    "label": 0
                },
                {
                    "sent": "Would you like a cookie?",
                    "label": 0
                },
                {
                    "sent": "Will give you a cookie for trying.",
                    "label": 0
                },
                {
                    "sent": "Stuff, thank you.",
                    "label": 0
                },
                {
                    "sent": "Whoever said, Dad, you know?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How to claim your cookie.",
                    "label": 0
                },
                {
                    "sent": "OK next one.",
                    "label": 0
                },
                {
                    "sent": "The lady over there has a cookie.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This guy.",
                    "label": 0
                },
                {
                    "sent": "You got to cook.",
                    "label": 0
                },
                {
                    "sent": "That deserves a cookie.",
                    "label": 0
                },
                {
                    "sent": "OK, here can tell me if a strategy to do this.",
                    "label": 0
                },
                {
                    "sent": "Huh?",
                    "label": 0
                },
                {
                    "sent": "Try and see.",
                    "label": 0
                },
                {
                    "sent": "This is usually an easy one before.",
                    "label": 0
                },
                {
                    "sent": "Before we do Riemann integration.",
                    "label": 0
                },
                {
                    "sent": "Or we break the thing in squares.",
                    "label": 0
                },
                {
                    "sent": "We count the number of red squares, divide by the total number of squares, and that gives you the probability of this.",
                    "label": 0
                },
                {
                    "sent": "And so these guys introduced this yesterday.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that here you need.",
                    "label": 0
                },
                {
                    "sent": "You need to end well.",
                    "label": 0
                },
                {
                    "sent": "You need end by end points if you're gonna go and do this helps make sure that with the previous one.",
                    "label": 0
                },
                {
                    "sent": "Then by Anne.",
                    "label": 0
                },
                {
                    "sent": "If you are in 3D.",
                    "label": 0
                },
                {
                    "sent": "You're gonna need.",
                    "label": 0
                },
                {
                    "sent": "To do a cube.",
                    "label": 0
                },
                {
                    "sent": "And so you'll need an by and by and.",
                    "label": 0
                },
                {
                    "sent": "So you need Ncube.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah you need an square.",
                    "label": 0
                },
                {
                    "sent": "So the problem being that as you go up in dimension.",
                    "label": 0
                },
                {
                    "sent": "You increase with powers of dimension.",
                    "label": 0
                },
                {
                    "sent": "And so this method will not scale.",
                    "label": 0
                },
                {
                    "sent": "Having said that, a lot of people do adaptive grids, so the grid size changes and.",
                    "label": 0
                },
                {
                    "sent": "The coding is just very nasty, but you know some people work in six dimensions and so on.",
                    "label": 0
                },
                {
                    "sent": "And these adaptive grids actually can actually work pretty well.",
                    "label": 0
                },
                {
                    "sent": "So it's more, I think of more matter of software engineering then.",
                    "label": 0
                },
                {
                    "sent": "Oh I mean you go for the volume to the surface so.",
                    "label": 0
                },
                {
                    "sent": "Go to the end to the D -- 1.",
                    "label": 0
                },
                {
                    "sent": "With the.",
                    "label": 0
                },
                {
                    "sent": "With adaptive grid.",
                    "label": 0
                },
                {
                    "sent": "That way, but.",
                    "label": 0
                },
                {
                    "sent": "Five or so, but it is 10 who cares about intercultural?",
                    "label": 0
                },
                {
                    "sent": "No, I agree with you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, now I'm totally with you, that's why.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, throw darts at the board.",
                    "label": 0
                },
                {
                    "sent": "Close your eyes products.",
                    "label": 0
                },
                {
                    "sent": "And then you count the number of dots that fall inside divided by the total number of dark.",
                    "label": 0
                },
                {
                    "sent": "So 3 / 4 / 7.",
                    "label": 0
                },
                {
                    "sent": "So number of dots in that area divided by number dot in the box and that gives you an estimate of the area.",
                    "label": 0
                },
                {
                    "sent": "Gives you an estimate of the probability that you will hit this.",
                    "label": 0
                },
                {
                    "sent": "OK, probabilities and areas.",
                    "label": 0
                },
                {
                    "sent": "Kind of the same thing.",
                    "label": 0
                },
                {
                    "sent": "OK. Probability is a way of measuring things, measuring events.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so first Montecarlo started with Guinness.",
                    "label": 0
                },
                {
                    "sent": "And the 1700s guy called.",
                    "label": 0
                },
                {
                    "sent": "William Gospel visit.",
                    "label": 0
                },
                {
                    "sent": "He published he was working for Guinness.",
                    "label": 0
                },
                {
                    "sent": "An he published a paper in those days 17 I think with 1700s this is the student T paper about the student T distribution and what he used to figure out the characteristics of the student T distribution with Monte Carlo simulation.",
                    "label": 0
                },
                {
                    "sent": "So that would be sort of one of the first published works or Monte Carlo simulation, though the Greeks already has some Montecarlo ways of getting pie and so on, so it all starts with Guinness research.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Center um, but what it really took off was motivated by two things that happen at the same time.",
                    "label": 0
                },
                {
                    "sent": "The fashionable 40s, when actually there were more women in computer science in those days.",
                    "label": 0
                },
                {
                    "sent": "Cancel the wedding charge of the ENIAC.",
                    "label": 1
                },
                {
                    "sent": "And the drive was this the drivers to you know nuclear power people wanted to simulate.",
                    "label": 0
                },
                {
                    "sent": "Samples and examples.",
                    "label": 0
                },
                {
                    "sent": "In this case we're actually knew turns and so on, and people wanted to compute properties of this nutrient.",
                    "label": 0
                },
                {
                    "sent": "Where is the diffusion time of this thing going through a tube 'cause you need to have that right in order to build a nuclear device.",
                    "label": 0
                },
                {
                    "sent": "Right at the same time is when computer start appearing.",
                    "label": 0
                },
                {
                    "sent": "When this is being done an when, like the ENIAC, is moved from the East Coast to Los Alamos.",
                    "label": 0
                },
                {
                    "sent": "And they did that in order to run this Monte Carlo simulations.",
                    "label": 0
                },
                {
                    "sent": "That's where the computer started and clarify Neumann for Neumann.",
                    "label": 0
                },
                {
                    "sent": "The famous phenomenon of game theory and computer science, the computer architecture started as one of these programmers.",
                    "label": 0
                },
                {
                    "sent": "One of these people that keeps wiring these things, and it was a very tedious task.",
                    "label": 0
                },
                {
                    "sent": "And for Norman actually designed the modern computer architecture to.",
                    "label": 0
                },
                {
                    "sent": "Kind of sidestepped this technical problem.",
                    "label": 1
                },
                {
                    "sent": "And be able to design Monte Carlo simulators.",
                    "label": 0
                },
                {
                    "sent": "Important sampling was invented by for Neumann.",
                    "label": 0
                },
                {
                    "sent": "I've seen the original letter whether he describes it and he actually writes the pseudocode with with numbers.",
                    "label": 0
                },
                {
                    "sent": "You know with line numbers for the code.",
                    "label": 0
                },
                {
                    "sent": "And that's the first modern program ever written.",
                    "label": 0
                },
                {
                    "sent": "In fact, at the bottom he even says I have reason to believe that a computer will one day be able to understand this.",
                    "label": 0
                },
                {
                    "sent": "So there was dust days.",
                    "label": 0
                },
                {
                    "sent": "That's when most things were developed, like the particle filters we're going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "They were developed in those days.",
                    "label": 0
                },
                {
                    "sent": "There was in 1949 the 1st paper introduced the idea.",
                    "label": 0
                },
                {
                    "sent": "An idea that was sort of this discovered I rediscovered in the 90s by many people actually started there.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And they were very smart people here at this stage.",
                    "label": 0
                },
                {
                    "sent": "Enrico Fermi had his own way of doing Monte Carlo integration.",
                    "label": 1
                },
                {
                    "sent": "He had a computer called a firm yak.",
                    "label": 0
                },
                {
                    "sent": "Nick Metropolis Stanislav William, the famous mathematician, was working with this with the guy called Metropolis, so we'll hear more about.",
                    "label": 0
                },
                {
                    "sent": "And Metropolis actually decide to cut also construct a machine.",
                    "label": 0
                },
                {
                    "sent": "So we had the ENIAC, the firm Yakan.",
                    "label": 0
                },
                {
                    "sent": "He decided to construct the maniac.",
                    "label": 0
                },
                {
                    "sent": "Thought that would be the end of acronyms in computer science.",
                    "label": 0
                },
                {
                    "sent": "These other guys metropoles for nine months for me.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Canola.",
                    "label": 0
                },
                {
                    "sent": "OK, So what can we do with this stuff?",
                    "label": 0
                },
                {
                    "sent": "So that's a sort of the history.",
                    "label": 0
                },
                {
                    "sent": "I'm so simulation is one of those things and we're going to see quite a bit of that, not only these days not.",
                    "label": 0
                },
                {
                    "sent": "But please.",
                    "label": 0
                },
                {
                    "sent": "What can I do?",
                    "label": 0
                },
                {
                    "sent": "Not so much for neutron diffusion time simulation, but more to do with you know, animation and so on.",
                    "label": 1
                },
                {
                    "sent": "These methods can be used for optimization, though I have to say when it comes to optimization, there's lots of competitors out there, so you should think twice before you adopt A month car logarithm for optimization.",
                    "label": 0
                },
                {
                    "sent": "Because if the state space is discrete, is the guys that do combinatorial optimization have come up with lots of good techniques?",
                    "label": 0
                },
                {
                    "sent": "If you can map it as a continuous problem, then Alex today will discuss a bunch of very good techniques that you could use instead.",
                    "label": 0
                },
                {
                    "sent": "But then we get to the problem of integration.",
                    "label": 0
                },
                {
                    "sent": "An an integration is the computational problem in Bayesian stats.",
                    "label": 0
                },
                {
                    "sent": "If you could do integration in high dimensions based on stats would be feasible and would be the method of choice.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Everything you do in basin integration will require solving integrals, and we're going to come to that, and the same is true when you do game theory.",
                    "label": 0
                },
                {
                    "sent": "When you need to compute best response to in order to get to Nash equilibrium.",
                    "label": 1
                },
                {
                    "sent": "Computing volumes are in high dimensions also of interest.",
                    "label": 0
                },
                {
                    "sent": "So it's a related problem.",
                    "label": 0
                },
                {
                    "sent": "If you want to compute eigenfunctions of integral operators, then again.",
                    "label": 0
                },
                {
                    "sent": "Computing eigenvectors you can do it and you can solve differential equations in integral form.",
                    "label": 0
                },
                {
                    "sent": "So if you can have a good integration method, you can compute all the standing waves.",
                    "label": 0
                },
                {
                    "sent": "Of a particle in a box or around the Atom, and you can, you know, build lasers and do all these quantum things.",
                    "label": 0
                },
                {
                    "sent": "You can also study physical properties of objects, statistical properties of materials, and so on.",
                    "label": 0
                },
                {
                    "sent": "And basically I think that last line I put there is it's all about Monte Carlo's.",
                    "label": 0
                },
                {
                    "sent": "In this setting is all about counting lots very quickly.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example of how you can use it for simulation.",
                    "label": 0
                },
                {
                    "sent": "This comes from a SIGGRAPH paper of chenyan foresight.",
                    "label": 0
                },
                {
                    "sent": "If I can get this to run.",
                    "label": 0
                },
                {
                    "sent": "Oh, hang on.",
                    "label": 0
                },
                {
                    "sent": "Sorry about that.",
                    "label": 0
                },
                {
                    "sent": "I'm having a bit of technical difficulty with this today.",
                    "label": 0
                },
                {
                    "sent": "Let me just fire it here.",
                    "label": 0
                },
                {
                    "sent": "So this is a Monte Carlo simulation of dice.",
                    "label": 0
                },
                {
                    "sent": "You know, like in the casino.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And yeah, some people already laughing said so the the idea is to try to make things that are realistic that look realistic.",
                    "label": 0
                },
                {
                    "sent": "So that looks like it's real dice in a computer program, but at the same time you have full control of the thing.",
                    "label": 0
                },
                {
                    "sent": "So in particular, we observe it.",
                    "label": 0
                },
                {
                    "sent": "Carefully, the one goes to a one.",
                    "label": 0
                },
                {
                    "sent": "The two will go to a 2.",
                    "label": 0
                },
                {
                    "sent": "The three will go to a three, and so on, so it's like if you're designing computer games, you want to create realistic settings and you want to at the same time have control of these.",
                    "label": 0
                },
                {
                    "sent": "You know, some people in the graphics literature have been doing this, and there's quite a few more examples.",
                    "label": 0
                },
                {
                    "sent": "I'm just showing you one.",
                    "label": 0
                },
                {
                    "sent": "We're gonna be more interested with using Monte Carlo to the machine learning 'cause it's the machine learning summer school.",
                    "label": 0
                },
                {
                    "sent": "And so here the idea is, you know we were trying to come up with some sort of model of the world.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm using A tag to describe the world of horses.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And we would like to do something as good as this so.",
                    "label": 0
                },
                {
                    "sent": "Let me give you now.",
                    "label": 0
                },
                {
                    "sent": "Serve for another cookie another few cookies, another game.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of things here.",
                    "label": 0
                },
                {
                    "sent": "An I have highlighted three of the two first.",
                    "label": 0
                },
                {
                    "sent": "OK, there's one too far here, another one here, and this is 1/3 too far.",
                    "label": 0
                },
                {
                    "sent": "OK, so for the cookie.",
                    "label": 0
                },
                {
                    "sent": "OK, hang on.",
                    "label": 0
                },
                {
                    "sent": "I ask this questions.",
                    "label": 0
                },
                {
                    "sent": "He got sick sorry.",
                    "label": 0
                },
                {
                    "sent": "Cooking ones left.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "Why does it will come back to that?",
                    "label": 0
                },
                {
                    "sent": "Can someone tell me?",
                    "label": 0
                },
                {
                    "sent": "And let's use the index here.",
                    "label": 0
                },
                {
                    "sent": "This will be a rose.",
                    "label": 0
                },
                {
                    "sent": "This will be column, so this is 2 one this is 3, one versus 3 two.",
                    "label": 0
                },
                {
                    "sent": "Can one point out where there is a 2 for?",
                    "label": 0
                },
                {
                    "sent": "34 oh sorry, this guy.",
                    "label": 0
                },
                {
                    "sent": "How many people agree that this is a TOFA?",
                    "label": 0
                },
                {
                    "sent": "How many people think it's not a tofa?",
                    "label": 0
                },
                {
                    "sent": "OK, so whoever put that candidate gets a cookie, OK, another one.",
                    "label": 0
                },
                {
                    "sent": "For sex, how many people agree?",
                    "label": 0
                },
                {
                    "sent": "Disagree.",
                    "label": 0
                },
                {
                    "sent": "OK. How about let me pick one?",
                    "label": 0
                },
                {
                    "sent": "My current I I I. Alright, this guy.",
                    "label": 0
                },
                {
                    "sent": "How many people think that?",
                    "label": 0
                },
                {
                    "sent": "I think these guys are too for how many people think it is.",
                    "label": 0
                },
                {
                    "sent": "This is how much faith you have in me.",
                    "label": 0
                },
                {
                    "sent": "Who doesn't think this is a true fact?",
                    "label": 0
                },
                {
                    "sent": "What about the two full with like a baby, two for growing on top?",
                    "label": 0
                },
                {
                    "sent": "OK, so there there sort of was played to quite a few people chose not to vote.",
                    "label": 0
                },
                {
                    "sent": "I have no clue a tattoo face.",
                    "label": 0
                },
                {
                    "sent": "All I know is I can take a bunch of abstract symbols.",
                    "label": 0
                },
                {
                    "sent": "I can tell you what are two first.",
                    "label": 0
                },
                {
                    "sent": "And very quickly in this, you actually made pretty strong opinions of water too far worse than what it was not, and sometimes.",
                    "label": 0
                },
                {
                    "sent": "And also it was subjective, so some people didn't pick on those same features.",
                    "label": 0
                },
                {
                    "sent": "This kind of very fast learning, very kind of abstraction, is what?",
                    "label": 0
                },
                {
                    "sent": "So that's what we would like to build given day to be able to do these induction.",
                    "label": 0
                },
                {
                    "sent": "What Josh Tenenbaum calls them the induction leaps.",
                    "label": 0
                },
                {
                    "sent": "So we very quickly learn what something is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you've seen base rule.",
                    "label": 0
                },
                {
                    "sent": "So the idea is we want to learn this.",
                    "label": 0
                },
                {
                    "sent": "Given the data D we want to learn these hypothesis and base rule provides us with a mechanism for that.",
                    "label": 0
                },
                {
                    "sent": "As long as we have a prior model of a hypothesis and we have the data and this is the sort of simulation I used for my class.",
                    "label": 0
                },
                {
                    "sent": "The sheep plus.",
                    "label": 0
                },
                {
                    "sent": "Where you know a child might have a distribution indicating you know according to the height of this density, how likely something is to be a sheep.",
                    "label": 0
                },
                {
                    "sent": "And so there's a few goats there, because God's kind of cookies have arrived.",
                    "label": 0
                },
                {
                    "sent": "Who I'll just handle who 21?",
                    "label": 0
                },
                {
                    "sent": "Alright, so the guy for asking the question there.",
                    "label": 0
                },
                {
                    "sent": "This will come in handy when the coffee arrives.",
                    "label": 0
                },
                {
                    "sent": "Who else claimed the coskey?",
                    "label": 0
                },
                {
                    "sent": "User one.",
                    "label": 0
                },
                {
                    "sent": "OK, so go to kind of like shape.",
                    "label": 0
                },
                {
                    "sent": "You might have that initial belief.",
                    "label": 0
                },
                {
                    "sent": "Then here comes the data someone actually gives you the label sheep for these guys.",
                    "label": 0
                },
                {
                    "sent": "OK, so now you have a label that ties the blue thing they had the the measurement model.",
                    "label": 0
                },
                {
                    "sent": "And why there's noise?",
                    "label": 0
                },
                {
                    "sent": "Well, because your parents say there's a ship over there and you kind of look over there and there's trees and there's grass you gotta figure out which the sheep is.",
                    "label": 0
                },
                {
                    "sent": "An if you see enough instances you soon any you know you have a good primer on how your parents think.",
                    "label": 0
                },
                {
                    "sent": "You soon start, figure out what they're going on about.",
                    "label": 0
                },
                {
                    "sent": "And so you had that prior shape.",
                    "label": 0
                },
                {
                    "sent": "You have a new observation that brings in data the data being the tag shape.",
                    "label": 0
                },
                {
                    "sent": "And with that you now get a posterior which is, you know, kind of nicely.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "I will be using a lot of graphical models which you'll hear more about next week and the way to represent this model.",
                    "label": 0
                },
                {
                    "sent": "That probabilistic model works with this graph.",
                    "label": 0
                },
                {
                    "sent": "You had a brief introduction to this yesterday, so no, that is unshaded is something we want to learn.",
                    "label": 0
                },
                {
                    "sent": "The arrow indicates the conditional probability P of the given H. A note by itself that's unshaded is just a marginal probability P of H. And then this whole thing denotes the joint of PFD komaj.",
                    "label": 0
                },
                {
                    "sent": "It's just a graphical way of representing this.",
                    "label": 0
                },
                {
                    "sent": "And here are some examples of this sort of thing.",
                    "label": 0
                },
                {
                    "sent": "And there's one more thing I needed to say there.",
                    "label": 0
                },
                {
                    "sent": "This all seems easy.",
                    "label": 0
                },
                {
                    "sent": "The trick is.",
                    "label": 0
                },
                {
                    "sent": "To do this integral.",
                    "label": 0
                },
                {
                    "sent": "You need to do the normalization to notice distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you have many hypothesis, many alternative hypothesis could be huge, and this is usually a combinatorial integral.",
                    "label": 0
                },
                {
                    "sent": "It's sort of very high dimensional.",
                    "label": 0
                },
                {
                    "sent": "Continuous integral.",
                    "label": 0
                },
                {
                    "sent": "For Bayesian inference, there's no optimization.",
                    "label": 1
                },
                {
                    "sent": "It's all about computing this integral.",
                    "label": 0
                },
                {
                    "sent": "It's an integration problems, not an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Here's another example that I got from Kevin Murphy.",
                    "label": 0
                },
                {
                    "sent": "You have a language model.",
                    "label": 0
                },
                {
                    "sent": "Probability of words in a language you have a likelihood that indicates how sounds are produced given the words, and we know how to do speech synthesis synthesis pretty well in computers, so we have good models of that and given sounds, we try to infer words.",
                    "label": 0
                },
                {
                    "sent": "So speech recognition.",
                    "label": 0
                },
                {
                    "sent": "Recognize speech.",
                    "label": 0
                },
                {
                    "sent": "Wreck Beach is a nudist beach in Vancouver and just wondering why Kevin Murphy came up with that example.",
                    "label": 0
                },
                {
                    "sent": "Um, here's another example.",
                    "label": 0
                },
                {
                    "sent": "Computer vision.",
                    "label": 0
                },
                {
                    "sent": "You have a belief beliefs about the world, the properties of the world, and so on.",
                    "label": 0
                },
                {
                    "sent": "How light comes to your eyes, how it gets reflected in objects and so on.",
                    "label": 0
                },
                {
                    "sent": "Maybe some properties of objects.",
                    "label": 0
                },
                {
                    "sent": "Pixels I guess not pixels, but contours and so on.",
                    "label": 0
                },
                {
                    "sent": "And you also know there's computer graphics that tells you, given a model, how you generate how you render images.",
                    "label": 0
                },
                {
                    "sent": "So you have an observation model, and then from that observation model you try to do computer vision to decide what the world is about given an image of the world.",
                    "label": 0
                },
                {
                    "sent": "Again, an integration problem in this sort of abstract setting.",
                    "label": 0
                },
                {
                    "sent": "But now it's not only about learning and abstraction, it's about.",
                    "label": 0
                },
                {
                    "sent": "You usually learn an abstraction with a purpose in mind.",
                    "label": 0
                },
                {
                    "sent": "Like Marcus mentioned yesterday.",
                    "label": 0
                },
                {
                    "sent": "And this is the sort of not all people with actually believe this.",
                    "label": 0
                },
                {
                    "sent": "This is the utilitarian view.",
                    "label": 0
                },
                {
                    "sent": "In philosophy we do everything with the utility in mind.",
                    "label": 0
                },
                {
                    "sent": "Let's look at the another example.",
                    "label": 0
                },
                {
                    "sent": "We saw one yesterday, but just recap.",
                    "label": 0
                },
                {
                    "sent": "Assume that we first learn a population model and we do a density very trivial density estimate like.",
                    "label": 0
                },
                {
                    "sent": "We saw yesterday.",
                    "label": 0
                },
                {
                    "sent": "You basically just count how many people are healthy, how many people have cancer in the population and that gives.",
                    "label": 0
                },
                {
                    "sent": "That's kind of a way of learning.",
                    "label": 0
                },
                {
                    "sent": "A probability that describes the population in general.",
                    "label": 0
                },
                {
                    "sent": "This will be a more complex model, but the methodology is the same.",
                    "label": 0
                },
                {
                    "sent": "Once you have that, you also can learn a reward model, reward model.",
                    "label": 0
                },
                {
                    "sent": "Actually subway, you're going to talk about that.",
                    "label": 0
                },
                {
                    "sent": "Saba, Yahoo.",
                    "label": 0
                },
                {
                    "sent": "Reading email.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "How do you pronounce it?",
                    "label": 0
                },
                {
                    "sent": "Java OK, you're going to talk about inverse.",
                    "label": 0
                },
                {
                    "sent": "Not OK, he's not, but if you need to know more about this, talk to him.",
                    "label": 0
                },
                {
                    "sent": "He'll be around.",
                    "label": 0
                },
                {
                    "sent": "Learning the rewards is actually very tough problem.",
                    "label": 0
                },
                {
                    "sent": "You know, usually we have an objective function optimizing, but there's such objective function come from that in itself is quite a challenging problem.",
                    "label": 0
                },
                {
                    "sent": "But let's assume we have learned that you're saying Java's latest algorithm that he's not going to talk to us about, and we know that if a patient is healthy, and this might also be decided by a bunch of people doing policy making, you know your politicians and your current government.",
                    "label": 0
                },
                {
                    "sent": "Might decide that if you're healthy.",
                    "label": 0
                },
                {
                    "sent": "Annual receive no treatment and there's no cost to the nation.",
                    "label": 0
                },
                {
                    "sent": "If you're have cancer in your receive no treatment, then will you die and that's kind of a loss of resources to the nation.",
                    "label": 0
                },
                {
                    "sent": "If you are healthy in your receive treatment.",
                    "label": 0
                },
                {
                    "sent": "You lose your hair and that's minus 30 cost.",
                    "label": 0
                },
                {
                    "sent": "An if you have cancer.",
                    "label": 0
                },
                {
                    "sent": "And you do receive treatment.",
                    "label": 0
                },
                {
                    "sent": "Well, you survived, but it's still.",
                    "label": 0
                },
                {
                    "sent": "You know it's tough going through this.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "The principle of expected utility, which is not the axiom, is not here expected utility.",
                    "label": 0
                },
                {
                    "sent": "I don't have time to go into it, but it comes from actually the work of for Neumann and Morgenstern in the 40s, again.",
                    "label": 0
                },
                {
                    "sent": "And it's about choice is something that comes from choice theory, where in about combining individual preferences, how to come up with a voting scheme that makes everyone happy.",
                    "label": 0
                },
                {
                    "sent": "That if you know obvious things in preferences, if you prefer it to be and you prefer B to C, then you should prefer A to C. And then there's five more for more axioms.",
                    "label": 0
                },
                {
                    "sent": "Which seems to be a better unassailable.",
                    "label": 0
                },
                {
                    "sent": "And then you try to find a function that a social choice function that satisfies all those axioms.",
                    "label": 0
                },
                {
                    "sent": "An what arises is this thing called the expected utility.",
                    "label": 0
                },
                {
                    "sent": "So it's rational in that sense, if you wanna play.",
                    "label": 0
                },
                {
                    "sent": "A game like in game theory and you wanna do?",
                    "label": 0
                },
                {
                    "sent": "Arrive at the Nash equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Then what Nash proved is that Chief you maximize this quantity.",
                    "label": 0
                },
                {
                    "sent": "Each player maximizes quantity, they'll converge to the Nash equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So in that setting it's called best response.",
                    "label": 0
                },
                {
                    "sent": "The idea of expected utility is.",
                    "label": 0
                },
                {
                    "sent": "Or this is also called average case analysis?",
                    "label": 0
                },
                {
                    "sent": "As opposed to worst case.",
                    "label": 0
                },
                {
                    "sent": "In average case analysis you assume.",
                    "label": 0
                },
                {
                    "sent": "That you want to come up with some action you wanna come up with some decision as to how to best treat, decide whether to treat people or not.",
                    "label": 0
                },
                {
                    "sent": "And the way you do it is you wait the reward according to it according to the probability that that thing might happen.",
                    "label": 0
                },
                {
                    "sent": "So you take those averages and then you maximize.",
                    "label": 0
                },
                {
                    "sent": "You find the action that maximizes that average.",
                    "label": 0
                },
                {
                    "sent": "And as a homework exercise beach exercise, you can check out that in this case you get these numbers if you actually expand those.",
                    "label": 0
                },
                {
                    "sent": "So just basically plug these numbers here.",
                    "label": 0
                },
                {
                    "sent": "And you'll get those and then you get the decision.",
                    "label": 0
                },
                {
                    "sent": "So it's this is more or less how the whole thing happens.",
                    "label": 0
                },
                {
                    "sent": "In the end you have reward models, objective models you might have to learn they might be parameterized, in which case you're learning something about it.",
                    "label": 0
                },
                {
                    "sent": "These guys might be parameterized as well.",
                    "label": 0
                },
                {
                    "sent": "You're learning something about it at the end of the day we want to reach.",
                    "label": 0
                },
                {
                    "sent": "Make a decision.",
                    "label": 0
                },
                {
                    "sent": "And this type of graphical model is represented with an influence diagram that.",
                    "label": 0
                },
                {
                    "sent": "Again, we have the data model.",
                    "label": 0
                },
                {
                    "sent": "We have the unknown quantity.",
                    "label": 0
                },
                {
                    "sent": "We have the data.",
                    "label": 0
                },
                {
                    "sent": "This is a probabilistic model, but now we have this sort of diamond nodes that indicate rewards.",
                    "label": 0
                },
                {
                    "sent": "Then we have the action.",
                    "label": 0
                },
                {
                    "sent": "The square nodes are indicate decisions.",
                    "label": 0
                },
                {
                    "sent": "And we're going to see the a bit more of this tomorrow.",
                    "label": 0
                },
                {
                    "sent": "How many of you have used Stuart Russell's book?",
                    "label": 0
                },
                {
                    "sent": "AI.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a sort of preferred approach to introduce decision theory in this book.",
                    "label": 0
                },
                {
                    "sent": "Um, so again.",
                    "label": 0
                },
                {
                    "sent": "The point of this whole thing being that.",
                    "label": 0
                },
                {
                    "sent": "If we want to solve this problem, if we want to do this, all rational decision making the trick here is to solve an integral.",
                    "label": 0
                },
                {
                    "sent": "This interval in general will be very huge.",
                    "label": 0
                },
                {
                    "sent": "That's going to be a combinatorial sum.",
                    "label": 0
                },
                {
                    "sent": "It's actually more than that.",
                    "label": 0
                },
                {
                    "sent": "It's a combinatorial sum, and it has a Max operator 'cause over 'cause what you're trying to do is you find the best action the best response, so there's Max some.",
                    "label": 0
                },
                {
                    "sent": "So you have the Max problem, the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "You have the same problem, which is just integration problem and the maximum and the maximum in many cases is easier under some problem 'cause you can do branch and bound something that I'll get you soon.",
                    "label": 0
                },
                {
                    "sent": "So one way to do going back to learning one way to do learning we've seen, is to do maximization.",
                    "label": 0
                },
                {
                    "sent": "And this is actually in fact for most settings when you're working on the web when you just want one solution.",
                    "label": 0
                },
                {
                    "sent": "This might be the best thing to do.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Where you basically just maximize the likelihood times the prior or in log space to some of their logs.",
                    "label": 0
                },
                {
                    "sent": "So the idea being that you learn this in the training data.",
                    "label": 0
                },
                {
                    "sent": "An once you have an estimate of the training data to computer prediction for the new observation.",
                    "label": 0
                },
                {
                    "sent": "Given an input.",
                    "label": 0
                },
                {
                    "sent": "You just plug in.",
                    "label": 0
                },
                {
                    "sent": "Your best estimate, the map estimate, or if you have no prior to maximum likelihood estimate or other estimates, there are the things you can do.",
                    "label": 0
                },
                {
                    "sent": "There's lots of worst case estimates where instead of taking the average of what could happen, you actually expect the worst was going to happen and you prepare yourself for the worst case.",
                    "label": 0
                },
                {
                    "sent": "So it's a sort of adversarial setting.",
                    "label": 0
                },
                {
                    "sent": "An they young Liqun has a lot of interesting algorithms.",
                    "label": 0
                },
                {
                    "sent": "Alex is also been working on those.",
                    "label": 0
                },
                {
                    "sent": "So again, we have a graph.",
                    "label": 0
                },
                {
                    "sent": "This is the parameter learning according to this parameter.",
                    "label": 0
                },
                {
                    "sent": "These observations are independent.",
                    "label": 0
                },
                {
                    "sent": "If you knew this guy, this will be independent.",
                    "label": 0
                },
                {
                    "sent": "So think of Theta as.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Rain and this means the grass is wet.",
                    "label": 0
                },
                {
                    "sent": "Let me try to come out.",
                    "label": 0
                },
                {
                    "sent": "I hate it when I try to come up with examples that make sense.",
                    "label": 0
                },
                {
                    "sent": "The sprinkler.",
                    "label": 0
                },
                {
                    "sent": "Is that the sprinkler one?",
                    "label": 0
                },
                {
                    "sent": "When you have rain?",
                    "label": 0
                },
                {
                    "sent": "You wanna know if you know this variable?",
                    "label": 0
                },
                {
                    "sent": "Then you know it's independent of that.",
                    "label": 0
                },
                {
                    "sent": "This is cloudy.",
                    "label": 0
                },
                {
                    "sent": "Hang on, let me just bring those examples here, 'cause they're very useful.",
                    "label": 0
                },
                {
                    "sent": "So no graphical model.",
                    "label": 0
                },
                {
                    "sent": "You might have something that if you have a variable that's the variable that say rain, and let's say the train.",
                    "label": 0
                },
                {
                    "sent": "Is either true or false?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Actually, let's put clouds.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "Clouds, rain and then wet.",
                    "label": 0
                },
                {
                    "sent": "Now, if you want to know.",
                    "label": 0
                },
                {
                    "sent": "Actually, let's not make it through yet.",
                    "label": 0
                },
                {
                    "sent": "If you want to know whether you're going to get so, the conditional independence here and let me use just the word CR.",
                    "label": 0
                },
                {
                    "sent": "CRNW did the notice, so this whole thing describes the joint distribution of PFW, R, C, and it's factorized as P of W given R. Times piov are given C * P FC.",
                    "label": 0
                },
                {
                    "sent": "And independence assumption here is, given that it's raining.",
                    "label": 0
                },
                {
                    "sent": "You you know whether you're wet or not.",
                    "label": 0
                },
                {
                    "sent": "So if you're outside and it's raining, then you know you will get wet.",
                    "label": 0
                },
                {
                    "sent": "You don't need to know whether there's clouds.",
                    "label": 0
                },
                {
                    "sent": "In order to know that you're going to get wet.",
                    "label": 0
                },
                {
                    "sent": "OK, so given.",
                    "label": 0
                },
                {
                    "sent": "So in other words, wet is independent.",
                    "label": 0
                },
                {
                    "sent": "Of clouds given rain.",
                    "label": 0
                },
                {
                    "sent": "So that's independent.",
                    "label": 0
                },
                {
                    "sent": "Given.",
                    "label": 0
                },
                {
                    "sent": "So that's one situation.",
                    "label": 0
                },
                {
                    "sent": "Another situation that arises.",
                    "label": 0
                },
                {
                    "sent": "And you'll see all this more in the graphical models literature, but I'm just trying to kind of.",
                    "label": 0
                },
                {
                    "sent": "But that give you a quick introduction so that.",
                    "label": 0
                },
                {
                    "sent": "More or less understand the semantics there.",
                    "label": 0
                },
                {
                    "sent": "Another example that might arise is this where you have.",
                    "label": 0
                },
                {
                    "sent": "Um and I couldn't just come up with an example.",
                    "label": 0
                },
                {
                    "sent": "No, I said that you're wet again and then there's a sprinkler.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "That's probably a bad example, but again here.",
                    "label": 0
                },
                {
                    "sent": "Rain causes you to get wet.",
                    "label": 0
                },
                {
                    "sent": "Or let's say rain.",
                    "label": 0
                },
                {
                    "sent": "Causes the frogs to come out.",
                    "label": 0
                },
                {
                    "sent": "OK. Again, if it rains, chances are she'll get wet.",
                    "label": 0
                },
                {
                    "sent": "If you happen to be outside on the grass.",
                    "label": 0
                },
                {
                    "sent": "If if it doesn't rain, then chances are that you'll be dry.",
                    "label": 0
                },
                {
                    "sent": "My inference about whether I'm wet or not does not depend on frogs.",
                    "label": 0
                },
                {
                    "sent": "In particular, wet is independent.",
                    "label": 0
                },
                {
                    "sent": "Whether you get wet is independent of whether there are frogs or not.",
                    "label": 0
                },
                {
                    "sent": "If it's given that it's raining, given that you know.",
                    "label": 0
                },
                {
                    "sent": "The value of the variable rate.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, I mean you're out there in the grass and suppose you could not tell whether it's raining or not.",
                    "label": 0
                },
                {
                    "sent": "Then you would have the.",
                    "label": 0
                },
                {
                    "sent": "You would probably look at the frogs if you knew the frogs come out when it's raining, that would give you an idea of whether you would get wet or not.",
                    "label": 0
                },
                {
                    "sent": "But if you know that it's raining that you don't need to look at the at the frogs in order to know that you're wet.",
                    "label": 0
                },
                {
                    "sent": "And that's the semantics that this is kind of captured.",
                    "label": 0
                },
                {
                    "sent": "The parameter, in other words, has given this parameter.",
                    "label": 0
                },
                {
                    "sent": "There's enough information here to generate.",
                    "label": 0
                },
                {
                    "sent": "All this.",
                    "label": 0
                },
                {
                    "sent": "Data so the parameter is a sufficient statistic for the data.",
                    "label": 0
                },
                {
                    "sent": "Is sufficient.",
                    "label": 0
                },
                {
                    "sent": "It describes everything there is about that data.",
                    "label": 0
                },
                {
                    "sent": "That's the assumption.",
                    "label": 0
                },
                {
                    "sent": "And that's more or less what this graph encodes.",
                    "label": 0
                },
                {
                    "sent": "It's also encoding how the observations are arising.",
                    "label": 0
                },
                {
                    "sent": "So we've observed this.",
                    "label": 0
                },
                {
                    "sent": "How we infer a new one.",
                    "label": 0
                },
                {
                    "sent": "So it's a graphical model way of representing set classification or regression problem.",
                    "label": 0
                },
                {
                    "sent": "The important thing in this setting is you do things by, you know, map estimation.",
                    "label": 0
                },
                {
                    "sent": "For a Bayesian, you start with base rule.",
                    "label": 0
                },
                {
                    "sent": "You keep this guy the marginal.",
                    "label": 0
                },
                {
                    "sent": "And recall that the.",
                    "label": 0
                },
                {
                    "sent": "The the the marginal again.",
                    "label": 0
                },
                {
                    "sent": "Is the integral of PO.",
                    "label": 0
                },
                {
                    "sent": "The given theater times P of theater.",
                    "label": 0
                },
                {
                    "sent": "Overfit.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In order to make a prediction, you use this quantity.",
                    "label": 0
                },
                {
                    "sent": "The evidence that we saw this predictive distribution, and the predictive for Bayesian.",
                    "label": 0
                },
                {
                    "sent": "If you want to compute the prediction, you average.",
                    "label": 0
                },
                {
                    "sent": "Overall, the data according to the posterior.",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea being that.",
                    "label": 0
                },
                {
                    "sent": "Kind of to make it you wanna compute P of Y star given X star.",
                    "label": 0
                },
                {
                    "sent": "Comedi you want a prediction based on all your data?",
                    "label": 0
                },
                {
                    "sent": "What should the prediction before and you guy X star?",
                    "label": 0
                },
                {
                    "sent": "You don't need to know about the parameters to make this prediction.",
                    "label": 0
                },
                {
                    "sent": "Because all you want is you want the integral of P of Y star, theater given X star.",
                    "label": 0
                },
                {
                    "sent": "Call Maddie over teach.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So whenever you don't know a variable you marginalise, let's.",
                    "label": 0
                },
                {
                    "sent": "That's straight from the axioms of probability.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then we use conditional.",
                    "label": 0
                },
                {
                    "sent": "The conditional independence implied by the graph and the condition independence implied by the graph.",
                    "label": 0
                },
                {
                    "sent": "So if we expand this now using conditional probability.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "Let me bring you a clean slide for this.",
                    "label": 0
                },
                {
                    "sent": "I wish I knew how to bring a slide.",
                    "label": 0
                },
                {
                    "sent": "Actually, let me do it on the board.",
                    "label": 0
                },
                {
                    "sent": "So we want to make a prediction P of Y star foreign you data input text are given our past data which included a bunch of records, XY pairs and that's the integral of P of Y star.",
                    "label": 0
                },
                {
                    "sent": "Given X star, D. , whoops.",
                    "label": 0
                },
                {
                    "sent": "Forgot the feet.",
                    "label": 0
                },
                {
                    "sent": ", theater given X star.",
                    "label": 0
                },
                {
                    "sent": "Comedi except star.",
                    "label": 0
                },
                {
                    "sent": "The theater.",
                    "label": 0
                },
                {
                    "sent": "And now we can expand this guy using conditional probability as P of Y star.",
                    "label": 0
                },
                {
                    "sent": "Given theater, X star, D. Times, P of theater given X star committee.",
                    "label": 0
                },
                {
                    "sent": "The theater.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the rule that I'm using here.",
                    "label": 0
                },
                {
                    "sent": "Is that PFA?",
                    "label": 0
                },
                {
                    "sent": "From the rules of probability, is the integral of PFA&B of AB.",
                    "label": 0
                },
                {
                    "sent": "And the role that I'm using here is P of A&B.",
                    "label": 0
                },
                {
                    "sent": "Is equal to PFB given a.",
                    "label": 0
                },
                {
                    "sent": "Times B of A.",
                    "label": 0
                },
                {
                    "sent": "Marginal set session and conditioning.",
                    "label": 0
                },
                {
                    "sent": "And the next thing is, I exploited semantics of my model an according to my model White Star given X star.",
                    "label": 0
                },
                {
                    "sent": "Is an given feature is independent of the so it's the same Mr. Frog situation?",
                    "label": 0
                },
                {
                    "sent": "These guys are frogs.",
                    "label": 0
                },
                {
                    "sent": "This is your getting wet.",
                    "label": 0
                },
                {
                    "sent": "Given that you know the state of the world, whether it's raining or not, you no longer depend on this.",
                    "label": 0
                },
                {
                    "sent": "So the information of your data is being summarized by the theater so I can drop that so I can just write this as P of Y star.",
                    "label": 0
                },
                {
                    "sent": "Given X star, D. Sorry, feet.",
                    "label": 0
                },
                {
                    "sent": "Times.",
                    "label": 0
                },
                {
                    "sent": "PIA feature and stays the same.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I should be to also given the.",
                    "label": 0
                },
                {
                    "sent": "Your first teacher from the not from extra.",
                    "label": 0
                },
                {
                    "sent": "So exploiting the conditional dependence of our model.",
                    "label": 0
                },
                {
                    "sent": "We arrive at the way of making a prediction.",
                    "label": 0
                },
                {
                    "sent": "So, and this was basically saying is you take every possible prediction that you could have every possible sort of likelihood model.",
                    "label": 0
                },
                {
                    "sent": "And you waited according to how probable that model is.",
                    "label": 0
                },
                {
                    "sent": "Maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "Does the following.",
                    "label": 0
                },
                {
                    "sent": "Assume that P of feature.",
                    "label": 0
                },
                {
                    "sent": "Given D. Can be modeled.",
                    "label": 0
                },
                {
                    "sent": "By a Delta function, a Delta functions are functions as a spike at one specific value, an theater map.",
                    "label": 0
                },
                {
                    "sent": "So it's a function that looks like this.",
                    "label": 0
                },
                {
                    "sent": "He has a spike at theater map.",
                    "label": 0
                },
                {
                    "sent": "Now a property.",
                    "label": 0
                },
                {
                    "sent": "So we'll leave this as base.",
                    "label": 0
                },
                {
                    "sent": "And then in the ML what you do is Europe.",
                    "label": 0
                },
                {
                    "sent": "You use the same stuff.",
                    "label": 0
                },
                {
                    "sent": "But you replace this distribution by the approximation, which is, you believe, only a single value, one single truth, and that truth is for the specific value of the parameters that you've obtained by optimization.",
                    "label": 0
                },
                {
                    "sent": "So you plug the Delta function there.",
                    "label": 0
                },
                {
                    "sent": "And then the property of the Dirac function is when you multiply, when you convolve it with any function, it's just equivalent evaluating the function at that point, so you get.",
                    "label": 0
                },
                {
                    "sent": "The solution of the integral gets solved automatically.",
                    "label": 0
                },
                {
                    "sent": "And so you get what we had in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "Which was.",
                    "label": 0
                },
                {
                    "sent": "This guy.",
                    "label": 0
                },
                {
                    "sent": "So you replace the integral by open optimization problem.",
                    "label": 0
                },
                {
                    "sent": "But the inverse problem you're solving is still one of integration.",
                    "label": 0
                },
                {
                    "sent": "So one way to solve an integral is to.",
                    "label": 0
                },
                {
                    "sent": "Pick one value that happens to be a value that you believe in and stick with it.",
                    "label": 0
                },
                {
                    "sent": "There's a problem with this that sometimes there isn't one single value.",
                    "label": 0
                },
                {
                    "sent": "That's obviously the best one, and there's several values or things are sort of flat.",
                    "label": 0
                },
                {
                    "sent": "And in that case.",
                    "label": 0
                },
                {
                    "sent": "You need to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The full solution.",
                    "label": 0
                },
                {
                    "sent": "So let me try to summarize.",
                    "label": 0
                },
                {
                    "sent": "In Bayesian stats, there's several ways in which integrals arise.",
                    "label": 0
                },
                {
                    "sent": "When you need to compute the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "You need to normalize.",
                    "label": 0
                },
                {
                    "sent": "You need to compute this thing.",
                    "label": 0
                },
                {
                    "sent": "The normalization constant that sometimes people refer to as the reference or the partition function.",
                    "label": 0
                },
                {
                    "sent": "You need to do marginalization.",
                    "label": 0
                },
                {
                    "sent": "You might have several variables in your model, but you only care about a subset of them.",
                    "label": 0
                },
                {
                    "sent": "So you need to do this sort of thing the inference task.",
                    "label": 0
                },
                {
                    "sent": "Which is if you have a model with lots of variables, how quickly you draw an inference about one specific variable.",
                    "label": 0
                },
                {
                    "sent": "And sometimes you're also interested in expectations.",
                    "label": 0
                },
                {
                    "sent": "You just care about the actually.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you care about the map answer or the mean, and so on.",
                    "label": 0
                },
                {
                    "sent": "If you could just about the map, then optimization kind of makes more sense.",
                    "label": 0
                },
                {
                    "sent": "No, you don't.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you just need a reconstructed image.",
                    "label": 0
                },
                {
                    "sent": "You don't need all the possible reconstructed images according to their probability.",
                    "label": 0
                },
                {
                    "sent": "So in that case you silly to be doing this type of analysis.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So that's how integrals arising in basin starts and decision theory in a simulation, and what we're going to do for the next couple of hours after coffee is trying to figure out ways of solving this integrals.",
                    "label": 0
                },
                {
                    "sent": "Questions before I go to coffee.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}