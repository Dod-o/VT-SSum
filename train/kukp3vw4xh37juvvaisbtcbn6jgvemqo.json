{
    "id": "kukp3vw4xh37juvvaisbtcbn6jgvemqo",
    "title": "Multiarmed Bandits With Limited Expert Advice",
    "info": {
        "author": [
            "Satyen Kale, Yahoo! Research"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2014_kale_limited/",
    "segmentation": [
        [
            "Well, thanks now Nicole introduction.",
            "Yahoo and this is.",
            "Attack on multi armed bandits with limited expert advice, so sorry."
        ],
        [
            "OK, so to motivate the problem I'm going to talk about the story from Nips maybe this year, maybe last year in May or may not be true, but this is quite possible, so you're at NIPS and you have a bag of money that you have to spend before it before it gets taken away from you somehow.",
            "And there are two possibilities, so there is the Harrah's Casino or the Harveys Casino.",
            "And being an academic, you really have no idea which of these two casinos you want to go and invest your money in.",
            "So so, So what you do is you go and seek out all the inveterate gamblers that you know and you ask them for their advice, because they I mean they have a lot of experience with these kinds of things.",
            "The problem is that these guys these guys are very experienced and and the demand payment in terms of beer and you being a cheap academic can only afford 2 beers.",
            "So you have to ask like two people.",
            "So let's say you ask these guys OK. Um, somehow you trust the top guy more so you decide to go with his suggestion.",
            "You go to Harrah's Lake Tahoe.",
            "Rest your money there and you end up losing all your money so.",
            "Anyway, so you know.",
            "So you're sad, but you still have some more money to invest the next day and you repeat this process over and over again.",
            "OK, but eventually you want to be able to figure out which of these guys are, you know, are good, you know, because you have a limited amount of money that you can spend on beers, so you want to be able to figure out which of these gamblers is the best one.",
            "That's the story to keep in mind.",
            "Alright."
        ],
        [
            "So to formalize this problem, here is how we do it.",
            "So we it's in the prediction with expert advice setting in the bandit case I guess.",
            "So we have a set of N experts.",
            "We call them each one through HN and there are K arms that can be pulled.",
            "So there are numbered one through K and there is a bound M on the total number of experts that you can query in each round.",
            "So in each round this is what happens if it is an online learning problem, you need each round.",
            "And every expert chooses one of these games.",
            "Pull OK, but they don't tell you what it is.",
            "So you select a subset St of at most M experts to query and then you get their advice.",
            "So basically they tell you which arm should pull now based on their advice is select one of the one of the KMS, let's call it a sub T and then you pull that arm and then you suffer the associated loss.",
            "OK, so the losses in 01 or something and as usual in online learning scenarios we measure.",
            "Performance using the metric called regret, which is simply the total loss that you know.",
            "Your algorithm suffers overtime minus the loss of the best expert.",
            "Lots of the best expert in terms of the loss that he would have suffered.",
            "If you're following this advice overtime.",
            "OK."
        ],
        [
            "So that's a set up and.",
            "This actually this this actually the setup was was appeared in the cold open problem from last year.",
            "So by any certain copy.",
            "Cameron, Peter Bartlett.",
            "So this was an open problem that they had last year and they they formalize this problem and ask for upper and lower bounds.",
            "And the conjecture that it is possible to get regret bound of something like square root K and T / M. And the motivation for for conjecturing upper bound like this is the following.",
            "So this is what happens if you look at 2 special cases.",
            "So if you look at the case N = 1, which is, which is the case where you can only query one expert.",
            "It basically reduces to the multi arm bandit problem with N as in a different terms.",
            "And in that case you can standard algorithm like Exp three will give you regret which is like order square root NT.",
            "OK so either way this little notation stands for.",
            "Basically, in the total notation I'm suppressing or logarithmic factors.",
            "In the case when M = N, that means you can query all the experts.",
            "This is the well studied.",
            "This is also investigating the literature.",
            "The well known algorithm Exp.",
            "Four will give you regret of order square root Katie.",
            "OK, so the conjecture up there is some sort of interpolation between these two upper bounds.",
            "So, but as you as you can see, actually in the M = 1 case, the conjectured upper bound is not quite tight, it has an extra factor of Ki mean.",
            "So what we're actually able to prove in this paper is that is that we actually got a tight bound, so it looks something like that.",
            "So the upper and lower bound, which looks like square root minimum of K M / M * N T and you can verify that it matches the.",
            "The special case is M = 1 and M = N. OK, so that's basically what I'm going to present now.",
            "So now I mean most of the techniques that I use in this paper are fairly well known and standard.",
            "So what I would like to highlight in this talk is how this weird minimum function arises in the upper and lower bounds, because that is really the as far as I can as I'm concerned it is the interesting part of the paper as they arise for kind of different reasons for the upper and lower bounds.",
            "OK, unfortunately there was no prize money or naming rights given for this open problem.",
            "But anyway, bragging rights."
        ],
        [
            "OK, so this is how the algorithm works.",
            "It's really quite simple.",
            "You you did, you're an experts, and you arbitrarily partition them into into an over N groups.",
            "Each group of size exactly M and let's call, let's call them B1B2 through B N / M bins.",
            "And then this is how you done this is what you do in algorithm in algorithm.",
            "So you run standard experts learning algorithm.",
            "Same model could updates or the Poly in algorithm and in every round this algorithm.",
            "This based learning expert learning algorithm gives you a probability distribution over experts Q1 to Q2 through QN.",
            "Then you select an expert from this distribution and then and you basically ask for his advice and use that arm.",
            "And then you basically choose the same bin in which the expert is located to query for for advice.",
            "So so, so essentially you're exactly querying M experts in every round.",
            "OK. Oh, so once you do that, you construct unbiased loss estimators for every expert using the standard importance weighting scheme.",
            "Again, the math is not very important, but it's the standard so that you might have seen fast, so you plug in these unbiased loss estimators into your base learning algorithm and then updates your distribution, and then you repeat this process.",
            "So that's that's how the algorithm works.",
            "Oak."
        ],
        [
            "So analysis it's again not very hard.",
            "So first of all, the first thing to notice is that because we are basically choosing the expert to query from the distribution given by the base expert learning algorithm, the expected regret of our algorithm is basically equal to the expected regret of the base learning algorithm.",
            "Now you can bound the regret of the base learning algorithm in terms of essentially the variance of the loss estimators.",
            "So it looks like square root of the sum of the expected way the variance expected squared values of the loss estimators times the log in factor.",
            "So the game.",
            "So basically all we have to do is like bound this expectation of the square OK. Again, not a very difficult analysis tells you that this expectation is is simply the IT can be.",
            "You can basically do a simple counting argument which tells you that this expectation is simply the number of pairs I, a where I indexes have been of experts and indexes and arm so that basically there is an expert in that bin which advises that arm OK. And this is easily bounded by the total number of bins, which is an over M times the total number of arms that can be recommended by any experts in the bin, and that is simply wanted by minimum of carms because the effective number of arms of recommended by any by experts in any bin is at most minimum of K, and that's where the minimum comes from.",
            "In the upper bound here you plug it into the standard analysis and you get the upper bound that you want.",
            "OK, so don't."
        ],
        [
            "To the to the lower bound, it's again follows the pretty standard information theoretic arguments.",
            "So so, so basically the way it works is very simple in right at the beginning you select one of the experts arbitrarily to be your best expert.",
            "And in each round, what you're going to do is every expert chooses one of the K arms uniformly at random.",
            "OK, except sorry, and then you specify the loss of the of the arms.",
            "So basically, the best expert, whatever army chooses in any given down, we choose the loss of that arm from a Bernoulli with parameter half minus epsilon, and the losses of all other arms that are not chosen by the best expert or just uniform random bundles.",
            "So it's very easy to see that unless the best expert is in your selected set of experts to query in any round for the algorithm and the arm that you chose is the one that is recommended by the best expert, your regret is going to be at least epsilon over 2 in expectation.",
            "So so basically all you have to do is like bound the probability that that in any given round the best expert is in the selected set of experts and the arm that you chose was the one that is recommended by the best expert."
        ],
        [
            "You can bound this probability.",
            "It automatically implies lower bound, which on the regret which looks like square root T divided by the probability.",
            "OK, so essentially we want to upper bound the probability.",
            "OK, now if you.",
            "If you workout the combinatorics of this it's quite simple.",
            "It turns out that you can actually bound this probability by, but what I've written there.",
            "So in words.",
            "Basically what you have to do is bound the expected number of the maximum number of experts in any given bin that will recommend given arm OK.",
            "So let me say that again.",
            "So it is the expectation of the the most experts that you can find in any bin which recommend the same arm and that divided by N. OK, so the probability is bounded by this expectation.",
            "And now to be able to bound this expectation, we think of this very classic.",
            "Stochastic process that is studied in classically, maybe the balls into bins process, which basically you think of you think of the K arms, has bins and you're tossing EM.",
            "You're tossing em balls into the bins and uniformly at random.",
            "Basically because every expert chooses a band, uniform and arm uniformly at random to select.",
            "And then what you need to bound here is exactly the maximum expected expected maximum load in this ball balls into bins process.",
            "OK, that's all we need to bound.",
            "And again, this is a very well developed well known theory.",
            "The expected maximum load is can be bounded by the Max of EM over K, which is like which is expected value and lock key.",
            "OK, because what happens is if M = K then essentially the most loaded bin Tere needs about log case like actually log out, log, log but for our purposes legisla came.",
            "OK, so that's what we get from the expected Max load.",
            "Again, you plug it into the bounded I mentioned above.",
            "The Max goes in the denominator when you bring it to the numerator becomes a min OK, and so you end up with a lower bound which looks like square root, min KM, mean of K were murdered by M * N T. OK, so that's basically all I have to say, except that there are."
        ],
        [
            "Extensions so this lower bound technique that I showed you here also extends very easily to a situation where you don't have to necessarily select exactly M experts in every round.",
            "But if you're given a global budget of empty, that empty queries to all experts overall rounds the same.",
            "Lower bound works OK, so essentially it tells you that the best strategy is to simply allocate your query budget uniformly over rounds.",
            "Again, again, the upper and lower bounds both extent pretty easily to the situation where you have specified a different number of number of experts that you can query in every round sieve in round T specified empty experts to be queried.",
            "You essentially get the same kind of points.",
            "OK, the lower bounds also extended pretty pretty easily.",
            "So that those are the couple extensions and I'll just end with some conclusions.",
            "So so."
        ],
        [
            "In this paper we gave near optimal upper and lower bounds for the multi arm bandit problem will expire twice, thereby solving the cold open problem from last year.",
            "And we have a couple of extensions to having a global limit on the number of experts we queried, as well as changing limits on the queries.",
            "A nice open problem is to figure out how to close the.",
            "There's like a log arhythmic or maybe a square root log arhythmic upload gap between the upper and lower bounds encrypted if you can close that and that's it.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, thanks now Nicole introduction.",
                    "label": 0
                },
                {
                    "sent": "Yahoo and this is.",
                    "label": 0
                },
                {
                    "sent": "Attack on multi armed bandits with limited expert advice, so sorry.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so to motivate the problem I'm going to talk about the story from Nips maybe this year, maybe last year in May or may not be true, but this is quite possible, so you're at NIPS and you have a bag of money that you have to spend before it before it gets taken away from you somehow.",
                    "label": 0
                },
                {
                    "sent": "And there are two possibilities, so there is the Harrah's Casino or the Harveys Casino.",
                    "label": 0
                },
                {
                    "sent": "And being an academic, you really have no idea which of these two casinos you want to go and invest your money in.",
                    "label": 0
                },
                {
                    "sent": "So so, So what you do is you go and seek out all the inveterate gamblers that you know and you ask them for their advice, because they I mean they have a lot of experience with these kinds of things.",
                    "label": 0
                },
                {
                    "sent": "The problem is that these guys these guys are very experienced and and the demand payment in terms of beer and you being a cheap academic can only afford 2 beers.",
                    "label": 0
                },
                {
                    "sent": "So you have to ask like two people.",
                    "label": 0
                },
                {
                    "sent": "So let's say you ask these guys OK. Um, somehow you trust the top guy more so you decide to go with his suggestion.",
                    "label": 0
                },
                {
                    "sent": "You go to Harrah's Lake Tahoe.",
                    "label": 0
                },
                {
                    "sent": "Rest your money there and you end up losing all your money so.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so you know.",
                    "label": 0
                },
                {
                    "sent": "So you're sad, but you still have some more money to invest the next day and you repeat this process over and over again.",
                    "label": 0
                },
                {
                    "sent": "OK, but eventually you want to be able to figure out which of these guys are, you know, are good, you know, because you have a limited amount of money that you can spend on beers, so you want to be able to figure out which of these gamblers is the best one.",
                    "label": 0
                },
                {
                    "sent": "That's the story to keep in mind.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to formalize this problem, here is how we do it.",
                    "label": 0
                },
                {
                    "sent": "So we it's in the prediction with expert advice setting in the bandit case I guess.",
                    "label": 0
                },
                {
                    "sent": "So we have a set of N experts.",
                    "label": 0
                },
                {
                    "sent": "We call them each one through HN and there are K arms that can be pulled.",
                    "label": 0
                },
                {
                    "sent": "So there are numbered one through K and there is a bound M on the total number of experts that you can query in each round.",
                    "label": 0
                },
                {
                    "sent": "So in each round this is what happens if it is an online learning problem, you need each round.",
                    "label": 0
                },
                {
                    "sent": "And every expert chooses one of these games.",
                    "label": 0
                },
                {
                    "sent": "Pull OK, but they don't tell you what it is.",
                    "label": 0
                },
                {
                    "sent": "So you select a subset St of at most M experts to query and then you get their advice.",
                    "label": 1
                },
                {
                    "sent": "So basically they tell you which arm should pull now based on their advice is select one of the one of the KMS, let's call it a sub T and then you pull that arm and then you suffer the associated loss.",
                    "label": 0
                },
                {
                    "sent": "OK, so the losses in 01 or something and as usual in online learning scenarios we measure.",
                    "label": 0
                },
                {
                    "sent": "Performance using the metric called regret, which is simply the total loss that you know.",
                    "label": 0
                },
                {
                    "sent": "Your algorithm suffers overtime minus the loss of the best expert.",
                    "label": 0
                },
                {
                    "sent": "Lots of the best expert in terms of the loss that he would have suffered.",
                    "label": 0
                },
                {
                    "sent": "If you're following this advice overtime.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's a set up and.",
                    "label": 0
                },
                {
                    "sent": "This actually this this actually the setup was was appeared in the cold open problem from last year.",
                    "label": 0
                },
                {
                    "sent": "So by any certain copy.",
                    "label": 0
                },
                {
                    "sent": "Cameron, Peter Bartlett.",
                    "label": 0
                },
                {
                    "sent": "So this was an open problem that they had last year and they they formalize this problem and ask for upper and lower bounds.",
                    "label": 1
                },
                {
                    "sent": "And the conjecture that it is possible to get regret bound of something like square root K and T / M. And the motivation for for conjecturing upper bound like this is the following.",
                    "label": 0
                },
                {
                    "sent": "So this is what happens if you look at 2 special cases.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the case N = 1, which is, which is the case where you can only query one expert.",
                    "label": 0
                },
                {
                    "sent": "It basically reduces to the multi arm bandit problem with N as in a different terms.",
                    "label": 0
                },
                {
                    "sent": "And in that case you can standard algorithm like Exp three will give you regret which is like order square root NT.",
                    "label": 0
                },
                {
                    "sent": "OK so either way this little notation stands for.",
                    "label": 0
                },
                {
                    "sent": "Basically, in the total notation I'm suppressing or logarithmic factors.",
                    "label": 0
                },
                {
                    "sent": "In the case when M = N, that means you can query all the experts.",
                    "label": 0
                },
                {
                    "sent": "This is the well studied.",
                    "label": 0
                },
                {
                    "sent": "This is also investigating the literature.",
                    "label": 0
                },
                {
                    "sent": "The well known algorithm Exp.",
                    "label": 0
                },
                {
                    "sent": "Four will give you regret of order square root Katie.",
                    "label": 0
                },
                {
                    "sent": "OK, so the conjecture up there is some sort of interpolation between these two upper bounds.",
                    "label": 0
                },
                {
                    "sent": "So, but as you as you can see, actually in the M = 1 case, the conjectured upper bound is not quite tight, it has an extra factor of Ki mean.",
                    "label": 0
                },
                {
                    "sent": "So what we're actually able to prove in this paper is that is that we actually got a tight bound, so it looks something like that.",
                    "label": 0
                },
                {
                    "sent": "So the upper and lower bound, which looks like square root minimum of K M / M * N T and you can verify that it matches the.",
                    "label": 1
                },
                {
                    "sent": "The special case is M = 1 and M = N. OK, so that's basically what I'm going to present now.",
                    "label": 0
                },
                {
                    "sent": "So now I mean most of the techniques that I use in this paper are fairly well known and standard.",
                    "label": 0
                },
                {
                    "sent": "So what I would like to highlight in this talk is how this weird minimum function arises in the upper and lower bounds, because that is really the as far as I can as I'm concerned it is the interesting part of the paper as they arise for kind of different reasons for the upper and lower bounds.",
                    "label": 0
                },
                {
                    "sent": "OK, unfortunately there was no prize money or naming rights given for this open problem.",
                    "label": 0
                },
                {
                    "sent": "But anyway, bragging rights.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is how the algorithm works.",
                    "label": 0
                },
                {
                    "sent": "It's really quite simple.",
                    "label": 0
                },
                {
                    "sent": "You you did, you're an experts, and you arbitrarily partition them into into an over N groups.",
                    "label": 0
                },
                {
                    "sent": "Each group of size exactly M and let's call, let's call them B1B2 through B N / M bins.",
                    "label": 1
                },
                {
                    "sent": "And then this is how you done this is what you do in algorithm in algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you run standard experts learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Same model could updates or the Poly in algorithm and in every round this algorithm.",
                    "label": 1
                },
                {
                    "sent": "This based learning expert learning algorithm gives you a probability distribution over experts Q1 to Q2 through QN.",
                    "label": 1
                },
                {
                    "sent": "Then you select an expert from this distribution and then and you basically ask for his advice and use that arm.",
                    "label": 0
                },
                {
                    "sent": "And then you basically choose the same bin in which the expert is located to query for for advice.",
                    "label": 0
                },
                {
                    "sent": "So so, so essentially you're exactly querying M experts in every round.",
                    "label": 0
                },
                {
                    "sent": "OK. Oh, so once you do that, you construct unbiased loss estimators for every expert using the standard importance weighting scheme.",
                    "label": 0
                },
                {
                    "sent": "Again, the math is not very important, but it's the standard so that you might have seen fast, so you plug in these unbiased loss estimators into your base learning algorithm and then updates your distribution, and then you repeat this process.",
                    "label": 0
                },
                {
                    "sent": "So that's that's how the algorithm works.",
                    "label": 0
                },
                {
                    "sent": "Oak.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So analysis it's again not very hard.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the first thing to notice is that because we are basically choosing the expert to query from the distribution given by the base expert learning algorithm, the expected regret of our algorithm is basically equal to the expected regret of the base learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now you can bound the regret of the base learning algorithm in terms of essentially the variance of the loss estimators.",
                    "label": 1
                },
                {
                    "sent": "So it looks like square root of the sum of the expected way the variance expected squared values of the loss estimators times the log in factor.",
                    "label": 0
                },
                {
                    "sent": "So the game.",
                    "label": 0
                },
                {
                    "sent": "So basically all we have to do is like bound this expectation of the square OK. Again, not a very difficult analysis tells you that this expectation is is simply the IT can be.",
                    "label": 0
                },
                {
                    "sent": "You can basically do a simple counting argument which tells you that this expectation is simply the number of pairs I, a where I indexes have been of experts and indexes and arm so that basically there is an expert in that bin which advises that arm OK. And this is easily bounded by the total number of bins, which is an over M times the total number of arms that can be recommended by any experts in the bin, and that is simply wanted by minimum of carms because the effective number of arms of recommended by any by experts in any bin is at most minimum of K, and that's where the minimum comes from.",
                    "label": 0
                },
                {
                    "sent": "In the upper bound here you plug it into the standard analysis and you get the upper bound that you want.",
                    "label": 0
                },
                {
                    "sent": "OK, so don't.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the to the lower bound, it's again follows the pretty standard information theoretic arguments.",
                    "label": 0
                },
                {
                    "sent": "So so, so basically the way it works is very simple in right at the beginning you select one of the experts arbitrarily to be your best expert.",
                    "label": 0
                },
                {
                    "sent": "And in each round, what you're going to do is every expert chooses one of the K arms uniformly at random.",
                    "label": 1
                },
                {
                    "sent": "OK, except sorry, and then you specify the loss of the of the arms.",
                    "label": 0
                },
                {
                    "sent": "So basically, the best expert, whatever army chooses in any given down, we choose the loss of that arm from a Bernoulli with parameter half minus epsilon, and the losses of all other arms that are not chosen by the best expert or just uniform random bundles.",
                    "label": 0
                },
                {
                    "sent": "So it's very easy to see that unless the best expert is in your selected set of experts to query in any round for the algorithm and the arm that you chose is the one that is recommended by the best expert, your regret is going to be at least epsilon over 2 in expectation.",
                    "label": 0
                },
                {
                    "sent": "So so basically all you have to do is like bound the probability that that in any given round the best expert is in the selected set of experts and the arm that you chose was the one that is recommended by the best expert.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can bound this probability.",
                    "label": 0
                },
                {
                    "sent": "It automatically implies lower bound, which on the regret which looks like square root T divided by the probability.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially we want to upper bound the probability.",
                    "label": 0
                },
                {
                    "sent": "OK, now if you.",
                    "label": 0
                },
                {
                    "sent": "If you workout the combinatorics of this it's quite simple.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you can actually bound this probability by, but what I've written there.",
                    "label": 0
                },
                {
                    "sent": "So in words.",
                    "label": 0
                },
                {
                    "sent": "Basically what you have to do is bound the expected number of the maximum number of experts in any given bin that will recommend given arm OK.",
                    "label": 0
                },
                {
                    "sent": "So let me say that again.",
                    "label": 0
                },
                {
                    "sent": "So it is the expectation of the the most experts that you can find in any bin which recommend the same arm and that divided by N. OK, so the probability is bounded by this expectation.",
                    "label": 0
                },
                {
                    "sent": "And now to be able to bound this expectation, we think of this very classic.",
                    "label": 0
                },
                {
                    "sent": "Stochastic process that is studied in classically, maybe the balls into bins process, which basically you think of you think of the K arms, has bins and you're tossing EM.",
                    "label": 0
                },
                {
                    "sent": "You're tossing em balls into the bins and uniformly at random.",
                    "label": 0
                },
                {
                    "sent": "Basically because every expert chooses a band, uniform and arm uniformly at random to select.",
                    "label": 0
                },
                {
                    "sent": "And then what you need to bound here is exactly the maximum expected expected maximum load in this ball balls into bins process.",
                    "label": 0
                },
                {
                    "sent": "OK, that's all we need to bound.",
                    "label": 1
                },
                {
                    "sent": "And again, this is a very well developed well known theory.",
                    "label": 0
                },
                {
                    "sent": "The expected maximum load is can be bounded by the Max of EM over K, which is like which is expected value and lock key.",
                    "label": 0
                },
                {
                    "sent": "OK, because what happens is if M = K then essentially the most loaded bin Tere needs about log case like actually log out, log, log but for our purposes legisla came.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's what we get from the expected Max load.",
                    "label": 0
                },
                {
                    "sent": "Again, you plug it into the bounded I mentioned above.",
                    "label": 0
                },
                {
                    "sent": "The Max goes in the denominator when you bring it to the numerator becomes a min OK, and so you end up with a lower bound which looks like square root, min KM, mean of K were murdered by M * N T. OK, so that's basically all I have to say, except that there are.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Extensions so this lower bound technique that I showed you here also extends very easily to a situation where you don't have to necessarily select exactly M experts in every round.",
                    "label": 1
                },
                {
                    "sent": "But if you're given a global budget of empty, that empty queries to all experts overall rounds the same.",
                    "label": 0
                },
                {
                    "sent": "Lower bound works OK, so essentially it tells you that the best strategy is to simply allocate your query budget uniformly over rounds.",
                    "label": 0
                },
                {
                    "sent": "Again, again, the upper and lower bounds both extent pretty easily to the situation where you have specified a different number of number of experts that you can query in every round sieve in round T specified empty experts to be queried.",
                    "label": 0
                },
                {
                    "sent": "You essentially get the same kind of points.",
                    "label": 0
                },
                {
                    "sent": "OK, the lower bounds also extended pretty pretty easily.",
                    "label": 0
                },
                {
                    "sent": "So that those are the couple extensions and I'll just end with some conclusions.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this paper we gave near optimal upper and lower bounds for the multi arm bandit problem will expire twice, thereby solving the cold open problem from last year.",
                    "label": 1
                },
                {
                    "sent": "And we have a couple of extensions to having a global limit on the number of experts we queried, as well as changing limits on the queries.",
                    "label": 0
                },
                {
                    "sent": "A nice open problem is to figure out how to close the.",
                    "label": 1
                },
                {
                    "sent": "There's like a log arhythmic or maybe a square root log arhythmic upload gap between the upper and lower bounds encrypted if you can close that and that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}