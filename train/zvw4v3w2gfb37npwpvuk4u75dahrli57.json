{
    "id": "zvw4v3w2gfb37npwpvuk4u75dahrli57",
    "title": "Machine learning",
    "info": {
        "author": [
            "Bla\u017e Fortuna, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Oct. 6, 2016",
        "recorded": "September 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2016_fortuna_machine_learning/",
    "segmentation": [
        [
            "In the morning.",
            "Over some probability and statistics encountered if some introduction to data science and what have we covered in our next.",
            "His first.",
            "What do we understand by machine learning?",
            "Then go over some ideas over some problems that are typically solved emotional learning and will be added.",
            "Check couple of methods, so hopefully by the end of this, however, we have a better understanding.",
            "To use machine learning and what?",
            "How to use it?"
        ],
        [
            "Richard Pryor the motivation.",
            "So let's say we are given appropriate task to develop a program that identifies all the persons in this article.",
            "So this is one article you see, there's a stop talking about American Medical.",
            "Theresa May now some other entities, but they're not personal, so maybe they are not what they want to cover.",
            "You don't want identify.",
            "Other question is how would one approach developing such a program?"
        ],
        [
            "So let's say one day would be so OK we can.",
            "Down open hours, delegated, understaffed, OK. Let's say we have a list of common person language that sounds like a good way to start.",
            "Identify all the all the words in the document that are from this list.",
            "Maybe then add some rules.",
            "So many rules checking as they were the leader capital character.",
            "English people names usually start with capital characters.",
            "Then we can also try to find some expressions.",
            "Maybe it's written somewhere somebody said and people usually talk, so maybe somebody is also a person and so on.",
            "So this is if you can go down and drive this route, but it's kind of tedious and it's.",
            "Cards to this kind of brittle rules to comfort."
        ],
        [
            "No.",
            "Let's say that we would have a have a collection of articles already, so we're giving the big corpus and all the names people names are annotated in there.",
            "Now the question is, can be trained a program from this kind of training it or something this labeled corpus?",
            "Can we train a program that would recognize people's and this is exactly what we do with machine learning approaches.",
            "And in our example, how would that look like?",
            "So first we have to decide that will do.",
            "It will go by label identifying putting towards this belong to a person name or not.",
            "So we break the people commenting towards and describe each work with some characteristic.",
            "So maybe everything that's on the previous slide could be used as one of the features, but we don't really need to tell the system is it and what's feature and bad features.",
            "How does it interact with the others?",
            "So example, beyond the capital, stop the capital character, it's on the list of common names.",
            "What are the words in the context?",
            "Then we mark each work from our from our purpose as a person for other.",
            "So this is what our collection of African gives us.",
            "And then we have a.",
            "We take one or one of the machine learning algorithms apply to this.",
            "And we show each other this training data and outcomes the model.",
            "And the model is basically a function to give it to work and can tell is it a person or is it other, but it's kind of very handily high level overview.",
            "And but the main idea is instead of approaching the problem from starts or saying, how is a person, then trying to maybe figure out rules and so on.",
            "We want to go for the other way.",
            "Can we see a lot of annotated data and let this machine do the figuring out of the room you just provided the signal?"
        ],
        [
            "So their features.",
            "Now get out there.",
            "So first we check with this machine learning.",
            "Then they check the standard machine learning problems so but the different classes controller problems surprised to supervise and so on.",
            "Then we will get more into detail.",
            "So how do we represent data?",
            "What actually is a model?",
            "How to represent a model, how to fit a model?",
            "It's a good model and then how to evaluate?",
            "So how good are we doing?",
            "OK, so."
        ],
        [
            "What is a learning?",
            "First of all, it says subfield of computer science.",
            "Nicole from.",
            "When will the machine became machines become more powerful?",
            "So it's kind of evolved from this pattern pattern recognition, imitation, learning theory, artificial intelligence, but nowadays it would be largely considered kind of a subfield of AI artificial intelligence.",
            "And this is an old boat from 59, so there are some summers at the field of study that gives computers the ability to learn without being explicitly programmed so.",
            "We give means of computer code, so we give it to material material to learn from.",
            "They give it kind of approaches for learning from this material and then we let it go and hopefully the out we get a model.",
            "We get out the program that is better if you'd try to program incrementally.",
            "And machine learning with most people working on machine learning, but they do, they mostly remain.",
            "The core task would be developing algorithms efficient algorithm can learn models from.",
            "In addition, please."
        ],
        [
            "So this is 1 slide from this year skinny.",
            "So lots of things are kind of on the borderline between statistics and other science.",
            "And then what was the machine learning considered a separate field?",
            "Or, heads?",
            "Or this data?",
            "Science is actually with computer scientists are better than statisticians at marketing.",
            "And it's not so.",
            "This also the cloudless code.",
            "But as data scientist do, so it's kind of in between computer science and statistics."
        ],
        [
            "Get out terminology so we'll be using couple of words throughout this talk.",
            "Maybe just to send them down.",
            "So first this training data.",
            "So what we consider building data so it's the input data be fit to the machine learning algorithm.",
            "Another it can be labeled.",
            "It can be unlabeled.",
            "We see differences.",
            "And one example of me, if you're doing sentiment classification, so we have a collection of tweets and preached, we say is it positive?",
            "Is it negative?",
            "Is it neutral sentiment?",
            "And this this is kind of the training data.",
            "So we want we want the machine to replicate.",
            "So getting from a tree to sentiment label.",
            "Then another Victor Miss model.",
            "So that is a model basically can look at it as a function that is kind of derived using some machine learning algorithm and it takes the input data and produces the desired output.",
            "So in that example the beginning input would be award out would be saying easy to a person or is not a person.",
            "And what is it then?",
            "The last word is prediction, so that is a prediction.",
            "So if you take a data point, applying the model to get a prediction.",
            "Now."
        ],
        [
            "Quick demo.",
            "So we had to so he had been what we'll be doing is binary classification, which we did.",
            "More details about it later.",
            "But what is let's suppose be?",
            "Are given a data set.",
            "We have a.",
            "Our space is a 2 dimensional thing.",
            "We have some points that we would like to classify as positive.",
            "We have some points.",
            "We would like to classify as negative.",
            "Basically we just want to.",
            "Discriminate between them so.",
            "Are being given a collection of points.",
            "Would somebody say they are ready for some sailor blue?",
            "Another question is.",
            "Can you learn a model?",
            "It will that that will be able to predict or the new point that will appoint it appears here.",
            "Is it blue or red?",
            "So looking at this picture here, it would probably say should be blue here it should be read here, not sure so.",
            "And then one by one easy way to do this.",
            "Is by.",
            "Throwing up like between the two clouds, this is called the linear model and here and everything that's in this side of the line is blue.",
            "Everything that's on this side of the line is correct, so.",
            "In that sense, so this line was picked by Central theorem to be the optimal line for this collection of data points.",
            "But you can see that if we say here, we can based on this model, you can say it said that we don't really know.",
            "We don't have any evidence.",
            "Now the models can get arbitrarily more complex, so let's say we have some more red points down here.",
            "No, we can try seem to draw a line that you see, so maybe for some blue ones we make a mistake.",
            "For some relevance, make a mistake if you try to put the line on.",
            "And here's what we can do is increase the complexity of the model so we can set up a line where it can be.",
            "Sorry.",
            "Compared to put the appointment of 2nd degrees or Parabola Tweet and we see that in this one it's doing better already.",
            "Maybe we can increase the complexity of it more as well.",
            "And then you see OK. Now if you do this kind of semicircle around this, point it within our translating.",
            "In particular whether this model in general as well, it's hard to tell this case 'cause it's a.",
            "We made it quite complex already.",
            "And what would be predictions here?",
            "So everything we discovered, what kind of white should be read?",
            "Everything that is dark grey should be blue.",
            "So disappointed, eyes here we would predict it blue and here on the edge is kind of on the edge and then you can either tell maybe here.",
            "It's still in blue but less confident blue here and still have not been responsive.",
            "Interest just kind of so this would be kind of very anecdotal view of.",
            "With machine learning algorithms do."
        ],
        [
            "You know what are the standard problems that we typically solve in machine learning approaches, so there are few classes will mostly focus on the first one first 2 classes, so one class is called supervised learning.",
            "So the idea here is we're given inputs.",
            "Plus we are also given the outputs the desired output.",
            "So example would be.",
            "I work in a labeled easy to person or not person, which would be example would be a tweet and a sentiment of that week.",
            "So we already tell the machine.",
            "But do we want to the output and now the task is just to figure out the best possible function to get this output.",
            "The second class is called on supervised and unsupervised means that we don't really have any output labels, so it's up to.",
            "Are there whoever is applying machine learning to know what he's doing and see what can he get out?",
            "The typical goal would be here too.",
            "We want to extract, detect some patterns in every cluster input.",
            "Follow this and we'll see some concrete examples of this that another class would be reinforcement learning so they won't be touching this.",
            "The idea here is that we have a program that is not given up from the input data and output data, but its position in some more dynamical environment.",
            "And it's adjusting the model that it's interacting with environment and this alcohol was so this.",
            "Using an example of reinforcement learning using neural networks for example, and then there are some kind of grey areas or not that the semi supervised where we are working with the both labeled and unlabeled data and typically the idea is we're giving a bit of level data, lots of unlabeled data can be better than just working with the label.",
            "Data directly induces an examples for that as well."
        ],
        [
            "So first supervised learning.",
            "So what's the kind of prototypical example we have training data we have inputs for this will be their access and the expected outputs.",
            "That would be wise.",
            "Again, pairs of a set of this kind of pairs and the goal is given these pairs, find a function that can match given input to the desired output.",
            "And then we have a couple of tasks, so this couldn't.",
            "Breakdown into different types of functions.",
            "For example, in classification, the output space would be a set of small set of descriptor values.",
            "In regression we are projecting into continuous space in ranking.",
            "The goal is to identify best possible order of the input data."
        ],
        [
            "So let's fication here, uh, why is appearance at any special case where we have only two like you saw before red and blue people give quality positive or negative.",
            "It's called binary classification.",
            "So then we just have pairs, but it is the input so that week and out is the sum is either plus or minus other positive sentiment, for example, or negative sentiment.",
            "Functions of the map.",
            "You could still plus or minus and we call this function of binary classifier.",
            "Computer for example.",
            "4 So we have a red points.",
            "We have blue points.",
            "And the binary classifier basically some boundary splitting our input space into into half into tool to grasp."
        ],
        [
            "If you have more than two labels.",
            "So then it's for Utah.",
            "Typically would be multiclass problem, so this means that output weaken the output is one of K, brings only one and this can be either.",
            "We can convert it to several binary problems so we can have a separate classifier for each of the K states, separate binary classifier and then pick the value of the most confident one we can have one versus one, so we could have for each pair of output value, train a binary classifier and then the label that has the most votes.",
            "Means in some problems at blue stick regression, Moody, normal logistic regression, collecting parts, or multiclass problems.",
            "But it's a decent good to keep this distinction between binary classification and multi class classification, because binary is really a special special case that can be just that.",
            "Many problems can be translated."
        ],
        [
            "Yes, so send them any problems can be translated to binary classification.",
            "Another case would be multi labeled, so here we are assigning multiple labels to one instance.",
            "Example of this would be for example topic classification.",
            "We have a document in the document, could talk about sports tennis will be games, so we have multiple levels and how to do this with binary classification.",
            "So we'll just have to train a classifier for each of the labels.",
            "And then given a new document called, Run.",
            "For the binary classifiers and assign it all the labels which are binary classifiers.",
            "And we can also music store.",
            "Lewis called the Structured output prediction, so then the output is not.",
            "Simple structure like value from a set.",
            "Here are subset, but maybe the output is 3 or something more complex.",
            "We can again translate it to a binary classification problem."
        ],
        [
            "Some examples document.",
            "So we have a optical, so it's in our case will be documents and why so the output space would be topics and technology, sports, entertainment and strong and what we want is a function that can map out.",
            "Documentaries after we do.",
            "What about topics?"
        ],
        [
            "Another example is sentiment analysis, so here we have two tweets.",
            "So the input, so the expense would be other University fees, and the output would be.",
            "Space three classes, positive, negative or neutral.",
            "There are two examples, so first 20 angry about care segment like this.",
            "Classifier."
        ],
        [
            "Another example would be object detection or images.",
            "Computers are image and the goal is to identify all the areas in the image and give them that have a bit correspond to some object in our database that they would have a bike.",
            "Here we have a person and all together you would kind of person on the bike.",
            "Classification problem."
        ],
        [
            "Another factor later, but different problem would be regression.",
            "So here we are mapping her from our.",
            "Your output space would be real numbers.",
            "Exam."
        ],
        [
            "I would input data is the how well a student is doing the high school output data is covered.",
            "The student is doing the University and then can we predict from his high school grades can predict how it will be doing at University.",
            "Again, regression problem.",
            "So we're predicting the number."
        ],
        [
            "Another example would be.",
            "Probability of default.",
            "So this is a lot.",
            "You risk management.",
            "You want to switch your.",
            "Working because different companies you might want to maybe compute the risk of individual company spelling.",
            "This is called probability of defaulting and again here input is the company or company described by some parameters and the output is hearing some country actually and the output would be the likelihood that the country will not be able to repay some of its levels in real time.",
            "And again the output is a number.",
            "So we can correct itself."
        ],
        [
            "Another problem would be that a supervised problem is ranking, so here the idea is we are given a set of objects.",
            "X1 to XN, maybe a very as well, and what we want to do is find give back unordered set of items and the training data can be provided either pointwise so that we can have a set of items and preach item in which position should it be?",
            "But it can be, which is typically easier.",
            "It can be paralyzed saying that this article should be ranked higher than this.",
            "For example."
        ],
        [
            "If you go to Google search for new product.",
            "There are 28 million pages at the back.",
            "We have to decide which ones to put to the top, and it does that by ranking function and just means that this Wikipedia page for two public was scored the highest by this ranking function.",
            "No help with the one train this so we have to get the.",
            "Did you get the police?",
            "So if you just observing but people are clicking so after somebody's back super quick and then clicks on a Lonely Planet, that's some signal.",
            "So it does that Lonely Planet page should be ranked maybe at least for this user should be rent about the Wikipedia page, maybe you can tell us something about this one that's lonely.",
            "Bandit page should be named above.",
            "Maybe we don't know.",
            "Plus maybe the user stopped reading here so the signal protected will lower and then by assembling many of these kinds of training person you can train a ranking function.",
            "Under example Dolphins.",
            "So that's a dolphin.",
            "The top ranking Pizza GameCube emulator.",
            "Followed by the animal again.",
            "How to decide which which one first, which is the ranking function?"
        ],
        [
            "Another ranking problem for probability can take into ranking would be recommendation, or in this case is a user accommodation, so you're using is leading this article.",
            "Can you recommend?",
            "Looking for articles.",
            "And this.",
            "The four articles will typically be so we have a pool of particles appearing commending articles from the last day last week.",
            "Last year what are the top four rank particles?",
            "Whether input Harry is the user context, so he's reading this article here, at least in the session here, at least in his history.",
            "Again, this is kind of and then if somebody if you will go and click this we can say OK, so this this article should be ranked higher than these three when you're training and we handle through usage, generate more training data.",
            "So this would be examples of.",
            "Supervise."
        ],
        [
            "Supervised so here we just get the examples input data, but we don't really have any.",
            "Any guidance on the output?",
            "And what can we do in this case?",
            "Is an issue because of tasks will be like clustering, anomaly detection, emotionality reductions."
        ],
        [
            "Only one so class clustering, so clustering is.",
            "One of our standard Pacific nation clustering.",
            "We wanna be standard or tools in the machine learning toolbox.",
            "Full of clustering, so we're given a virtual object.",
            "We want to identify some groups of objects that are still share some characteristics that is different given by some similarity function.",
            "So that means if you have a you see some objects would be these points.",
            "Here we would like to say that the ones that are closer to each other maybe share should belong to the same group, where there is another not so close to each other should not belong in the same group.",
            "You can see that here.",
            "Big blobs and you would want our clustering algorithm figure after this tool box.",
            "Now one thing that is very important it is that this pretty much depends on the similarity measure that you give it.",
            "So the similarity measure is the distance.",
            "Then we could say OK if you would be able to capture this.",
            "If you imagine that we project all these data to the white exist, then the distance on the Y axis doesn't really tell us anything about these two clusters.",
            "Needed senses.",
            "Outlook.",
            "I'm working because of this.",
            "Also, it's like nontrivial to do a proper operation of two different clustering approaches, and it's very much.",
            "So any?"
        ],
        [
            "Use optical, so let's say we have a stream of.",
            "All or most of the news articles published in some period of time.",
            "Well, if you would cluster similar articles together, what we get is hammock events so.",
            "So clustering one day of news is would be kind of top events and you considered so Trump says something has 2000 capitals Galaxy Note 7, exploding his thousand particles and so on.",
            "So these are all the articles that were talking about Samsung Galaxy Note 7 for some aspect of it that study or together and they were not see that enough to something else.",
            "Some other classes.",
            "And if you look inside, we see the connected lots of kind of similar articles talking about the same topic, and this is the similarity.",
            "For example, this clustering algorithm was using.",
            "So putting articles about same entities and topics together.",
            "Another one."
        ],
        [
            "Supervised another area for unsupervised methods would be anomaly detection.",
            "So here they used to identify events or if there is a stream of events of observations and we want to identify when observational in events is not.",
            "Does not conform to something that is expected.",
            "It's good to know that anomaly is a very domain specific term.",
            "Presently, if you hear this again so.",
            "Who is missing here?",
            "Kind of a bad thing.",
            "Earthquake.",
            "Is not missing here would be a good thing.",
            "So very we have to visit.",
            "You have to make taking this domain into account."
        ],
        [
            "How we usually deal with the density.",
            "That'll be the anomaly detection, so one standard base dividend too.",
            "Been kind of density so that the estimated distribution in degree and then of the space of all the observations sending a new observational demand falls into low likelihood space.",
            "Then we say, OK, let's anomaly, and these are some examples of teenagers.",
            "Neighbors would be nice for one class SVM, so before we're looking at this, we were trying to speed this space in half.",
            "Now here we have a bunch of points we're not trying to see the space in half, but.",
            "We have three branches, be the spacing help, but we're splitting it in a way so we have all the points in one side and our space should be as small as possible, so that's kind of different things in everything that should be outside another point that belongs clearly says Anomaly.",
            "It belongs here.",
            "They say that's expected.",
            "Clustering could be used for that as well so.",
            "Another"
        ],
        [
            "Radio 4 infection.",
            "There is two different given some car dimensional data and we would like to identify a couple of Rd dimensional couple of dimensions.",
            "For.",
            "That's still capture the most information is data, but as most information mean, every principle component analysis is 1 standard approach to this.",
            "They're most information.",
            "It mean capturing the most varieties of a full power data would be in a crowd like this.",
            "They would say, OK, this is the most important dimension 'cause it has the most variety along.",
            "Another approach to this would be similar in composition.",
            "There we are trying to find the low rank matrix.",
            "It approximates the data.",
            "Population analysis for multiple data."
        ],
        [
            "Another another this is the latest or anomaly detection in some way, but there are supervised area between density estimation.",
            "So here again we're doing a bunch of formulation and ideas can be estimated.",
            "The density function of this.",
            "And the last one with."
        ],
        [
            "We are out in quarters.",
            "How are you?",
            "This is using a neural network, artificial neural network and the idea here is that we have our input.",
            "This is what we're given and we say our inputs should approximately correspond to what the input.",
            "But we try to squeeze it through some kind of low dimensional representation.",
            "And this is useful in either dimension.",
            "Look summation, so visualizations if you want high dimensional data and you want to put it on the monitor and then we have to put it in somehow into D and then getting here for points to do it means that we have now haptics and why and you can say OK, Now we can run the script.",
            "The later on the screen.",
            "Other thing is unsupervised feature learning and this is now especially for the image.",
            "Image sure computer vision, so sending lots of images or little parts of images through this and see what they're kind of.",
            "The prototypical things that.",
            "Gets built in settings or other features."
        ],
        [
            "Now one class of.",
            "Yet another class of problems that lies in the boundary would be.",
            "The idea here is we are we have some label data, but we also have access to lots of unlabeled data.",
            "So sometimes this is something this is the case sometimes not.",
            "For example, if you have lots of documents but it's very expensive to label the documents and we would get 100 documents table and have a million documents in the site so we can use this to use this unlabeled documents to better get the feel of the space.",
            "The ones with Adventure Market would be the ones that they are not able to.",
            "Once with this one is would be marked as related.",
            "We could see this kind of distribution that is underlying the data from this unlabeled documents and it's easy to say maybe for this one.",
            "Let's say this green picture.",
            "It say it's green.",
            "This one is red, whereas if you wouldn't care if you wouldn't have this label twice, the model would probably be quite different.",
            "This approach is usually called transduction."
        ],
        [
            "Another nice one is active learning.",
            "Useful technique, so the idea here is we are given with a.",
            "And we have access to our expert that can label a document.",
            "Now the question is so we don't have enough money for the expert to label all the data set.",
            "Can we select some small subset that would be optimal for the task we are trying to accomplish an example classification?",
            "She's a short animation."
        ],
        [
            "So let's see there.",
            "We have a data set of companies which company is described by something some features.",
            "And we want to train a classifier between detect financial companies.",
            "So this would be the ones here and we had somebody went down, provided some examples and Barclays.",
            "This is Goldman Sachs or financial companies.",
            "Apple is not a financial company, General Motor Sport or not.",
            "And then these other ones.",
            "We don't really know and now we would run the model like we did before by clicking by.",
            "Did you run this demo before and you get this kind of line?",
            "So OK?",
            "These are these are.",
            "Company.",
            "Actually this is.",
            "And then we select and then we algorithms goes and says OK, Apple is efinancial company or not and the user says no.",
            "Labeling group anything around the\nOut the line is a bit higher then the algorithm says.",
            "What about Microsoft Microsoft Financial Company?",
            "And the expert says no.",
            "And we saw that stopping from these two investor companies and asking fewer there.",
            "Now we slowly converge to open Mark Citigroup.",
            "This one you're slowly converging to the good place and the way we were selecting this user algorithms away for selecting which company to label.",
            "It was mostly on how close it is to the decision boundary, meaning how uncertain the model is about where to put it.",
            "And the intuition goes, if we can label this uncertain elements, and so we are introducing certainty in the system.",
            "In helping the model.",
            "So this would be kind of the.",
            "How would you do that if you know?",
            "I mean, you could have whatever polynomial distribution or something.",
            "Yeah, yeah strange.",
            "I'm just wondering how you combine that with model selection for each model that candidates can do active learning.",
            "So depending you could run it with different model parameters in parallel.",
            "Can you different model parameters to select the?",
            "Think not think maybe for now, not on the level of.",
            "You can people do it sometimes for optimizing kind of learnings for this regularization parameters model selection I think is already kind of.",
            "Lots of approaches depend on the explicit model being used, so need to hear if we're relying a model big align to some degree curve.",
            "Decision tree would be not really have the same effect.",
            "In this case we have optimism."
        ],
        [
            "So we went to different.",
            "Examples of different problems that we can that people are selling machine learning.",
            "There are many more so, but this is just a scratch the surface and now we'll go kind of through the pipeline how to how starting to feel a pinch of data, how to get to a working model.",
            "So the first thing is data representation.",
            "So if you are giving the text and the algorithm expects a vector on input, how do we go from one to the other one example?",
            "So what we should data points are typically represented by features or attributes, so it's just called.",
            "Whenever I say pictures, I mean some.",
            "Parameters and one you related to the example.",
            "Is it?",
            "Is it exact representation?",
            "Depends on the algorithm.",
            "So if you're working with decision trees then they work with the individual attributes and distinguish between continuous and discrete attributes.",
            "For example, if you work with a linear models like logistic regression, SVM.",
            "They work with vectors for most directive we are, so we have to get our data to something that we can encode into as a point in a vector space.",
            "Then there are approaches that only require similarity measure.",
            "So given to data points we don't need it's representation.",
            "You just need to tell how similar they are some degree.",
            "Methods for example.",
            "And then also.",
            "Actually learning representation.",
            "So if you start with words in the figure out their vector representation can be learned from the data itself."
        ],
        [
            "So when the standard example that will be using like the House in the account of camera end zone section is text presentation and vector space model would be one of the standard representations on the idea of vector space model.",
            "So we take document and we first identify all the unique words that occur in this document.",
            "According to Partition the documents and then each word becomes one dimension.",
            "Example later and then for the individual document.",
            "So it's a vector in this space which which each word corresponding to.",
            "And then you say the value in that dimension is 1, but the network occurs if the document is there otherwise.",
            "So this can be more complicated, so we can use different weights, but this is a basic level.",
            "We're just for a document saying that some of the current feature or not."
        ],
        [
            "So here we have 3.",
            "We have three documents.",
            "Bachman Turner, two documentaries without my phone, 2, three, and here are a couple of thoughts that I slept from these documents for.",
            "There are many more, so this typically working with vector space model.",
            "You're quite early.",
            "Get to hundreds of thousands of dimensions, so whatever algorithm using they have to be able to copy that.",
            "So then we have.",
            "We take OK the first words we say Angela and you see it appears in all the documents.",
            "Now we can do also called engrams, for this case, bigram, so frequently Co occurring words Whitaker together, and this kind of allows us to extract decreases as well.",
            "Brexit occurs in the first one.",
            "You don't need a second and the problem is you want and now at the end if you need.",
            "If you have three vectors and now if you compare the distance between these factors we can see how all this on some level, usually more topical level.",
            "How similar we are.",
            "So the distance between these large dimensional data points which we don't measure video previous distance, but you measured it causing distance, which is kind of.",
            "Normalize vectors and then check the angle between them is this.",
            "Kind of compensates for the length of the document, so it's easier also to compare short and long documents."
        ],
        [
            "Now there are a couple of.",
            "Or a couple of things that's good to know, so this this is different.",
            "The representation is also called bag of words back in a sense that we take all the words of the document and we threw them in.",
            "We disregard the order, but most often we would also count how many times individual work occurs, so it's not always 10 or something else like.",
            "There are different ways how to actually compute the weights in the world, so it's not obvious that one is the best or surely surely it's not the best way.",
            "So how for a different word, for example?"
        ],
        [
            "He's great, he's comparing Brexit position.",
            "Which one is more important in our representation?",
            "This would often depend on the data set.",
            "So if and what are the topics?",
            "Is it asking for your week?"
        ],
        [
            "Problem can be stopped once you can have both good or other filler words that are hard to that could occur often include make.",
            "Documents look seem that even though they don't really share any kind of more important words.",
            "So one simple way is just to ignore this promising and fixed set of common words.",
            "And The thing is, if you have words of different forms of Magnus banking stuff like that, we would all want to normalize it tomorrow.",
            "Thank you.",
            "Can use understanding organization for this kind of cutting the ending.",
            "Bend high dimensionality.",
            "So for a large corpus you can easily end up with millions of words and easy way of dealing with this is using hash country where we don't actually remember.",
            "We don't say we don't assign.",
            "We from each quarter computer cash.",
            "And then we divide this cash Modelo some, let's say 100,000.",
            "And what we get out is actually our dimension.",
            "So this kind of gives us limits as to 100,000 dimension.",
            "For example, there's a number of pick and also the likelihood of distorting the similarity measure is very low.",
            "And, uh."
        ],
        [
            "Approach that we can do is actually learn representation.",
            "Another so just to be here is, so this is this vote to make.",
            "And the idea here is can be in given words and how they Co occur, how they recording documents with.",
            "But what is a Co occur with can be ended by end dimensional vectors so that words that occur in similar context.",
            "So words that have investment and stuff around it would be.",
            "Close in space.",
            "And we can see if you do that for this.",
            "Once examples we have animals and then some ports and would be closer to each other than others.",
            "So this is."
        ],
        [
            "Another modality of data type of data would be time serious.",
            "OK, very given measurements.",
            "Series of data points in time order.",
            "So for example temperature readings once per day or once per hour that I think readings here.",
            "We have number of airline passengers per year or different stuff.",
            "And if you want to do some example regression on this or some classification on this, we would also want to represent.",
            "So let's say we're here.",
            "We want to make some decision of how the things we go, but are the features that we should use and then we have some.",
            "We can compute standard statistics, mean deviation.",
            "So on we can use standalone bedding.",
            "So just use last N values.",
            "I will have the time series or any of these features or we can also.",
            "Transport the time series into some frequency domain, for example, extracted features from there.",
            "But the important thing here is that depending on the data that we get to each data packet have some specifics that it's good to know before he started crying or doing any learning on top of it."
        ],
        [
            "So, so much particular presentation.",
            "So.",
            "Model is working, machine is kind of the output of the training program.",
            "So we can put it specification for example, so it's a function function function, right?",
            "I don't know.",
            "We have different types of models, so some others can be just discriminative.",
            "So there we saw before the number example this line and that model hotel is something on one side or the other, but it didn't really tell us much more about the data.",
            "You can have generative models, but from the model we can go out and actually generate examples that look very much like our data set.",
            "Alien.",
            "So each model we want also depends on the task.",
            "But it's more."
        ],
        [
            "Have we got a couple of super models and how they look like for the most one of the most common models is a linear model, so it's very simple, so we have a linear function.",
            "Features.",
            "We multiply the feature vector with some.",
            "And we get a prediction.",
            "Then if you specification we can change that may be the sign of the prediction to say it's a positive or negative, but that's it.",
            "In the end, we are searching for the linear model, but we are searching for is basically the parameter vector W. When they can be off, they are kind of nice and easy behaved.",
            "Yeah, typically on expanding not so expensive to train.",
            "Most prediction is quite fast, so just the number will never compile in the number of features that we have nausea features.",
            "Probably not.",
            "You know, so we don't really.",
            "They can't capture nonlinear patterns, and here is the examples.",
            "We have house size and price later, and it's not really noticeable relationship.",
            "So it goes kind of like this and if you want to, if you go try to fit it with the line, it kind of fits but not really.",
            "She tried to put a rubber tree just kind of looks better already if you picked up or polynomial of degree 6 St we can hit each point exactly but I think looking at this time everybody would agree that it's probably.",
            "It doesn't generalize helping other data, and this is what we call overthinking, and we do that."
        ],
        [
            "Geometric interpretation of classifier.",
            "It's basically the W vector would be a normal of these hyperplanes.",
            "That is dividing the positive and negative side."
        ],
        [
            "Their position is that we have a support each feature to get away.",
            "Positive features vote for a positive plus negative features.",
            "Features for negative class.",
            "We sent them all together.",
            "We move to present with features from them up together and we see the final both conclusion.",
            "Larger debates, typically stronger divorce, also depending on the picture size, but that's kind of the interpretation and we'll see later in the hands of 1 computers entities.",
            "No."
        ],
        [
            "How can we increase the?",
            "How can we get more fixed?",
            "With a bit more complex data, so we can't really do believe that model for efficient approaches, one would be kernel methods, so there is a bunch of algorithms there that can be written in a way that you only interact with the data points throughout the DOT product.",
            "And these dogs properties, typically called our kernel and the story behind it goes the following.",
            "So have a some mapping.",
            "It takes data from other input space in Maps into some high dimensional space, can be high in a sense of loss of dimension, number of dimension.",
            "And if you can, you can compute dot product in there.",
            "Without explicitly mapping the data for this other space and then this will be called.",
            "And the intuition behind is that in one way we are doing our learning problem in a much higher dimensional space.",
            "So what's linear Del sooner up there is not linear.",
            "Once we projected the decision now.",
            "Thank you some examples.",
            "So let's say we have a.",
            "Well this would be negative positive class.",
            "I believe that model would go like this.",
            "Now if you use a polynomial kernel.",
            "So this is what we were drinking the example before over the second degree we got this kind of problem.",
            "Use degree treat regarding a more complex so the higher the degree, the more complicated the water can be.",
            "And basically this line here is a.",
            "Actually.",
            "It's a state line, but in some higher dimensional space, so not into dimensionally, but in some foreign Nationals.",
            "If you look if you try to write it down."
        ],
        [
            "So this would be there.",
            "So what we do, we take the.",
            "We have two elements X&Y and we want to complete this indefinite dot product between them so we still do the dot product between them, but we.",
            "Would that be greedy?",
            "And if you go down and help, right, right, right it out.",
            "So let's say we have a our feature space because it's just so we have two dimensions.",
            "Our degree of the polynomial kernel is 2 and C would be once this constant factor.",
            "So what happens?",
            "So we have these two vectors.",
            "We write them down so we have a basically.",
            "So the dot product plus one.",
            "Target for that equation there and then we go down we modified began this something here and we could try to break it apart and write it again as a two individual vectors, but one has only elements from XML.",
            "He's only elements provide.",
            "We can see that.",
            "Actually this corresponds to.",
            "Don't product enough 123456 dimensional space.",
            "This not straight line before."
        ],
        [
            "So this curve is actually projection of straight line from 6 dimensional space down here and that is nice."
        ],
        [
            "That so that we have two pictures.",
            "So leader mother can't capture interaction, so it can only feature one is active or not.",
            "Feature two is one or zero for example as well.",
            "But linear model can say is feature one or two 10?",
            "Or is they're both positive?",
            "For example there is.",
            "Here you see we have a product X one times X 200.",
            "So through just by going through this kernel, methods of this polynomial kernel we are able to capture the signal.",
            "So this interaction this file.",
            "Paralyzing connections between features.",
            "Now if we increase the degree then we get the interaction between 3 features variance one.",
            "In the extreme."
        ],
        [
            "We can go to the cabin Ocean kernel very basically mapped infinite dimensional space in the capture or possible interactions.",
            "Described by public speakers.",
            "Again here.",
            "It's very easy to overfit now."
        ],
        [
            "Another way of dealing with this for how to increase the capacity would be going through supplying the artificial neural effort.",
            "And, uh.",
            "Or this is an example of neural network, but we're basically trying to do is an approximate the function, so like.",
            "Other approaches, but we use network coding, so here we have a note.",
            "This would be input nodes output nodes with our end of the notes, so everything in between and.",
            "These are called neurons.",
            "So one note can depend on more.",
            "One of the more inputs and they can send the signal outdoor one more properties and each each architecture of the network will be how are basically this topology of the graph.",
            "And then also there, but we've kept it specifies that activation, so lot of the functions.",
            "And how does this note here?",
            "How does it take that list to the inputs?",
            "And how does it integrate them together?"
        ],
        [
            "This would be moving their projector, so here we have a supervised approach, so the output will be presented, glasses or aggression.",
            "Must have at least three layers.",
            "You could layer output layer at least one hidden layer.",
            "Activation functions can be either linear, so after we take the outputs and you multiply them with a linear function, you get the value or it can be nonlinear African.",
            "Take that input and send it for some nonlinear function sigmoid or something like that.",
            "And we can do because if you get the global outlook you can use something for the softmax, skip now.",
            "Skip this, go to the demo."
        ],
        [
            "This one is a playground.",
            "Tensorflow don't work.",
            "Want to play so once we do here we select the training data.",
            "So let's start with something simple.",
            "Then you select whether our features so features will be weeks one and X2.",
            "So basically coordinates.",
            "And we don't give any hidden layers for start and that means that output is just a linear combination of these two guys if we start.",
            "We'll end up with that.",
            "Now we go for something more complex.",
            "Also this is.",
            "Maybe it would be better.",
            "Yes, you do not seem right.",
            "Yeah, just.",
            "It's more right.",
            "So we see there are blue points.",
            "It's kind of a check transport.",
            "And if you try to pick the line for secondry separated string.",
            "I mean the the model doesn't have the capacity to capture this now.",
            "One simple thing would be we can increase their features.",
            "So if you add a product feature so they're not really so before that, this polynomial of 2nd degree with already included.",
            "So if we add one more feature so the product of fixed right.",
            "Here we get up.",
            "Get perfect terms classification.",
            "But this is a this was a.",
            "Basically we're messing up the inputs so we're kind of in the future engineer.",
            "And you know how to compensate this with a more structured ways.",
            "Using for this kernel methods that we saw before, but another option since we have a neural network here.",
            "Another way of dealing with the nonlinearities introduced this linear layers.",
            "So now we have this goalkeeper features that will get mapped into intermediary values that then get mapped into the classification.",
            "Now we feel like this.",
            "We have only two neurons, limited trying.",
            "It's doing something so I can see it before I get more complex, so most of the blue aren't look most of the orange or orange, so I'm in the middle of a sacrifice, but.",
            "Increase the capacity.",
            "Free.",
            "Is not.",
            "At 4:00 component scandal stock ticker.",
            "Starting to bend.",
            "It's struggling, but it's kind of something is happening at another layer.",
            "Explain the learning curve so this is a. Alto parameter so distortion training loss so we can you know that.",
            "So the idea here is the.",
            "Applying the model of these points and training last week, how well are we doing from the training data?",
            "So if you're not doing that in the training data, then propose we want to as well on the other data.",
            "If you're doing well on the training data doesn't mean that we will do well on the other data 'cause we might be overheating.",
            "Baby please.",
            "Select all.",
            "Good point if it starts to repeat.",
            "Do you have an accent?",
            "Do you have any information or what is happening happening in the Community players?",
            "So this is the the if you just use this feature of the classifier, you will kind of.",
            "It captures this kind of signal.",
            "Then as you're learning you can see that this one basically now also added his serious kind of does.",
            "He's doing this prediction.",
            "This one is doing kind of complementary and then things get refined here and then kind of summed up together, but it's.",
            "There's lots of.",
            "So this is these are simple examples here, so it's you know it's easy to experiment.",
            "So when you get a bigger system, you really need to spend some time to get also the learning parameter, right and everything.",
            "And is adding features, so adding the number of layers.",
            "So now it looks like.",
            "So the number of hidden layers, the number of nodes in the hidden layers and the teachers is just trying to find out if I know.",
            "I mean you have a some.",
            "For some problems you have a bad, understood architectures that you could even use.",
            "So, but it's like you're selling something that is not that wasn't done with these digits.",
            "You're with lots of experimentation in your future, so it's not like this that you are doing it and then you are getting inside what is happening in this hidden layers.",
            "So you get we will ever get an intuition of what we learn.",
            "For example, if you are.",
            "Bismarck"
        ],
        [
            "So this is a neural network for solving the problem we were doing in the motivation.",
            "So this name entity recognition, for example users exactly so it has a.",
            "It starts with the word on.",
            "It takes its context and it first Maps them into.",
            "Each word is mapped into 50 dimensional vector for example.",
            "Then it is good transformation and then again the softmax to figure out the class.",
            "Now for this, if you look at this letter sent after you run documents for awhile, look at this vector, then it turns out that words that are similar by some connected similar class would have vectors that are closer together than words that are not in the same class.",
            "But this is something that is very specific to this kind of architecture.",
            "If you have some different things, there are some different wiring.",
            "Then again, you would have to go down and check what exactly it means, whereas for this lower layers it's hard to.",
            "Maybe we do lots of handwaving where lots of air particles figure out, maybe some meetings, but it's very hard to understand what's happening there.",
            "Network Speed dancer players and it gets more or less impossible.",
            "You can do visualizations for example later, so before an outing whether if you have an image problem then you can see how this image is broken into simple features and then each layer kind of capture capture with more complex features.",
            "But again, we see images.",
            "You can visualize this and agree Christopher reversing back to the image or text is a bit harder already 'cause.",
            "For this reason.",
            "Sweets.",
            "It's a large degree to black folks.",
            "And also it can be so can be also quite the month.",
            "Side effects are very good performance other side and can help out everybody which classification we have.",
            "Some examples when you take the image you just slightly distorted so you wouldn't even notice the difference and it will be classified in a completely different class.",
            "And vice versa, I can give you some which looks more like like random noise to you and you would classify it in it.",
            "Look like a classified into some quick class.",
            "Just because this intermediate layers are hard to prove.",
            "Is something going this is understanding during that time?",
            "Is 1 big coffee garden just came from this CBD conference and whose topic which is not really addressed or unlocking here public versus?",
            "Pretend.",
            "Black box.",
            "Which.",
            "Intermediate neurons right?",
            "There are some kind of Lego pieces building blocks twitch.",
            "Allow people to do this or to give up the solution in a better way for the question is.",
            "Alchemist and is building blocks.",
            "This label pieces so this is on here.",
            "And I'm sorry.",
            "Oh 15 in the case of images, somehow we can see this some elements with text, some kind of compare things may be less clear, but.",
            "General instructions, and really there's no solution will.",
            "Community doesn't have any proprietary yet.",
            "Canada.",
            "Hello.",
            "You can include the regulations or pursuing your career.",
            "So before in the examples.",
            "Here we had a good support at one or after regularization and the model or help this early stopping or something that fits their things.",
            "Yeah, it's not not definition.",
            "I just wanted to check, for example using features exponent extremely revealing some variable values.",
            "Can you just show in one year what is the equation that represents one of the like probably the first human legs.",
            "So just want to visualize it like Mathematica.",
            "Like instead of having so many features, if I just have two features, for example, it's an experience.",
            "Values of just make up relatively each feature or something, so can you just represent once mathematical?",
            "He wasn't one of them like running for student, there isn't it.",
            "Yeah, so here.",
            "It would be physically just.",
            "So linear function with some weights times X1 plus wait times X2 that extends to downloads capabilities.",
            "So this is kind of activations functions, so that would be.",
            "Lyrics.",
            "Each year we learn something and then we go to the next layer, right definition.",
            "So what is the I mean, just one simple decoration?",
            "Probably that takes from the features in the sense that to the to the next leader.",
            "So just want to make this."
        ],
        [
            "For example.",
            "Let's say we have a one possible step from input to the hidden person.",
            "There would be have a metrics that takes this three element and outputs would happen.",
            "So 3 by 4 matrix.",
            "While computing is really the weights of each of the training will give you is the metrics a in this case, for example.",
            "So this is what you're optimizing over.",
            "Well, this is fixed.",
            "The output is fixed.",
            "But you're optimizing is.",
            "Figure out out either the this metrics a.",
            "Either that's it, yeah.",
            "They are random and then they are changed.",
            "Reminder.",
            "Yes.",
            "You can understand by random or you can have some.",
            "We have different different.",
            "You can disguise."
        ],
        [
            "You cannot.",
            "So it can hear we are solving limited recognition.",
            "We can solve a similar problem or similar problem problem for example this.",
            "What to make very does this and then the task is to predict which work will be in the middle and you can use the display are both correct and plug it in here and use that as the starting point and then you're already forward to like it's much easier to generate lots of training data then from entities.",
            "And this is one way of how we can boost the performance so not starting program down from something.",
            "Maybe could you explain the principle of black backdrop?",
            "This might be sort of.",
            "The loss.",
            "Maybe just one, maybe since you're short.",
            "Spencer for radio, can you show the evil example spiral?",
            "So here we want to separate threads thoughts from blocks, right?",
            "So you see, it's pretty unpleasant.",
            "With.",
            "This setting you won't be able to do much better.",
            "Could be stronger integration.",
            "Still longer.",
            "Add other features.",
            "The nondeterministic definition.",
            "And a few more layers.",
            "Actually it's very.",
            "Very generous.",
            "So does it mean that when you do something on this, you really do like this?",
            "You have feature your layers and then yeah, this is black magic with these people.",
            "Then you're popular.",
            "Then which?",
            "Pretty much what you say, so thank here.",
            "It could be.",
            "I mean there is some you there or something.",
            "Busy.",
            "Freedom, you get some feeling, but there's lots of craft in training.",
            "Switch back now.",
            "So I think I think he had the problem is the debt is how you how you nonlinear, so you need hundreds of layers to order two previous necessarily at your stuff enough there.",
            "So the question was how many monkey are you try and so we can.",
            "We can you can you can approximate any function with the neural network.",
            "Just question is how many letters from any?",
            "But also definitely trading deficit in order to function in this area.",
            "Let's see I mean, we need to look at this.",
            "Neural networks are not not something outside whatever blush was saying before, so you never is just another function approximator.",
            "So fancy, however, everything saying, well, let's forget what we used to do and now this will solve at least once.",
            "I mean all the participants around your metrics are exactly the same.",
            "I mean, who had training testing an error?",
            "Learning great, I mean all these terms are still there, right?",
            "We just we have different functional groups.",
            "Just go to the last part, so this may be goes in line with your question.",
            "So how do we actually?"
        ],
        [
            "So now that we decided our model is this.",
            "Metrics are this vector or something.",
            "How do you find the best one?",
            "Another question first is what they mean by fast, so we have kind of two parts.",
            "One, we would want the model to work put value on the training set so even some loss function measuring the error or something on the training set.",
            "We want to be as better good as possible and the other expense case we also find another way side both on the model to generalize well to unseen data.",
            "So if you have something that was not in the training set.",
            "The whole point was that we would also work well on that, and this is kind of two competing parts.",
            "Now we go through each of them."
        ],
        [
            "So first question is how to measure loss and with the general principle is we compare the model.",
            "With the expected outputs.",
            "So in our in the cancer flow before here this also, this points are our expected outputs.",
            "The colored effect is our output, and now we want to describe this relationship.",
            "You want to describe this relationship.",
            "With some function that we can optimize over though.",
            "Preferably easily optimized and what your networks are doing is already back propagation, so you can write all the equation down and do the stochastic gradient descent.",
            "And this is one of the purchasing check from work here.",
            "So if you're doing."
        ],
        [
            "And how do we measure loss?",
            "So one straightforward, straightforward will say that.",
            "If our prediction is the same as the training data prediction, then we say it's good, so there's no.",
            "It's zero if the prediction is.",
            "If the if the difference of declassification says.",
            "So.",
            "If our predictions is different than the training data says, then you count 1.",
            "Now if we do that on the whole training data, we can write on it as application.",
            "And then this is something that we can go down and putting some optimization software in the figure and it would spit out the best F for this loss.",
            "Another way of looking at this sheet so this hinge loss.",
            "So here we say either our.",
            "Our classifier is good and if it says if we take the output, it must be quite confident in the prediction as well as soon as it's not confident saying that it's don't look at design of the function, but it has to be actually bigger than money for the confidence.",
            "As soon as it's outside lower than this, restart applying penalty and the penalty linearly increase.",
            "The bigger the misclassification is.",
            "So this is called conditionals."
        ],
        [
            "Another way of looking at it is maximum likelihood, so we are given a training data.",
            "We have our model and then we can compare because ask ourselves what's the likelihood of this data given this model?",
            "OK, so for our output for our training data, but is there a likelihood of disease classification of electrical data outputs?",
            "And the closer it is to the this is the training output, training input and the higher the likelihood of this is the happier we are.",
            "Again, we can write it down as a function.",
            "We can derive optimizing and so on so.",
            "But still.",
            "That's the general idea we want to capture the loss we want to capture the.",
            "Property of the model to work well on the training data as some more optimizable function.",
            "Then we optimize it by finding the most."
        ],
        [
            "Now the other problem is how do we ensure that we generalize well?",
            "So let's say we are.",
            "So before, so we likely to course.",
            "Might be good.",
            "Movie 6 is already obviously overheating, and now with the stand."
        ],
        [
            "This would be kind of welcome razors, so we would like to find the simplest model possible that still produces good result.",
            "Now the question is how to?",
            "How do we define a simple?"
        ],
        [
            "So this is usually by regularization and regularization can be either.",
            "Not directly included in the optimization function.",
            "In our case linear model, the norm of the vector, typically of the normal vector typically corresponds to the margin.",
            "So how it's positioned over with respect to the training data and the smaller the smaller the the normal, the larger the matching.",
            "So that's one way of shooting it.",
            "Your networks you also do.",
            "You will take your training data, take out a bit of a small set that you call validation, set and value optimizing on the training data and error will go down as we're getting more than one, we're approximately better and better.",
            "At some point the validation set, so the one that is.",
            "Part of the training set that is not used in the optimization.",
            "The error there will start to increase this.",
            "OK if you got it here then maybe we have a very generalizable model.",
            "Decision tree and then boom.",
            "Super money."
        ],
        [
            "Enough.",
            "Support vector machines, so because it's nicely German metric interpretation, so let's say we have a. Positives and negatives.",
            "There are many possible models we can lines that we can drop them between them now, which one will be preferred and one approach is to say we want the one that produces maximum margin.",
            "Now if you would put this link here then the margin so between the line and the nearest negative index positive example is quite small versus if you put the line like this it's quite the decryption.",
            "Now the task comes down to we want to find the plane that.",
            "Of course it separates plus in using the maximum margin."
        ],
        [
            "Write this down.",
            "We get down to want to minimize the North of the model.",
            "Given that we are classifying correctly, but this is not typically not possible because we have noise.",
            "Assumes perfect supportability.",
            "And then you can say OK, relax.",
            "So we still want small normal, but you also small ones.",
            "One small loss.",
            "So this is this hinge loss before.",
            "If you put these two together you basically get.",
            "So much from the mothers."
        ],
        [
            "Now the last part is how do we know we say?",
            "Be.",
            "But the data we representatives and how we train the model on it?",
            "How good are we doing so?",
            "There are three questions, kind of major questions we want to ask yourself.",
            "So what is called even tell?",
            "How would we drink?",
            "How can you be?",
            "But we will measure.",
            "Second question, how well do we have the model generalize?",
            "The last one is is better than other models.",
            "So the last time goes in line with Canvas presented today."
        ],
        [
            "Or how to quantify model performance.",
            "So typically we would.",
            "If you kept up bunch of evaluation metrics for different types of problems.",
            "Depends on the problem.",
            "Also transportation will be measured differently than regression.",
            "And also depends a lot on the domain and what is actually cause.",
            "There have been some domains.",
            "We don't care if if we find more like positive examples, but really don't want to miss anybody some other domain.",
            "So different types of wrong answers for different amount of cost plus cost, different amount of money and maybe we would factory light according to this or how much money we are using that we are making even the mother.",
            "So this is really specific and it's easy for a supervised, it's easier.",
            "Account created, nothing else where we are given explicit outputs that we want.",
            "Which might be noisy as well, but soon there kind of high quality and it gets quite hard for unsupervised problems 'cause it's given to different clusterings.",
            "Traffic collisions better without some good.",
            "They coming of age to qualify better."
        ],
        [
            "An example for a binary classification, but we typically measure, so we have a prediction.",
            "We have the true label and then we can each instance.",
            "Can be positioned into rolling.",
            "Start with the test set which reportedly separate country mix up appears to be simple.",
            "We check for each element from the test set, which are the prediction.",
            "We check the actual label and we see 2 positive means that they are.",
            "They both agree to negative means they go for grip on the negative class.",
            "Then you have false negative false positive which is kind of.",
            "Different types of mistake, and from this we can get to the kind of basic classification measure.",
            "So one is precision.",
            "Precision tells you from all the positive ones how T. Or are they.",
            "So how many of the massive positives are actually positives?",
            "Another one is very cold, so from all the positives, how many degree dentify?",
            "So these are kind of usually you get high precision but just classifying everything was negative was that it didn't make any any.",
            "Mistake, we just be very Conservative and Liberal.",
            "Few positive, but then it gets very low record and vice versa.",
            "You can always stable everything positive having terrible precision and a very good report.",
            "And then one way of combining this is called F1 measure which is geometric mean."
        ],
        [
            "Another way of looking at the model.",
            "Model Caesar through this RC cars so the idea here is that we computed two characteristics for each model, so one is this true positive rate which is a.",
            "So I know how many.",
            "So many positives can be fined and false positive rates is how many false negatives?",
            "How many negatives to be put into politics classes very well?",
            "We did them.",
            "And if you.",
            "Optimal position would be here and random would be kind of historic times 2."
        ],
        [
            "And what is nice is if you have some for lots of models and we have some confidence source, we could take the predictions sorted by the office and scores and then slowly as we increase the threshold.",
            "Threshold for where we say something is positive.",
            "So we start here everything being zero and slowly jump up and go up there.",
            "And the better the model the most keep these curves.",
            "You cannot do this if your mother doesn't have the confidence right.",
            "Motherfucker, you just need to get some samples.",
            "You can leave this apartment sacrificing after one week.",
            "Modern.",
            "Season 3"
        ],
        [
            "Progression.",
            "See, these are the measurements.",
            "This is the model will check how far the March measurement is and then we have other means.",
            "Carrera should be some dispenser is residuals.",
            "Mental confidence and determination which we do later in the end zone which tells us how well they behaves."
        ],
        [
            "Now the question 2 plus how well do we generalize?",
            "So for generalization, so one rule so that we have to be always very careful about never test on trainings, training data.",
            "This is can give.",
            "It gives full sense, false sense of performance and the model.",
            "It doesn't tell you much, so it's always good to.",
            "Split if you have the training.",
            "A lot of Liberator disputed existing training data in training and test parts.",
            "We train on the training part, then compute the valuation measures in the test part.",
            "And it's kind of sounds straightforward, but it's always.",
            "Always getting all these very easy.",
            "There's some information on the training data.",
            "Would look into the test, set one up if you have a.",
            "A stream of particles newsarticles in time.",
            "And you would randomly split in training and test and then do topic classification of those.",
            "Then it's a bit unfair.",
            "It was maybe artikkel.",
            "Use the model.",
            "In reality is you have the past data you train on and then you apply it in the future articles so you have to do this time wise place of your entity occurs in the future.",
            "If you want to handle it fell around as well and this kind of random script will not work well.",
            "Also feature extraction is running, so if you're doing the TF, IDF or some weighting scheme on the documents.",
            "Do you want to do it only on the training set, not from the combination of everything, because it start again here.",
            "So it's always good to have another difficult rule of thumb if you run your algorithm, you test it.",
            "You get a very good result.",
            "The first question should always be but very in-depth training data linking to the testing for the test data leading to the training process, so this is."
        ],
        [
            "I don't know how do we get confidence about it so when easy way of obtaining multiple metrics from the same training data is to do something called cross validation.",
            "And the idea here is that we instead of doing last month Train Pass Creek, you can do many tenfold cross predictions on standard thing.",
            "And that's where you get more number of metrics is and then you can start doing some statistical tests and therefore significance significance.",
            "And one extreme of that would be leave one out very quickly, take for the training data, remove an example training and test it on the model is 1 example and you do this for each individual example.",
            "But this can be quite possible."
        ],
        [
            "And now the last question is, is a train, the model?",
            "Is it better than what the literature says about this type of problems?",
            "Typical approach would be so this closing line against with statistics from before.",
            "We have two models F1F2.",
            "Can you tell which is better?",
            "We compute valuation metrics on a different speeds of train test.",
            "And because the Hippocrates, do they have the same mean?",
            "This would be an example of this.",
            "This permutation test that you're not showing before the thing would be, but the two sets drawn from the same distribution or not so.",
            "We have tested that and this is something that we can then say to models are statistically different.",
            "They produced a simple different output and one is better because it has a higher need for examples."
        ],
        [
            "That's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the morning.",
                    "label": 0
                },
                {
                    "sent": "Over some probability and statistics encountered if some introduction to data science and what have we covered in our next.",
                    "label": 0
                },
                {
                    "sent": "His first.",
                    "label": 0
                },
                {
                    "sent": "What do we understand by machine learning?",
                    "label": 0
                },
                {
                    "sent": "Then go over some ideas over some problems that are typically solved emotional learning and will be added.",
                    "label": 0
                },
                {
                    "sent": "Check couple of methods, so hopefully by the end of this, however, we have a better understanding.",
                    "label": 0
                },
                {
                    "sent": "To use machine learning and what?",
                    "label": 1
                },
                {
                    "sent": "How to use it?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Richard Pryor the motivation.",
                    "label": 0
                },
                {
                    "sent": "So let's say we are given appropriate task to develop a program that identifies all the persons in this article.",
                    "label": 1
                },
                {
                    "sent": "So this is one article you see, there's a stop talking about American Medical.",
                    "label": 0
                },
                {
                    "sent": "Theresa May now some other entities, but they're not personal, so maybe they are not what they want to cover.",
                    "label": 0
                },
                {
                    "sent": "You don't want identify.",
                    "label": 0
                },
                {
                    "sent": "Other question is how would one approach developing such a program?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's say one day would be so OK we can.",
                    "label": 0
                },
                {
                    "sent": "Down open hours, delegated, understaffed, OK. Let's say we have a list of common person language that sounds like a good way to start.",
                    "label": 1
                },
                {
                    "sent": "Identify all the all the words in the document that are from this list.",
                    "label": 0
                },
                {
                    "sent": "Maybe then add some rules.",
                    "label": 0
                },
                {
                    "sent": "So many rules checking as they were the leader capital character.",
                    "label": 1
                },
                {
                    "sent": "English people names usually start with capital characters.",
                    "label": 0
                },
                {
                    "sent": "Then we can also try to find some expressions.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's written somewhere somebody said and people usually talk, so maybe somebody is also a person and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is if you can go down and drive this route, but it's kind of tedious and it's.",
                    "label": 0
                },
                {
                    "sent": "Cards to this kind of brittle rules to comfort.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we would have a have a collection of articles already, so we're giving the big corpus and all the names people names are annotated in there.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, can be trained a program from this kind of training it or something this labeled corpus?",
                    "label": 0
                },
                {
                    "sent": "Can we train a program that would recognize people's and this is exactly what we do with machine learning approaches.",
                    "label": 1
                },
                {
                    "sent": "And in our example, how would that look like?",
                    "label": 0
                },
                {
                    "sent": "So first we have to decide that will do.",
                    "label": 1
                },
                {
                    "sent": "It will go by label identifying putting towards this belong to a person name or not.",
                    "label": 0
                },
                {
                    "sent": "So we break the people commenting towards and describe each work with some characteristic.",
                    "label": 0
                },
                {
                    "sent": "So maybe everything that's on the previous slide could be used as one of the features, but we don't really need to tell the system is it and what's feature and bad features.",
                    "label": 0
                },
                {
                    "sent": "How does it interact with the others?",
                    "label": 0
                },
                {
                    "sent": "So example, beyond the capital, stop the capital character, it's on the list of common names.",
                    "label": 0
                },
                {
                    "sent": "What are the words in the context?",
                    "label": 0
                },
                {
                    "sent": "Then we mark each work from our from our purpose as a person for other.",
                    "label": 1
                },
                {
                    "sent": "So this is what our collection of African gives us.",
                    "label": 0
                },
                {
                    "sent": "And then we have a.",
                    "label": 0
                },
                {
                    "sent": "We take one or one of the machine learning algorithms apply to this.",
                    "label": 0
                },
                {
                    "sent": "And we show each other this training data and outcomes the model.",
                    "label": 0
                },
                {
                    "sent": "And the model is basically a function to give it to work and can tell is it a person or is it other, but it's kind of very handily high level overview.",
                    "label": 0
                },
                {
                    "sent": "And but the main idea is instead of approaching the problem from starts or saying, how is a person, then trying to maybe figure out rules and so on.",
                    "label": 0
                },
                {
                    "sent": "We want to go for the other way.",
                    "label": 0
                },
                {
                    "sent": "Can we see a lot of annotated data and let this machine do the figuring out of the room you just provided the signal?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So their features.",
                    "label": 0
                },
                {
                    "sent": "Now get out there.",
                    "label": 0
                },
                {
                    "sent": "So first we check with this machine learning.",
                    "label": 0
                },
                {
                    "sent": "Then they check the standard machine learning problems so but the different classes controller problems surprised to supervise and so on.",
                    "label": 0
                },
                {
                    "sent": "Then we will get more into detail.",
                    "label": 0
                },
                {
                    "sent": "So how do we represent data?",
                    "label": 0
                },
                {
                    "sent": "What actually is a model?",
                    "label": 0
                },
                {
                    "sent": "How to represent a model, how to fit a model?",
                    "label": 1
                },
                {
                    "sent": "It's a good model and then how to evaluate?",
                    "label": 0
                },
                {
                    "sent": "So how good are we doing?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is a learning?",
                    "label": 0
                },
                {
                    "sent": "First of all, it says subfield of computer science.",
                    "label": 1
                },
                {
                    "sent": "Nicole from.",
                    "label": 0
                },
                {
                    "sent": "When will the machine became machines become more powerful?",
                    "label": 0
                },
                {
                    "sent": "So it's kind of evolved from this pattern pattern recognition, imitation, learning theory, artificial intelligence, but nowadays it would be largely considered kind of a subfield of AI artificial intelligence.",
                    "label": 1
                },
                {
                    "sent": "And this is an old boat from 59, so there are some summers at the field of study that gives computers the ability to learn without being explicitly programmed so.",
                    "label": 1
                },
                {
                    "sent": "We give means of computer code, so we give it to material material to learn from.",
                    "label": 0
                },
                {
                    "sent": "They give it kind of approaches for learning from this material and then we let it go and hopefully the out we get a model.",
                    "label": 0
                },
                {
                    "sent": "We get out the program that is better if you'd try to program incrementally.",
                    "label": 0
                },
                {
                    "sent": "And machine learning with most people working on machine learning, but they do, they mostly remain.",
                    "label": 0
                },
                {
                    "sent": "The core task would be developing algorithms efficient algorithm can learn models from.",
                    "label": 0
                },
                {
                    "sent": "In addition, please.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is 1 slide from this year skinny.",
                    "label": 0
                },
                {
                    "sent": "So lots of things are kind of on the borderline between statistics and other science.",
                    "label": 0
                },
                {
                    "sent": "And then what was the machine learning considered a separate field?",
                    "label": 0
                },
                {
                    "sent": "Or, heads?",
                    "label": 0
                },
                {
                    "sent": "Or this data?",
                    "label": 0
                },
                {
                    "sent": "Science is actually with computer scientists are better than statisticians at marketing.",
                    "label": 0
                },
                {
                    "sent": "And it's not so.",
                    "label": 0
                },
                {
                    "sent": "This also the cloudless code.",
                    "label": 0
                },
                {
                    "sent": "But as data scientist do, so it's kind of in between computer science and statistics.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get out terminology so we'll be using couple of words throughout this talk.",
                    "label": 0
                },
                {
                    "sent": "Maybe just to send them down.",
                    "label": 0
                },
                {
                    "sent": "So first this training data.",
                    "label": 1
                },
                {
                    "sent": "So what we consider building data so it's the input data be fit to the machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Another it can be labeled.",
                    "label": 0
                },
                {
                    "sent": "It can be unlabeled.",
                    "label": 0
                },
                {
                    "sent": "We see differences.",
                    "label": 0
                },
                {
                    "sent": "And one example of me, if you're doing sentiment classification, so we have a collection of tweets and preached, we say is it positive?",
                    "label": 0
                },
                {
                    "sent": "Is it negative?",
                    "label": 0
                },
                {
                    "sent": "Is it neutral sentiment?",
                    "label": 0
                },
                {
                    "sent": "And this this is kind of the training data.",
                    "label": 1
                },
                {
                    "sent": "So we want we want the machine to replicate.",
                    "label": 0
                },
                {
                    "sent": "So getting from a tree to sentiment label.",
                    "label": 0
                },
                {
                    "sent": "Then another Victor Miss model.",
                    "label": 0
                },
                {
                    "sent": "So that is a model basically can look at it as a function that is kind of derived using some machine learning algorithm and it takes the input data and produces the desired output.",
                    "label": 1
                },
                {
                    "sent": "So in that example the beginning input would be award out would be saying easy to a person or is not a person.",
                    "label": 0
                },
                {
                    "sent": "And what is it then?",
                    "label": 1
                },
                {
                    "sent": "The last word is prediction, so that is a prediction.",
                    "label": 0
                },
                {
                    "sent": "So if you take a data point, applying the model to get a prediction.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quick demo.",
                    "label": 0
                },
                {
                    "sent": "So we had to so he had been what we'll be doing is binary classification, which we did.",
                    "label": 0
                },
                {
                    "sent": "More details about it later.",
                    "label": 0
                },
                {
                    "sent": "But what is let's suppose be?",
                    "label": 0
                },
                {
                    "sent": "Are given a data set.",
                    "label": 0
                },
                {
                    "sent": "We have a.",
                    "label": 0
                },
                {
                    "sent": "Our space is a 2 dimensional thing.",
                    "label": 0
                },
                {
                    "sent": "We have some points that we would like to classify as positive.",
                    "label": 0
                },
                {
                    "sent": "We have some points.",
                    "label": 0
                },
                {
                    "sent": "We would like to classify as negative.",
                    "label": 0
                },
                {
                    "sent": "Basically we just want to.",
                    "label": 0
                },
                {
                    "sent": "Discriminate between them so.",
                    "label": 0
                },
                {
                    "sent": "Are being given a collection of points.",
                    "label": 0
                },
                {
                    "sent": "Would somebody say they are ready for some sailor blue?",
                    "label": 0
                },
                {
                    "sent": "Another question is.",
                    "label": 0
                },
                {
                    "sent": "Can you learn a model?",
                    "label": 0
                },
                {
                    "sent": "It will that that will be able to predict or the new point that will appoint it appears here.",
                    "label": 0
                },
                {
                    "sent": "Is it blue or red?",
                    "label": 0
                },
                {
                    "sent": "So looking at this picture here, it would probably say should be blue here it should be read here, not sure so.",
                    "label": 0
                },
                {
                    "sent": "And then one by one easy way to do this.",
                    "label": 0
                },
                {
                    "sent": "Is by.",
                    "label": 0
                },
                {
                    "sent": "Throwing up like between the two clouds, this is called the linear model and here and everything that's in this side of the line is blue.",
                    "label": 0
                },
                {
                    "sent": "Everything that's on this side of the line is correct, so.",
                    "label": 0
                },
                {
                    "sent": "In that sense, so this line was picked by Central theorem to be the optimal line for this collection of data points.",
                    "label": 0
                },
                {
                    "sent": "But you can see that if we say here, we can based on this model, you can say it said that we don't really know.",
                    "label": 0
                },
                {
                    "sent": "We don't have any evidence.",
                    "label": 0
                },
                {
                    "sent": "Now the models can get arbitrarily more complex, so let's say we have some more red points down here.",
                    "label": 0
                },
                {
                    "sent": "No, we can try seem to draw a line that you see, so maybe for some blue ones we make a mistake.",
                    "label": 0
                },
                {
                    "sent": "For some relevance, make a mistake if you try to put the line on.",
                    "label": 0
                },
                {
                    "sent": "And here's what we can do is increase the complexity of the model so we can set up a line where it can be.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Compared to put the appointment of 2nd degrees or Parabola Tweet and we see that in this one it's doing better already.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can increase the complexity of it more as well.",
                    "label": 0
                },
                {
                    "sent": "And then you see OK. Now if you do this kind of semicircle around this, point it within our translating.",
                    "label": 0
                },
                {
                    "sent": "In particular whether this model in general as well, it's hard to tell this case 'cause it's a.",
                    "label": 0
                },
                {
                    "sent": "We made it quite complex already.",
                    "label": 0
                },
                {
                    "sent": "And what would be predictions here?",
                    "label": 0
                },
                {
                    "sent": "So everything we discovered, what kind of white should be read?",
                    "label": 0
                },
                {
                    "sent": "Everything that is dark grey should be blue.",
                    "label": 0
                },
                {
                    "sent": "So disappointed, eyes here we would predict it blue and here on the edge is kind of on the edge and then you can either tell maybe here.",
                    "label": 0
                },
                {
                    "sent": "It's still in blue but less confident blue here and still have not been responsive.",
                    "label": 0
                },
                {
                    "sent": "Interest just kind of so this would be kind of very anecdotal view of.",
                    "label": 0
                },
                {
                    "sent": "With machine learning algorithms do.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know what are the standard problems that we typically solve in machine learning approaches, so there are few classes will mostly focus on the first one first 2 classes, so one class is called supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is we're given inputs.",
                    "label": 0
                },
                {
                    "sent": "Plus we are also given the outputs the desired output.",
                    "label": 0
                },
                {
                    "sent": "So example would be.",
                    "label": 0
                },
                {
                    "sent": "I work in a labeled easy to person or not person, which would be example would be a tweet and a sentiment of that week.",
                    "label": 0
                },
                {
                    "sent": "So we already tell the machine.",
                    "label": 0
                },
                {
                    "sent": "But do we want to the output and now the task is just to figure out the best possible function to get this output.",
                    "label": 0
                },
                {
                    "sent": "The second class is called on supervised and unsupervised means that we don't really have any output labels, so it's up to.",
                    "label": 1
                },
                {
                    "sent": "Are there whoever is applying machine learning to know what he's doing and see what can he get out?",
                    "label": 0
                },
                {
                    "sent": "The typical goal would be here too.",
                    "label": 1
                },
                {
                    "sent": "We want to extract, detect some patterns in every cluster input.",
                    "label": 1
                },
                {
                    "sent": "Follow this and we'll see some concrete examples of this that another class would be reinforcement learning so they won't be touching this.",
                    "label": 0
                },
                {
                    "sent": "The idea here is that we have a program that is not given up from the input data and output data, but its position in some more dynamical environment.",
                    "label": 0
                },
                {
                    "sent": "And it's adjusting the model that it's interacting with environment and this alcohol was so this.",
                    "label": 0
                },
                {
                    "sent": "Using an example of reinforcement learning using neural networks for example, and then there are some kind of grey areas or not that the semi supervised where we are working with the both labeled and unlabeled data and typically the idea is we're giving a bit of level data, lots of unlabeled data can be better than just working with the label.",
                    "label": 0
                },
                {
                    "sent": "Data directly induces an examples for that as well.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first supervised learning.",
                    "label": 0
                },
                {
                    "sent": "So what's the kind of prototypical example we have training data we have inputs for this will be their access and the expected outputs.",
                    "label": 1
                },
                {
                    "sent": "That would be wise.",
                    "label": 0
                },
                {
                    "sent": "Again, pairs of a set of this kind of pairs and the goal is given these pairs, find a function that can match given input to the desired output.",
                    "label": 0
                },
                {
                    "sent": "And then we have a couple of tasks, so this couldn't.",
                    "label": 0
                },
                {
                    "sent": "Breakdown into different types of functions.",
                    "label": 0
                },
                {
                    "sent": "For example, in classification, the output space would be a set of small set of descriptor values.",
                    "label": 0
                },
                {
                    "sent": "In regression we are projecting into continuous space in ranking.",
                    "label": 0
                },
                {
                    "sent": "The goal is to identify best possible order of the input data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's fication here, uh, why is appearance at any special case where we have only two like you saw before red and blue people give quality positive or negative.",
                    "label": 0
                },
                {
                    "sent": "It's called binary classification.",
                    "label": 0
                },
                {
                    "sent": "So then we just have pairs, but it is the input so that week and out is the sum is either plus or minus other positive sentiment, for example, or negative sentiment.",
                    "label": 0
                },
                {
                    "sent": "Functions of the map.",
                    "label": 0
                },
                {
                    "sent": "You could still plus or minus and we call this function of binary classifier.",
                    "label": 0
                },
                {
                    "sent": "Computer for example.",
                    "label": 0
                },
                {
                    "sent": "4 So we have a red points.",
                    "label": 0
                },
                {
                    "sent": "We have blue points.",
                    "label": 0
                },
                {
                    "sent": "And the binary classifier basically some boundary splitting our input space into into half into tool to grasp.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you have more than two labels.",
                    "label": 0
                },
                {
                    "sent": "So then it's for Utah.",
                    "label": 0
                },
                {
                    "sent": "Typically would be multiclass problem, so this means that output weaken the output is one of K, brings only one and this can be either.",
                    "label": 0
                },
                {
                    "sent": "We can convert it to several binary problems so we can have a separate classifier for each of the K states, separate binary classifier and then pick the value of the most confident one we can have one versus one, so we could have for each pair of output value, train a binary classifier and then the label that has the most votes.",
                    "label": 1
                },
                {
                    "sent": "Means in some problems at blue stick regression, Moody, normal logistic regression, collecting parts, or multiclass problems.",
                    "label": 1
                },
                {
                    "sent": "But it's a decent good to keep this distinction between binary classification and multi class classification, because binary is really a special special case that can be just that.",
                    "label": 0
                },
                {
                    "sent": "Many problems can be translated.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, so send them any problems can be translated to binary classification.",
                    "label": 1
                },
                {
                    "sent": "Another case would be multi labeled, so here we are assigning multiple labels to one instance.",
                    "label": 0
                },
                {
                    "sent": "Example of this would be for example topic classification.",
                    "label": 0
                },
                {
                    "sent": "We have a document in the document, could talk about sports tennis will be games, so we have multiple levels and how to do this with binary classification.",
                    "label": 1
                },
                {
                    "sent": "So we'll just have to train a classifier for each of the labels.",
                    "label": 0
                },
                {
                    "sent": "And then given a new document called, Run.",
                    "label": 0
                },
                {
                    "sent": "For the binary classifiers and assign it all the labels which are binary classifiers.",
                    "label": 0
                },
                {
                    "sent": "And we can also music store.",
                    "label": 0
                },
                {
                    "sent": "Lewis called the Structured output prediction, so then the output is not.",
                    "label": 0
                },
                {
                    "sent": "Simple structure like value from a set.",
                    "label": 0
                },
                {
                    "sent": "Here are subset, but maybe the output is 3 or something more complex.",
                    "label": 0
                },
                {
                    "sent": "We can again translate it to a binary classification problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some examples document.",
                    "label": 0
                },
                {
                    "sent": "So we have a optical, so it's in our case will be documents and why so the output space would be topics and technology, sports, entertainment and strong and what we want is a function that can map out.",
                    "label": 0
                },
                {
                    "sent": "Documentaries after we do.",
                    "label": 0
                },
                {
                    "sent": "What about topics?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example is sentiment analysis, so here we have two tweets.",
                    "label": 1
                },
                {
                    "sent": "So the input, so the expense would be other University fees, and the output would be.",
                    "label": 0
                },
                {
                    "sent": "Space three classes, positive, negative or neutral.",
                    "label": 0
                },
                {
                    "sent": "There are two examples, so first 20 angry about care segment like this.",
                    "label": 0
                },
                {
                    "sent": "Classifier.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example would be object detection or images.",
                    "label": 1
                },
                {
                    "sent": "Computers are image and the goal is to identify all the areas in the image and give them that have a bit correspond to some object in our database that they would have a bike.",
                    "label": 0
                },
                {
                    "sent": "Here we have a person and all together you would kind of person on the bike.",
                    "label": 0
                },
                {
                    "sent": "Classification problem.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another factor later, but different problem would be regression.",
                    "label": 0
                },
                {
                    "sent": "So here we are mapping her from our.",
                    "label": 0
                },
                {
                    "sent": "Your output space would be real numbers.",
                    "label": 0
                },
                {
                    "sent": "Exam.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would input data is the how well a student is doing the high school output data is covered.",
                    "label": 0
                },
                {
                    "sent": "The student is doing the University and then can we predict from his high school grades can predict how it will be doing at University.",
                    "label": 0
                },
                {
                    "sent": "Again, regression problem.",
                    "label": 0
                },
                {
                    "sent": "So we're predicting the number.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another example would be.",
                    "label": 0
                },
                {
                    "sent": "Probability of default.",
                    "label": 0
                },
                {
                    "sent": "So this is a lot.",
                    "label": 0
                },
                {
                    "sent": "You risk management.",
                    "label": 0
                },
                {
                    "sent": "You want to switch your.",
                    "label": 0
                },
                {
                    "sent": "Working because different companies you might want to maybe compute the risk of individual company spelling.",
                    "label": 0
                },
                {
                    "sent": "This is called probability of defaulting and again here input is the company or company described by some parameters and the output is hearing some country actually and the output would be the likelihood that the country will not be able to repay some of its levels in real time.",
                    "label": 1
                },
                {
                    "sent": "And again the output is a number.",
                    "label": 0
                },
                {
                    "sent": "So we can correct itself.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another problem would be that a supervised problem is ranking, so here the idea is we are given a set of objects.",
                    "label": 1
                },
                {
                    "sent": "X1 to XN, maybe a very as well, and what we want to do is find give back unordered set of items and the training data can be provided either pointwise so that we can have a set of items and preach item in which position should it be?",
                    "label": 0
                },
                {
                    "sent": "But it can be, which is typically easier.",
                    "label": 0
                },
                {
                    "sent": "It can be paralyzed saying that this article should be ranked higher than this.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you go to Google search for new product.",
                    "label": 0
                },
                {
                    "sent": "There are 28 million pages at the back.",
                    "label": 0
                },
                {
                    "sent": "We have to decide which ones to put to the top, and it does that by ranking function and just means that this Wikipedia page for two public was scored the highest by this ranking function.",
                    "label": 0
                },
                {
                    "sent": "No help with the one train this so we have to get the.",
                    "label": 0
                },
                {
                    "sent": "Did you get the police?",
                    "label": 0
                },
                {
                    "sent": "So if you just observing but people are clicking so after somebody's back super quick and then clicks on a Lonely Planet, that's some signal.",
                    "label": 0
                },
                {
                    "sent": "So it does that Lonely Planet page should be ranked maybe at least for this user should be rent about the Wikipedia page, maybe you can tell us something about this one that's lonely.",
                    "label": 0
                },
                {
                    "sent": "Bandit page should be named above.",
                    "label": 0
                },
                {
                    "sent": "Maybe we don't know.",
                    "label": 0
                },
                {
                    "sent": "Plus maybe the user stopped reading here so the signal protected will lower and then by assembling many of these kinds of training person you can train a ranking function.",
                    "label": 0
                },
                {
                    "sent": "Under example Dolphins.",
                    "label": 0
                },
                {
                    "sent": "So that's a dolphin.",
                    "label": 0
                },
                {
                    "sent": "The top ranking Pizza GameCube emulator.",
                    "label": 0
                },
                {
                    "sent": "Followed by the animal again.",
                    "label": 0
                },
                {
                    "sent": "How to decide which which one first, which is the ranking function?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another ranking problem for probability can take into ranking would be recommendation, or in this case is a user accommodation, so you're using is leading this article.",
                    "label": 0
                },
                {
                    "sent": "Can you recommend?",
                    "label": 0
                },
                {
                    "sent": "Looking for articles.",
                    "label": 0
                },
                {
                    "sent": "And this.",
                    "label": 0
                },
                {
                    "sent": "The four articles will typically be so we have a pool of particles appearing commending articles from the last day last week.",
                    "label": 0
                },
                {
                    "sent": "Last year what are the top four rank particles?",
                    "label": 0
                },
                {
                    "sent": "Whether input Harry is the user context, so he's reading this article here, at least in the session here, at least in his history.",
                    "label": 0
                },
                {
                    "sent": "Again, this is kind of and then if somebody if you will go and click this we can say OK, so this this article should be ranked higher than these three when you're training and we handle through usage, generate more training data.",
                    "label": 0
                },
                {
                    "sent": "So this would be examples of.",
                    "label": 0
                },
                {
                    "sent": "Supervise.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Supervised so here we just get the examples input data, but we don't really have any.",
                    "label": 0
                },
                {
                    "sent": "Any guidance on the output?",
                    "label": 0
                },
                {
                    "sent": "And what can we do in this case?",
                    "label": 0
                },
                {
                    "sent": "Is an issue because of tasks will be like clustering, anomaly detection, emotionality reductions.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only one so class clustering, so clustering is.",
                    "label": 0
                },
                {
                    "sent": "One of our standard Pacific nation clustering.",
                    "label": 0
                },
                {
                    "sent": "We wanna be standard or tools in the machine learning toolbox.",
                    "label": 0
                },
                {
                    "sent": "Full of clustering, so we're given a virtual object.",
                    "label": 0
                },
                {
                    "sent": "We want to identify some groups of objects that are still share some characteristics that is different given by some similarity function.",
                    "label": 0
                },
                {
                    "sent": "So that means if you have a you see some objects would be these points.",
                    "label": 0
                },
                {
                    "sent": "Here we would like to say that the ones that are closer to each other maybe share should belong to the same group, where there is another not so close to each other should not belong in the same group.",
                    "label": 1
                },
                {
                    "sent": "You can see that here.",
                    "label": 0
                },
                {
                    "sent": "Big blobs and you would want our clustering algorithm figure after this tool box.",
                    "label": 0
                },
                {
                    "sent": "Now one thing that is very important it is that this pretty much depends on the similarity measure that you give it.",
                    "label": 0
                },
                {
                    "sent": "So the similarity measure is the distance.",
                    "label": 0
                },
                {
                    "sent": "Then we could say OK if you would be able to capture this.",
                    "label": 0
                },
                {
                    "sent": "If you imagine that we project all these data to the white exist, then the distance on the Y axis doesn't really tell us anything about these two clusters.",
                    "label": 0
                },
                {
                    "sent": "Needed senses.",
                    "label": 0
                },
                {
                    "sent": "Outlook.",
                    "label": 0
                },
                {
                    "sent": "I'm working because of this.",
                    "label": 0
                },
                {
                    "sent": "Also, it's like nontrivial to do a proper operation of two different clustering approaches, and it's very much.",
                    "label": 0
                },
                {
                    "sent": "So any?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use optical, so let's say we have a stream of.",
                    "label": 0
                },
                {
                    "sent": "All or most of the news articles published in some period of time.",
                    "label": 1
                },
                {
                    "sent": "Well, if you would cluster similar articles together, what we get is hammock events so.",
                    "label": 0
                },
                {
                    "sent": "So clustering one day of news is would be kind of top events and you considered so Trump says something has 2000 capitals Galaxy Note 7, exploding his thousand particles and so on.",
                    "label": 0
                },
                {
                    "sent": "So these are all the articles that were talking about Samsung Galaxy Note 7 for some aspect of it that study or together and they were not see that enough to something else.",
                    "label": 0
                },
                {
                    "sent": "Some other classes.",
                    "label": 0
                },
                {
                    "sent": "And if you look inside, we see the connected lots of kind of similar articles talking about the same topic, and this is the similarity.",
                    "label": 0
                },
                {
                    "sent": "For example, this clustering algorithm was using.",
                    "label": 0
                },
                {
                    "sent": "So putting articles about same entities and topics together.",
                    "label": 0
                },
                {
                    "sent": "Another one.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Supervised another area for unsupervised methods would be anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "So here they used to identify events or if there is a stream of events of observations and we want to identify when observational in events is not.",
                    "label": 0
                },
                {
                    "sent": "Does not conform to something that is expected.",
                    "label": 1
                },
                {
                    "sent": "It's good to know that anomaly is a very domain specific term.",
                    "label": 1
                },
                {
                    "sent": "Presently, if you hear this again so.",
                    "label": 0
                },
                {
                    "sent": "Who is missing here?",
                    "label": 0
                },
                {
                    "sent": "Kind of a bad thing.",
                    "label": 0
                },
                {
                    "sent": "Earthquake.",
                    "label": 0
                },
                {
                    "sent": "Is not missing here would be a good thing.",
                    "label": 0
                },
                {
                    "sent": "So very we have to visit.",
                    "label": 0
                },
                {
                    "sent": "You have to make taking this domain into account.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How we usually deal with the density.",
                    "label": 0
                },
                {
                    "sent": "That'll be the anomaly detection, so one standard base dividend too.",
                    "label": 0
                },
                {
                    "sent": "Been kind of density so that the estimated distribution in degree and then of the space of all the observations sending a new observational demand falls into low likelihood space.",
                    "label": 0
                },
                {
                    "sent": "Then we say, OK, let's anomaly, and these are some examples of teenagers.",
                    "label": 0
                },
                {
                    "sent": "Neighbors would be nice for one class SVM, so before we're looking at this, we were trying to speed this space in half.",
                    "label": 0
                },
                {
                    "sent": "Now here we have a bunch of points we're not trying to see the space in half, but.",
                    "label": 0
                },
                {
                    "sent": "We have three branches, be the spacing help, but we're splitting it in a way so we have all the points in one side and our space should be as small as possible, so that's kind of different things in everything that should be outside another point that belongs clearly says Anomaly.",
                    "label": 0
                },
                {
                    "sent": "It belongs here.",
                    "label": 0
                },
                {
                    "sent": "They say that's expected.",
                    "label": 0
                },
                {
                    "sent": "Clustering could be used for that as well so.",
                    "label": 0
                },
                {
                    "sent": "Another",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Radio 4 infection.",
                    "label": 0
                },
                {
                    "sent": "There is two different given some car dimensional data and we would like to identify a couple of Rd dimensional couple of dimensions.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "That's still capture the most information is data, but as most information mean, every principle component analysis is 1 standard approach to this.",
                    "label": 1
                },
                {
                    "sent": "They're most information.",
                    "label": 0
                },
                {
                    "sent": "It mean capturing the most varieties of a full power data would be in a crowd like this.",
                    "label": 0
                },
                {
                    "sent": "They would say, OK, this is the most important dimension 'cause it has the most variety along.",
                    "label": 0
                },
                {
                    "sent": "Another approach to this would be similar in composition.",
                    "label": 0
                },
                {
                    "sent": "There we are trying to find the low rank matrix.",
                    "label": 1
                },
                {
                    "sent": "It approximates the data.",
                    "label": 0
                },
                {
                    "sent": "Population analysis for multiple data.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another another this is the latest or anomaly detection in some way, but there are supervised area between density estimation.",
                    "label": 1
                },
                {
                    "sent": "So here again we're doing a bunch of formulation and ideas can be estimated.",
                    "label": 0
                },
                {
                    "sent": "The density function of this.",
                    "label": 0
                },
                {
                    "sent": "And the last one with.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are out in quarters.",
                    "label": 0
                },
                {
                    "sent": "How are you?",
                    "label": 0
                },
                {
                    "sent": "This is using a neural network, artificial neural network and the idea here is that we have our input.",
                    "label": 1
                },
                {
                    "sent": "This is what we're given and we say our inputs should approximately correspond to what the input.",
                    "label": 0
                },
                {
                    "sent": "But we try to squeeze it through some kind of low dimensional representation.",
                    "label": 0
                },
                {
                    "sent": "And this is useful in either dimension.",
                    "label": 0
                },
                {
                    "sent": "Look summation, so visualizations if you want high dimensional data and you want to put it on the monitor and then we have to put it in somehow into D and then getting here for points to do it means that we have now haptics and why and you can say OK, Now we can run the script.",
                    "label": 0
                },
                {
                    "sent": "The later on the screen.",
                    "label": 0
                },
                {
                    "sent": "Other thing is unsupervised feature learning and this is now especially for the image.",
                    "label": 1
                },
                {
                    "sent": "Image sure computer vision, so sending lots of images or little parts of images through this and see what they're kind of.",
                    "label": 0
                },
                {
                    "sent": "The prototypical things that.",
                    "label": 0
                },
                {
                    "sent": "Gets built in settings or other features.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now one class of.",
                    "label": 0
                },
                {
                    "sent": "Yet another class of problems that lies in the boundary would be.",
                    "label": 0
                },
                {
                    "sent": "The idea here is we are we have some label data, but we also have access to lots of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "So sometimes this is something this is the case sometimes not.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have lots of documents but it's very expensive to label the documents and we would get 100 documents table and have a million documents in the site so we can use this to use this unlabeled documents to better get the feel of the space.",
                    "label": 0
                },
                {
                    "sent": "The ones with Adventure Market would be the ones that they are not able to.",
                    "label": 0
                },
                {
                    "sent": "Once with this one is would be marked as related.",
                    "label": 0
                },
                {
                    "sent": "We could see this kind of distribution that is underlying the data from this unlabeled documents and it's easy to say maybe for this one.",
                    "label": 0
                },
                {
                    "sent": "Let's say this green picture.",
                    "label": 0
                },
                {
                    "sent": "It say it's green.",
                    "label": 0
                },
                {
                    "sent": "This one is red, whereas if you wouldn't care if you wouldn't have this label twice, the model would probably be quite different.",
                    "label": 0
                },
                {
                    "sent": "This approach is usually called transduction.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another nice one is active learning.",
                    "label": 0
                },
                {
                    "sent": "Useful technique, so the idea here is we are given with a.",
                    "label": 0
                },
                {
                    "sent": "And we have access to our expert that can label a document.",
                    "label": 0
                },
                {
                    "sent": "Now the question is so we don't have enough money for the expert to label all the data set.",
                    "label": 0
                },
                {
                    "sent": "Can we select some small subset that would be optimal for the task we are trying to accomplish an example classification?",
                    "label": 0
                },
                {
                    "sent": "She's a short animation.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see there.",
                    "label": 0
                },
                {
                    "sent": "We have a data set of companies which company is described by something some features.",
                    "label": 0
                },
                {
                    "sent": "And we want to train a classifier between detect financial companies.",
                    "label": 0
                },
                {
                    "sent": "So this would be the ones here and we had somebody went down, provided some examples and Barclays.",
                    "label": 0
                },
                {
                    "sent": "This is Goldman Sachs or financial companies.",
                    "label": 0
                },
                {
                    "sent": "Apple is not a financial company, General Motor Sport or not.",
                    "label": 0
                },
                {
                    "sent": "And then these other ones.",
                    "label": 0
                },
                {
                    "sent": "We don't really know and now we would run the model like we did before by clicking by.",
                    "label": 0
                },
                {
                    "sent": "Did you run this demo before and you get this kind of line?",
                    "label": 0
                },
                {
                    "sent": "So OK?",
                    "label": 0
                },
                {
                    "sent": "These are these are.",
                    "label": 0
                },
                {
                    "sent": "Company.",
                    "label": 0
                },
                {
                    "sent": "Actually this is.",
                    "label": 0
                },
                {
                    "sent": "And then we select and then we algorithms goes and says OK, Apple is efinancial company or not and the user says no.",
                    "label": 0
                },
                {
                    "sent": "Labeling group anything around the\nOut the line is a bit higher then the algorithm says.",
                    "label": 0
                },
                {
                    "sent": "What about Microsoft Microsoft Financial Company?",
                    "label": 0
                },
                {
                    "sent": "And the expert says no.",
                    "label": 0
                },
                {
                    "sent": "And we saw that stopping from these two investor companies and asking fewer there.",
                    "label": 0
                },
                {
                    "sent": "Now we slowly converge to open Mark Citigroup.",
                    "label": 0
                },
                {
                    "sent": "This one you're slowly converging to the good place and the way we were selecting this user algorithms away for selecting which company to label.",
                    "label": 0
                },
                {
                    "sent": "It was mostly on how close it is to the decision boundary, meaning how uncertain the model is about where to put it.",
                    "label": 0
                },
                {
                    "sent": "And the intuition goes, if we can label this uncertain elements, and so we are introducing certainty in the system.",
                    "label": 0
                },
                {
                    "sent": "In helping the model.",
                    "label": 0
                },
                {
                    "sent": "So this would be kind of the.",
                    "label": 0
                },
                {
                    "sent": "How would you do that if you know?",
                    "label": 0
                },
                {
                    "sent": "I mean, you could have whatever polynomial distribution or something.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah strange.",
                    "label": 0
                },
                {
                    "sent": "I'm just wondering how you combine that with model selection for each model that candidates can do active learning.",
                    "label": 0
                },
                {
                    "sent": "So depending you could run it with different model parameters in parallel.",
                    "label": 0
                },
                {
                    "sent": "Can you different model parameters to select the?",
                    "label": 0
                },
                {
                    "sent": "Think not think maybe for now, not on the level of.",
                    "label": 0
                },
                {
                    "sent": "You can people do it sometimes for optimizing kind of learnings for this regularization parameters model selection I think is already kind of.",
                    "label": 0
                },
                {
                    "sent": "Lots of approaches depend on the explicit model being used, so need to hear if we're relying a model big align to some degree curve.",
                    "label": 0
                },
                {
                    "sent": "Decision tree would be not really have the same effect.",
                    "label": 0
                },
                {
                    "sent": "In this case we have optimism.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we went to different.",
                    "label": 0
                },
                {
                    "sent": "Examples of different problems that we can that people are selling machine learning.",
                    "label": 0
                },
                {
                    "sent": "There are many more so, but this is just a scratch the surface and now we'll go kind of through the pipeline how to how starting to feel a pinch of data, how to get to a working model.",
                    "label": 0
                },
                {
                    "sent": "So the first thing is data representation.",
                    "label": 1
                },
                {
                    "sent": "So if you are giving the text and the algorithm expects a vector on input, how do we go from one to the other one example?",
                    "label": 0
                },
                {
                    "sent": "So what we should data points are typically represented by features or attributes, so it's just called.",
                    "label": 1
                },
                {
                    "sent": "Whenever I say pictures, I mean some.",
                    "label": 0
                },
                {
                    "sent": "Parameters and one you related to the example.",
                    "label": 0
                },
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "Is it exact representation?",
                    "label": 0
                },
                {
                    "sent": "Depends on the algorithm.",
                    "label": 1
                },
                {
                    "sent": "So if you're working with decision trees then they work with the individual attributes and distinguish between continuous and discrete attributes.",
                    "label": 1
                },
                {
                    "sent": "For example, if you work with a linear models like logistic regression, SVM.",
                    "label": 0
                },
                {
                    "sent": "They work with vectors for most directive we are, so we have to get our data to something that we can encode into as a point in a vector space.",
                    "label": 1
                },
                {
                    "sent": "Then there are approaches that only require similarity measure.",
                    "label": 0
                },
                {
                    "sent": "So given to data points we don't need it's representation.",
                    "label": 0
                },
                {
                    "sent": "You just need to tell how similar they are some degree.",
                    "label": 0
                },
                {
                    "sent": "Methods for example.",
                    "label": 0
                },
                {
                    "sent": "And then also.",
                    "label": 0
                },
                {
                    "sent": "Actually learning representation.",
                    "label": 0
                },
                {
                    "sent": "So if you start with words in the figure out their vector representation can be learned from the data itself.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when the standard example that will be using like the House in the account of camera end zone section is text presentation and vector space model would be one of the standard representations on the idea of vector space model.",
                    "label": 0
                },
                {
                    "sent": "So we take document and we first identify all the unique words that occur in this document.",
                    "label": 1
                },
                {
                    "sent": "According to Partition the documents and then each word becomes one dimension.",
                    "label": 1
                },
                {
                    "sent": "Example later and then for the individual document.",
                    "label": 0
                },
                {
                    "sent": "So it's a vector in this space which which each word corresponding to.",
                    "label": 0
                },
                {
                    "sent": "And then you say the value in that dimension is 1, but the network occurs if the document is there otherwise.",
                    "label": 0
                },
                {
                    "sent": "So this can be more complicated, so we can use different weights, but this is a basic level.",
                    "label": 0
                },
                {
                    "sent": "We're just for a document saying that some of the current feature or not.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we have 3.",
                    "label": 0
                },
                {
                    "sent": "We have three documents.",
                    "label": 0
                },
                {
                    "sent": "Bachman Turner, two documentaries without my phone, 2, three, and here are a couple of thoughts that I slept from these documents for.",
                    "label": 0
                },
                {
                    "sent": "There are many more, so this typically working with vector space model.",
                    "label": 0
                },
                {
                    "sent": "You're quite early.",
                    "label": 0
                },
                {
                    "sent": "Get to hundreds of thousands of dimensions, so whatever algorithm using they have to be able to copy that.",
                    "label": 0
                },
                {
                    "sent": "So then we have.",
                    "label": 0
                },
                {
                    "sent": "We take OK the first words we say Angela and you see it appears in all the documents.",
                    "label": 0
                },
                {
                    "sent": "Now we can do also called engrams, for this case, bigram, so frequently Co occurring words Whitaker together, and this kind of allows us to extract decreases as well.",
                    "label": 0
                },
                {
                    "sent": "Brexit occurs in the first one.",
                    "label": 0
                },
                {
                    "sent": "You don't need a second and the problem is you want and now at the end if you need.",
                    "label": 0
                },
                {
                    "sent": "If you have three vectors and now if you compare the distance between these factors we can see how all this on some level, usually more topical level.",
                    "label": 0
                },
                {
                    "sent": "How similar we are.",
                    "label": 0
                },
                {
                    "sent": "So the distance between these large dimensional data points which we don't measure video previous distance, but you measured it causing distance, which is kind of.",
                    "label": 0
                },
                {
                    "sent": "Normalize vectors and then check the angle between them is this.",
                    "label": 0
                },
                {
                    "sent": "Kind of compensates for the length of the document, so it's easier also to compare short and long documents.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there are a couple of.",
                    "label": 0
                },
                {
                    "sent": "Or a couple of things that's good to know, so this this is different.",
                    "label": 0
                },
                {
                    "sent": "The representation is also called bag of words back in a sense that we take all the words of the document and we threw them in.",
                    "label": 0
                },
                {
                    "sent": "We disregard the order, but most often we would also count how many times individual work occurs, so it's not always 10 or something else like.",
                    "label": 0
                },
                {
                    "sent": "There are different ways how to actually compute the weights in the world, so it's not obvious that one is the best or surely surely it's not the best way.",
                    "label": 0
                },
                {
                    "sent": "So how for a different word, for example?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He's great, he's comparing Brexit position.",
                    "label": 0
                },
                {
                    "sent": "Which one is more important in our representation?",
                    "label": 0
                },
                {
                    "sent": "This would often depend on the data set.",
                    "label": 0
                },
                {
                    "sent": "So if and what are the topics?",
                    "label": 0
                },
                {
                    "sent": "Is it asking for your week?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem can be stopped once you can have both good or other filler words that are hard to that could occur often include make.",
                    "label": 0
                },
                {
                    "sent": "Documents look seem that even though they don't really share any kind of more important words.",
                    "label": 0
                },
                {
                    "sent": "So one simple way is just to ignore this promising and fixed set of common words.",
                    "label": 0
                },
                {
                    "sent": "And The thing is, if you have words of different forms of Magnus banking stuff like that, we would all want to normalize it tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Can use understanding organization for this kind of cutting the ending.",
                    "label": 0
                },
                {
                    "sent": "Bend high dimensionality.",
                    "label": 0
                },
                {
                    "sent": "So for a large corpus you can easily end up with millions of words and easy way of dealing with this is using hash country where we don't actually remember.",
                    "label": 0
                },
                {
                    "sent": "We don't say we don't assign.",
                    "label": 0
                },
                {
                    "sent": "We from each quarter computer cash.",
                    "label": 0
                },
                {
                    "sent": "And then we divide this cash Modelo some, let's say 100,000.",
                    "label": 0
                },
                {
                    "sent": "And what we get out is actually our dimension.",
                    "label": 0
                },
                {
                    "sent": "So this kind of gives us limits as to 100,000 dimension.",
                    "label": 0
                },
                {
                    "sent": "For example, there's a number of pick and also the likelihood of distorting the similarity measure is very low.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach that we can do is actually learn representation.",
                    "label": 0
                },
                {
                    "sent": "Another so just to be here is, so this is this vote to make.",
                    "label": 0
                },
                {
                    "sent": "And the idea here is can be in given words and how they Co occur, how they recording documents with.",
                    "label": 0
                },
                {
                    "sent": "But what is a Co occur with can be ended by end dimensional vectors so that words that occur in similar context.",
                    "label": 0
                },
                {
                    "sent": "So words that have investment and stuff around it would be.",
                    "label": 0
                },
                {
                    "sent": "Close in space.",
                    "label": 0
                },
                {
                    "sent": "And we can see if you do that for this.",
                    "label": 0
                },
                {
                    "sent": "Once examples we have animals and then some ports and would be closer to each other than others.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another modality of data type of data would be time serious.",
                    "label": 0
                },
                {
                    "sent": "OK, very given measurements.",
                    "label": 0
                },
                {
                    "sent": "Series of data points in time order.",
                    "label": 1
                },
                {
                    "sent": "So for example temperature readings once per day or once per hour that I think readings here.",
                    "label": 0
                },
                {
                    "sent": "We have number of airline passengers per year or different stuff.",
                    "label": 0
                },
                {
                    "sent": "And if you want to do some example regression on this or some classification on this, we would also want to represent.",
                    "label": 0
                },
                {
                    "sent": "So let's say we're here.",
                    "label": 0
                },
                {
                    "sent": "We want to make some decision of how the things we go, but are the features that we should use and then we have some.",
                    "label": 0
                },
                {
                    "sent": "We can compute standard statistics, mean deviation.",
                    "label": 0
                },
                {
                    "sent": "So on we can use standalone bedding.",
                    "label": 0
                },
                {
                    "sent": "So just use last N values.",
                    "label": 0
                },
                {
                    "sent": "I will have the time series or any of these features or we can also.",
                    "label": 0
                },
                {
                    "sent": "Transport the time series into some frequency domain, for example, extracted features from there.",
                    "label": 0
                },
                {
                    "sent": "But the important thing here is that depending on the data that we get to each data packet have some specifics that it's good to know before he started crying or doing any learning on top of it.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so much particular presentation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Model is working, machine is kind of the output of the training program.",
                    "label": 1
                },
                {
                    "sent": "So we can put it specification for example, so it's a function function function, right?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "We have different types of models, so some others can be just discriminative.",
                    "label": 1
                },
                {
                    "sent": "So there we saw before the number example this line and that model hotel is something on one side or the other, but it didn't really tell us much more about the data.",
                    "label": 0
                },
                {
                    "sent": "You can have generative models, but from the model we can go out and actually generate examples that look very much like our data set.",
                    "label": 0
                },
                {
                    "sent": "Alien.",
                    "label": 1
                },
                {
                    "sent": "So each model we want also depends on the task.",
                    "label": 0
                },
                {
                    "sent": "But it's more.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have we got a couple of super models and how they look like for the most one of the most common models is a linear model, so it's very simple, so we have a linear function.",
                    "label": 1
                },
                {
                    "sent": "Features.",
                    "label": 0
                },
                {
                    "sent": "We multiply the feature vector with some.",
                    "label": 0
                },
                {
                    "sent": "And we get a prediction.",
                    "label": 0
                },
                {
                    "sent": "Then if you specification we can change that may be the sign of the prediction to say it's a positive or negative, but that's it.",
                    "label": 0
                },
                {
                    "sent": "In the end, we are searching for the linear model, but we are searching for is basically the parameter vector W. When they can be off, they are kind of nice and easy behaved.",
                    "label": 0
                },
                {
                    "sent": "Yeah, typically on expanding not so expensive to train.",
                    "label": 1
                },
                {
                    "sent": "Most prediction is quite fast, so just the number will never compile in the number of features that we have nausea features.",
                    "label": 0
                },
                {
                    "sent": "Probably not.",
                    "label": 0
                },
                {
                    "sent": "You know, so we don't really.",
                    "label": 1
                },
                {
                    "sent": "They can't capture nonlinear patterns, and here is the examples.",
                    "label": 0
                },
                {
                    "sent": "We have house size and price later, and it's not really noticeable relationship.",
                    "label": 0
                },
                {
                    "sent": "So it goes kind of like this and if you want to, if you go try to fit it with the line, it kind of fits but not really.",
                    "label": 0
                },
                {
                    "sent": "She tried to put a rubber tree just kind of looks better already if you picked up or polynomial of degree 6 St we can hit each point exactly but I think looking at this time everybody would agree that it's probably.",
                    "label": 0
                },
                {
                    "sent": "It doesn't generalize helping other data, and this is what we call overthinking, and we do that.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Geometric interpretation of classifier.",
                    "label": 0
                },
                {
                    "sent": "It's basically the W vector would be a normal of these hyperplanes.",
                    "label": 0
                },
                {
                    "sent": "That is dividing the positive and negative side.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Their position is that we have a support each feature to get away.",
                    "label": 0
                },
                {
                    "sent": "Positive features vote for a positive plus negative features.",
                    "label": 1
                },
                {
                    "sent": "Features for negative class.",
                    "label": 0
                },
                {
                    "sent": "We sent them all together.",
                    "label": 0
                },
                {
                    "sent": "We move to present with features from them up together and we see the final both conclusion.",
                    "label": 0
                },
                {
                    "sent": "Larger debates, typically stronger divorce, also depending on the picture size, but that's kind of the interpretation and we'll see later in the hands of 1 computers entities.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can we increase the?",
                    "label": 0
                },
                {
                    "sent": "How can we get more fixed?",
                    "label": 0
                },
                {
                    "sent": "With a bit more complex data, so we can't really do believe that model for efficient approaches, one would be kernel methods, so there is a bunch of algorithms there that can be written in a way that you only interact with the data points throughout the DOT product.",
                    "label": 0
                },
                {
                    "sent": "And these dogs properties, typically called our kernel and the story behind it goes the following.",
                    "label": 0
                },
                {
                    "sent": "So have a some mapping.",
                    "label": 0
                },
                {
                    "sent": "It takes data from other input space in Maps into some high dimensional space, can be high in a sense of loss of dimension, number of dimension.",
                    "label": 0
                },
                {
                    "sent": "And if you can, you can compute dot product in there.",
                    "label": 1
                },
                {
                    "sent": "Without explicitly mapping the data for this other space and then this will be called.",
                    "label": 0
                },
                {
                    "sent": "And the intuition behind is that in one way we are doing our learning problem in a much higher dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So what's linear Del sooner up there is not linear.",
                    "label": 0
                },
                {
                    "sent": "Once we projected the decision now.",
                    "label": 0
                },
                {
                    "sent": "Thank you some examples.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have a.",
                    "label": 0
                },
                {
                    "sent": "Well this would be negative positive class.",
                    "label": 0
                },
                {
                    "sent": "I believe that model would go like this.",
                    "label": 0
                },
                {
                    "sent": "Now if you use a polynomial kernel.",
                    "label": 0
                },
                {
                    "sent": "So this is what we were drinking the example before over the second degree we got this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "Use degree treat regarding a more complex so the higher the degree, the more complicated the water can be.",
                    "label": 0
                },
                {
                    "sent": "And basically this line here is a.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "It's a state line, but in some higher dimensional space, so not into dimensionally, but in some foreign Nationals.",
                    "label": 0
                },
                {
                    "sent": "If you look if you try to write it down.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this would be there.",
                    "label": 0
                },
                {
                    "sent": "So what we do, we take the.",
                    "label": 0
                },
                {
                    "sent": "We have two elements X&Y and we want to complete this indefinite dot product between them so we still do the dot product between them, but we.",
                    "label": 0
                },
                {
                    "sent": "Would that be greedy?",
                    "label": 0
                },
                {
                    "sent": "And if you go down and help, right, right, right it out.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have a our feature space because it's just so we have two dimensions.",
                    "label": 0
                },
                {
                    "sent": "Our degree of the polynomial kernel is 2 and C would be once this constant factor.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                },
                {
                    "sent": "So we have these two vectors.",
                    "label": 0
                },
                {
                    "sent": "We write them down so we have a basically.",
                    "label": 0
                },
                {
                    "sent": "So the dot product plus one.",
                    "label": 0
                },
                {
                    "sent": "Target for that equation there and then we go down we modified began this something here and we could try to break it apart and write it again as a two individual vectors, but one has only elements from XML.",
                    "label": 0
                },
                {
                    "sent": "He's only elements provide.",
                    "label": 0
                },
                {
                    "sent": "We can see that.",
                    "label": 0
                },
                {
                    "sent": "Actually this corresponds to.",
                    "label": 0
                },
                {
                    "sent": "Don't product enough 123456 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "This not straight line before.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this curve is actually projection of straight line from 6 dimensional space down here and that is nice.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That so that we have two pictures.",
                    "label": 0
                },
                {
                    "sent": "So leader mother can't capture interaction, so it can only feature one is active or not.",
                    "label": 0
                },
                {
                    "sent": "Feature two is one or zero for example as well.",
                    "label": 0
                },
                {
                    "sent": "But linear model can say is feature one or two 10?",
                    "label": 0
                },
                {
                    "sent": "Or is they're both positive?",
                    "label": 0
                },
                {
                    "sent": "For example there is.",
                    "label": 0
                },
                {
                    "sent": "Here you see we have a product X one times X 200.",
                    "label": 0
                },
                {
                    "sent": "So through just by going through this kernel, methods of this polynomial kernel we are able to capture the signal.",
                    "label": 0
                },
                {
                    "sent": "So this interaction this file.",
                    "label": 0
                },
                {
                    "sent": "Paralyzing connections between features.",
                    "label": 0
                },
                {
                    "sent": "Now if we increase the degree then we get the interaction between 3 features variance one.",
                    "label": 0
                },
                {
                    "sent": "In the extreme.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can go to the cabin Ocean kernel very basically mapped infinite dimensional space in the capture or possible interactions.",
                    "label": 1
                },
                {
                    "sent": "Described by public speakers.",
                    "label": 0
                },
                {
                    "sent": "Again here.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to overfit now.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of dealing with this for how to increase the capacity would be going through supplying the artificial neural effort.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                },
                {
                    "sent": "Or this is an example of neural network, but we're basically trying to do is an approximate the function, so like.",
                    "label": 0
                },
                {
                    "sent": "Other approaches, but we use network coding, so here we have a note.",
                    "label": 0
                },
                {
                    "sent": "This would be input nodes output nodes with our end of the notes, so everything in between and.",
                    "label": 0
                },
                {
                    "sent": "These are called neurons.",
                    "label": 0
                },
                {
                    "sent": "So one note can depend on more.",
                    "label": 1
                },
                {
                    "sent": "One of the more inputs and they can send the signal outdoor one more properties and each each architecture of the network will be how are basically this topology of the graph.",
                    "label": 0
                },
                {
                    "sent": "And then also there, but we've kept it specifies that activation, so lot of the functions.",
                    "label": 0
                },
                {
                    "sent": "And how does this note here?",
                    "label": 0
                },
                {
                    "sent": "How does it take that list to the inputs?",
                    "label": 0
                },
                {
                    "sent": "And how does it integrate them together?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This would be moving their projector, so here we have a supervised approach, so the output will be presented, glasses or aggression.",
                    "label": 0
                },
                {
                    "sent": "Must have at least three layers.",
                    "label": 0
                },
                {
                    "sent": "You could layer output layer at least one hidden layer.",
                    "label": 0
                },
                {
                    "sent": "Activation functions can be either linear, so after we take the outputs and you multiply them with a linear function, you get the value or it can be nonlinear African.",
                    "label": 0
                },
                {
                    "sent": "Take that input and send it for some nonlinear function sigmoid or something like that.",
                    "label": 0
                },
                {
                    "sent": "And we can do because if you get the global outlook you can use something for the softmax, skip now.",
                    "label": 0
                },
                {
                    "sent": "Skip this, go to the demo.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one is a playground.",
                    "label": 0
                },
                {
                    "sent": "Tensorflow don't work.",
                    "label": 0
                },
                {
                    "sent": "Want to play so once we do here we select the training data.",
                    "label": 0
                },
                {
                    "sent": "So let's start with something simple.",
                    "label": 0
                },
                {
                    "sent": "Then you select whether our features so features will be weeks one and X2.",
                    "label": 0
                },
                {
                    "sent": "So basically coordinates.",
                    "label": 0
                },
                {
                    "sent": "And we don't give any hidden layers for start and that means that output is just a linear combination of these two guys if we start.",
                    "label": 0
                },
                {
                    "sent": "We'll end up with that.",
                    "label": 0
                },
                {
                    "sent": "Now we go for something more complex.",
                    "label": 0
                },
                {
                    "sent": "Also this is.",
                    "label": 0
                },
                {
                    "sent": "Maybe it would be better.",
                    "label": 0
                },
                {
                    "sent": "Yes, you do not seem right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, just.",
                    "label": 0
                },
                {
                    "sent": "It's more right.",
                    "label": 0
                },
                {
                    "sent": "So we see there are blue points.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a check transport.",
                    "label": 0
                },
                {
                    "sent": "And if you try to pick the line for secondry separated string.",
                    "label": 0
                },
                {
                    "sent": "I mean the the model doesn't have the capacity to capture this now.",
                    "label": 0
                },
                {
                    "sent": "One simple thing would be we can increase their features.",
                    "label": 0
                },
                {
                    "sent": "So if you add a product feature so they're not really so before that, this polynomial of 2nd degree with already included.",
                    "label": 0
                },
                {
                    "sent": "So if we add one more feature so the product of fixed right.",
                    "label": 0
                },
                {
                    "sent": "Here we get up.",
                    "label": 0
                },
                {
                    "sent": "Get perfect terms classification.",
                    "label": 0
                },
                {
                    "sent": "But this is a this was a.",
                    "label": 0
                },
                {
                    "sent": "Basically we're messing up the inputs so we're kind of in the future engineer.",
                    "label": 0
                },
                {
                    "sent": "And you know how to compensate this with a more structured ways.",
                    "label": 0
                },
                {
                    "sent": "Using for this kernel methods that we saw before, but another option since we have a neural network here.",
                    "label": 0
                },
                {
                    "sent": "Another way of dealing with the nonlinearities introduced this linear layers.",
                    "label": 0
                },
                {
                    "sent": "So now we have this goalkeeper features that will get mapped into intermediary values that then get mapped into the classification.",
                    "label": 0
                },
                {
                    "sent": "Now we feel like this.",
                    "label": 0
                },
                {
                    "sent": "We have only two neurons, limited trying.",
                    "label": 0
                },
                {
                    "sent": "It's doing something so I can see it before I get more complex, so most of the blue aren't look most of the orange or orange, so I'm in the middle of a sacrifice, but.",
                    "label": 0
                },
                {
                    "sent": "Increase the capacity.",
                    "label": 0
                },
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "Is not.",
                    "label": 0
                },
                {
                    "sent": "At 4:00 component scandal stock ticker.",
                    "label": 0
                },
                {
                    "sent": "Starting to bend.",
                    "label": 0
                },
                {
                    "sent": "It's struggling, but it's kind of something is happening at another layer.",
                    "label": 0
                },
                {
                    "sent": "Explain the learning curve so this is a. Alto parameter so distortion training loss so we can you know that.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is the.",
                    "label": 0
                },
                {
                    "sent": "Applying the model of these points and training last week, how well are we doing from the training data?",
                    "label": 0
                },
                {
                    "sent": "So if you're not doing that in the training data, then propose we want to as well on the other data.",
                    "label": 0
                },
                {
                    "sent": "If you're doing well on the training data doesn't mean that we will do well on the other data 'cause we might be overheating.",
                    "label": 0
                },
                {
                    "sent": "Baby please.",
                    "label": 0
                },
                {
                    "sent": "Select all.",
                    "label": 0
                },
                {
                    "sent": "Good point if it starts to repeat.",
                    "label": 0
                },
                {
                    "sent": "Do you have an accent?",
                    "label": 0
                },
                {
                    "sent": "Do you have any information or what is happening happening in the Community players?",
                    "label": 0
                },
                {
                    "sent": "So this is the the if you just use this feature of the classifier, you will kind of.",
                    "label": 0
                },
                {
                    "sent": "It captures this kind of signal.",
                    "label": 0
                },
                {
                    "sent": "Then as you're learning you can see that this one basically now also added his serious kind of does.",
                    "label": 0
                },
                {
                    "sent": "He's doing this prediction.",
                    "label": 0
                },
                {
                    "sent": "This one is doing kind of complementary and then things get refined here and then kind of summed up together, but it's.",
                    "label": 0
                },
                {
                    "sent": "There's lots of.",
                    "label": 0
                },
                {
                    "sent": "So this is these are simple examples here, so it's you know it's easy to experiment.",
                    "label": 0
                },
                {
                    "sent": "So when you get a bigger system, you really need to spend some time to get also the learning parameter, right and everything.",
                    "label": 0
                },
                {
                    "sent": "And is adding features, so adding the number of layers.",
                    "label": 0
                },
                {
                    "sent": "So now it looks like.",
                    "label": 0
                },
                {
                    "sent": "So the number of hidden layers, the number of nodes in the hidden layers and the teachers is just trying to find out if I know.",
                    "label": 0
                },
                {
                    "sent": "I mean you have a some.",
                    "label": 0
                },
                {
                    "sent": "For some problems you have a bad, understood architectures that you could even use.",
                    "label": 0
                },
                {
                    "sent": "So, but it's like you're selling something that is not that wasn't done with these digits.",
                    "label": 0
                },
                {
                    "sent": "You're with lots of experimentation in your future, so it's not like this that you are doing it and then you are getting inside what is happening in this hidden layers.",
                    "label": 0
                },
                {
                    "sent": "So you get we will ever get an intuition of what we learn.",
                    "label": 0
                },
                {
                    "sent": "For example, if you are.",
                    "label": 0
                },
                {
                    "sent": "Bismarck",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a neural network for solving the problem we were doing in the motivation.",
                    "label": 1
                },
                {
                    "sent": "So this name entity recognition, for example users exactly so it has a.",
                    "label": 0
                },
                {
                    "sent": "It starts with the word on.",
                    "label": 0
                },
                {
                    "sent": "It takes its context and it first Maps them into.",
                    "label": 0
                },
                {
                    "sent": "Each word is mapped into 50 dimensional vector for example.",
                    "label": 0
                },
                {
                    "sent": "Then it is good transformation and then again the softmax to figure out the class.",
                    "label": 0
                },
                {
                    "sent": "Now for this, if you look at this letter sent after you run documents for awhile, look at this vector, then it turns out that words that are similar by some connected similar class would have vectors that are closer together than words that are not in the same class.",
                    "label": 0
                },
                {
                    "sent": "But this is something that is very specific to this kind of architecture.",
                    "label": 0
                },
                {
                    "sent": "If you have some different things, there are some different wiring.",
                    "label": 0
                },
                {
                    "sent": "Then again, you would have to go down and check what exactly it means, whereas for this lower layers it's hard to.",
                    "label": 0
                },
                {
                    "sent": "Maybe we do lots of handwaving where lots of air particles figure out, maybe some meetings, but it's very hard to understand what's happening there.",
                    "label": 0
                },
                {
                    "sent": "Network Speed dancer players and it gets more or less impossible.",
                    "label": 0
                },
                {
                    "sent": "You can do visualizations for example later, so before an outing whether if you have an image problem then you can see how this image is broken into simple features and then each layer kind of capture capture with more complex features.",
                    "label": 0
                },
                {
                    "sent": "But again, we see images.",
                    "label": 0
                },
                {
                    "sent": "You can visualize this and agree Christopher reversing back to the image or text is a bit harder already 'cause.",
                    "label": 0
                },
                {
                    "sent": "For this reason.",
                    "label": 0
                },
                {
                    "sent": "Sweets.",
                    "label": 0
                },
                {
                    "sent": "It's a large degree to black folks.",
                    "label": 0
                },
                {
                    "sent": "And also it can be so can be also quite the month.",
                    "label": 0
                },
                {
                    "sent": "Side effects are very good performance other side and can help out everybody which classification we have.",
                    "label": 0
                },
                {
                    "sent": "Some examples when you take the image you just slightly distorted so you wouldn't even notice the difference and it will be classified in a completely different class.",
                    "label": 0
                },
                {
                    "sent": "And vice versa, I can give you some which looks more like like random noise to you and you would classify it in it.",
                    "label": 0
                },
                {
                    "sent": "Look like a classified into some quick class.",
                    "label": 0
                },
                {
                    "sent": "Just because this intermediate layers are hard to prove.",
                    "label": 0
                },
                {
                    "sent": "Is something going this is understanding during that time?",
                    "label": 0
                },
                {
                    "sent": "Is 1 big coffee garden just came from this CBD conference and whose topic which is not really addressed or unlocking here public versus?",
                    "label": 0
                },
                {
                    "sent": "Pretend.",
                    "label": 0
                },
                {
                    "sent": "Black box.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Intermediate neurons right?",
                    "label": 0
                },
                {
                    "sent": "There are some kind of Lego pieces building blocks twitch.",
                    "label": 0
                },
                {
                    "sent": "Allow people to do this or to give up the solution in a better way for the question is.",
                    "label": 0
                },
                {
                    "sent": "Alchemist and is building blocks.",
                    "label": 0
                },
                {
                    "sent": "This label pieces so this is on here.",
                    "label": 0
                },
                {
                    "sent": "And I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Oh 15 in the case of images, somehow we can see this some elements with text, some kind of compare things may be less clear, but.",
                    "label": 0
                },
                {
                    "sent": "General instructions, and really there's no solution will.",
                    "label": 0
                },
                {
                    "sent": "Community doesn't have any proprietary yet.",
                    "label": 0
                },
                {
                    "sent": "Canada.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "You can include the regulations or pursuing your career.",
                    "label": 0
                },
                {
                    "sent": "So before in the examples.",
                    "label": 0
                },
                {
                    "sent": "Here we had a good support at one or after regularization and the model or help this early stopping or something that fits their things.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's not not definition.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to check, for example using features exponent extremely revealing some variable values.",
                    "label": 0
                },
                {
                    "sent": "Can you just show in one year what is the equation that represents one of the like probably the first human legs.",
                    "label": 0
                },
                {
                    "sent": "So just want to visualize it like Mathematica.",
                    "label": 0
                },
                {
                    "sent": "Like instead of having so many features, if I just have two features, for example, it's an experience.",
                    "label": 0
                },
                {
                    "sent": "Values of just make up relatively each feature or something, so can you just represent once mathematical?",
                    "label": 0
                },
                {
                    "sent": "He wasn't one of them like running for student, there isn't it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so here.",
                    "label": 0
                },
                {
                    "sent": "It would be physically just.",
                    "label": 0
                },
                {
                    "sent": "So linear function with some weights times X1 plus wait times X2 that extends to downloads capabilities.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of activations functions, so that would be.",
                    "label": 0
                },
                {
                    "sent": "Lyrics.",
                    "label": 0
                },
                {
                    "sent": "Each year we learn something and then we go to the next layer, right definition.",
                    "label": 0
                },
                {
                    "sent": "So what is the I mean, just one simple decoration?",
                    "label": 0
                },
                {
                    "sent": "Probably that takes from the features in the sense that to the to the next leader.",
                    "label": 0
                },
                {
                    "sent": "So just want to make this.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have a one possible step from input to the hidden person.",
                    "label": 0
                },
                {
                    "sent": "There would be have a metrics that takes this three element and outputs would happen.",
                    "label": 0
                },
                {
                    "sent": "So 3 by 4 matrix.",
                    "label": 0
                },
                {
                    "sent": "While computing is really the weights of each of the training will give you is the metrics a in this case, for example.",
                    "label": 0
                },
                {
                    "sent": "So this is what you're optimizing over.",
                    "label": 0
                },
                {
                    "sent": "Well, this is fixed.",
                    "label": 0
                },
                {
                    "sent": "The output is fixed.",
                    "label": 0
                },
                {
                    "sent": "But you're optimizing is.",
                    "label": 0
                },
                {
                    "sent": "Figure out out either the this metrics a.",
                    "label": 0
                },
                {
                    "sent": "Either that's it, yeah.",
                    "label": 0
                },
                {
                    "sent": "They are random and then they are changed.",
                    "label": 0
                },
                {
                    "sent": "Reminder.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "You can understand by random or you can have some.",
                    "label": 0
                },
                {
                    "sent": "We have different different.",
                    "label": 0
                },
                {
                    "sent": "You can disguise.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You cannot.",
                    "label": 0
                },
                {
                    "sent": "So it can hear we are solving limited recognition.",
                    "label": 0
                },
                {
                    "sent": "We can solve a similar problem or similar problem problem for example this.",
                    "label": 0
                },
                {
                    "sent": "What to make very does this and then the task is to predict which work will be in the middle and you can use the display are both correct and plug it in here and use that as the starting point and then you're already forward to like it's much easier to generate lots of training data then from entities.",
                    "label": 0
                },
                {
                    "sent": "And this is one way of how we can boost the performance so not starting program down from something.",
                    "label": 0
                },
                {
                    "sent": "Maybe could you explain the principle of black backdrop?",
                    "label": 0
                },
                {
                    "sent": "This might be sort of.",
                    "label": 0
                },
                {
                    "sent": "The loss.",
                    "label": 0
                },
                {
                    "sent": "Maybe just one, maybe since you're short.",
                    "label": 0
                },
                {
                    "sent": "Spencer for radio, can you show the evil example spiral?",
                    "label": 0
                },
                {
                    "sent": "So here we want to separate threads thoughts from blocks, right?",
                    "label": 0
                },
                {
                    "sent": "So you see, it's pretty unpleasant.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "This setting you won't be able to do much better.",
                    "label": 0
                },
                {
                    "sent": "Could be stronger integration.",
                    "label": 0
                },
                {
                    "sent": "Still longer.",
                    "label": 0
                },
                {
                    "sent": "Add other features.",
                    "label": 0
                },
                {
                    "sent": "The nondeterministic definition.",
                    "label": 0
                },
                {
                    "sent": "And a few more layers.",
                    "label": 0
                },
                {
                    "sent": "Actually it's very.",
                    "label": 0
                },
                {
                    "sent": "Very generous.",
                    "label": 0
                },
                {
                    "sent": "So does it mean that when you do something on this, you really do like this?",
                    "label": 0
                },
                {
                    "sent": "You have feature your layers and then yeah, this is black magic with these people.",
                    "label": 0
                },
                {
                    "sent": "Then you're popular.",
                    "label": 0
                },
                {
                    "sent": "Then which?",
                    "label": 0
                },
                {
                    "sent": "Pretty much what you say, so thank here.",
                    "label": 0
                },
                {
                    "sent": "It could be.",
                    "label": 0
                },
                {
                    "sent": "I mean there is some you there or something.",
                    "label": 0
                },
                {
                    "sent": "Busy.",
                    "label": 0
                },
                {
                    "sent": "Freedom, you get some feeling, but there's lots of craft in training.",
                    "label": 0
                },
                {
                    "sent": "Switch back now.",
                    "label": 0
                },
                {
                    "sent": "So I think I think he had the problem is the debt is how you how you nonlinear, so you need hundreds of layers to order two previous necessarily at your stuff enough there.",
                    "label": 0
                },
                {
                    "sent": "So the question was how many monkey are you try and so we can.",
                    "label": 0
                },
                {
                    "sent": "We can you can you can approximate any function with the neural network.",
                    "label": 1
                },
                {
                    "sent": "Just question is how many letters from any?",
                    "label": 0
                },
                {
                    "sent": "But also definitely trading deficit in order to function in this area.",
                    "label": 0
                },
                {
                    "sent": "Let's see I mean, we need to look at this.",
                    "label": 0
                },
                {
                    "sent": "Neural networks are not not something outside whatever blush was saying before, so you never is just another function approximator.",
                    "label": 0
                },
                {
                    "sent": "So fancy, however, everything saying, well, let's forget what we used to do and now this will solve at least once.",
                    "label": 0
                },
                {
                    "sent": "I mean all the participants around your metrics are exactly the same.",
                    "label": 0
                },
                {
                    "sent": "I mean, who had training testing an error?",
                    "label": 0
                },
                {
                    "sent": "Learning great, I mean all these terms are still there, right?",
                    "label": 0
                },
                {
                    "sent": "We just we have different functional groups.",
                    "label": 0
                },
                {
                    "sent": "Just go to the last part, so this may be goes in line with your question.",
                    "label": 0
                },
                {
                    "sent": "So how do we actually?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now that we decided our model is this.",
                    "label": 0
                },
                {
                    "sent": "Metrics are this vector or something.",
                    "label": 0
                },
                {
                    "sent": "How do you find the best one?",
                    "label": 1
                },
                {
                    "sent": "Another question first is what they mean by fast, so we have kind of two parts.",
                    "label": 0
                },
                {
                    "sent": "One, we would want the model to work put value on the training set so even some loss function measuring the error or something on the training set.",
                    "label": 0
                },
                {
                    "sent": "We want to be as better good as possible and the other expense case we also find another way side both on the model to generalize well to unseen data.",
                    "label": 1
                },
                {
                    "sent": "So if you have something that was not in the training set.",
                    "label": 0
                },
                {
                    "sent": "The whole point was that we would also work well on that, and this is kind of two competing parts.",
                    "label": 0
                },
                {
                    "sent": "Now we go through each of them.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first question is how to measure loss and with the general principle is we compare the model.",
                    "label": 1
                },
                {
                    "sent": "With the expected outputs.",
                    "label": 0
                },
                {
                    "sent": "So in our in the cancer flow before here this also, this points are our expected outputs.",
                    "label": 0
                },
                {
                    "sent": "The colored effect is our output, and now we want to describe this relationship.",
                    "label": 0
                },
                {
                    "sent": "You want to describe this relationship.",
                    "label": 0
                },
                {
                    "sent": "With some function that we can optimize over though.",
                    "label": 0
                },
                {
                    "sent": "Preferably easily optimized and what your networks are doing is already back propagation, so you can write all the equation down and do the stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "And this is one of the purchasing check from work here.",
                    "label": 0
                },
                {
                    "sent": "So if you're doing.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And how do we measure loss?",
                    "label": 0
                },
                {
                    "sent": "So one straightforward, straightforward will say that.",
                    "label": 0
                },
                {
                    "sent": "If our prediction is the same as the training data prediction, then we say it's good, so there's no.",
                    "label": 0
                },
                {
                    "sent": "It's zero if the prediction is.",
                    "label": 0
                },
                {
                    "sent": "If the if the difference of declassification says.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If our predictions is different than the training data says, then you count 1.",
                    "label": 0
                },
                {
                    "sent": "Now if we do that on the whole training data, we can write on it as application.",
                    "label": 0
                },
                {
                    "sent": "And then this is something that we can go down and putting some optimization software in the figure and it would spit out the best F for this loss.",
                    "label": 0
                },
                {
                    "sent": "Another way of looking at this sheet so this hinge loss.",
                    "label": 1
                },
                {
                    "sent": "So here we say either our.",
                    "label": 0
                },
                {
                    "sent": "Our classifier is good and if it says if we take the output, it must be quite confident in the prediction as well as soon as it's not confident saying that it's don't look at design of the function, but it has to be actually bigger than money for the confidence.",
                    "label": 0
                },
                {
                    "sent": "As soon as it's outside lower than this, restart applying penalty and the penalty linearly increase.",
                    "label": 0
                },
                {
                    "sent": "The bigger the misclassification is.",
                    "label": 0
                },
                {
                    "sent": "So this is called conditionals.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of looking at it is maximum likelihood, so we are given a training data.",
                    "label": 1
                },
                {
                    "sent": "We have our model and then we can compare because ask ourselves what's the likelihood of this data given this model?",
                    "label": 0
                },
                {
                    "sent": "OK, so for our output for our training data, but is there a likelihood of disease classification of electrical data outputs?",
                    "label": 0
                },
                {
                    "sent": "And the closer it is to the this is the training output, training input and the higher the likelihood of this is the happier we are.",
                    "label": 0
                },
                {
                    "sent": "Again, we can write it down as a function.",
                    "label": 0
                },
                {
                    "sent": "We can derive optimizing and so on so.",
                    "label": 0
                },
                {
                    "sent": "But still.",
                    "label": 0
                },
                {
                    "sent": "That's the general idea we want to capture the loss we want to capture the.",
                    "label": 1
                },
                {
                    "sent": "Property of the model to work well on the training data as some more optimizable function.",
                    "label": 0
                },
                {
                    "sent": "Then we optimize it by finding the most.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the other problem is how do we ensure that we generalize well?",
                    "label": 1
                },
                {
                    "sent": "So let's say we are.",
                    "label": 0
                },
                {
                    "sent": "So before, so we likely to course.",
                    "label": 0
                },
                {
                    "sent": "Might be good.",
                    "label": 0
                },
                {
                    "sent": "Movie 6 is already obviously overheating, and now with the stand.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This would be kind of welcome razors, so we would like to find the simplest model possible that still produces good result.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how to?",
                    "label": 0
                },
                {
                    "sent": "How do we define a simple?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is usually by regularization and regularization can be either.",
                    "label": 0
                },
                {
                    "sent": "Not directly included in the optimization function.",
                    "label": 0
                },
                {
                    "sent": "In our case linear model, the norm of the vector, typically of the normal vector typically corresponds to the margin.",
                    "label": 0
                },
                {
                    "sent": "So how it's positioned over with respect to the training data and the smaller the smaller the the normal, the larger the matching.",
                    "label": 0
                },
                {
                    "sent": "So that's one way of shooting it.",
                    "label": 0
                },
                {
                    "sent": "Your networks you also do.",
                    "label": 0
                },
                {
                    "sent": "You will take your training data, take out a bit of a small set that you call validation, set and value optimizing on the training data and error will go down as we're getting more than one, we're approximately better and better.",
                    "label": 0
                },
                {
                    "sent": "At some point the validation set, so the one that is.",
                    "label": 0
                },
                {
                    "sent": "Part of the training set that is not used in the optimization.",
                    "label": 0
                },
                {
                    "sent": "The error there will start to increase this.",
                    "label": 0
                },
                {
                    "sent": "OK if you got it here then maybe we have a very generalizable model.",
                    "label": 0
                },
                {
                    "sent": "Decision tree and then boom.",
                    "label": 0
                },
                {
                    "sent": "Super money.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Enough.",
                    "label": 0
                },
                {
                    "sent": "Support vector machines, so because it's nicely German metric interpretation, so let's say we have a. Positives and negatives.",
                    "label": 1
                },
                {
                    "sent": "There are many possible models we can lines that we can drop them between them now, which one will be preferred and one approach is to say we want the one that produces maximum margin.",
                    "label": 0
                },
                {
                    "sent": "Now if you would put this link here then the margin so between the line and the nearest negative index positive example is quite small versus if you put the line like this it's quite the decryption.",
                    "label": 0
                },
                {
                    "sent": "Now the task comes down to we want to find the plane that.",
                    "label": 0
                },
                {
                    "sent": "Of course it separates plus in using the maximum margin.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write this down.",
                    "label": 0
                },
                {
                    "sent": "We get down to want to minimize the North of the model.",
                    "label": 0
                },
                {
                    "sent": "Given that we are classifying correctly, but this is not typically not possible because we have noise.",
                    "label": 0
                },
                {
                    "sent": "Assumes perfect supportability.",
                    "label": 0
                },
                {
                    "sent": "And then you can say OK, relax.",
                    "label": 0
                },
                {
                    "sent": "So we still want small normal, but you also small ones.",
                    "label": 0
                },
                {
                    "sent": "One small loss.",
                    "label": 0
                },
                {
                    "sent": "So this is this hinge loss before.",
                    "label": 0
                },
                {
                    "sent": "If you put these two together you basically get.",
                    "label": 0
                },
                {
                    "sent": "So much from the mothers.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the last part is how do we know we say?",
                    "label": 0
                },
                {
                    "sent": "Be.",
                    "label": 0
                },
                {
                    "sent": "But the data we representatives and how we train the model on it?",
                    "label": 0
                },
                {
                    "sent": "How good are we doing so?",
                    "label": 0
                },
                {
                    "sent": "There are three questions, kind of major questions we want to ask yourself.",
                    "label": 0
                },
                {
                    "sent": "So what is called even tell?",
                    "label": 0
                },
                {
                    "sent": "How would we drink?",
                    "label": 0
                },
                {
                    "sent": "How can you be?",
                    "label": 0
                },
                {
                    "sent": "But we will measure.",
                    "label": 0
                },
                {
                    "sent": "Second question, how well do we have the model generalize?",
                    "label": 1
                },
                {
                    "sent": "The last one is is better than other models.",
                    "label": 0
                },
                {
                    "sent": "So the last time goes in line with Canvas presented today.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or how to quantify model performance.",
                    "label": 1
                },
                {
                    "sent": "So typically we would.",
                    "label": 1
                },
                {
                    "sent": "If you kept up bunch of evaluation metrics for different types of problems.",
                    "label": 0
                },
                {
                    "sent": "Depends on the problem.",
                    "label": 0
                },
                {
                    "sent": "Also transportation will be measured differently than regression.",
                    "label": 1
                },
                {
                    "sent": "And also depends a lot on the domain and what is actually cause.",
                    "label": 1
                },
                {
                    "sent": "There have been some domains.",
                    "label": 0
                },
                {
                    "sent": "We don't care if if we find more like positive examples, but really don't want to miss anybody some other domain.",
                    "label": 0
                },
                {
                    "sent": "So different types of wrong answers for different amount of cost plus cost, different amount of money and maybe we would factory light according to this or how much money we are using that we are making even the mother.",
                    "label": 0
                },
                {
                    "sent": "So this is really specific and it's easy for a supervised, it's easier.",
                    "label": 0
                },
                {
                    "sent": "Account created, nothing else where we are given explicit outputs that we want.",
                    "label": 0
                },
                {
                    "sent": "Which might be noisy as well, but soon there kind of high quality and it gets quite hard for unsupervised problems 'cause it's given to different clusterings.",
                    "label": 0
                },
                {
                    "sent": "Traffic collisions better without some good.",
                    "label": 0
                },
                {
                    "sent": "They coming of age to qualify better.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An example for a binary classification, but we typically measure, so we have a prediction.",
                    "label": 1
                },
                {
                    "sent": "We have the true label and then we can each instance.",
                    "label": 0
                },
                {
                    "sent": "Can be positioned into rolling.",
                    "label": 1
                },
                {
                    "sent": "Start with the test set which reportedly separate country mix up appears to be simple.",
                    "label": 0
                },
                {
                    "sent": "We check for each element from the test set, which are the prediction.",
                    "label": 1
                },
                {
                    "sent": "We check the actual label and we see 2 positive means that they are.",
                    "label": 0
                },
                {
                    "sent": "They both agree to negative means they go for grip on the negative class.",
                    "label": 1
                },
                {
                    "sent": "Then you have false negative false positive which is kind of.",
                    "label": 0
                },
                {
                    "sent": "Different types of mistake, and from this we can get to the kind of basic classification measure.",
                    "label": 0
                },
                {
                    "sent": "So one is precision.",
                    "label": 1
                },
                {
                    "sent": "Precision tells you from all the positive ones how T. Or are they.",
                    "label": 0
                },
                {
                    "sent": "So how many of the massive positives are actually positives?",
                    "label": 0
                },
                {
                    "sent": "Another one is very cold, so from all the positives, how many degree dentify?",
                    "label": 0
                },
                {
                    "sent": "So these are kind of usually you get high precision but just classifying everything was negative was that it didn't make any any.",
                    "label": 0
                },
                {
                    "sent": "Mistake, we just be very Conservative and Liberal.",
                    "label": 0
                },
                {
                    "sent": "Few positive, but then it gets very low record and vice versa.",
                    "label": 0
                },
                {
                    "sent": "You can always stable everything positive having terrible precision and a very good report.",
                    "label": 0
                },
                {
                    "sent": "And then one way of combining this is called F1 measure which is geometric mean.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of looking at the model.",
                    "label": 0
                },
                {
                    "sent": "Model Caesar through this RC cars so the idea here is that we computed two characteristics for each model, so one is this true positive rate which is a.",
                    "label": 1
                },
                {
                    "sent": "So I know how many.",
                    "label": 1
                },
                {
                    "sent": "So many positives can be fined and false positive rates is how many false negatives?",
                    "label": 0
                },
                {
                    "sent": "How many negatives to be put into politics classes very well?",
                    "label": 0
                },
                {
                    "sent": "We did them.",
                    "label": 0
                },
                {
                    "sent": "And if you.",
                    "label": 0
                },
                {
                    "sent": "Optimal position would be here and random would be kind of historic times 2.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what is nice is if you have some for lots of models and we have some confidence source, we could take the predictions sorted by the office and scores and then slowly as we increase the threshold.",
                    "label": 0
                },
                {
                    "sent": "Threshold for where we say something is positive.",
                    "label": 0
                },
                {
                    "sent": "So we start here everything being zero and slowly jump up and go up there.",
                    "label": 0
                },
                {
                    "sent": "And the better the model the most keep these curves.",
                    "label": 0
                },
                {
                    "sent": "You cannot do this if your mother doesn't have the confidence right.",
                    "label": 0
                },
                {
                    "sent": "Motherfucker, you just need to get some samples.",
                    "label": 0
                },
                {
                    "sent": "You can leave this apartment sacrificing after one week.",
                    "label": 0
                },
                {
                    "sent": "Modern.",
                    "label": 0
                },
                {
                    "sent": "Season 3",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Progression.",
                    "label": 0
                },
                {
                    "sent": "See, these are the measurements.",
                    "label": 0
                },
                {
                    "sent": "This is the model will check how far the March measurement is and then we have other means.",
                    "label": 0
                },
                {
                    "sent": "Carrera should be some dispenser is residuals.",
                    "label": 0
                },
                {
                    "sent": "Mental confidence and determination which we do later in the end zone which tells us how well they behaves.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the question 2 plus how well do we generalize?",
                    "label": 0
                },
                {
                    "sent": "So for generalization, so one rule so that we have to be always very careful about never test on trainings, training data.",
                    "label": 0
                },
                {
                    "sent": "This is can give.",
                    "label": 0
                },
                {
                    "sent": "It gives full sense, false sense of performance and the model.",
                    "label": 0
                },
                {
                    "sent": "It doesn't tell you much, so it's always good to.",
                    "label": 0
                },
                {
                    "sent": "Split if you have the training.",
                    "label": 1
                },
                {
                    "sent": "A lot of Liberator disputed existing training data in training and test parts.",
                    "label": 0
                },
                {
                    "sent": "We train on the training part, then compute the valuation measures in the test part.",
                    "label": 1
                },
                {
                    "sent": "And it's kind of sounds straightforward, but it's always.",
                    "label": 0
                },
                {
                    "sent": "Always getting all these very easy.",
                    "label": 1
                },
                {
                    "sent": "There's some information on the training data.",
                    "label": 0
                },
                {
                    "sent": "Would look into the test, set one up if you have a.",
                    "label": 0
                },
                {
                    "sent": "A stream of particles newsarticles in time.",
                    "label": 0
                },
                {
                    "sent": "And you would randomly split in training and test and then do topic classification of those.",
                    "label": 0
                },
                {
                    "sent": "Then it's a bit unfair.",
                    "label": 0
                },
                {
                    "sent": "It was maybe artikkel.",
                    "label": 0
                },
                {
                    "sent": "Use the model.",
                    "label": 0
                },
                {
                    "sent": "In reality is you have the past data you train on and then you apply it in the future articles so you have to do this time wise place of your entity occurs in the future.",
                    "label": 0
                },
                {
                    "sent": "If you want to handle it fell around as well and this kind of random script will not work well.",
                    "label": 0
                },
                {
                    "sent": "Also feature extraction is running, so if you're doing the TF, IDF or some weighting scheme on the documents.",
                    "label": 0
                },
                {
                    "sent": "Do you want to do it only on the training set, not from the combination of everything, because it start again here.",
                    "label": 0
                },
                {
                    "sent": "So it's always good to have another difficult rule of thumb if you run your algorithm, you test it.",
                    "label": 0
                },
                {
                    "sent": "You get a very good result.",
                    "label": 0
                },
                {
                    "sent": "The first question should always be but very in-depth training data linking to the testing for the test data leading to the training process, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I don't know how do we get confidence about it so when easy way of obtaining multiple metrics from the same training data is to do something called cross validation.",
                    "label": 1
                },
                {
                    "sent": "And the idea here is that we instead of doing last month Train Pass Creek, you can do many tenfold cross predictions on standard thing.",
                    "label": 0
                },
                {
                    "sent": "And that's where you get more number of metrics is and then you can start doing some statistical tests and therefore significance significance.",
                    "label": 0
                },
                {
                    "sent": "And one extreme of that would be leave one out very quickly, take for the training data, remove an example training and test it on the model is 1 example and you do this for each individual example.",
                    "label": 0
                },
                {
                    "sent": "But this can be quite possible.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now the last question is, is a train, the model?",
                    "label": 0
                },
                {
                    "sent": "Is it better than what the literature says about this type of problems?",
                    "label": 0
                },
                {
                    "sent": "Typical approach would be so this closing line against with statistics from before.",
                    "label": 0
                },
                {
                    "sent": "We have two models F1F2.",
                    "label": 1
                },
                {
                    "sent": "Can you tell which is better?",
                    "label": 1
                },
                {
                    "sent": "We compute valuation metrics on a different speeds of train test.",
                    "label": 0
                },
                {
                    "sent": "And because the Hippocrates, do they have the same mean?",
                    "label": 0
                },
                {
                    "sent": "This would be an example of this.",
                    "label": 0
                },
                {
                    "sent": "This permutation test that you're not showing before the thing would be, but the two sets drawn from the same distribution or not so.",
                    "label": 1
                },
                {
                    "sent": "We have tested that and this is something that we can then say to models are statistically different.",
                    "label": 0
                },
                {
                    "sent": "They produced a simple different output and one is better because it has a higher need for examples.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it.",
                    "label": 0
                }
            ]
        }
    }
}