{
    "id": "etypuxdlmis7yclklctlfaswwvnfgjlq",
    "title": "Mismatched Models, Wrong Results, and Dreadful Decisions",
    "info": {
        "author": [
            "David Hand, Department of Mathematics, Imperial College London"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd09_hand_mmwrdd/",
    "segmentation": [
        [
            "Today is the first full day of of KDD.",
            "As you know, we have a full program of 2 1/2 days and we have excellent invited speakers every morning at 9:00 and today.",
            "It is my great honor and pleasure to to introduce David Hand.",
            "David is very well known in the data mining community.",
            "For instance, he's one of the three authors.",
            "Of the principles of data mining book, which I understand has been translated in Chinese and Polish and probably a couple of other languages are forthcoming.",
            "And when I actually looked at it, I realized that quite extraordinarily we have all three authors of that book at this conference, giving plenary speeches.",
            "So yesterday we had the drug Smith.",
            "Today we have David Anne.",
            "On Wednesday we have Haki, so I think it's only fitting that we have.",
            "Three data mining experts giving giving plenary talks here.",
            "David is very prolific author.",
            "I just did a quick count on the number of books that he edited or authored, and I I counted several times and it was every time different, so it's something like 28 plus or minus one.",
            "His latest book is actually you can see it at the CRC Press Stand.",
            "It's on the.",
            "I received curves for continuous data topic very close to my my heart.",
            "One paper up Davids thereby very often referred to in my own work, is the paper that he wrote with Robert Hill is the name yes Robert Till in which they proposed a multiclass version of the AUC measure that paper always has a very nice ring to it because I like to refer to it as hand until which sounds a little bit like hand until which as David is also a financial data mining expert.",
            "Shouldn't really surprise us very much.",
            "That the occasionally has his hand in the till.",
            "Anyway enough of that.",
            "Please join me in welcoming David Hand."
        ],
        [
            "Just just realized that this laser pointer is useless here, because if I point at this thing here.",
            "I need an assistant on the other side, so thank you very much indeed for inviting me to speak at this conference.",
            "It's it's good to be back at a KDD conference, and it's always very nice to be in Paris.",
            "As Peter said, I think this is the first time that Parrot, Heike and I have been at the same conference for 10 years.",
            "In fact, since before we wrote the book, it's not because we fell out while we were writing the book or anything like that.",
            "It's simply that we just haven't happened to go inside.",
            "I am I heard a story the other day about two school boys.",
            "One was very good at mathematics and the other was very bad.",
            "The one who is very good grew up to become a professor of mathematics.",
            "The one who is very bad grew up to become a millionaire.",
            "Long after leaving school they.",
            "Ask the professor how did someone who was as bad at math as you become a millionaire?",
            "It was easy, said the millionaire.",
            "I buy things for $1 and I sell them for two.",
            "That 1% profit soon adds up to a lot of money.",
            "The point of that story is that while not understanding what you're doing, can sometimes have good results in reality, it's much more likely to have bad results.",
            "I want to kick off by quoting from the story which appeared in the British Sunday Times newspaper in April of this year.",
            "So it's it's very recent.",
            "The story was about face scanners used at airports to compare faces with digital passports.",
            "To stop terrorists getting into the UK, the story said, and I quote the machines started to throw out numerous false alarms because of the growing number of false negatives.",
            "Immigration officers say they were ordered last month to re calibrate the machines.",
            "Lowering the threshold match from 80% to 30%.",
            "Changes appear to have been made without giving anyone a reason for the machines creating what is, in effect a 70% error rate.",
            "So what we're talking about in this example is a classification rule being used to see if a traveler matches the passport they're traveling on.",
            "Clearly the classification rule is highly sophisticated.",
            "Facial recognition systems have to be highly sophisticated, but as with all classification rules, there are parameters to be set in particular.",
            "In that case, there's a classification threshold striking a balance between the different kinds of misclassifications.",
            "The balance between on the one hand incorrectly saying that the person doesn't match the passport doesn't match the passport when they don't, and on the other saying they do match the passport don't match the passport when they do.",
            "There are two crucial things about this.",
            "This example one is measuring performance.",
            "And how one actually does measure performance and the other is that when you build a classifier you don't know what value the classification threshold will have when it's used in that example later on, once the system had been built and a year down the line when it was used, the threshold was adjusted and that changed the error rate.",
            "You didn't, you don't know when you're building it, what the classification threshold will be.",
            "So that's a very specific example, but I'm going to come back to it later.",
            "It's an example of how a poor choice of model, or even of a single parameter within a model can lead to problems.",
            "So we're all familiar with the old adage computer science quotation, garbage in, garbage out.",
            "It describes the role of data in decision making, but a similar adage might be coined for poor choice of model, and that's what I want to talk about today.",
            "So I want to kick off sort of at the high level and know that."
        ],
        [
            "Data mining is a very broad discipline.",
            "There are a lot of different aspects to it, including things like predicting numerical values, supervised classification, unsupervised classification or clustering.",
            "Things like anomaly detection, Association analysis and so on.",
            "A lot of different areas, a lot of different sorts of exercises are included within the broad description of data mining."
        ],
        [
            "The sorts of things I'm going to talk about today apply to just about any aspect of data mining, but today because I'm only got 45 minutes or so, I'm going to focus on supervised classification.",
            "There are a number of reasons for that.",
            "That's an area I haven't worked in my life, so I know about it.",
            "It does also illustrate all of the sorts of things I want to discuss, and I can't cover everything so.",
            "So I guess everybody hears."
        ],
        [
            "Million with a sort of.",
            "Paradigm of supervised classification.",
            "You're given a set of objects.",
            "They have known descriptive characteristics.",
            "Each object has a known descriptive vector of descriptive characteristics, and we also have known class memberships, and the aim is to use that data set to construct a rule which will allow you to assign new objects to the class based just on their descriptive vector.",
            "So that's what we're interested in doing given the data set constructor rule."
        ],
        [
            "This sort of paradigm.",
            "Because it's ubiquitous, it occurs all over the place in science, business everywhere, medical diagnosis, fraud detection.",
            "Classifying astronomical objects.",
            "Is it a star or Galaxy?",
            "For instance, customer value management all over the place?",
            "So it's a very widely used kind of data mining sort of problem.",
            "And as."
        ],
        [
            "You will know a huge number of different sorts of rules have been constructed to tackle this problem.",
            "Bypass different intellectual communities, some by statisticians done by machine learning.",
            "People sound like data mining people and so on.",
            "There's a list of just some of them.",
            "You can doubtless add others, which I haven't got up there yourselves.",
            "It goes on and on and on.",
            "When given such a huge list that prompts the obvious question, well, given a particular problem given my face recognition problem or medical diagnosis problem, or how do I choose which of these methods should I use?"
        ],
        [
            "In order to choose, you need a criterion by which you can compare the methods.",
            "You need a performance measure.",
            "These performance measures in fact have various roles they used to estimate the parameters which in some sense is equivalent to choosing between different classification rules of the same sort of model, but with different parameters.",
            "So one role of these things is to estimate parameters.",
            "Another is to choose model components.",
            "Which variables should I include?",
            "Which transformations of the variables for instance?",
            "And another one is simply to evaluate models.",
            "Is this model better than that one does?",
            "It produces a superior result, and of course not.",
            "Just is it better?",
            "But also is good enough for whatever you actually want to do with it, so various roles for these performance criteria, these criteria telling you how good your model is doing."
        ],
        [
            "So performance criteria play a crucial role in data mining.",
            "They've got to be simple numerical summaries.",
            "Our aim is to choose primary inspired unconcern today is to choose between different models on the basis of them.",
            "So I need a simple numerical summary.",
            "It's too complicated.",
            "I won't be able to use it to choose.",
            "I also need to be able to compute these things automatically if I'm looking at millions of different models.",
            "I can't plot a Roc curve.",
            "I'm assuming everybody knows what RFC codes are.",
            "I can't produce a Roc curve for each of these measures and compare them by.",
            "If I've got 10 million of them might be there forever.",
            "I need to be able to do it automatically, so there's a sort of criteria that the performance criteria themselves."
        ],
        [
            "The danger, if you don't choose a performance criterion appropriately, the risk of using a poor performance criterion is that you will get a perform model that would get a poor model and as a result your decisions won't be good.",
            "You'll make mistakes, you'll miss, diagnose sick patients.",
            "You'll lose money in a banking situation, whatever.",
            "A very simple and familiar example of this sort of thing is using misclassification rate.",
            "When you have severely unbalanced classes.",
            "In fraud detection, normally relatively small proportion of the transactions are fraudulent, so very unbalanced classes for rarity, disease detection of very the disease is rare, so that the classes are unbalanced, and if you use error rate, the obvious thing it says it's classify everybody's healthy.",
            "In this case in this example.",
            "So you get a very small error rate and just get all the all the disease people wrong.",
            "Very, very few of those, so you get a very small error rate, but that's absolutely useless for this problem, so clearly error rate is an inappropriate performance criterion for that problem."
        ],
        [
            "Is another example of inappropriate criteria.",
            "This relates to some work I've been doing on fraud detection.",
            "We've got true class is legitimate or fraudulent, cross classified by predicted class, legitimately forging our classification rules has produced a predicted class is class, and we've got counts in each of those cells.",
            "So we've got a objects which really are legitimate, are correctly predicted as legitimate.",
            "Now.",
            "There are various ways we could do this.",
            "One would be to look at accounts we could look at all of the transactions in an account and monitor all those transactions, and if any of them are turned out to be fraudulent, we can classify the account as fraudulent.",
            "The trouble with that is that if you monitor account for long enough, well, the longer you monitor an account the the greater the chance that it will become fraud and that someone will break into the account, clone the credit card card or or whatever.",
            "So using accounts for this means that your counts ABCD in here.",
            "Depends how long you study the thing for, so that would be an inappropriate criteria.",
            "Much better to use transactions, individual transactions in this case, so there's a 2 little examples of.",
            "Where an inappropriate for performance criteria can lead to wrong results."
        ],
        [
            "Now there are different types of performance criteria is useful to distinguish three different types.",
            "One problem based criteria could be problem based criterion model, fit criterion, classification, accuracy criteria.",
            "I'm really interested in the third one today, but let me.",
            "Indeed, illustrate the sorts of things I mean by the."
        ],
        [
            "Other criteria problem based criteria are things like speed of construction of the classification rule.",
            "Speed of classification and so on.",
            "There things which are very much context dependent.",
            "Speed of classification will be important.",
            "Well in many situations.",
            "Let me come back to the fraud detection example.",
            "A classifier which gets things 100% right.",
            "Let's talk about credit card fraud detection.",
            "A classifier which gets things 100% right.",
            "It looks at each transaction and correctly assigns it to the legitimate or fraudulent class would be useless if it took three months to do that.",
            "You really need to know now at the time of transactions being made so you can stop it.",
            "So in that case speed of classification would be important and in all of these examples here there are application domains where these particular properties are important.",
            "So these things themselves are criteria for in some sense how good the rule is, how useful it is for your particular problem in bioinformatics.",
            "For example, there are a lot of small and large pee problems, and in other areas also.",
            "So you need a classification which could cope with those sorts of problems quite easily.",
            "Many problems, especially those involving data collected from human beings, have incomplete data.",
            "There are often missing values.",
            "If your classification rule struggles to cope with missing values, then it probably isn't a very good one for whatever that particular problem is.",
            "So these are problem based criteria.",
            "They're very much context dependent, so I can't say much about them.",
            "In general, when we can only say something about them.",
            "When you focus on a on a particular problem."
        ],
        [
            "An example of this sort of thing, again coming back to the fraud detection example.",
            "Is timeliness I've already referred to speed and this this speed of detection and classification?",
            "This illustrates it.",
            "I've got a string of transactions there labeled N. If they are legitimate.",
            "If they're non fraudulent, and F if they are fraudulent.",
            "The colored red.",
            "The color red when my fraud detector.",
            "Flags in my classifier.",
            "Classifieds them as suspicious.",
            "My classifier says I think this is fraudulent.",
            "So what you can see is for non fortunate ones, fraud legitimate ones to start with on the left, which the classifier thinks that colored and black.",
            "So it thinks that adjustment, then a fraudulent one which it is missed.",
            "It's frozen, it's not colored red, it's missed it.",
            "Couple of legitimate ones, and then another fraudulent one.",
            "It's missed.",
            "And so on.",
            "And then we get to the first red end.",
            "It's a legitimate transaction, but the fraud detector.",
            "Race is suspicious about it, so you know the bank manager phones up and said, did you make this transaction and the thing trundles along until it reaches the last one, which is a fraudulent transaction F which is colored red.",
            "It's the detector has flagged this.",
            "The classifier is flagged it as suspicious, and so it's correctly identified a fraudulent transaction.",
            "Now.",
            "What we're interested in here is one of the things we're interested in.",
            "Here is, of course, how many it gets right, how many it gets wrong, but also how many gets wrong, how many of the FCT gets wrong?",
            "How many of the fraudulent transactions it gets wrong before it correctly identifies a fraudulent transaction and stops the card?",
            "So an appropriate measure of timeliness.",
            "For example, there might be the number of black FS in this sequence of transactions that might be inappropriate.",
            "Appropriate measure of performance.",
            "Very context dependent.",
            "So that was my first kind of performance criteria.",
            "Problem based criteria."
        ],
        [
            "The second kind was model fit criteria.",
            "Model fit criteria are basically accurate measures of accuracy of probability estimates.",
            "How accurate is the?",
            "Let's suppose I've just got two classes.",
            "To make life simple, and in fact most of what I'm going to talk about from now on assumes two classes.",
            "So a measure of accuracy of probability estimates would be how accurate you think the probability your estimate of the probability belonging to class one for a particular measurement vector is.",
            "And there are various measures.",
            "Log likelihood is a measure, Brier score is a measure there.",
            "It was a common measures.",
            "There are other measures as well.",
            "There are measures of how accurate your.",
            "Estimated probability belong to class one is.",
            "This is not very well and it is quite widely used.",
            "The more widely used in certain intellectual communities and others, but they're quite widely used.",
            "Likely it of course, is very widely used in statistics.",
            "Thing is, however, the goodness of fit.",
            "How accurate these probability estimates are isn't the same as accuracy of classification.",
            "And in fact, a poor fit can mean greater."
        ],
        [
            "Here's a little example.",
            "On the horizontal axis, I've got my predictor variables.",
            "I've only got 1 here X on the vertical axis I've got the estimated probability of belonging to class one with the horizontal line indicating estimated probability of 1/2.",
            "In the left hand.",
            "In the left hand graph here, the red line is the true probability of belonging to class one for different values of X.",
            "And in the left hand graph, I'm going to assume that my.",
            "Classifier is unbiased so that on average, if I took different designing set different training sets, different design sets, and built my classification rule on average, it would give me an estimated probability of belonging class one which lies absolutely on the true value on the red line.",
            "But of course it's on average.",
            "If I took a different training set, I would get different estimates and the distribution about the red line.",
            "Here the distribution about the red line here indicates that the sort of range of values of the estimate I would get at that value of X if I took different training sets, and you can see that sometimes I would be below what I'm taking as a threshold value of 1/2.",
            "Sometimes if I based my classifications on this rule despite it being unbiased.",
            "Despite on average, overall different classification rules, it giving the correct estimated problem belonging to class One at that value of X.",
            "Sometimes it would produce wrong decisions.",
            "Some of these things are below half.",
            "Now let's look at this alternative classifier, which produces an estimated probability of class one which is bias.",
            "It produces an estimated probability of class one lying on this broken line.",
            "So it's biased.",
            "It's not lying on the correct value, the unbroken line.",
            "Again, we've got variation about that line.",
            "If I took different training sets, different design sets, I would have variation about that.",
            "So again, I've got this distribution about this here, but you can see that nowhere or hardly any of the tails of that distribution lie below the threshold of 1/2.",
            "So this second classifier is biased.",
            "Its estimate of the probability of belonging to class one is not as accurate as the first classifier, but it's producing fewer misclassifications.",
            "So estimated probability belonging to Class 1.",
            "And accurate values of that.",
            "Is not the same as classification accuracy and you can do better with biased classifications.",
            "Jerry Friedman produced a very nice paper in 1997 going into the details of this very elegant little paper."
        ],
        [
            "OK. And now I come to in some sense what I really want to talk about today.",
            "This is a third group of performance measures.",
            "Classification accuracy criteria.",
            "So what I've got is a score for each value of X estimated probability belong to class one.",
            "Or perhaps something else but a score, and what I'm going to do to produce classification, always calculate that score and impose a threshold or threshold T anything belote anything with a score or estimated probability of allowing the Class One belote I'm going to predict his class, not anything above.",
            "I'm going to predict his Class 1.",
            "Cannot produce the standard sort of classification table.",
            "Here I've got across classification of true class by by predicted class.",
            "I've got a class notes like below T, so a of the true class notes are correctly predicted as belonging class Norton.",
            "The same for the rest of the little table.",
            "This is a sort of standard sort of thing, and this is what I want to do."
        ],
        [
            "For the next few slides.",
            "So in the top here I've got the little classification table again.",
            "And there are various different performance criteria you can produce based on this table, and they're they're immensely widely used.",
            "If I call if I think of class one, is the cases or the positives or frauds, or the abnormals or whatever.",
            "In some sense, the thing I'm interested in identifying then various different familiar measures are produced from this.",
            "So for example, the proportion of class ones which are correctly classified as class 1D over B + D. The medicine is called sensitivity in computer science information retrieval.",
            "It's called recall, and so on, and analogist thing over here.",
            "The proportion of class notes which are correctly classified and medicines called specificity and those two examples involve probabilities.",
            "Given the true class, but one can also calculate probabilities given the predicted class and then you get things like positive predictive value in medicine or precision information return and so on.",
            "Different ways you can calculate these things.",
            "Clearly there are going to be relationships between these involving the class priors, the class prize, the proportion in class, not in this report."
        ],
        [
            "During Class 1.",
            "So I had four counts in my little table ABC and D. The priors, the proportions in class, Norton class one don't depend on the classification rules, so I can take them as fixed and I can take the total number of things I'm looking at in order to produce the table that doesn't depend on the classification rule so I can take that is fixed.",
            "So I got 4 numbers ABCD and I've got two constraints on it, so I've got 2 degrees of freedom in here.",
            "To produce a performance metric, something I can actually use to compare classification rules, I need to reduce those to one so that I can say this has a higher performance value than this.",
            "So I need to reduce these things to 1 degree of freedom, and that's where that's where all our problems stop.",
            "How do we combine these into a single performance measure?",
            "And there are many familiar ways of doing this.",
            "Error rate is a familiar example error rate basically.",
            "Wait, sleep sensitivity by the proportion in class one adds it to the specificity.",
            "By times the proportioning class nought, and that's equivalent to error rate.",
            "It's the ones that the proportion I get wrong B + C over the total number.",
            "That's one way of combining or reducing our two degrees of freedom to one."
        ],
        [
            "One might be in some applications one might want to adjust for the fact that you would expect to get some correct by chance, so another simple performance measure adjusts for the proportion you'd expect to get correct by chance.",
            "Another measure widely used in the information retrieval community combines them in combines these things in a rather more complicated way to produce the F measure.",
            "And there are many other ways of reducing those four numbers just to one which we can then use as a performance criterion to rank our different classifiers and hint choose between them."
        ],
        [
            "First, obviously these different performance criteria aren't monotonically related.",
            "If this one gives this criterion gives a higher score for this model and that model and other criteria might not give a higher score for this model compared with that model.",
            "If they did give.",
            "If they were monotonically related, they'd all be equivalent.",
            "There wouldn't be any point in using it, so they're not monotonically related.",
            "But there are relationships between them.",
            "I'm not going to bore you by going through this.",
            "The the details of these clearly there you know, we've only got 4 numbers which we are trying to summarize in some way.",
            "There are relationships."
        ],
        [
            "However.",
            "All the methods based on that little classification table.",
            "Model ABCD.",
            "Assume that I had chosen a threshold threshold such that if my score or my estimated probability or whatever was less than two yard sales class Norton if it is above TI, would say it was class one.",
            "I had to have that threshold to produce that table.",
            "And that raises the question of where did that T come from?",
            "How did you choose that threshold?",
            "So I'm going to approach this one particular way.",
            "You don't have to approach it this way and what I'm about to say is going to be fairly controversial, but it's sound I'm not going to be able to go into all the details and happy to talk to people about it in more detail afterwards.",
            "As a paper appearing about to appear in machine learning, which gives the gives it in more detail.",
            "So how to choose T?",
            "Well, to approach it, I'm going to suppose that the cost of misclassifying across I object, like was not a one.",
            "Here should be CI socin autism cost of misclassifying a class not object.",
            "In that case, the overall loss due to misclassification is this.",
            "This is just the proportion of class notes which are above the threshold 1 minus the proportion below times the proportion of objects which belong to class North Times the cost of misclassifying each of those, and then a similar thing for class one.",
            "So that's the overall loss given that we've chosen a particular threshold.",
            "The rational thing to do, if you know what the costs.",
            "See Norton C1R is to choose a threshold which minimizes the total loss."
        ],
        [
            "The threshold which minimizes the loss.",
            "It's a little bit of calculus really written it down there.",
            "I'm going to call the threshold, which minimizes the total loss capital T so you give me the cost C Norton C1 and we can then find.",
            "The minimum of array of this little expression here with the T which minimizes that the threshold which produces minimum loss and then a little bit of calculus.",
            "You have to do some.",
            "It's a bit more complicated.",
            "Things aren't continuous and somebody you know.",
            "No real problems, little bit of calculus essentially leads to a mapping between the ratio between those two misclassification costs.",
            "See one overseen ought and the optimal threshold, and this is all.",
            "This is all perfectly standard stuff.",
            "None of this is original.",
            "And of course, given the T then then this is the the given the threshold and cost management loss minimizing threshold.",
            "Then that's human loss.",
            "Q Given by that."
        ],
        [
            "That's fine if you know what C, Norton, C1R.",
            "But what do you do if you don't know what the costs are going to be in the future?",
            "Remember the airport facial scanner example.",
            "They change their minds about where the threshold should be.",
            "They changed their minds about what they regarded as important relative costs in the future.",
            "So when you're building these things, you don't necessarily know how it's going to be used in the future.",
            "So what do we do if we don't know what the costs are going to be?",
            "Equipment, well, we've got this relationship between tools."
        ],
        [
            "We've got this little relationship between the ratio C not and C1 and T."
        ],
        [
            "So not knowing the cost is perfectly equivalent to saying what do I do if the future threshold is unknown?",
            "The threshold that's going to be used in the future is unknown.",
            "These two things are equivalent.",
            "Not knowing the cost ratio, not knowing."
        ],
        [
            "T. Well, there are two approaches to this.",
            "The first approach, very widely used is to make default assumptions.",
            "So, for example, we might assume that C. Norton C1 are equal.",
            "Standardize the units Towanda.",
            "We might assume that they are equal.",
            "If you assume they're equal, it's very easy to see that that leads to misclassification rate.",
            "That leads to error rate, so that's using error rate is equivalent to making the default assumption that costs are equal, and everybody knows this.",
            "Another default assumption is to assume that the Cir.",
            "Let's see, note is equal to the prior of the other class and see one is equal to the prior of the other class.",
            "And if you do that, you end up with other also widely used measures.",
            "In particular context, the udon statistic that KS statistic and so on very widely used in credit scoring, for instance.",
            "So error rate is used by more than 95% of papers evaluating classification rules in the machine learning literature.",
            "For instance, an AKS statistic is very widely used in, as I say in credit scoring, so different communities use different measures.",
            "But in this case these are examples of.",
            "Default assumptions to overcome the fact that we don't actually know what these costs are."
        ],
        [
            "So very well, but default assumptions.",
            "That's equivalent.",
            "Picking things to make life easy.",
            "Picking them for mathematical convenience, we really should choose our costs.",
            "Our threshold.",
            "Because of what the problem?",
            "Because of what we think the relative severities are.",
            "Remember, if you choose the wrong performance criterion, you could end up with the wrong model.",
            "And and incorrect conclusions and misdiagnosed patients or whatever.",
            "So we really ought to choose these costs.",
            "The ratio between them on the basis of what matters for the problem."
        ],
        [
            "So how much?"
        ],
        [
            "First strategy.",
            "Make the."
        ],
        [
            "Old assumptions, but that's not really a very wise thing to do, even though practically everybody, including myself."
        ],
        [
            "Generally done that.",
            "The second strategy is to average over all possible costs.",
            "What we could do is say, well, we don't know what the future costs or the ratio C not to see one is actually going to be, but I think it's quite likely to be this less likely to be that and so on.",
            "If you like, we could put a prior on this concentration.",
            "The prior ones, the joint distribution of C. Norton C1.",
            "So that's what I've got here.",
            "I've got this this bid in red is just the last thing that I had up before.",
            "A weighted sum of the costs of the two kinds of misclassification weighted by the relative sizes of the classes.",
            "And I've got some sort of distribution for what I think the likely future costs are likely to be.",
            "And then I'm just going to integrate over that distribution to those brief sort of average expected loss.",
            "If you like expected future loss.",
            "And I've slightly simplified things down here because you you remember from before C. Norton C1 didn't really matter by themselves, it was the ratio of them which was crucial.",
            "It was the ratio of them which mattered.",
            "So I basically in essence on basically replacing see Norton C1 by something equivalent to the ratio, which I've called C. So here is my.",
            "Expected loss.",
            "Averaged over what I think like C is likely to be in the future.",
            "If you're not Bayesian and you don't like these sort of subjective distributions.",
            "Bear with me because you'll see that this sort of thing has implications for the way things are used in practice.",
            "OK, so average expected loss here.",
            "No.",
            "The key in all this, of course, is going to be how you choose W. How you choose this distribution for what you think the values of C are likely to be in the future."
        ],
        [
            "Well, here's a particular, just terribly ugly expression W star now.",
            "Please don't study the details of that.",
            "I'm going to come back to the one important feature of it in a moment.",
            "It's just clearly quite a big, complicated expression.",
            "It's the particular expression of particular form, but my point about this is that if you choose that particular form than my average expected loss, and I'm sparing you the tedium of the mathematics, the average expected loss can be rewritten to be that and simplifies to that the average expected loss is a simple linear transformation of.",
            "Is equivalent to the area under the Arosi cap.",
            "The arosi curve you recall is a plot of F nought proportion proportion of class notes below the threshold.",
            "On the vertical axis and F1, the proportion of class ones below the threshold as the threshold varies.",
            "That's the Roc Cup and a very widely used measure in certain intellectual communities of performance is the area under the arosi curve and our OC curve is better than nearer.",
            "It goes to this top left hand corner if it lies on the diagonal, it's equivalent to chance classification, random assignment to classes.",
            "So in some sense, it's a good measure.",
            "The area under the curve, the further it pushes up, the bigger the area becomes, the better the classifier is.",
            "And as I've just shown, I haven't actually shown.",
            "I've told you I've waved my hands, but the maths is behind it.",
            "The area under the curve is equivalent to.",
            "The misclassification.",
            "Loss if you use this particular weight function.",
            "As I say, I hope you looked at the details of."
        ],
        [
            "Wait function 'cause it doesn't matter.",
            "OK, this summarizes where I've got to the moment L is equal to this loss, averaged over some distribution W. And if you choose a particular distribution W star, the one which I've written down there, you get L being equivalent to the area under the curve."
        ],
        [
            "So area under the curve is equivalent to averaging the loss over this cost function W star.",
            "And the crucial thing is that W star that horrible expression that I put up and that I've reproduced here.",
            "Depends upon F nought and F1.",
            "It depends on the observed score distributions.",
            "If not, is the score distribution distribution of estimated probably belong to class one for class nought and F1 is the corresponding scene for Class 1.",
            "So this distribution W star.",
            "Depends on the empirical data.",
            "Your choice about how much weight you should give to different values of C. Depends upon the empirical data."
        ],
        [
            "And this is kind of crucial because knowledge of C or equivalently have seen on C1 the ratio between them relative costs the relative severity of misclassifications.",
            "Can't come from the data, it's gotta come from outside.",
            "It's gotta come from an extra mathematical sort of thing you've got to look at the thing and say if I miss classify this fraud as legitimate relative to the other way round that it's 100 times a serious or whatever.",
            "You can't look at the data and say Oh well if I got different data it would be different in different degree of severity.",
            "That would be nonsensical.",
            "In fact, I'm driving at home here."
        ],
        [
            "So what this means is that using the area under the quote, not under the curve under the RSC curve.",
            "Is equivalent to saying that your belief in the relative severity which will be assigned to different types of misclassifications depends on your choice of classifier.",
            "It depends on distributions F, Norton F1 and different classifiers will give you different distributions.",
            "This whole point.",
            "What this says is that your distribution the.",
            "Your belief in the relative severity ends which classifier you happen to use.",
            "That's clearly nonsensical.",
            "I have a little example here.",
            "It's like measuring my height in millimeters and yours in feet and saying I'm taller because my number is bigger than yours.",
            "Is pleading on sensical"
        ],
        [
            "OK people say, but area under the curve has several nice interpretations.",
            "I've used it, you know, for the last 2530 years and.",
            "Everybody uses it.",
            "It's got all sorts of nice interpretations.",
            "Here is 1.",
            "It's the average value of the vertical axis, assuming if you take a uniform distribution on the horizontal axis on our OC curve, the average value of F nought if F1 is chosen from a uniform distribution.",
            "So I've written it down here.",
            "Very nice sort of interpretation.",
            "We assume that any value of F1 is equally likely a uniform distribution for F1, and then we average the corresponding values of F Nord.",
            "A very nice sort of interpretation."
        ],
        [
            "The trouble is that F nought and F1 are what you might call operating characteristics of the curve.",
            "Indeed, it's the receiver operating characteristic curve.",
            "It's not my work and operating characteristics is you can choose them.",
            "You can choose one of them and that tells you the shape of the curve, so I can choose F1 or I could choose F, not one or the other according to what sort of behavior I wanted from my classifier.",
            "And of course, it's entirely possible I might choose a different value for different rules, so I've got a little example here.",
            "Rule one might be logistic regression, Rule 2 might be a random forest or something like that.",
            "So on the left here I've got rule one which gets 95% of Class 1 correct, 95% or above the threshold and it gets 89% of class not correct.",
            "If I adjust my threshold to increase F North there, I've increased it to F nought.",
            "I will reduce this particular rule.",
            "This logistic regression or whatever it was reduce my proportion of F1 which I'm getting correct, 80% reduction that improvement from 89 to 90 is tiny.",
            "The reduction from 95 to 80 is quite substantial, so I might prefer with rule one.",
            "I might prefer to use threshold T, which gives me 95% across one right and 89% of class.",
            "Not right?",
            "What about rule two?",
            "Rule two?",
            "Well, if I choose the threshold to give me 95% of Class 1 right happens.",
            "This random forest happens to give me 10% of class, not right?",
            "What if I change the threshold to teen or to reduce this to 80% to make it compatible with the other one?",
            "Then my proportion of class more correct leaps to 80.",
            "So in that case I might well prefer to use T star tick tick T dashed.",
            "This threshold with rule tool with two months giving me 80% of Class 1 right and 90% of.",
            "Class.",
            "Not right so?",
            "I can choose.",
            "I might well choose a different F1, a different proportion of class one correctly classified according to which rule I'm using.",
            "Different rules might lead me to different proportions.",
            "The point is that there's nothing fundamental about the proportion F1 of class one.",
            "I choose to correctly classify or of fnord.",
            "It's it's my choice."
        ],
        [
            "But the distribution of the relative costs comes from the problem.",
            "It's what you think the relative relative severity of the two different kinds of misclassification, or it's not something you can choose.",
            "It's a matter of what you believe about what's going on.",
            "What this means, of course, is that.",
            "This distribution WC what you think the distribution, relative severities is likely to be, can't vary from classified a classifier.",
            "It's a fundamental fundamental aspect of the problem is not like choosing the proportion of class ones I get right in my little example on the previous slide, this is fundamental.",
            "It doesn't vary from classifier classifier.",
            "So the colored example.",
            "I can't say if I use logistic regression then misclassifying a cancer sufferer is as healthy as 10 times as serious as the reverse.",
            "But if I use a tree classifier, then it's 100 times it's serious, that's ridiculous.",
            "See is a property of the problem, not the classifier."
        ],
        [
            "No, I haven't gone through the mass, but there's a relationship between this.",
            "See this cost ratio and sensitivity.",
            "The proportion of class when I get right.",
            "We've seen the relationship between the ratio.",
            "See Norton C1 and Capital T, and of course choosing Capital T determines the proportion of class one I get right?",
            "So that gives us a relationship between the ratio of C. Norton C1 and the sensitivity.",
            "And of course, that relationship, as we've seen, depends on the empirical distribution that depends on the score distributions.",
            "The F, North and F1 distributions.",
            "There's a relationship, so these things are linked together.",
            "You do something with one, it changes what's happening to the other.",
            "OK, now I could choose my distribution over which I average my distribution over F1, which I used to average F not remember the area under the curve.",
            "It said what's the average value of F nought?",
            "If I assume a uniform distribution for F1?",
            "So in the area under the curve, I've chosen a particular distribution for F1.",
            "I could choose others to shift the weight elsewhere, partially area under the curve is an example of that sort of thing.",
            "So that's what five in hit.",
            "That's what five represents.",
            "It's whatever distribution I've chosen for averaging over F1 uniform in the case of the area under the curve.",
            "And W is my choice of distribution for this cost ratio seen over C1.",
            "So I've got these two distributions and they are tide together because of the relationship between the costs and F1.",
            "What this means is you can't simultaneously choose a file distribution and a W distribution.",
            "In dependently empirical distributions you tell me you want distribution you want for five and because of this relationship you end up with a W distribution which depends on F, not F1.",
            "It depends on the empirical score distributions and the other way round you tell me what distribution you want to use for W and because of the relationship it means that your file distribution will depend on if not on F1 you can't.",
            "You can't simultaneously choose.",
            "Both these distributions, independently of the empirical distributions.",
            "What it means is that.",
            "If you choose one distribution, I want a uniform distribution or whatever the other distribution depends on the empirical on what classifier you're using."
        ],
        [
            "So.",
            "Which should we use?",
            "Should we should we fix fi independent of the classifier or should we fix W?",
            "Well, we've already seen that.",
            "Find the distribution over X the distribution over F1.",
            "Is a matter of choice.",
            "I could choose a uniform distribution as the area under the curve that I could choose.",
            "Sort of step function for a partial area under could choose what I like.",
            "We saw in my little table comparing different classifiers with different threshold values.",
            "It's a matter of choice.",
            "I can choose different values for different classifiers, But see this cost ratio is not something I can choose.",
            "It is a fundamental fundamental property of the problem.",
            "I don't know what it is I'm going to have to come up with some distribution for what I think it is, but it can't vary from classified a classifier.",
            "The area under the curve, however.",
            "As I've basically said, fixes fight to be the uniform distribution.",
            "What that means is that the area under the curve implies that your W distribution varies from classifier classifier.",
            "You use a random forest classifier.",
            "You are saying I believe the cost distribution is like this.",
            "If I use a logistic regression, I believe it's like that."
        ],
        [
            "Now it's OK for different researchers to choose to have different beliefs about the relative costs your your your distribution of relative cost values may vary be very different from yours.",
            "That's OK, you know.",
            "I think this is much more likely to be this kind of misclassification is is much more serious than that kind.",
            "You might not think it's so, so that's fine, and they may be interested in different aspects of the problem, so that's fine.",
            "But it's wrong for a single researcher for me.",
            "For example to choose different contribution distributions for different classifiers.",
            "Cost distribution has to come out of the problem."
        ],
        [
            "OK, the way to get round this, which I'm not going to have time to talk about today, is to choose a W distribution which is the same full classifiers, which necessarily means that the weighting distribution over F1 is going to vary from classified classified.",
            "But you can't have it both ways and the cost distribution is fundamental.",
            "So there are basically two ways to do this.",
            "The first approach is to choose W to reflect your personal beliefs in the likely cost distribution, cost ratio distribution, and the other way is to choose a universal standard.",
            "I think in real problems you should report both of these so that in the first case you can say, well, I think this is what's important and we bought that.",
            "And in the second case you can, anybody would produce the same result and paper in machine learning goes into details of this, but I think in real problems you should report both."
        ],
        [
            "OK, so let's summarize.",
            "As far as supervised classification is concerned, different application domains tend to favor different performance measures, so medicine looks at sensitivity, specificity, machine learning, looks error and so on and so forth."
        ],
        [
            "The conclusions from this are.",
            "Don't use measure measures of model fit if classifications, then remember my little example about biased classifier, poor estimated probability belonging to class one, giving you better classification results, greater proportion correct or whatever.",
            "2nd.",
            "Clearly this is the context dependent stuff.",
            "Choose a measure which best matches your objectives.",
            "And of course you don't have to just choose one measure.",
            "You might look at classification accuracy and speed and so.",
            "And that's asserting take special aspects of the problem into account.",
            "And then at the bottom in red don't use the area under the RO seeker because at its core it has this fundamental incoherence.",
            "It means that if you're using different classifiers, then you believe that the relative severities of the different kinds of misclassification are different.",
            "Remember my example about measuring my height in millimeters and yours in feet.",
            "It is in fact nonsensical."
        ],
        [
            "In general, of course, at a high level, choosing an inappropriate measure can mean the title of the talk, mismatched models, wrong results, and dreadful decisions.",
            "You classify the cancer sufferer as healthy.",
            "That's happened.",
            "I have other examples of this sort of thing, and as a consequence they suffer.",
            "I've used supervised classification as an example because it's an area I know about, but the same.",
            "The same applies much more generally in all modeling and in your data mining exercises.",
            "Choice of the performance measure.",
            "Is crucial."
        ],
        [
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today is the first full day of of KDD.",
                    "label": 0
                },
                {
                    "sent": "As you know, we have a full program of 2 1/2 days and we have excellent invited speakers every morning at 9:00 and today.",
                    "label": 0
                },
                {
                    "sent": "It is my great honor and pleasure to to introduce David Hand.",
                    "label": 0
                },
                {
                    "sent": "David is very well known in the data mining community.",
                    "label": 0
                },
                {
                    "sent": "For instance, he's one of the three authors.",
                    "label": 0
                },
                {
                    "sent": "Of the principles of data mining book, which I understand has been translated in Chinese and Polish and probably a couple of other languages are forthcoming.",
                    "label": 0
                },
                {
                    "sent": "And when I actually looked at it, I realized that quite extraordinarily we have all three authors of that book at this conference, giving plenary speeches.",
                    "label": 0
                },
                {
                    "sent": "So yesterday we had the drug Smith.",
                    "label": 0
                },
                {
                    "sent": "Today we have David Anne.",
                    "label": 0
                },
                {
                    "sent": "On Wednesday we have Haki, so I think it's only fitting that we have.",
                    "label": 0
                },
                {
                    "sent": "Three data mining experts giving giving plenary talks here.",
                    "label": 1
                },
                {
                    "sent": "David is very prolific author.",
                    "label": 0
                },
                {
                    "sent": "I just did a quick count on the number of books that he edited or authored, and I I counted several times and it was every time different, so it's something like 28 plus or minus one.",
                    "label": 0
                },
                {
                    "sent": "His latest book is actually you can see it at the CRC Press Stand.",
                    "label": 0
                },
                {
                    "sent": "It's on the.",
                    "label": 0
                },
                {
                    "sent": "I received curves for continuous data topic very close to my my heart.",
                    "label": 0
                },
                {
                    "sent": "One paper up Davids thereby very often referred to in my own work, is the paper that he wrote with Robert Hill is the name yes Robert Till in which they proposed a multiclass version of the AUC measure that paper always has a very nice ring to it because I like to refer to it as hand until which sounds a little bit like hand until which as David is also a financial data mining expert.",
                    "label": 0
                },
                {
                    "sent": "Shouldn't really surprise us very much.",
                    "label": 0
                },
                {
                    "sent": "That the occasionally has his hand in the till.",
                    "label": 0
                },
                {
                    "sent": "Anyway enough of that.",
                    "label": 0
                },
                {
                    "sent": "Please join me in welcoming David Hand.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just just realized that this laser pointer is useless here, because if I point at this thing here.",
                    "label": 0
                },
                {
                    "sent": "I need an assistant on the other side, so thank you very much indeed for inviting me to speak at this conference.",
                    "label": 0
                },
                {
                    "sent": "It's it's good to be back at a KDD conference, and it's always very nice to be in Paris.",
                    "label": 0
                },
                {
                    "sent": "As Peter said, I think this is the first time that Parrot, Heike and I have been at the same conference for 10 years.",
                    "label": 0
                },
                {
                    "sent": "In fact, since before we wrote the book, it's not because we fell out while we were writing the book or anything like that.",
                    "label": 0
                },
                {
                    "sent": "It's simply that we just haven't happened to go inside.",
                    "label": 0
                },
                {
                    "sent": "I am I heard a story the other day about two school boys.",
                    "label": 0
                },
                {
                    "sent": "One was very good at mathematics and the other was very bad.",
                    "label": 0
                },
                {
                    "sent": "The one who is very good grew up to become a professor of mathematics.",
                    "label": 0
                },
                {
                    "sent": "The one who is very bad grew up to become a millionaire.",
                    "label": 0
                },
                {
                    "sent": "Long after leaving school they.",
                    "label": 0
                },
                {
                    "sent": "Ask the professor how did someone who was as bad at math as you become a millionaire?",
                    "label": 0
                },
                {
                    "sent": "It was easy, said the millionaire.",
                    "label": 0
                },
                {
                    "sent": "I buy things for $1 and I sell them for two.",
                    "label": 0
                },
                {
                    "sent": "That 1% profit soon adds up to a lot of money.",
                    "label": 0
                },
                {
                    "sent": "The point of that story is that while not understanding what you're doing, can sometimes have good results in reality, it's much more likely to have bad results.",
                    "label": 0
                },
                {
                    "sent": "I want to kick off by quoting from the story which appeared in the British Sunday Times newspaper in April of this year.",
                    "label": 0
                },
                {
                    "sent": "So it's it's very recent.",
                    "label": 0
                },
                {
                    "sent": "The story was about face scanners used at airports to compare faces with digital passports.",
                    "label": 0
                },
                {
                    "sent": "To stop terrorists getting into the UK, the story said, and I quote the machines started to throw out numerous false alarms because of the growing number of false negatives.",
                    "label": 0
                },
                {
                    "sent": "Immigration officers say they were ordered last month to re calibrate the machines.",
                    "label": 0
                },
                {
                    "sent": "Lowering the threshold match from 80% to 30%.",
                    "label": 0
                },
                {
                    "sent": "Changes appear to have been made without giving anyone a reason for the machines creating what is, in effect a 70% error rate.",
                    "label": 0
                },
                {
                    "sent": "So what we're talking about in this example is a classification rule being used to see if a traveler matches the passport they're traveling on.",
                    "label": 0
                },
                {
                    "sent": "Clearly the classification rule is highly sophisticated.",
                    "label": 0
                },
                {
                    "sent": "Facial recognition systems have to be highly sophisticated, but as with all classification rules, there are parameters to be set in particular.",
                    "label": 0
                },
                {
                    "sent": "In that case, there's a classification threshold striking a balance between the different kinds of misclassifications.",
                    "label": 0
                },
                {
                    "sent": "The balance between on the one hand incorrectly saying that the person doesn't match the passport doesn't match the passport when they don't, and on the other saying they do match the passport don't match the passport when they do.",
                    "label": 0
                },
                {
                    "sent": "There are two crucial things about this.",
                    "label": 0
                },
                {
                    "sent": "This example one is measuring performance.",
                    "label": 0
                },
                {
                    "sent": "And how one actually does measure performance and the other is that when you build a classifier you don't know what value the classification threshold will have when it's used in that example later on, once the system had been built and a year down the line when it was used, the threshold was adjusted and that changed the error rate.",
                    "label": 0
                },
                {
                    "sent": "You didn't, you don't know when you're building it, what the classification threshold will be.",
                    "label": 0
                },
                {
                    "sent": "So that's a very specific example, but I'm going to come back to it later.",
                    "label": 0
                },
                {
                    "sent": "It's an example of how a poor choice of model, or even of a single parameter within a model can lead to problems.",
                    "label": 0
                },
                {
                    "sent": "So we're all familiar with the old adage computer science quotation, garbage in, garbage out.",
                    "label": 0
                },
                {
                    "sent": "It describes the role of data in decision making, but a similar adage might be coined for poor choice of model, and that's what I want to talk about today.",
                    "label": 0
                },
                {
                    "sent": "So I want to kick off sort of at the high level and know that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data mining is a very broad discipline.",
                    "label": 1
                },
                {
                    "sent": "There are a lot of different aspects to it, including things like predicting numerical values, supervised classification, unsupervised classification or clustering.",
                    "label": 1
                },
                {
                    "sent": "Things like anomaly detection, Association analysis and so on.",
                    "label": 0
                },
                {
                    "sent": "A lot of different areas, a lot of different sorts of exercises are included within the broad description of data mining.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The sorts of things I'm going to talk about today apply to just about any aspect of data mining, but today because I'm only got 45 minutes or so, I'm going to focus on supervised classification.",
                    "label": 1
                },
                {
                    "sent": "There are a number of reasons for that.",
                    "label": 1
                },
                {
                    "sent": "That's an area I haven't worked in my life, so I know about it.",
                    "label": 0
                },
                {
                    "sent": "It does also illustrate all of the sorts of things I want to discuss, and I can't cover everything so.",
                    "label": 0
                },
                {
                    "sent": "So I guess everybody hears.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Million with a sort of.",
                    "label": 0
                },
                {
                    "sent": "Paradigm of supervised classification.",
                    "label": 0
                },
                {
                    "sent": "You're given a set of objects.",
                    "label": 1
                },
                {
                    "sent": "They have known descriptive characteristics.",
                    "label": 0
                },
                {
                    "sent": "Each object has a known descriptive vector of descriptive characteristics, and we also have known class memberships, and the aim is to use that data set to construct a rule which will allow you to assign new objects to the class based just on their descriptive vector.",
                    "label": 1
                },
                {
                    "sent": "So that's what we're interested in doing given the data set constructor rule.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This sort of paradigm.",
                    "label": 0
                },
                {
                    "sent": "Because it's ubiquitous, it occurs all over the place in science, business everywhere, medical diagnosis, fraud detection.",
                    "label": 1
                },
                {
                    "sent": "Classifying astronomical objects.",
                    "label": 0
                },
                {
                    "sent": "Is it a star or Galaxy?",
                    "label": 0
                },
                {
                    "sent": "For instance, customer value management all over the place?",
                    "label": 1
                },
                {
                    "sent": "So it's a very widely used kind of data mining sort of problem.",
                    "label": 0
                },
                {
                    "sent": "And as.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You will know a huge number of different sorts of rules have been constructed to tackle this problem.",
                    "label": 0
                },
                {
                    "sent": "Bypass different intellectual communities, some by statisticians done by machine learning.",
                    "label": 0
                },
                {
                    "sent": "People sound like data mining people and so on.",
                    "label": 0
                },
                {
                    "sent": "There's a list of just some of them.",
                    "label": 0
                },
                {
                    "sent": "You can doubtless add others, which I haven't got up there yourselves.",
                    "label": 0
                },
                {
                    "sent": "It goes on and on and on.",
                    "label": 0
                },
                {
                    "sent": "When given such a huge list that prompts the obvious question, well, given a particular problem given my face recognition problem or medical diagnosis problem, or how do I choose which of these methods should I use?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to choose, you need a criterion by which you can compare the methods.",
                    "label": 0
                },
                {
                    "sent": "You need a performance measure.",
                    "label": 1
                },
                {
                    "sent": "These performance measures in fact have various roles they used to estimate the parameters which in some sense is equivalent to choosing between different classification rules of the same sort of model, but with different parameters.",
                    "label": 1
                },
                {
                    "sent": "So one role of these things is to estimate parameters.",
                    "label": 1
                },
                {
                    "sent": "Another is to choose model components.",
                    "label": 1
                },
                {
                    "sent": "Which variables should I include?",
                    "label": 1
                },
                {
                    "sent": "Which transformations of the variables for instance?",
                    "label": 0
                },
                {
                    "sent": "And another one is simply to evaluate models.",
                    "label": 0
                },
                {
                    "sent": "Is this model better than that one does?",
                    "label": 0
                },
                {
                    "sent": "It produces a superior result, and of course not.",
                    "label": 0
                },
                {
                    "sent": "Just is it better?",
                    "label": 0
                },
                {
                    "sent": "But also is good enough for whatever you actually want to do with it, so various roles for these performance criteria, these criteria telling you how good your model is doing.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So performance criteria play a crucial role in data mining.",
                    "label": 1
                },
                {
                    "sent": "They've got to be simple numerical summaries.",
                    "label": 0
                },
                {
                    "sent": "Our aim is to choose primary inspired unconcern today is to choose between different models on the basis of them.",
                    "label": 0
                },
                {
                    "sent": "So I need a simple numerical summary.",
                    "label": 0
                },
                {
                    "sent": "It's too complicated.",
                    "label": 0
                },
                {
                    "sent": "I won't be able to use it to choose.",
                    "label": 0
                },
                {
                    "sent": "I also need to be able to compute these things automatically if I'm looking at millions of different models.",
                    "label": 0
                },
                {
                    "sent": "I can't plot a Roc curve.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming everybody knows what RFC codes are.",
                    "label": 0
                },
                {
                    "sent": "I can't produce a Roc curve for each of these measures and compare them by.",
                    "label": 0
                },
                {
                    "sent": "If I've got 10 million of them might be there forever.",
                    "label": 0
                },
                {
                    "sent": "I need to be able to do it automatically, so there's a sort of criteria that the performance criteria themselves.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The danger, if you don't choose a performance criterion appropriately, the risk of using a poor performance criterion is that you will get a perform model that would get a poor model and as a result your decisions won't be good.",
                    "label": 0
                },
                {
                    "sent": "You'll make mistakes, you'll miss, diagnose sick patients.",
                    "label": 0
                },
                {
                    "sent": "You'll lose money in a banking situation, whatever.",
                    "label": 0
                },
                {
                    "sent": "A very simple and familiar example of this sort of thing is using misclassification rate.",
                    "label": 0
                },
                {
                    "sent": "When you have severely unbalanced classes.",
                    "label": 1
                },
                {
                    "sent": "In fraud detection, normally relatively small proportion of the transactions are fraudulent, so very unbalanced classes for rarity, disease detection of very the disease is rare, so that the classes are unbalanced, and if you use error rate, the obvious thing it says it's classify everybody's healthy.",
                    "label": 0
                },
                {
                    "sent": "In this case in this example.",
                    "label": 0
                },
                {
                    "sent": "So you get a very small error rate and just get all the all the disease people wrong.",
                    "label": 0
                },
                {
                    "sent": "Very, very few of those, so you get a very small error rate, but that's absolutely useless for this problem, so clearly error rate is an inappropriate performance criterion for that problem.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is another example of inappropriate criteria.",
                    "label": 0
                },
                {
                    "sent": "This relates to some work I've been doing on fraud detection.",
                    "label": 0
                },
                {
                    "sent": "We've got true class is legitimate or fraudulent, cross classified by predicted class, legitimately forging our classification rules has produced a predicted class is class, and we've got counts in each of those cells.",
                    "label": 0
                },
                {
                    "sent": "So we've got a objects which really are legitimate, are correctly predicted as legitimate.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "There are various ways we could do this.",
                    "label": 0
                },
                {
                    "sent": "One would be to look at accounts we could look at all of the transactions in an account and monitor all those transactions, and if any of them are turned out to be fraudulent, we can classify the account as fraudulent.",
                    "label": 0
                },
                {
                    "sent": "The trouble with that is that if you monitor account for long enough, well, the longer you monitor an account the the greater the chance that it will become fraud and that someone will break into the account, clone the credit card card or or whatever.",
                    "label": 0
                },
                {
                    "sent": "So using accounts for this means that your counts ABCD in here.",
                    "label": 0
                },
                {
                    "sent": "Depends how long you study the thing for, so that would be an inappropriate criteria.",
                    "label": 0
                },
                {
                    "sent": "Much better to use transactions, individual transactions in this case, so there's a 2 little examples of.",
                    "label": 0
                },
                {
                    "sent": "Where an inappropriate for performance criteria can lead to wrong results.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now there are different types of performance criteria is useful to distinguish three different types.",
                    "label": 1
                },
                {
                    "sent": "One problem based criteria could be problem based criterion model, fit criterion, classification, accuracy criteria.",
                    "label": 0
                },
                {
                    "sent": "I'm really interested in the third one today, but let me.",
                    "label": 0
                },
                {
                    "sent": "Indeed, illustrate the sorts of things I mean by the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other criteria problem based criteria are things like speed of construction of the classification rule.",
                    "label": 1
                },
                {
                    "sent": "Speed of classification and so on.",
                    "label": 0
                },
                {
                    "sent": "There things which are very much context dependent.",
                    "label": 0
                },
                {
                    "sent": "Speed of classification will be important.",
                    "label": 0
                },
                {
                    "sent": "Well in many situations.",
                    "label": 0
                },
                {
                    "sent": "Let me come back to the fraud detection example.",
                    "label": 0
                },
                {
                    "sent": "A classifier which gets things 100% right.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about credit card fraud detection.",
                    "label": 0
                },
                {
                    "sent": "A classifier which gets things 100% right.",
                    "label": 0
                },
                {
                    "sent": "It looks at each transaction and correctly assigns it to the legitimate or fraudulent class would be useless if it took three months to do that.",
                    "label": 0
                },
                {
                    "sent": "You really need to know now at the time of transactions being made so you can stop it.",
                    "label": 0
                },
                {
                    "sent": "So in that case speed of classification would be important and in all of these examples here there are application domains where these particular properties are important.",
                    "label": 0
                },
                {
                    "sent": "So these things themselves are criteria for in some sense how good the rule is, how useful it is for your particular problem in bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "For example, there are a lot of small and large pee problems, and in other areas also.",
                    "label": 0
                },
                {
                    "sent": "So you need a classification which could cope with those sorts of problems quite easily.",
                    "label": 0
                },
                {
                    "sent": "Many problems, especially those involving data collected from human beings, have incomplete data.",
                    "label": 0
                },
                {
                    "sent": "There are often missing values.",
                    "label": 0
                },
                {
                    "sent": "If your classification rule struggles to cope with missing values, then it probably isn't a very good one for whatever that particular problem is.",
                    "label": 0
                },
                {
                    "sent": "So these are problem based criteria.",
                    "label": 0
                },
                {
                    "sent": "They're very much context dependent, so I can't say much about them.",
                    "label": 0
                },
                {
                    "sent": "In general, when we can only say something about them.",
                    "label": 0
                },
                {
                    "sent": "When you focus on a on a particular problem.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An example of this sort of thing, again coming back to the fraud detection example.",
                    "label": 0
                },
                {
                    "sent": "Is timeliness I've already referred to speed and this this speed of detection and classification?",
                    "label": 0
                },
                {
                    "sent": "This illustrates it.",
                    "label": 0
                },
                {
                    "sent": "I've got a string of transactions there labeled N. If they are legitimate.",
                    "label": 0
                },
                {
                    "sent": "If they're non fraudulent, and F if they are fraudulent.",
                    "label": 0
                },
                {
                    "sent": "The colored red.",
                    "label": 0
                },
                {
                    "sent": "The color red when my fraud detector.",
                    "label": 0
                },
                {
                    "sent": "Flags in my classifier.",
                    "label": 0
                },
                {
                    "sent": "Classifieds them as suspicious.",
                    "label": 0
                },
                {
                    "sent": "My classifier says I think this is fraudulent.",
                    "label": 0
                },
                {
                    "sent": "So what you can see is for non fortunate ones, fraud legitimate ones to start with on the left, which the classifier thinks that colored and black.",
                    "label": 0
                },
                {
                    "sent": "So it thinks that adjustment, then a fraudulent one which it is missed.",
                    "label": 0
                },
                {
                    "sent": "It's frozen, it's not colored red, it's missed it.",
                    "label": 0
                },
                {
                    "sent": "Couple of legitimate ones, and then another fraudulent one.",
                    "label": 0
                },
                {
                    "sent": "It's missed.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And then we get to the first red end.",
                    "label": 0
                },
                {
                    "sent": "It's a legitimate transaction, but the fraud detector.",
                    "label": 0
                },
                {
                    "sent": "Race is suspicious about it, so you know the bank manager phones up and said, did you make this transaction and the thing trundles along until it reaches the last one, which is a fraudulent transaction F which is colored red.",
                    "label": 0
                },
                {
                    "sent": "It's the detector has flagged this.",
                    "label": 0
                },
                {
                    "sent": "The classifier is flagged it as suspicious, and so it's correctly identified a fraudulent transaction.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "What we're interested in here is one of the things we're interested in.",
                    "label": 0
                },
                {
                    "sent": "Here is, of course, how many it gets right, how many it gets wrong, but also how many gets wrong, how many of the FCT gets wrong?",
                    "label": 0
                },
                {
                    "sent": "How many of the fraudulent transactions it gets wrong before it correctly identifies a fraudulent transaction and stops the card?",
                    "label": 0
                },
                {
                    "sent": "So an appropriate measure of timeliness.",
                    "label": 0
                },
                {
                    "sent": "For example, there might be the number of black FS in this sequence of transactions that might be inappropriate.",
                    "label": 0
                },
                {
                    "sent": "Appropriate measure of performance.",
                    "label": 0
                },
                {
                    "sent": "Very context dependent.",
                    "label": 0
                },
                {
                    "sent": "So that was my first kind of performance criteria.",
                    "label": 0
                },
                {
                    "sent": "Problem based criteria.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second kind was model fit criteria.",
                    "label": 1
                },
                {
                    "sent": "Model fit criteria are basically accurate measures of accuracy of probability estimates.",
                    "label": 1
                },
                {
                    "sent": "How accurate is the?",
                    "label": 0
                },
                {
                    "sent": "Let's suppose I've just got two classes.",
                    "label": 0
                },
                {
                    "sent": "To make life simple, and in fact most of what I'm going to talk about from now on assumes two classes.",
                    "label": 0
                },
                {
                    "sent": "So a measure of accuracy of probability estimates would be how accurate you think the probability your estimate of the probability belonging to class one for a particular measurement vector is.",
                    "label": 0
                },
                {
                    "sent": "And there are various measures.",
                    "label": 0
                },
                {
                    "sent": "Log likelihood is a measure, Brier score is a measure there.",
                    "label": 0
                },
                {
                    "sent": "It was a common measures.",
                    "label": 0
                },
                {
                    "sent": "There are other measures as well.",
                    "label": 0
                },
                {
                    "sent": "There are measures of how accurate your.",
                    "label": 0
                },
                {
                    "sent": "Estimated probability belong to class one is.",
                    "label": 0
                },
                {
                    "sent": "This is not very well and it is quite widely used.",
                    "label": 0
                },
                {
                    "sent": "The more widely used in certain intellectual communities and others, but they're quite widely used.",
                    "label": 0
                },
                {
                    "sent": "Likely it of course, is very widely used in statistics.",
                    "label": 1
                },
                {
                    "sent": "Thing is, however, the goodness of fit.",
                    "label": 1
                },
                {
                    "sent": "How accurate these probability estimates are isn't the same as accuracy of classification.",
                    "label": 0
                },
                {
                    "sent": "And in fact, a poor fit can mean greater.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's a little example.",
                    "label": 0
                },
                {
                    "sent": "On the horizontal axis, I've got my predictor variables.",
                    "label": 0
                },
                {
                    "sent": "I've only got 1 here X on the vertical axis I've got the estimated probability of belonging to class one with the horizontal line indicating estimated probability of 1/2.",
                    "label": 0
                },
                {
                    "sent": "In the left hand.",
                    "label": 0
                },
                {
                    "sent": "In the left hand graph here, the red line is the true probability of belonging to class one for different values of X.",
                    "label": 0
                },
                {
                    "sent": "And in the left hand graph, I'm going to assume that my.",
                    "label": 0
                },
                {
                    "sent": "Classifier is unbiased so that on average, if I took different designing set different training sets, different design sets, and built my classification rule on average, it would give me an estimated probability of belonging class one which lies absolutely on the true value on the red line.",
                    "label": 0
                },
                {
                    "sent": "But of course it's on average.",
                    "label": 0
                },
                {
                    "sent": "If I took a different training set, I would get different estimates and the distribution about the red line.",
                    "label": 0
                },
                {
                    "sent": "Here the distribution about the red line here indicates that the sort of range of values of the estimate I would get at that value of X if I took different training sets, and you can see that sometimes I would be below what I'm taking as a threshold value of 1/2.",
                    "label": 0
                },
                {
                    "sent": "Sometimes if I based my classifications on this rule despite it being unbiased.",
                    "label": 0
                },
                {
                    "sent": "Despite on average, overall different classification rules, it giving the correct estimated problem belonging to class One at that value of X.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it would produce wrong decisions.",
                    "label": 0
                },
                {
                    "sent": "Some of these things are below half.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at this alternative classifier, which produces an estimated probability of class one which is bias.",
                    "label": 0
                },
                {
                    "sent": "It produces an estimated probability of class one lying on this broken line.",
                    "label": 1
                },
                {
                    "sent": "So it's biased.",
                    "label": 0
                },
                {
                    "sent": "It's not lying on the correct value, the unbroken line.",
                    "label": 0
                },
                {
                    "sent": "Again, we've got variation about that line.",
                    "label": 0
                },
                {
                    "sent": "If I took different training sets, different design sets, I would have variation about that.",
                    "label": 0
                },
                {
                    "sent": "So again, I've got this distribution about this here, but you can see that nowhere or hardly any of the tails of that distribution lie below the threshold of 1/2.",
                    "label": 0
                },
                {
                    "sent": "So this second classifier is biased.",
                    "label": 0
                },
                {
                    "sent": "Its estimate of the probability of belonging to class one is not as accurate as the first classifier, but it's producing fewer misclassifications.",
                    "label": 1
                },
                {
                    "sent": "So estimated probability belonging to Class 1.",
                    "label": 0
                },
                {
                    "sent": "And accurate values of that.",
                    "label": 0
                },
                {
                    "sent": "Is not the same as classification accuracy and you can do better with biased classifications.",
                    "label": 0
                },
                {
                    "sent": "Jerry Friedman produced a very nice paper in 1997 going into the details of this very elegant little paper.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And now I come to in some sense what I really want to talk about today.",
                    "label": 0
                },
                {
                    "sent": "This is a third group of performance measures.",
                    "label": 0
                },
                {
                    "sent": "Classification accuracy criteria.",
                    "label": 0
                },
                {
                    "sent": "So what I've got is a score for each value of X estimated probability belong to class one.",
                    "label": 0
                },
                {
                    "sent": "Or perhaps something else but a score, and what I'm going to do to produce classification, always calculate that score and impose a threshold or threshold T anything belote anything with a score or estimated probability of allowing the Class One belote I'm going to predict his class, not anything above.",
                    "label": 0
                },
                {
                    "sent": "I'm going to predict his Class 1.",
                    "label": 1
                },
                {
                    "sent": "Cannot produce the standard sort of classification table.",
                    "label": 0
                },
                {
                    "sent": "Here I've got across classification of true class by by predicted class.",
                    "label": 1
                },
                {
                    "sent": "I've got a class notes like below T, so a of the true class notes are correctly predicted as belonging class Norton.",
                    "label": 0
                },
                {
                    "sent": "The same for the rest of the little table.",
                    "label": 0
                },
                {
                    "sent": "This is a sort of standard sort of thing, and this is what I want to do.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the next few slides.",
                    "label": 0
                },
                {
                    "sent": "So in the top here I've got the little classification table again.",
                    "label": 0
                },
                {
                    "sent": "And there are various different performance criteria you can produce based on this table, and they're they're immensely widely used.",
                    "label": 0
                },
                {
                    "sent": "If I call if I think of class one, is the cases or the positives or frauds, or the abnormals or whatever.",
                    "label": 0
                },
                {
                    "sent": "In some sense, the thing I'm interested in identifying then various different familiar measures are produced from this.",
                    "label": 0
                },
                {
                    "sent": "So for example, the proportion of class ones which are correctly classified as class 1D over B + D. The medicine is called sensitivity in computer science information retrieval.",
                    "label": 1
                },
                {
                    "sent": "It's called recall, and so on, and analogist thing over here.",
                    "label": 0
                },
                {
                    "sent": "The proportion of class notes which are correctly classified and medicines called specificity and those two examples involve probabilities.",
                    "label": 0
                },
                {
                    "sent": "Given the true class, but one can also calculate probabilities given the predicted class and then you get things like positive predictive value in medicine or precision information return and so on.",
                    "label": 1
                },
                {
                    "sent": "Different ways you can calculate these things.",
                    "label": 1
                },
                {
                    "sent": "Clearly there are going to be relationships between these involving the class priors, the class prize, the proportion in class, not in this report.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "During Class 1.",
                    "label": 0
                },
                {
                    "sent": "So I had four counts in my little table ABC and D. The priors, the proportions in class, Norton class one don't depend on the classification rules, so I can take them as fixed and I can take the total number of things I'm looking at in order to produce the table that doesn't depend on the classification rule so I can take that is fixed.",
                    "label": 0
                },
                {
                    "sent": "So I got 4 numbers ABCD and I've got two constraints on it, so I've got 2 degrees of freedom in here.",
                    "label": 0
                },
                {
                    "sent": "To produce a performance metric, something I can actually use to compare classification rules, I need to reduce those to one so that I can say this has a higher performance value than this.",
                    "label": 0
                },
                {
                    "sent": "So I need to reduce these things to 1 degree of freedom, and that's where that's where all our problems stop.",
                    "label": 0
                },
                {
                    "sent": "How do we combine these into a single performance measure?",
                    "label": 1
                },
                {
                    "sent": "And there are many familiar ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "Error rate is a familiar example error rate basically.",
                    "label": 1
                },
                {
                    "sent": "Wait, sleep sensitivity by the proportion in class one adds it to the specificity.",
                    "label": 0
                },
                {
                    "sent": "By times the proportioning class nought, and that's equivalent to error rate.",
                    "label": 0
                },
                {
                    "sent": "It's the ones that the proportion I get wrong B + C over the total number.",
                    "label": 0
                },
                {
                    "sent": "That's one way of combining or reducing our two degrees of freedom to one.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One might be in some applications one might want to adjust for the fact that you would expect to get some correct by chance, so another simple performance measure adjusts for the proportion you'd expect to get correct by chance.",
                    "label": 0
                },
                {
                    "sent": "Another measure widely used in the information retrieval community combines them in combines these things in a rather more complicated way to produce the F measure.",
                    "label": 0
                },
                {
                    "sent": "And there are many other ways of reducing those four numbers just to one which we can then use as a performance criterion to rank our different classifiers and hint choose between them.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, obviously these different performance criteria aren't monotonically related.",
                    "label": 1
                },
                {
                    "sent": "If this one gives this criterion gives a higher score for this model and that model and other criteria might not give a higher score for this model compared with that model.",
                    "label": 0
                },
                {
                    "sent": "If they did give.",
                    "label": 0
                },
                {
                    "sent": "If they were monotonically related, they'd all be equivalent.",
                    "label": 0
                },
                {
                    "sent": "There wouldn't be any point in using it, so they're not monotonically related.",
                    "label": 0
                },
                {
                    "sent": "But there are relationships between them.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to bore you by going through this.",
                    "label": 0
                },
                {
                    "sent": "The the details of these clearly there you know, we've only got 4 numbers which we are trying to summarize in some way.",
                    "label": 0
                },
                {
                    "sent": "There are relationships.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "All the methods based on that little classification table.",
                    "label": 1
                },
                {
                    "sent": "Model ABCD.",
                    "label": 0
                },
                {
                    "sent": "Assume that I had chosen a threshold threshold such that if my score or my estimated probability or whatever was less than two yard sales class Norton if it is above TI, would say it was class one.",
                    "label": 0
                },
                {
                    "sent": "I had to have that threshold to produce that table.",
                    "label": 0
                },
                {
                    "sent": "And that raises the question of where did that T come from?",
                    "label": 0
                },
                {
                    "sent": "How did you choose that threshold?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to approach this one particular way.",
                    "label": 0
                },
                {
                    "sent": "You don't have to approach it this way and what I'm about to say is going to be fairly controversial, but it's sound I'm not going to be able to go into all the details and happy to talk to people about it in more detail afterwards.",
                    "label": 0
                },
                {
                    "sent": "As a paper appearing about to appear in machine learning, which gives the gives it in more detail.",
                    "label": 0
                },
                {
                    "sent": "So how to choose T?",
                    "label": 1
                },
                {
                    "sent": "Well, to approach it, I'm going to suppose that the cost of misclassifying across I object, like was not a one.",
                    "label": 0
                },
                {
                    "sent": "Here should be CI socin autism cost of misclassifying a class not object.",
                    "label": 1
                },
                {
                    "sent": "In that case, the overall loss due to misclassification is this.",
                    "label": 0
                },
                {
                    "sent": "This is just the proportion of class notes which are above the threshold 1 minus the proportion below times the proportion of objects which belong to class North Times the cost of misclassifying each of those, and then a similar thing for class one.",
                    "label": 0
                },
                {
                    "sent": "So that's the overall loss given that we've chosen a particular threshold.",
                    "label": 0
                },
                {
                    "sent": "The rational thing to do, if you know what the costs.",
                    "label": 0
                },
                {
                    "sent": "See Norton C1R is to choose a threshold which minimizes the total loss.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The threshold which minimizes the loss.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit of calculus really written it down there.",
                    "label": 0
                },
                {
                    "sent": "I'm going to call the threshold, which minimizes the total loss capital T so you give me the cost C Norton C1 and we can then find.",
                    "label": 0
                },
                {
                    "sent": "The minimum of array of this little expression here with the T which minimizes that the threshold which produces minimum loss and then a little bit of calculus.",
                    "label": 1
                },
                {
                    "sent": "You have to do some.",
                    "label": 0
                },
                {
                    "sent": "It's a bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "Things aren't continuous and somebody you know.",
                    "label": 0
                },
                {
                    "sent": "No real problems, little bit of calculus essentially leads to a mapping between the ratio between those two misclassification costs.",
                    "label": 1
                },
                {
                    "sent": "See one overseen ought and the optimal threshold, and this is all.",
                    "label": 0
                },
                {
                    "sent": "This is all perfectly standard stuff.",
                    "label": 0
                },
                {
                    "sent": "None of this is original.",
                    "label": 0
                },
                {
                    "sent": "And of course, given the T then then this is the the given the threshold and cost management loss minimizing threshold.",
                    "label": 0
                },
                {
                    "sent": "Then that's human loss.",
                    "label": 0
                },
                {
                    "sent": "Q Given by that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's fine if you know what C, Norton, C1R.",
                    "label": 0
                },
                {
                    "sent": "But what do you do if you don't know what the costs are going to be in the future?",
                    "label": 1
                },
                {
                    "sent": "Remember the airport facial scanner example.",
                    "label": 1
                },
                {
                    "sent": "They change their minds about where the threshold should be.",
                    "label": 0
                },
                {
                    "sent": "They changed their minds about what they regarded as important relative costs in the future.",
                    "label": 0
                },
                {
                    "sent": "So when you're building these things, you don't necessarily know how it's going to be used in the future.",
                    "label": 1
                },
                {
                    "sent": "So what do we do if we don't know what the costs are going to be?",
                    "label": 0
                },
                {
                    "sent": "Equipment, well, we've got this relationship between tools.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've got this little relationship between the ratio C not and C1 and T.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So not knowing the cost is perfectly equivalent to saying what do I do if the future threshold is unknown?",
                    "label": 1
                },
                {
                    "sent": "The threshold that's going to be used in the future is unknown.",
                    "label": 0
                },
                {
                    "sent": "These two things are equivalent.",
                    "label": 0
                },
                {
                    "sent": "Not knowing the cost ratio, not knowing.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "T. Well, there are two approaches to this.",
                    "label": 0
                },
                {
                    "sent": "The first approach, very widely used is to make default assumptions.",
                    "label": 1
                },
                {
                    "sent": "So, for example, we might assume that C. Norton C1 are equal.",
                    "label": 0
                },
                {
                    "sent": "Standardize the units Towanda.",
                    "label": 0
                },
                {
                    "sent": "We might assume that they are equal.",
                    "label": 0
                },
                {
                    "sent": "If you assume they're equal, it's very easy to see that that leads to misclassification rate.",
                    "label": 1
                },
                {
                    "sent": "That leads to error rate, so that's using error rate is equivalent to making the default assumption that costs are equal, and everybody knows this.",
                    "label": 0
                },
                {
                    "sent": "Another default assumption is to assume that the Cir.",
                    "label": 0
                },
                {
                    "sent": "Let's see, note is equal to the prior of the other class and see one is equal to the prior of the other class.",
                    "label": 0
                },
                {
                    "sent": "And if you do that, you end up with other also widely used measures.",
                    "label": 0
                },
                {
                    "sent": "In particular context, the udon statistic that KS statistic and so on very widely used in credit scoring, for instance.",
                    "label": 0
                },
                {
                    "sent": "So error rate is used by more than 95% of papers evaluating classification rules in the machine learning literature.",
                    "label": 0
                },
                {
                    "sent": "For instance, an AKS statistic is very widely used in, as I say in credit scoring, so different communities use different measures.",
                    "label": 0
                },
                {
                    "sent": "But in this case these are examples of.",
                    "label": 0
                },
                {
                    "sent": "Default assumptions to overcome the fact that we don't actually know what these costs are.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So very well, but default assumptions.",
                    "label": 0
                },
                {
                    "sent": "That's equivalent.",
                    "label": 0
                },
                {
                    "sent": "Picking things to make life easy.",
                    "label": 0
                },
                {
                    "sent": "Picking them for mathematical convenience, we really should choose our costs.",
                    "label": 0
                },
                {
                    "sent": "Our threshold.",
                    "label": 0
                },
                {
                    "sent": "Because of what the problem?",
                    "label": 0
                },
                {
                    "sent": "Because of what we think the relative severities are.",
                    "label": 0
                },
                {
                    "sent": "Remember, if you choose the wrong performance criterion, you could end up with the wrong model.",
                    "label": 0
                },
                {
                    "sent": "And and incorrect conclusions and misdiagnosed patients or whatever.",
                    "label": 0
                },
                {
                    "sent": "So we really ought to choose these costs.",
                    "label": 0
                },
                {
                    "sent": "The ratio between them on the basis of what matters for the problem.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how much?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First strategy.",
                    "label": 0
                },
                {
                    "sent": "Make the.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Old assumptions, but that's not really a very wise thing to do, even though practically everybody, including myself.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Generally done that.",
                    "label": 0
                },
                {
                    "sent": "The second strategy is to average over all possible costs.",
                    "label": 1
                },
                {
                    "sent": "What we could do is say, well, we don't know what the future costs or the ratio C not to see one is actually going to be, but I think it's quite likely to be this less likely to be that and so on.",
                    "label": 0
                },
                {
                    "sent": "If you like, we could put a prior on this concentration.",
                    "label": 0
                },
                {
                    "sent": "The prior ones, the joint distribution of C. Norton C1.",
                    "label": 0
                },
                {
                    "sent": "So that's what I've got here.",
                    "label": 0
                },
                {
                    "sent": "I've got this this bid in red is just the last thing that I had up before.",
                    "label": 0
                },
                {
                    "sent": "A weighted sum of the costs of the two kinds of misclassification weighted by the relative sizes of the classes.",
                    "label": 0
                },
                {
                    "sent": "And I've got some sort of distribution for what I think the likely future costs are likely to be.",
                    "label": 0
                },
                {
                    "sent": "And then I'm just going to integrate over that distribution to those brief sort of average expected loss.",
                    "label": 0
                },
                {
                    "sent": "If you like expected future loss.",
                    "label": 0
                },
                {
                    "sent": "And I've slightly simplified things down here because you you remember from before C. Norton C1 didn't really matter by themselves, it was the ratio of them which was crucial.",
                    "label": 0
                },
                {
                    "sent": "It was the ratio of them which mattered.",
                    "label": 0
                },
                {
                    "sent": "So I basically in essence on basically replacing see Norton C1 by something equivalent to the ratio, which I've called C. So here is my.",
                    "label": 0
                },
                {
                    "sent": "Expected loss.",
                    "label": 0
                },
                {
                    "sent": "Averaged over what I think like C is likely to be in the future.",
                    "label": 0
                },
                {
                    "sent": "If you're not Bayesian and you don't like these sort of subjective distributions.",
                    "label": 0
                },
                {
                    "sent": "Bear with me because you'll see that this sort of thing has implications for the way things are used in practice.",
                    "label": 0
                },
                {
                    "sent": "OK, so average expected loss here.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "The key in all this, of course, is going to be how you choose W. How you choose this distribution for what you think the values of C are likely to be in the future.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, here's a particular, just terribly ugly expression W star now.",
                    "label": 0
                },
                {
                    "sent": "Please don't study the details of that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to come back to the one important feature of it in a moment.",
                    "label": 0
                },
                {
                    "sent": "It's just clearly quite a big, complicated expression.",
                    "label": 0
                },
                {
                    "sent": "It's the particular expression of particular form, but my point about this is that if you choose that particular form than my average expected loss, and I'm sparing you the tedium of the mathematics, the average expected loss can be rewritten to be that and simplifies to that the average expected loss is a simple linear transformation of.",
                    "label": 0
                },
                {
                    "sent": "Is equivalent to the area under the Arosi cap.",
                    "label": 0
                },
                {
                    "sent": "The arosi curve you recall is a plot of F nought proportion proportion of class notes below the threshold.",
                    "label": 0
                },
                {
                    "sent": "On the vertical axis and F1, the proportion of class ones below the threshold as the threshold varies.",
                    "label": 0
                },
                {
                    "sent": "That's the Roc Cup and a very widely used measure in certain intellectual communities of performance is the area under the arosi curve and our OC curve is better than nearer.",
                    "label": 0
                },
                {
                    "sent": "It goes to this top left hand corner if it lies on the diagonal, it's equivalent to chance classification, random assignment to classes.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, it's a good measure.",
                    "label": 0
                },
                {
                    "sent": "The area under the curve, the further it pushes up, the bigger the area becomes, the better the classifier is.",
                    "label": 0
                },
                {
                    "sent": "And as I've just shown, I haven't actually shown.",
                    "label": 0
                },
                {
                    "sent": "I've told you I've waved my hands, but the maths is behind it.",
                    "label": 0
                },
                {
                    "sent": "The area under the curve is equivalent to.",
                    "label": 0
                },
                {
                    "sent": "The misclassification.",
                    "label": 0
                },
                {
                    "sent": "Loss if you use this particular weight function.",
                    "label": 0
                },
                {
                    "sent": "As I say, I hope you looked at the details of.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wait function 'cause it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "OK, this summarizes where I've got to the moment L is equal to this loss, averaged over some distribution W. And if you choose a particular distribution W star, the one which I've written down there, you get L being equivalent to the area under the curve.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So area under the curve is equivalent to averaging the loss over this cost function W star.",
                    "label": 1
                },
                {
                    "sent": "And the crucial thing is that W star that horrible expression that I put up and that I've reproduced here.",
                    "label": 0
                },
                {
                    "sent": "Depends upon F nought and F1.",
                    "label": 1
                },
                {
                    "sent": "It depends on the observed score distributions.",
                    "label": 0
                },
                {
                    "sent": "If not, is the score distribution distribution of estimated probably belong to class one for class nought and F1 is the corresponding scene for Class 1.",
                    "label": 0
                },
                {
                    "sent": "So this distribution W star.",
                    "label": 0
                },
                {
                    "sent": "Depends on the empirical data.",
                    "label": 0
                },
                {
                    "sent": "Your choice about how much weight you should give to different values of C. Depends upon the empirical data.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is kind of crucial because knowledge of C or equivalently have seen on C1 the ratio between them relative costs the relative severity of misclassifications.",
                    "label": 1
                },
                {
                    "sent": "Can't come from the data, it's gotta come from outside.",
                    "label": 0
                },
                {
                    "sent": "It's gotta come from an extra mathematical sort of thing you've got to look at the thing and say if I miss classify this fraud as legitimate relative to the other way round that it's 100 times a serious or whatever.",
                    "label": 0
                },
                {
                    "sent": "You can't look at the data and say Oh well if I got different data it would be different in different degree of severity.",
                    "label": 0
                },
                {
                    "sent": "That would be nonsensical.",
                    "label": 0
                },
                {
                    "sent": "In fact, I'm driving at home here.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what this means is that using the area under the quote, not under the curve under the RSC curve.",
                    "label": 0
                },
                {
                    "sent": "Is equivalent to saying that your belief in the relative severity which will be assigned to different types of misclassifications depends on your choice of classifier.",
                    "label": 1
                },
                {
                    "sent": "It depends on distributions F, Norton F1 and different classifiers will give you different distributions.",
                    "label": 0
                },
                {
                    "sent": "This whole point.",
                    "label": 0
                },
                {
                    "sent": "What this says is that your distribution the.",
                    "label": 0
                },
                {
                    "sent": "Your belief in the relative severity ends which classifier you happen to use.",
                    "label": 0
                },
                {
                    "sent": "That's clearly nonsensical.",
                    "label": 0
                },
                {
                    "sent": "I have a little example here.",
                    "label": 1
                },
                {
                    "sent": "It's like measuring my height in millimeters and yours in feet and saying I'm taller because my number is bigger than yours.",
                    "label": 0
                },
                {
                    "sent": "Is pleading on sensical",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK people say, but area under the curve has several nice interpretations.",
                    "label": 1
                },
                {
                    "sent": "I've used it, you know, for the last 2530 years and.",
                    "label": 0
                },
                {
                    "sent": "Everybody uses it.",
                    "label": 0
                },
                {
                    "sent": "It's got all sorts of nice interpretations.",
                    "label": 0
                },
                {
                    "sent": "Here is 1.",
                    "label": 0
                },
                {
                    "sent": "It's the average value of the vertical axis, assuming if you take a uniform distribution on the horizontal axis on our OC curve, the average value of F nought if F1 is chosen from a uniform distribution.",
                    "label": 1
                },
                {
                    "sent": "So I've written it down here.",
                    "label": 0
                },
                {
                    "sent": "Very nice sort of interpretation.",
                    "label": 0
                },
                {
                    "sent": "We assume that any value of F1 is equally likely a uniform distribution for F1, and then we average the corresponding values of F Nord.",
                    "label": 0
                },
                {
                    "sent": "A very nice sort of interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The trouble is that F nought and F1 are what you might call operating characteristics of the curve.",
                    "label": 0
                },
                {
                    "sent": "Indeed, it's the receiver operating characteristic curve.",
                    "label": 0
                },
                {
                    "sent": "It's not my work and operating characteristics is you can choose them.",
                    "label": 0
                },
                {
                    "sent": "You can choose one of them and that tells you the shape of the curve, so I can choose F1 or I could choose F, not one or the other according to what sort of behavior I wanted from my classifier.",
                    "label": 1
                },
                {
                    "sent": "And of course, it's entirely possible I might choose a different value for different rules, so I've got a little example here.",
                    "label": 1
                },
                {
                    "sent": "Rule one might be logistic regression, Rule 2 might be a random forest or something like that.",
                    "label": 0
                },
                {
                    "sent": "So on the left here I've got rule one which gets 95% of Class 1 correct, 95% or above the threshold and it gets 89% of class not correct.",
                    "label": 0
                },
                {
                    "sent": "If I adjust my threshold to increase F North there, I've increased it to F nought.",
                    "label": 0
                },
                {
                    "sent": "I will reduce this particular rule.",
                    "label": 0
                },
                {
                    "sent": "This logistic regression or whatever it was reduce my proportion of F1 which I'm getting correct, 80% reduction that improvement from 89 to 90 is tiny.",
                    "label": 0
                },
                {
                    "sent": "The reduction from 95 to 80 is quite substantial, so I might prefer with rule one.",
                    "label": 0
                },
                {
                    "sent": "I might prefer to use threshold T, which gives me 95% across one right and 89% of class.",
                    "label": 0
                },
                {
                    "sent": "Not right?",
                    "label": 0
                },
                {
                    "sent": "What about rule two?",
                    "label": 0
                },
                {
                    "sent": "Rule two?",
                    "label": 0
                },
                {
                    "sent": "Well, if I choose the threshold to give me 95% of Class 1 right happens.",
                    "label": 0
                },
                {
                    "sent": "This random forest happens to give me 10% of class, not right?",
                    "label": 0
                },
                {
                    "sent": "What if I change the threshold to teen or to reduce this to 80% to make it compatible with the other one?",
                    "label": 0
                },
                {
                    "sent": "Then my proportion of class more correct leaps to 80.",
                    "label": 0
                },
                {
                    "sent": "So in that case I might well prefer to use T star tick tick T dashed.",
                    "label": 0
                },
                {
                    "sent": "This threshold with rule tool with two months giving me 80% of Class 1 right and 90% of.",
                    "label": 0
                },
                {
                    "sent": "Class.",
                    "label": 0
                },
                {
                    "sent": "Not right so?",
                    "label": 0
                },
                {
                    "sent": "I can choose.",
                    "label": 0
                },
                {
                    "sent": "I might well choose a different F1, a different proportion of class one correctly classified according to which rule I'm using.",
                    "label": 0
                },
                {
                    "sent": "Different rules might lead me to different proportions.",
                    "label": 0
                },
                {
                    "sent": "The point is that there's nothing fundamental about the proportion F1 of class one.",
                    "label": 0
                },
                {
                    "sent": "I choose to correctly classify or of fnord.",
                    "label": 0
                },
                {
                    "sent": "It's it's my choice.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the distribution of the relative costs comes from the problem.",
                    "label": 0
                },
                {
                    "sent": "It's what you think the relative relative severity of the two different kinds of misclassification, or it's not something you can choose.",
                    "label": 0
                },
                {
                    "sent": "It's a matter of what you believe about what's going on.",
                    "label": 0
                },
                {
                    "sent": "What this means, of course, is that.",
                    "label": 0
                },
                {
                    "sent": "This distribution WC what you think the distribution, relative severities is likely to be, can't vary from classified a classifier.",
                    "label": 0
                },
                {
                    "sent": "It's a fundamental fundamental aspect of the problem is not like choosing the proportion of class ones I get right in my little example on the previous slide, this is fundamental.",
                    "label": 0
                },
                {
                    "sent": "It doesn't vary from classifier classifier.",
                    "label": 0
                },
                {
                    "sent": "So the colored example.",
                    "label": 0
                },
                {
                    "sent": "I can't say if I use logistic regression then misclassifying a cancer sufferer is as healthy as 10 times as serious as the reverse.",
                    "label": 1
                },
                {
                    "sent": "But if I use a tree classifier, then it's 100 times it's serious, that's ridiculous.",
                    "label": 1
                },
                {
                    "sent": "See is a property of the problem, not the classifier.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, I haven't gone through the mass, but there's a relationship between this.",
                    "label": 0
                },
                {
                    "sent": "See this cost ratio and sensitivity.",
                    "label": 0
                },
                {
                    "sent": "The proportion of class when I get right.",
                    "label": 0
                },
                {
                    "sent": "We've seen the relationship between the ratio.",
                    "label": 0
                },
                {
                    "sent": "See Norton C1 and Capital T, and of course choosing Capital T determines the proportion of class one I get right?",
                    "label": 0
                },
                {
                    "sent": "So that gives us a relationship between the ratio of C. Norton C1 and the sensitivity.",
                    "label": 0
                },
                {
                    "sent": "And of course, that relationship, as we've seen, depends on the empirical distribution that depends on the score distributions.",
                    "label": 0
                },
                {
                    "sent": "The F, North and F1 distributions.",
                    "label": 0
                },
                {
                    "sent": "There's a relationship, so these things are linked together.",
                    "label": 0
                },
                {
                    "sent": "You do something with one, it changes what's happening to the other.",
                    "label": 0
                },
                {
                    "sent": "OK, now I could choose my distribution over which I average my distribution over F1, which I used to average F not remember the area under the curve.",
                    "label": 0
                },
                {
                    "sent": "It said what's the average value of F nought?",
                    "label": 0
                },
                {
                    "sent": "If I assume a uniform distribution for F1?",
                    "label": 0
                },
                {
                    "sent": "So in the area under the curve, I've chosen a particular distribution for F1.",
                    "label": 0
                },
                {
                    "sent": "I could choose others to shift the weight elsewhere, partially area under the curve is an example of that sort of thing.",
                    "label": 0
                },
                {
                    "sent": "So that's what five in hit.",
                    "label": 0
                },
                {
                    "sent": "That's what five represents.",
                    "label": 0
                },
                {
                    "sent": "It's whatever distribution I've chosen for averaging over F1 uniform in the case of the area under the curve.",
                    "label": 0
                },
                {
                    "sent": "And W is my choice of distribution for this cost ratio seen over C1.",
                    "label": 1
                },
                {
                    "sent": "So I've got these two distributions and they are tide together because of the relationship between the costs and F1.",
                    "label": 0
                },
                {
                    "sent": "What this means is you can't simultaneously choose a file distribution and a W distribution.",
                    "label": 0
                },
                {
                    "sent": "In dependently empirical distributions you tell me you want distribution you want for five and because of this relationship you end up with a W distribution which depends on F, not F1.",
                    "label": 0
                },
                {
                    "sent": "It depends on the empirical score distributions and the other way round you tell me what distribution you want to use for W and because of the relationship it means that your file distribution will depend on if not on F1 you can't.",
                    "label": 1
                },
                {
                    "sent": "You can't simultaneously choose.",
                    "label": 1
                },
                {
                    "sent": "Both these distributions, independently of the empirical distributions.",
                    "label": 0
                },
                {
                    "sent": "What it means is that.",
                    "label": 0
                },
                {
                    "sent": "If you choose one distribution, I want a uniform distribution or whatever the other distribution depends on the empirical on what classifier you're using.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Which should we use?",
                    "label": 0
                },
                {
                    "sent": "Should we should we fix fi independent of the classifier or should we fix W?",
                    "label": 0
                },
                {
                    "sent": "Well, we've already seen that.",
                    "label": 0
                },
                {
                    "sent": "Find the distribution over X the distribution over F1.",
                    "label": 0
                },
                {
                    "sent": "Is a matter of choice.",
                    "label": 1
                },
                {
                    "sent": "I could choose a uniform distribution as the area under the curve that I could choose.",
                    "label": 0
                },
                {
                    "sent": "Sort of step function for a partial area under could choose what I like.",
                    "label": 0
                },
                {
                    "sent": "We saw in my little table comparing different classifiers with different threshold values.",
                    "label": 0
                },
                {
                    "sent": "It's a matter of choice.",
                    "label": 0
                },
                {
                    "sent": "I can choose different values for different classifiers, But see this cost ratio is not something I can choose.",
                    "label": 1
                },
                {
                    "sent": "It is a fundamental fundamental property of the problem.",
                    "label": 0
                },
                {
                    "sent": "I don't know what it is I'm going to have to come up with some distribution for what I think it is, but it can't vary from classified a classifier.",
                    "label": 0
                },
                {
                    "sent": "The area under the curve, however.",
                    "label": 0
                },
                {
                    "sent": "As I've basically said, fixes fight to be the uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "What that means is that the area under the curve implies that your W distribution varies from classifier classifier.",
                    "label": 0
                },
                {
                    "sent": "You use a random forest classifier.",
                    "label": 0
                },
                {
                    "sent": "You are saying I believe the cost distribution is like this.",
                    "label": 0
                },
                {
                    "sent": "If I use a logistic regression, I believe it's like that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it's OK for different researchers to choose to have different beliefs about the relative costs your your your distribution of relative cost values may vary be very different from yours.",
                    "label": 1
                },
                {
                    "sent": "That's OK, you know.",
                    "label": 0
                },
                {
                    "sent": "I think this is much more likely to be this kind of misclassification is is much more serious than that kind.",
                    "label": 0
                },
                {
                    "sent": "You might not think it's so, so that's fine, and they may be interested in different aspects of the problem, so that's fine.",
                    "label": 1
                },
                {
                    "sent": "But it's wrong for a single researcher for me.",
                    "label": 1
                },
                {
                    "sent": "For example to choose different contribution distributions for different classifiers.",
                    "label": 0
                },
                {
                    "sent": "Cost distribution has to come out of the problem.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the way to get round this, which I'm not going to have time to talk about today, is to choose a W distribution which is the same full classifiers, which necessarily means that the weighting distribution over F1 is going to vary from classified classified.",
                    "label": 0
                },
                {
                    "sent": "But you can't have it both ways and the cost distribution is fundamental.",
                    "label": 0
                },
                {
                    "sent": "So there are basically two ways to do this.",
                    "label": 0
                },
                {
                    "sent": "The first approach is to choose W to reflect your personal beliefs in the likely cost distribution, cost ratio distribution, and the other way is to choose a universal standard.",
                    "label": 1
                },
                {
                    "sent": "I think in real problems you should report both of these so that in the first case you can say, well, I think this is what's important and we bought that.",
                    "label": 0
                },
                {
                    "sent": "And in the second case you can, anybody would produce the same result and paper in machine learning goes into details of this, but I think in real problems you should report both.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's summarize.",
                    "label": 0
                },
                {
                    "sent": "As far as supervised classification is concerned, different application domains tend to favor different performance measures, so medicine looks at sensitivity, specificity, machine learning, looks error and so on and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The conclusions from this are.",
                    "label": 0
                },
                {
                    "sent": "Don't use measure measures of model fit if classifications, then remember my little example about biased classifier, poor estimated probability belonging to class one, giving you better classification results, greater proportion correct or whatever.",
                    "label": 0
                },
                {
                    "sent": "2nd.",
                    "label": 0
                },
                {
                    "sent": "Clearly this is the context dependent stuff.",
                    "label": 0
                },
                {
                    "sent": "Choose a measure which best matches your objectives.",
                    "label": 1
                },
                {
                    "sent": "And of course you don't have to just choose one measure.",
                    "label": 0
                },
                {
                    "sent": "You might look at classification accuracy and speed and so.",
                    "label": 1
                },
                {
                    "sent": "And that's asserting take special aspects of the problem into account.",
                    "label": 0
                },
                {
                    "sent": "And then at the bottom in red don't use the area under the RO seeker because at its core it has this fundamental incoherence.",
                    "label": 0
                },
                {
                    "sent": "It means that if you're using different classifiers, then you believe that the relative severities of the different kinds of misclassification are different.",
                    "label": 0
                },
                {
                    "sent": "Remember my example about measuring my height in millimeters and yours in feet.",
                    "label": 0
                },
                {
                    "sent": "It is in fact nonsensical.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In general, of course, at a high level, choosing an inappropriate measure can mean the title of the talk, mismatched models, wrong results, and dreadful decisions.",
                    "label": 1
                },
                {
                    "sent": "You classify the cancer sufferer as healthy.",
                    "label": 0
                },
                {
                    "sent": "That's happened.",
                    "label": 0
                },
                {
                    "sent": "I have other examples of this sort of thing, and as a consequence they suffer.",
                    "label": 1
                },
                {
                    "sent": "I've used supervised classification as an example because it's an area I know about, but the same.",
                    "label": 0
                },
                {
                    "sent": "The same applies much more generally in all modeling and in your data mining exercises.",
                    "label": 0
                },
                {
                    "sent": "Choice of the performance measure.",
                    "label": 0
                },
                {
                    "sent": "Is crucial.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}