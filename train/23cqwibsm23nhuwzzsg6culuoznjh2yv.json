{
    "id": "23cqwibsm23nhuwzzsg6culuoznjh2yv",
    "title": "Preserving Metadata from Parliamentary Debates",
    "info": {
        "author": [
            "Alina Karakanta, Department of Language Science and Technology, Saarland University"
        ],
        "published": "May 30, 2018",
        "recorded": "May 2018",
        "category": [
            "Top->Computers->Digital Media",
            "Top->Humanities->Languages",
            "Top->Social Sciences->Society"
        ]
    },
    "url": "http://videolectures.net/parlaCLARIN2018_karakanta_parliamentary_debates/",
    "segmentation": [
        [
            "Hello for me I'm"
        ],
        [
            "Merlin Mccarrick and I'm working together with Michaela, Bella Natchitoches at the University of Saarland and I'm going to present today a corpus we created in the scope of our project on modeling human translation.",
            "In this corpus is called Europarl UDS, University of Saarland and also I'm going to describe the pipeline we used to compile this corpus and how it can be used to help.",
            "Also other linguistic applications."
        ],
        [
            "So first I'm going to speak a bit about our corpus and how it is different from other corpora made from European Parliament proceedings.",
            "I'm going to describe how exactly we built it, its structure, some statistics, and then how it can be used in different application."
        ],
        [
            "Oceans.",
            "So once we have seen noted in this workshop, but umentary corpora a high resource for many linguistic applications, the problem is that most of the times they cannot be used directly in the format that they are given by the Parliament.",
            "So we need to find ways to structure, organize and filter this data.",
            "In our case, we're likely because we don't have that scan to PDF's or that text or OCR.",
            "But we still need to be able to filter this data to serve our purposes.",
            "Since we are speaking about European Parliament, debates will also mention here some other projects that have been trying to structure correct and represent the date of the European Parliament.",
            "For example, like the last one as linked data."
        ],
        [
            "So how can this corpora be used in different applications?",
            "First of all, we have machine translation for machine translation.",
            "We need very good quality and aligned parallel data.",
            "Another other phase that can benefit from very well structured data is for example social Sciences or political science is 1.",
            "Example is gender identification where if we have information about the speaker we can also see how different features evolve from gender between genders.",
            "In political Sciences we have topic detection or we can see how different topics evolve based on the national order.",
            "the European part is that the members belong to last but not the least, we come to our field of work which is translation studies.",
            "Here we want to observe the features of translated text lists are also called translation is and for this purpose we cannot use.",
            "The parallel corpora but are used in machine translation and why?",
            "Because this corpora doesn't have information about the weather, the taxes or regional or translation.",
            "So if we have English into German, we have original and translations English in original translation German we cannot distinguish.",
            "One project by Rabinovich and others have tried to classify this text, and they have provided a useful resource.",
            "However, another thing that there is another factor that is important for translation studies is also the status of the speaker.",
            "So whether it is a native speaker or a non native speaker, we already know that text produced by non native speakers of the language are not clear texts clean because they also carry traits of the first language of the speaker.",
            "So in this case we really need to be able to identify whether the text was produced by Native speaker or not, and we saw and others have made a project on this topic.",
            "However what they created was only a more lingual corpus of English texts.",
            "This contains native, non native and translated.",
            "Next, but it was not enough for our purposes."
        ],
        [
            "So for this I come to our corpus.",
            "What it contains.",
            "It contains parallel corpora, where the source language sentences come from native speakers of the language and they are aligned to translations in the target language.",
            "So for example, we have on the source side English text by native English speakers and their translations into German or Spanish.",
            "Secondly, we have comparably monolingual corpora of the target languages, so only text made by native German speakers or Spanish speakers and the 3rd and most important for me is the pipeline.",
            "To create such corpus.",
            "So we make available all the code and it can be clearly used for by others for their own purposes.",
            "Currently we have 3 supported languages, English, German, and Spanish, but.",
            "These can be very easily adapted to other languages only by translating the roles of the members of the Parliament.",
            "Like President, it's something like 30 words, which can be very easily done."
        ],
        [
            "So now I'm going to talk about how we created this corpus.",
            "This is more or less the pipeline we used.",
            "The method we used to collect and filter, so I'm going."
        ],
        [
            "Start step by step first we have to download the automatically the proceedings from the website of the European Parliament.",
            "Here we can specify the specific date range.",
            "For example, we want only tax from 2013 or we want all the texts, which is what we did for our corpus.",
            "Then another thing we download from the same website is number 2 is the data of the members of the Parliament.",
            "This is in HTML format, which we later extract it into a CSV file and of course with the proceedings we download it in HTML with automatically converted in XML format."
        ],
        [
            "Now what data are already in the proceedings and what data we need to add specifically to extend the data.",
            "The proceedings have a specific structure which is starts from text, which is the whole session.",
            "It goes down to sections which are specific agenda items, then interventions when specific speakers, pics and then we have paragraphs and annotations which contain the actual text.",
            "So here we have.",
            "We preserve information about the date of the session, the language of the session.",
            "Later we have the speaker ID, which is very important to identify the speaker.",
            "If it is a member of the Parliament or not, the mode the mode is also something very important because we know that some speeches are written to be spoken or just written and this can also help us clean the data if we want to see.",
            "Traits of spoken discourse or written discourse.",
            "And other things like the function of the speaker and the actual text."
        ],
        [
            "Now the information about the members of the Parliament.",
            "Here we have very important information.",
            "Is the nationality of the members of the Parliament.",
            "Because this is actually what offers the possibility to distinguish whether this is a native speaker or not.",
            "For example, for English native speakers we have Members of Parliament who are born in the UK, Ireland or Malta.",
            "We have other data like Birthplace and deathplace not so important and then we have the national parties and the political parties and this can be useful for political scientists."
        ],
        [
            "Now the next step is to filter out the text of the proceedings that is not in the expected language, because sometimes we have the text of the proceedings, but it's not all translated and it might be that in an English tax withheld, will Guardian or Romanian segments which we have to take out.",
            "So this we do automatically and then we have the clean XML data.",
            "To this we add the metadata from the members of the Parliament.",
            "Then depending on the task we want, we might need to access boundaries, which means to split the paragraphs into one sentence per line.",
            "If we do machine translation for example, this is the format that is unnecessary.",
            "And then depending also on the task, we can annotate for tokens SLT, our parts of speech."
        ],
        [
            "And then at the end we come to the translation is features.",
            "Let's say to criteria that are important for translation studies.",
            "Here we separate the originals from the translations and we also filter by native speakers.",
            "So from each language text we create 3 sub corpora, which is Originals translations, an origonal Spain native speakers.",
            "Then if we want to build the comparably and the parallel corpora, we extract the text from the XML in reformer and then we automatically align in order to create parallel corpus."
        ],
        [
            "Here are some details about the process, what tools we used, what is specifically important is the automatic alignment.",
            "You might say that maybe we don't have very good quality.",
            "However, here we aligned per intervention, which is a small tax unit.",
            "And this means that we have a very high quality in the alignment, so this is a very accurate corpus."
        ],
        [
            "This is the structure of the corpus.",
            "We have a different directory, different folder for every processing step.",
            "For now we have made available the last two directories comparably in the parallel corpora website, but we will soon make available also the meta data versions."
        ],
        [
            "Here there are some statistics of the core program.",
            "We can see that if we get if we have all the data, we have a very large data set.",
            "However, since we want as clean as possible data set, we have to reduce allowed learn.",
            "The size, which means that we get around 3 million words, but still this is significant if we want to do studies and we can also see some insights of the language using the European Parliament.",
            "If you see the compatible with corporate, the last line shows actually how many, how much taxes produced by English native speakers and compared to German and Spanish and we see that English is much more used."
        ],
        [
            "Now for the last part, I'm going to speak a bit about the possible applications.",
            "This corpus can be used in machine translation, where we have seen that careful data selection can actually improve performance.",
            "Instead of using the data available, then it allows us to see the translation is features that I was speaking about before.",
            "For example, how much more frequent are some words or structures in translated text versus original text?",
            "And the last part is actually our project that we're working on, which is modeling human translation choice.",
            "And in this we try to approximate the probability Fidelity to source language and the conformity to the target language."
        ],
        [
            "The corpus can be available via the public arena infrastructure.",
            "It is the Creative common license and we also have the code.",
            "We welcome any feedback and thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello for me I'm",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Merlin Mccarrick and I'm working together with Michaela, Bella Natchitoches at the University of Saarland and I'm going to present today a corpus we created in the scope of our project on modeling human translation.",
                    "label": 0
                },
                {
                    "sent": "In this corpus is called Europarl UDS, University of Saarland and also I'm going to describe the pipeline we used to compile this corpus and how it can be used to help.",
                    "label": 0
                },
                {
                    "sent": "Also other linguistic applications.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first I'm going to speak a bit about our corpus and how it is different from other corpora made from European Parliament proceedings.",
                    "label": 0
                },
                {
                    "sent": "I'm going to describe how exactly we built it, its structure, some statistics, and then how it can be used in different application.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oceans.",
                    "label": 0
                },
                {
                    "sent": "So once we have seen noted in this workshop, but umentary corpora a high resource for many linguistic applications, the problem is that most of the times they cannot be used directly in the format that they are given by the Parliament.",
                    "label": 0
                },
                {
                    "sent": "So we need to find ways to structure, organize and filter this data.",
                    "label": 0
                },
                {
                    "sent": "In our case, we're likely because we don't have that scan to PDF's or that text or OCR.",
                    "label": 0
                },
                {
                    "sent": "But we still need to be able to filter this data to serve our purposes.",
                    "label": 0
                },
                {
                    "sent": "Since we are speaking about European Parliament, debates will also mention here some other projects that have been trying to structure correct and represent the date of the European Parliament.",
                    "label": 1
                },
                {
                    "sent": "For example, like the last one as linked data.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can this corpora be used in different applications?",
                    "label": 0
                },
                {
                    "sent": "First of all, we have machine translation for machine translation.",
                    "label": 1
                },
                {
                    "sent": "We need very good quality and aligned parallel data.",
                    "label": 0
                },
                {
                    "sent": "Another other phase that can benefit from very well structured data is for example social Sciences or political science is 1.",
                    "label": 1
                },
                {
                    "sent": "Example is gender identification where if we have information about the speaker we can also see how different features evolve from gender between genders.",
                    "label": 1
                },
                {
                    "sent": "In political Sciences we have topic detection or we can see how different topics evolve based on the national order.",
                    "label": 0
                },
                {
                    "sent": "the European part is that the members belong to last but not the least, we come to our field of work which is translation studies.",
                    "label": 0
                },
                {
                    "sent": "Here we want to observe the features of translated text lists are also called translation is and for this purpose we cannot use.",
                    "label": 0
                },
                {
                    "sent": "The parallel corpora but are used in machine translation and why?",
                    "label": 0
                },
                {
                    "sent": "Because this corpora doesn't have information about the weather, the taxes or regional or translation.",
                    "label": 0
                },
                {
                    "sent": "So if we have English into German, we have original and translations English in original translation German we cannot distinguish.",
                    "label": 1
                },
                {
                    "sent": "One project by Rabinovich and others have tried to classify this text, and they have provided a useful resource.",
                    "label": 0
                },
                {
                    "sent": "However, another thing that there is another factor that is important for translation studies is also the status of the speaker.",
                    "label": 0
                },
                {
                    "sent": "So whether it is a native speaker or a non native speaker, we already know that text produced by non native speakers of the language are not clear texts clean because they also carry traits of the first language of the speaker.",
                    "label": 0
                },
                {
                    "sent": "So in this case we really need to be able to identify whether the text was produced by Native speaker or not, and we saw and others have made a project on this topic.",
                    "label": 0
                },
                {
                    "sent": "However what they created was only a more lingual corpus of English texts.",
                    "label": 0
                },
                {
                    "sent": "This contains native, non native and translated.",
                    "label": 0
                },
                {
                    "sent": "Next, but it was not enough for our purposes.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for this I come to our corpus.",
                    "label": 0
                },
                {
                    "sent": "What it contains.",
                    "label": 0
                },
                {
                    "sent": "It contains parallel corpora, where the source language sentences come from native speakers of the language and they are aligned to translations in the target language.",
                    "label": 1
                },
                {
                    "sent": "So for example, we have on the source side English text by native English speakers and their translations into German or Spanish.",
                    "label": 0
                },
                {
                    "sent": "Secondly, we have comparably monolingual corpora of the target languages, so only text made by native German speakers or Spanish speakers and the 3rd and most important for me is the pipeline.",
                    "label": 0
                },
                {
                    "sent": "To create such corpus.",
                    "label": 0
                },
                {
                    "sent": "So we make available all the code and it can be clearly used for by others for their own purposes.",
                    "label": 0
                },
                {
                    "sent": "Currently we have 3 supported languages, English, German, and Spanish, but.",
                    "label": 0
                },
                {
                    "sent": "These can be very easily adapted to other languages only by translating the roles of the members of the Parliament.",
                    "label": 0
                },
                {
                    "sent": "Like President, it's something like 30 words, which can be very easily done.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm going to talk about how we created this corpus.",
                    "label": 0
                },
                {
                    "sent": "This is more or less the pipeline we used.",
                    "label": 0
                },
                {
                    "sent": "The method we used to collect and filter, so I'm going.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Start step by step first we have to download the automatically the proceedings from the website of the European Parliament.",
                    "label": 0
                },
                {
                    "sent": "Here we can specify the specific date range.",
                    "label": 0
                },
                {
                    "sent": "For example, we want only tax from 2013 or we want all the texts, which is what we did for our corpus.",
                    "label": 0
                },
                {
                    "sent": "Then another thing we download from the same website is number 2 is the data of the members of the Parliament.",
                    "label": 0
                },
                {
                    "sent": "This is in HTML format, which we later extract it into a CSV file and of course with the proceedings we download it in HTML with automatically converted in XML format.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what data are already in the proceedings and what data we need to add specifically to extend the data.",
                    "label": 0
                },
                {
                    "sent": "The proceedings have a specific structure which is starts from text, which is the whole session.",
                    "label": 0
                },
                {
                    "sent": "It goes down to sections which are specific agenda items, then interventions when specific speakers, pics and then we have paragraphs and annotations which contain the actual text.",
                    "label": 0
                },
                {
                    "sent": "So here we have.",
                    "label": 0
                },
                {
                    "sent": "We preserve information about the date of the session, the language of the session.",
                    "label": 1
                },
                {
                    "sent": "Later we have the speaker ID, which is very important to identify the speaker.",
                    "label": 0
                },
                {
                    "sent": "If it is a member of the Parliament or not, the mode the mode is also something very important because we know that some speeches are written to be spoken or just written and this can also help us clean the data if we want to see.",
                    "label": 1
                },
                {
                    "sent": "Traits of spoken discourse or written discourse.",
                    "label": 0
                },
                {
                    "sent": "And other things like the function of the speaker and the actual text.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the information about the members of the Parliament.",
                    "label": 0
                },
                {
                    "sent": "Here we have very important information.",
                    "label": 0
                },
                {
                    "sent": "Is the nationality of the members of the Parliament.",
                    "label": 1
                },
                {
                    "sent": "Because this is actually what offers the possibility to distinguish whether this is a native speaker or not.",
                    "label": 1
                },
                {
                    "sent": "For example, for English native speakers we have Members of Parliament who are born in the UK, Ireland or Malta.",
                    "label": 1
                },
                {
                    "sent": "We have other data like Birthplace and deathplace not so important and then we have the national parties and the political parties and this can be useful for political scientists.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the next step is to filter out the text of the proceedings that is not in the expected language, because sometimes we have the text of the proceedings, but it's not all translated and it might be that in an English tax withheld, will Guardian or Romanian segments which we have to take out.",
                    "label": 1
                },
                {
                    "sent": "So this we do automatically and then we have the clean XML data.",
                    "label": 0
                },
                {
                    "sent": "To this we add the metadata from the members of the Parliament.",
                    "label": 0
                },
                {
                    "sent": "Then depending on the task we want, we might need to access boundaries, which means to split the paragraphs into one sentence per line.",
                    "label": 0
                },
                {
                    "sent": "If we do machine translation for example, this is the format that is unnecessary.",
                    "label": 0
                },
                {
                    "sent": "And then depending also on the task, we can annotate for tokens SLT, our parts of speech.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then at the end we come to the translation is features.",
                    "label": 0
                },
                {
                    "sent": "Let's say to criteria that are important for translation studies.",
                    "label": 0
                },
                {
                    "sent": "Here we separate the originals from the translations and we also filter by native speakers.",
                    "label": 1
                },
                {
                    "sent": "So from each language text we create 3 sub corpora, which is Originals translations, an origonal Spain native speakers.",
                    "label": 0
                },
                {
                    "sent": "Then if we want to build the comparably and the parallel corpora, we extract the text from the XML in reformer and then we automatically align in order to create parallel corpus.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some details about the process, what tools we used, what is specifically important is the automatic alignment.",
                    "label": 0
                },
                {
                    "sent": "You might say that maybe we don't have very good quality.",
                    "label": 0
                },
                {
                    "sent": "However, here we aligned per intervention, which is a small tax unit.",
                    "label": 1
                },
                {
                    "sent": "And this means that we have a very high quality in the alignment, so this is a very accurate corpus.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the structure of the corpus.",
                    "label": 0
                },
                {
                    "sent": "We have a different directory, different folder for every processing step.",
                    "label": 0
                },
                {
                    "sent": "For now we have made available the last two directories comparably in the parallel corpora website, but we will soon make available also the meta data versions.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here there are some statistics of the core program.",
                    "label": 0
                },
                {
                    "sent": "We can see that if we get if we have all the data, we have a very large data set.",
                    "label": 0
                },
                {
                    "sent": "However, since we want as clean as possible data set, we have to reduce allowed learn.",
                    "label": 0
                },
                {
                    "sent": "The size, which means that we get around 3 million words, but still this is significant if we want to do studies and we can also see some insights of the language using the European Parliament.",
                    "label": 0
                },
                {
                    "sent": "If you see the compatible with corporate, the last line shows actually how many, how much taxes produced by English native speakers and compared to German and Spanish and we see that English is much more used.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now for the last part, I'm going to speak a bit about the possible applications.",
                    "label": 1
                },
                {
                    "sent": "This corpus can be used in machine translation, where we have seen that careful data selection can actually improve performance.",
                    "label": 1
                },
                {
                    "sent": "Instead of using the data available, then it allows us to see the translation is features that I was speaking about before.",
                    "label": 0
                },
                {
                    "sent": "For example, how much more frequent are some words or structures in translated text versus original text?",
                    "label": 0
                },
                {
                    "sent": "And the last part is actually our project that we're working on, which is modeling human translation choice.",
                    "label": 1
                },
                {
                    "sent": "And in this we try to approximate the probability Fidelity to source language and the conformity to the target language.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The corpus can be available via the public arena infrastructure.",
                    "label": 1
                },
                {
                    "sent": "It is the Creative common license and we also have the code.",
                    "label": 0
                },
                {
                    "sent": "We welcome any feedback and thank you very much.",
                    "label": 1
                }
            ]
        }
    }
}