{
    "id": "pjg5wy7tek3olrfluxohm7wpvpob4q7t",
    "title": "SVD and Higher Order Correlations for Distributed Data",
    "info": {
        "author": [
            "Ravindran Kannan, Microsoft Research India"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2014_kannan_distributed_data/",
    "segmentation": [
        [
            "The biggest result of this talk is the way the slides are made, because for two days I was sitting in the back and I couldn't read the slides.",
            "Hopefully you will tell me what it is that's different and that."
        ],
        [
            "I can read them, I hope so, but we'll see simple tray.",
            "OK, so.",
            "Here is I got 2 problems in this top.",
            "I'll talk about the first one most of the time it is you have an input matrix A which is distributed among various servers F servers and I want to do singular value decomposition or low rank approximation on it.",
            "But I want to introduce the model with one example.",
            "I don't want to tell you host of examples to say speed is important.",
            "Perhaps all if you believe that.",
            "But here's one example that illustrates why.",
            "I'm assuming what the model is.",
            "So if the customer product matrix.",
            "A bunch of customers.",
            "There are as shops.",
            "They of Shakti records all the things that every customer bought in that shop.",
            "That's all the bag of products, right?",
            "And that called the matrix that the server T has customer product matrix a super T and then our entire matrix is the sum of all these matrices.",
            "Every entry sound.",
            "Now this is different from the model in which you assume that each customer shops only in one place, one shop.",
            "In that case, every customer the entire row would be in one place.",
            "We don't assume that the entire rows are in one place, we assume just a matrix is sound.",
            "OK, so more general model then assuming a row partition for this reason.",
            "Now some of these results are known in the row partition model already, but I want to look at this general model."
        ],
        [
            "So here's a definition of the low rank approximation problem.",
            "LRA that I want to solve.",
            "We have an end by D matrix stored the way I set on this service, so the T has also an end by the matrix.",
            "A Super T and the sum is what we're interested in.",
            "We assume it's a tall skinny matrix.",
            "Otherwise we could turn it around or we assume it's a tall skinny matrix.",
            "An N is bigger than D for most of the talk you can think of N as much bigger than D. So N is something we want to avoid in our complexity, right?",
            "The output is going to help you avoid this.",
            "Keep it distributed, and that's important.",
            "Cervati at the end is going to have a matrix C. Super T is also end by D and with the following conditions there's some matrix is rank K or less.",
            "OK, that's your rank approximation, but we don't explicitly compute the sum at any server, right?",
            "That's going to be important, and then the sum matrix C is a good approximation in the sense that it's error in Frobenius norm sum of squares.",
            "Is within one plus epsilon or the best you can do with the ranking matrix?",
            "Best you can do today, sweetie on the whole matrix, that's what we would like right then?",
            "The entire output is not collected in one server.",
            "That would cost you too much and hear all the resources which I won't repeat.",
            "But let each server is a polynomial time bounded machine.",
            "There's no synchronization, it's a very simple model.",
            "One of the ideas of this is there are many complex and detailed models.",
            "I want a simple model of distributed data.",
            "Where I can, I can say so it's not a new model, it's just a simple model of distributed data where I can prove things further, we restrict each server to have linear space.",
            "They shouldn't exceed the space they have, essentially by more than a constant.",
            "Communication is important because you have to compute the sum.",
            "Something about the sum of function of the some communication is allowed to be only in a constant number of rounds.",
            "I won't precisely tell you what around is, but around is basically.",
            "Any amount of communication can take place in around, but it's sort of.",
            "There's a termination of the round when everybody knows it's done OK. Then I also measure the total amount of communication taken over all the rounds, and that's the biggest resource and the main theorems of this part.",
            "There's an upper bound on the lower bound stated here together near optimal communication algorithm, so an algorithm that is nearly optimal in the number of bits, number of words communicated.",
            "Excuse me, the number of words.",
            "Not number of bits, slight difference, and the optimal communication S * K * T as the number of pro service case.",
            "The rank I'm D is the smaller of the two dimensions, no end in it.",
            "That's very important, right?",
            "I'm going to try and avoid it.",
            "That's both an upper and lower bound.",
            "The star omits log rhythmic factors and epsilon based factors.",
            "He Moe."
        ],
        [
            "Actually, I'll talk about Upper bound.",
            "I'll also talk about the lower bound a little bit.",
            "OK, so here's a first tool that we use.",
            "It's really due to a sequence of papers, and perhaps the climax was a paper by Clarkson Woodruff.",
            "It says the following.",
            "I have what's called a random sign matrix, and I'll tell you in a minute what it is.",
            "With very few rules with Ambrose, M is basically KK is small and you is the projection onto the row space of S applied to a.",
            "So this is a think of it as a random projection.",
            "S is a random projection of a an take the row space of that.",
            "Now if I took the best Frankie approximation to 8 * U, I went to that space.",
            "I projected ETA that space and they took the ranking approximation that does the job.",
            "That's the theorem.",
            "I won't be very precise because I want to give you the intuitive idea clearly, so if you could do this, you're done.",
            "So can you do this?",
            "OK, I'm going to propose an algorithm where the red stuff is meant to wake you up when you see stuff in black, you can go to sleep.",
            "It's fine, but the red stuff you have to pay attention.",
            "There's a central processor by the way, throughout the communications, only with the central processor.",
            "So it's even a more restricted model in which the proper bounds.",
            "There's a central processor, selects the random sign matrix as.",
            "And sends it to each server that's in red for a reason.",
            "It will come to the reason later Cervati.",
            "Takes place a random projections to its own matrix and sends it to the central processor.",
            "No red there, it's fine, and then the central processor finds the sum, which is S projects acting all of a because all linear and then in red sends it to all the servers and and the service server T finds each matrix projected to this U look at the term.",
            "That's what we have to do and then write sensor to the central processor.",
            "The central processor finds AU does SVD.",
            "And we're done.",
            "Now all the black stuff is fine.",
            "All the red stuff is not fine.",
            "Because there's too much communication, so sending S it turns out this is an old trick going back, perhaps at least alone material things are getting in their Seminole paper on frequency moments, so you have that K wise independence is enough for us not fully independent and then a pseudorandom S will do, and what the central processor does in the 1st right step is communicate just the seed of the pseudorandom generator and everybody computes as locali, and that's the thing.",
            "Sending a transpose U which is which call it B transpose is not done that still red and that's the next part of the talk next next slide in some ways.",
            "So how do these guys send BT BT is a big matrix is N by K we don't want anything right?",
            "We don't want any communication so."
        ],
        [
            "Do you do that?",
            "There's a second projection matrix that's going to be used, but we kept the problem has been reduced to the following.",
            "Now we have an end by K matrix at each server not end by DN BI K and we like to do the SVD of this song right approximate this review this OK.",
            "Here's a simple lemma.",
            "This projection of my sister in the same matrix stuff.",
            "So if you have a schedule random matrix which is K by N an applied to be.",
            "Now because of some apply it to be.",
            "Then you can prove that for every vector X that you can put on that every vector, no exceptions.",
            "The length of PBX and the length of BX or within relative epsilon.",
            "That's what that says.",
            "So instead of doing SVD on P * B on B, you can do on P * P. OK, and PB is small.",
            "It can be communicated.",
            "OK, that's going to be the point right now.",
            "You can see that this should sort of be true because X listen K dimensional space and epsilon net would have exponential in K. So if P has K rolls, that's enough.",
            "This is intuition, but this is simple enough limp.",
            "This suffices really hyped.",
            "There's a proof which is given in the book paper.",
            "I won't go through that, but it hides a bit of stuff, but let's take it now.",
            "So this is a two stage 2 random projection still stated after process, and while it is simple is quite useful, it's being used in a couple of papers already.",
            "One of them is very nice paper books.",
            "Addison Woodruff which was in stock this bus stop.",
            "OK, now I want to indicate the lower bound in a couple of lines.",
            "There's not a danger of finished too early, but it's I think you would be with me.",
            "That's fine, but let me indicate the lower bound in a couple of lines.",
            "I'd like to prove a lower bound of S * K * V right of communication.",
            "OK. Now, let's say that Cervati has now occur by the matrix only Kairos.",
            "Now, if you had only came by the matrices, the rank is K. And if the rank is K, the best approximation makes error zero, right?",
            "And since we're doing relative error, if the absolute error, the best seller, you can do zero, you better make an error OF01 plus epsilon times 00.",
            "So because it's K the you have to find the exact matrix, right?",
            "You have to find the exact sound, basically exact some eight.",
            "That's the best rank approximation to a itself.",
            "Now if I require that the exact approximation be.",
            "On one server at the end, then the lower bound is done because that's as times K times the communication test to get it to the one server.",
            "But my model is I don't require it to be in one server.",
            "So how do I manage that?",
            "I'll only say a couple of lines the way you manage that is.",
            "I'm going to do a trick.",
            "I'm going to give several one and two in my instance the identity and minus identity respectively.",
            "They don't affect the sum together, but because it's the identity by the end of this process server one, everybody must know the projection to the correct space to get their local copy of the Matrix at the end, and if they know the projection because its identity, it actually knows the entire matrix.",
            "So really you end up having the entire matrix collected in one place.",
            "Now you can believe the lower bound.",
            "Because what this is saying is at the end, with a lot of skips at the end server one has the exact matrix.",
            "Say, let's computing the sum of many things, but there S * K * D. Things computing this some surely requires that much communication intuitively, and then we prove it in the paper.",
            "Now I."
        ],
        [
            "I want to say a couple of things which are not in the paper which came since the paper, which are interesting.",
            "There's been a lot of interest in a more community on distributed optimization, exactly this kind of setup, where the matrix perhaps, or the constraints of optimization problem or distributed.",
            "Not, I sort of, I know I don't know too many things probably done so there's a lot of heuristics and there's a lot of empirical evidence for various things.",
            "But here's a question.",
            "What about linear programming?",
            "So here I have an end by the matrix M constraints variables.",
            "The constraints are split among service, but each constraint reside fully on a server now.",
            "OK, it's easy to see that order starved to the four will be enough if you just run over the ellipsoid algorithm.",
            "The ellipsoid algorithm has to communicate just a current.",
            "Center of the ellipsoid, which is D communication each time, and so this is not difficult to see.",
            "You can ask for a lower bound.",
            "It's also not that difficult, and I won't tell you, but the lower bound is the square.",
            "There's at least three squared work needed, so there's a little bit of a gap for linear programming between these squared and Y to the 4th.",
            "Perhaps not that big a gap that would be nice to close earlier, and nonlinear optimization is important.",
            "The one thing I didn't do here is fault.",
            "Log in SVD.",
            "Water service failed, that is of great interest in practice.",
            "People would like to know fault tolerant ways of doing this.",
            "That's all I'll say about this part now.",
            "Part 2 of the top, which I'll make briefer."
        ],
        [
            "Is A is a hierarchical relations and I want to introduce that again by an example you have, let's say time series data.",
            "There are many events an for each event.",
            "For each time step, you know whether the event happened or not.",
            "These are these time steps on each event.",
            "Now we assume recites fully on one server and we want to do things like this.",
            "This is a hierarchical relation.",
            "This is interesting in a lot of context.",
            "I want to know the number of seven triples.",
            "Three events in four times so that each of those three events occurs in each of those four times steps.",
            "I want to estimate this number, the three and four can be replaced by any constants.",
            "This is actually just a bipartite graph.",
            "You want the number of Casey falls.",
            "You can think of it.",
            "There are more general problems, customers and products.",
            "Again, each customer now recites wholly on one server.",
            "We want to estimate the number of triples of customers and four couples of product so that each of the three customers buys at least.",
            "X amount of at least three of the four product.",
            "You can have complicated predicates like this, but the reality is constant.",
            "That's important to three info.",
            "OK.",
            "The main result is going to be that we can do all of this in the communication flow communication model.",
            "So customer I in this example turns into.",
            "And choose four component vector.",
            "So for every four couple of product I'm going to put down where the customer buys at least X amount of that or not.",
            "In my vector.",
            "I cannot construct this vector explicitly because I'm allowed only linear space, so this has to be implicitly done.",
            "But once I have these vectors without a full proof, it's intuitively obvious or what I want is to three normal playback.",
            "Of the sun baked.",
            "Excuse me, I want to sum of all the customers.",
            "And then I want the three normal fit vector.",
            "Sum of cubes of the components of the sum of the vectors over all the servers.",
            "OK, that's what I want.",
            "The three should ring a Bell if you're familiar with streaming frequency moments is a very big subarea of streaming and we know from streaming results that the three being greater than two makes it impossible to do it in streaming with polylog communication and these lower bounds and upper bounds in streaming came after a lot of work in a series of papers.",
            "But now we know the answer.",
            "Any exponent higher than two strictly cannot be done in polylog space now.",
            "It will turn out in this model.",
            "We can do it.",
            "This is a more powerful model in streaming, and in fact we can do it so."
        ],
        [
            "I'm going to state that result.",
            "The general set up every server.",
            "I'm sorry every server has a set of N vectors.",
            "OK, each end vector there's a bunch of vectors each besides holding on one server, and we want I have them two normal that, but we want something more general, so K another fixed positive integers, G is that predicate which said I bought at least X amount of at least three product.",
            "Something like that.",
            "OK, so G is some function from the non negative Caples KK dimensional vectors to non negative reals, monotone.",
            "And the result is this guy, which is a generalization of what you saw for customers, is a generalization frequency domains, so you apply G. 2.",
            "Kate couples of components of VI.",
            "Some over I take the teeth power and then take the J1 to JK outside.",
            "Believe me without going into details, this generalizes the customer product problem.",
            "Those kinds of higher order correlations, so this can be computed where each service spends linear space polytime order N rounds, and the amount of communication is as to the Ark was too.",
            "So if your Polygon processes, you can do it in polylog communication.",
            "And it turns out that we need we have a lower bound.",
            "Avesta R -- 1.",
            "I am for the classic frequency moments problem, for which in the streaming model we not right upper and lower bounds.",
            "It turns out we can make this right here also."
        ],
        [
            "See, I'm going to give you 1 slide.",
            "This is the last Flight 1 slight idea of the algorithm.",
            "So here's the algorithm.",
            "So so that he has a vector UT we want the sum of the vectors of all the service and three normal that.",
            "It's not difficult to believe that you could reduce it to sampling with probability sampling.",
            "A coordinate of the sum vector with probability proportional to the cube.",
            "So if you can sample with this probability, you can compute the sum of the cubes, right that you can believe that's intuitively not so difficult, but we don't have those vector in one.",
            "Place it to some of the vectors from many servers.",
            "Each server is only one part of this vector, right?",
            "So what does it do?",
            "The basic idea is a server.",
            "That's something that's intuitively what you would like to do.",
            "Which samples I with probability proportional to its own vectors, components, cubed?",
            "'cause that's all it has and then you pass these vectors to the central processor.",
            "There's some rejection sampling an after that it turns out you can.",
            "Do that now in the tournament.",
            "The paper is more gentle than this.",
            "The art power is replaced by a general function in some sense, for any general function that characterizes.",
            "Within factors of escalated characterizes with upper and lower bounds, how much communication you need to compute such generalized moments.",
            "Now there are many open problems I mentioned, some with the first part for the second part I would say there's a nice open problem characterizing all functions F&G, which can be handled like this.",
            "Now I told you the bipartite graph.",
            "You can estimate the number of 3 four complete graphs there are there's interest in estimating number of communities of various types.",
            "It's an open question as to what classes are bipartite graphs you can do in the paper.",
            "We do something more general than just complete graphs.",
            "But it's not known at the moment what classes of bipartite graphs you can count this way, that's another story."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The biggest result of this talk is the way the slides are made, because for two days I was sitting in the back and I couldn't read the slides.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you will tell me what it is that's different and that.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I can read them, I hope so, but we'll see simple tray.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Here is I got 2 problems in this top.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about the first one most of the time it is you have an input matrix A which is distributed among various servers F servers and I want to do singular value decomposition or low rank approximation on it.",
                    "label": 0
                },
                {
                    "sent": "But I want to introduce the model with one example.",
                    "label": 0
                },
                {
                    "sent": "I don't want to tell you host of examples to say speed is important.",
                    "label": 0
                },
                {
                    "sent": "Perhaps all if you believe that.",
                    "label": 0
                },
                {
                    "sent": "But here's one example that illustrates why.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming what the model is.",
                    "label": 0
                },
                {
                    "sent": "So if the customer product matrix.",
                    "label": 0
                },
                {
                    "sent": "A bunch of customers.",
                    "label": 0
                },
                {
                    "sent": "There are as shops.",
                    "label": 0
                },
                {
                    "sent": "They of Shakti records all the things that every customer bought in that shop.",
                    "label": 0
                },
                {
                    "sent": "That's all the bag of products, right?",
                    "label": 0
                },
                {
                    "sent": "And that called the matrix that the server T has customer product matrix a super T and then our entire matrix is the sum of all these matrices.",
                    "label": 0
                },
                {
                    "sent": "Every entry sound.",
                    "label": 0
                },
                {
                    "sent": "Now this is different from the model in which you assume that each customer shops only in one place, one shop.",
                    "label": 1
                },
                {
                    "sent": "In that case, every customer the entire row would be in one place.",
                    "label": 0
                },
                {
                    "sent": "We don't assume that the entire rows are in one place, we assume just a matrix is sound.",
                    "label": 1
                },
                {
                    "sent": "OK, so more general model then assuming a row partition for this reason.",
                    "label": 0
                },
                {
                    "sent": "Now some of these results are known in the row partition model already, but I want to look at this general model.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a definition of the low rank approximation problem.",
                    "label": 1
                },
                {
                    "sent": "LRA that I want to solve.",
                    "label": 0
                },
                {
                    "sent": "We have an end by D matrix stored the way I set on this service, so the T has also an end by the matrix.",
                    "label": 0
                },
                {
                    "sent": "A Super T and the sum is what we're interested in.",
                    "label": 0
                },
                {
                    "sent": "We assume it's a tall skinny matrix.",
                    "label": 1
                },
                {
                    "sent": "Otherwise we could turn it around or we assume it's a tall skinny matrix.",
                    "label": 0
                },
                {
                    "sent": "An N is bigger than D for most of the talk you can think of N as much bigger than D. So N is something we want to avoid in our complexity, right?",
                    "label": 0
                },
                {
                    "sent": "The output is going to help you avoid this.",
                    "label": 0
                },
                {
                    "sent": "Keep it distributed, and that's important.",
                    "label": 0
                },
                {
                    "sent": "Cervati at the end is going to have a matrix C. Super T is also end by D and with the following conditions there's some matrix is rank K or less.",
                    "label": 0
                },
                {
                    "sent": "OK, that's your rank approximation, but we don't explicitly compute the sum at any server, right?",
                    "label": 0
                },
                {
                    "sent": "That's going to be important, and then the sum matrix C is a good approximation in the sense that it's error in Frobenius norm sum of squares.",
                    "label": 0
                },
                {
                    "sent": "Is within one plus epsilon or the best you can do with the ranking matrix?",
                    "label": 0
                },
                {
                    "sent": "Best you can do today, sweetie on the whole matrix, that's what we would like right then?",
                    "label": 0
                },
                {
                    "sent": "The entire output is not collected in one server.",
                    "label": 1
                },
                {
                    "sent": "That would cost you too much and hear all the resources which I won't repeat.",
                    "label": 0
                },
                {
                    "sent": "But let each server is a polynomial time bounded machine.",
                    "label": 0
                },
                {
                    "sent": "There's no synchronization, it's a very simple model.",
                    "label": 0
                },
                {
                    "sent": "One of the ideas of this is there are many complex and detailed models.",
                    "label": 0
                },
                {
                    "sent": "I want a simple model of distributed data.",
                    "label": 0
                },
                {
                    "sent": "Where I can, I can say so it's not a new model, it's just a simple model of distributed data where I can prove things further, we restrict each server to have linear space.",
                    "label": 0
                },
                {
                    "sent": "They shouldn't exceed the space they have, essentially by more than a constant.",
                    "label": 0
                },
                {
                    "sent": "Communication is important because you have to compute the sum.",
                    "label": 0
                },
                {
                    "sent": "Something about the sum of function of the some communication is allowed to be only in a constant number of rounds.",
                    "label": 0
                },
                {
                    "sent": "I won't precisely tell you what around is, but around is basically.",
                    "label": 1
                },
                {
                    "sent": "Any amount of communication can take place in around, but it's sort of.",
                    "label": 0
                },
                {
                    "sent": "There's a termination of the round when everybody knows it's done OK. Then I also measure the total amount of communication taken over all the rounds, and that's the biggest resource and the main theorems of this part.",
                    "label": 1
                },
                {
                    "sent": "There's an upper bound on the lower bound stated here together near optimal communication algorithm, so an algorithm that is nearly optimal in the number of bits, number of words communicated.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, the number of words.",
                    "label": 0
                },
                {
                    "sent": "Not number of bits, slight difference, and the optimal communication S * K * T as the number of pro service case.",
                    "label": 0
                },
                {
                    "sent": "The rank I'm D is the smaller of the two dimensions, no end in it.",
                    "label": 0
                },
                {
                    "sent": "That's very important, right?",
                    "label": 0
                },
                {
                    "sent": "I'm going to try and avoid it.",
                    "label": 0
                },
                {
                    "sent": "That's both an upper and lower bound.",
                    "label": 0
                },
                {
                    "sent": "The star omits log rhythmic factors and epsilon based factors.",
                    "label": 0
                },
                {
                    "sent": "He Moe.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, I'll talk about Upper bound.",
                    "label": 0
                },
                {
                    "sent": "I'll also talk about the lower bound a little bit.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a first tool that we use.",
                    "label": 0
                },
                {
                    "sent": "It's really due to a sequence of papers, and perhaps the climax was a paper by Clarkson Woodruff.",
                    "label": 0
                },
                {
                    "sent": "It says the following.",
                    "label": 0
                },
                {
                    "sent": "I have what's called a random sign matrix, and I'll tell you in a minute what it is.",
                    "label": 0
                },
                {
                    "sent": "With very few rules with Ambrose, M is basically KK is small and you is the projection onto the row space of S applied to a.",
                    "label": 1
                },
                {
                    "sent": "So this is a think of it as a random projection.",
                    "label": 0
                },
                {
                    "sent": "S is a random projection of a an take the row space of that.",
                    "label": 0
                },
                {
                    "sent": "Now if I took the best Frankie approximation to 8 * U, I went to that space.",
                    "label": 0
                },
                {
                    "sent": "I projected ETA that space and they took the ranking approximation that does the job.",
                    "label": 0
                },
                {
                    "sent": "That's the theorem.",
                    "label": 0
                },
                {
                    "sent": "I won't be very precise because I want to give you the intuitive idea clearly, so if you could do this, you're done.",
                    "label": 0
                },
                {
                    "sent": "So can you do this?",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to propose an algorithm where the red stuff is meant to wake you up when you see stuff in black, you can go to sleep.",
                    "label": 0
                },
                {
                    "sent": "It's fine, but the red stuff you have to pay attention.",
                    "label": 0
                },
                {
                    "sent": "There's a central processor by the way, throughout the communications, only with the central processor.",
                    "label": 0
                },
                {
                    "sent": "So it's even a more restricted model in which the proper bounds.",
                    "label": 0
                },
                {
                    "sent": "There's a central processor, selects the random sign matrix as.",
                    "label": 0
                },
                {
                    "sent": "And sends it to each server that's in red for a reason.",
                    "label": 1
                },
                {
                    "sent": "It will come to the reason later Cervati.",
                    "label": 1
                },
                {
                    "sent": "Takes place a random projections to its own matrix and sends it to the central processor.",
                    "label": 0
                },
                {
                    "sent": "No red there, it's fine, and then the central processor finds the sum, which is S projects acting all of a because all linear and then in red sends it to all the servers and and the service server T finds each matrix projected to this U look at the term.",
                    "label": 1
                },
                {
                    "sent": "That's what we have to do and then write sensor to the central processor.",
                    "label": 0
                },
                {
                    "sent": "The central processor finds AU does SVD.",
                    "label": 0
                },
                {
                    "sent": "And we're done.",
                    "label": 0
                },
                {
                    "sent": "Now all the black stuff is fine.",
                    "label": 0
                },
                {
                    "sent": "All the red stuff is not fine.",
                    "label": 0
                },
                {
                    "sent": "Because there's too much communication, so sending S it turns out this is an old trick going back, perhaps at least alone material things are getting in their Seminole paper on frequency moments, so you have that K wise independence is enough for us not fully independent and then a pseudorandom S will do, and what the central processor does in the 1st right step is communicate just the seed of the pseudorandom generator and everybody computes as locali, and that's the thing.",
                    "label": 0
                },
                {
                    "sent": "Sending a transpose U which is which call it B transpose is not done that still red and that's the next part of the talk next next slide in some ways.",
                    "label": 0
                },
                {
                    "sent": "So how do these guys send BT BT is a big matrix is N by K we don't want anything right?",
                    "label": 0
                },
                {
                    "sent": "We don't want any communication so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do you do that?",
                    "label": 0
                },
                {
                    "sent": "There's a second projection matrix that's going to be used, but we kept the problem has been reduced to the following.",
                    "label": 0
                },
                {
                    "sent": "Now we have an end by K matrix at each server not end by DN BI K and we like to do the SVD of this song right approximate this review this OK.",
                    "label": 1
                },
                {
                    "sent": "Here's a simple lemma.",
                    "label": 0
                },
                {
                    "sent": "This projection of my sister in the same matrix stuff.",
                    "label": 0
                },
                {
                    "sent": "So if you have a schedule random matrix which is K by N an applied to be.",
                    "label": 0
                },
                {
                    "sent": "Now because of some apply it to be.",
                    "label": 0
                },
                {
                    "sent": "Then you can prove that for every vector X that you can put on that every vector, no exceptions.",
                    "label": 0
                },
                {
                    "sent": "The length of PBX and the length of BX or within relative epsilon.",
                    "label": 0
                },
                {
                    "sent": "That's what that says.",
                    "label": 0
                },
                {
                    "sent": "So instead of doing SVD on P * B on B, you can do on P * P. OK, and PB is small.",
                    "label": 0
                },
                {
                    "sent": "It can be communicated.",
                    "label": 0
                },
                {
                    "sent": "OK, that's going to be the point right now.",
                    "label": 0
                },
                {
                    "sent": "You can see that this should sort of be true because X listen K dimensional space and epsilon net would have exponential in K. So if P has K rolls, that's enough.",
                    "label": 0
                },
                {
                    "sent": "This is intuition, but this is simple enough limp.",
                    "label": 0
                },
                {
                    "sent": "This suffices really hyped.",
                    "label": 0
                },
                {
                    "sent": "There's a proof which is given in the book paper.",
                    "label": 0
                },
                {
                    "sent": "I won't go through that, but it hides a bit of stuff, but let's take it now.",
                    "label": 0
                },
                {
                    "sent": "So this is a two stage 2 random projection still stated after process, and while it is simple is quite useful, it's being used in a couple of papers already.",
                    "label": 0
                },
                {
                    "sent": "One of them is very nice paper books.",
                    "label": 0
                },
                {
                    "sent": "Addison Woodruff which was in stock this bus stop.",
                    "label": 0
                },
                {
                    "sent": "OK, now I want to indicate the lower bound in a couple of lines.",
                    "label": 0
                },
                {
                    "sent": "There's not a danger of finished too early, but it's I think you would be with me.",
                    "label": 0
                },
                {
                    "sent": "That's fine, but let me indicate the lower bound in a couple of lines.",
                    "label": 0
                },
                {
                    "sent": "I'd like to prove a lower bound of S * K * V right of communication.",
                    "label": 0
                },
                {
                    "sent": "OK. Now, let's say that Cervati has now occur by the matrix only Kairos.",
                    "label": 0
                },
                {
                    "sent": "Now, if you had only came by the matrices, the rank is K. And if the rank is K, the best approximation makes error zero, right?",
                    "label": 0
                },
                {
                    "sent": "And since we're doing relative error, if the absolute error, the best seller, you can do zero, you better make an error OF01 plus epsilon times 00.",
                    "label": 0
                },
                {
                    "sent": "So because it's K the you have to find the exact matrix, right?",
                    "label": 0
                },
                {
                    "sent": "You have to find the exact sound, basically exact some eight.",
                    "label": 0
                },
                {
                    "sent": "That's the best rank approximation to a itself.",
                    "label": 0
                },
                {
                    "sent": "Now if I require that the exact approximation be.",
                    "label": 0
                },
                {
                    "sent": "On one server at the end, then the lower bound is done because that's as times K times the communication test to get it to the one server.",
                    "label": 1
                },
                {
                    "sent": "But my model is I don't require it to be in one server.",
                    "label": 0
                },
                {
                    "sent": "So how do I manage that?",
                    "label": 0
                },
                {
                    "sent": "I'll only say a couple of lines the way you manage that is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to do a trick.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give several one and two in my instance the identity and minus identity respectively.",
                    "label": 0
                },
                {
                    "sent": "They don't affect the sum together, but because it's the identity by the end of this process server one, everybody must know the projection to the correct space to get their local copy of the Matrix at the end, and if they know the projection because its identity, it actually knows the entire matrix.",
                    "label": 0
                },
                {
                    "sent": "So really you end up having the entire matrix collected in one place.",
                    "label": 0
                },
                {
                    "sent": "Now you can believe the lower bound.",
                    "label": 0
                },
                {
                    "sent": "Because what this is saying is at the end, with a lot of skips at the end server one has the exact matrix.",
                    "label": 0
                },
                {
                    "sent": "Say, let's computing the sum of many things, but there S * K * D. Things computing this some surely requires that much communication intuitively, and then we prove it in the paper.",
                    "label": 0
                },
                {
                    "sent": "Now I.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to say a couple of things which are not in the paper which came since the paper, which are interesting.",
                    "label": 1
                },
                {
                    "sent": "There's been a lot of interest in a more community on distributed optimization, exactly this kind of setup, where the matrix perhaps, or the constraints of optimization problem or distributed.",
                    "label": 0
                },
                {
                    "sent": "Not, I sort of, I know I don't know too many things probably done so there's a lot of heuristics and there's a lot of empirical evidence for various things.",
                    "label": 0
                },
                {
                    "sent": "But here's a question.",
                    "label": 0
                },
                {
                    "sent": "What about linear programming?",
                    "label": 0
                },
                {
                    "sent": "So here I have an end by the matrix M constraints variables.",
                    "label": 0
                },
                {
                    "sent": "The constraints are split among service, but each constraint reside fully on a server now.",
                    "label": 1
                },
                {
                    "sent": "OK, it's easy to see that order starved to the four will be enough if you just run over the ellipsoid algorithm.",
                    "label": 0
                },
                {
                    "sent": "The ellipsoid algorithm has to communicate just a current.",
                    "label": 1
                },
                {
                    "sent": "Center of the ellipsoid, which is D communication each time, and so this is not difficult to see.",
                    "label": 0
                },
                {
                    "sent": "You can ask for a lower bound.",
                    "label": 0
                },
                {
                    "sent": "It's also not that difficult, and I won't tell you, but the lower bound is the square.",
                    "label": 1
                },
                {
                    "sent": "There's at least three squared work needed, so there's a little bit of a gap for linear programming between these squared and Y to the 4th.",
                    "label": 1
                },
                {
                    "sent": "Perhaps not that big a gap that would be nice to close earlier, and nonlinear optimization is important.",
                    "label": 0
                },
                {
                    "sent": "The one thing I didn't do here is fault.",
                    "label": 0
                },
                {
                    "sent": "Log in SVD.",
                    "label": 0
                },
                {
                    "sent": "Water service failed, that is of great interest in practice.",
                    "label": 0
                },
                {
                    "sent": "People would like to know fault tolerant ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "That's all I'll say about this part now.",
                    "label": 0
                },
                {
                    "sent": "Part 2 of the top, which I'll make briefer.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is A is a hierarchical relations and I want to introduce that again by an example you have, let's say time series data.",
                    "label": 0
                },
                {
                    "sent": "There are many events an for each event.",
                    "label": 1
                },
                {
                    "sent": "For each time step, you know whether the event happened or not.",
                    "label": 0
                },
                {
                    "sent": "These are these time steps on each event.",
                    "label": 0
                },
                {
                    "sent": "Now we assume recites fully on one server and we want to do things like this.",
                    "label": 1
                },
                {
                    "sent": "This is a hierarchical relation.",
                    "label": 0
                },
                {
                    "sent": "This is interesting in a lot of context.",
                    "label": 1
                },
                {
                    "sent": "I want to know the number of seven triples.",
                    "label": 1
                },
                {
                    "sent": "Three events in four times so that each of those three events occurs in each of those four times steps.",
                    "label": 0
                },
                {
                    "sent": "I want to estimate this number, the three and four can be replaced by any constants.",
                    "label": 0
                },
                {
                    "sent": "This is actually just a bipartite graph.",
                    "label": 0
                },
                {
                    "sent": "You want the number of Casey falls.",
                    "label": 0
                },
                {
                    "sent": "You can think of it.",
                    "label": 0
                },
                {
                    "sent": "There are more general problems, customers and products.",
                    "label": 0
                },
                {
                    "sent": "Again, each customer now recites wholly on one server.",
                    "label": 1
                },
                {
                    "sent": "We want to estimate the number of triples of customers and four couples of product so that each of the three customers buys at least.",
                    "label": 1
                },
                {
                    "sent": "X amount of at least three of the four product.",
                    "label": 1
                },
                {
                    "sent": "You can have complicated predicates like this, but the reality is constant.",
                    "label": 0
                },
                {
                    "sent": "That's important to three info.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The main result is going to be that we can do all of this in the communication flow communication model.",
                    "label": 0
                },
                {
                    "sent": "So customer I in this example turns into.",
                    "label": 0
                },
                {
                    "sent": "And choose four component vector.",
                    "label": 0
                },
                {
                    "sent": "So for every four couple of product I'm going to put down where the customer buys at least X amount of that or not.",
                    "label": 0
                },
                {
                    "sent": "In my vector.",
                    "label": 0
                },
                {
                    "sent": "I cannot construct this vector explicitly because I'm allowed only linear space, so this has to be implicitly done.",
                    "label": 1
                },
                {
                    "sent": "But once I have these vectors without a full proof, it's intuitively obvious or what I want is to three normal playback.",
                    "label": 0
                },
                {
                    "sent": "Of the sun baked.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, I want to sum of all the customers.",
                    "label": 0
                },
                {
                    "sent": "And then I want the three normal fit vector.",
                    "label": 0
                },
                {
                    "sent": "Sum of cubes of the components of the sum of the vectors over all the servers.",
                    "label": 1
                },
                {
                    "sent": "OK, that's what I want.",
                    "label": 1
                },
                {
                    "sent": "The three should ring a Bell if you're familiar with streaming frequency moments is a very big subarea of streaming and we know from streaming results that the three being greater than two makes it impossible to do it in streaming with polylog communication and these lower bounds and upper bounds in streaming came after a lot of work in a series of papers.",
                    "label": 0
                },
                {
                    "sent": "But now we know the answer.",
                    "label": 0
                },
                {
                    "sent": "Any exponent higher than two strictly cannot be done in polylog space now.",
                    "label": 0
                },
                {
                    "sent": "It will turn out in this model.",
                    "label": 0
                },
                {
                    "sent": "We can do it.",
                    "label": 0
                },
                {
                    "sent": "This is a more powerful model in streaming, and in fact we can do it so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to state that result.",
                    "label": 0
                },
                {
                    "sent": "The general set up every server.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry every server has a set of N vectors.",
                    "label": 1
                },
                {
                    "sent": "OK, each end vector there's a bunch of vectors each besides holding on one server, and we want I have them two normal that, but we want something more general, so K another fixed positive integers, G is that predicate which said I bought at least X amount of at least three product.",
                    "label": 0
                },
                {
                    "sent": "Something like that.",
                    "label": 0
                },
                {
                    "sent": "OK, so G is some function from the non negative Caples KK dimensional vectors to non negative reals, monotone.",
                    "label": 0
                },
                {
                    "sent": "And the result is this guy, which is a generalization of what you saw for customers, is a generalization frequency domains, so you apply G. 2.",
                    "label": 0
                },
                {
                    "sent": "Kate couples of components of VI.",
                    "label": 0
                },
                {
                    "sent": "Some over I take the teeth power and then take the J1 to JK outside.",
                    "label": 0
                },
                {
                    "sent": "Believe me without going into details, this generalizes the customer product problem.",
                    "label": 0
                },
                {
                    "sent": "Those kinds of higher order correlations, so this can be computed where each service spends linear space polytime order N rounds, and the amount of communication is as to the Ark was too.",
                    "label": 1
                },
                {
                    "sent": "So if your Polygon processes, you can do it in polylog communication.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that we need we have a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Avesta R -- 1.",
                    "label": 0
                },
                {
                    "sent": "I am for the classic frequency moments problem, for which in the streaming model we not right upper and lower bounds.",
                    "label": 0
                },
                {
                    "sent": "It turns out we can make this right here also.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See, I'm going to give you 1 slide.",
                    "label": 0
                },
                {
                    "sent": "This is the last Flight 1 slight idea of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here's the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So so that he has a vector UT we want the sum of the vectors of all the service and three normal that.",
                    "label": 0
                },
                {
                    "sent": "It's not difficult to believe that you could reduce it to sampling with probability sampling.",
                    "label": 0
                },
                {
                    "sent": "A coordinate of the sum vector with probability proportional to the cube.",
                    "label": 0
                },
                {
                    "sent": "So if you can sample with this probability, you can compute the sum of the cubes, right that you can believe that's intuitively not so difficult, but we don't have those vector in one.",
                    "label": 0
                },
                {
                    "sent": "Place it to some of the vectors from many servers.",
                    "label": 0
                },
                {
                    "sent": "Each server is only one part of this vector, right?",
                    "label": 0
                },
                {
                    "sent": "So what does it do?",
                    "label": 0
                },
                {
                    "sent": "The basic idea is a server.",
                    "label": 0
                },
                {
                    "sent": "That's something that's intuitively what you would like to do.",
                    "label": 0
                },
                {
                    "sent": "Which samples I with probability proportional to its own vectors, components, cubed?",
                    "label": 1
                },
                {
                    "sent": "'cause that's all it has and then you pass these vectors to the central processor.",
                    "label": 0
                },
                {
                    "sent": "There's some rejection sampling an after that it turns out you can.",
                    "label": 0
                },
                {
                    "sent": "Do that now in the tournament.",
                    "label": 0
                },
                {
                    "sent": "The paper is more gentle than this.",
                    "label": 0
                },
                {
                    "sent": "The art power is replaced by a general function in some sense, for any general function that characterizes.",
                    "label": 0
                },
                {
                    "sent": "Within factors of escalated characterizes with upper and lower bounds, how much communication you need to compute such generalized moments.",
                    "label": 0
                },
                {
                    "sent": "Now there are many open problems I mentioned, some with the first part for the second part I would say there's a nice open problem characterizing all functions F&G, which can be handled like this.",
                    "label": 1
                },
                {
                    "sent": "Now I told you the bipartite graph.",
                    "label": 0
                },
                {
                    "sent": "You can estimate the number of 3 four complete graphs there are there's interest in estimating number of communities of various types.",
                    "label": 0
                },
                {
                    "sent": "It's an open question as to what classes are bipartite graphs you can do in the paper.",
                    "label": 0
                },
                {
                    "sent": "We do something more general than just complete graphs.",
                    "label": 0
                },
                {
                    "sent": "But it's not known at the moment what classes of bipartite graphs you can count this way, that's another story.",
                    "label": 0
                }
            ]
        }
    }
}