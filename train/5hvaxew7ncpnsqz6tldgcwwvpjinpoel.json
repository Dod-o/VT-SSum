{
    "id": "5hvaxew7ncpnsqz6tldgcwwvpjinpoel",
    "title": "Future dark energy probes and their robustness to systematics",
    "info": {
        "author": [
            "Marisa Cristina March, University of Sussex"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Astronomy->Cosmology",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_march_energy/",
    "segmentation": [
        [
            "Say good morning everybody and one of the things that went in cosmology is putting constraints on parameters, and in particular in training dark energy parameters.",
            "Here, W. Nolan WA using different kinds of datasets and one thing I want to do is we want to think about in the future.",
            "We plan future experiments.",
            "How do we decide that experiment to go for which experiment is going to give us the best constraints on those parameters?",
            "And one thing we do is we predict what will the error... be on those parameters.",
            "So here we've got.",
            "Just a schematic for the dark Energy Task force.",
            "Paper showing an error ellipse for WAW nought, and this is a 95% confidence interval.",
            "Send official model and I do as you want evaluate this error ellipse for all of your future proposed experiments.",
            "Decide which experiment is going to give you the tightest constraints are either smallest error... and go with that experiment, But the problem is this is only considering the statistical errors is not considering systematic errors."
        ],
        [
            "So one question is, what can we do to include some kind of indication on how this future experiment could be affected by a systematic bias?",
            "How do we account for that?",
            "So just to give you some more information about the statistical figure of merit.",
            "So generally what you might have is some kind of existing experiment represented by this red error ellipse, and you can propose a new experiment which is going to give you these blue error... here, and you might be considering, say, supernova.",
            "Data and we cleansing data is sort of new probe or a new version of your weak lensing experiment.",
            "In an ideal world, your future experiment is going to be centered on the same physical parameters as your existing experiment, but in reality you might find your future experiments biased by some amount.",
            "So that's shown here by this displacement.",
            "This green bias are here now.",
            "What you evaluate is the joint constraints of your existing probe and your future probe, and you joint theory here.",
            "Shannon Black, now close to Stickle figure of merit these.",
            "Black dotted outlets is only depend on the orientation of the probes.",
            "So for example in these two top panels you can see the orientations of probes the same, but they displaced with respect to each other.",
            "In this case, you're going to get the same.",
            "You're going to get the same statistical figure of merit for both cases.",
            "And here is this different orientation and your statistical figure of merit will change.",
            "But what it doesn't count for is if this feature probe is displays significantly, you're going to get the same statistical figure of merit.",
            "So what can we do to?",
            "Quantify this."
        ],
        [
            "Bias the systematic bias so we introduced their best miss figure of merit and this is it's based on a Bayesian ratio of how do you account for the same experiment?",
            "If you consider that separately or the data datasets together?",
            "So what's the degree of consistency between these two different datasets?",
            "And this essentially translate size?",
            "How well to a different error... overlap?",
            "And for details, see the poster or the paper.",
            "So what we say is that product is a greater degree of overlap, are more robust to systematic bias than those which don't have a good degree of overlap.",
            "And just to give you a quick plot here of this is our existing probe and a future probe, and you can and as you rotate these probes, you see that the statistical figure of merit is maximized when they're orthogonal and the system at the systematic.",
            "Then robustness is maximized when they're in parallel, and I've just shown here three different bias directions along these different arrows, and you'll maximize your breasts in a systematic error when the bias arrow.",
            "Aligns with your generative projection direction, your systematic errors.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Say good morning everybody and one of the things that went in cosmology is putting constraints on parameters, and in particular in training dark energy parameters.",
                    "label": 0
                },
                {
                    "sent": "Here, W. Nolan WA using different kinds of datasets and one thing I want to do is we want to think about in the future.",
                    "label": 0
                },
                {
                    "sent": "We plan future experiments.",
                    "label": 0
                },
                {
                    "sent": "How do we decide that experiment to go for which experiment is going to give us the best constraints on those parameters?",
                    "label": 0
                },
                {
                    "sent": "And one thing we do is we predict what will the error... be on those parameters.",
                    "label": 0
                },
                {
                    "sent": "So here we've got.",
                    "label": 0
                },
                {
                    "sent": "Just a schematic for the dark Energy Task force.",
                    "label": 1
                },
                {
                    "sent": "Paper showing an error ellipse for WAW nought, and this is a 95% confidence interval.",
                    "label": 0
                },
                {
                    "sent": "Send official model and I do as you want evaluate this error ellipse for all of your future proposed experiments.",
                    "label": 0
                },
                {
                    "sent": "Decide which experiment is going to give you the tightest constraints are either smallest error... and go with that experiment, But the problem is this is only considering the statistical errors is not considering systematic errors.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one question is, what can we do to include some kind of indication on how this future experiment could be affected by a systematic bias?",
                    "label": 0
                },
                {
                    "sent": "How do we account for that?",
                    "label": 0
                },
                {
                    "sent": "So just to give you some more information about the statistical figure of merit.",
                    "label": 1
                },
                {
                    "sent": "So generally what you might have is some kind of existing experiment represented by this red error ellipse, and you can propose a new experiment which is going to give you these blue error... here, and you might be considering, say, supernova.",
                    "label": 0
                },
                {
                    "sent": "Data and we cleansing data is sort of new probe or a new version of your weak lensing experiment.",
                    "label": 0
                },
                {
                    "sent": "In an ideal world, your future experiment is going to be centered on the same physical parameters as your existing experiment, but in reality you might find your future experiments biased by some amount.",
                    "label": 0
                },
                {
                    "sent": "So that's shown here by this displacement.",
                    "label": 0
                },
                {
                    "sent": "This green bias are here now.",
                    "label": 1
                },
                {
                    "sent": "What you evaluate is the joint constraints of your existing probe and your future probe, and you joint theory here.",
                    "label": 0
                },
                {
                    "sent": "Shannon Black, now close to Stickle figure of merit these.",
                    "label": 0
                },
                {
                    "sent": "Black dotted outlets is only depend on the orientation of the probes.",
                    "label": 1
                },
                {
                    "sent": "So for example in these two top panels you can see the orientations of probes the same, but they displaced with respect to each other.",
                    "label": 0
                },
                {
                    "sent": "In this case, you're going to get the same.",
                    "label": 0
                },
                {
                    "sent": "You're going to get the same statistical figure of merit for both cases.",
                    "label": 0
                },
                {
                    "sent": "And here is this different orientation and your statistical figure of merit will change.",
                    "label": 0
                },
                {
                    "sent": "But what it doesn't count for is if this feature probe is displays significantly, you're going to get the same statistical figure of merit.",
                    "label": 0
                },
                {
                    "sent": "So what can we do to?",
                    "label": 0
                },
                {
                    "sent": "Quantify this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bias the systematic bias so we introduced their best miss figure of merit and this is it's based on a Bayesian ratio of how do you account for the same experiment?",
                    "label": 1
                },
                {
                    "sent": "If you consider that separately or the data datasets together?",
                    "label": 0
                },
                {
                    "sent": "So what's the degree of consistency between these two different datasets?",
                    "label": 1
                },
                {
                    "sent": "And this essentially translate size?",
                    "label": 0
                },
                {
                    "sent": "How well to a different error... overlap?",
                    "label": 0
                },
                {
                    "sent": "And for details, see the poster or the paper.",
                    "label": 0
                },
                {
                    "sent": "So what we say is that product is a greater degree of overlap, are more robust to systematic bias than those which don't have a good degree of overlap.",
                    "label": 1
                },
                {
                    "sent": "And just to give you a quick plot here of this is our existing probe and a future probe, and you can and as you rotate these probes, you see that the statistical figure of merit is maximized when they're orthogonal and the system at the systematic.",
                    "label": 0
                },
                {
                    "sent": "Then robustness is maximized when they're in parallel, and I've just shown here three different bias directions along these different arrows, and you'll maximize your breasts in a systematic error when the bias arrow.",
                    "label": 0
                },
                {
                    "sent": "Aligns with your generative projection direction, your systematic errors.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}