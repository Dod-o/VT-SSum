{
    "id": "7qfpotipbihikgbb2vxjzgijyauydilh",
    "title": "Towards Linked Data Update Notifications",
    "info": {
        "author": [
            "Magnus Knuth, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_knuth_linked_data/",
    "segmentation": [
        [
            "Welcome to my talk about towards Link data update notifications.",
            "Reviewing and generating the sparkle push approach.",
            "This is a joint work with people I met last year on the Web Intelligence Summer School.",
            "In some ITN, it's with dinners ready, Anastasia Dimou.",
            "So how about that?",
            "Ian George Castrey knickers."
        ],
        [
            "So.",
            "My talk is about.",
            "Update notifications in linked data, so I will first give you the motivation was actually didn't motivation for that.",
            "And then I will.",
            "Presented the actual idea that we found already exists and tell you about the shortcomings that we identified there.",
            "Later on I will tell you about research problems were identified from this implementation or from this approach and the requirements we put on that."
        ],
        [
            "So the actually motivation behind that idea that we identified in this summer school worse.",
            "How can data consumers be supported when they are working with linked data that changes, so we all know the problem when we have a data set that is published by a consumer and know that is published by the publisher and the consumer uses these data set, but at some point the data set changes so it would be a nice.",
            "Feature when the consumer gets notified about changes or and especially about changes that he is interested in so that he can later on re consume this data and also re process.",
            "So in his workflow.",
            "So that was actually the idea we had for this summer school Heckert.",
            "And then we realized."
        ],
        [
            "So we thought about it and then we realized, oh, there's been a publication in 2010 by Alexandra Person.",
            "It's called the sparkle push, so the idea behind bucket pushes pretty pretty cool.",
            "So we really don't want to bash it so, but we think it's really a nice idea because we had the same.",
            "So the idea is that the consumer, when he wants to get notified, get notifications about updates.",
            "He registers his.",
            "Particular sparkle query for a data set at this park and push service and as soon as the result for this sparkle query changes, he gets notified by this sparkle push server.",
            "The idea behind Block pushes that this happens with pub sub hubbub and Additionally these changes are also tracked in RSS feed.",
            "So that you can see all the changes in history.",
            "Yeah, so that's actually what we want to have."
        ],
        [
            "So we analyzed this sparkle push implementation plan and then we found out it's not very generalizable, so it's actually intended to be used for microblogging applications and the authors or the programmers.",
            "They put some quite hot restrictions on the sparkle queries, for example, so they only support select queries.",
            "No ask, describe, or construct they.",
            "Need to have the UI and date variables in the select phrase and Additionally mandatorily they you can have the label and author variable there, nothing else so that really restricts your queries.",
            "What they also did.",
            "They used the latest date in the result set to identify whether there was a change so they do not really compare this Parker site they just look at the latest date.",
            "And they only allow updates happening via this interface.",
            "This bucket push interface, so there are no other possibilities to put updates in the data set."
        ],
        [
            "So, but we had other requirements.",
            "So we put up the other requirements.",
            "For example, what we want to have is we want to process arbitrary sparkle queries because we think it's really important that users can express their information need in a way they want, so they express their information if they have.",
            "The second requirement was that this service should work on any sparkle endpoint, so with any data set.",
            "Uh.",
            "The third one was that we don't want to put unnecessary load on the sparkle interfaces, so becausw querying is very expensive and we don't want to denial the service of the public endpoints.",
            "And we also think it's necessary to express this.",
            "The change descriptions of these.",
            "To express the descriptions of these changes sufficiently that the user can decide, does this change really?",
            "In fact, or affect me or not.",
            "So from these requirements, we then identified that are actually some hard problems in there and we identified.",
            "Research problems that are currently not really solved."
        ],
        [
            "So the first problem with Spark queries is that the results that can be really really large.",
            "For example, if you ask in DB pedia for the redir data set so just all pages which redirect to another page, you get several gigabytes of data back.",
            "So one problem there is of course and that usually triple stores or sparkle endpoints, they do not give you all the data, they have a limit of 10,000 lines for example, and then they stop.",
            "So you can circumvent it by pagination, for example, but in the end it's still a lot of data that you have to 1st transmit, and Secondly you have to store it for the comparison with the next result.",
            "So we propose in our paper some solutions how you can cope with that.",
            "One solution would be aggregation, so we could for example rewrite the select queries and then we just take the number of results.",
            "So we get the number of solutions, so we have a very smaller resultset, but it's somehow incomplete, so we just recognize if something has been added or something has been deleted, but we don't know when something's changed.",
            "Another possibility would be to hash the result set so we have less memory to store, but still we have all the data transfer over the net.",
            "And a third possibility we thought about using triple fragment servers.",
            "There we can start.",
            "We thought we can somehow apply this or use this streaming functionality so we can detect changes without retrieving the full results.",
            "Nevertheless, we might retrieve the full result to compare it with the next iteration."
        ],
        [
            "The second research problem we identified is the comparison of Sparkle Resultsets.",
            "So the research question we put there is how can sparkle results be efficiently and effectively compared so we have one for ask queries.",
            "It's pretty similar.",
            "We have true or faults.",
            "So for describing construct queries, the result is a RDF craft and.",
            "When we want to compare RDF graphs, we have the problem of graph is amorphism and there is currently or.",
            "The biggest problem is there to cope with blank nodes.",
            "So to name these blank nodes probably so their recent research has been done there by Hogan.",
            "So it seems that he has a solution for that.",
            "Not sure, but at least he showed that this problem is not so worse as everybody think cause at the moment we are not sure whether it's solvable in Poland or middle time.",
            "Ann and 3rd for select queries.",
            "The result set is variables and bindings, so solution bindings there.",
            "The current solution would be to use the general arc API, though they have a comparison, but that only delivers whether the results it is the same or not and they don't tell us what's actually changed.",
            "So to get there actually change but also the library does internally is would be to transform that.",
            "Resides at two RDF and then we have again the problem of graphics is the morphisms."
        ],
        [
            "And the third research problem we identified is the scheduling.",
            "So what is the best time to at which irrelevant data change has occurred?",
            "So there our proposal would be either to use a data set, descriptions like Void, where we have the modification date.",
            "We also could sense or updates from the publisher so that the publisher notify or makes notifications about that he changed the data.",
            "But we have this.",
            "For example, DB pedia life, where we have updates every minute.",
            "We also know what changed, but still it's not trivial to know which spark queries are affected by that.",
            "And we also could estimate update intervals as this is also done by web crawlers."
        ],
        [
            "4th research problem was how can we identify equals sparkle queries.",
            "So there is currently research in Spark Sparkle caching especially and typical solutions are either on the syntactical level.",
            "Which is usually used by Levenstein similarity.",
            "But actually leaving so string similarity has nothing to do with semantic similarity, especially in the first part of the queries.",
            "And for structure occurs similarity there.",
            "Of these algorithms, they build pattern trees and check for equivalence or containment."
        ],
        [
            "And last research question was.",
            "How how we can describe these changes so that users can users know what has changed and therefore we also would propose to write the Sparkle resultset as RDF and then expresses as RDF change, and for that we have vocabularies like changes change sets to graph update Ontology or RDF path Patch."
        ],
        [
            "OK, so as a conclusion what we did is we put up requirements for real sparkle push service.",
            "We identified the issues which lead to nontrivial research problems and we somehow learned that.",
            "The regarding performance and scalability.",
            "There might not be one solution, so it's also a tradeoff for some data set, you should use that approach.",
            "For other datasets, you should use another OK."
        ],
        [
            "That's it, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome to my talk about towards Link data update notifications.",
                    "label": 1
                },
                {
                    "sent": "Reviewing and generating the sparkle push approach.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with people I met last year on the Web Intelligence Summer School.",
                    "label": 0
                },
                {
                    "sent": "In some ITN, it's with dinners ready, Anastasia Dimou.",
                    "label": 0
                },
                {
                    "sent": "So how about that?",
                    "label": 0
                },
                {
                    "sent": "Ian George Castrey knickers.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "My talk is about.",
                    "label": 0
                },
                {
                    "sent": "Update notifications in linked data, so I will first give you the motivation was actually didn't motivation for that.",
                    "label": 0
                },
                {
                    "sent": "And then I will.",
                    "label": 0
                },
                {
                    "sent": "Presented the actual idea that we found already exists and tell you about the shortcomings that we identified there.",
                    "label": 0
                },
                {
                    "sent": "Later on I will tell you about research problems were identified from this implementation or from this approach and the requirements we put on that.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the actually motivation behind that idea that we identified in this summer school worse.",
                    "label": 0
                },
                {
                    "sent": "How can data consumers be supported when they are working with linked data that changes, so we all know the problem when we have a data set that is published by a consumer and know that is published by the publisher and the consumer uses these data set, but at some point the data set changes so it would be a nice.",
                    "label": 1
                },
                {
                    "sent": "Feature when the consumer gets notified about changes or and especially about changes that he is interested in so that he can later on re consume this data and also re process.",
                    "label": 0
                },
                {
                    "sent": "So in his workflow.",
                    "label": 0
                },
                {
                    "sent": "So that was actually the idea we had for this summer school Heckert.",
                    "label": 0
                },
                {
                    "sent": "And then we realized.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we thought about it and then we realized, oh, there's been a publication in 2010 by Alexandra Person.",
                    "label": 0
                },
                {
                    "sent": "It's called the sparkle push, so the idea behind bucket pushes pretty pretty cool.",
                    "label": 0
                },
                {
                    "sent": "So we really don't want to bash it so, but we think it's really a nice idea because we had the same.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that the consumer, when he wants to get notified, get notifications about updates.",
                    "label": 0
                },
                {
                    "sent": "He registers his.",
                    "label": 0
                },
                {
                    "sent": "Particular sparkle query for a data set at this park and push service and as soon as the result for this sparkle query changes, he gets notified by this sparkle push server.",
                    "label": 0
                },
                {
                    "sent": "The idea behind Block pushes that this happens with pub sub hubbub and Additionally these changes are also tracked in RSS feed.",
                    "label": 0
                },
                {
                    "sent": "So that you can see all the changes in history.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's actually what we want to have.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we analyzed this sparkle push implementation plan and then we found out it's not very generalizable, so it's actually intended to be used for microblogging applications and the authors or the programmers.",
                    "label": 1
                },
                {
                    "sent": "They put some quite hot restrictions on the sparkle queries, for example, so they only support select queries.",
                    "label": 0
                },
                {
                    "sent": "No ask, describe, or construct they.",
                    "label": 1
                },
                {
                    "sent": "Need to have the UI and date variables in the select phrase and Additionally mandatorily they you can have the label and author variable there, nothing else so that really restricts your queries.",
                    "label": 0
                },
                {
                    "sent": "What they also did.",
                    "label": 0
                },
                {
                    "sent": "They used the latest date in the result set to identify whether there was a change so they do not really compare this Parker site they just look at the latest date.",
                    "label": 0
                },
                {
                    "sent": "And they only allow updates happening via this interface.",
                    "label": 0
                },
                {
                    "sent": "This bucket push interface, so there are no other possibilities to put updates in the data set.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, but we had other requirements.",
                    "label": 0
                },
                {
                    "sent": "So we put up the other requirements.",
                    "label": 0
                },
                {
                    "sent": "For example, what we want to have is we want to process arbitrary sparkle queries because we think it's really important that users can express their information need in a way they want, so they express their information if they have.",
                    "label": 0
                },
                {
                    "sent": "The second requirement was that this service should work on any sparkle endpoint, so with any data set.",
                    "label": 1
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "The third one was that we don't want to put unnecessary load on the sparkle interfaces, so becausw querying is very expensive and we don't want to denial the service of the public endpoints.",
                    "label": 1
                },
                {
                    "sent": "And we also think it's necessary to express this.",
                    "label": 0
                },
                {
                    "sent": "The change descriptions of these.",
                    "label": 0
                },
                {
                    "sent": "To express the descriptions of these changes sufficiently that the user can decide, does this change really?",
                    "label": 0
                },
                {
                    "sent": "In fact, or affect me or not.",
                    "label": 0
                },
                {
                    "sent": "So from these requirements, we then identified that are actually some hard problems in there and we identified.",
                    "label": 0
                },
                {
                    "sent": "Research problems that are currently not really solved.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first problem with Spark queries is that the results that can be really really large.",
                    "label": 0
                },
                {
                    "sent": "For example, if you ask in DB pedia for the redir data set so just all pages which redirect to another page, you get several gigabytes of data back.",
                    "label": 0
                },
                {
                    "sent": "So one problem there is of course and that usually triple stores or sparkle endpoints, they do not give you all the data, they have a limit of 10,000 lines for example, and then they stop.",
                    "label": 0
                },
                {
                    "sent": "So you can circumvent it by pagination, for example, but in the end it's still a lot of data that you have to 1st transmit, and Secondly you have to store it for the comparison with the next result.",
                    "label": 0
                },
                {
                    "sent": "So we propose in our paper some solutions how you can cope with that.",
                    "label": 0
                },
                {
                    "sent": "One solution would be aggregation, so we could for example rewrite the select queries and then we just take the number of results.",
                    "label": 0
                },
                {
                    "sent": "So we get the number of solutions, so we have a very smaller resultset, but it's somehow incomplete, so we just recognize if something has been added or something has been deleted, but we don't know when something's changed.",
                    "label": 0
                },
                {
                    "sent": "Another possibility would be to hash the result set so we have less memory to store, but still we have all the data transfer over the net.",
                    "label": 0
                },
                {
                    "sent": "And a third possibility we thought about using triple fragment servers.",
                    "label": 0
                },
                {
                    "sent": "There we can start.",
                    "label": 0
                },
                {
                    "sent": "We thought we can somehow apply this or use this streaming functionality so we can detect changes without retrieving the full results.",
                    "label": 1
                },
                {
                    "sent": "Nevertheless, we might retrieve the full result to compare it with the next iteration.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second research problem we identified is the comparison of Sparkle Resultsets.",
                    "label": 1
                },
                {
                    "sent": "So the research question we put there is how can sparkle results be efficiently and effectively compared so we have one for ask queries.",
                    "label": 1
                },
                {
                    "sent": "It's pretty similar.",
                    "label": 1
                },
                {
                    "sent": "We have true or faults.",
                    "label": 1
                },
                {
                    "sent": "So for describing construct queries, the result is a RDF craft and.",
                    "label": 0
                },
                {
                    "sent": "When we want to compare RDF graphs, we have the problem of graph is amorphism and there is currently or.",
                    "label": 0
                },
                {
                    "sent": "The biggest problem is there to cope with blank nodes.",
                    "label": 1
                },
                {
                    "sent": "So to name these blank nodes probably so their recent research has been done there by Hogan.",
                    "label": 1
                },
                {
                    "sent": "So it seems that he has a solution for that.",
                    "label": 0
                },
                {
                    "sent": "Not sure, but at least he showed that this problem is not so worse as everybody think cause at the moment we are not sure whether it's solvable in Poland or middle time.",
                    "label": 0
                },
                {
                    "sent": "Ann and 3rd for select queries.",
                    "label": 0
                },
                {
                    "sent": "The result set is variables and bindings, so solution bindings there.",
                    "label": 0
                },
                {
                    "sent": "The current solution would be to use the general arc API, though they have a comparison, but that only delivers whether the results it is the same or not and they don't tell us what's actually changed.",
                    "label": 0
                },
                {
                    "sent": "So to get there actually change but also the library does internally is would be to transform that.",
                    "label": 0
                },
                {
                    "sent": "Resides at two RDF and then we have again the problem of graphics is the morphisms.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the third research problem we identified is the scheduling.",
                    "label": 1
                },
                {
                    "sent": "So what is the best time to at which irrelevant data change has occurred?",
                    "label": 1
                },
                {
                    "sent": "So there our proposal would be either to use a data set, descriptions like Void, where we have the modification date.",
                    "label": 0
                },
                {
                    "sent": "We also could sense or updates from the publisher so that the publisher notify or makes notifications about that he changed the data.",
                    "label": 0
                },
                {
                    "sent": "But we have this.",
                    "label": 0
                },
                {
                    "sent": "For example, DB pedia life, where we have updates every minute.",
                    "label": 1
                },
                {
                    "sent": "We also know what changed, but still it's not trivial to know which spark queries are affected by that.",
                    "label": 0
                },
                {
                    "sent": "And we also could estimate update intervals as this is also done by web crawlers.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "4th research problem was how can we identify equals sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "So there is currently research in Spark Sparkle caching especially and typical solutions are either on the syntactical level.",
                    "label": 0
                },
                {
                    "sent": "Which is usually used by Levenstein similarity.",
                    "label": 0
                },
                {
                    "sent": "But actually leaving so string similarity has nothing to do with semantic similarity, especially in the first part of the queries.",
                    "label": 0
                },
                {
                    "sent": "And for structure occurs similarity there.",
                    "label": 0
                },
                {
                    "sent": "Of these algorithms, they build pattern trees and check for equivalence or containment.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And last research question was.",
                    "label": 0
                },
                {
                    "sent": "How how we can describe these changes so that users can users know what has changed and therefore we also would propose to write the Sparkle resultset as RDF and then expresses as RDF change, and for that we have vocabularies like changes change sets to graph update Ontology or RDF path Patch.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so as a conclusion what we did is we put up requirements for real sparkle push service.",
                    "label": 0
                },
                {
                    "sent": "We identified the issues which lead to nontrivial research problems and we somehow learned that.",
                    "label": 0
                },
                {
                    "sent": "The regarding performance and scalability.",
                    "label": 1
                },
                {
                    "sent": "There might not be one solution, so it's also a tradeoff for some data set, you should use that approach.",
                    "label": 0
                },
                {
                    "sent": "For other datasets, you should use another OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, thank you.",
                    "label": 0
                }
            ]
        }
    }
}