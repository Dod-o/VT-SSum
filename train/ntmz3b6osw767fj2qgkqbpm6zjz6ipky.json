{
    "id": "ntmz3b6osw767fj2qgkqbpm6zjz6ipky",
    "title": "Dynamic Ranked Retrieval",
    "info": {
        "author": [
            "Thorsten Joachims, Department of Computer Science, Cornell University"
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_joachims_drr/",
    "segmentation": [
        [
            "So this is joint work with my students.",
            "Christy Brandy from you and Jacob Bank, all of which are too busy to actually come here.",
            "So I have to give the talk."
        ],
        [
            "So this talk is about querying ambiguous queries and how to handle them.",
            "I think most queries are biggest at some level, but let's pick one of my favorite examples, which is the query SVM.",
            "Probably most people have the intent of the machine learning method, support vector machines for this query, so there will probably be quite happy with the ranking that's presented.",
            "The Left 6 results relevant for support vector machines.",
            "But there are other intents for this query.",
            "So for example there is the company ServiceMaster which has SVM as a stock ticker symbol.",
            "Their Society of vascular medicine.",
            "So some fraction of users is going to be actually very unhappy with this ranking.",
            "Get zero utility out of it.",
            "So of course been realized and.",
            "Instead of focusing on one intent, you would probably want to present a diversified ranking.",
            "So for example, in the extreme case here, there's one relevant result for each possible intent for this query.",
            "Now that makes everybody a little bit happy.",
            "Nobody has zero utility, but nobody is real happy with this ranking either.",
            "For example, the majority intent support vector machine shows as this one Wikipedia page to it.",
            "Now the question is, can we get out of this kind of resource constraint?",
            "I mean, if you just stick with this model, there's really no way of you know resolving this inherent.",
            "Tradeoff between depth and and coverage.",
            "So what we want to try to do here is kind of change the rules of the game a little bit to make everybody."
        ],
        [
            "So here's the basic idea.",
            "We call this dynamic ranking and the key idea is that we allow some interactivity.",
            "So for example, we present this diversified ranking first and then we see that the user may be allowed to allow the user to click on this icon or just hover over this link.",
            "And what happens is this link gets expanded and additional results that are conditionally relevant get inserted here.",
            "Maybe the same thing happens again for this SVM light link.",
            "More results get inserted.",
            "So what happened here?",
            "What actually happened is that the user constructed his or her own ranking interactively, right?",
            "So we can think about this as being the ranking now.",
            "So we went from one relevant result for S for support vector machines in the top five to four relevant results.",
            "And if the user had a different, maybe the the company ServiceMaster would have.",
            "Contracts are different ranking by expanding different links.",
            "So the way you can reason about this now is that the search engine no longer has just a single static ranking, but that there is a whole tree of possible ways the user can explore the ranking.",
            "So for example for ServiceMaster the user may have expanded the first link and kind of ended up in this tree down here.",
            "So let's formula."
        ],
        [
            "That a little bit more and get to a decision theoretic model.",
            "So as I said, we have these dynamic ranking trees which are now kind of replacing this individual single static ranking.",
            "We have a distribution of user intents could be an infinite number.",
            "And you can think about this as just a rating.",
            "Vectors that are different for different intents for all documents in the collection.",
            "Then we have to specify what our user behaviors and we say we have a policy Pi that takes a relevance vector U for the particular intent.",
            "One of these dynamic ranking trees and produces a path through this tree Sigma.",
            "So if we have K intents and a deterministic policy, we would get K path.",
            "Every intent takes a different path, could have a stochastic policy.",
            "Then we have distributions over path.",
            "Here for the simplicity of the talk I'm just going to think it's.",
            "Ministik then each of these paths no is essentially just a ranking right that the user constructed so we can score these rankings by some utility measure and that can really be your your favorite ranked retrieval measure, right?",
            "So ECG and ECG, whatever.",
            "And then we can reason about the utility of a complete ranking tree as the expectation over all intents.",
            "And if you have a degenerate tree, which kind of has the same document on each level, essentially producing a ranking, then this is the same as these attentive measures by aggrawal.",
            "So it's a generalization of that."
        ],
        [
            "OK, so let's go through an example.",
            "So let's say we have five different user intents, bunch of documents here and here are the relevance ratings for the various documents.",
            "Let's take DCG.",
            "As our performance measure, we have that here and very simple user behavior policy.",
            "A user expands a document if it's relevant, otherwise skips over.",
            "So what happens for the first user here?",
            "User things D1 is relevant so expensive.",
            "Do two is relevant, so expensive to three so this user gets all this is relevant documents in the top three position.",
            "Great DCG of 2.1 three if you put it into the formula.",
            "Second user do you want is relevant goes here.",
            "D2 is not relevant.",
            "Skips it takes this past DCG.",
            "1.9 three of this path and so on for the third user.",
            "Takes the red route.",
            "4th user goes this way.",
            "5th user goes that way so they all take different paths and get different rankings.",
            "Now we can take the expected utility if assuming that there are uniformly distributed.",
            "For example, you get an expectedly of this tree of 1.5.",
            "Two.",
            "Now compare that to the utility or the DCG of the single best ranking that we could have presented.",
            "So if you had presented a static ranking like in a conventional retrieval system, which would be putting D1 and D7 to the top and then the other documents below that.",
            "That would have given us a DCG of oh point 8 four, so potentially by being dynamic and adaptive you can gain a lot of retrieval performance.",
            "The key question now becomes, how do we actually compute these trees?",
            "How do we compute which document to put in each node of this tree?"
        ],
        [
            "So before we get into the details, let's for the simplicity of the talk and the theoretical arguments.",
            "Results later, let's focus on a subset of performance measures, which is called modular utility functions, and these model utility functions are essentially that we take the sum of the document utilities discounted by some factor depending on how far down the ranking we're going.",
            "So, for example, DCG fits into this right?",
            "We just have the one over lock.",
            "Accounts here N DCG fits into this position at K. Fits into this right.",
            "One that doesn't fit just average position.",
            "So."
        ],
        [
            "Before we get to constructing trees, let's first think about how would we actually construct a single static ranking, I mean.",
            "We have no multiple intents for each for each query, and it's not entirely clear how we do that right.",
            "Let's take the simplest approach.",
            "Instead of considering all of these different intents, let's just take the marginal probability of relevance over all of these intents.",
            "So this was the probability of an intent.",
            "This was the conditional relevance based based on the intent.",
            "So let's just marginalized out the intents and we get a probability of relevance for each document.",
            "And then just sort the documents just like probability ranking principle, sort them by this conditional probability of relevance.",
            "Sounds like a reasonable algorithm, so and it actually turns out that for these we call this algorithm static.",
            "Myopic because it's just greedily adds the next document, the list, and for model utility functions we show in the paper that static myopic is actually optimal.",
            "Approves is the optimal ranking in terms of retrieval performance.",
            "It's actually not optimal for general utility functions.",
            "For example, for average precision and multiple intents, this is no longer the optimal algorithm, so it's different from the single intent kind of normal probability ranking principle."
        ],
        [
            "OK, but we were interested in dynamic ranking trees, right?",
            "So how do we construct those so we have two algorithms, one we call dynamic myopic?",
            "And let's say we already have constructed the blue part of this tree, and now we want to add this node in red here.",
            "Which document should be put there?",
            "So what dynamic myopic does is?",
            "It takes the conditional probability of relevance.",
            "Now, if you think about it to get to this note, user must have expanded.",
            "This document expanded document three to get down here.",
            "That means we have a more specific distribution of users that actually makes it to this node.",
            "And so we put the document here that conditioned on these actions actually has the highest probability of relevance.",
            "Or more generally, if you have non binary relevance judgment, the highest conditional utility.",
            "Very simple and efficient algorithm.",
            "One thing that bugged us about this algorithm is that it's, well, it's very myopic.",
            "It actually doesn't take into account how well D will partition my users.",
            "Further right so that the better I partition my users by their different intents, the more specific and I make the results at each of the sub trees right in the szczepanik."
        ],
        [
            "Spanned subtree so that's.",
            "One reason why we came with this algorithm algorithm dynamic look ahead what that algorithm does is it takes into account.",
            "What's the utility that I can gain in the left subtree and the utility in the right subtree.",
            "So if I partition my users well, these utilities are going to be high.",
            "Because they're going to be single intent.",
            "In the extreme case, so we consider this conditional distribution.",
            "If the user skips or conditional distribution with the user expands this document that we put here.",
            "Since we can't compute the exact utilities of each of the subtrees, we lower bounded with the utility of the optimal static ranking and we can show that that's a lower bound.",
            "So what we optimize in dynamic look ahead is the sum of this lower bound on the utility of the complete subtree.",
            "If you put document D in the root here.",
            "OK."
        ],
        [
            "Now the key question is this dynamic rankings constructed by these algorithms?",
            "How do they stack up against a single static ranking and we define the adaptivity gain as?",
            "The utility of other retrieval performance of a dynamic ranking algorithm A compared to the retrieval performance of static, myopic and remember static myopic is optimal for these module utility measures.",
            "We were able to show is that both our algorithms, dynamic, myopic and dynamic look ahead are guaranteed to always have a non negative adaptivity gain for model utility functions, meaning that we never do worse than presenting the optimal static ranking.",
            "So that's nice.",
            "It's somewhat reassuring we can't actually get any worse.",
            "But since it's a tight bound so there are, you can construct adversarial cases where they actually they are equal.",
            "So how much they obey the activity gains in practice is really an empirical question, and we're going to get to that in a second."
        ],
        [
            "But let me step back a little bit and kind of give a overview of how this fits into the bigger picture.",
            "So clearly what we've presented here is an interactive retrieval model.",
            "And it's actually a lot like the interface a lot like surfcanyon.com if you.",
            "If you've seen that, I think the methods are different, but the interface is similar.",
            "We focus on a very simple interactive retrieval model, much simpler than most academic systems, particularly in close to menu browsing, and also to ranked retrieval as people know it.",
            "So to make a transition very easy.",
            "And since it's simple, our decision theoretic model is more specific and also more tractable in terms of that, be able to prove results and guide algorithms, design, then general models of interactive retrieval.",
            "It's also a form of relevance feedback, right?",
            "And whenever you skip or you expand result, you essentially giving feedback.",
            "But it's a very tight integration between this feedback mechanism and the presentation of the results, right?",
            "Essentially, you keep this tree.",
            "And that allows you to keep state.",
            "It's not like most.",
            "Relevance feedback systems where you kind of reformulate the query and they get a new set of 10 results.",
            "So that's what we mean by keeping state.",
            "Because you're kind of just like in the menu and you can back up again if you want to.",
            "And I think very importantly, it's a model that allows you to not only kind of.",
            "Take passively take training examples, but it also needs to.",
            "Let's see reason about.",
            "You know what document should I put here so that if I get feedback on it, it will actually give me a lot of information.",
            "So it's an exploration exploitation model and it accounts for that.",
            "And finally, if you think about the left branch of our tree, this skip skip Skip tree is actually very similar to the channel cargo model for diversification.",
            "You know what should I put in the second position?",
            "If in the first position the people are the person skip the result?",
            "What should I put in the third position if the 1st two got skipped and so on."
        ],
        [
            "Good, so let's talk about some empirical results so it experiments on two collections, the web track and interactive track from from track.",
            "All of them are labeled by multiple intents, so it several different relevance profiles for each query according to which intended one."
        ],
        [
            "So here are the results in the.",
            "Very basic case, so we assume that we have that the algorithm actually has access to the correct relevance profiles, so it can compute all of these conditional probabilities that it needs to compute exactly, and that user behavior is deterministic, so users will always expand relevant documents to take a right take the right branch in the tree and always skip non relevant documents.",
            "Take the left branch of the tree.",
            "Yeah, the results for Weapon Interactive for precision at 10, Everett, position, DCG and NDC G. The black bar here is static, myopic and remember for the modular utility functions or retrieval measures this is the best ranking that you can possibly produce.",
            "Dynamic market congre endemic.",
            "Look ahead in white.",
            "What you can see is that the adaptivity gain for all measures and all the experiments actually quite substantial.",
            "So if you look for example at N DCG, here it goes from something like 55% to 70%.",
            "And this is compared to the optimal static ranking, right?",
            "I mean if you think about it, how much effort search engines are spending to get 1% improvement in NDC G?",
            "This is a lot.",
            "Potentially really kind of change that upper bound of how good you can get with a single ranking.",
            "One thing that surprised us is that actually the lookahead and myopic algorithm for dynamic ranking perform almost the same, and I can talk to you offline for why this look ahead doesn't actually help."
        ],
        [
            "Let's relax this assumption that gives us behaved deterministically.",
            "That's clearly not the case, so let's say let's allow users to be stochastic.",
            "So let's say that users there's some probability epsilon that uses Skipper relevant result, and similarly that they expand and non relevant result.",
            "And then you can.",
            "We can vary this probability this noise probability from zero all the way to oh point 5 complete noise, right?",
            "What you can see in in these plots here is that even if you have pretty high noise levels, the adaptivity gain is still quite substantial.",
            "So this is the performance of static myopic, so the optimal single ranking.",
            "So Even so, since the model or the performance degrades gracefully."
        ],
        [
            "And finally, let's look at at the question of.",
            "Well, what if you don't actually have access to the probabilities, but we would have to approximate them somewhere.",
            "If you look at the algorithm, really the only thing that you need is these conditional distributions of relevance.",
            "So how likely is it that D document D is relevant?",
            "Give 4 bit ticular query QQ given have the prefix of actions in the tree kind of skips and and expands in the tree.",
            "My wife just down here in this experiment is who trained a logistic regression model to fit these these conditional distributions and you pick the feature as well.",
            "Notice the model document document relationships.",
            "You can see that even worse, these approximate distributions.",
            "You still have quite an ad activity game."
        ],
        [
            "OK, so let me conclude.",
            "So what we presented was a very simple interactive retrieval model which combines.",
            "Diversity and recall, which were kind of in the static ranking model opposing.",
            "We purposely went for an evolution of the user interface, not a revolution.",
            "So in particular, the first set of results that you get is just this left branch of the tree, and that's just a nice diversified ranking.",
            "So even if the user never expands anything, I just get some nicely diversified ranking, so it's kind of a nice fall back position.",
            "And I think it's we conjecture that it's easy for users to understand, because it actually resembles menu browsing.",
            "On top of this kind of conventional rank retrieval.",
            "We present a theoretical model which is concise enough to, you know, provide a prescription for how to evaluate this quantitatively and reason about the quantity to design algorithms and also prove theoretical results presented two efficient algorithms that we prove have nonnegative adaptivity gain for modular performance measures, and if you're interested in an implementation of these algorithms, you can download it from our website, but I'm most excited about is.",
            "The directions of research that this opens up kind of a machine learning perspective constructing these dynamic ranking trees is actually like a partial information online learning problem like a bandit problem or a variant of the bandits problem, so there's probably some interesting algorithmic inside an approximation algorithms for constructing these trees that are better than the algorithms that we have right now.",
            "I think particularly intriguing is the idea of these conditional distributions of relevance.",
            "I think we can actually train those based on click data from session based click data, right all that you need to know is oh, user.",
            "Clicked or skipped.",
            "Particular other documents?",
            "What does this tell me about the relationship of the relevance of A of another document so we could potentially play train that in big amounts of excess data?",
            "There's a lot of room for coming up is more sophisticated user behavioral policy's additional actions beyond skip and click.",
            "So we get ternary trees that way potentially, and there's a lot of interesting questions in usability of this method.",
            "I mean, how should we actually layout the results that was presented here was just one way you could do it.",
            "There are many other ways.",
            "And kind of, how do we actually want users to interact clicking mousing and how easy it is for users to understand?",
            "Alright, thank you.",
            "We have time for questions.",
            "Andrew.",
            "Did you?",
            "Did you have a sense, either empirically or theoretically, of what kind of loss there might be compared to the brute force algorithm?",
            "No so.",
            "We tried to find approximation algorithms where within approximation factor guarantee.",
            "And that turned out to be tricky so far, so we left that for future work and we didn't actually do the exhaustive enumeration.",
            "I guess for something like.",
            "A depth of five or so we could actually do it.",
            "I think that, yeah, that would be an interesting question.",
            "My gut feeling is that these algorithms are actually in practice tend to work quite well.",
            "So I'm not sure how much of a gap there is towards optimal, so I have a question related to that.",
            "In the resource the myopic was identical to the other going right to the look ahead.",
            "So the look ahead has this additional kind of factor N complexity and it doesn't seem to be worth it right there, there's actually.",
            "The problem is that we are approximating the utility of the subtrees by the utilities of the of the static ranking, which is a lower bound, but it's a bad lower bound and it's actually so bad that it.",
            "Helps just as much as it hurts in other cases basically.",
            "So I think towards the design of a better algorithm would be to actually look at how can we better lower bound the utility of the subject.",
            "Papa yes if I compare it with, let's say clustering algorithms, very cluster, different intents.",
            "Usually cluster formations have errors.",
            "That means there are things that are supposed to be in one cluster because of various metrics or shapes.",
            "They get clustered into the wrong cluster, right?",
            "So where does that fit in here?",
            "Because here you're assuming the intent are all partitions of the space, and it's very clear that which intent each document falls into.",
            "So I think one of the big advantages of this approach is that you don't have to commit to a clustering or something like that, right?",
            "So there's there's never a step where you discretely kind of cluster things together and call it an intent.",
            "Really, and nowhere in this model intent explicitly occurs.",
            "It just kind of encoded in this conditional probabilities of relevance so that you never have to make this kind of hard commitment to an intent which you probably get wrong quite often, and this one following is that Canada document end up in two different intercluster.",
            "Yeah, it can appear in multiple places in the tree, definitely.",
            "Very quick question on the on the interaction so when you click the will expand.",
            "You will see the document.",
            "So really I'm being kind of fuzzy about what the right model is in terms of usability.",
            "I would think that you know something like I just mouse over that result or I maybe click these this little icon there.",
            "That's actually the Surf Canyon icon.",
            "That's how they do it, but I think that's actually way too small and too awkward to hit.",
            "But maybe if I just mouse over it just like I have like the instant previews in Google or Bing, right?",
            "That this would expand the result doesn't have to be expanded like this.",
            "It could be in different ranking to the side that gets inserted there many, many different ways.",
            "How one could do it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is joint work with my students.",
                    "label": 0
                },
                {
                    "sent": "Christy Brandy from you and Jacob Bank, all of which are too busy to actually come here.",
                    "label": 1
                },
                {
                    "sent": "So I have to give the talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this talk is about querying ambiguous queries and how to handle them.",
                    "label": 0
                },
                {
                    "sent": "I think most queries are biggest at some level, but let's pick one of my favorite examples, which is the query SVM.",
                    "label": 0
                },
                {
                    "sent": "Probably most people have the intent of the machine learning method, support vector machines for this query, so there will probably be quite happy with the ranking that's presented.",
                    "label": 0
                },
                {
                    "sent": "The Left 6 results relevant for support vector machines.",
                    "label": 0
                },
                {
                    "sent": "But there are other intents for this query.",
                    "label": 0
                },
                {
                    "sent": "So for example there is the company ServiceMaster which has SVM as a stock ticker symbol.",
                    "label": 0
                },
                {
                    "sent": "Their Society of vascular medicine.",
                    "label": 0
                },
                {
                    "sent": "So some fraction of users is going to be actually very unhappy with this ranking.",
                    "label": 0
                },
                {
                    "sent": "Get zero utility out of it.",
                    "label": 0
                },
                {
                    "sent": "So of course been realized and.",
                    "label": 0
                },
                {
                    "sent": "Instead of focusing on one intent, you would probably want to present a diversified ranking.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the extreme case here, there's one relevant result for each possible intent for this query.",
                    "label": 0
                },
                {
                    "sent": "Now that makes everybody a little bit happy.",
                    "label": 0
                },
                {
                    "sent": "Nobody has zero utility, but nobody is real happy with this ranking either.",
                    "label": 0
                },
                {
                    "sent": "For example, the majority intent support vector machine shows as this one Wikipedia page to it.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, can we get out of this kind of resource constraint?",
                    "label": 0
                },
                {
                    "sent": "I mean, if you just stick with this model, there's really no way of you know resolving this inherent.",
                    "label": 0
                },
                {
                    "sent": "Tradeoff between depth and and coverage.",
                    "label": 0
                },
                {
                    "sent": "So what we want to try to do here is kind of change the rules of the game a little bit to make everybody.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "We call this dynamic ranking and the key idea is that we allow some interactivity.",
                    "label": 1
                },
                {
                    "sent": "So for example, we present this diversified ranking first and then we see that the user may be allowed to allow the user to click on this icon or just hover over this link.",
                    "label": 0
                },
                {
                    "sent": "And what happens is this link gets expanded and additional results that are conditionally relevant get inserted here.",
                    "label": 0
                },
                {
                    "sent": "Maybe the same thing happens again for this SVM light link.",
                    "label": 0
                },
                {
                    "sent": "More results get inserted.",
                    "label": 0
                },
                {
                    "sent": "So what happened here?",
                    "label": 0
                },
                {
                    "sent": "What actually happened is that the user constructed his or her own ranking interactively, right?",
                    "label": 0
                },
                {
                    "sent": "So we can think about this as being the ranking now.",
                    "label": 0
                },
                {
                    "sent": "So we went from one relevant result for S for support vector machines in the top five to four relevant results.",
                    "label": 0
                },
                {
                    "sent": "And if the user had a different, maybe the the company ServiceMaster would have.",
                    "label": 0
                },
                {
                    "sent": "Contracts are different ranking by expanding different links.",
                    "label": 0
                },
                {
                    "sent": "So the way you can reason about this now is that the search engine no longer has just a single static ranking, but that there is a whole tree of possible ways the user can explore the ranking.",
                    "label": 0
                },
                {
                    "sent": "So for example for ServiceMaster the user may have expanded the first link and kind of ended up in this tree down here.",
                    "label": 0
                },
                {
                    "sent": "So let's formula.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That a little bit more and get to a decision theoretic model.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we have these dynamic ranking trees which are now kind of replacing this individual single static ranking.",
                    "label": 0
                },
                {
                    "sent": "We have a distribution of user intents could be an infinite number.",
                    "label": 0
                },
                {
                    "sent": "And you can think about this as just a rating.",
                    "label": 0
                },
                {
                    "sent": "Vectors that are different for different intents for all documents in the collection.",
                    "label": 0
                },
                {
                    "sent": "Then we have to specify what our user behaviors and we say we have a policy Pi that takes a relevance vector U for the particular intent.",
                    "label": 0
                },
                {
                    "sent": "One of these dynamic ranking trees and produces a path through this tree Sigma.",
                    "label": 0
                },
                {
                    "sent": "So if we have K intents and a deterministic policy, we would get K path.",
                    "label": 0
                },
                {
                    "sent": "Every intent takes a different path, could have a stochastic policy.",
                    "label": 0
                },
                {
                    "sent": "Then we have distributions over path.",
                    "label": 0
                },
                {
                    "sent": "Here for the simplicity of the talk I'm just going to think it's.",
                    "label": 0
                },
                {
                    "sent": "Ministik then each of these paths no is essentially just a ranking right that the user constructed so we can score these rankings by some utility measure and that can really be your your favorite ranked retrieval measure, right?",
                    "label": 0
                },
                {
                    "sent": "So ECG and ECG, whatever.",
                    "label": 0
                },
                {
                    "sent": "And then we can reason about the utility of a complete ranking tree as the expectation over all intents.",
                    "label": 0
                },
                {
                    "sent": "And if you have a degenerate tree, which kind of has the same document on each level, essentially producing a ranking, then this is the same as these attentive measures by aggrawal.",
                    "label": 0
                },
                {
                    "sent": "So it's a generalization of that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's go through an example.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have five different user intents, bunch of documents here and here are the relevance ratings for the various documents.",
                    "label": 0
                },
                {
                    "sent": "Let's take DCG.",
                    "label": 0
                },
                {
                    "sent": "As our performance measure, we have that here and very simple user behavior policy.",
                    "label": 0
                },
                {
                    "sent": "A user expands a document if it's relevant, otherwise skips over.",
                    "label": 0
                },
                {
                    "sent": "So what happens for the first user here?",
                    "label": 0
                },
                {
                    "sent": "User things D1 is relevant so expensive.",
                    "label": 0
                },
                {
                    "sent": "Do two is relevant, so expensive to three so this user gets all this is relevant documents in the top three position.",
                    "label": 0
                },
                {
                    "sent": "Great DCG of 2.1 three if you put it into the formula.",
                    "label": 0
                },
                {
                    "sent": "Second user do you want is relevant goes here.",
                    "label": 0
                },
                {
                    "sent": "D2 is not relevant.",
                    "label": 0
                },
                {
                    "sent": "Skips it takes this past DCG.",
                    "label": 0
                },
                {
                    "sent": "1.9 three of this path and so on for the third user.",
                    "label": 0
                },
                {
                    "sent": "Takes the red route.",
                    "label": 0
                },
                {
                    "sent": "4th user goes this way.",
                    "label": 0
                },
                {
                    "sent": "5th user goes that way so they all take different paths and get different rankings.",
                    "label": 0
                },
                {
                    "sent": "Now we can take the expected utility if assuming that there are uniformly distributed.",
                    "label": 0
                },
                {
                    "sent": "For example, you get an expectedly of this tree of 1.5.",
                    "label": 0
                },
                {
                    "sent": "Two.",
                    "label": 0
                },
                {
                    "sent": "Now compare that to the utility or the DCG of the single best ranking that we could have presented.",
                    "label": 0
                },
                {
                    "sent": "So if you had presented a static ranking like in a conventional retrieval system, which would be putting D1 and D7 to the top and then the other documents below that.",
                    "label": 0
                },
                {
                    "sent": "That would have given us a DCG of oh point 8 four, so potentially by being dynamic and adaptive you can gain a lot of retrieval performance.",
                    "label": 0
                },
                {
                    "sent": "The key question now becomes, how do we actually compute these trees?",
                    "label": 0
                },
                {
                    "sent": "How do we compute which document to put in each node of this tree?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before we get into the details, let's for the simplicity of the talk and the theoretical arguments.",
                    "label": 0
                },
                {
                    "sent": "Results later, let's focus on a subset of performance measures, which is called modular utility functions, and these model utility functions are essentially that we take the sum of the document utilities discounted by some factor depending on how far down the ranking we're going.",
                    "label": 0
                },
                {
                    "sent": "So, for example, DCG fits into this right?",
                    "label": 0
                },
                {
                    "sent": "We just have the one over lock.",
                    "label": 0
                },
                {
                    "sent": "Accounts here N DCG fits into this position at K. Fits into this right.",
                    "label": 0
                },
                {
                    "sent": "One that doesn't fit just average position.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before we get to constructing trees, let's first think about how would we actually construct a single static ranking, I mean.",
                    "label": 0
                },
                {
                    "sent": "We have no multiple intents for each for each query, and it's not entirely clear how we do that right.",
                    "label": 0
                },
                {
                    "sent": "Let's take the simplest approach.",
                    "label": 0
                },
                {
                    "sent": "Instead of considering all of these different intents, let's just take the marginal probability of relevance over all of these intents.",
                    "label": 0
                },
                {
                    "sent": "So this was the probability of an intent.",
                    "label": 0
                },
                {
                    "sent": "This was the conditional relevance based based on the intent.",
                    "label": 0
                },
                {
                    "sent": "So let's just marginalized out the intents and we get a probability of relevance for each document.",
                    "label": 0
                },
                {
                    "sent": "And then just sort the documents just like probability ranking principle, sort them by this conditional probability of relevance.",
                    "label": 0
                },
                {
                    "sent": "Sounds like a reasonable algorithm, so and it actually turns out that for these we call this algorithm static.",
                    "label": 0
                },
                {
                    "sent": "Myopic because it's just greedily adds the next document, the list, and for model utility functions we show in the paper that static myopic is actually optimal.",
                    "label": 0
                },
                {
                    "sent": "Approves is the optimal ranking in terms of retrieval performance.",
                    "label": 0
                },
                {
                    "sent": "It's actually not optimal for general utility functions.",
                    "label": 1
                },
                {
                    "sent": "For example, for average precision and multiple intents, this is no longer the optimal algorithm, so it's different from the single intent kind of normal probability ranking principle.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but we were interested in dynamic ranking trees, right?",
                    "label": 1
                },
                {
                    "sent": "So how do we construct those so we have two algorithms, one we call dynamic myopic?",
                    "label": 0
                },
                {
                    "sent": "And let's say we already have constructed the blue part of this tree, and now we want to add this node in red here.",
                    "label": 0
                },
                {
                    "sent": "Which document should be put there?",
                    "label": 0
                },
                {
                    "sent": "So what dynamic myopic does is?",
                    "label": 0
                },
                {
                    "sent": "It takes the conditional probability of relevance.",
                    "label": 0
                },
                {
                    "sent": "Now, if you think about it to get to this note, user must have expanded.",
                    "label": 0
                },
                {
                    "sent": "This document expanded document three to get down here.",
                    "label": 0
                },
                {
                    "sent": "That means we have a more specific distribution of users that actually makes it to this node.",
                    "label": 1
                },
                {
                    "sent": "And so we put the document here that conditioned on these actions actually has the highest probability of relevance.",
                    "label": 0
                },
                {
                    "sent": "Or more generally, if you have non binary relevance judgment, the highest conditional utility.",
                    "label": 0
                },
                {
                    "sent": "Very simple and efficient algorithm.",
                    "label": 0
                },
                {
                    "sent": "One thing that bugged us about this algorithm is that it's, well, it's very myopic.",
                    "label": 0
                },
                {
                    "sent": "It actually doesn't take into account how well D will partition my users.",
                    "label": 0
                },
                {
                    "sent": "Further right so that the better I partition my users by their different intents, the more specific and I make the results at each of the sub trees right in the szczepanik.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Spanned subtree so that's.",
                    "label": 0
                },
                {
                    "sent": "One reason why we came with this algorithm algorithm dynamic look ahead what that algorithm does is it takes into account.",
                    "label": 0
                },
                {
                    "sent": "What's the utility that I can gain in the left subtree and the utility in the right subtree.",
                    "label": 1
                },
                {
                    "sent": "So if I partition my users well, these utilities are going to be high.",
                    "label": 0
                },
                {
                    "sent": "Because they're going to be single intent.",
                    "label": 0
                },
                {
                    "sent": "In the extreme case, so we consider this conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "If the user skips or conditional distribution with the user expands this document that we put here.",
                    "label": 0
                },
                {
                    "sent": "Since we can't compute the exact utilities of each of the subtrees, we lower bounded with the utility of the optimal static ranking and we can show that that's a lower bound.",
                    "label": 1
                },
                {
                    "sent": "So what we optimize in dynamic look ahead is the sum of this lower bound on the utility of the complete subtree.",
                    "label": 0
                },
                {
                    "sent": "If you put document D in the root here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the key question is this dynamic rankings constructed by these algorithms?",
                    "label": 0
                },
                {
                    "sent": "How do they stack up against a single static ranking and we define the adaptivity gain as?",
                    "label": 1
                },
                {
                    "sent": "The utility of other retrieval performance of a dynamic ranking algorithm A compared to the retrieval performance of static, myopic and remember static myopic is optimal for these module utility measures.",
                    "label": 1
                },
                {
                    "sent": "We were able to show is that both our algorithms, dynamic, myopic and dynamic look ahead are guaranteed to always have a non negative adaptivity gain for model utility functions, meaning that we never do worse than presenting the optimal static ranking.",
                    "label": 0
                },
                {
                    "sent": "So that's nice.",
                    "label": 0
                },
                {
                    "sent": "It's somewhat reassuring we can't actually get any worse.",
                    "label": 0
                },
                {
                    "sent": "But since it's a tight bound so there are, you can construct adversarial cases where they actually they are equal.",
                    "label": 0
                },
                {
                    "sent": "So how much they obey the activity gains in practice is really an empirical question, and we're going to get to that in a second.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But let me step back a little bit and kind of give a overview of how this fits into the bigger picture.",
                    "label": 0
                },
                {
                    "sent": "So clearly what we've presented here is an interactive retrieval model.",
                    "label": 0
                },
                {
                    "sent": "And it's actually a lot like the interface a lot like surfcanyon.com if you.",
                    "label": 1
                },
                {
                    "sent": "If you've seen that, I think the methods are different, but the interface is similar.",
                    "label": 0
                },
                {
                    "sent": "We focus on a very simple interactive retrieval model, much simpler than most academic systems, particularly in close to menu browsing, and also to ranked retrieval as people know it.",
                    "label": 0
                },
                {
                    "sent": "So to make a transition very easy.",
                    "label": 0
                },
                {
                    "sent": "And since it's simple, our decision theoretic model is more specific and also more tractable in terms of that, be able to prove results and guide algorithms, design, then general models of interactive retrieval.",
                    "label": 0
                },
                {
                    "sent": "It's also a form of relevance feedback, right?",
                    "label": 1
                },
                {
                    "sent": "And whenever you skip or you expand result, you essentially giving feedback.",
                    "label": 0
                },
                {
                    "sent": "But it's a very tight integration between this feedback mechanism and the presentation of the results, right?",
                    "label": 0
                },
                {
                    "sent": "Essentially, you keep this tree.",
                    "label": 0
                },
                {
                    "sent": "And that allows you to keep state.",
                    "label": 1
                },
                {
                    "sent": "It's not like most.",
                    "label": 0
                },
                {
                    "sent": "Relevance feedback systems where you kind of reformulate the query and they get a new set of 10 results.",
                    "label": 0
                },
                {
                    "sent": "So that's what we mean by keeping state.",
                    "label": 0
                },
                {
                    "sent": "Because you're kind of just like in the menu and you can back up again if you want to.",
                    "label": 0
                },
                {
                    "sent": "And I think very importantly, it's a model that allows you to not only kind of.",
                    "label": 0
                },
                {
                    "sent": "Take passively take training examples, but it also needs to.",
                    "label": 0
                },
                {
                    "sent": "Let's see reason about.",
                    "label": 0
                },
                {
                    "sent": "You know what document should I put here so that if I get feedback on it, it will actually give me a lot of information.",
                    "label": 0
                },
                {
                    "sent": "So it's an exploration exploitation model and it accounts for that.",
                    "label": 0
                },
                {
                    "sent": "And finally, if you think about the left branch of our tree, this skip skip Skip tree is actually very similar to the channel cargo model for diversification.",
                    "label": 1
                },
                {
                    "sent": "You know what should I put in the second position?",
                    "label": 0
                },
                {
                    "sent": "If in the first position the people are the person skip the result?",
                    "label": 0
                },
                {
                    "sent": "What should I put in the third position if the 1st two got skipped and so on.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good, so let's talk about some empirical results so it experiments on two collections, the web track and interactive track from from track.",
                    "label": 0
                },
                {
                    "sent": "All of them are labeled by multiple intents, so it several different relevance profiles for each query according to which intended one.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results in the.",
                    "label": 0
                },
                {
                    "sent": "Very basic case, so we assume that we have that the algorithm actually has access to the correct relevance profiles, so it can compute all of these conditional probabilities that it needs to compute exactly, and that user behavior is deterministic, so users will always expand relevant documents to take a right take the right branch in the tree and always skip non relevant documents.",
                    "label": 1
                },
                {
                    "sent": "Take the left branch of the tree.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the results for Weapon Interactive for precision at 10, Everett, position, DCG and NDC G. The black bar here is static, myopic and remember for the modular utility functions or retrieval measures this is the best ranking that you can possibly produce.",
                    "label": 0
                },
                {
                    "sent": "Dynamic market congre endemic.",
                    "label": 0
                },
                {
                    "sent": "Look ahead in white.",
                    "label": 1
                },
                {
                    "sent": "What you can see is that the adaptivity gain for all measures and all the experiments actually quite substantial.",
                    "label": 0
                },
                {
                    "sent": "So if you look for example at N DCG, here it goes from something like 55% to 70%.",
                    "label": 0
                },
                {
                    "sent": "And this is compared to the optimal static ranking, right?",
                    "label": 0
                },
                {
                    "sent": "I mean if you think about it, how much effort search engines are spending to get 1% improvement in NDC G?",
                    "label": 0
                },
                {
                    "sent": "This is a lot.",
                    "label": 0
                },
                {
                    "sent": "Potentially really kind of change that upper bound of how good you can get with a single ranking.",
                    "label": 0
                },
                {
                    "sent": "One thing that surprised us is that actually the lookahead and myopic algorithm for dynamic ranking perform almost the same, and I can talk to you offline for why this look ahead doesn't actually help.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's relax this assumption that gives us behaved deterministically.",
                    "label": 0
                },
                {
                    "sent": "That's clearly not the case, so let's say let's allow users to be stochastic.",
                    "label": 0
                },
                {
                    "sent": "So let's say that users there's some probability epsilon that uses Skipper relevant result, and similarly that they expand and non relevant result.",
                    "label": 0
                },
                {
                    "sent": "And then you can.",
                    "label": 0
                },
                {
                    "sent": "We can vary this probability this noise probability from zero all the way to oh point 5 complete noise, right?",
                    "label": 0
                },
                {
                    "sent": "What you can see in in these plots here is that even if you have pretty high noise levels, the adaptivity gain is still quite substantial.",
                    "label": 0
                },
                {
                    "sent": "So this is the performance of static myopic, so the optimal single ranking.",
                    "label": 0
                },
                {
                    "sent": "So Even so, since the model or the performance degrades gracefully.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, let's look at at the question of.",
                    "label": 0
                },
                {
                    "sent": "Well, what if you don't actually have access to the probabilities, but we would have to approximate them somewhere.",
                    "label": 0
                },
                {
                    "sent": "If you look at the algorithm, really the only thing that you need is these conditional distributions of relevance.",
                    "label": 0
                },
                {
                    "sent": "So how likely is it that D document D is relevant?",
                    "label": 0
                },
                {
                    "sent": "Give 4 bit ticular query QQ given have the prefix of actions in the tree kind of skips and and expands in the tree.",
                    "label": 0
                },
                {
                    "sent": "My wife just down here in this experiment is who trained a logistic regression model to fit these these conditional distributions and you pick the feature as well.",
                    "label": 0
                },
                {
                    "sent": "Notice the model document document relationships.",
                    "label": 0
                },
                {
                    "sent": "You can see that even worse, these approximate distributions.",
                    "label": 0
                },
                {
                    "sent": "You still have quite an ad activity game.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me conclude.",
                    "label": 0
                },
                {
                    "sent": "So what we presented was a very simple interactive retrieval model which combines.",
                    "label": 1
                },
                {
                    "sent": "Diversity and recall, which were kind of in the static ranking model opposing.",
                    "label": 0
                },
                {
                    "sent": "We purposely went for an evolution of the user interface, not a revolution.",
                    "label": 0
                },
                {
                    "sent": "So in particular, the first set of results that you get is just this left branch of the tree, and that's just a nice diversified ranking.",
                    "label": 0
                },
                {
                    "sent": "So even if the user never expands anything, I just get some nicely diversified ranking, so it's kind of a nice fall back position.",
                    "label": 0
                },
                {
                    "sent": "And I think it's we conjecture that it's easy for users to understand, because it actually resembles menu browsing.",
                    "label": 0
                },
                {
                    "sent": "On top of this kind of conventional rank retrieval.",
                    "label": 0
                },
                {
                    "sent": "We present a theoretical model which is concise enough to, you know, provide a prescription for how to evaluate this quantitatively and reason about the quantity to design algorithms and also prove theoretical results presented two efficient algorithms that we prove have nonnegative adaptivity gain for modular performance measures, and if you're interested in an implementation of these algorithms, you can download it from our website, but I'm most excited about is.",
                    "label": 1
                },
                {
                    "sent": "The directions of research that this opens up kind of a machine learning perspective constructing these dynamic ranking trees is actually like a partial information online learning problem like a bandit problem or a variant of the bandits problem, so there's probably some interesting algorithmic inside an approximation algorithms for constructing these trees that are better than the algorithms that we have right now.",
                    "label": 0
                },
                {
                    "sent": "I think particularly intriguing is the idea of these conditional distributions of relevance.",
                    "label": 0
                },
                {
                    "sent": "I think we can actually train those based on click data from session based click data, right all that you need to know is oh, user.",
                    "label": 0
                },
                {
                    "sent": "Clicked or skipped.",
                    "label": 0
                },
                {
                    "sent": "Particular other documents?",
                    "label": 0
                },
                {
                    "sent": "What does this tell me about the relationship of the relevance of A of another document so we could potentially play train that in big amounts of excess data?",
                    "label": 1
                },
                {
                    "sent": "There's a lot of room for coming up is more sophisticated user behavioral policy's additional actions beyond skip and click.",
                    "label": 0
                },
                {
                    "sent": "So we get ternary trees that way potentially, and there's a lot of interesting questions in usability of this method.",
                    "label": 0
                },
                {
                    "sent": "I mean, how should we actually layout the results that was presented here was just one way you could do it.",
                    "label": 0
                },
                {
                    "sent": "There are many other ways.",
                    "label": 0
                },
                {
                    "sent": "And kind of, how do we actually want users to interact clicking mousing and how easy it is for users to understand?",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you.",
                    "label": 0
                },
                {
                    "sent": "We have time for questions.",
                    "label": 0
                },
                {
                    "sent": "Andrew.",
                    "label": 0
                },
                {
                    "sent": "Did you?",
                    "label": 0
                },
                {
                    "sent": "Did you have a sense, either empirically or theoretically, of what kind of loss there might be compared to the brute force algorithm?",
                    "label": 0
                },
                {
                    "sent": "No so.",
                    "label": 0
                },
                {
                    "sent": "We tried to find approximation algorithms where within approximation factor guarantee.",
                    "label": 0
                },
                {
                    "sent": "And that turned out to be tricky so far, so we left that for future work and we didn't actually do the exhaustive enumeration.",
                    "label": 0
                },
                {
                    "sent": "I guess for something like.",
                    "label": 0
                },
                {
                    "sent": "A depth of five or so we could actually do it.",
                    "label": 0
                },
                {
                    "sent": "I think that, yeah, that would be an interesting question.",
                    "label": 0
                },
                {
                    "sent": "My gut feeling is that these algorithms are actually in practice tend to work quite well.",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure how much of a gap there is towards optimal, so I have a question related to that.",
                    "label": 0
                },
                {
                    "sent": "In the resource the myopic was identical to the other going right to the look ahead.",
                    "label": 0
                },
                {
                    "sent": "So the look ahead has this additional kind of factor N complexity and it doesn't seem to be worth it right there, there's actually.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we are approximating the utility of the subtrees by the utilities of the of the static ranking, which is a lower bound, but it's a bad lower bound and it's actually so bad that it.",
                    "label": 0
                },
                {
                    "sent": "Helps just as much as it hurts in other cases basically.",
                    "label": 0
                },
                {
                    "sent": "So I think towards the design of a better algorithm would be to actually look at how can we better lower bound the utility of the subject.",
                    "label": 0
                },
                {
                    "sent": "Papa yes if I compare it with, let's say clustering algorithms, very cluster, different intents.",
                    "label": 0
                },
                {
                    "sent": "Usually cluster formations have errors.",
                    "label": 0
                },
                {
                    "sent": "That means there are things that are supposed to be in one cluster because of various metrics or shapes.",
                    "label": 0
                },
                {
                    "sent": "They get clustered into the wrong cluster, right?",
                    "label": 0
                },
                {
                    "sent": "So where does that fit in here?",
                    "label": 0
                },
                {
                    "sent": "Because here you're assuming the intent are all partitions of the space, and it's very clear that which intent each document falls into.",
                    "label": 0
                },
                {
                    "sent": "So I think one of the big advantages of this approach is that you don't have to commit to a clustering or something like that, right?",
                    "label": 0
                },
                {
                    "sent": "So there's there's never a step where you discretely kind of cluster things together and call it an intent.",
                    "label": 0
                },
                {
                    "sent": "Really, and nowhere in this model intent explicitly occurs.",
                    "label": 0
                },
                {
                    "sent": "It just kind of encoded in this conditional probabilities of relevance so that you never have to make this kind of hard commitment to an intent which you probably get wrong quite often, and this one following is that Canada document end up in two different intercluster.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it can appear in multiple places in the tree, definitely.",
                    "label": 0
                },
                {
                    "sent": "Very quick question on the on the interaction so when you click the will expand.",
                    "label": 0
                },
                {
                    "sent": "You will see the document.",
                    "label": 0
                },
                {
                    "sent": "So really I'm being kind of fuzzy about what the right model is in terms of usability.",
                    "label": 0
                },
                {
                    "sent": "I would think that you know something like I just mouse over that result or I maybe click these this little icon there.",
                    "label": 0
                },
                {
                    "sent": "That's actually the Surf Canyon icon.",
                    "label": 0
                },
                {
                    "sent": "That's how they do it, but I think that's actually way too small and too awkward to hit.",
                    "label": 0
                },
                {
                    "sent": "But maybe if I just mouse over it just like I have like the instant previews in Google or Bing, right?",
                    "label": 0
                },
                {
                    "sent": "That this would expand the result doesn't have to be expanded like this.",
                    "label": 0
                },
                {
                    "sent": "It could be in different ranking to the side that gets inserted there many, many different ways.",
                    "label": 0
                },
                {
                    "sent": "How one could do it.",
                    "label": 0
                }
            ]
        }
    }
}