{
    "id": "y4qntdkj6ljgu2r67nyelr7jn26zmnct",
    "title": "Semi-Supervised Learning with Adversarially Missing Label Information",
    "info": {
        "author": [
            "Umar Syed, Department of Computer and Information Science, University of Pennsylvania"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/nips2010_syed_ssl/",
    "segmentation": [
        [
            "Thank you, this is joint work with Ben Taskar ANWR from the University of Pennsylvania.",
            "So the basic idea behind Semi supervised learning is that unlabeled data is much easier and cheaper to obtain than labeled data.",
            "But in practice, where do partially labeled datasets come from?",
            "The basic motivation behind this work is our belief that there is currently a gap between the way semi supervised learning algorithms are used and the way they are analyzed."
        ],
        [
            "So consider the following simple model of how a learning algorithm might obtain a partially labeled data set, so a labeler examines some training data."
        ],
        [
            "And then choose to reveal the labels of some of the examples while keeping the others hidden.",
            "So how does the labeler choose which examples to label?"
        ],
        [
            "Well, in most analysis of semi supervised learning, it is assumed that the labels are chosen randomly and often uniformly at random."
        ],
        [
            "But in naturally occurring datasets, the labeling process is not random.",
            "Consider Facebook photos that are posted on Facebook can be tagged by users with the names of the people in the photo.",
            "How do people decide which photos to tag?",
            "Well, it's not really clear, but it almost certainly isn't a random process."
        ],
        [
            "Yes.",
            "And indeed, most sites on the Internet which solicit user feedback are in one way or another, generating a parse."
        ],
        [
            "The labeled data set.",
            "In bioprocess that is not random, can be difficult to describe or even to know."
        ],
        [
            "So motivated by these observations in this work, we introduce a framework for semi supervised learning, in which the label information is missing in an arbitrary and perhaps even adversarial fashion.",
            "Because we know so little about how naturally occurring, partially labeled datasets are generated, we want to be able to develop an algorithm and conduct an analysis under minimal assumptions.",
            "Additionally, and somewhat orthogonally, our framework is general enough to allow a labeler to not only give local information about the labels of individual examples, but also global information about the labeling of the entire data set, and I'll say more about that in a little bit."
        ],
        [
            "So the basic idea of our framework is a labeler examines the training, some training data XY."
        ],
        [
            "And then reveals to the learning algorithm a label regularizer function R."
        ],
        [
            "And this function R is chosen arbitrarily, even adversarially from some known fixed function family.",
            "And the function R encodes all of the information about the labeling of the training data that the labeler wishes to reveal to the learner."
        ],
        [
            "So the semantics of this regularizer are basically those of in asymmetric penalty function on complete labelings of the training data.",
            "In other words, if R assigns a large value to some full labeling, why of the training data?",
            "Then this labeling is likely not to be the true labeling of the training data.",
            "On the other hand, if R assigns a small value to some full labeling Y, then Y may or may not be the true labeling of the training data.",
            "So in this sense we can sort of roughly say that the minima or near minima of R. Are the possible labelings of the training data?"
        ],
        [
            "So, just to recap, here's the overview of the framework.",
            "Is that some label training data is drawn from some distribution.",
            "This data is given to a labeler and he replaces the actual labeling of the training data with this regularizer function, which encodes all of the information he wishes to reveal to the learning algorithm.",
            "And this is the only information that the algorithm gets."
        ],
        [
            "So in this framework we have several contributions.",
            "Firstly, we provide nearly tight upper and lower bounds on the true loss of any learning algorithm.",
            "Under worst case assumptions about the about the labeling.",
            "These bounds lead directly to an efficient learning algorithm which can be formulated as a convex optimization.",
            "And experimentally, we showed that our algorithm is robust against data that has been labeled by.",
            "Certain types of unhelpful or confused labelers, and it's more robust than traditional semi supervised learning algorithms."
        ],
        [
            "The the idea of a label regularizer is actually quite similar to the concept of a compatibility function which was introduced and analyzed by Balcan and Blumenau 5, but importantly in their work they did not envision the possibility that the function would be chosen by an adversary.",
            "Our setting is also very similar to the malicious label noise setting, so in this setting an adversary can select a small fraction of the training data any fraction he likes and change the labels of those examples.",
            "This is a very challenging learning setting and most positive results.",
            "In this setting makes strong assumptions about the data distribution.",
            "Well, it turns out that our analysis is valid in this setting.",
            "However, our bounds are quite loose, and so in this sense our analysis isn't really suited for the malicious label noise setting, and is instead suited for a setting where the information is missing adversarially but not actually corrupted.",
            "And I'll expand on this and talk about this a little more in a few slides."
        ],
        [
            "OK, so let me give you some some concrete examples of how existing approaches to semi supervised learning can be expressed in our framework.",
            "So consider a setting in which the labeler reveals, for each example, a set of possible labels called partial label sets.",
            "This information can be very simply encoded in our regularizer by assigning the value 0 to any full labeling that is consistent with these label sets an Infinity elsewhere."
        ],
        [
            "Sometimes in some settings, the labeler reveals a similarity score for every pair of examples in the training set, and asserts that similar examples have similar labels.",
            "A version of this is Laplacian regularization, which is given by this expression."
        ],
        [
            "Another possibility is that labeler tells us the expected value of certain features with respect to the true posterior distribution.",
            "This is called posterior regularization.",
            "And let me just point out that in this expression the domain of the regularizer R has changed from a labeling to a distribution over labelings, and in the rest of this talk I'm going to be using this somewhat softer notion of labeling."
        ],
        [
            "Label regularizers can also be combined simply by adding them.",
            "For example, if we're in a setting where the labeler reveals, for each example, a set of possible labels and some similarity information about the examples, then this information can be represented simply by adding the appropriate regularizers.",
            "And in fact, this is exactly the type of regularizer that we're going to be using in our experiments."
        ],
        [
            "OK, so let me move on to the analysis.",
            "So let X&Y be a training set drawn from some distribution containing an examples.",
            "And let L be the loss of some parameter Theta.",
            "So the loss function is like hinge loss, log loss etc.",
            "And again, the R is the label regularizer.",
            "So with one."
        ],
        [
            "With probability 1 minus Delta we have the following bound on the expected loss of any parameter Theta.",
            "The expression on the right."
        ],
        [
            "Inside is the sum of three different terms, and each of these terms has sort of a nice intuitive interpretation, which I'll walk you through now and hopefully will give you some sense of what this bound is really saying."
        ],
        [
            "So the first expression if you examine it, it can be shown that this this term tends to be large when the function R has many minima.",
            "That is to say, when R is ambiguous about that, what the true labeling is."
        ],
        [
            "The second term is the value that are assigns to the true labeling of the data set, and so this term is large when R is misleading, that is, it assigns a large penalty to the actual correct labeling of the training set."
        ],
        [
            "And the last term, which tends to zero as the number of examples, goes to Infinity.",
            "Is just comes from standard arguments about uniform convergence.",
            "So putting this all together, we have that as the number of examples goes to Infinity, the loss of any learned parameter is bounded by how ambiguous and how misleading the labeler was when he told us the labels of the training data."
        ],
        [
            "We also have a nearly matching lower bound which is nearly matching except for this gap.",
            "And this gap is the difference in the value that the regularizer.",
            "Assigns to the true labeling of the data set.",
            "And the smallest value it assigns to any labeling of the data set.",
            "So in other words, this gap is large when the the labeler is is misleading.",
            "And it so when this gap is larger, upper and lower bounds are quite loose.",
            "An it is in this sense that our analysis is not suitable for the malicious label noise setting in which the labeler typically does mislead the training algorithm by learning algorithm by lot.",
            "Let me let me stress that this lower bound requires several assumptions on the label regularizer.",
            "And but these assumptions are fairly technical, and so let me defer to the paper in the supplement where we discussed them at some length."
        ],
        [
            "So our bounds sort of lead very naturally to a learning algorithm, which is simply minimize the upper bound over all possibilities for Theta.",
            "So.",
            "R."
        ],
        [
            "Algorithm, which we call the game algorithm is basically a two step algorithm for optimizing this minimax objective and finding Theta star.",
            "The analysis of the algorithm assumes that both the loss function L and the label regularizer are are convex.",
            "All of the examples of loss functions and label regularizers that I've given you so far are convex.",
            "The game algorithm is really a meta algorithm.",
            "Which in its implementation differs depending on the choice of loss function for the rest of this talk.",
            "For simplicity, let's assume that the loss function is log loss."
        ],
        [
            "So I said it was a two step algorithm.",
            "Here's the first step.",
            "Step is so that the true labeling of the data set of course is unknown.",
            "So the first step is to compute a sort of pessimistic distribution over possible labelings called Q star and Q star is computed as follows.",
            "So we start with our objective.",
            "We swap them in the Max.",
            "This is OK to do because Ellen are both convex.",
            "We take the dual of the inner minimization.",
            "And for log loss, we are left with this objective.",
            "This this objective is convex with simplex constraints, and so we can use an exponentiated gradient method to minimize this objective."
        ],
        [
            "In the second step, after we found this pessimistic label distribution Q star, we simply find the best parameter Theta star for this fixed distribution on the labeling."
        ],
        [
            "And when this is log lost, this is simply a maximum likelihood estimate problem.",
            "So now Theta star is simply the Emily with respect to the training set and this pessimistic label distribution Q star.",
            "And let."
        ],
        [
            "The let me emphasize that this algorithm efficiently finds a global optimum of our objective."
        ],
        [
            "So let me talk a little bit about the experiments.",
            "Recent studies, including at least one that was presented in this conference, have shown that labelers who are employed by services like Amazon Mechanical Turk, often behave in ways that are erratic and malign.",
            "So we tested our algorithm, another semi supervised learning algorithms on datasets that were labeled by simulated malign labellers."
        ],
        [
            "So we tested the game algorithm on two kinds of tasks, binary classification and multi class classification.",
            "And several and we tested.",
            "We compared it with several traditional semi supervised learning algorithms in each of those categories including semi supervised variants of support vector machines.",
            "And also in the multiclass case, algorithms which treat the missing labels, sort of in a probabilistic way and take a maximum likelihood approach.",
            "In all of these experiments, the game algorithm uses.",
            "The regularizer consisting of partial label sets for each example and also the Laplacian.",
            "And we trained the gain algorithm using log loss.",
            "But in all of our results we report accuracy."
        ],
        [
            "So the first task is binary classification.",
            "And in this, in this task we labeled the datasets by an unhelpful labeler.",
            "Who labels outliers 1st and so this is intended to simulate a labeler who erroneously but perhaps sincerely thinks that his effort is best concentrated on those examples that are exceptions to the general rule."
        ],
        [
            "And so in our experiments we labeled."
        ],
        [
            "Outliers first meaning we lay."
        ],
        [
            "Examples.",
            "In decreasing order of the number of neighbors they have that belong to the opposite class.",
            "As follows, so in out.",
            "So we labeled far outliers 1st and then.",
            "Less for outliers and so on in that order."
        ],
        [
            "We tested on two kinds of datasets.",
            "Both datasets are belong to a sort of standard semi supervised learning benchmark.",
            "The first is a library of images of household objects, and the 2nd is EG.",
            "Brain scans from a single human subject.",
            "We chose these datasets because they they contain a lot of outliers."
        ],
        [
            "So just to give you kind of a sense of what example is our label or labeling, here's the first example that it labels.",
            "The first outlier is sort of the most outlier of all the outliers in the image library.",
            "So this image library contains category several categories of objects.",
            "Two of them are medicine cartons and toy cars, and the example that I've circled in red is actually is a toy car, but it looks just like a medicine carton because of the odd angle of the of the photo."
        ],
        [
            "So so here are the results and all of the algorithms perform better as the amount the fraction of labeled training data increases.",
            "But in the regime where only a very small fraction of it is labeled, our algorithm, which is designed for this sort of adversarial setting, performs better."
        ],
        [
            "And we get a similar kind of trend on the EG data."
        ],
        [
            "In the second task, multi class classification task, we labeled the data using a simulated, quote, unquote lazy labeler.",
            "So a lazy labeler is one who labels exact border examples last and by border examples I mean examples that fall in the overlap between two class clusters."
        ],
        [
            "So this is intended to simulate a labeler who is reluctant to commit to a label.",
            "For those examples that seem like they could belong to more than one class, so he's lazy.",
            "And in this, so in the experiment, what we did is that we labeled examples in increasing order of their distance from the centroid of each class cluster."
        ],
        [
            "In this fashion."
        ],
        [
            "So border examples are labeled last."
        ],
        [
            "We tested our algorithms on a data set called faces in the Wild, which is a data set of face photographs of public figures."
        ],
        [
            "Again, to give you an idea of the kinds of examples that are are lazy labeler is reluctant to label here.",
            "The two classes in our data set that have the largest overlap, that is the largest mutual border, and it turns out to be governor of California.",
            "Arnold Schwarzenegger and former German Chancellor Gerhard Schroeder, and I guess they do kind of look alike."
        ],
        [
            "And here are the results on this data set.",
            "Again, the all the algorithms do better as the amount of labeled training data increases.",
            "But again, in the regime where there's very little labeled data, our game algorithm outperforms the other.",
            "Standard Semi supervised learning algorithms."
        ],
        [
            "So in conclusion, what we've done here is presented a new adversarial, semi supervised learning framework, and we've described an algorithm that we show is both theoretically and experimentally robust to label information that is missing adversarially.",
            "And in the future we have a number of questions we'd like to address.",
            "Some of them are.",
            "First of all.",
            "Is this a good model of the way that naturally occurring, labeled naturally occurring datasets are labeled?",
            "Or Amazon Turk datasets are labeled?",
            "We believe that we can extend this approach to structured prediction.",
            "And finally, we think that this might yield kind of a different approach to active learning, in which the partial label information amounts to sort of constraints, and then we just sort of iteratively run the algorithm and ask for more and more refined constraints."
        ],
        [
            "Thanks very much.",
            "So are they any questions?",
            "Can you get to the microphone please?",
            "What's the difference between the adversary at laborers and non adversarial laborers?",
            "So what's what's the difference?",
            "So, so the usual assumption is that in semi super typical assumption and often use assumption is that.",
            "That the training examples that are labeled, which ones are there that they have been selected uniformly at random.",
            "This is the typical assumption used in analysis of semi supervised learning algorithms and we lift that assumption.",
            "We say that the examples have been chosen arbitrarily.",
            "Any examples could have been labeled at all.",
            "So I hope that addressed your question.",
            "Any other questions?",
            "Yes.",
            "What if users only provide labels for one of the classes?",
            "Yeah, that's a very good question.",
            "So does it?",
            "Does it provide?",
            "Are there any other examples in any other class?",
            "Right none none.",
            "I'm sorry, so in that case there will be no examples from the other classes you look, so a label or will only provide examples for one of the classes, right, right?",
            "So the general behavior you know is that of our algorithm is one that hedges.",
            "So when label information is missing, it makes this sort of most uniform and.",
            "Sort of hedged prediction.",
            "So so on those examples for which no clue is provided us with the true label is it will tend to.",
            "It will tend to predict more uniform distributions on those labels on those examples.",
            "Listing of the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, this is joint work with Ben Taskar ANWR from the University of Pennsylvania.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea behind Semi supervised learning is that unlabeled data is much easier and cheaper to obtain than labeled data.",
                    "label": 0
                },
                {
                    "sent": "But in practice, where do partially labeled datasets come from?",
                    "label": 0
                },
                {
                    "sent": "The basic motivation behind this work is our belief that there is currently a gap between the way semi supervised learning algorithms are used and the way they are analyzed.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So consider the following simple model of how a learning algorithm might obtain a partially labeled data set, so a labeler examines some training data.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then choose to reveal the labels of some of the examples while keeping the others hidden.",
                    "label": 0
                },
                {
                    "sent": "So how does the labeler choose which examples to label?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, in most analysis of semi supervised learning, it is assumed that the labels are chosen randomly and often uniformly at random.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in naturally occurring datasets, the labeling process is not random.",
                    "label": 0
                },
                {
                    "sent": "Consider Facebook photos that are posted on Facebook can be tagged by users with the names of the people in the photo.",
                    "label": 0
                },
                {
                    "sent": "How do people decide which photos to tag?",
                    "label": 0
                },
                {
                    "sent": "Well, it's not really clear, but it almost certainly isn't a random process.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "And indeed, most sites on the Internet which solicit user feedback are in one way or another, generating a parse.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The labeled data set.",
                    "label": 0
                },
                {
                    "sent": "In bioprocess that is not random, can be difficult to describe or even to know.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So motivated by these observations in this work, we introduce a framework for semi supervised learning, in which the label information is missing in an arbitrary and perhaps even adversarial fashion.",
                    "label": 0
                },
                {
                    "sent": "Because we know so little about how naturally occurring, partially labeled datasets are generated, we want to be able to develop an algorithm and conduct an analysis under minimal assumptions.",
                    "label": 0
                },
                {
                    "sent": "Additionally, and somewhat orthogonally, our framework is general enough to allow a labeler to not only give local information about the labels of individual examples, but also global information about the labeling of the entire data set, and I'll say more about that in a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basic idea of our framework is a labeler examines the training, some training data XY.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then reveals to the learning algorithm a label regularizer function R.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this function R is chosen arbitrarily, even adversarially from some known fixed function family.",
                    "label": 0
                },
                {
                    "sent": "And the function R encodes all of the information about the labeling of the training data that the labeler wishes to reveal to the learner.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the semantics of this regularizer are basically those of in asymmetric penalty function on complete labelings of the training data.",
                    "label": 0
                },
                {
                    "sent": "In other words, if R assigns a large value to some full labeling, why of the training data?",
                    "label": 0
                },
                {
                    "sent": "Then this labeling is likely not to be the true labeling of the training data.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if R assigns a small value to some full labeling Y, then Y may or may not be the true labeling of the training data.",
                    "label": 0
                },
                {
                    "sent": "So in this sense we can sort of roughly say that the minima or near minima of R. Are the possible labelings of the training data?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, just to recap, here's the overview of the framework.",
                    "label": 0
                },
                {
                    "sent": "Is that some label training data is drawn from some distribution.",
                    "label": 0
                },
                {
                    "sent": "This data is given to a labeler and he replaces the actual labeling of the training data with this regularizer function, which encodes all of the information he wishes to reveal to the learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And this is the only information that the algorithm gets.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this framework we have several contributions.",
                    "label": 0
                },
                {
                    "sent": "Firstly, we provide nearly tight upper and lower bounds on the true loss of any learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Under worst case assumptions about the about the labeling.",
                    "label": 0
                },
                {
                    "sent": "These bounds lead directly to an efficient learning algorithm which can be formulated as a convex optimization.",
                    "label": 0
                },
                {
                    "sent": "And experimentally, we showed that our algorithm is robust against data that has been labeled by.",
                    "label": 0
                },
                {
                    "sent": "Certain types of unhelpful or confused labelers, and it's more robust than traditional semi supervised learning algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The the idea of a label regularizer is actually quite similar to the concept of a compatibility function which was introduced and analyzed by Balcan and Blumenau 5, but importantly in their work they did not envision the possibility that the function would be chosen by an adversary.",
                    "label": 0
                },
                {
                    "sent": "Our setting is also very similar to the malicious label noise setting, so in this setting an adversary can select a small fraction of the training data any fraction he likes and change the labels of those examples.",
                    "label": 0
                },
                {
                    "sent": "This is a very challenging learning setting and most positive results.",
                    "label": 0
                },
                {
                    "sent": "In this setting makes strong assumptions about the data distribution.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that our analysis is valid in this setting.",
                    "label": 0
                },
                {
                    "sent": "However, our bounds are quite loose, and so in this sense our analysis isn't really suited for the malicious label noise setting, and is instead suited for a setting where the information is missing adversarially but not actually corrupted.",
                    "label": 0
                },
                {
                    "sent": "And I'll expand on this and talk about this a little more in a few slides.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me give you some some concrete examples of how existing approaches to semi supervised learning can be expressed in our framework.",
                    "label": 0
                },
                {
                    "sent": "So consider a setting in which the labeler reveals, for each example, a set of possible labels called partial label sets.",
                    "label": 0
                },
                {
                    "sent": "This information can be very simply encoded in our regularizer by assigning the value 0 to any full labeling that is consistent with these label sets an Infinity elsewhere.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sometimes in some settings, the labeler reveals a similarity score for every pair of examples in the training set, and asserts that similar examples have similar labels.",
                    "label": 0
                },
                {
                    "sent": "A version of this is Laplacian regularization, which is given by this expression.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another possibility is that labeler tells us the expected value of certain features with respect to the true posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "This is called posterior regularization.",
                    "label": 0
                },
                {
                    "sent": "And let me just point out that in this expression the domain of the regularizer R has changed from a labeling to a distribution over labelings, and in the rest of this talk I'm going to be using this somewhat softer notion of labeling.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Label regularizers can also be combined simply by adding them.",
                    "label": 0
                },
                {
                    "sent": "For example, if we're in a setting where the labeler reveals, for each example, a set of possible labels and some similarity information about the examples, then this information can be represented simply by adding the appropriate regularizers.",
                    "label": 0
                },
                {
                    "sent": "And in fact, this is exactly the type of regularizer that we're going to be using in our experiments.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me move on to the analysis.",
                    "label": 0
                },
                {
                    "sent": "So let X&Y be a training set drawn from some distribution containing an examples.",
                    "label": 0
                },
                {
                    "sent": "And let L be the loss of some parameter Theta.",
                    "label": 0
                },
                {
                    "sent": "So the loss function is like hinge loss, log loss etc.",
                    "label": 0
                },
                {
                    "sent": "And again, the R is the label regularizer.",
                    "label": 0
                },
                {
                    "sent": "So with one.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With probability 1 minus Delta we have the following bound on the expected loss of any parameter Theta.",
                    "label": 0
                },
                {
                    "sent": "The expression on the right.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inside is the sum of three different terms, and each of these terms has sort of a nice intuitive interpretation, which I'll walk you through now and hopefully will give you some sense of what this bound is really saying.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first expression if you examine it, it can be shown that this this term tends to be large when the function R has many minima.",
                    "label": 0
                },
                {
                    "sent": "That is to say, when R is ambiguous about that, what the true labeling is.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second term is the value that are assigns to the true labeling of the data set, and so this term is large when R is misleading, that is, it assigns a large penalty to the actual correct labeling of the training set.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the last term, which tends to zero as the number of examples, goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Is just comes from standard arguments about uniform convergence.",
                    "label": 0
                },
                {
                    "sent": "So putting this all together, we have that as the number of examples goes to Infinity, the loss of any learned parameter is bounded by how ambiguous and how misleading the labeler was when he told us the labels of the training data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also have a nearly matching lower bound which is nearly matching except for this gap.",
                    "label": 0
                },
                {
                    "sent": "And this gap is the difference in the value that the regularizer.",
                    "label": 0
                },
                {
                    "sent": "Assigns to the true labeling of the data set.",
                    "label": 0
                },
                {
                    "sent": "And the smallest value it assigns to any labeling of the data set.",
                    "label": 0
                },
                {
                    "sent": "So in other words, this gap is large when the the labeler is is misleading.",
                    "label": 0
                },
                {
                    "sent": "And it so when this gap is larger, upper and lower bounds are quite loose.",
                    "label": 0
                },
                {
                    "sent": "An it is in this sense that our analysis is not suitable for the malicious label noise setting in which the labeler typically does mislead the training algorithm by learning algorithm by lot.",
                    "label": 0
                },
                {
                    "sent": "Let me let me stress that this lower bound requires several assumptions on the label regularizer.",
                    "label": 0
                },
                {
                    "sent": "And but these assumptions are fairly technical, and so let me defer to the paper in the supplement where we discussed them at some length.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our bounds sort of lead very naturally to a learning algorithm, which is simply minimize the upper bound over all possibilities for Theta.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "R.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithm, which we call the game algorithm is basically a two step algorithm for optimizing this minimax objective and finding Theta star.",
                    "label": 0
                },
                {
                    "sent": "The analysis of the algorithm assumes that both the loss function L and the label regularizer are are convex.",
                    "label": 0
                },
                {
                    "sent": "All of the examples of loss functions and label regularizers that I've given you so far are convex.",
                    "label": 0
                },
                {
                    "sent": "The game algorithm is really a meta algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which in its implementation differs depending on the choice of loss function for the rest of this talk.",
                    "label": 0
                },
                {
                    "sent": "For simplicity, let's assume that the loss function is log loss.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I said it was a two step algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here's the first step.",
                    "label": 0
                },
                {
                    "sent": "Step is so that the true labeling of the data set of course is unknown.",
                    "label": 0
                },
                {
                    "sent": "So the first step is to compute a sort of pessimistic distribution over possible labelings called Q star and Q star is computed as follows.",
                    "label": 0
                },
                {
                    "sent": "So we start with our objective.",
                    "label": 0
                },
                {
                    "sent": "We swap them in the Max.",
                    "label": 0
                },
                {
                    "sent": "This is OK to do because Ellen are both convex.",
                    "label": 0
                },
                {
                    "sent": "We take the dual of the inner minimization.",
                    "label": 0
                },
                {
                    "sent": "And for log loss, we are left with this objective.",
                    "label": 0
                },
                {
                    "sent": "This this objective is convex with simplex constraints, and so we can use an exponentiated gradient method to minimize this objective.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second step, after we found this pessimistic label distribution Q star, we simply find the best parameter Theta star for this fixed distribution on the labeling.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when this is log lost, this is simply a maximum likelihood estimate problem.",
                    "label": 0
                },
                {
                    "sent": "So now Theta star is simply the Emily with respect to the training set and this pessimistic label distribution Q star.",
                    "label": 0
                },
                {
                    "sent": "And let.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The let me emphasize that this algorithm efficiently finds a global optimum of our objective.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me talk a little bit about the experiments.",
                    "label": 0
                },
                {
                    "sent": "Recent studies, including at least one that was presented in this conference, have shown that labelers who are employed by services like Amazon Mechanical Turk, often behave in ways that are erratic and malign.",
                    "label": 0
                },
                {
                    "sent": "So we tested our algorithm, another semi supervised learning algorithms on datasets that were labeled by simulated malign labellers.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we tested the game algorithm on two kinds of tasks, binary classification and multi class classification.",
                    "label": 0
                },
                {
                    "sent": "And several and we tested.",
                    "label": 0
                },
                {
                    "sent": "We compared it with several traditional semi supervised learning algorithms in each of those categories including semi supervised variants of support vector machines.",
                    "label": 0
                },
                {
                    "sent": "And also in the multiclass case, algorithms which treat the missing labels, sort of in a probabilistic way and take a maximum likelihood approach.",
                    "label": 0
                },
                {
                    "sent": "In all of these experiments, the game algorithm uses.",
                    "label": 0
                },
                {
                    "sent": "The regularizer consisting of partial label sets for each example and also the Laplacian.",
                    "label": 0
                },
                {
                    "sent": "And we trained the gain algorithm using log loss.",
                    "label": 0
                },
                {
                    "sent": "But in all of our results we report accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first task is binary classification.",
                    "label": 0
                },
                {
                    "sent": "And in this, in this task we labeled the datasets by an unhelpful labeler.",
                    "label": 0
                },
                {
                    "sent": "Who labels outliers 1st and so this is intended to simulate a labeler who erroneously but perhaps sincerely thinks that his effort is best concentrated on those examples that are exceptions to the general rule.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so in our experiments we labeled.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Outliers first meaning we lay.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples.",
                    "label": 0
                },
                {
                    "sent": "In decreasing order of the number of neighbors they have that belong to the opposite class.",
                    "label": 0
                },
                {
                    "sent": "As follows, so in out.",
                    "label": 0
                },
                {
                    "sent": "So we labeled far outliers 1st and then.",
                    "label": 0
                },
                {
                    "sent": "Less for outliers and so on in that order.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We tested on two kinds of datasets.",
                    "label": 0
                },
                {
                    "sent": "Both datasets are belong to a sort of standard semi supervised learning benchmark.",
                    "label": 0
                },
                {
                    "sent": "The first is a library of images of household objects, and the 2nd is EG.",
                    "label": 0
                },
                {
                    "sent": "Brain scans from a single human subject.",
                    "label": 0
                },
                {
                    "sent": "We chose these datasets because they they contain a lot of outliers.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to give you kind of a sense of what example is our label or labeling, here's the first example that it labels.",
                    "label": 0
                },
                {
                    "sent": "The first outlier is sort of the most outlier of all the outliers in the image library.",
                    "label": 0
                },
                {
                    "sent": "So this image library contains category several categories of objects.",
                    "label": 0
                },
                {
                    "sent": "Two of them are medicine cartons and toy cars, and the example that I've circled in red is actually is a toy car, but it looks just like a medicine carton because of the odd angle of the of the photo.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so here are the results and all of the algorithms perform better as the amount the fraction of labeled training data increases.",
                    "label": 0
                },
                {
                    "sent": "But in the regime where only a very small fraction of it is labeled, our algorithm, which is designed for this sort of adversarial setting, performs better.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we get a similar kind of trend on the EG data.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second task, multi class classification task, we labeled the data using a simulated, quote, unquote lazy labeler.",
                    "label": 0
                },
                {
                    "sent": "So a lazy labeler is one who labels exact border examples last and by border examples I mean examples that fall in the overlap between two class clusters.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is intended to simulate a labeler who is reluctant to commit to a label.",
                    "label": 0
                },
                {
                    "sent": "For those examples that seem like they could belong to more than one class, so he's lazy.",
                    "label": 0
                },
                {
                    "sent": "And in this, so in the experiment, what we did is that we labeled examples in increasing order of their distance from the centroid of each class cluster.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this fashion.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So border examples are labeled last.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We tested our algorithms on a data set called faces in the Wild, which is a data set of face photographs of public figures.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, to give you an idea of the kinds of examples that are are lazy labeler is reluctant to label here.",
                    "label": 0
                },
                {
                    "sent": "The two classes in our data set that have the largest overlap, that is the largest mutual border, and it turns out to be governor of California.",
                    "label": 0
                },
                {
                    "sent": "Arnold Schwarzenegger and former German Chancellor Gerhard Schroeder, and I guess they do kind of look alike.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are the results on this data set.",
                    "label": 0
                },
                {
                    "sent": "Again, the all the algorithms do better as the amount of labeled training data increases.",
                    "label": 0
                },
                {
                    "sent": "But again, in the regime where there's very little labeled data, our game algorithm outperforms the other.",
                    "label": 0
                },
                {
                    "sent": "Standard Semi supervised learning algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, what we've done here is presented a new adversarial, semi supervised learning framework, and we've described an algorithm that we show is both theoretically and experimentally robust to label information that is missing adversarially.",
                    "label": 0
                },
                {
                    "sent": "And in the future we have a number of questions we'd like to address.",
                    "label": 0
                },
                {
                    "sent": "Some of them are.",
                    "label": 0
                },
                {
                    "sent": "First of all.",
                    "label": 0
                },
                {
                    "sent": "Is this a good model of the way that naturally occurring, labeled naturally occurring datasets are labeled?",
                    "label": 0
                },
                {
                    "sent": "Or Amazon Turk datasets are labeled?",
                    "label": 0
                },
                {
                    "sent": "We believe that we can extend this approach to structured prediction.",
                    "label": 0
                },
                {
                    "sent": "And finally, we think that this might yield kind of a different approach to active learning, in which the partial label information amounts to sort of constraints, and then we just sort of iteratively run the algorithm and ask for more and more refined constraints.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks very much.",
                    "label": 0
                },
                {
                    "sent": "So are they any questions?",
                    "label": 0
                },
                {
                    "sent": "Can you get to the microphone please?",
                    "label": 0
                },
                {
                    "sent": "What's the difference between the adversary at laborers and non adversarial laborers?",
                    "label": 0
                },
                {
                    "sent": "So what's what's the difference?",
                    "label": 0
                },
                {
                    "sent": "So, so the usual assumption is that in semi super typical assumption and often use assumption is that.",
                    "label": 0
                },
                {
                    "sent": "That the training examples that are labeled, which ones are there that they have been selected uniformly at random.",
                    "label": 0
                },
                {
                    "sent": "This is the typical assumption used in analysis of semi supervised learning algorithms and we lift that assumption.",
                    "label": 0
                },
                {
                    "sent": "We say that the examples have been chosen arbitrarily.",
                    "label": 0
                },
                {
                    "sent": "Any examples could have been labeled at all.",
                    "label": 0
                },
                {
                    "sent": "So I hope that addressed your question.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What if users only provide labels for one of the classes?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "So does it?",
                    "label": 0
                },
                {
                    "sent": "Does it provide?",
                    "label": 0
                },
                {
                    "sent": "Are there any other examples in any other class?",
                    "label": 0
                },
                {
                    "sent": "Right none none.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, so in that case there will be no examples from the other classes you look, so a label or will only provide examples for one of the classes, right, right?",
                    "label": 0
                },
                {
                    "sent": "So the general behavior you know is that of our algorithm is one that hedges.",
                    "label": 0
                },
                {
                    "sent": "So when label information is missing, it makes this sort of most uniform and.",
                    "label": 0
                },
                {
                    "sent": "Sort of hedged prediction.",
                    "label": 0
                },
                {
                    "sent": "So so on those examples for which no clue is provided us with the true label is it will tend to.",
                    "label": 0
                },
                {
                    "sent": "It will tend to predict more uniform distributions on those labels on those examples.",
                    "label": 0
                },
                {
                    "sent": "Listing of the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}