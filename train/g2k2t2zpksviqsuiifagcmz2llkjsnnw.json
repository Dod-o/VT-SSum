{
    "id": "g2k2t2zpksviqsuiifagcmz2llkjsnnw",
    "title": "Non-parametric Mixtures Models for Clustering",
    "info": {
        "author": [
            "Serhat Selcuk Bucak, Department of Computer Science and Engineering, Michigan State University"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_bucak_npm/",
    "segmentation": [
        [
            "So we are from Michigan City or State poem has just graduated and currently at MIT right now at wrong tonight until tonight.",
            "My advisors.",
            "Do that today is not permitted.",
            "Mixers for data clustering.",
            "So to give a basic introduction are aiming clustering is to partition and points which are D dimensional into G clusters.",
            "So we assume that the number of clusters, which is capital J is given.",
            "So in this two month date set."
        ],
        [
            "We have this points and ideally clustered data is red and blue points.",
            "So in this set our aim is to get this result."
        ],
        [
            "Before.",
            "Getting into our approach, I want to give a.",
            "Probably of the methods.",
            "Sorry for the resolution issue, so first column is the method or family of clustering.",
            "Different approaches and in second column we have some examples.",
            "The third column shows whether they are nonparametric corners.",
            "So when we say classic methods parametrics, we try to impose a structure like a Gaussian assumption on the clusters.",
            "And when we say nonparametric, we don't assume any structure.",
            "Classes can be from any other distribution, but we are trying to find them by using information from other points and a kernel metrics.",
            "Generally, RBF kernels are using this cases.",
            "Runs out of sample.",
            "We mean a new point which is not used when finding the classes.",
            "Can be assigned to any clusters.",
            "And when they are pushed we can either have discrete labels like we chose to each cluster, the samples blank, or we might have probabilities.",
            "And finally this column shows whether these methods.",
            "Need to be specified about the number of clusters.",
            "So our first group is methods that you squared error like K means or eyes on map.",
            "These are parametric, so we have an or an for known for this column there out of sample so.",
            "We have a new test point.",
            "You can just assign to one of the existing clusters.",
            "We have discrete labels here and you have to specify the number of clusters.",
            "The second approach, which is permitted mixture, models a Gaussian mixture model, can be given as an example.",
            "This is close to what I'm going to present here, so in this case we have we model the classes different mixtures, so all are assumed from come from a Gaussian distribution.",
            "And as an output you have probabilities of and.",
            "Sample to assigning this clusters.",
            "I guess you have to close specified number of clusters.",
            "So the other ones are non parametric so you don't have to specify it structure for clusters and general they're not out of sample, so you have to use the samples in constructing the clusters and they have discrete labels.",
            "And in some of them, like normal as customer information Turkey approaches, you have to specify the number of classes.",
            "But in hyper classing or tested based classes you don't have to specify the number of classes.",
            "Are approaches proposed nonparametric mixture models?",
            "It is non parametric.",
            "It is out of samples.",
            "So after we form the clusters any sample can be assigned to any clusters.",
            "Doc with these probabilities, it is fuzzy assignments.",
            "We can also put it in that and we have to specify the number of clusters.",
            "So first dislikes about mix general mixture models for clustering."
        ],
        [
            "Our aim is to represent the density of a point.",
            "X is a mixture of G components G clusters, so G is showing the class index an.",
            "We have total of capital G clusters, so the probability density 4.6 can be given at the sum of prior of the clusters and there.",
            "Yeah.",
            "Conditional.",
            "Product of X given classes CG.",
            "So each component here each C represent a cluster.",
            "So in this case for example, you can assume a Gaussian distribution where each classic can be represented by the mean and covariance values.",
            "And foster purpose is of course should sum to one.",
            "So if if the nature of your data go well with their sync model, it works fine.",
            "But unfortunately real data is."
        ],
        [
            "Not always caution, and even if some of the classes can be modeled by Gaussian distribution, there is no granted every cluster will have same distribution and classes maybe multimodal so.",
            "Because of these shortcomings of parametric methods, the authors decide to propose a non parametric mixture model.",
            "So in this case, since you don't have a specific structure for clusters, you have to estimate the density for each point by using the information from the other point."
        ],
        [
            "Son, you made this by using Journal metrics where this Sigma is selecting parameter and is the number of points and K is your kernel.",
            "So by using this.",
            "Methods.",
            "You can.",
            "Find any arbitrary density functions so.",
            "Regions where you have gas points will have high values, and it's possible you will get this small value.",
            "So this is how you get density.",
            "We use stationary kernels here, so it will be independent from the locations.",
            "And the aim is to model any arbitrary distribution.",
            "So similar to Gaussian mixture models, the aim is to perform classic by."
        ],
        [
            "Using mixture of testis classes, but here the mixture you will get a mixer from nonparametric densities and each component will be again a different cluster and density estimate.",
            "So from the previous last we saw this the best can basement by using this, but when we use journals we can just for a new sample X we will use the points that are including its cluster G and this is the number of clusters, number of samples in that cluster.",
            "So given this cluster you can estimate the density."
        ],
        [
            "That quite expires in this formula.",
            "So the goal is like some mixed models to maximize the data likelihoods.",
            "The stands for data here so.",
            "Recall this formula.",
            "We will have to multiply this component for each.",
            "Clusters at foreach clusters to sample heart problems.",
            "So in order to come up with efficient algorithm.",
            "Delta propose an approximate algorithm to solve this.",
            "So the previous slide we've seen this formula, but here the authors County relaxation where."
        ],
        [
            "Since we don't have labels, instead of using this hearts assignment two clusters they at this profile vector where Qi G shows eisd sense for sample and G stands for cluster.",
            "It shows relative importance of this sample for that for the test of this cluster.",
            "So by waiting by using the kernel between the point and other points.",
            "And the contribution of the point to the cluster.",
            "You can estimate the conditional density of X given the clusters.",
            "So for each classes you will have this profile.",
            "Vectors and by using the by combining these vectors for all classes, you will have this Ant empty matrix Q which is called profile metrics.",
            "So the aim here is to.",
            "Find the profile metrics.",
            "Another important thing to note is that.",
            "That will leave one out lactic maximization is used in this estimation problem, because when you leave one out."
        ],
        [
            "Left foot is that you exclude your own point from this an samples, otherwise you might end up with overfitting overestimation of Q.",
            "So 1 two.",
            "You want to exclude your sample.",
            "We've used this data.",
            "Expression so when I is equal to J, this will have one and one lines fun with rent it will exclude your point XI.",
            "And to calculate our conditional density from the conditional probability, you will just multiply this estimate by the mixing parameters.",
            "G again, this is the number stands for cluster and I is for your sample.",
            "Note that this mixing parameters is different from this one for this case and mixing parameters for the cluster is independent of the samples, so it is same for the cluster.",
            "But in this case.",
            "It also depends on your sample.",
            "So mix mixing question for a cluster will be different for each sample you are trying to estimate.",
            "So we're trying to."
        ],
        [
            "Maximize liquid of this.",
            "Unconditional.",
            "There's two, plus the authors also protect Gaussian prior to increase the robustness so you will end up with this optimization scheme for Q, an mixing parameter gamma.",
            "So they don't provide the details of the optimization scheme.",
            "The paper it is.",
            "I guess it is a little complicated, but always speaking they follow an attendant alternative approach in each step initiatives operation, you first estimate the profiles Q, Max, Q and then using this Q metrics.",
            "You try to find, so your labels or."
        ],
        [
            "Probabilities are.",
            "Containing, So once you have this final government, you can just.",
            "Assign samples to clusters.",
            "So we have a simple example.",
            "Here again, two more datasets.",
            "If you use Gaussian mixture model with two components.",
            "Since the distribution of data is not cursing, you will not have the optimal.",
            "Classes, but one cluster will be in this shape.",
            "This looks Gaussian and the other Gaussian will be in this chip, so it fails in this case.",
            "But the proposed approach.",
            "Estimated dances quite well.",
            "In this point, because of this samples, there's some variation, but still we can say that.",
            "It doesn't favor fairly good job."
        ],
        [
            "And again we use another data set which is known to be difficult for spectral clustering.",
            "So in this case this is ordinal points.",
            "We have three clusters, means are.",
            "020066180 so we have three classes without 4K.",
            "Mrs Dissenter result perspective.",
            "Clustering is this.",
            "So unlike these approaches, the proposed method again gives good estimates for the densities, so these are the results for the estimates.",
            "10 statements for three clusters, so these are the eyes of counters, so the warmer colors means higher probabilities."
        ],
        [
            "Love, guess who's the real data work date?",
            "Since we have 8 high dimension text datasets.",
            "So it is very unlikely that you can assume any well known structures like Gaussian distributions to emulate a fun pairwise.",
            "Affirm measure is used.",
            "Three types of baselines.",
            "Classic metal service came is is well known as expected.",
            "Clustering method is used.",
            "An linkage.",
            "Algorithms for hierarchical clustering are also used.",
            "So we have three linkage algorithms.",
            "But the best results will be reported for the tables, since K misses his shortcoming for trapping in local minima, five different initialization are used in.",
            "Extra attempt and the best performance is given.",
            "And each item is around 10 times to get significantly.",
            "Results."
        ],
        [
            "And got some make some other models are not used because the.",
            "Dimension of data is generally bigger than the number of samples, so this full problem.",
            "Numerical problems when finding the inverse of the covariance matrix.",
            "So these are the text datasets, the second column, and shows the number of samples.",
            "D is the dimension.",
            "So generally these are high dimensional.",
            "This is, which is a proud perspective clustering and actually most of the classroom methods.",
            "G is the number of classes, so we can use this.",
            "As an input.",
            "So animal is the proposal.",
            "We can see that I think.",
            "Almost in almost all datasets.",
            "Outperforms the other baselines methods, so system.",
            "Is his height dimension mean squared error for chemists?",
            "Doesn't work very well and spectral clustering methods.",
            "You use G -- 1.",
            "I can barely use eigenvectors, so.",
            "Element change, unlike this spectrum metals, anyone can get use of the old kernel metrics, so this might be the reason for this better performance and leakage methods are unfortunately outperformed by other matters."
        ],
        [
            "Conclusions or summary of the presentation.",
            "So a nonparametric mixture model for that class is purpose.",
            "So unlike other methods, you can estimate any densities you don't have to specify any structure for the clusters.",
            "According to the experiments we showed, the proposed methods outperforms the baseline methods, which includes hierarchal clustering, K means and spectral methods.",
            "The reason we don't use then that's the best method is that they are generally they can't perform good in high dimension data set because it's generally difficult to define the neighborhood for those dense space approaches.",
            "So unlike those again, unlike those dance to base methods or cows mixed models, it can also perform well in high dimensional data sets.",
            "Yeah, we have two parameters here.",
            "One was.",
            "You might ask the robots to parametres.",
            "This was excluded, but we have two parameters, one for this.",
            ", I'm not sure for Gaussian prior and we have the smoothing parameter.",
            "Sigma, so if you check the paper we can see that this quite robust to the selection of this two parameters.",
            "But still you can as a future work you can try to optimize bandwidth selection to submitting parameter selection.",
            "And of course there is always room for improvement in scalability of the classic metals, especially when The Time Machine is high.",
            "Angelidis so promising method for using in other application with past domains like the application bioinformatics.",
            "So this is it.",
            "Thank you for listening.",
            "Thank you for the presentation.",
            "Is there any question also?",
            "Yep."
        ],
        [
            "Uninstall the objective with this method.",
            "Seem to be quite similar to the same supervisors convinced estimation.",
            "Proposed by one or something and the unseen.",
            "His paper sets and the.",
            "Cross Ring performance is quite sensitive to the band wise of the corner of Colonel, otherwise renewal, and he also proposed and automatic gunfire selection method in this paper, so the so I think there.",
            "So The thing is, well, yeah, you are right that if you choose a very small or very large bandwidth you can end up with medical problems.",
            "So what they do in this paper is that they use mean pairwise distances and get 5 percentage.",
            "Yeah, I think they should also show a reference there which it might same reference which calculates the bandwidth.",
            "So there adopting the authors adopting is is in that approach, but again they are using this.",
            "Bandwidth selection and also their methods.",
            "I don't need to see related, but there's multiple kernel methods where you don't specify the values, but you can use a family of the same kernel with different bandwidths and find a combination of this channels.",
            "Maybe those kinds of approaches can also be adopted in this case, but thank you think you can drive the cross validation and trust.",
            "Yeah.",
            "Each day is and also it is kernel mean ship by here right?",
            "Yes actually yeah, but I think yeah.",
            "Please, actually, that's a good point.",
            "A question.",
            "How can you?",
            "Work with the Constipation in higher dimensions and a low number of samples.",
            "How is it performing, yeah.",
            "Well, The thing is, I'm not an expert, but I saw some methods where you don't estimate whole Journal but.",
            "You assume that journalists will be sparse, so only some part of the komatik will be meaningful, and I know that says there are some methods which track list meta kernel by assume the kernel will be Spa sandwich.",
            "Try to estimate only parts of the kernel which are significant.",
            "But that's a good point.",
            "I don't have a full answer for that yet."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we are from Michigan City or State poem has just graduated and currently at MIT right now at wrong tonight until tonight.",
                    "label": 0
                },
                {
                    "sent": "My advisors.",
                    "label": 0
                },
                {
                    "sent": "Do that today is not permitted.",
                    "label": 0
                },
                {
                    "sent": "Mixers for data clustering.",
                    "label": 0
                },
                {
                    "sent": "So to give a basic introduction are aiming clustering is to partition and points which are D dimensional into G clusters.",
                    "label": 0
                },
                {
                    "sent": "So we assume that the number of clusters, which is capital J is given.",
                    "label": 0
                },
                {
                    "sent": "So in this two month date set.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have this points and ideally clustered data is red and blue points.",
                    "label": 0
                },
                {
                    "sent": "So in this set our aim is to get this result.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before.",
                    "label": 0
                },
                {
                    "sent": "Getting into our approach, I want to give a.",
                    "label": 0
                },
                {
                    "sent": "Probably of the methods.",
                    "label": 0
                },
                {
                    "sent": "Sorry for the resolution issue, so first column is the method or family of clustering.",
                    "label": 0
                },
                {
                    "sent": "Different approaches and in second column we have some examples.",
                    "label": 0
                },
                {
                    "sent": "The third column shows whether they are nonparametric corners.",
                    "label": 0
                },
                {
                    "sent": "So when we say classic methods parametrics, we try to impose a structure like a Gaussian assumption on the clusters.",
                    "label": 0
                },
                {
                    "sent": "And when we say nonparametric, we don't assume any structure.",
                    "label": 0
                },
                {
                    "sent": "Classes can be from any other distribution, but we are trying to find them by using information from other points and a kernel metrics.",
                    "label": 0
                },
                {
                    "sent": "Generally, RBF kernels are using this cases.",
                    "label": 0
                },
                {
                    "sent": "Runs out of sample.",
                    "label": 0
                },
                {
                    "sent": "We mean a new point which is not used when finding the classes.",
                    "label": 0
                },
                {
                    "sent": "Can be assigned to any clusters.",
                    "label": 0
                },
                {
                    "sent": "And when they are pushed we can either have discrete labels like we chose to each cluster, the samples blank, or we might have probabilities.",
                    "label": 0
                },
                {
                    "sent": "And finally this column shows whether these methods.",
                    "label": 0
                },
                {
                    "sent": "Need to be specified about the number of clusters.",
                    "label": 1
                },
                {
                    "sent": "So our first group is methods that you squared error like K means or eyes on map.",
                    "label": 0
                },
                {
                    "sent": "These are parametric, so we have an or an for known for this column there out of sample so.",
                    "label": 0
                },
                {
                    "sent": "We have a new test point.",
                    "label": 0
                },
                {
                    "sent": "You can just assign to one of the existing clusters.",
                    "label": 0
                },
                {
                    "sent": "We have discrete labels here and you have to specify the number of clusters.",
                    "label": 1
                },
                {
                    "sent": "The second approach, which is permitted mixture, models a Gaussian mixture model, can be given as an example.",
                    "label": 0
                },
                {
                    "sent": "This is close to what I'm going to present here, so in this case we have we model the classes different mixtures, so all are assumed from come from a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "And as an output you have probabilities of and.",
                    "label": 0
                },
                {
                    "sent": "Sample to assigning this clusters.",
                    "label": 0
                },
                {
                    "sent": "I guess you have to close specified number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So the other ones are non parametric so you don't have to specify it structure for clusters and general they're not out of sample, so you have to use the samples in constructing the clusters and they have discrete labels.",
                    "label": 0
                },
                {
                    "sent": "And in some of them, like normal as customer information Turkey approaches, you have to specify the number of classes.",
                    "label": 0
                },
                {
                    "sent": "But in hyper classing or tested based classes you don't have to specify the number of classes.",
                    "label": 0
                },
                {
                    "sent": "Are approaches proposed nonparametric mixture models?",
                    "label": 0
                },
                {
                    "sent": "It is non parametric.",
                    "label": 0
                },
                {
                    "sent": "It is out of samples.",
                    "label": 0
                },
                {
                    "sent": "So after we form the clusters any sample can be assigned to any clusters.",
                    "label": 0
                },
                {
                    "sent": "Doc with these probabilities, it is fuzzy assignments.",
                    "label": 0
                },
                {
                    "sent": "We can also put it in that and we have to specify the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So first dislikes about mix general mixture models for clustering.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our aim is to represent the density of a point.",
                    "label": 1
                },
                {
                    "sent": "X is a mixture of G components G clusters, so G is showing the class index an.",
                    "label": 0
                },
                {
                    "sent": "We have total of capital G clusters, so the probability density 4.6 can be given at the sum of prior of the clusters and there.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Conditional.",
                    "label": 0
                },
                {
                    "sent": "Product of X given classes CG.",
                    "label": 0
                },
                {
                    "sent": "So each component here each C represent a cluster.",
                    "label": 0
                },
                {
                    "sent": "So in this case for example, you can assume a Gaussian distribution where each classic can be represented by the mean and covariance values.",
                    "label": 0
                },
                {
                    "sent": "And foster purpose is of course should sum to one.",
                    "label": 0
                },
                {
                    "sent": "So if if the nature of your data go well with their sync model, it works fine.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately real data is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not always caution, and even if some of the classes can be modeled by Gaussian distribution, there is no granted every cluster will have same distribution and classes maybe multimodal so.",
                    "label": 0
                },
                {
                    "sent": "Because of these shortcomings of parametric methods, the authors decide to propose a non parametric mixture model.",
                    "label": 0
                },
                {
                    "sent": "So in this case, since you don't have a specific structure for clusters, you have to estimate the density for each point by using the information from the other point.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Son, you made this by using Journal metrics where this Sigma is selecting parameter and is the number of points and K is your kernel.",
                    "label": 0
                },
                {
                    "sent": "So by using this.",
                    "label": 0
                },
                {
                    "sent": "Methods.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "Find any arbitrary density functions so.",
                    "label": 0
                },
                {
                    "sent": "Regions where you have gas points will have high values, and it's possible you will get this small value.",
                    "label": 0
                },
                {
                    "sent": "So this is how you get density.",
                    "label": 0
                },
                {
                    "sent": "We use stationary kernels here, so it will be independent from the locations.",
                    "label": 0
                },
                {
                    "sent": "And the aim is to model any arbitrary distribution.",
                    "label": 0
                },
                {
                    "sent": "So similar to Gaussian mixture models, the aim is to perform classic by.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using mixture of testis classes, but here the mixture you will get a mixer from nonparametric densities and each component will be again a different cluster and density estimate.",
                    "label": 1
                },
                {
                    "sent": "So from the previous last we saw this the best can basement by using this, but when we use journals we can just for a new sample X we will use the points that are including its cluster G and this is the number of clusters, number of samples in that cluster.",
                    "label": 0
                },
                {
                    "sent": "So given this cluster you can estimate the density.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That quite expires in this formula.",
                    "label": 0
                },
                {
                    "sent": "So the goal is like some mixed models to maximize the data likelihoods.",
                    "label": 1
                },
                {
                    "sent": "The stands for data here so.",
                    "label": 0
                },
                {
                    "sent": "Recall this formula.",
                    "label": 0
                },
                {
                    "sent": "We will have to multiply this component for each.",
                    "label": 0
                },
                {
                    "sent": "Clusters at foreach clusters to sample heart problems.",
                    "label": 0
                },
                {
                    "sent": "So in order to come up with efficient algorithm.",
                    "label": 0
                },
                {
                    "sent": "Delta propose an approximate algorithm to solve this.",
                    "label": 1
                },
                {
                    "sent": "So the previous slide we've seen this formula, but here the authors County relaxation where.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Since we don't have labels, instead of using this hearts assignment two clusters they at this profile vector where Qi G shows eisd sense for sample and G stands for cluster.",
                    "label": 0
                },
                {
                    "sent": "It shows relative importance of this sample for that for the test of this cluster.",
                    "label": 0
                },
                {
                    "sent": "So by waiting by using the kernel between the point and other points.",
                    "label": 0
                },
                {
                    "sent": "And the contribution of the point to the cluster.",
                    "label": 1
                },
                {
                    "sent": "You can estimate the conditional density of X given the clusters.",
                    "label": 1
                },
                {
                    "sent": "So for each classes you will have this profile.",
                    "label": 0
                },
                {
                    "sent": "Vectors and by using the by combining these vectors for all classes, you will have this Ant empty matrix Q which is called profile metrics.",
                    "label": 0
                },
                {
                    "sent": "So the aim here is to.",
                    "label": 0
                },
                {
                    "sent": "Find the profile metrics.",
                    "label": 0
                },
                {
                    "sent": "Another important thing to note is that.",
                    "label": 0
                },
                {
                    "sent": "That will leave one out lactic maximization is used in this estimation problem, because when you leave one out.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Left foot is that you exclude your own point from this an samples, otherwise you might end up with overfitting overestimation of Q.",
                    "label": 0
                },
                {
                    "sent": "So 1 two.",
                    "label": 0
                },
                {
                    "sent": "You want to exclude your sample.",
                    "label": 0
                },
                {
                    "sent": "We've used this data.",
                    "label": 0
                },
                {
                    "sent": "Expression so when I is equal to J, this will have one and one lines fun with rent it will exclude your point XI.",
                    "label": 0
                },
                {
                    "sent": "And to calculate our conditional density from the conditional probability, you will just multiply this estimate by the mixing parameters.",
                    "label": 1
                },
                {
                    "sent": "G again, this is the number stands for cluster and I is for your sample.",
                    "label": 0
                },
                {
                    "sent": "Note that this mixing parameters is different from this one for this case and mixing parameters for the cluster is independent of the samples, so it is same for the cluster.",
                    "label": 0
                },
                {
                    "sent": "But in this case.",
                    "label": 0
                },
                {
                    "sent": "It also depends on your sample.",
                    "label": 0
                },
                {
                    "sent": "So mix mixing question for a cluster will be different for each sample you are trying to estimate.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maximize liquid of this.",
                    "label": 0
                },
                {
                    "sent": "Unconditional.",
                    "label": 0
                },
                {
                    "sent": "There's two, plus the authors also protect Gaussian prior to increase the robustness so you will end up with this optimization scheme for Q, an mixing parameter gamma.",
                    "label": 0
                },
                {
                    "sent": "So they don't provide the details of the optimization scheme.",
                    "label": 0
                },
                {
                    "sent": "The paper it is.",
                    "label": 0
                },
                {
                    "sent": "I guess it is a little complicated, but always speaking they follow an attendant alternative approach in each step initiatives operation, you first estimate the profiles Q, Max, Q and then using this Q metrics.",
                    "label": 1
                },
                {
                    "sent": "You try to find, so your labels or.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probabilities are.",
                    "label": 0
                },
                {
                    "sent": "Containing, So once you have this final government, you can just.",
                    "label": 0
                },
                {
                    "sent": "Assign samples to clusters.",
                    "label": 0
                },
                {
                    "sent": "So we have a simple example.",
                    "label": 0
                },
                {
                    "sent": "Here again, two more datasets.",
                    "label": 0
                },
                {
                    "sent": "If you use Gaussian mixture model with two components.",
                    "label": 0
                },
                {
                    "sent": "Since the distribution of data is not cursing, you will not have the optimal.",
                    "label": 0
                },
                {
                    "sent": "Classes, but one cluster will be in this shape.",
                    "label": 0
                },
                {
                    "sent": "This looks Gaussian and the other Gaussian will be in this chip, so it fails in this case.",
                    "label": 0
                },
                {
                    "sent": "But the proposed approach.",
                    "label": 0
                },
                {
                    "sent": "Estimated dances quite well.",
                    "label": 0
                },
                {
                    "sent": "In this point, because of this samples, there's some variation, but still we can say that.",
                    "label": 0
                },
                {
                    "sent": "It doesn't favor fairly good job.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again we use another data set which is known to be difficult for spectral clustering.",
                    "label": 0
                },
                {
                    "sent": "So in this case this is ordinal points.",
                    "label": 0
                },
                {
                    "sent": "We have three clusters, means are.",
                    "label": 0
                },
                {
                    "sent": "020066180 so we have three classes without 4K.",
                    "label": 0
                },
                {
                    "sent": "Mrs Dissenter result perspective.",
                    "label": 0
                },
                {
                    "sent": "Clustering is this.",
                    "label": 0
                },
                {
                    "sent": "So unlike these approaches, the proposed method again gives good estimates for the densities, so these are the results for the estimates.",
                    "label": 0
                },
                {
                    "sent": "10 statements for three clusters, so these are the eyes of counters, so the warmer colors means higher probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Love, guess who's the real data work date?",
                    "label": 0
                },
                {
                    "sent": "Since we have 8 high dimension text datasets.",
                    "label": 1
                },
                {
                    "sent": "So it is very unlikely that you can assume any well known structures like Gaussian distributions to emulate a fun pairwise.",
                    "label": 0
                },
                {
                    "sent": "Affirm measure is used.",
                    "label": 0
                },
                {
                    "sent": "Three types of baselines.",
                    "label": 0
                },
                {
                    "sent": "Classic metal service came is is well known as expected.",
                    "label": 0
                },
                {
                    "sent": "Clustering method is used.",
                    "label": 0
                },
                {
                    "sent": "An linkage.",
                    "label": 0
                },
                {
                    "sent": "Algorithms for hierarchical clustering are also used.",
                    "label": 0
                },
                {
                    "sent": "So we have three linkage algorithms.",
                    "label": 1
                },
                {
                    "sent": "But the best results will be reported for the tables, since K misses his shortcoming for trapping in local minima, five different initialization are used in.",
                    "label": 0
                },
                {
                    "sent": "Extra attempt and the best performance is given.",
                    "label": 1
                },
                {
                    "sent": "And each item is around 10 times to get significantly.",
                    "label": 0
                },
                {
                    "sent": "Results.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And got some make some other models are not used because the.",
                    "label": 1
                },
                {
                    "sent": "Dimension of data is generally bigger than the number of samples, so this full problem.",
                    "label": 1
                },
                {
                    "sent": "Numerical problems when finding the inverse of the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So these are the text datasets, the second column, and shows the number of samples.",
                    "label": 0
                },
                {
                    "sent": "D is the dimension.",
                    "label": 0
                },
                {
                    "sent": "So generally these are high dimensional.",
                    "label": 0
                },
                {
                    "sent": "This is, which is a proud perspective clustering and actually most of the classroom methods.",
                    "label": 0
                },
                {
                    "sent": "G is the number of classes, so we can use this.",
                    "label": 0
                },
                {
                    "sent": "As an input.",
                    "label": 0
                },
                {
                    "sent": "So animal is the proposal.",
                    "label": 0
                },
                {
                    "sent": "We can see that I think.",
                    "label": 0
                },
                {
                    "sent": "Almost in almost all datasets.",
                    "label": 0
                },
                {
                    "sent": "Outperforms the other baselines methods, so system.",
                    "label": 0
                },
                {
                    "sent": "Is his height dimension mean squared error for chemists?",
                    "label": 0
                },
                {
                    "sent": "Doesn't work very well and spectral clustering methods.",
                    "label": 0
                },
                {
                    "sent": "You use G -- 1.",
                    "label": 0
                },
                {
                    "sent": "I can barely use eigenvectors, so.",
                    "label": 0
                },
                {
                    "sent": "Element change, unlike this spectrum metals, anyone can get use of the old kernel metrics, so this might be the reason for this better performance and leakage methods are unfortunately outperformed by other matters.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclusions or summary of the presentation.",
                    "label": 1
                },
                {
                    "sent": "So a nonparametric mixture model for that class is purpose.",
                    "label": 1
                },
                {
                    "sent": "So unlike other methods, you can estimate any densities you don't have to specify any structure for the clusters.",
                    "label": 0
                },
                {
                    "sent": "According to the experiments we showed, the proposed methods outperforms the baseline methods, which includes hierarchal clustering, K means and spectral methods.",
                    "label": 0
                },
                {
                    "sent": "The reason we don't use then that's the best method is that they are generally they can't perform good in high dimension data set because it's generally difficult to define the neighborhood for those dense space approaches.",
                    "label": 0
                },
                {
                    "sent": "So unlike those again, unlike those dance to base methods or cows mixed models, it can also perform well in high dimensional data sets.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have two parameters here.",
                    "label": 0
                },
                {
                    "sent": "One was.",
                    "label": 0
                },
                {
                    "sent": "You might ask the robots to parametres.",
                    "label": 0
                },
                {
                    "sent": "This was excluded, but we have two parameters, one for this.",
                    "label": 0
                },
                {
                    "sent": ", I'm not sure for Gaussian prior and we have the smoothing parameter.",
                    "label": 0
                },
                {
                    "sent": "Sigma, so if you check the paper we can see that this quite robust to the selection of this two parameters.",
                    "label": 1
                },
                {
                    "sent": "But still you can as a future work you can try to optimize bandwidth selection to submitting parameter selection.",
                    "label": 0
                },
                {
                    "sent": "And of course there is always room for improvement in scalability of the classic metals, especially when The Time Machine is high.",
                    "label": 0
                },
                {
                    "sent": "Angelidis so promising method for using in other application with past domains like the application bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "So this is it.",
                    "label": 0
                },
                {
                    "sent": "Thank you for listening.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the presentation.",
                    "label": 0
                },
                {
                    "sent": "Is there any question also?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uninstall the objective with this method.",
                    "label": 0
                },
                {
                    "sent": "Seem to be quite similar to the same supervisors convinced estimation.",
                    "label": 0
                },
                {
                    "sent": "Proposed by one or something and the unseen.",
                    "label": 0
                },
                {
                    "sent": "His paper sets and the.",
                    "label": 0
                },
                {
                    "sent": "Cross Ring performance is quite sensitive to the band wise of the corner of Colonel, otherwise renewal, and he also proposed and automatic gunfire selection method in this paper, so the so I think there.",
                    "label": 0
                },
                {
                    "sent": "So The thing is, well, yeah, you are right that if you choose a very small or very large bandwidth you can end up with medical problems.",
                    "label": 0
                },
                {
                    "sent": "So what they do in this paper is that they use mean pairwise distances and get 5 percentage.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think they should also show a reference there which it might same reference which calculates the bandwidth.",
                    "label": 0
                },
                {
                    "sent": "So there adopting the authors adopting is is in that approach, but again they are using this.",
                    "label": 0
                },
                {
                    "sent": "Bandwidth selection and also their methods.",
                    "label": 0
                },
                {
                    "sent": "I don't need to see related, but there's multiple kernel methods where you don't specify the values, but you can use a family of the same kernel with different bandwidths and find a combination of this channels.",
                    "label": 0
                },
                {
                    "sent": "Maybe those kinds of approaches can also be adopted in this case, but thank you think you can drive the cross validation and trust.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Each day is and also it is kernel mean ship by here right?",
                    "label": 0
                },
                {
                    "sent": "Yes actually yeah, but I think yeah.",
                    "label": 0
                },
                {
                    "sent": "Please, actually, that's a good point.",
                    "label": 0
                },
                {
                    "sent": "A question.",
                    "label": 0
                },
                {
                    "sent": "How can you?",
                    "label": 0
                },
                {
                    "sent": "Work with the Constipation in higher dimensions and a low number of samples.",
                    "label": 0
                },
                {
                    "sent": "How is it performing, yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, The thing is, I'm not an expert, but I saw some methods where you don't estimate whole Journal but.",
                    "label": 0
                },
                {
                    "sent": "You assume that journalists will be sparse, so only some part of the komatik will be meaningful, and I know that says there are some methods which track list meta kernel by assume the kernel will be Spa sandwich.",
                    "label": 0
                },
                {
                    "sent": "Try to estimate only parts of the kernel which are significant.",
                    "label": 0
                },
                {
                    "sent": "But that's a good point.",
                    "label": 0
                },
                {
                    "sent": "I don't have a full answer for that yet.",
                    "label": 0
                }
            ]
        }
    }
}