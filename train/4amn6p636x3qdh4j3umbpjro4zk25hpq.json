{
    "id": "4amn6p636x3qdh4j3umbpjro4zk25hpq",
    "title": "Opportunistic Strategies for Generalized No-Regret Problems",
    "info": {
        "author": [
            "Andrey Bernstein, Technion - Israel Institute of Technology"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_bernstein_problems/",
    "segmentation": [
        [
            "So this is the outline."
        ],
        [
            "In the talk I will be talking about certain generalized, no regret problems.",
            "I will explain their relation to the approachability problem.",
            "And eventually, we'll present what do we mean by opportunistic?",
            "No regret strategies."
        ],
        [
            "So let's start."
        ],
        [
            "With general setting of no regret.",
            "Learning, which is a standard setting of two players, the agent and the opponent.",
            "So the difference in the setting that we present is that the reward payoff is a vector valued function.",
            "So in this setting we assume the following two things about what we have.",
            "What agent has.",
            "So for each mixed action of the opponent, we assume that the agent has a desired pay offset our Star Q.",
            "And a response function P star Q which actually brings the expected payoff vector to the desired set.",
            "OK, so you can think we'll see that it's just a generalization of a standard no regret notion using the following definition."
        ],
        [
            "So we say that an algorithm is a no regret algorithm with respect to the function are stark.",
            "You if the agent can bring the average reward vector to this set, are stark Q bark bark you anywhere bar que is the expected frequent the average empirical frequency of the opening section?",
            "OK, so if this holds almost surely forever strategy of the opponent.",
            "Then we say that the strategies has no regret with respect to this Arthur Q and we can easy.",
            "So we just say for sure that the average reward approaches are star in this case.",
            "And it's easy to see that the standard no regret case is a special case of this definition.",
            "By using scholar rewards and the desired set, our Star Q, which is defined as old scholars R which are above the best reward in hindsight forgiven Q.",
            "So where are star Q the small?",
            "Our Star Q is the best reward in height and basically this is the standard definition of regret and the proof of existence of no regret algorithms in this standard setting is.",
            "If it essentially relies on the convexity of this multifunction, our Star Q, which in this case is convex because of the convexity of small, are starting.",
            "But in this paper, our main interest was in nonconvex multifunction, Arthur Q and we will see now an example.",
            "Why it's interesting?"
        ],
        [
            "So the example is of constraint regret minimization.",
            "And in this case, in addition to maximizing the average reward.",
            "We have certain cost function CAZ which would like to keep under a certain threshold in the in the long term sense.",
            "OK, so now we have two component components of the basically of the in our in our problem and we have a trade off between them.",
            "So first we would like to have no regret with respect to the scholar reward function and Secondly would like to have the average cost to be bounded in the long term by by the constant gamma.",
            "Of course this can be generalized for any convex constraints, But let's consider for simplicity the linear constraints of this four and let's define the best reward in hindsight.",
            "Problem, which is basically the solution of the constraint optimization problem which is written here in mixed actions.",
            "So this is the equivalent of the best reward in hindsight.",
            "Are star Q here.",
            "For the constraint case.",
            "So.",
            "We can divide, define the desired set of the pairs, reward costs.",
            "This big are star Q which is all the pairs you see so that U is above the constraint.",
            "Best reward in hindsight and the cost is below the given constant gum.",
            "And of course, we can also define the response in this case, because if we just use the mixed action that solves the optimization problem, this optimization problem, then we have the desired property.",
            "So if we choose this mixed action, the average the expected reward are of the star Q&Q is in big artstar.",
            "By the definition, just by the definition.",
            "But the main thing here to notice that this function, that big our structure is actually a non convex set value function cause the best reward in hindsight.",
            "Here in this case this function is non convex.",
            "Compared to the standard case.",
            "And it was shown also by menorah talent to 1009 that we cannot attain.",
            "No regret in general in this problem against the general opponent.",
            "And again this follows basically from the non convexity of this multi function."
        ],
        [
            "So to show this or just to have an idea why this is true, let's let's connect this."
        ],
        [
            "Them to the approachability problem that already was presented yesterday.",
            "So just briefly the approachability.",
            "We can see it as a another generalization of the previous problem, where the goal is to approach a certain target set South, namely to bring the average reward payoff to the set no matter what the opponent.",
            "Doesn't this if this can be done, then we say that X is approaching.",
            "OK, this is briefly what is approachability and there are many.",
            "I mean there are steps, standard results that I will also mention briefly now.",
            "But first let's see how our generalized no regret problem can be formulated as a special case of approachability so we can see that if we define.",
            "The following target set, which.",
            "It is a collection of pairs.",
            "RQ so that R is in Arthur Q.",
            "Basically we have here and a lift that version of vector valued pair of where we include in a vector reward also.",
            "In addition to the original vector reward, we include also the mixed action of the opponent.",
            "So if we define this problem, this problem in the approachability sense is equivalent to having no regret with respect to our Star Q. OK, because if the virtual world converges to this set, then.",
            "It will be eventually in the desired rewards set.",
            "So.",
            "Well then this is important thing that this set satisfies.",
            "Actually this set that is defined here.",
            "We can show that it's not excludable in the sense that for any mixed action Q of the opponent, we have a response.",
            "Mixed action of the agent so that the average payoff is in S, and this is actually necessary condition for possibility of any set.",
            "As was shown by Blackwell, but.",
            "Anne.",
            "And we and we call these sets D sets just for distance here for dual.",
            "But the main."
        ],
        [
            "Interesting thing is that this condition which is necessary for general sets is necessary and sufficient for convex sets.",
            "Again, this is a standard result from approachability.",
            "And the same result also implies that if you take a convex Hull over the set, it will be approachable.",
            "OK, because convex Hull over this it is a convex set.",
            "And its approach.",
            "So this means that from these results we can have the following result against a general opponent.",
            "Is that the convex Hull of the set which related to the general is not regular problem is approachable.",
            "In this case the convex Hull of the set of the target set can be written as the.",
            "All the pairs are star R&Q, so that R is in MCQ where RC is the convex Hull of the multifunction arse Turkey.",
            "And the convex Hull of a set value function, roughly speaking, is the smallest convex multi function that contains our star.",
            "OK, so this is the best thing that can be guaranteed against the general opponent, but the main observation that we want to make in this paper is that.",
            "We can do better if the opponent is regular in some sense.",
            "OK, so if we know, for example that the opponent is stationary, namely it just uses the same extraction at each time step, then of course we can just obtain the original desired set.",
            "Our star Q just by estimating the strategy of the opponent and doing best response.",
            "Let's say to this strategy.",
            "But of course we don't know this in advance, and the main requirement that we.",
            "Post here is that we want online algorithms that capitalize on this regularity.",
            "Anne.",
            "In an online manner, trying to approach the best set they can approach.",
            "Against a given opponent.",
            "If opponent is very not nice then you will approach the convex Hull as guaranteed by the approachability.",
            "But if for example, if it converged the mixed actions or even the empirical frequencies converge to certain point, then we would like to have a result that.",
            "Our algorithm."
        ],
        [
            "Means the strict goal and, well, we show that there exists.",
            "The main result is that the existence of such an algorithm and this algorithm."
        ],
        [
            "Actually, which is based on the calibration, and I will now mention briefly what is collaboration.",
            "So basically I'm talking about forecasting the actions of the opponent.",
            "So in general we have a certain probability YN at time N, which predicts the actions and the basic requirement from a former forecaster is is, is that it is calibrated and roughly speaking, what is calibration if we consider?",
            "Prediction of rain, for example, and then the forecaster predicts, let's say, 90% of rain at certain days.",
            "So calibration means that at those days, 90% of those days there were there was rain.",
            "OK, so this is very roughly speaking.",
            "What is calibration?",
            "But this is written here mathematically and this is this requirement from a forecaster is very basic.",
            "It doesn't says anything about.",
            "Well, it doesn't say that the forecaster is very good or it's very bad, but.",
            "This is the property and this property is some sort of mixing property and it turns out to be useful.",
            "In many applications, and also here.",
            "So the main result from the 85 is that there are no calibrated forecasters which are deterministic.",
            "So basically the forecaster should randomize in the sense that there is a probability distribution at the North from which the forecast is drawn, and then there is there is a forecaster that is run is calibrated for any possible sequence.",
            "OK, so."
        ],
        [
            "Having this machinery, let's say we assume that we have the calibrated forecast.",
            "The algorithm that computes the calibrated forecast.",
            "Then our algorithm is very simple.",
            "Ann is the following thing so.",
            "Recall that we have a response function.",
            "Which the interpretation is that for any Q you have some kind of mix action QP that.",
            "Brings the expected one step reward vector into the desired set.",
            "OK, this is our basic assumption in generalized no regret problem.",
            "So basically we use this response function to act against the opponent, but we use it with the calibrated forecast.",
            "So basically have a response to calibrated forecast at time.",
            "And this strategy was proposed previously by per share, but it was not analyzed in this in this setting of opportunistic portability.",
            "So basically the proof of general general, no regret or general approach ability will use these terms, both because they are really connected here.",
            "So the proof is very simple.",
            "The proof of general approach ability well for the convex Hull of the set.",
            "Is based on this simple relations.",
            "We just proved that the average reward vector converges to the average of our star.",
            "Add the calibrated forecasts and from the calibration property we know that the empirical frequencies also converge to the average of the forecasts and this by definition means that this thing converge to the.",
            "To the RC of QN.",
            "And we have done, but of course well, this very I'm omitting many steps, but this is the idea.",
            "So but"
        ],
        [
            "I remind you that we won."
        ],
        [
            "Something more from the algorithm.",
            "Basically what I showed now here briefly is that the algorithm against the general opponent attains the convex Hull.",
            "And this is the first goal, but we want algorithm that simultaneously does also this thing.",
            "Let's say we have restricted opponent in terms of empirical frequencies.",
            "And let's say they converge to some set.",
            "Then we would like to obtain a strict subset of RRC and in the case of stationary opponent, would like to obtain our star itself.",
            "And the main result is that our algorithm does this and actually."
        ],
        [
            "It's more things and I would like to define more formally.",
            "What does it mean?",
            "Empirical or does it mean that the opponent is restricted, so I'm starting with very simple definition in terms of statistical properties of the opponent.",
            "We say that the opponent is statistically curious stricted if.",
            "The next section of the opponent converge to some set Q of the of the simplex OK in this, in this desirable mean sense.",
            "But this definition is basically has certain weakness and this weakness is twofold and 1st.",
            "We don't necessarily know the mixed actions of the opponent, and the 2nd is that even they may be meaningless.",
            "Becausw maybe we are facing individual sequences.",
            "Of."
        ],
        [
            "Or actions, so we want another definition which is.",
            "We call empirically heuristic that play with respect to a given partition, where we compute the frequencies of the pure actions on a given partition, and we require that the same.",
            "Says Arrow mean weighted Sarah mean on this partition convergence.",
            "The empirical frequencies converge to QoS set key."
        ],
        [
            "So I will skip this."
        ],
        [
            "And basically what we want to say is that given AQ, if the opponent is key restricted, then we require essentially convergence of the average reward payoff to restriction of the RC to this set key, which is written mathematically here.",
            "So you see here, this is basically the convex Hull, but the Qi are restricted to Q.",
            "And just a sanity check is that if we take a Singleton Q 0.",
            "Then this is the same as convergent to the original R Star Q0 and if we take the whole simplex so there is no restriction, then we actually have only guaranteed that we converge to the convex Hull.",
            "But we can have anything in between."
        ],
        [
            "OK, there is a refinement of this thing.",
            "I don't have time to get into it.",
            "I will skip this.",
            "Basically we need also include the jumps cause the possible discontinuities."
        ],
        [
            "The main result is that opportunistic strategy has to be.",
            "It has no regret with respect to this restricted.",
            "The restriction of the RC to key in terms of the following definitions.",
            "The same.",
            "No regret property.",
            "But here we put the actual restriction of the target set to the restriction set Q.",
            "And we have two definitions, one in terms of the statistical restricted play and the 2nd is in terms of the empirical restricted play."
        ],
        [
            "So finally for to the main results I remind you the algorithm that we were analyzing.",
            "The algorithm is just doing the best response during the response to calibrate it forecasts and main result is that this algorithm is statistically statistically opportunistic.",
            "So if the opponent is statistically curious stricted, then we obtain this no regret property with respect to the restriction set.",
            "And it is also empirically opportunistic.",
            "But the main condition for empirical.",
            "Organism here is slowly change slowly varying calibration algorithm this this particular condition.",
            "So remind you that at the end is the distribution of the forecasts of the calibrated forecasts.",
            "In order to prove empirical opportunism, we need this slowly varying condition and the complementary theorem is that we show that there exists such calibrated forecasts and in particular the one of them.",
            "Famous ones which are based on internal organ minimization is like this.",
            "We don't know if this is the general case, this is just still an open question, but at least one exists that is slowly varying in this sense.",
            "So this was very technical theorem which.",
            "Required a lot of pages of proofs.",
            "This is less.",
            "This is more nicer, nicer result.",
            "There's a, there's a proof, it's nicer."
        ],
        [
            "So OK, so there is a proof idea, but I'm not sure I have time for this.",
            "I would just like to."
        ],
        [
            "Summarize.",
            "Something regarding the computational issues and convergence rate.",
            "So first of all, the calibration is known to be very hard and I don't want to get into detail what does it mean, but it's a hard problem and there are no efficient.",
            "Calibration algorithms epsilon collaboration is possible, but then you will have epsilon, approachability and then the convergence rate is regular.",
            "Standard approach ability convergence rate.",
            "But the main point in this work was not efficiency actually, but the idea of the concept and the existence of such algorithms.",
            "And if we want an efficient algorithm, we can offer another algorithm that works differently.",
            "It works on blocks and does some kind of no regret with respect to projected Scholary work function and this algorithm can be applied in practice, but it has less nice guarantees.",
            "OK, so this is."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the outline.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the talk I will be talking about certain generalized, no regret problems.",
                    "label": 0
                },
                {
                    "sent": "I will explain their relation to the approachability problem.",
                    "label": 0
                },
                {
                    "sent": "And eventually, we'll present what do we mean by opportunistic?",
                    "label": 0
                },
                {
                    "sent": "No regret strategies.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With general setting of no regret.",
                    "label": 0
                },
                {
                    "sent": "Learning, which is a standard setting of two players, the agent and the opponent.",
                    "label": 1
                },
                {
                    "sent": "So the difference in the setting that we present is that the reward payoff is a vector valued function.",
                    "label": 0
                },
                {
                    "sent": "So in this setting we assume the following two things about what we have.",
                    "label": 0
                },
                {
                    "sent": "What agent has.",
                    "label": 0
                },
                {
                    "sent": "So for each mixed action of the opponent, we assume that the agent has a desired pay offset our Star Q.",
                    "label": 1
                },
                {
                    "sent": "And a response function P star Q which actually brings the expected payoff vector to the desired set.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can think we'll see that it's just a generalization of a standard no regret notion using the following definition.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we say that an algorithm is a no regret algorithm with respect to the function are stark.",
                    "label": 1
                },
                {
                    "sent": "You if the agent can bring the average reward vector to this set, are stark Q bark bark you anywhere bar que is the expected frequent the average empirical frequency of the opening section?",
                    "label": 1
                },
                {
                    "sent": "OK, so if this holds almost surely forever strategy of the opponent.",
                    "label": 0
                },
                {
                    "sent": "Then we say that the strategies has no regret with respect to this Arthur Q and we can easy.",
                    "label": 0
                },
                {
                    "sent": "So we just say for sure that the average reward approaches are star in this case.",
                    "label": 0
                },
                {
                    "sent": "And it's easy to see that the standard no regret case is a special case of this definition.",
                    "label": 1
                },
                {
                    "sent": "By using scholar rewards and the desired set, our Star Q, which is defined as old scholars R which are above the best reward in hindsight forgiven Q.",
                    "label": 1
                },
                {
                    "sent": "So where are star Q the small?",
                    "label": 1
                },
                {
                    "sent": "Our Star Q is the best reward in height and basically this is the standard definition of regret and the proof of existence of no regret algorithms in this standard setting is.",
                    "label": 0
                },
                {
                    "sent": "If it essentially relies on the convexity of this multifunction, our Star Q, which in this case is convex because of the convexity of small, are starting.",
                    "label": 0
                },
                {
                    "sent": "But in this paper, our main interest was in nonconvex multifunction, Arthur Q and we will see now an example.",
                    "label": 0
                },
                {
                    "sent": "Why it's interesting?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the example is of constraint regret minimization.",
                    "label": 1
                },
                {
                    "sent": "And in this case, in addition to maximizing the average reward.",
                    "label": 0
                },
                {
                    "sent": "We have certain cost function CAZ which would like to keep under a certain threshold in the in the long term sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have two component components of the basically of the in our in our problem and we have a trade off between them.",
                    "label": 0
                },
                {
                    "sent": "So first we would like to have no regret with respect to the scholar reward function and Secondly would like to have the average cost to be bounded in the long term by by the constant gamma.",
                    "label": 1
                },
                {
                    "sent": "Of course this can be generalized for any convex constraints, But let's consider for simplicity the linear constraints of this four and let's define the best reward in hindsight.",
                    "label": 0
                },
                {
                    "sent": "Problem, which is basically the solution of the constraint optimization problem which is written here in mixed actions.",
                    "label": 0
                },
                {
                    "sent": "So this is the equivalent of the best reward in hindsight.",
                    "label": 0
                },
                {
                    "sent": "Are star Q here.",
                    "label": 1
                },
                {
                    "sent": "For the constraint case.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can divide, define the desired set of the pairs, reward costs.",
                    "label": 1
                },
                {
                    "sent": "This big are star Q which is all the pairs you see so that U is above the constraint.",
                    "label": 0
                },
                {
                    "sent": "Best reward in hindsight and the cost is below the given constant gum.",
                    "label": 0
                },
                {
                    "sent": "And of course, we can also define the response in this case, because if we just use the mixed action that solves the optimization problem, this optimization problem, then we have the desired property.",
                    "label": 0
                },
                {
                    "sent": "So if we choose this mixed action, the average the expected reward are of the star Q&Q is in big artstar.",
                    "label": 0
                },
                {
                    "sent": "By the definition, just by the definition.",
                    "label": 1
                },
                {
                    "sent": "But the main thing here to notice that this function, that big our structure is actually a non convex set value function cause the best reward in hindsight.",
                    "label": 0
                },
                {
                    "sent": "Here in this case this function is non convex.",
                    "label": 0
                },
                {
                    "sent": "Compared to the standard case.",
                    "label": 0
                },
                {
                    "sent": "And it was shown also by menorah talent to 1009 that we cannot attain.",
                    "label": 0
                },
                {
                    "sent": "No regret in general in this problem against the general opponent.",
                    "label": 0
                },
                {
                    "sent": "And again this follows basically from the non convexity of this multi function.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to show this or just to have an idea why this is true, let's let's connect this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Them to the approachability problem that already was presented yesterday.",
                    "label": 1
                },
                {
                    "sent": "So just briefly the approachability.",
                    "label": 0
                },
                {
                    "sent": "We can see it as a another generalization of the previous problem, where the goal is to approach a certain target set South, namely to bring the average reward payoff to the set no matter what the opponent.",
                    "label": 1
                },
                {
                    "sent": "Doesn't this if this can be done, then we say that X is approaching.",
                    "label": 0
                },
                {
                    "sent": "OK, this is briefly what is approachability and there are many.",
                    "label": 0
                },
                {
                    "sent": "I mean there are steps, standard results that I will also mention briefly now.",
                    "label": 0
                },
                {
                    "sent": "But first let's see how our generalized no regret problem can be formulated as a special case of approachability so we can see that if we define.",
                    "label": 0
                },
                {
                    "sent": "The following target set, which.",
                    "label": 0
                },
                {
                    "sent": "It is a collection of pairs.",
                    "label": 0
                },
                {
                    "sent": "RQ so that R is in Arthur Q.",
                    "label": 0
                },
                {
                    "sent": "Basically we have here and a lift that version of vector valued pair of where we include in a vector reward also.",
                    "label": 0
                },
                {
                    "sent": "In addition to the original vector reward, we include also the mixed action of the opponent.",
                    "label": 0
                },
                {
                    "sent": "So if we define this problem, this problem in the approachability sense is equivalent to having no regret with respect to our Star Q. OK, because if the virtual world converges to this set, then.",
                    "label": 1
                },
                {
                    "sent": "It will be eventually in the desired rewards set.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well then this is important thing that this set satisfies.",
                    "label": 0
                },
                {
                    "sent": "Actually this set that is defined here.",
                    "label": 0
                },
                {
                    "sent": "We can show that it's not excludable in the sense that for any mixed action Q of the opponent, we have a response.",
                    "label": 0
                },
                {
                    "sent": "Mixed action of the agent so that the average payoff is in S, and this is actually necessary condition for possibility of any set.",
                    "label": 0
                },
                {
                    "sent": "As was shown by Blackwell, but.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And we and we call these sets D sets just for distance here for dual.",
                    "label": 0
                },
                {
                    "sent": "But the main.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interesting thing is that this condition which is necessary for general sets is necessary and sufficient for convex sets.",
                    "label": 0
                },
                {
                    "sent": "Again, this is a standard result from approachability.",
                    "label": 0
                },
                {
                    "sent": "And the same result also implies that if you take a convex Hull over the set, it will be approachable.",
                    "label": 0
                },
                {
                    "sent": "OK, because convex Hull over this it is a convex set.",
                    "label": 1
                },
                {
                    "sent": "And its approach.",
                    "label": 0
                },
                {
                    "sent": "So this means that from these results we can have the following result against a general opponent.",
                    "label": 0
                },
                {
                    "sent": "Is that the convex Hull of the set which related to the general is not regular problem is approachable.",
                    "label": 0
                },
                {
                    "sent": "In this case the convex Hull of the set of the target set can be written as the.",
                    "label": 1
                },
                {
                    "sent": "All the pairs are star R&Q, so that R is in MCQ where RC is the convex Hull of the multifunction arse Turkey.",
                    "label": 0
                },
                {
                    "sent": "And the convex Hull of a set value function, roughly speaking, is the smallest convex multi function that contains our star.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the best thing that can be guaranteed against the general opponent, but the main observation that we want to make in this paper is that.",
                    "label": 0
                },
                {
                    "sent": "We can do better if the opponent is regular in some sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we know, for example that the opponent is stationary, namely it just uses the same extraction at each time step, then of course we can just obtain the original desired set.",
                    "label": 0
                },
                {
                    "sent": "Our star Q just by estimating the strategy of the opponent and doing best response.",
                    "label": 0
                },
                {
                    "sent": "Let's say to this strategy.",
                    "label": 0
                },
                {
                    "sent": "But of course we don't know this in advance, and the main requirement that we.",
                    "label": 0
                },
                {
                    "sent": "Post here is that we want online algorithms that capitalize on this regularity.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "In an online manner, trying to approach the best set they can approach.",
                    "label": 0
                },
                {
                    "sent": "Against a given opponent.",
                    "label": 0
                },
                {
                    "sent": "If opponent is very not nice then you will approach the convex Hull as guaranteed by the approachability.",
                    "label": 0
                },
                {
                    "sent": "But if for example, if it converged the mixed actions or even the empirical frequencies converge to certain point, then we would like to have a result that.",
                    "label": 0
                },
                {
                    "sent": "Our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Means the strict goal and, well, we show that there exists.",
                    "label": 0
                },
                {
                    "sent": "The main result is that the existence of such an algorithm and this algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, which is based on the calibration, and I will now mention briefly what is collaboration.",
                    "label": 0
                },
                {
                    "sent": "So basically I'm talking about forecasting the actions of the opponent.",
                    "label": 1
                },
                {
                    "sent": "So in general we have a certain probability YN at time N, which predicts the actions and the basic requirement from a former forecaster is is, is that it is calibrated and roughly speaking, what is calibration if we consider?",
                    "label": 0
                },
                {
                    "sent": "Prediction of rain, for example, and then the forecaster predicts, let's say, 90% of rain at certain days.",
                    "label": 0
                },
                {
                    "sent": "So calibration means that at those days, 90% of those days there were there was rain.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is very roughly speaking.",
                    "label": 0
                },
                {
                    "sent": "What is calibration?",
                    "label": 1
                },
                {
                    "sent": "But this is written here mathematically and this is this requirement from a forecaster is very basic.",
                    "label": 0
                },
                {
                    "sent": "It doesn't says anything about.",
                    "label": 0
                },
                {
                    "sent": "Well, it doesn't say that the forecaster is very good or it's very bad, but.",
                    "label": 0
                },
                {
                    "sent": "This is the property and this property is some sort of mixing property and it turns out to be useful.",
                    "label": 0
                },
                {
                    "sent": "In many applications, and also here.",
                    "label": 0
                },
                {
                    "sent": "So the main result from the 85 is that there are no calibrated forecasters which are deterministic.",
                    "label": 0
                },
                {
                    "sent": "So basically the forecaster should randomize in the sense that there is a probability distribution at the North from which the forecast is drawn, and then there is there is a forecaster that is run is calibrated for any possible sequence.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Having this machinery, let's say we assume that we have the calibrated forecast.",
                    "label": 0
                },
                {
                    "sent": "The algorithm that computes the calibrated forecast.",
                    "label": 1
                },
                {
                    "sent": "Then our algorithm is very simple.",
                    "label": 1
                },
                {
                    "sent": "Ann is the following thing so.",
                    "label": 1
                },
                {
                    "sent": "Recall that we have a response function.",
                    "label": 0
                },
                {
                    "sent": "Which the interpretation is that for any Q you have some kind of mix action QP that.",
                    "label": 0
                },
                {
                    "sent": "Brings the expected one step reward vector into the desired set.",
                    "label": 0
                },
                {
                    "sent": "OK, this is our basic assumption in generalized no regret problem.",
                    "label": 0
                },
                {
                    "sent": "So basically we use this response function to act against the opponent, but we use it with the calibrated forecast.",
                    "label": 0
                },
                {
                    "sent": "So basically have a response to calibrated forecast at time.",
                    "label": 1
                },
                {
                    "sent": "And this strategy was proposed previously by per share, but it was not analyzed in this in this setting of opportunistic portability.",
                    "label": 0
                },
                {
                    "sent": "So basically the proof of general general, no regret or general approach ability will use these terms, both because they are really connected here.",
                    "label": 0
                },
                {
                    "sent": "So the proof is very simple.",
                    "label": 0
                },
                {
                    "sent": "The proof of general approach ability well for the convex Hull of the set.",
                    "label": 0
                },
                {
                    "sent": "Is based on this simple relations.",
                    "label": 0
                },
                {
                    "sent": "We just proved that the average reward vector converges to the average of our star.",
                    "label": 0
                },
                {
                    "sent": "Add the calibrated forecasts and from the calibration property we know that the empirical frequencies also converge to the average of the forecasts and this by definition means that this thing converge to the.",
                    "label": 0
                },
                {
                    "sent": "To the RC of QN.",
                    "label": 0
                },
                {
                    "sent": "And we have done, but of course well, this very I'm omitting many steps, but this is the idea.",
                    "label": 0
                },
                {
                    "sent": "So but",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I remind you that we won.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something more from the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Basically what I showed now here briefly is that the algorithm against the general opponent attains the convex Hull.",
                    "label": 1
                },
                {
                    "sent": "And this is the first goal, but we want algorithm that simultaneously does also this thing.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have restricted opponent in terms of empirical frequencies.",
                    "label": 0
                },
                {
                    "sent": "And let's say they converge to some set.",
                    "label": 0
                },
                {
                    "sent": "Then we would like to obtain a strict subset of RRC and in the case of stationary opponent, would like to obtain our star itself.",
                    "label": 1
                },
                {
                    "sent": "And the main result is that our algorithm does this and actually.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's more things and I would like to define more formally.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "Empirical or does it mean that the opponent is restricted, so I'm starting with very simple definition in terms of statistical properties of the opponent.",
                    "label": 1
                },
                {
                    "sent": "We say that the opponent is statistically curious stricted if.",
                    "label": 1
                },
                {
                    "sent": "The next section of the opponent converge to some set Q of the of the simplex OK in this, in this desirable mean sense.",
                    "label": 0
                },
                {
                    "sent": "But this definition is basically has certain weakness and this weakness is twofold and 1st.",
                    "label": 0
                },
                {
                    "sent": "We don't necessarily know the mixed actions of the opponent, and the 2nd is that even they may be meaningless.",
                    "label": 1
                },
                {
                    "sent": "Becausw maybe we are facing individual sequences.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or actions, so we want another definition which is.",
                    "label": 0
                },
                {
                    "sent": "We call empirically heuristic that play with respect to a given partition, where we compute the frequencies of the pure actions on a given partition, and we require that the same.",
                    "label": 0
                },
                {
                    "sent": "Says Arrow mean weighted Sarah mean on this partition convergence.",
                    "label": 0
                },
                {
                    "sent": "The empirical frequencies converge to QoS set key.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will skip this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And basically what we want to say is that given AQ, if the opponent is key restricted, then we require essentially convergence of the average reward payoff to restriction of the RC to this set key, which is written mathematically here.",
                    "label": 0
                },
                {
                    "sent": "So you see here, this is basically the convex Hull, but the Qi are restricted to Q.",
                    "label": 0
                },
                {
                    "sent": "And just a sanity check is that if we take a Singleton Q 0.",
                    "label": 0
                },
                {
                    "sent": "Then this is the same as convergent to the original R Star Q0 and if we take the whole simplex so there is no restriction, then we actually have only guaranteed that we converge to the convex Hull.",
                    "label": 0
                },
                {
                    "sent": "But we can have anything in between.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there is a refinement of this thing.",
                    "label": 0
                },
                {
                    "sent": "I don't have time to get into it.",
                    "label": 0
                },
                {
                    "sent": "I will skip this.",
                    "label": 0
                },
                {
                    "sent": "Basically we need also include the jumps cause the possible discontinuities.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main result is that opportunistic strategy has to be.",
                    "label": 1
                },
                {
                    "sent": "It has no regret with respect to this restricted.",
                    "label": 1
                },
                {
                    "sent": "The restriction of the RC to key in terms of the following definitions.",
                    "label": 0
                },
                {
                    "sent": "The same.",
                    "label": 0
                },
                {
                    "sent": "No regret property.",
                    "label": 0
                },
                {
                    "sent": "But here we put the actual restriction of the target set to the restriction set Q.",
                    "label": 0
                },
                {
                    "sent": "And we have two definitions, one in terms of the statistical restricted play and the 2nd is in terms of the empirical restricted play.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally for to the main results I remind you the algorithm that we were analyzing.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is just doing the best response during the response to calibrate it forecasts and main result is that this algorithm is statistically statistically opportunistic.",
                    "label": 0
                },
                {
                    "sent": "So if the opponent is statistically curious stricted, then we obtain this no regret property with respect to the restriction set.",
                    "label": 1
                },
                {
                    "sent": "And it is also empirically opportunistic.",
                    "label": 1
                },
                {
                    "sent": "But the main condition for empirical.",
                    "label": 0
                },
                {
                    "sent": "Organism here is slowly change slowly varying calibration algorithm this this particular condition.",
                    "label": 0
                },
                {
                    "sent": "So remind you that at the end is the distribution of the forecasts of the calibrated forecasts.",
                    "label": 1
                },
                {
                    "sent": "In order to prove empirical opportunism, we need this slowly varying condition and the complementary theorem is that we show that there exists such calibrated forecasts and in particular the one of them.",
                    "label": 1
                },
                {
                    "sent": "Famous ones which are based on internal organ minimization is like this.",
                    "label": 0
                },
                {
                    "sent": "We don't know if this is the general case, this is just still an open question, but at least one exists that is slowly varying in this sense.",
                    "label": 0
                },
                {
                    "sent": "So this was very technical theorem which.",
                    "label": 0
                },
                {
                    "sent": "Required a lot of pages of proofs.",
                    "label": 0
                },
                {
                    "sent": "This is less.",
                    "label": 0
                },
                {
                    "sent": "This is more nicer, nicer result.",
                    "label": 0
                },
                {
                    "sent": "There's a, there's a proof, it's nicer.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so there is a proof idea, but I'm not sure I have time for this.",
                    "label": 0
                },
                {
                    "sent": "I would just like to.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summarize.",
                    "label": 0
                },
                {
                    "sent": "Something regarding the computational issues and convergence rate.",
                    "label": 1
                },
                {
                    "sent": "So first of all, the calibration is known to be very hard and I don't want to get into detail what does it mean, but it's a hard problem and there are no efficient.",
                    "label": 0
                },
                {
                    "sent": "Calibration algorithms epsilon collaboration is possible, but then you will have epsilon, approachability and then the convergence rate is regular.",
                    "label": 0
                },
                {
                    "sent": "Standard approach ability convergence rate.",
                    "label": 0
                },
                {
                    "sent": "But the main point in this work was not efficiency actually, but the idea of the concept and the existence of such algorithms.",
                    "label": 1
                },
                {
                    "sent": "And if we want an efficient algorithm, we can offer another algorithm that works differently.",
                    "label": 0
                },
                {
                    "sent": "It works on blocks and does some kind of no regret with respect to projected Scholary work function and this algorithm can be applied in practice, but it has less nice guarantees.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                }
            ]
        }
    }
}