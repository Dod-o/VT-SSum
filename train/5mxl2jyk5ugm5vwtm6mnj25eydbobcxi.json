{
    "id": "5mxl2jyk5ugm5vwtm6mnj25eydbobcxi",
    "title": "Learning to See",
    "info": {
        "author": [
            "Antonio Torralba, Center for Future Civic Media, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_torralba_learning_see/",
    "segmentation": [
        [
            "OK, so if you know that alqueire star lowering my voice just tell me at the back of the room is you cannot hear me because I'm kind of jet lag so I might fall asleep at some point."
        ],
        [
            "OK, so it is a really exciting time for computer vision.",
            "You have seen all the things that Rob has been showing you.",
            "It really works really well.",
            "There are many different applications that are working nowadays and it's really exciting time for computer vision.",
            "But things have not been always like this."
        ],
        [
            "So just let me tell you a little bit of his story before I go into what we're doing now.",
            "So films start."
        ],
        [
            "Long time ago people were really optimistic.",
            "You know, in the 60s this is a tech report from the eye lab from Simon Popper and his team decided that computer vision was really simple, so he decided to solve vision in a summer project.",
            "So he took the students that were not even graduated students because he thought it was too simple for a grad student to do and he asked them to Salvation.",
            "So this tech report at lies all the different things that they need to solve in order to have a visual system.",
            "And it's a really interesting read because it actually, you know.",
            "Post as many of the interesting things that need to be solved, but there still then struggled during the entire summer and they didn't really get anything out."
        ],
        [
            "And the problem is that something like 50 or 6070 years ago you take."
        ],
        [
            "An image like this one job.",
            "Load it into your computer to do some analysis, and this is the typical output.",
            "So there was basically.",
            "There was basically nothing you could do.",
            "Computers were really slow and despite of that they actually made a lot of progress in the algorithms and the methods and so on, but they could actually try them very well things."
        ],
        [
            "Got a lot better than you know 25 years ago.",
            "You could take a pic."
        ],
        [
            "Sure you could upload it in the computer.",
            "It wouldn't give you out of memory and this was the typical output of a system.",
            "So many of us have worked with systems like this ones are.",
            "You could publish this.",
            "It was not so bad."
        ],
        [
            "And you know it was really depressing at the time because you are working.",
            "You get this algorithm and it's very depressing, because vision seems so easy for us.",
            "Seeing is such a simple task.",
            "In fact.",
            "Let me show you a video is a very low resolution video, so this is starting the vision crisis."
        ],
        [
            "It's a very low resolution video and you can recognize everything that is going on here.",
            "It contains about 20 pixels worth of vertical resolution, so it's really low resolution.",
            "Most of the objects take maybe just one pixel and still you can recognize everything that goes on here because for you vision is so easy you see you open your eyes in the morning and you get to see.",
            "And it's just simple Journal Titof scene at the end of the day, despite the old your brain is devoted to see in the world time.",
            "But for you, it's not.",
            "It's not.",
            "It's not a hard thing.",
            "So it's very hard to convince your parents that you're doing something interesting now because it seems so easy.",
            "OK, this is a chair, just tell me it's a chair just recognizing why is just system not working and The thing is that when you see you actually put into the world alot more than what there is actually there, now you get to interpret what you see.",
            "So for realizing that, let me show you the high resolution video."
        ],
        [
            "So this is a.",
            "You can see that you know you wear.",
            "Seeing a lot of things that were not really there, this is a.",
            "This is a ferragus.",
            "Will recorded this when we were sharing office when we were post docs on Bill Freeman was paying us and we were recording videos like this one here.",
            "So you can see that you know."
        ],
        [
            "Despite a very low resolution, you still you know you get to interpret because you're projecting into the video.",
            "All the things that you know about the world, you have all these contextual relationships.",
            "All these semantics and common sense knowledge that you have that help you to interpret the visual world an.",
            "That's what makes vision so hard.",
            "How do you get all those things into a computer?",
            "In fact, when I show you a picture like this one, you can recognize perfectly what is the object behind the red mask.",
            "Despite that you don't see it, and it's because you know all the things that make the world, so I'm sure."
        ],
        [
            "You got it right."
        ],
        [
            "But 15 years ago, things change quite dramatically.",
            "An in particular phase detection appear as the first thing that actually was working at a commercial grade, and it was a recognition task.",
            "There were other things working, but for object recognition, face detection was probably the first thing that made it into the commercial world.",
            "So Paul Viola and Mike Jones introduce have really interesting detector for faces that was able to work in real time with really cheap processors and most digital cameras have now.",
            "Face detection that relies on that algorithm."
        ],
        [
            "So, well, you know things like Facebook like Google will just hit to blur faces on Street View an it will blur all."
        ],
        [
            "Some things, but it worked really well and it was, you know, deploy in billions of images in super real time because they had to filter all those images really really fast so it was just an amazing thing."
        ],
        [
            "And this created a big advance in all kinds of methods in computer vision, most of them were handcrafted features.",
            "Now people went there.",
            "Some students will think, oh, I think I know how to make a better descriptor and justice coded app and it worked.",
            "That was the way that people were making proud."
        ],
        [
            "This in parallel there was another thing that was also very important is the data.",
            "How do you train all these systems?",
            "An advances in data sets has been also one of the reasons why computer vision is now nowadays so successful.",
            "So let me tell you just a short story of image databases and how they change over."
        ],
        [
            "I'm so here I'm going to show you just several data sets organize across time in the central axis on the vertical axis, the number of images that are available and how progress happens overtime.",
            "So in the 70s most of the people had one data set that consisted in one single image that was the lender picture, which is a very famous and controversial picture, and that was basically what everybody was trying their algorithms on.",
            "We knew everything about this picture.",
            "We know who was the person in the picture.",
            "We knew what was outside of this group version.",
            "We knew.",
            "We need all kinds of things.",
            "It was that I said this was our training example and our test example.",
            "It was everything.",
            "Then things got a little bit better and seems like the fair database for faces appear contain 10s of thousands of images, so not a very large database.",
            "For face recognition, then something like the coil database.",
            "This was a database made of toy objects against a black background.",
            "These objects were taking pictures in different poses and again this was a really hard task at the time people couldn't get algorithms to work at 100% recognition rate Despite that this was really really simple task.",
            "Then the contact four is just four categories with a few hundreds of images per category.",
            "Very simple data set.",
            "This was nearly two year 2000.",
            "Then contact 101.",
            "This is 2000 one 2002.",
            "An it contain about maybe 60,000 images, so still not a very large database.",
            "101 object categories.",
            "It created a lot of progress.",
            "Many people started working on object recognition and making a lot of progress at the time.",
            "But then the Pascal data set, which is a very important benchmark that appeared in the computer Vision community, still induce many algorithms.",
            "If you're reporting performance on object recognition, probably you have to test on this one cause it gives context on how your algorithm is doing with respect to many other algorithms in the past.",
            "But again, there are really a small data set, just 10s of thousands of images very very small for such a hard task.",
            "General object Recognition, then things like the 80,000,000 images that Robin I created.",
            "Several years ago, on image net, they try to go a lot farther.",
            "Instead of doing something like after 101 with just a hundred categories.",
            "The goal here was to collect them all so we just went to war net and collected all the words and started downloaded images and this is how I imagine it was created an.",
            "The places database I will talk also about it is just the same thing but for scenes.",
            "And this is really interesting if you compare the size of these data sets with the amount of data that a kid gets to see.",
            "So a 2 year old kid will be there up there in the corner.",
            "He sees about 10 to the nine images and we could discuss along time about how do you count exactly the number of images that a kid will see, but you roughly count 3 images per second?",
            "OK, they're going to be highly correlated by, you know, just for psych of an argument, 3 images per per second being awake 16 hours per day.",
            "If you are lucky an.",
            "An during two years is going to see something like 10 to the nine images, so we are getting really close.",
            "We're still not there.",
            "We are still a couple of orders of money too short of what a kid will see, but given the diversity of the nature of the images that these data sets are made of, probably this is a lot more data than what a 2 year old kid gets to see.",
            "Although there is there other modalities and so on that I will talk about it."
        ],
        [
            "An so nowadays is the time of big data for you having access to big data sets, it seems something very simple, not just go there and download images, and it seems trivial.",
            "There are so many data sets available nowadays, but those data sets are very recent.",
            "People.",
            "In the past they you know they had very few images to train their algorithms."
        ],
        [
            "So in 2010, more or less a newer student will get into computer vision, will see the success of action get really excited, will pick one data set to train.",
            "The algorithm, will pick one model out of all the possible models that exist."
        ],
        [
            "Will take one picture.",
            "Will run the algorithm and that was the output.",
            "This is 2010, so what's going wrong here?"
        ],
        [
            "OK, who's to blame?",
            "Here is the data, the features the student.",
            "What's the problem here?",
            "So."
        ],
        [
            "So the most popular descriptor at the time in 2010, between 2005 and 2010 was hog.",
            "I don't know how many of you have heard of Hog.",
            "OK, like half of the audience, this was a really popular descriptor at the time.",
            "If you wanted to have an algorithm that will do object detection with the state of the art performance, you had to use hog and it basically just a bunch of layers.",
            "It looks very much like a confident but all the different layers and filters are chosen by hand.",
            "The coefficients everything is set by hand an is basically a recipe that you apply to the picture and it will go through a set of nonlinearities and at the end it will give you a vector.",
            "And the question is, well, why is this not working?",
            "Why is that it will say that there is a car on the water and it's really hard to tell 'cause the process is so nonlinear.",
            "So a couple of my students wanted to know if we could visualize this output.",
            "So what they proposed was just some way of rendering back the pictures just given the output, render the picture that will give rise to the exact same descriptor and you can do that as just some minimization technique just formulated the problem as I want to look for the image that when you throw the same computation, it will give you a fixed output and just do gradient descent on that.",
            "When you do that."
        ],
        [
            "This is the output that you get.",
            "An here it shows a little bit the type of things that were important for this descriptor and is actually important in many representations that are just in computer vision.",
            "One is contrast normalization, like here.",
            "You can see that the background has some black regions, but here you can see some contrast, and it's because there is some normalization and this is something that is done inconvenient.",
            "Sometimes it is now as Rob was describing.",
            "Sometimes it works better, sometimes it doesn't exactly are.",
            "In this case this was part of the representation.",
            "You can still recognize that there is a person here, so clearly is seeing all the information that seems relevant for doing object detection.",
            "So now what you can do is you take this visualization, you take your classifier that is trained with this particular descriptor.",
            "You run it in images.",
            "And you train it to the text on particular object.",
            "Let's say cars.",
            "You run it through many images in the Pascal data set, for instance, and you crop the regions weather detector fire with highest confidence and those will be your detection's.",
            "And then you visualize the output with this particular technique."
        ],
        [
            "So here what I'm showing is groups from images that created a strong response for the person detector, the chair detector and the car detector.",
            "So if you haven't seen this before, can you guess which one are false alarms?",
            "So now I'm going to show you the actual images where the crops are coming from and they are all."
        ],
        [
            "False alarms.",
            "These are the crops.",
            "This is what?"
        ],
        [
            "Actually, the vector was seen."
        ],
        [
            "This is what the image contains, so you can see that it's throwing away all the information that was relevant for the detection and is just turning these objects into the thing that you're looking for because."
        ],
        [
            "When you look at these representations, they actually kind of look like the objects are looking for.",
            "Now.",
            "You can even tell stories about the people that you see there.",
            "Now some people are like a standing, some like the first one.",
            "Seems somebody in front of a mirror, so you can tell kind of a story of what is going on here and other cars.",
            "They look pretty compelling, like if you look at this one here.",
            "Right, it looks like the wheels, but this."
        ],
        [
            "Just two heads.",
            "So it's a disaster now."
        ],
        [
            "And in fact, when you just this visualization and you show it to humans and you ask humans to do the classification, they perform like the detector.",
            "So once you have these features, appliance VM an the fact that the performances are not so great could be because the classifier maybe is not strong enough.",
            "Maybe you need better machine learning there an in fact when you remove that classifier and you put a human there, the performances are almost identical to the classifier.",
            "So in blue.",
            "Is the classifier on in red?",
            "Is the human performance and this is a standard precision recall curve and in green is the curve that you get when you ask humans to classify the original Patch so you can see that humans can do the task is just that when it goes through the descriptor information is gone.",
            "So this was what was going on in the year 2010, more or less and you know the only way around it is better descriptors."
        ],
        [
            "So this is the original picture.",
            "This is the region where the doctor thought there is a car.",
            "This is the image Patch and this is what the detector gets to see.",
            "So it actually doesn't look like a side view of a car, so that factor was working in some sense.",
            "And then.",
            "The size of the window should do better because window sizes so small and hence you can see a car.",
            "But if you increase the size you will see the edges of the dog and probably won't see a garden.",
            "Yeah, so yeah, so you can do things like increasing the windows so that you can get the more context and so on, But then performances drop for other reasons because suddenly you get a lot more confusion.",
            "Your algorithm needs to focus in their internal region, which is generally the more relevant one.",
            "Some people have tried all these kind of things and just there's really no way around it."
        ],
        [
            "OK, so deep learning came along and it makes a big difference as Rob has been showing so I'm not going to give a lot of details about it."
        ],
        [
            "But we also got interested into it.",
            "An we saw that it was really well.",
            "So we created a scene recognition demo that you can run it.",
            "You go to this link and I show you some images and this was just a straight application of the Alex Net architecture that Rob has been describing.",
            "Trained for the task of scene recognition and the task of synchronization is just given a picture to tell what type of environment it is like.",
            "This is an auditorium or regarding a street and so on.",
            "So here."
        ],
        [
            "There are some examples.",
            "These are pictures I took just a few weeks ago while going on vacation.",
            "So it will say this is a swimming pool, so it was really well."
        ],
        [
            "And this is just today when I was arriving to the airport and there were big lines.",
            "So it says Airport Terminal which is quite amazing because it you know it looks like an airport terminal.",
            "But it seems like it's not a very Canonical view of an airport terminal.",
            "Is quite amazing that it works so well even when you look at attributes it will say waiting in line which I had to do for an hour."
        ],
        [
            "This is another picture taken on the on the taxi drive to tell the taxi the cabin of a taxi is not a category in the in the in the database, but it still says like cockpit parking lot and so it still says waiting in line.",
            "You probably.",
            "In Neil, I've been waiting for a long time."
        ],
        [
            "Yeah.",
            "This is now.",
            "This is just sorry this is a different auditorium.",
            "It says Auditorium Conference Center then."
        ],
        [
            "I took a picture of rap talking now and it says auditorium but it says Bar.",
            "Rob likes bars a lot.",
            "I have no idea how the network knows this, but.",
            "But it works amazingly well."
        ],
        [
            "So here is another picture.",
            "Taking a hotel room and it says hotel room."
        ],
        [
            "And this is a different picture in the same in the same room.",
            "It still says hotel room, which I thought it was really really amazing because there is almost nothing here in this picture is really not not a Canonical view of another room.",
            "So how can we know that this is another room?",
            "Well, this lamp is alarmed that generally people don't have at home, so it looks like another room lamp.",
            "Well, certainly if some of you have a lamp like this.",
            "Is beautiful.",
            "But you know, it doesn't look like a hotel room lamp, so I was thinking OK, so maybe the network is actually detecting the altar room lamp.",
            "It has learned somehow to detect that lamp."
        ],
        [
            "Yep, so the question then was then OK, how is this possible?",
            "How is working so well?",
            "You have this network that you train and rock has been showing a number of different architectures.",
            "You have some tasks.",
            "You train your network and it just works very well and it's always treated like a black box.",
            "Now it just looks like some magical machine learning architecture that you throw data to it and it will give you a solution to your task.",
            "But then the question is OK, how it is working?",
            "What is the representation that is being built inside the network?",
            "And that's the question that we try to answer now.",
            "It just seems like an important question to understand."
        ],
        [
            "There is a number of pieces of work that tried to visualize what is that.",
            "Individual units inside the network of learning and Rob has described some of them like the convolution technique that he has been showing.",
            "There are other techniques like doing backpropagation.",
            "You take one unit and you do back propagation to see what in the images activating that unit.",
            "You can also look you can study a strong activations.",
            "You can take one unit and just check which images produced the strongest activation into that particular unit.",
            "So there are different techniques."
        ],
        [
            "So the one that Rob described that I'm not going to talk about."
        ],
        [
            "There are also this in this work by Ben Jaanan, collaborators, in which they try to train the use this adversarial networks, which probably you have talk, or you will talk.",
            "Somebody will talk, so I'll just give you a one minute summary, but basically the idea is you have one generator that is going to take us input a random vector.",
            "And you want the output to look like a picture.",
            "So how do you train this random generator?",
            "This generator?",
            "Well, do train, also a discriminator that is going to solve a particular task is going to take us input.",
            "The images that conference your generator and also images that come from the real database and the task of the discriminator is to say if it is recreated.",
            "And the generator task is to be able to fool the discriminator, so you need to train the generator so that the discriminator cannot tell apart the two samples.",
            "It cannot tell apart which ones are generated and which ones are real, and these two things are trained jointly.",
            "So in this particular work they just do multilayer perceptrons.",
            "An they train it to generate real images."
        ],
        [
            "So this has some samples.",
            "Once it's trained, these are some samples that come from that particular generator.",
            "Well, they don't really look like real images, but they start getting some of the components.",
            "Not like the colors.",
            "They look like some type of wild animals, although you cannot really see what animals are there, but it looks a lot like texture synthesis in the 90s.",
            "So they don't know this is start being beautiful images.",
            "They have the right distribution of colors and they look as having a blob somewhere there that looks kind of has the color of a nanny."
        ],
        [
            "Call Ann.",
            "And then there were improvements over these techniques.",
            "This technique, so one of the issues was that using this multilayer perceptron probably was not a very strong representation.",
            "So here, in this particular work they introduce using calmness to generate images."
        ],
        [
            "So what they do here is they have a generator.",
            "Evolution on narrow network that takes us input a vector and it will output a picture and it's just a sequence of convolutional, an upsampling layers so that the output is a picture.",
            "And so here, not just start with random generator with random uniform vector and then you generate a picture and those are samples that come from this process.",
            "Ann again, it's trained with this adversarial training and it looks really, really nice now these are this is trained with like 100,000 bedrooms, so lots of bedrooms.",
            "It only knows how to generate bedrooms but they look beautiful.",
            "They look like real bedrooms and they looked into the database and they concluded that those images are not inside the data set.",
            "So it's really generalizing them.",
            "You know this is for, maybe it needs a closer inspection."
        ],
        [
            "And then this other paper basically took this similar idea and justice."
        ],
        [
            "A little bit further, and the idea here was to try to visualize what different units are doing and for this they just components, a generator, which is the one that I just previously described as the convolutional neural network, and then the network that you want to visualize.",
            "Let's say that it's Alex Net and what you do is you take the output of the generator and you connect it as the input of the network."
        ],
        [
            "And then so you have this and then you pick one unit in your Internet work that you want to visualize and you change.",
            "You change the input what they generate, change the random vector that the generator takes us input so that the output.",
            "But this is an image that is strongly activates the unit diagram looking for OK, so you can do that again with back propagation.",
            "And here is an example of an image that gets generated so that the the table lamp detector gets strongly activated and it looks like a table lamp is a beautiful.",
            "OK, it's not perfect, it's not photo realistic, but it has all the right elements.",
            "Now you can see that it's on is a really beautiful save the image of a table lamp."
        ],
        [
            "Here are more examples of visualizing different output units in Alex Net.",
            "What is trying to do.",
            "The image net classification.",
            "An image net contains lots of images that are individual objects like table lamps, here test libraries, cheeseburgers, barns, candles, table lamps, and so on.",
            "So here there are.",
            "These images are generated from this method.",
            "So each one is one of those samples and they look really beautiful.",
            "And."
        ],
        [
            "So.",
            "If anybody has questions, just raise your hands.",
            "So first I wanted this community in two different tasks because we will use them to better understand what the network is.",
            "Learning, object detection, unseen recognition, object detection will be something like that.",
            "Rob has been talking about.",
            "Given a picture you want to locate that there is a bird or maybe just say that there is a bird in this picture, which is mostly what what image net is focused on.",
            "This images of objects I'm seeing recognition will be more like given a picture.",
            "Just tell what type of environment it is like saying that this is a bathroom is a very similar classification.",
            "Ask for the machine learning perspective is just one label that gets attached to the picture, but from the viewpoint of our representation, these two tasks are very different."
        ],
        [
            "And that's what we will focus on.",
            "So for the object classification task, we can just imagine it, which is this very important data set that created by Faye and collaborators, and basically what they did is they quarknet one.",
            "It is this electronic dictionary developed Princeton take all the words that correspond to the subjects and downloaded images and there are 10s of thousands of categories for each category.",
            "You have thousands of images.",
            "And they are organized in this three that is given by Warnet."
        ],
        [
            "Then we created a data set for the scene recognition task, which is the parallel to Imagine network for sins.",
            "And this is the places database and basically what we did was again take the burner dictionary but now look at the words and take only the words that corresponded to seeing categories.",
            "Things like offices, bathrooms, corridors, not a specific places like Eiffel Tower generic scenes.",
            "So we have one student going through this list.",
            "It took about six months the student survive.",
            "And then we just downloaded images and then we had a process of cleaning the map.",
            "Because when you download images from Google you don't get the Sally.",
            "What you are asking for and we had to do a lot of manual cleaning."
        ],
        [
            "So we have these two big databases imaginum places.",
            "They have very similar structure from a machine learning point of view is a classification task, but from the representation that you need to build to solve this task is very different."
        ],
        [
            "So if you think so now what we will do is just take the same architecture.",
            "In this case I'm going to focus on Alex Net, but you can do the same thing for any architecture.",
            "Ann will take the same architecture and training with these two very different data sets."
        ],
        [
            "So.",
            "What is the internal representation that might emerge inside the network well?"
        ],
        [
            "Play something that imagine it that is focused on objects.",
            "Well, what could be a representation for objects?",
            "Well, it could be part.",
            "Maybe do one of the different pieces of objects and have some type of spatial relationships between them.",
            "That tells you when the object is there or not.",
            "You could describe an object as sub mixture of textures, or you could have attributes which is also very popular representation for objects.",
            "All those are possible representations.",
            "One of the problems is that you think about objects you do want to find what an object part is is very hard because what is the part of the parts of a phase are the eyes, the mouth, the nose, or is the two eyes together one part or maybe one I and a piece of the nose.",
            "Is that a valid part?",
            "Well, maybe Jess, so it's very hard to define what is the set of parts that is convenient for representation."
        ],
        [
            "In since you have a similar task.",
            "And now the possible internal representations.",
            "Well, it could be seen parts, it could be something.",
            "There's like object parse.",
            "It could be some parts that don't really have much meaning.",
            "It could be objects.",
            "Objects could be the things that you are going to use to represent scenes, so those are also seen parts.",
            "But now they are very well defined.",
            "An object is something very concrete, it could be seen attributes, it could be object parts, it could be textures.",
            "All those things are things that people in computer vision have been using as possible representations, of which one of those is the one that the network learns to do."
        ],
        [
            "So now we have this network an.",
            "One standard strategy to train this to use this network for different tasks is to train one network with, let's say image net.",
            "You remove the final classification layer and reduce the output that remains as a generic feature, and then you train a linear SVM with whatever task you want to do.",
            "And this is a very standard technique and it works really well.",
            "So here there are examples of doing this.",
            "Now you take another train with image, Net, or with places and you and you test it on different benchmarks.",
            "Like here these are seen data sets like indoor classification, seen attributes classification, different benchmarks that are simulated, and you can train what happens with features that are genetic features that come from a network train with image, net or with both with places and what you see, is that forcing related tasks, training with scenes works better.",
            "And when you have object centric tasks then if you train with image, net is better and there are big differences between the two.",
            "So clearly these two networks are doing something different.",
            "They're learning a different representation.",
            "Performances are high in both cases, but they seem to be specialized and they perform much better when the task looks like that as they have been trained with."
        ],
        [
            "So another way of seeing that the representations are different is by looking at whatever the preferred images for each layer in the network.",
            "So here's what I'm going to show is we took 200,000 images, 100,000 images coming from Image net, 100,000 images coming from places with throw them to the network, and we look at the three images that produce the stronger, strongest activation at each layer, and here by a stronger activation what it means.",
            "I take all the units in that layer and with some other activations an we get one number.",
            "All the images with that number.",
            "There are many other ways that you could do this.",
            "This is one way.",
            "So these are the three images that the image net train network prefers.",
            "And you know they look like having texture all over the place.",
            "And these are the three images that the place network wants.",
            "And two of them are common and the other ones that they come nearby.",
            "So you want to look a few more images that you will get them there.",
            "And this is among 300,000 images.",
            "This is very different.",
            "Training data sets for each network, but the filters that they converge to in the first layer, they seem almost identical.",
            "Because the three images they just are identical, so it's quite amazing.",
            "This is the second layer.",
            "And these are the three preferred images for places.",
            "Again, very, very similar.",
            "One of them is in common and the others just came come a little bit later in the ranking, so it's still you know what would be the chance of getting this Now if the layers were just slightly different.",
            "This is the third layer.",
            "This is the images that imaginative prefers, and this is places now they start looking different.",
            "Imagine it looks like a.",
            "Lines and so on places look, start looking like scenes but still texture like.",
            "This is comfort.",
            "Imagine that starts having some preference for objects.",
            "In this case, both know it likes round things all over the place and this is places.",
            "Now it looks like scenes now some perspective.",
            "These are very very different now and this is part five image net docs.",
            "One is that among the thousand categories that there are 200 of them are dogs, an service grace this interest in the network to Watch Dogs now, and you know, it just papers.",
            "And when they do Alusa Nation of things now you get to see all these dogs emerging all over the place all the time now because 20% of imagine it is about dogs.",
            "And this is what happens with places.",
            "Now perspective he likes totally different types of things.",
            "Now the last layers are clearly doing something very different."
        ],
        [
            "So another important thing is to estimate.",
            "Try to get a sense of what each unit is focusing on on the picture.",
            "What is the receptive field an?",
            "There are many ways in which you could do this.",
            "You could do it.",
            "You could take 11 unit in one layer and try to do back propagation to see what is the region that it gets to see.",
            "Or you could do just try to look at the convolutions.",
            "And get some theoretical size that you will get in a particular unit.",
            "Here is a very simple trick that you can do.",
            "It doesn't matter what the architecture is.",
            "One thing that you can do is, let's say that you want to know the receptive field of this particular unit there.",
            "This is your input.",
            "Just take an image that produces a strong activation in that unit.",
            "It doesn't need to be the strongest activation, just some activation there.",
            "And then you take a black square.",
            "Just the dumbest thing that you can imagine.",
            "Just take a block of square, put it on top of the image and move it along.",
            "And record the activation of the unit and check where it changes and it will get you some sense of what is the relative of that unit.",
            "OK, and people have been doing this for localising objects in images like Rob has been doing that too.",
            "So this is an example of this receptive field for this particular unit."
        ],
        [
            "Anne.",
            "So in leisure one if you do this trick, but you find is that objective, fields are very small.",
            "Now it's just the size of the kernel, just very very small.",
            "This is layer 3.",
            "In orange, Kieran showing what is this practical receptive field that we synthetic empirical receptive field that we find when we pass this Black Square now?",
            "And you can change the size of the square doesn't really matter something that creates some activation and some change in the activation.",
            "And Jello is the theoretical receptive field size.",
            "This is just taking into account the size of the convolutions and the fact that when you convolve things get added so you can see that the actual receptive field is a lot smaller than the theoretical varsity field.",
            "And this is in layer five, which generally we think that layer 5 gets to see the entire picture almost gets to see the entire picture, and it's true that it has the potential to do it.",
            "But in practice it actually selects a much smaller piece, something like 20% of the picture.",
            "So it has a lot of localization capabilities.",
            "We can localize things in the picture.",
            "So these are smaller and this is true for almost all units in layer 5."
        ],
        [
            "And then you can do things like doing segmentation.",
            "Or you can take the feature map.",
            "The activation of all the different units that are that are within the same convolutional layer, the same that apply the same kernel."
        ],
        [
            "And let's say in Layer 5 this will be the activations."
        ],
        [
            "And you can just do a weighted sum of this protective field that you found and just create a mask of what the object where the objects should be so."
        ],
        [
            "There's something trivial now.",
            "In this case you could get something like this.",
            "Anne."
        ],
        [
            "OK, so once you do this so once we have the receptive field for each unit in the network, so all the layers, one thing that we want to know is what are all these different journeys doing?",
            "So there are too many units to go 1 by 1 by hand.",
            "So what we did was to crowd source the interpretation of the network.",
            "So you take, you take one unit, you pass the 200,000 images and we select the 60 images that produce the strongest activation in that particular unit, and then we apply the receptive field to know exactly what is the region of the picture that produces strongest activation there and then show it in Mechanical Turk just in answer Mechanical Turk so that workers could tell us what.",
            "What is that journey doing?",
            "So this is."
        ],
        [
            "Snapshot of the interface.",
            "We show them 60 images and we ask them to tell us what is the concept that these images have in common.",
            "They don't know anything about where these images are coming from.",
            "Ann and they also get to click on the images that do not fit that concept because some images might be just wrong detections.",
            "So in this particular case the worker says OK, this all these images seem to have in common a lighthouse, and there are these images here that were something else that are not like houses.",
            "So he mark those images and then."
        ],
        [
            "We also ask to tell us what type of concept that description belong to.",
            "It's an object part is a scene is an object, type is a texture.",
            "It's a simple element.",
            "What is it?"
        ],
        [
            "And then now we have this for all the units we did it with several people per unit, and here is an example of one of the units in Port 5 an in this case this is trained for the same recognition task.",
            "And this particular unit got the label Ocean.",
            "An you can see that is segmenting the ocean on these images.",
            "It seems to be localized in it pretty well, and there are four errors out of the 60 images.",
            "That, well, you know this could be.",
            "The errors they look they look wrong, but you could imagine why the neuron the unit could fire there."
        ],
        [
            "This is another example.",
            "This is detecting lamps.",
            "Ann is quite reliable it because there are.",
            "There are a few errors here, but most of the most of that actions are correct, and this localising these lamps in the picture is not just saying that there is not, the worker is hallucinate ING some concept here and there is a lot of consistency across people."
        ],
        [
            "This unit here is detecting Lex.",
            "Any kind of legs?",
            "Anne."
        ],
        [
            "And this one here is detecting pool tables and is also confusing swimming pools here is well there is some visual similarities, so maybe you could imagine why these two concepts get mixed here."
        ],
        [
            "Here is another example of a unit that mixes to concert.",
            "This is something that we found that happens.",
            "Relatively often that there could be a unit that is mixing two objects.",
            "It doesn't fire to anything else, just these two objects, like here.",
            "Now it's detecting tables.",
            "Special settings know for tables and this is not the typical setting that you will have at home and buildings, but kind of Barack buildings, and there are a few errors.",
            "There are a few things that are not this not like a sink here.",
            "There are few errors, but most of the time it's just these two concepts.",
            "Feels like the Pool 5 contains about contains only 256 units and it feels like it once more units not to separate these objects, and in fact, when you put more units you have more you have more unique elements that appear."
        ],
        [
            "So now we can analyze what is happening in each layer.",
            "Now all these situations that Rob was describing before we can, we can look quantitatively at them and see you know what each particular layer is trying to do as a representation so.",
            "So first let's focus on simple elements and colors.",
            "This will be units that react just a simple colors or lines, but nothing semantic and we can check where are they located.",
            "And as you could expect, they're mostly located in the first layer.",
            "So here this plot what it shows is the recent Alexis is the layer number and the vertical axis is the percentage of units that got assigned.",
            "To 1 one of those to this concept to the simple elements and colors.",
            "And here to decide that one unit is sensitive to one of those concepts.",
            "We only count units that.",
            "Are correct, at least 75% of the time on these 60 images that we showed.",
            "OK so.",
            "Otherwise, there are some other units that could go here, but it's unclear what exactly they doing because the performance is slightly lower and there are about 60% of the units that get assigned clearly to one of those concepts, both in image net train network in places.",
            "In this model, is constant across all all the layers around 60% of the units.",
            "You can tell what they are doing.",
            "And so you can see that as you go deeper into the network towards higher layers, you drop in the percentage of elements that of June is that are sensitive to simple elements in green is what happens with a network very strained with image net and in red is what happens with the network, but it's trained with places forcing recognition and you can see that with image net there are still a higher percentage of units even in Pool 5 that are sensitive to simple elements.",
            "Anne."
        ],
        [
            "So we can do the same thing with texture materials.",
            "Here is the distribution.",
            "An again, they're mostly concentrated in the first 2 layers, and then it drops."
        ],
        [
            "You can look at regions and surfaces and here there are already semantics, so regions and surfaces here I'm referring to grass Sky roads, so these are already semantical concepts.",
            "So when you do this, define that they appear toward the higher layers, mostly in the last layer input 5.",
            "After that, there are the fully connected layers, so we're not looking into those.",
            "There is some mess on concepts, it's all mixed in here.",
            "You can see that regions and surfaces appear mostly when you train with places, but not with image net, and that makes sense because you mention it is oriented towards objects.",
            "Most of the objects are relatively big an.",
            "However, for scenes you really want to recognize things like Sky and Roseann grass, this is a very important categorisation thing that you need to solve in order to the scene recognition."
        ],
        [
            "Then object parts.",
            "In this case, Imagenet finds a slightly more objects parts than places.",
            "Again, it makes sense yes.",
            "Listen to it is edges are object cards are using humans with yeah, so the question is how do we make this classification of the units into object parts simple elements and so on.",
            "And this is one of the tasks that Amazon mechanical Work Turkers have to do, so they have to tell us what of those concepts is.",
            "So object parts, so there are just the thing wheels and legs and you can see there are slightly more in image net and they pick in layer four.",
            "Although pull five Layer 5 is mostly more or less the same."
        ],
        [
            "And then objects.",
            "This ad units that got assigned to specific objects an here now image.",
            "Net places finds more than Image Net which was kind of surprising to me.",
            "Becausw image Net is trained to do object detection is trying to do object classification.",
            "So it feels like it should be able to objects in the 1st place because otherwise how do you decide that the object is there but there are a lot fewer objects emerging.",
            "However places had a lot more objects emerging inside.",
            "Probably cause.",
            "The output is already object classification task and internal representation that imagine it is trying to fill our object pieces, not object, not full objects that you know the output will take care of that.",
            "So there are about in places that are about 25% of the units doing objects and this is out of 60% of the units that get classified as something.",
            "So it's a very high percentage.",
            "1/3 of the units are doing clearly."
        ],
        [
            "And then you can do the same thing with since an around 10% of the units are going scene classification in the last layer image net.",
            "Don't find any, mostly none of them an this makes a lot of sense because there are no since there are very few scenes in Imagine."
        ],
        [
            "And what objects are found?",
            "Well, if you look at."
        ],
        [
            "Image net these are the units that appear inside image net, so you find things like Tor source of people.",
            "This is our shape unit.",
            "Imagine that there are lots of those.",
            "This is detecting this round corners and this is not a simple classification task.",
            "You can see that this round corners have many different colors and changes in appearance, so it's not a simple classification task, but it's not a high level concept, but it still is.",
            "A is an interesting task that is solving internally animals, Flowers, dogs and more dogs.",
            "There are many units doing dogs.",
            "Highly specialized, then this is what you find."
        ],
        [
            "In places that are faces and this is surprising 'cause there is no.",
            "People category in the scene recognition task is all about offices, bathrooms, corridors, streets.",
            "There are pool tables, lamps, screens and you can see it's detecting.",
            "The screen is pretty well nice.",
            "Segmenting them is not just an illusion nation trying to detect the squares is really detecting these screens baseball fields.",
            "Mountains and is locating them so this is not something that by chance looks like it seems to be that is really detecting this object."
        ],
        [
            "This is a bad detector that emerges inside the network.",
            "There is 1 unit that is detecting bets and it does it quite well.",
            "So these are many of the images.",
            "The top images that this unit is reactive tool and this is auto 200 two 100,000 images.",
            "It has both imagination places together so it could be responding to anything but it picks bets, bets and detects them quite well and even if you keep looking at more on lower rank images they are they are best so I mean it's pretty high.",
            "It's quite high performance."
        ],
        [
            "This is the one that lamps.",
            "The square Mason is detecting this.",
            "Alter lamps know this.",
            "And if there are two, you will see two peaks of activation, so it's quite a nice quiet nice segment."
        ],
        [
            "And.",
            "So here is the histogram of the objects that got that emerge inside the network.",
            "So this is for image net.",
            "Anne.",
            "So here we are, mixing anything.",
            "We're mixing anything that has semantics, not just objects.",
            "If there is something that actually surfaces, we also put it here.",
            "So out of the 256 during simple 560, around 59 are detecting objects or something that has some semantic meaning.",
            "And 15 of those are dogs, then births and then it goes flat quite fast.",
            "Here are some of the examples of the units."
        ],
        [
            "For places so there are around 150 units that are detecting something that is semantic, so this is more than half of the units.",
            "Do some semantics an this is not by chance.",
            "It's just doing like Sky region Skyroads screens is detecting things that you can put names to and the distribution of objects is a lot.",
            "It doesn't drop as fast so again is a power law.",
            "This is very typical so there are 15 June is detecting all kinds of buildings and then you have 3.",
            "Raslor mountains, people, water and so on, and it drops quite fast.",
            "There are a lot more large variety of objects that emerge, so these are some of the units."
        ],
        [
            "Here's just a classification of the units that emerged.",
            "This is not all of them, just some of them.",
            "And there are buildings in their objects, furniture, outdoor objects, lighting that respond to specific types of lighting, nature, and so on.",
            "These are objects that for some reason they are important, forcing classification."
        ],
        [
            "An in fact, one thing that you can do is you can take this method and you can take also the method for visualizing what the units are doing that I described before by rendering an image that produces that confuses that creates an strong activation and you can render instead look look a lot like the object that we think is detecting.",
            "Like this unit here is detecting this rocks in the water and when you do the rendering of what activates that unit you get this.",
            "So it doesn't look you know this totally different methods.",
            "They arrived to the same conclusion, so it's not.",
            "It's not as just fooling ourselves thinking that the unit might be doing that like this one here is detecting roads and this is a rendering of what will activate that unit most.",
            "And it looks like a like a Rd.",
            "Here is an arc detecting unit and it will render arcs.",
            "This is the pool, the pool table and it will draw a pool table.",
            "This is like a mixture of the pool tables with all the orientation, so it's kind of round but.",
            "You know it's.",
            "Is it clearly Apple table?",
            "Yeah."
        ],
        [
            "OK, so basically when you're turning these networks it feels like the first layers seem to be mostly task independent.",
            "You take these two different tasks, like imaginative places more or less get the same filters you know the preferred images.",
            "They look like they are almost identical, so they look very much like doing the same thing.",
            "So this mostly seems like task independent.",
            "Then you have your representation that might not be the thing that you're trying to solve.",
            "Like in the case of place recognition, is doing objects and then you have your final classification that is translating that representation into the task that you're going to solve.",
            "And this representation in some cases might be even more interesting than the task that you want to solve, like here.",
            "Now this representation is doing object segmentation and we were just trying to do some classification, which is a very simple task to do.",
            "Easy to collect data for object segmentation is a lot harder to collect this data, so it's like we're solving an interesting task.",
            "There is a lot more interesting than the task that we try to solve in the 1st place, so this black boxes they are not arriving to the classification solution in some mystical way.",
            "They are actually creating a representation that seems really, really useful.",
            "And they're doing it really, really well."
        ],
        [
            "Anne.",
            "So whenever you have a new task, one of the strategies that people use all the time is, well, you take one of these networks.",
            "You freeze all the parameters and you just train the last layers, and that seems to be a very reasonable thing to do because the first layers are going to be task independent mostly.",
            "So it depends how many, how much computational power do you have, or how much training data do you have.",
            "You can you can decide to train more or less layers, but the first layers it seems like you already have them.",
            "You already have the train.",
            "For whatever task you had in the 1st place, you know it's probably going to transfer pretty well.",
            "So this is a very."
        ],
        [
            "Our task.",
            "And so just freeze the first layers and train the upper layers with whatever new data set you have."
        ],
        [
            "But what happens if you take the task?",
            "You keep the same task, but you change the input modality, and this is something that people in computer vision are trying to look at, and this is an example from the Paris website.",
            "They are doing a lot of work on Clip Art an the idea here is that.",
            "If you just clip art for training, a computer vision system, you can generate a lot of data.",
            "Without having privacy issues, because this is synthetic data, so you can do whatever you want, you can create examples that maybe will be really hard to collect because you can create scenes in which there will be just small differences in the data in how this Clipper is organized, but it will change the concept that you can generate samples that are very close to the classification boundary.",
            "So there are all these things that you can do with clip art that might be really hard to do with real images, so they had a line of work in trying to do a systems that will learn from Clipper and then be applicable to the real world."
        ],
        [
            "So this is a work that we did with several people, and."
        ],
        [
            "With risk with this here yes one question.",
            "Being more independent, does it?",
            "Related to the fact that the gradient gets smaller.",
            "I don't think so.",
            "I think it's really big cause this first layers they're trying to solve a sub task that is very common to many of the things that you're gonna solve, like edge detection and things like that.",
            "Those are things that you will have to do for almost any visual task, but there could be other visual tasks that suddenly changed alot representation that you get in the first layer.",
            "We just haven't found those, but there could be.",
            "I don't think it has anything to do with the gradients.",
            "Anne.",
            "OK, so.",
            "We wanted to create also training system data from other modalities like line drawing.",
            "So you can you can put a interface in Mechanical Turk and ask people to create line drawings of all kinds of things."
        ],
        [
            "So here is the clip art from Davis and this is my best rendering.",
            "This is Amy drawing drawing this and trying to reproduce the data.",
            "This is actually the best I can draw.",
            "But here now you can see that people are not even people that you would recognize with a genetic system.",
            "Now is like an iconic representation of other person is."
        ],
        [
            "And you know, we can crowd source this and get all kinds of line drawings for different scenes, so these are bedrooms."
        ],
        [
            "Now they look."
        ],
        [
            "Denies some of them."
        ],
        [
            "So much."
        ],
        [
            "Some people are ready."
        ],
        [
            "Schematic."
        ],
        [
            "And you can get all kinds of categories.",
            "So we collected a lot of data like that."
        ],
        [
            "Library."
        ],
        [
            "You can also generate data from other ways.",
            "For instance, you can create images in which there are just words that tells you which objects should be there, like here.",
            "Now this is a Rd is a highway in which you have roads, car, Sky and it's just the words."
        ],
        [
            "You can create all kinds of data like that by sampling from a segmented data set."
        ],
        [
            "You can also create.",
            "You can also take us input descriptions now you could have descriptions that tell you how how different things look like, so these are description of a bedroom is not associated to any picture of a bedroom.",
            "It's just a description of a bedroom and you might want to learn from this."
        ],
        [
            "So this is a description of an auditorium."
        ],
        [
            "Of a classroom.",
            "And it contains all the elements.",
            "Measuring these to kind of more or less create a picture mental picture of what the classroom is."
        ],
        [
            "So we have a database with different modalities.",
            "Each modality is classified according to different categories.",
            "Each modality is not aligned with other modalities.",
            "So for a particular description you don't have the corresponding picture that goes with it.",
            "The only thing that you know about that description is that it's talking or the sensing category."
        ],
        [
            "So now you can take this network that is trained with places or with real images.",
            "On the first layer were task independent.",
            "The last layers are mostly task dependent, so these are the ones built in the representation.",
            "So the first layers are going to be modality dependent because it will depend on what the modality they will change.",
            "The type of filters that you want to use.",
            "However, the large representation might be modality independent cause.",
            "It doesn't rely so much on the pixel values that we had the input."
        ],
        [
            "So what we propose is, let's remove the first layers instead of freezing up the first layers.",
            "Let's freeze the last layers.",
            "So you take the same classification task you have trained.",
            "This network here is doing some sort of object detection, and now you plug here.",
            "A new set up layers with Ramadan initialization and you train it with line drawings.",
            "And you freeze the parameters of the last layer.",
            "So how can this work?",
            "OK, the only thing that this can do is somehow it has to align the output of this line drawings to create the same objects that the last layers are expecting.",
            "Otherwise it cannot work.",
            "If this realize that here there is 1 unit that is detecting bets.",
            "And it has got it all the things here so that that unit expects the only thing that we can do is transform itself here so that this unit keeps detecting bets even if they come from line drawings.",
            "And you can do this with all the modalities.",
            "You can plug a number of different modalities.",
            "You can even insert descriptions.",
            "So here these layers will have to have a different nature.",
            "It will have to be like last names or something different that creates a particular representation and now you plug that representation into pull 5 and it will have to create some objects, otherwise it cannot work.",
            "And indeed, when you do that is."
        ],
        [
            "Works.",
            "So.",
            "So when you train this system like that, you look at one particular unit.",
            "Let's say that one, the one that was detecting bets and it takes bets on real images.",
            "But it also detects bets on clip art.",
            "Line drawings of bats.",
            "It detects the word bad when you train with just words.",
            "And it kind of reacts to some of the words in the descriptions that are aligned with Beth.",
            "This is not perfect.",
            "I think we are lacking data here, but this is quite surprising though, so it's aligning this water presentation with the object that is detected.",
            "Is the only way I could make it work now I have to align these things."
        ],
        [
            "And so here is just another unit detecting."
        ],
        [
            "Sometimes an is detecting fan tension in all kind of modalities."
        ],
        [
            "And then you can do things like inverting so you can take one modality generator representation on the back, propagate through another representation, and you can go from line drawings to real images.",
            "So this is just some of the some of the oil rendering techniques that are much better now, so probably this could work better, but you can see that this transforming this line drawings into images that kind of looks.",
            "It looks nice.",
            "So this is all this is working because the internal representation that has been learned by the network it actually makes sense.",
            "It's not just some crazy thing that the network needs to do in order to solve the task that is not interpretable, or like a black box.",
            "So you can actually look inside the black box and it kind of makes sense.",
            "What is do?"
        ],
        [
            "And this place across model learning.",
            "There are lots of techniques.",
            "It's actually something that in computer vision is very interesting nowadays, so combining text and images and here is 1 example of a work of a piece of work in which what they do is they want to train object detector by just using a description.",
            "So I give you the definition of the object and you need to from that definition build the object classifier that will detect the object on images.",
            "Anne."
        ],
        [
            "So the way it works basically."
        ],
        [
            "He is.",
            "It has to pass."
        ],
        [
            "One path that is going to take the image and it's going to generate some features and another path that is going to take a Wikipedia article or of an object definition is going to do some representation in this case, like a bag of words is going to is going to go through multilayer perception and create.",
            "A function.",
            "That is going to output the classifier parameters so that now you take that that those classifier parameters apply it to the features extracted from a picture and it will tell you if that's or not the object you are looking for and the way you train this is by starting with a database in which you have lots of definitions and images that are pair.",
            "So that's the way you train it."
        ],
        [
            "So here is an example of definition of a cormorant, and these are the images that the detector found.",
            "So it works.",
            "It's not perfect.",
            "There is a lot of work to do, so even though we show like Rob has been showing amazing results is not like the problem is solved.",
            "There are lots of mistakes, it's just that it works a lot better than it was working before.",
            "But there is still a lot of room for improvement, but now you can be ambitious international.",
            "You can try to solve much harder task than before.",
            "So here is, these are the images."
        ],
        [
            "You can actually apply rubs technique doing backpropagation to seek what is that is activating that particular unit and you can see that you get to localize the birth in this particular case."
        ],
        [
            "So.",
            "So this is very computer vision.",
            "There are lots of different ways of training systems.",
            "One is pixel labeling and Rob has been showing a few examples in which you try to do scene segmentation.",
            "And for that you just wrong supervision.",
            "And when you have a database with images on each pixel gets a label and that's given you is given to you as training data."
        ],
        [
            "Which supervision is more or less what I've been describing when you train with image net, you only have one word assigned to a picture, so you don't get to know where the object is in the picture that the network will have to figure it out an.",
            "I've shown that even when you train with a task that is different from object detection, you might still get object detectors and they get to learn to segmented objects.",
            "So this is just a quick supervision."
        ],
        [
            "But cross model learning is something that is very important nowadays in computer vision.",
            "So here is an example of an example from Coco in which you have a picture and you have a description and that is like a caption with natural language, freeform style that describes what the content of the picture is and you need to learn to describe that."
        ],
        [
            "So another way is using questions and answers.",
            "So here in this particular case, the way that you train the system is you have a database of images and questions about that picture and the answers that go with it.",
            "So you train a system that, given a question on a picture, it will give you the answer.",
            "And that's really an interesting way of training cause first it only uses natural language.",
            "There is no, you don't need to agree on the vocabulary that you will use to label your objects, and you can.",
            "You can ask all sorts of questions and the system will have in order to answer those questions they will have to learn to detect the objects and all kinds of things.",
            "And it's amazing the progress that has been made in in this field.",
            "So here is a link.",
            "If you go there you can play with a demo that this is worth from this product group and it was really well."
        ],
        [
            "Anne.",
            "But that's very different from the way that kids learn.",
            "Of course, kids ask a lot of questions, but before they can speak, they already know how to see.",
            "So they are actually interacting with the world in a very different way.",
            "And now is when I have a lot of videos, so let's cross all the fingers.",
            "And I have audio, so the probability of this computer crashing is extremely high.",
            "So the way that the kid learns is very different."
        ],
        [
            "So the kid will learn that the world is made out of different materials and the way that it has to do that is by playing with the world it will style.",
            "It will stop touching it, hearing the noises that it makes, and so on."
        ],
        [
            "So.",
            "Here is a. Yeah, it works.",
            "This is a travel songs kit.",
            "Hello.",
            "How?",
            "So you put things in your mouth, juice all the modalities that you have.",
            "To learn about the world, we have nothing like this.",
            "We don't have any data set that looks like this."
        ],
        [
            "So just by hitting the actually sound is already a really powerful cue to learn about the world.",
            "So just by hearing, you can tell many things about how the world is made of.",
            "So here I'm sure you just very blurry video."
        ],
        [
            "Well, it's just audio.",
            "So this is a steal in Andrew Owens playing with drumstick on a particular scene and you can get a good sense of the type of material.",
            "Now you can hear that there are some things that are hard, some things that look like sound, like plants.",
            "Some things are rough.",
            "So you get more or less a classifica."
        ],
        [
            "You know this is the original scene.",
            "And this was the.",
            "Excuse me yes.",
            "So you get that you get a sense of what are the different materials that are making."
        ],
        [
            "So this is work.",
            "Bill Freeman and Andrew Owens is the main driving force behind all this, so he's the one making all the noises that you will hear."
        ],
        [
            "So the first thing that he did was to collect database of physical interactions.",
            "So I'm trying to get a little bit of this type of data that is more cross model now.",
            "So he created the greatest hits data set in which he goes with this drumstick and starts hitting absolutely everything that he sees.",
            "She created about 1000 videos, 30 seconds long each.",
            "Annual heats scratches.",
            "He does all kinds of things.",
            "And there are all types of materials."
        ],
        [
            "So here is just a collection of the greatest hits.",
            "You can hit basically everything."
        ],
        [
            "Is a really fun project for him.",
            "Another question is, can you predict?",
            "Can you learn material properties from sound?",
            "And here is a little bit coming back to this internal representation.",
            "What is the internal representation that the network will have to build in order to solve the task of associating images and audio?",
            "So here you have a task for which is very easy to collect data and hopefully the internal representation is very meaningful.",
            "So that's what we're going."
        ],
        [
            "Look here so you get a video.",
            "And our goal is to predict sound features and here in order to encode sound instead of learning the features which we are trying to do here, we decided to 1st.",
            "You know there is a deadline arriving.",
            "You know there is not much time and at the end you just use all the hacks that are in the box that allows you to arrive to the deadline.",
            "So one of them is to do some well established sound features that will encode the audio signal and hear what we are using.",
            "Is the cochlea gram?",
            "This is a you take the audio signal you pass it through a filter Bank of 40 different filters is tuned to a different frequency.",
            "And then you take that output so it's going to get some is going to be some sound wave for the output of each filter.",
            "You compute the envelope that filter output and you sample it.",
            "3 samples per second.",
            "And you do this for all the 40 bands and it doesn't will give you a long vector and then apply some compressive nonlinearity, which is, you know is what people do in all the analysis and that will be your audio vector.",
            "One thing that is nice is that you can take that vector and you can invert it and generate a sound more or less than it sounds real, so we know it's a relatively good representation.",
            "It might not be the best.",
            "The best thing would be to learn it, and that's something we're doing, but it's already doing something relatively well."
        ],
        [
            "So the first thing is that you can actually look at the mean sounds per category and they all look different, so this is a cloth, rock grass.",
            "This representation where they show is the recent relaxes time.",
            "The vertical axis is frequency.",
            "An dark.",
            "In this case it means a strong a lot of energy.",
            "So here in cloth is something that is sounds like low frequency sound.",
            "An rock is high frequency sound.",
            "A grass you know very flat spectrum."
        ],
        [
            "And now what we want to do is, given the video we want to train the video so that it's able to.",
            "Generate sound."
        ],
        [
            "OK, and for that we just just.",
            "The standard tricks then apply a convolutional neural network to each frame.",
            "You get an output and then the output gets into a recursive neural network, which I think you will see tomorrow an that will give the state vector and at a state vector we are going to use it to predict the this audio features.",
            "OK, their regression loss here is just equally and some robust norm to predict the audio sounds so something relatively simple.",
            "Nothing, nothing bad."
        ],
        [
            "Nancy Ann, once you train that you can test it and it kind of works and we can do to know if it's actually working.",
            "We can do a real or fake studies.",
            "Now we can take an image video.",
            "We can take the real sound, the sound we predict is going to make and show it to a human and ask if it's real or fake.",
            "So here is an example."
        ],
        [
            "Guess which one is real or fake?",
            "OK, so this one was fake and this is real OK."
        ],
        [
            "So we can do the same thing for many different videos and what we get is that.",
            "So if the model was perfect, you will get 50%.",
            "Now people will be a chance and select which one is the real or fake.",
            "It looks even better because in some cases actually hard for a human to tell what the audio is, not because you could be hitting something that is included and that will confuse the human, but the system will generate the sound that look visually looks like the right thing and humans could get confused.",
            "So in principle it could be.",
            "It could be possible to get above 50% here, but we're at 40% and it just take a random sound.",
            "Then you are around 20%, so it's not a super hard task, but we are clearly better than chance here."
        ],
        [
            "So here is an example of adding soundtracks to silent videos.",
            "So all this is fake.",
            "So more or less it tells.",
            "Sometimes it doesn't see that.",
            "OK, so."
        ],
        [
            "OK, here's what I'm going to show now is what video contain the sound that the system is using to generate that fake sound?"
        ],
        [
            "OK, so.",
            "It goes really fast.",
            "Well, it."
        ],
        [
            "Crash here, so one thing that is that is important is that here the way that we generated sounds was instead of doing inversion of the representation, we just took a video.",
            "That analogy clip that contain more or less the same features, not the one that was the closest and use that to synthesize, so it's more or less like a Patch based technique for rendering.",
            "You could do the inversion, but we found that it didn't sound so well right now, so it's like it's missing high frequencies.",
            "This method produce realistic sounds because they are real.",
            "But they but the number has to pick them from the right place, so that's what this transfer audio clips is showing is the place where the network is picking up the sound.",
            "The sound to generate that fake sound."
        ],
        [
            "So another example."
        ],
        [
            "This is another let me show.",
            "Starting to get we are computer."
        ],
        [
            "OK.",
            "Thank you.",
            "Is more is more of the same, so it's not very important, but now it will crash.",
            "Now I can feel it, I can feel it.",
            "This is getting hard that the computer.",
            "I think it crashed.",
            "I think it crashed.",
            "Well, so you know, for the I just have four more slides an it's not.",
            "I don't need the PowerPoint support to tell you what I'm going to say so.",
            "But no, no, it doesn't react.",
            "Well, the capitals yes.",
            "Yeah, so basically what we are doing now with this is we train this network to predict not just the sounds that you generate when you hit things, but we actually took just movies from Flickr that contain ambient sounds, just natural sounds and we train the network to predict given the input video, the natural sounds that you hear.",
            "So you're going to hear cars you are going to hear the wind water an for this prediction to work.",
            "The network has to be able to represent the objects that are making all these sounds.",
            "So that seems to be the natural representation to do, and when you do that and you look inside the network in the last layer, the last convolutional layer you look at the things that this journeys are doing.",
            "You find objects.",
            "You find that the network learns to take babies because there are a lot of baby crying videos in Flickr.",
            "So there are lots of journeys detecting babies for this data set.",
            "Our babies are like the docs for image net.",
            "And there are a lot of waterfalls.",
            "There are cars there are.",
            "There are all kinds of different objects emerging from this.",
            "Even objects that don't make sounds.",
            "There are some objects that don't make sounds but are contextually related to other objects that will make sounds and those are detected two and they are not mixed with the objects that make the sound.",
            "So you have this interesting properties emerging inside the network and strain with a task that require no.",
            "No supervision in the sense that there is no human telling what the network, you know what the labels should be, is just predicting one modality to another modality.",
            "And because these two modalities are so different that representation has to be something about the objects that make those sounds.",
            "So I'll stop here.",
            "If there are any questions.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so if you know that alqueire star lowering my voice just tell me at the back of the room is you cannot hear me because I'm kind of jet lag so I might fall asleep at some point.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it is a really exciting time for computer vision.",
                    "label": 1
                },
                {
                    "sent": "You have seen all the things that Rob has been showing you.",
                    "label": 0
                },
                {
                    "sent": "It really works really well.",
                    "label": 0
                },
                {
                    "sent": "There are many different applications that are working nowadays and it's really exciting time for computer vision.",
                    "label": 0
                },
                {
                    "sent": "But things have not been always like this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just let me tell you a little bit of his story before I go into what we're doing now.",
                    "label": 0
                },
                {
                    "sent": "So films start.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Long time ago people were really optimistic.",
                    "label": 0
                },
                {
                    "sent": "You know, in the 60s this is a tech report from the eye lab from Simon Popper and his team decided that computer vision was really simple, so he decided to solve vision in a summer project.",
                    "label": 0
                },
                {
                    "sent": "So he took the students that were not even graduated students because he thought it was too simple for a grad student to do and he asked them to Salvation.",
                    "label": 0
                },
                {
                    "sent": "So this tech report at lies all the different things that they need to solve in order to have a visual system.",
                    "label": 0
                },
                {
                    "sent": "And it's a really interesting read because it actually, you know.",
                    "label": 0
                },
                {
                    "sent": "Post as many of the interesting things that need to be solved, but there still then struggled during the entire summer and they didn't really get anything out.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the problem is that something like 50 or 6070 years ago you take.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An image like this one job.",
                    "label": 0
                },
                {
                    "sent": "Load it into your computer to do some analysis, and this is the typical output.",
                    "label": 0
                },
                {
                    "sent": "So there was basically.",
                    "label": 0
                },
                {
                    "sent": "There was basically nothing you could do.",
                    "label": 0
                },
                {
                    "sent": "Computers were really slow and despite of that they actually made a lot of progress in the algorithms and the methods and so on, but they could actually try them very well things.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Got a lot better than you know 25 years ago.",
                    "label": 0
                },
                {
                    "sent": "You could take a pic.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure you could upload it in the computer.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't give you out of memory and this was the typical output of a system.",
                    "label": 0
                },
                {
                    "sent": "So many of us have worked with systems like this ones are.",
                    "label": 0
                },
                {
                    "sent": "You could publish this.",
                    "label": 0
                },
                {
                    "sent": "It was not so bad.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know it was really depressing at the time because you are working.",
                    "label": 0
                },
                {
                    "sent": "You get this algorithm and it's very depressing, because vision seems so easy for us.",
                    "label": 0
                },
                {
                    "sent": "Seeing is such a simple task.",
                    "label": 0
                },
                {
                    "sent": "In fact.",
                    "label": 0
                },
                {
                    "sent": "Let me show you a video is a very low resolution video, so this is starting the vision crisis.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a very low resolution video and you can recognize everything that is going on here.",
                    "label": 0
                },
                {
                    "sent": "It contains about 20 pixels worth of vertical resolution, so it's really low resolution.",
                    "label": 0
                },
                {
                    "sent": "Most of the objects take maybe just one pixel and still you can recognize everything that goes on here because for you vision is so easy you see you open your eyes in the morning and you get to see.",
                    "label": 0
                },
                {
                    "sent": "And it's just simple Journal Titof scene at the end of the day, despite the old your brain is devoted to see in the world time.",
                    "label": 0
                },
                {
                    "sent": "But for you, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "It's not a hard thing.",
                    "label": 0
                },
                {
                    "sent": "So it's very hard to convince your parents that you're doing something interesting now because it seems so easy.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a chair, just tell me it's a chair just recognizing why is just system not working and The thing is that when you see you actually put into the world alot more than what there is actually there, now you get to interpret what you see.",
                    "label": 0
                },
                {
                    "sent": "So for realizing that, let me show you the high resolution video.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "You can see that you know you wear.",
                    "label": 0
                },
                {
                    "sent": "Seeing a lot of things that were not really there, this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a ferragus.",
                    "label": 0
                },
                {
                    "sent": "Will recorded this when we were sharing office when we were post docs on Bill Freeman was paying us and we were recording videos like this one here.",
                    "label": 0
                },
                {
                    "sent": "So you can see that you know.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Despite a very low resolution, you still you know you get to interpret because you're projecting into the video.",
                    "label": 0
                },
                {
                    "sent": "All the things that you know about the world, you have all these contextual relationships.",
                    "label": 0
                },
                {
                    "sent": "All these semantics and common sense knowledge that you have that help you to interpret the visual world an.",
                    "label": 0
                },
                {
                    "sent": "That's what makes vision so hard.",
                    "label": 0
                },
                {
                    "sent": "How do you get all those things into a computer?",
                    "label": 0
                },
                {
                    "sent": "In fact, when I show you a picture like this one, you can recognize perfectly what is the object behind the red mask.",
                    "label": 0
                },
                {
                    "sent": "Despite that you don't see it, and it's because you know all the things that make the world, so I'm sure.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You got it right.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But 15 years ago, things change quite dramatically.",
                    "label": 0
                },
                {
                    "sent": "An in particular phase detection appear as the first thing that actually was working at a commercial grade, and it was a recognition task.",
                    "label": 0
                },
                {
                    "sent": "There were other things working, but for object recognition, face detection was probably the first thing that made it into the commercial world.",
                    "label": 0
                },
                {
                    "sent": "So Paul Viola and Mike Jones introduce have really interesting detector for faces that was able to work in real time with really cheap processors and most digital cameras have now.",
                    "label": 0
                },
                {
                    "sent": "Face detection that relies on that algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, well, you know things like Facebook like Google will just hit to blur faces on Street View an it will blur all.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some things, but it worked really well and it was, you know, deploy in billions of images in super real time because they had to filter all those images really really fast so it was just an amazing thing.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this created a big advance in all kinds of methods in computer vision, most of them were handcrafted features.",
                    "label": 1
                },
                {
                    "sent": "Now people went there.",
                    "label": 0
                },
                {
                    "sent": "Some students will think, oh, I think I know how to make a better descriptor and justice coded app and it worked.",
                    "label": 0
                },
                {
                    "sent": "That was the way that people were making proud.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This in parallel there was another thing that was also very important is the data.",
                    "label": 0
                },
                {
                    "sent": "How do you train all these systems?",
                    "label": 0
                },
                {
                    "sent": "An advances in data sets has been also one of the reasons why computer vision is now nowadays so successful.",
                    "label": 0
                },
                {
                    "sent": "So let me tell you just a short story of image databases and how they change over.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm so here I'm going to show you just several data sets organize across time in the central axis on the vertical axis, the number of images that are available and how progress happens overtime.",
                    "label": 1
                },
                {
                    "sent": "So in the 70s most of the people had one data set that consisted in one single image that was the lender picture, which is a very famous and controversial picture, and that was basically what everybody was trying their algorithms on.",
                    "label": 0
                },
                {
                    "sent": "We knew everything about this picture.",
                    "label": 0
                },
                {
                    "sent": "We know who was the person in the picture.",
                    "label": 0
                },
                {
                    "sent": "We knew what was outside of this group version.",
                    "label": 0
                },
                {
                    "sent": "We knew.",
                    "label": 0
                },
                {
                    "sent": "We need all kinds of things.",
                    "label": 0
                },
                {
                    "sent": "It was that I said this was our training example and our test example.",
                    "label": 0
                },
                {
                    "sent": "It was everything.",
                    "label": 0
                },
                {
                    "sent": "Then things got a little bit better and seems like the fair database for faces appear contain 10s of thousands of images, so not a very large database.",
                    "label": 0
                },
                {
                    "sent": "For face recognition, then something like the coil database.",
                    "label": 0
                },
                {
                    "sent": "This was a database made of toy objects against a black background.",
                    "label": 0
                },
                {
                    "sent": "These objects were taking pictures in different poses and again this was a really hard task at the time people couldn't get algorithms to work at 100% recognition rate Despite that this was really really simple task.",
                    "label": 0
                },
                {
                    "sent": "Then the contact four is just four categories with a few hundreds of images per category.",
                    "label": 0
                },
                {
                    "sent": "Very simple data set.",
                    "label": 0
                },
                {
                    "sent": "This was nearly two year 2000.",
                    "label": 0
                },
                {
                    "sent": "Then contact 101.",
                    "label": 0
                },
                {
                    "sent": "This is 2000 one 2002.",
                    "label": 0
                },
                {
                    "sent": "An it contain about maybe 60,000 images, so still not a very large database.",
                    "label": 0
                },
                {
                    "sent": "101 object categories.",
                    "label": 0
                },
                {
                    "sent": "It created a lot of progress.",
                    "label": 0
                },
                {
                    "sent": "Many people started working on object recognition and making a lot of progress at the time.",
                    "label": 0
                },
                {
                    "sent": "But then the Pascal data set, which is a very important benchmark that appeared in the computer Vision community, still induce many algorithms.",
                    "label": 0
                },
                {
                    "sent": "If you're reporting performance on object recognition, probably you have to test on this one cause it gives context on how your algorithm is doing with respect to many other algorithms in the past.",
                    "label": 0
                },
                {
                    "sent": "But again, there are really a small data set, just 10s of thousands of images very very small for such a hard task.",
                    "label": 0
                },
                {
                    "sent": "General object Recognition, then things like the 80,000,000 images that Robin I created.",
                    "label": 0
                },
                {
                    "sent": "Several years ago, on image net, they try to go a lot farther.",
                    "label": 0
                },
                {
                    "sent": "Instead of doing something like after 101 with just a hundred categories.",
                    "label": 0
                },
                {
                    "sent": "The goal here was to collect them all so we just went to war net and collected all the words and started downloaded images and this is how I imagine it was created an.",
                    "label": 0
                },
                {
                    "sent": "The places database I will talk also about it is just the same thing but for scenes.",
                    "label": 0
                },
                {
                    "sent": "And this is really interesting if you compare the size of these data sets with the amount of data that a kid gets to see.",
                    "label": 0
                },
                {
                    "sent": "So a 2 year old kid will be there up there in the corner.",
                    "label": 0
                },
                {
                    "sent": "He sees about 10 to the nine images and we could discuss along time about how do you count exactly the number of images that a kid will see, but you roughly count 3 images per second?",
                    "label": 0
                },
                {
                    "sent": "OK, they're going to be highly correlated by, you know, just for psych of an argument, 3 images per per second being awake 16 hours per day.",
                    "label": 0
                },
                {
                    "sent": "If you are lucky an.",
                    "label": 0
                },
                {
                    "sent": "An during two years is going to see something like 10 to the nine images, so we are getting really close.",
                    "label": 0
                },
                {
                    "sent": "We're still not there.",
                    "label": 0
                },
                {
                    "sent": "We are still a couple of orders of money too short of what a kid will see, but given the diversity of the nature of the images that these data sets are made of, probably this is a lot more data than what a 2 year old kid gets to see.",
                    "label": 0
                },
                {
                    "sent": "Although there is there other modalities and so on that I will talk about it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An so nowadays is the time of big data for you having access to big data sets, it seems something very simple, not just go there and download images, and it seems trivial.",
                    "label": 1
                },
                {
                    "sent": "There are so many data sets available nowadays, but those data sets are very recent.",
                    "label": 0
                },
                {
                    "sent": "People.",
                    "label": 0
                },
                {
                    "sent": "In the past they you know they had very few images to train their algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in 2010, more or less a newer student will get into computer vision, will see the success of action get really excited, will pick one data set to train.",
                    "label": 0
                },
                {
                    "sent": "The algorithm, will pick one model out of all the possible models that exist.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will take one picture.",
                    "label": 0
                },
                {
                    "sent": "Will run the algorithm and that was the output.",
                    "label": 0
                },
                {
                    "sent": "This is 2010, so what's going wrong here?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, who's to blame?",
                    "label": 0
                },
                {
                    "sent": "Here is the data, the features the student.",
                    "label": 1
                },
                {
                    "sent": "What's the problem here?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the most popular descriptor at the time in 2010, between 2005 and 2010 was hog.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many of you have heard of Hog.",
                    "label": 0
                },
                {
                    "sent": "OK, like half of the audience, this was a really popular descriptor at the time.",
                    "label": 0
                },
                {
                    "sent": "If you wanted to have an algorithm that will do object detection with the state of the art performance, you had to use hog and it basically just a bunch of layers.",
                    "label": 0
                },
                {
                    "sent": "It looks very much like a confident but all the different layers and filters are chosen by hand.",
                    "label": 0
                },
                {
                    "sent": "The coefficients everything is set by hand an is basically a recipe that you apply to the picture and it will go through a set of nonlinearities and at the end it will give you a vector.",
                    "label": 0
                },
                {
                    "sent": "And the question is, well, why is this not working?",
                    "label": 0
                },
                {
                    "sent": "Why is that it will say that there is a car on the water and it's really hard to tell 'cause the process is so nonlinear.",
                    "label": 0
                },
                {
                    "sent": "So a couple of my students wanted to know if we could visualize this output.",
                    "label": 1
                },
                {
                    "sent": "So what they proposed was just some way of rendering back the pictures just given the output, render the picture that will give rise to the exact same descriptor and you can do that as just some minimization technique just formulated the problem as I want to look for the image that when you throw the same computation, it will give you a fixed output and just do gradient descent on that.",
                    "label": 0
                },
                {
                    "sent": "When you do that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the output that you get.",
                    "label": 0
                },
                {
                    "sent": "An here it shows a little bit the type of things that were important for this descriptor and is actually important in many representations that are just in computer vision.",
                    "label": 0
                },
                {
                    "sent": "One is contrast normalization, like here.",
                    "label": 0
                },
                {
                    "sent": "You can see that the background has some black regions, but here you can see some contrast, and it's because there is some normalization and this is something that is done inconvenient.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it is now as Rob was describing.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it works better, sometimes it doesn't exactly are.",
                    "label": 0
                },
                {
                    "sent": "In this case this was part of the representation.",
                    "label": 0
                },
                {
                    "sent": "You can still recognize that there is a person here, so clearly is seeing all the information that seems relevant for doing object detection.",
                    "label": 0
                },
                {
                    "sent": "So now what you can do is you take this visualization, you take your classifier that is trained with this particular descriptor.",
                    "label": 0
                },
                {
                    "sent": "You run it in images.",
                    "label": 0
                },
                {
                    "sent": "And you train it to the text on particular object.",
                    "label": 0
                },
                {
                    "sent": "Let's say cars.",
                    "label": 0
                },
                {
                    "sent": "You run it through many images in the Pascal data set, for instance, and you crop the regions weather detector fire with highest confidence and those will be your detection's.",
                    "label": 0
                },
                {
                    "sent": "And then you visualize the output with this particular technique.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here what I'm showing is groups from images that created a strong response for the person detector, the chair detector and the car detector.",
                    "label": 0
                },
                {
                    "sent": "So if you haven't seen this before, can you guess which one are false alarms?",
                    "label": 1
                },
                {
                    "sent": "So now I'm going to show you the actual images where the crops are coming from and they are all.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "False alarms.",
                    "label": 0
                },
                {
                    "sent": "These are the crops.",
                    "label": 0
                },
                {
                    "sent": "This is what?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, the vector was seen.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what the image contains, so you can see that it's throwing away all the information that was relevant for the detection and is just turning these objects into the thing that you're looking for because.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you look at these representations, they actually kind of look like the objects are looking for.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "You can even tell stories about the people that you see there.",
                    "label": 0
                },
                {
                    "sent": "Now some people are like a standing, some like the first one.",
                    "label": 0
                },
                {
                    "sent": "Seems somebody in front of a mirror, so you can tell kind of a story of what is going on here and other cars.",
                    "label": 0
                },
                {
                    "sent": "They look pretty compelling, like if you look at this one here.",
                    "label": 0
                },
                {
                    "sent": "Right, it looks like the wheels, but this.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just two heads.",
                    "label": 0
                },
                {
                    "sent": "So it's a disaster now.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in fact, when you just this visualization and you show it to humans and you ask humans to do the classification, they perform like the detector.",
                    "label": 0
                },
                {
                    "sent": "So once you have these features, appliance VM an the fact that the performances are not so great could be because the classifier maybe is not strong enough.",
                    "label": 0
                },
                {
                    "sent": "Maybe you need better machine learning there an in fact when you remove that classifier and you put a human there, the performances are almost identical to the classifier.",
                    "label": 0
                },
                {
                    "sent": "So in blue.",
                    "label": 0
                },
                {
                    "sent": "Is the classifier on in red?",
                    "label": 0
                },
                {
                    "sent": "Is the human performance and this is a standard precision recall curve and in green is the curve that you get when you ask humans to classify the original Patch so you can see that humans can do the task is just that when it goes through the descriptor information is gone.",
                    "label": 0
                },
                {
                    "sent": "So this was what was going on in the year 2010, more or less and you know the only way around it is better descriptors.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the original picture.",
                    "label": 0
                },
                {
                    "sent": "This is the region where the doctor thought there is a car.",
                    "label": 0
                },
                {
                    "sent": "This is the image Patch and this is what the detector gets to see.",
                    "label": 1
                },
                {
                    "sent": "So it actually doesn't look like a side view of a car, so that factor was working in some sense.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "The size of the window should do better because window sizes so small and hence you can see a car.",
                    "label": 0
                },
                {
                    "sent": "But if you increase the size you will see the edges of the dog and probably won't see a garden.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah, so you can do things like increasing the windows so that you can get the more context and so on, But then performances drop for other reasons because suddenly you get a lot more confusion.",
                    "label": 0
                },
                {
                    "sent": "Your algorithm needs to focus in their internal region, which is generally the more relevant one.",
                    "label": 0
                },
                {
                    "sent": "Some people have tried all these kind of things and just there's really no way around it.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so deep learning came along and it makes a big difference as Rob has been showing so I'm not going to give a lot of details about it.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we also got interested into it.",
                    "label": 0
                },
                {
                    "sent": "An we saw that it was really well.",
                    "label": 0
                },
                {
                    "sent": "So we created a scene recognition demo that you can run it.",
                    "label": 0
                },
                {
                    "sent": "You go to this link and I show you some images and this was just a straight application of the Alex Net architecture that Rob has been describing.",
                    "label": 0
                },
                {
                    "sent": "Trained for the task of scene recognition and the task of synchronization is just given a picture to tell what type of environment it is like.",
                    "label": 0
                },
                {
                    "sent": "This is an auditorium or regarding a street and so on.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are some examples.",
                    "label": 0
                },
                {
                    "sent": "These are pictures I took just a few weeks ago while going on vacation.",
                    "label": 0
                },
                {
                    "sent": "So it will say this is a swimming pool, so it was really well.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is just today when I was arriving to the airport and there were big lines.",
                    "label": 0
                },
                {
                    "sent": "So it says Airport Terminal which is quite amazing because it you know it looks like an airport terminal.",
                    "label": 0
                },
                {
                    "sent": "But it seems like it's not a very Canonical view of an airport terminal.",
                    "label": 0
                },
                {
                    "sent": "Is quite amazing that it works so well even when you look at attributes it will say waiting in line which I had to do for an hour.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is another picture taken on the on the taxi drive to tell the taxi the cabin of a taxi is not a category in the in the in the database, but it still says like cockpit parking lot and so it still says waiting in line.",
                    "label": 0
                },
                {
                    "sent": "You probably.",
                    "label": 0
                },
                {
                    "sent": "In Neil, I've been waiting for a long time.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "This is now.",
                    "label": 0
                },
                {
                    "sent": "This is just sorry this is a different auditorium.",
                    "label": 0
                },
                {
                    "sent": "It says Auditorium Conference Center then.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I took a picture of rap talking now and it says auditorium but it says Bar.",
                    "label": 0
                },
                {
                    "sent": "Rob likes bars a lot.",
                    "label": 0
                },
                {
                    "sent": "I have no idea how the network knows this, but.",
                    "label": 0
                },
                {
                    "sent": "But it works amazingly well.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is another picture.",
                    "label": 0
                },
                {
                    "sent": "Taking a hotel room and it says hotel room.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a different picture in the same in the same room.",
                    "label": 0
                },
                {
                    "sent": "It still says hotel room, which I thought it was really really amazing because there is almost nothing here in this picture is really not not a Canonical view of another room.",
                    "label": 0
                },
                {
                    "sent": "So how can we know that this is another room?",
                    "label": 0
                },
                {
                    "sent": "Well, this lamp is alarmed that generally people don't have at home, so it looks like another room lamp.",
                    "label": 0
                },
                {
                    "sent": "Well, certainly if some of you have a lamp like this.",
                    "label": 0
                },
                {
                    "sent": "Is beautiful.",
                    "label": 0
                },
                {
                    "sent": "But you know, it doesn't look like a hotel room lamp, so I was thinking OK, so maybe the network is actually detecting the altar room lamp.",
                    "label": 0
                },
                {
                    "sent": "It has learned somehow to detect that lamp.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yep, so the question then was then OK, how is this possible?",
                    "label": 0
                },
                {
                    "sent": "How is working so well?",
                    "label": 1
                },
                {
                    "sent": "You have this network that you train and rock has been showing a number of different architectures.",
                    "label": 0
                },
                {
                    "sent": "You have some tasks.",
                    "label": 0
                },
                {
                    "sent": "You train your network and it just works very well and it's always treated like a black box.",
                    "label": 0
                },
                {
                    "sent": "Now it just looks like some magical machine learning architecture that you throw data to it and it will give you a solution to your task.",
                    "label": 0
                },
                {
                    "sent": "But then the question is OK, how it is working?",
                    "label": 0
                },
                {
                    "sent": "What is the representation that is being built inside the network?",
                    "label": 0
                },
                {
                    "sent": "And that's the question that we try to answer now.",
                    "label": 0
                },
                {
                    "sent": "It just seems like an important question to understand.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a number of pieces of work that tried to visualize what is that.",
                    "label": 0
                },
                {
                    "sent": "Individual units inside the network of learning and Rob has described some of them like the convolution technique that he has been showing.",
                    "label": 0
                },
                {
                    "sent": "There are other techniques like doing backpropagation.",
                    "label": 0
                },
                {
                    "sent": "You take one unit and you do back propagation to see what in the images activating that unit.",
                    "label": 0
                },
                {
                    "sent": "You can also look you can study a strong activations.",
                    "label": 0
                },
                {
                    "sent": "You can take one unit and just check which images produced the strongest activation into that particular unit.",
                    "label": 0
                },
                {
                    "sent": "So there are different techniques.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the one that Rob described that I'm not going to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are also this in this work by Ben Jaanan, collaborators, in which they try to train the use this adversarial networks, which probably you have talk, or you will talk.",
                    "label": 0
                },
                {
                    "sent": "Somebody will talk, so I'll just give you a one minute summary, but basically the idea is you have one generator that is going to take us input a random vector.",
                    "label": 0
                },
                {
                    "sent": "And you want the output to look like a picture.",
                    "label": 0
                },
                {
                    "sent": "So how do you train this random generator?",
                    "label": 0
                },
                {
                    "sent": "This generator?",
                    "label": 0
                },
                {
                    "sent": "Well, do train, also a discriminator that is going to solve a particular task is going to take us input.",
                    "label": 0
                },
                {
                    "sent": "The images that conference your generator and also images that come from the real database and the task of the discriminator is to say if it is recreated.",
                    "label": 0
                },
                {
                    "sent": "And the generator task is to be able to fool the discriminator, so you need to train the generator so that the discriminator cannot tell apart the two samples.",
                    "label": 0
                },
                {
                    "sent": "It cannot tell apart which ones are generated and which ones are real, and these two things are trained jointly.",
                    "label": 0
                },
                {
                    "sent": "So in this particular work they just do multilayer perceptrons.",
                    "label": 0
                },
                {
                    "sent": "An they train it to generate real images.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this has some samples.",
                    "label": 0
                },
                {
                    "sent": "Once it's trained, these are some samples that come from that particular generator.",
                    "label": 0
                },
                {
                    "sent": "Well, they don't really look like real images, but they start getting some of the components.",
                    "label": 0
                },
                {
                    "sent": "Not like the colors.",
                    "label": 0
                },
                {
                    "sent": "They look like some type of wild animals, although you cannot really see what animals are there, but it looks a lot like texture synthesis in the 90s.",
                    "label": 0
                },
                {
                    "sent": "So they don't know this is start being beautiful images.",
                    "label": 0
                },
                {
                    "sent": "They have the right distribution of colors and they look as having a blob somewhere there that looks kind of has the color of a nanny.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Call Ann.",
                    "label": 0
                },
                {
                    "sent": "And then there were improvements over these techniques.",
                    "label": 0
                },
                {
                    "sent": "This technique, so one of the issues was that using this multilayer perceptron probably was not a very strong representation.",
                    "label": 0
                },
                {
                    "sent": "So here, in this particular work they introduce using calmness to generate images.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what they do here is they have a generator.",
                    "label": 0
                },
                {
                    "sent": "Evolution on narrow network that takes us input a vector and it will output a picture and it's just a sequence of convolutional, an upsampling layers so that the output is a picture.",
                    "label": 0
                },
                {
                    "sent": "And so here, not just start with random generator with random uniform vector and then you generate a picture and those are samples that come from this process.",
                    "label": 1
                },
                {
                    "sent": "Ann again, it's trained with this adversarial training and it looks really, really nice now these are this is trained with like 100,000 bedrooms, so lots of bedrooms.",
                    "label": 0
                },
                {
                    "sent": "It only knows how to generate bedrooms but they look beautiful.",
                    "label": 0
                },
                {
                    "sent": "They look like real bedrooms and they looked into the database and they concluded that those images are not inside the data set.",
                    "label": 0
                },
                {
                    "sent": "So it's really generalizing them.",
                    "label": 0
                },
                {
                    "sent": "You know this is for, maybe it needs a closer inspection.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this other paper basically took this similar idea and justice.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little bit further, and the idea here was to try to visualize what different units are doing and for this they just components, a generator, which is the one that I just previously described as the convolutional neural network, and then the network that you want to visualize.",
                    "label": 0
                },
                {
                    "sent": "Let's say that it's Alex Net and what you do is you take the output of the generator and you connect it as the input of the network.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then so you have this and then you pick one unit in your Internet work that you want to visualize and you change.",
                    "label": 1
                },
                {
                    "sent": "You change the input what they generate, change the random vector that the generator takes us input so that the output.",
                    "label": 0
                },
                {
                    "sent": "But this is an image that is strongly activates the unit diagram looking for OK, so you can do that again with back propagation.",
                    "label": 0
                },
                {
                    "sent": "And here is an example of an image that gets generated so that the the table lamp detector gets strongly activated and it looks like a table lamp is a beautiful.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not perfect, it's not photo realistic, but it has all the right elements.",
                    "label": 0
                },
                {
                    "sent": "Now you can see that it's on is a really beautiful save the image of a table lamp.",
                    "label": 1
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are more examples of visualizing different output units in Alex Net.",
                    "label": 0
                },
                {
                    "sent": "What is trying to do.",
                    "label": 0
                },
                {
                    "sent": "The image net classification.",
                    "label": 0
                },
                {
                    "sent": "An image net contains lots of images that are individual objects like table lamps, here test libraries, cheeseburgers, barns, candles, table lamps, and so on.",
                    "label": 0
                },
                {
                    "sent": "So here there are.",
                    "label": 0
                },
                {
                    "sent": "These images are generated from this method.",
                    "label": 0
                },
                {
                    "sent": "So each one is one of those samples and they look really beautiful.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If anybody has questions, just raise your hands.",
                    "label": 0
                },
                {
                    "sent": "So first I wanted this community in two different tasks because we will use them to better understand what the network is.",
                    "label": 0
                },
                {
                    "sent": "Learning, object detection, unseen recognition, object detection will be something like that.",
                    "label": 1
                },
                {
                    "sent": "Rob has been talking about.",
                    "label": 0
                },
                {
                    "sent": "Given a picture you want to locate that there is a bird or maybe just say that there is a bird in this picture, which is mostly what what image net is focused on.",
                    "label": 0
                },
                {
                    "sent": "This images of objects I'm seeing recognition will be more like given a picture.",
                    "label": 0
                },
                {
                    "sent": "Just tell what type of environment it is like saying that this is a bathroom is a very similar classification.",
                    "label": 0
                },
                {
                    "sent": "Ask for the machine learning perspective is just one label that gets attached to the picture, but from the viewpoint of our representation, these two tasks are very different.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's what we will focus on.",
                    "label": 0
                },
                {
                    "sent": "So for the object classification task, we can just imagine it, which is this very important data set that created by Faye and collaborators, and basically what they did is they quarknet one.",
                    "label": 0
                },
                {
                    "sent": "It is this electronic dictionary developed Princeton take all the words that correspond to the subjects and downloaded images and there are 10s of thousands of categories for each category.",
                    "label": 0
                },
                {
                    "sent": "You have thousands of images.",
                    "label": 0
                },
                {
                    "sent": "And they are organized in this three that is given by Warnet.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we created a data set for the scene recognition task, which is the parallel to Imagine network for sins.",
                    "label": 0
                },
                {
                    "sent": "And this is the places database and basically what we did was again take the burner dictionary but now look at the words and take only the words that corresponded to seeing categories.",
                    "label": 0
                },
                {
                    "sent": "Things like offices, bathrooms, corridors, not a specific places like Eiffel Tower generic scenes.",
                    "label": 0
                },
                {
                    "sent": "So we have one student going through this list.",
                    "label": 0
                },
                {
                    "sent": "It took about six months the student survive.",
                    "label": 0
                },
                {
                    "sent": "And then we just downloaded images and then we had a process of cleaning the map.",
                    "label": 1
                },
                {
                    "sent": "Because when you download images from Google you don't get the Sally.",
                    "label": 1
                },
                {
                    "sent": "What you are asking for and we had to do a lot of manual cleaning.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have these two big databases imaginum places.",
                    "label": 0
                },
                {
                    "sent": "They have very similar structure from a machine learning point of view is a classification task, but from the representation that you need to build to solve this task is very different.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you think so now what we will do is just take the same architecture.",
                    "label": 0
                },
                {
                    "sent": "In this case I'm going to focus on Alex Net, but you can do the same thing for any architecture.",
                    "label": 0
                },
                {
                    "sent": "Ann will take the same architecture and training with these two very different data sets.",
                    "label": 1
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What is the internal representation that might emerge inside the network well?",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Play something that imagine it that is focused on objects.",
                    "label": 0
                },
                {
                    "sent": "Well, what could be a representation for objects?",
                    "label": 0
                },
                {
                    "sent": "Well, it could be part.",
                    "label": 0
                },
                {
                    "sent": "Maybe do one of the different pieces of objects and have some type of spatial relationships between them.",
                    "label": 0
                },
                {
                    "sent": "That tells you when the object is there or not.",
                    "label": 0
                },
                {
                    "sent": "You could describe an object as sub mixture of textures, or you could have attributes which is also very popular representation for objects.",
                    "label": 0
                },
                {
                    "sent": "All those are possible representations.",
                    "label": 0
                },
                {
                    "sent": "One of the problems is that you think about objects you do want to find what an object part is is very hard because what is the part of the parts of a phase are the eyes, the mouth, the nose, or is the two eyes together one part or maybe one I and a piece of the nose.",
                    "label": 0
                },
                {
                    "sent": "Is that a valid part?",
                    "label": 0
                },
                {
                    "sent": "Well, maybe Jess, so it's very hard to define what is the set of parts that is convenient for representation.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In since you have a similar task.",
                    "label": 0
                },
                {
                    "sent": "And now the possible internal representations.",
                    "label": 1
                },
                {
                    "sent": "Well, it could be seen parts, it could be something.",
                    "label": 0
                },
                {
                    "sent": "There's like object parse.",
                    "label": 0
                },
                {
                    "sent": "It could be some parts that don't really have much meaning.",
                    "label": 0
                },
                {
                    "sent": "It could be objects.",
                    "label": 0
                },
                {
                    "sent": "Objects could be the things that you are going to use to represent scenes, so those are also seen parts.",
                    "label": 0
                },
                {
                    "sent": "But now they are very well defined.",
                    "label": 0
                },
                {
                    "sent": "An object is something very concrete, it could be seen attributes, it could be object parts, it could be textures.",
                    "label": 0
                },
                {
                    "sent": "All those things are things that people in computer vision have been using as possible representations, of which one of those is the one that the network learns to do.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we have this network an.",
                    "label": 0
                },
                {
                    "sent": "One standard strategy to train this to use this network for different tasks is to train one network with, let's say image net.",
                    "label": 0
                },
                {
                    "sent": "You remove the final classification layer and reduce the output that remains as a generic feature, and then you train a linear SVM with whatever task you want to do.",
                    "label": 0
                },
                {
                    "sent": "And this is a very standard technique and it works really well.",
                    "label": 0
                },
                {
                    "sent": "So here there are examples of doing this.",
                    "label": 0
                },
                {
                    "sent": "Now you take another train with image, Net, or with places and you and you test it on different benchmarks.",
                    "label": 1
                },
                {
                    "sent": "Like here these are seen data sets like indoor classification, seen attributes classification, different benchmarks that are simulated, and you can train what happens with features that are genetic features that come from a network train with image, net or with both with places and what you see, is that forcing related tasks, training with scenes works better.",
                    "label": 0
                },
                {
                    "sent": "And when you have object centric tasks then if you train with image, net is better and there are big differences between the two.",
                    "label": 0
                },
                {
                    "sent": "So clearly these two networks are doing something different.",
                    "label": 0
                },
                {
                    "sent": "They're learning a different representation.",
                    "label": 0
                },
                {
                    "sent": "Performances are high in both cases, but they seem to be specialized and they perform much better when the task looks like that as they have been trained with.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So another way of seeing that the representations are different is by looking at whatever the preferred images for each layer in the network.",
                    "label": 0
                },
                {
                    "sent": "So here's what I'm going to show is we took 200,000 images, 100,000 images coming from Image net, 100,000 images coming from places with throw them to the network, and we look at the three images that produce the stronger, strongest activation at each layer, and here by a stronger activation what it means.",
                    "label": 0
                },
                {
                    "sent": "I take all the units in that layer and with some other activations an we get one number.",
                    "label": 0
                },
                {
                    "sent": "All the images with that number.",
                    "label": 0
                },
                {
                    "sent": "There are many other ways that you could do this.",
                    "label": 0
                },
                {
                    "sent": "This is one way.",
                    "label": 0
                },
                {
                    "sent": "So these are the three images that the image net train network prefers.",
                    "label": 0
                },
                {
                    "sent": "And you know they look like having texture all over the place.",
                    "label": 0
                },
                {
                    "sent": "And these are the three images that the place network wants.",
                    "label": 0
                },
                {
                    "sent": "And two of them are common and the other ones that they come nearby.",
                    "label": 0
                },
                {
                    "sent": "So you want to look a few more images that you will get them there.",
                    "label": 0
                },
                {
                    "sent": "And this is among 300,000 images.",
                    "label": 0
                },
                {
                    "sent": "This is very different.",
                    "label": 0
                },
                {
                    "sent": "Training data sets for each network, but the filters that they converge to in the first layer, they seem almost identical.",
                    "label": 0
                },
                {
                    "sent": "Because the three images they just are identical, so it's quite amazing.",
                    "label": 0
                },
                {
                    "sent": "This is the second layer.",
                    "label": 0
                },
                {
                    "sent": "And these are the three preferred images for places.",
                    "label": 0
                },
                {
                    "sent": "Again, very, very similar.",
                    "label": 0
                },
                {
                    "sent": "One of them is in common and the others just came come a little bit later in the ranking, so it's still you know what would be the chance of getting this Now if the layers were just slightly different.",
                    "label": 0
                },
                {
                    "sent": "This is the third layer.",
                    "label": 0
                },
                {
                    "sent": "This is the images that imaginative prefers, and this is places now they start looking different.",
                    "label": 0
                },
                {
                    "sent": "Imagine it looks like a.",
                    "label": 0
                },
                {
                    "sent": "Lines and so on places look, start looking like scenes but still texture like.",
                    "label": 0
                },
                {
                    "sent": "This is comfort.",
                    "label": 0
                },
                {
                    "sent": "Imagine that starts having some preference for objects.",
                    "label": 0
                },
                {
                    "sent": "In this case, both know it likes round things all over the place and this is places.",
                    "label": 0
                },
                {
                    "sent": "Now it looks like scenes now some perspective.",
                    "label": 0
                },
                {
                    "sent": "These are very very different now and this is part five image net docs.",
                    "label": 0
                },
                {
                    "sent": "One is that among the thousand categories that there are 200 of them are dogs, an service grace this interest in the network to Watch Dogs now, and you know, it just papers.",
                    "label": 0
                },
                {
                    "sent": "And when they do Alusa Nation of things now you get to see all these dogs emerging all over the place all the time now because 20% of imagine it is about dogs.",
                    "label": 0
                },
                {
                    "sent": "And this is what happens with places.",
                    "label": 0
                },
                {
                    "sent": "Now perspective he likes totally different types of things.",
                    "label": 0
                },
                {
                    "sent": "Now the last layers are clearly doing something very different.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another important thing is to estimate.",
                    "label": 0
                },
                {
                    "sent": "Try to get a sense of what each unit is focusing on on the picture.",
                    "label": 0
                },
                {
                    "sent": "What is the receptive field an?",
                    "label": 1
                },
                {
                    "sent": "There are many ways in which you could do this.",
                    "label": 0
                },
                {
                    "sent": "You could do it.",
                    "label": 0
                },
                {
                    "sent": "You could take 11 unit in one layer and try to do back propagation to see what is the region that it gets to see.",
                    "label": 0
                },
                {
                    "sent": "Or you could do just try to look at the convolutions.",
                    "label": 0
                },
                {
                    "sent": "And get some theoretical size that you will get in a particular unit.",
                    "label": 0
                },
                {
                    "sent": "Here is a very simple trick that you can do.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter what the architecture is.",
                    "label": 0
                },
                {
                    "sent": "One thing that you can do is, let's say that you want to know the receptive field of this particular unit there.",
                    "label": 0
                },
                {
                    "sent": "This is your input.",
                    "label": 0
                },
                {
                    "sent": "Just take an image that produces a strong activation in that unit.",
                    "label": 0
                },
                {
                    "sent": "It doesn't need to be the strongest activation, just some activation there.",
                    "label": 0
                },
                {
                    "sent": "And then you take a black square.",
                    "label": 0
                },
                {
                    "sent": "Just the dumbest thing that you can imagine.",
                    "label": 0
                },
                {
                    "sent": "Just take a block of square, put it on top of the image and move it along.",
                    "label": 0
                },
                {
                    "sent": "And record the activation of the unit and check where it changes and it will get you some sense of what is the relative of that unit.",
                    "label": 0
                },
                {
                    "sent": "OK, and people have been doing this for localising objects in images like Rob has been doing that too.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of this receptive field for this particular unit.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So in leisure one if you do this trick, but you find is that objective, fields are very small.",
                    "label": 0
                },
                {
                    "sent": "Now it's just the size of the kernel, just very very small.",
                    "label": 0
                },
                {
                    "sent": "This is layer 3.",
                    "label": 0
                },
                {
                    "sent": "In orange, Kieran showing what is this practical receptive field that we synthetic empirical receptive field that we find when we pass this Black Square now?",
                    "label": 0
                },
                {
                    "sent": "And you can change the size of the square doesn't really matter something that creates some activation and some change in the activation.",
                    "label": 0
                },
                {
                    "sent": "And Jello is the theoretical receptive field size.",
                    "label": 1
                },
                {
                    "sent": "This is just taking into account the size of the convolutions and the fact that when you convolve things get added so you can see that the actual receptive field is a lot smaller than the theoretical varsity field.",
                    "label": 0
                },
                {
                    "sent": "And this is in layer five, which generally we think that layer 5 gets to see the entire picture almost gets to see the entire picture, and it's true that it has the potential to do it.",
                    "label": 0
                },
                {
                    "sent": "But in practice it actually selects a much smaller piece, something like 20% of the picture.",
                    "label": 0
                },
                {
                    "sent": "So it has a lot of localization capabilities.",
                    "label": 0
                },
                {
                    "sent": "We can localize things in the picture.",
                    "label": 1
                },
                {
                    "sent": "So these are smaller and this is true for almost all units in layer 5.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then you can do things like doing segmentation.",
                    "label": 0
                },
                {
                    "sent": "Or you can take the feature map.",
                    "label": 1
                },
                {
                    "sent": "The activation of all the different units that are that are within the same convolutional layer, the same that apply the same kernel.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's say in Layer 5 this will be the activations.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can just do a weighted sum of this protective field that you found and just create a mask of what the object where the objects should be so.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's something trivial now.",
                    "label": 0
                },
                {
                    "sent": "In this case you could get something like this.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so once you do this so once we have the receptive field for each unit in the network, so all the layers, one thing that we want to know is what are all these different journeys doing?",
                    "label": 0
                },
                {
                    "sent": "So there are too many units to go 1 by 1 by hand.",
                    "label": 0
                },
                {
                    "sent": "So what we did was to crowd source the interpretation of the network.",
                    "label": 0
                },
                {
                    "sent": "So you take, you take one unit, you pass the 200,000 images and we select the 60 images that produce the strongest activation in that particular unit, and then we apply the receptive field to know exactly what is the region of the picture that produces strongest activation there and then show it in Mechanical Turk just in answer Mechanical Turk so that workers could tell us what.",
                    "label": 0
                },
                {
                    "sent": "What is that journey doing?",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Snapshot of the interface.",
                    "label": 0
                },
                {
                    "sent": "We show them 60 images and we ask them to tell us what is the concept that these images have in common.",
                    "label": 0
                },
                {
                    "sent": "They don't know anything about where these images are coming from.",
                    "label": 0
                },
                {
                    "sent": "Ann and they also get to click on the images that do not fit that concept because some images might be just wrong detections.",
                    "label": 0
                },
                {
                    "sent": "So in this particular case the worker says OK, this all these images seem to have in common a lighthouse, and there are these images here that were something else that are not like houses.",
                    "label": 0
                },
                {
                    "sent": "So he mark those images and then.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also ask to tell us what type of concept that description belong to.",
                    "label": 0
                },
                {
                    "sent": "It's an object part is a scene is an object, type is a texture.",
                    "label": 0
                },
                {
                    "sent": "It's a simple element.",
                    "label": 0
                },
                {
                    "sent": "What is it?",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then now we have this for all the units we did it with several people per unit, and here is an example of one of the units in Port 5 an in this case this is trained for the same recognition task.",
                    "label": 0
                },
                {
                    "sent": "And this particular unit got the label Ocean.",
                    "label": 1
                },
                {
                    "sent": "An you can see that is segmenting the ocean on these images.",
                    "label": 0
                },
                {
                    "sent": "It seems to be localized in it pretty well, and there are four errors out of the 60 images.",
                    "label": 0
                },
                {
                    "sent": "That, well, you know this could be.",
                    "label": 0
                },
                {
                    "sent": "The errors they look they look wrong, but you could imagine why the neuron the unit could fire there.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is another example.",
                    "label": 0
                },
                {
                    "sent": "This is detecting lamps.",
                    "label": 0
                },
                {
                    "sent": "Ann is quite reliable it because there are.",
                    "label": 0
                },
                {
                    "sent": "There are a few errors here, but most of the most of that actions are correct, and this localising these lamps in the picture is not just saying that there is not, the worker is hallucinate ING some concept here and there is a lot of consistency across people.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This unit here is detecting Lex.",
                    "label": 0
                },
                {
                    "sent": "Any kind of legs?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this one here is detecting pool tables and is also confusing swimming pools here is well there is some visual similarities, so maybe you could imagine why these two concepts get mixed here.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is another example of a unit that mixes to concert.",
                    "label": 0
                },
                {
                    "sent": "This is something that we found that happens.",
                    "label": 0
                },
                {
                    "sent": "Relatively often that there could be a unit that is mixing two objects.",
                    "label": 0
                },
                {
                    "sent": "It doesn't fire to anything else, just these two objects, like here.",
                    "label": 0
                },
                {
                    "sent": "Now it's detecting tables.",
                    "label": 0
                },
                {
                    "sent": "Special settings know for tables and this is not the typical setting that you will have at home and buildings, but kind of Barack buildings, and there are a few errors.",
                    "label": 0
                },
                {
                    "sent": "There are a few things that are not this not like a sink here.",
                    "label": 0
                },
                {
                    "sent": "There are few errors, but most of the time it's just these two concepts.",
                    "label": 0
                },
                {
                    "sent": "Feels like the Pool 5 contains about contains only 256 units and it feels like it once more units not to separate these objects, and in fact, when you put more units you have more you have more unique elements that appear.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we can analyze what is happening in each layer.",
                    "label": 0
                },
                {
                    "sent": "Now all these situations that Rob was describing before we can, we can look quantitatively at them and see you know what each particular layer is trying to do as a representation so.",
                    "label": 0
                },
                {
                    "sent": "So first let's focus on simple elements and colors.",
                    "label": 1
                },
                {
                    "sent": "This will be units that react just a simple colors or lines, but nothing semantic and we can check where are they located.",
                    "label": 0
                },
                {
                    "sent": "And as you could expect, they're mostly located in the first layer.",
                    "label": 0
                },
                {
                    "sent": "So here this plot what it shows is the recent Alexis is the layer number and the vertical axis is the percentage of units that got assigned.",
                    "label": 0
                },
                {
                    "sent": "To 1 one of those to this concept to the simple elements and colors.",
                    "label": 0
                },
                {
                    "sent": "And here to decide that one unit is sensitive to one of those concepts.",
                    "label": 0
                },
                {
                    "sent": "We only count units that.",
                    "label": 0
                },
                {
                    "sent": "Are correct, at least 75% of the time on these 60 images that we showed.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, there are some other units that could go here, but it's unclear what exactly they doing because the performance is slightly lower and there are about 60% of the units that get assigned clearly to one of those concepts, both in image net train network in places.",
                    "label": 0
                },
                {
                    "sent": "In this model, is constant across all all the layers around 60% of the units.",
                    "label": 0
                },
                {
                    "sent": "You can tell what they are doing.",
                    "label": 0
                },
                {
                    "sent": "And so you can see that as you go deeper into the network towards higher layers, you drop in the percentage of elements that of June is that are sensitive to simple elements in green is what happens with a network very strained with image net and in red is what happens with the network, but it's trained with places forcing recognition and you can see that with image net there are still a higher percentage of units even in Pool 5 that are sensitive to simple elements.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can do the same thing with texture materials.",
                    "label": 0
                },
                {
                    "sent": "Here is the distribution.",
                    "label": 0
                },
                {
                    "sent": "An again, they're mostly concentrated in the first 2 layers, and then it drops.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can look at regions and surfaces and here there are already semantics, so regions and surfaces here I'm referring to grass Sky roads, so these are already semantical concepts.",
                    "label": 1
                },
                {
                    "sent": "So when you do this, define that they appear toward the higher layers, mostly in the last layer input 5.",
                    "label": 0
                },
                {
                    "sent": "After that, there are the fully connected layers, so we're not looking into those.",
                    "label": 0
                },
                {
                    "sent": "There is some mess on concepts, it's all mixed in here.",
                    "label": 0
                },
                {
                    "sent": "You can see that regions and surfaces appear mostly when you train with places, but not with image net, and that makes sense because you mention it is oriented towards objects.",
                    "label": 0
                },
                {
                    "sent": "Most of the objects are relatively big an.",
                    "label": 0
                },
                {
                    "sent": "However, for scenes you really want to recognize things like Sky and Roseann grass, this is a very important categorisation thing that you need to solve in order to the scene recognition.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then object parts.",
                    "label": 0
                },
                {
                    "sent": "In this case, Imagenet finds a slightly more objects parts than places.",
                    "label": 0
                },
                {
                    "sent": "Again, it makes sense yes.",
                    "label": 0
                },
                {
                    "sent": "Listen to it is edges are object cards are using humans with yeah, so the question is how do we make this classification of the units into object parts simple elements and so on.",
                    "label": 0
                },
                {
                    "sent": "And this is one of the tasks that Amazon mechanical Work Turkers have to do, so they have to tell us what of those concepts is.",
                    "label": 0
                },
                {
                    "sent": "So object parts, so there are just the thing wheels and legs and you can see there are slightly more in image net and they pick in layer four.",
                    "label": 0
                },
                {
                    "sent": "Although pull five Layer 5 is mostly more or less the same.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then objects.",
                    "label": 0
                },
                {
                    "sent": "This ad units that got assigned to specific objects an here now image.",
                    "label": 0
                },
                {
                    "sent": "Net places finds more than Image Net which was kind of surprising to me.",
                    "label": 0
                },
                {
                    "sent": "Becausw image Net is trained to do object detection is trying to do object classification.",
                    "label": 0
                },
                {
                    "sent": "So it feels like it should be able to objects in the 1st place because otherwise how do you decide that the object is there but there are a lot fewer objects emerging.",
                    "label": 0
                },
                {
                    "sent": "However places had a lot more objects emerging inside.",
                    "label": 0
                },
                {
                    "sent": "Probably cause.",
                    "label": 0
                },
                {
                    "sent": "The output is already object classification task and internal representation that imagine it is trying to fill our object pieces, not object, not full objects that you know the output will take care of that.",
                    "label": 0
                },
                {
                    "sent": "So there are about in places that are about 25% of the units doing objects and this is out of 60% of the units that get classified as something.",
                    "label": 1
                },
                {
                    "sent": "So it's a very high percentage.",
                    "label": 0
                },
                {
                    "sent": "1/3 of the units are doing clearly.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can do the same thing with since an around 10% of the units are going scene classification in the last layer image net.",
                    "label": 0
                },
                {
                    "sent": "Don't find any, mostly none of them an this makes a lot of sense because there are no since there are very few scenes in Imagine.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what objects are found?",
                    "label": 0
                },
                {
                    "sent": "Well, if you look at.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Image net these are the units that appear inside image net, so you find things like Tor source of people.",
                    "label": 0
                },
                {
                    "sent": "This is our shape unit.",
                    "label": 0
                },
                {
                    "sent": "Imagine that there are lots of those.",
                    "label": 0
                },
                {
                    "sent": "This is detecting this round corners and this is not a simple classification task.",
                    "label": 0
                },
                {
                    "sent": "You can see that this round corners have many different colors and changes in appearance, so it's not a simple classification task, but it's not a high level concept, but it still is.",
                    "label": 0
                },
                {
                    "sent": "A is an interesting task that is solving internally animals, Flowers, dogs and more dogs.",
                    "label": 0
                },
                {
                    "sent": "There are many units doing dogs.",
                    "label": 0
                },
                {
                    "sent": "Highly specialized, then this is what you find.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In places that are faces and this is surprising 'cause there is no.",
                    "label": 0
                },
                {
                    "sent": "People category in the scene recognition task is all about offices, bathrooms, corridors, streets.",
                    "label": 0
                },
                {
                    "sent": "There are pool tables, lamps, screens and you can see it's detecting.",
                    "label": 0
                },
                {
                    "sent": "The screen is pretty well nice.",
                    "label": 0
                },
                {
                    "sent": "Segmenting them is not just an illusion nation trying to detect the squares is really detecting these screens baseball fields.",
                    "label": 0
                },
                {
                    "sent": "Mountains and is locating them so this is not something that by chance looks like it seems to be that is really detecting this object.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a bad detector that emerges inside the network.",
                    "label": 0
                },
                {
                    "sent": "There is 1 unit that is detecting bets and it does it quite well.",
                    "label": 0
                },
                {
                    "sent": "So these are many of the images.",
                    "label": 0
                },
                {
                    "sent": "The top images that this unit is reactive tool and this is auto 200 two 100,000 images.",
                    "label": 0
                },
                {
                    "sent": "It has both imagination places together so it could be responding to anything but it picks bets, bets and detects them quite well and even if you keep looking at more on lower rank images they are they are best so I mean it's pretty high.",
                    "label": 0
                },
                {
                    "sent": "It's quite high performance.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the one that lamps.",
                    "label": 0
                },
                {
                    "sent": "The square Mason is detecting this.",
                    "label": 0
                },
                {
                    "sent": "Alter lamps know this.",
                    "label": 0
                },
                {
                    "sent": "And if there are two, you will see two peaks of activation, so it's quite a nice quiet nice segment.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So here is the histogram of the objects that got that emerge inside the network.",
                    "label": 1
                },
                {
                    "sent": "So this is for image net.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So here we are, mixing anything.",
                    "label": 0
                },
                {
                    "sent": "We're mixing anything that has semantics, not just objects.",
                    "label": 0
                },
                {
                    "sent": "If there is something that actually surfaces, we also put it here.",
                    "label": 0
                },
                {
                    "sent": "So out of the 256 during simple 560, around 59 are detecting objects or something that has some semantic meaning.",
                    "label": 0
                },
                {
                    "sent": "And 15 of those are dogs, then births and then it goes flat quite fast.",
                    "label": 0
                },
                {
                    "sent": "Here are some of the examples of the units.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For places so there are around 150 units that are detecting something that is semantic, so this is more than half of the units.",
                    "label": 0
                },
                {
                    "sent": "Do some semantics an this is not by chance.",
                    "label": 0
                },
                {
                    "sent": "It's just doing like Sky region Skyroads screens is detecting things that you can put names to and the distribution of objects is a lot.",
                    "label": 0
                },
                {
                    "sent": "It doesn't drop as fast so again is a power law.",
                    "label": 0
                },
                {
                    "sent": "This is very typical so there are 15 June is detecting all kinds of buildings and then you have 3.",
                    "label": 0
                },
                {
                    "sent": "Raslor mountains, people, water and so on, and it drops quite fast.",
                    "label": 0
                },
                {
                    "sent": "There are a lot more large variety of objects that emerge, so these are some of the units.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's just a classification of the units that emerged.",
                    "label": 0
                },
                {
                    "sent": "This is not all of them, just some of them.",
                    "label": 0
                },
                {
                    "sent": "And there are buildings in their objects, furniture, outdoor objects, lighting that respond to specific types of lighting, nature, and so on.",
                    "label": 0
                },
                {
                    "sent": "These are objects that for some reason they are important, forcing classification.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An in fact, one thing that you can do is you can take this method and you can take also the method for visualizing what the units are doing that I described before by rendering an image that produces that confuses that creates an strong activation and you can render instead look look a lot like the object that we think is detecting.",
                    "label": 0
                },
                {
                    "sent": "Like this unit here is detecting this rocks in the water and when you do the rendering of what activates that unit you get this.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't look you know this totally different methods.",
                    "label": 0
                },
                {
                    "sent": "They arrived to the same conclusion, so it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not as just fooling ourselves thinking that the unit might be doing that like this one here is detecting roads and this is a rendering of what will activate that unit most.",
                    "label": 0
                },
                {
                    "sent": "And it looks like a like a Rd.",
                    "label": 0
                },
                {
                    "sent": "Here is an arc detecting unit and it will render arcs.",
                    "label": 0
                },
                {
                    "sent": "This is the pool, the pool table and it will draw a pool table.",
                    "label": 0
                },
                {
                    "sent": "This is like a mixture of the pool tables with all the orientation, so it's kind of round but.",
                    "label": 0
                },
                {
                    "sent": "You know it's.",
                    "label": 0
                },
                {
                    "sent": "Is it clearly Apple table?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so basically when you're turning these networks it feels like the first layers seem to be mostly task independent.",
                    "label": 1
                },
                {
                    "sent": "You take these two different tasks, like imaginative places more or less get the same filters you know the preferred images.",
                    "label": 0
                },
                {
                    "sent": "They look like they are almost identical, so they look very much like doing the same thing.",
                    "label": 0
                },
                {
                    "sent": "So this mostly seems like task independent.",
                    "label": 0
                },
                {
                    "sent": "Then you have your representation that might not be the thing that you're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "Like in the case of place recognition, is doing objects and then you have your final classification that is translating that representation into the task that you're going to solve.",
                    "label": 0
                },
                {
                    "sent": "And this representation in some cases might be even more interesting than the task that you want to solve, like here.",
                    "label": 0
                },
                {
                    "sent": "Now this representation is doing object segmentation and we were just trying to do some classification, which is a very simple task to do.",
                    "label": 0
                },
                {
                    "sent": "Easy to collect data for object segmentation is a lot harder to collect this data, so it's like we're solving an interesting task.",
                    "label": 0
                },
                {
                    "sent": "There is a lot more interesting than the task that we try to solve in the 1st place, so this black boxes they are not arriving to the classification solution in some mystical way.",
                    "label": 0
                },
                {
                    "sent": "They are actually creating a representation that seems really, really useful.",
                    "label": 0
                },
                {
                    "sent": "And they're doing it really, really well.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So whenever you have a new task, one of the strategies that people use all the time is, well, you take one of these networks.",
                    "label": 0
                },
                {
                    "sent": "You freeze all the parameters and you just train the last layers, and that seems to be a very reasonable thing to do because the first layers are going to be task independent mostly.",
                    "label": 1
                },
                {
                    "sent": "So it depends how many, how much computational power do you have, or how much training data do you have.",
                    "label": 0
                },
                {
                    "sent": "You can you can decide to train more or less layers, but the first layers it seems like you already have them.",
                    "label": 0
                },
                {
                    "sent": "You already have the train.",
                    "label": 0
                },
                {
                    "sent": "For whatever task you had in the 1st place, you know it's probably going to transfer pretty well.",
                    "label": 0
                },
                {
                    "sent": "So this is a very.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our task.",
                    "label": 0
                },
                {
                    "sent": "And so just freeze the first layers and train the upper layers with whatever new data set you have.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But what happens if you take the task?",
                    "label": 0
                },
                {
                    "sent": "You keep the same task, but you change the input modality, and this is something that people in computer vision are trying to look at, and this is an example from the Paris website.",
                    "label": 1
                },
                {
                    "sent": "They are doing a lot of work on Clip Art an the idea here is that.",
                    "label": 0
                },
                {
                    "sent": "If you just clip art for training, a computer vision system, you can generate a lot of data.",
                    "label": 0
                },
                {
                    "sent": "Without having privacy issues, because this is synthetic data, so you can do whatever you want, you can create examples that maybe will be really hard to collect because you can create scenes in which there will be just small differences in the data in how this Clipper is organized, but it will change the concept that you can generate samples that are very close to the classification boundary.",
                    "label": 0
                },
                {
                    "sent": "So there are all these things that you can do with clip art that might be really hard to do with real images, so they had a line of work in trying to do a systems that will learn from Clipper and then be applicable to the real world.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a work that we did with several people, and.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With risk with this here yes one question.",
                    "label": 0
                },
                {
                    "sent": "Being more independent, does it?",
                    "label": 0
                },
                {
                    "sent": "Related to the fact that the gradient gets smaller.",
                    "label": 0
                },
                {
                    "sent": "I don't think so.",
                    "label": 0
                },
                {
                    "sent": "I think it's really big cause this first layers they're trying to solve a sub task that is very common to many of the things that you're gonna solve, like edge detection and things like that.",
                    "label": 0
                },
                {
                    "sent": "Those are things that you will have to do for almost any visual task, but there could be other visual tasks that suddenly changed alot representation that you get in the first layer.",
                    "label": 0
                },
                {
                    "sent": "We just haven't found those, but there could be.",
                    "label": 0
                },
                {
                    "sent": "I don't think it has anything to do with the gradients.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "We wanted to create also training system data from other modalities like line drawing.",
                    "label": 0
                },
                {
                    "sent": "So you can you can put a interface in Mechanical Turk and ask people to create line drawings of all kinds of things.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the clip art from Davis and this is my best rendering.",
                    "label": 0
                },
                {
                    "sent": "This is Amy drawing drawing this and trying to reproduce the data.",
                    "label": 0
                },
                {
                    "sent": "This is actually the best I can draw.",
                    "label": 0
                },
                {
                    "sent": "But here now you can see that people are not even people that you would recognize with a genetic system.",
                    "label": 0
                },
                {
                    "sent": "Now is like an iconic representation of other person is.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know, we can crowd source this and get all kinds of line drawings for different scenes, so these are bedrooms.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now they look.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Denies some of them.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So much.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some people are ready.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Schematic.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can get all kinds of categories.",
                    "label": 0
                },
                {
                    "sent": "So we collected a lot of data like that.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Library.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also generate data from other ways.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can create images in which there are just words that tells you which objects should be there, like here.",
                    "label": 0
                },
                {
                    "sent": "Now this is a Rd is a highway in which you have roads, car, Sky and it's just the words.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can create all kinds of data like that by sampling from a segmented data set.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also create.",
                    "label": 0
                },
                {
                    "sent": "You can also take us input descriptions now you could have descriptions that tell you how how different things look like, so these are description of a bedroom is not associated to any picture of a bedroom.",
                    "label": 0
                },
                {
                    "sent": "It's just a description of a bedroom and you might want to learn from this.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a description of an auditorium.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of a classroom.",
                    "label": 0
                },
                {
                    "sent": "And it contains all the elements.",
                    "label": 0
                },
                {
                    "sent": "Measuring these to kind of more or less create a picture mental picture of what the classroom is.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a database with different modalities.",
                    "label": 0
                },
                {
                    "sent": "Each modality is classified according to different categories.",
                    "label": 0
                },
                {
                    "sent": "Each modality is not aligned with other modalities.",
                    "label": 0
                },
                {
                    "sent": "So for a particular description you don't have the corresponding picture that goes with it.",
                    "label": 0
                },
                {
                    "sent": "The only thing that you know about that description is that it's talking or the sensing category.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now you can take this network that is trained with places or with real images.",
                    "label": 0
                },
                {
                    "sent": "On the first layer were task independent.",
                    "label": 0
                },
                {
                    "sent": "The last layers are mostly task dependent, so these are the ones built in the representation.",
                    "label": 0
                },
                {
                    "sent": "So the first layers are going to be modality dependent because it will depend on what the modality they will change.",
                    "label": 0
                },
                {
                    "sent": "The type of filters that you want to use.",
                    "label": 0
                },
                {
                    "sent": "However, the large representation might be modality independent cause.",
                    "label": 0
                },
                {
                    "sent": "It doesn't rely so much on the pixel values that we had the input.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we propose is, let's remove the first layers instead of freezing up the first layers.",
                    "label": 0
                },
                {
                    "sent": "Let's freeze the last layers.",
                    "label": 0
                },
                {
                    "sent": "So you take the same classification task you have trained.",
                    "label": 0
                },
                {
                    "sent": "This network here is doing some sort of object detection, and now you plug here.",
                    "label": 0
                },
                {
                    "sent": "A new set up layers with Ramadan initialization and you train it with line drawings.",
                    "label": 0
                },
                {
                    "sent": "And you freeze the parameters of the last layer.",
                    "label": 0
                },
                {
                    "sent": "So how can this work?",
                    "label": 0
                },
                {
                    "sent": "OK, the only thing that this can do is somehow it has to align the output of this line drawings to create the same objects that the last layers are expecting.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it cannot work.",
                    "label": 0
                },
                {
                    "sent": "If this realize that here there is 1 unit that is detecting bets.",
                    "label": 0
                },
                {
                    "sent": "And it has got it all the things here so that that unit expects the only thing that we can do is transform itself here so that this unit keeps detecting bets even if they come from line drawings.",
                    "label": 0
                },
                {
                    "sent": "And you can do this with all the modalities.",
                    "label": 0
                },
                {
                    "sent": "You can plug a number of different modalities.",
                    "label": 0
                },
                {
                    "sent": "You can even insert descriptions.",
                    "label": 0
                },
                {
                    "sent": "So here these layers will have to have a different nature.",
                    "label": 0
                },
                {
                    "sent": "It will have to be like last names or something different that creates a particular representation and now you plug that representation into pull 5 and it will have to create some objects, otherwise it cannot work.",
                    "label": 0
                },
                {
                    "sent": "And indeed, when you do that is.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Works.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So when you train this system like that, you look at one particular unit.",
                    "label": 0
                },
                {
                    "sent": "Let's say that one, the one that was detecting bets and it takes bets on real images.",
                    "label": 0
                },
                {
                    "sent": "But it also detects bets on clip art.",
                    "label": 0
                },
                {
                    "sent": "Line drawings of bats.",
                    "label": 0
                },
                {
                    "sent": "It detects the word bad when you train with just words.",
                    "label": 0
                },
                {
                    "sent": "And it kind of reacts to some of the words in the descriptions that are aligned with Beth.",
                    "label": 0
                },
                {
                    "sent": "This is not perfect.",
                    "label": 0
                },
                {
                    "sent": "I think we are lacking data here, but this is quite surprising though, so it's aligning this water presentation with the object that is detected.",
                    "label": 0
                },
                {
                    "sent": "Is the only way I could make it work now I have to align these things.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so here is just another unit detecting.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sometimes an is detecting fan tension in all kind of modalities.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can do things like inverting so you can take one modality generator representation on the back, propagate through another representation, and you can go from line drawings to real images.",
                    "label": 0
                },
                {
                    "sent": "So this is just some of the some of the oil rendering techniques that are much better now, so probably this could work better, but you can see that this transforming this line drawings into images that kind of looks.",
                    "label": 0
                },
                {
                    "sent": "It looks nice.",
                    "label": 0
                },
                {
                    "sent": "So this is all this is working because the internal representation that has been learned by the network it actually makes sense.",
                    "label": 0
                },
                {
                    "sent": "It's not just some crazy thing that the network needs to do in order to solve the task that is not interpretable, or like a black box.",
                    "label": 0
                },
                {
                    "sent": "So you can actually look inside the black box and it kind of makes sense.",
                    "label": 0
                },
                {
                    "sent": "What is do?",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this place across model learning.",
                    "label": 0
                },
                {
                    "sent": "There are lots of techniques.",
                    "label": 0
                },
                {
                    "sent": "It's actually something that in computer vision is very interesting nowadays, so combining text and images and here is 1 example of a work of a piece of work in which what they do is they want to train object detector by just using a description.",
                    "label": 0
                },
                {
                    "sent": "So I give you the definition of the object and you need to from that definition build the object classifier that will detect the object on images.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way it works basically.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He is.",
                    "label": 0
                },
                {
                    "sent": "It has to pass.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One path that is going to take the image and it's going to generate some features and another path that is going to take a Wikipedia article or of an object definition is going to do some representation in this case, like a bag of words is going to is going to go through multilayer perception and create.",
                    "label": 0
                },
                {
                    "sent": "A function.",
                    "label": 0
                },
                {
                    "sent": "That is going to output the classifier parameters so that now you take that that those classifier parameters apply it to the features extracted from a picture and it will tell you if that's or not the object you are looking for and the way you train this is by starting with a database in which you have lots of definitions and images that are pair.",
                    "label": 0
                },
                {
                    "sent": "So that's the way you train it.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is an example of definition of a cormorant, and these are the images that the detector found.",
                    "label": 0
                },
                {
                    "sent": "So it works.",
                    "label": 0
                },
                {
                    "sent": "It's not perfect.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of work to do, so even though we show like Rob has been showing amazing results is not like the problem is solved.",
                    "label": 0
                },
                {
                    "sent": "There are lots of mistakes, it's just that it works a lot better than it was working before.",
                    "label": 0
                },
                {
                    "sent": "But there is still a lot of room for improvement, but now you can be ambitious international.",
                    "label": 0
                },
                {
                    "sent": "You can try to solve much harder task than before.",
                    "label": 0
                },
                {
                    "sent": "So here is, these are the images.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can actually apply rubs technique doing backpropagation to seek what is that is activating that particular unit and you can see that you get to localize the birth in this particular case.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this is very computer vision.",
                    "label": 0
                },
                {
                    "sent": "There are lots of different ways of training systems.",
                    "label": 0
                },
                {
                    "sent": "One is pixel labeling and Rob has been showing a few examples in which you try to do scene segmentation.",
                    "label": 0
                },
                {
                    "sent": "And for that you just wrong supervision.",
                    "label": 0
                },
                {
                    "sent": "And when you have a database with images on each pixel gets a label and that's given you is given to you as training data.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which supervision is more or less what I've been describing when you train with image net, you only have one word assigned to a picture, so you don't get to know where the object is in the picture that the network will have to figure it out an.",
                    "label": 0
                },
                {
                    "sent": "I've shown that even when you train with a task that is different from object detection, you might still get object detectors and they get to learn to segmented objects.",
                    "label": 0
                },
                {
                    "sent": "So this is just a quick supervision.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But cross model learning is something that is very important nowadays in computer vision.",
                    "label": 0
                },
                {
                    "sent": "So here is an example of an example from Coco in which you have a picture and you have a description and that is like a caption with natural language, freeform style that describes what the content of the picture is and you need to learn to describe that.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So another way is using questions and answers.",
                    "label": 0
                },
                {
                    "sent": "So here in this particular case, the way that you train the system is you have a database of images and questions about that picture and the answers that go with it.",
                    "label": 0
                },
                {
                    "sent": "So you train a system that, given a question on a picture, it will give you the answer.",
                    "label": 0
                },
                {
                    "sent": "And that's really an interesting way of training cause first it only uses natural language.",
                    "label": 0
                },
                {
                    "sent": "There is no, you don't need to agree on the vocabulary that you will use to label your objects, and you can.",
                    "label": 0
                },
                {
                    "sent": "You can ask all sorts of questions and the system will have in order to answer those questions they will have to learn to detect the objects and all kinds of things.",
                    "label": 0
                },
                {
                    "sent": "And it's amazing the progress that has been made in in this field.",
                    "label": 0
                },
                {
                    "sent": "So here is a link.",
                    "label": 0
                },
                {
                    "sent": "If you go there you can play with a demo that this is worth from this product group and it was really well.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "But that's very different from the way that kids learn.",
                    "label": 0
                },
                {
                    "sent": "Of course, kids ask a lot of questions, but before they can speak, they already know how to see.",
                    "label": 0
                },
                {
                    "sent": "So they are actually interacting with the world in a very different way.",
                    "label": 0
                },
                {
                    "sent": "And now is when I have a lot of videos, so let's cross all the fingers.",
                    "label": 0
                },
                {
                    "sent": "And I have audio, so the probability of this computer crashing is extremely high.",
                    "label": 0
                },
                {
                    "sent": "So the way that the kid learns is very different.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the kid will learn that the world is made out of different materials and the way that it has to do that is by playing with the world it will style.",
                    "label": 0
                },
                {
                    "sent": "It will stop touching it, hearing the noises that it makes, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here is a. Yeah, it works.",
                    "label": 0
                },
                {
                    "sent": "This is a travel songs kit.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "So you put things in your mouth, juice all the modalities that you have.",
                    "label": 0
                },
                {
                    "sent": "To learn about the world, we have nothing like this.",
                    "label": 0
                },
                {
                    "sent": "We don't have any data set that looks like this.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just by hitting the actually sound is already a really powerful cue to learn about the world.",
                    "label": 0
                },
                {
                    "sent": "So just by hearing, you can tell many things about how the world is made of.",
                    "label": 0
                },
                {
                    "sent": "So here I'm sure you just very blurry video.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, it's just audio.",
                    "label": 0
                },
                {
                    "sent": "So this is a steal in Andrew Owens playing with drumstick on a particular scene and you can get a good sense of the type of material.",
                    "label": 0
                },
                {
                    "sent": "Now you can hear that there are some things that are hard, some things that look like sound, like plants.",
                    "label": 0
                },
                {
                    "sent": "Some things are rough.",
                    "label": 0
                },
                {
                    "sent": "So you get more or less a classifica.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know this is the original scene.",
                    "label": 0
                },
                {
                    "sent": "And this was the.",
                    "label": 0
                },
                {
                    "sent": "Excuse me yes.",
                    "label": 0
                },
                {
                    "sent": "So you get that you get a sense of what are the different materials that are making.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is work.",
                    "label": 0
                },
                {
                    "sent": "Bill Freeman and Andrew Owens is the main driving force behind all this, so he's the one making all the noises that you will hear.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing that he did was to collect database of physical interactions.",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to get a little bit of this type of data that is more cross model now.",
                    "label": 0
                },
                {
                    "sent": "So he created the greatest hits data set in which he goes with this drumstick and starts hitting absolutely everything that he sees.",
                    "label": 0
                },
                {
                    "sent": "She created about 1000 videos, 30 seconds long each.",
                    "label": 0
                },
                {
                    "sent": "Annual heats scratches.",
                    "label": 0
                },
                {
                    "sent": "He does all kinds of things.",
                    "label": 0
                },
                {
                    "sent": "And there are all types of materials.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is just a collection of the greatest hits.",
                    "label": 0
                },
                {
                    "sent": "You can hit basically everything.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a really fun project for him.",
                    "label": 0
                },
                {
                    "sent": "Another question is, can you predict?",
                    "label": 0
                },
                {
                    "sent": "Can you learn material properties from sound?",
                    "label": 0
                },
                {
                    "sent": "And here is a little bit coming back to this internal representation.",
                    "label": 0
                },
                {
                    "sent": "What is the internal representation that the network will have to build in order to solve the task of associating images and audio?",
                    "label": 0
                },
                {
                    "sent": "So here you have a task for which is very easy to collect data and hopefully the internal representation is very meaningful.",
                    "label": 0
                },
                {
                    "sent": "So that's what we're going.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look here so you get a video.",
                    "label": 0
                },
                {
                    "sent": "And our goal is to predict sound features and here in order to encode sound instead of learning the features which we are trying to do here, we decided to 1st.",
                    "label": 0
                },
                {
                    "sent": "You know there is a deadline arriving.",
                    "label": 0
                },
                {
                    "sent": "You know there is not much time and at the end you just use all the hacks that are in the box that allows you to arrive to the deadline.",
                    "label": 0
                },
                {
                    "sent": "So one of them is to do some well established sound features that will encode the audio signal and hear what we are using.",
                    "label": 0
                },
                {
                    "sent": "Is the cochlea gram?",
                    "label": 0
                },
                {
                    "sent": "This is a you take the audio signal you pass it through a filter Bank of 40 different filters is tuned to a different frequency.",
                    "label": 0
                },
                {
                    "sent": "And then you take that output so it's going to get some is going to be some sound wave for the output of each filter.",
                    "label": 0
                },
                {
                    "sent": "You compute the envelope that filter output and you sample it.",
                    "label": 0
                },
                {
                    "sent": "3 samples per second.",
                    "label": 0
                },
                {
                    "sent": "And you do this for all the 40 bands and it doesn't will give you a long vector and then apply some compressive nonlinearity, which is, you know is what people do in all the analysis and that will be your audio vector.",
                    "label": 0
                },
                {
                    "sent": "One thing that is nice is that you can take that vector and you can invert it and generate a sound more or less than it sounds real, so we know it's a relatively good representation.",
                    "label": 0
                },
                {
                    "sent": "It might not be the best.",
                    "label": 0
                },
                {
                    "sent": "The best thing would be to learn it, and that's something we're doing, but it's already doing something relatively well.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing is that you can actually look at the mean sounds per category and they all look different, so this is a cloth, rock grass.",
                    "label": 0
                },
                {
                    "sent": "This representation where they show is the recent relaxes time.",
                    "label": 0
                },
                {
                    "sent": "The vertical axis is frequency.",
                    "label": 0
                },
                {
                    "sent": "An dark.",
                    "label": 0
                },
                {
                    "sent": "In this case it means a strong a lot of energy.",
                    "label": 0
                },
                {
                    "sent": "So here in cloth is something that is sounds like low frequency sound.",
                    "label": 0
                },
                {
                    "sent": "An rock is high frequency sound.",
                    "label": 0
                },
                {
                    "sent": "A grass you know very flat spectrum.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now what we want to do is, given the video we want to train the video so that it's able to.",
                    "label": 0
                },
                {
                    "sent": "Generate sound.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and for that we just just.",
                    "label": 0
                },
                {
                    "sent": "The standard tricks then apply a convolutional neural network to each frame.",
                    "label": 0
                },
                {
                    "sent": "You get an output and then the output gets into a recursive neural network, which I think you will see tomorrow an that will give the state vector and at a state vector we are going to use it to predict the this audio features.",
                    "label": 0
                },
                {
                    "sent": "OK, their regression loss here is just equally and some robust norm to predict the audio sounds so something relatively simple.",
                    "label": 0
                },
                {
                    "sent": "Nothing, nothing bad.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nancy Ann, once you train that you can test it and it kind of works and we can do to know if it's actually working.",
                    "label": 0
                },
                {
                    "sent": "We can do a real or fake studies.",
                    "label": 0
                },
                {
                    "sent": "Now we can take an image video.",
                    "label": 0
                },
                {
                    "sent": "We can take the real sound, the sound we predict is going to make and show it to a human and ask if it's real or fake.",
                    "label": 0
                },
                {
                    "sent": "So here is an example.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Guess which one is real or fake?",
                    "label": 0
                },
                {
                    "sent": "OK, so this one was fake and this is real OK.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can do the same thing for many different videos and what we get is that.",
                    "label": 0
                },
                {
                    "sent": "So if the model was perfect, you will get 50%.",
                    "label": 0
                },
                {
                    "sent": "Now people will be a chance and select which one is the real or fake.",
                    "label": 0
                },
                {
                    "sent": "It looks even better because in some cases actually hard for a human to tell what the audio is, not because you could be hitting something that is included and that will confuse the human, but the system will generate the sound that look visually looks like the right thing and humans could get confused.",
                    "label": 0
                },
                {
                    "sent": "So in principle it could be.",
                    "label": 0
                },
                {
                    "sent": "It could be possible to get above 50% here, but we're at 40% and it just take a random sound.",
                    "label": 0
                },
                {
                    "sent": "Then you are around 20%, so it's not a super hard task, but we are clearly better than chance here.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is an example of adding soundtracks to silent videos.",
                    "label": 0
                },
                {
                    "sent": "So all this is fake.",
                    "label": 0
                },
                {
                    "sent": "So more or less it tells.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it doesn't see that.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, here's what I'm going to show now is what video contain the sound that the system is using to generate that fake sound?",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "It goes really fast.",
                    "label": 0
                },
                {
                    "sent": "Well, it.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Crash here, so one thing that is that is important is that here the way that we generated sounds was instead of doing inversion of the representation, we just took a video.",
                    "label": 0
                },
                {
                    "sent": "That analogy clip that contain more or less the same features, not the one that was the closest and use that to synthesize, so it's more or less like a Patch based technique for rendering.",
                    "label": 0
                },
                {
                    "sent": "You could do the inversion, but we found that it didn't sound so well right now, so it's like it's missing high frequencies.",
                    "label": 0
                },
                {
                    "sent": "This method produce realistic sounds because they are real.",
                    "label": 0
                },
                {
                    "sent": "But they but the number has to pick them from the right place, so that's what this transfer audio clips is showing is the place where the network is picking up the sound.",
                    "label": 0
                },
                {
                    "sent": "The sound to generate that fake sound.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So another example.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is another let me show.",
                    "label": 0
                },
                {
                    "sent": "Starting to get we are computer.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Is more is more of the same, so it's not very important, but now it will crash.",
                    "label": 0
                },
                {
                    "sent": "Now I can feel it, I can feel it.",
                    "label": 0
                },
                {
                    "sent": "This is getting hard that the computer.",
                    "label": 0
                },
                {
                    "sent": "I think it crashed.",
                    "label": 0
                },
                {
                    "sent": "I think it crashed.",
                    "label": 0
                },
                {
                    "sent": "Well, so you know, for the I just have four more slides an it's not.",
                    "label": 0
                },
                {
                    "sent": "I don't need the PowerPoint support to tell you what I'm going to say so.",
                    "label": 0
                },
                {
                    "sent": "But no, no, it doesn't react.",
                    "label": 0
                },
                {
                    "sent": "Well, the capitals yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so basically what we are doing now with this is we train this network to predict not just the sounds that you generate when you hit things, but we actually took just movies from Flickr that contain ambient sounds, just natural sounds and we train the network to predict given the input video, the natural sounds that you hear.",
                    "label": 0
                },
                {
                    "sent": "So you're going to hear cars you are going to hear the wind water an for this prediction to work.",
                    "label": 0
                },
                {
                    "sent": "The network has to be able to represent the objects that are making all these sounds.",
                    "label": 0
                },
                {
                    "sent": "So that seems to be the natural representation to do, and when you do that and you look inside the network in the last layer, the last convolutional layer you look at the things that this journeys are doing.",
                    "label": 0
                },
                {
                    "sent": "You find objects.",
                    "label": 0
                },
                {
                    "sent": "You find that the network learns to take babies because there are a lot of baby crying videos in Flickr.",
                    "label": 0
                },
                {
                    "sent": "So there are lots of journeys detecting babies for this data set.",
                    "label": 0
                },
                {
                    "sent": "Our babies are like the docs for image net.",
                    "label": 0
                },
                {
                    "sent": "And there are a lot of waterfalls.",
                    "label": 0
                },
                {
                    "sent": "There are cars there are.",
                    "label": 0
                },
                {
                    "sent": "There are all kinds of different objects emerging from this.",
                    "label": 0
                },
                {
                    "sent": "Even objects that don't make sounds.",
                    "label": 0
                },
                {
                    "sent": "There are some objects that don't make sounds but are contextually related to other objects that will make sounds and those are detected two and they are not mixed with the objects that make the sound.",
                    "label": 0
                },
                {
                    "sent": "So you have this interesting properties emerging inside the network and strain with a task that require no.",
                    "label": 0
                },
                {
                    "sent": "No supervision in the sense that there is no human telling what the network, you know what the labels should be, is just predicting one modality to another modality.",
                    "label": 0
                },
                {
                    "sent": "And because these two modalities are so different that representation has to be something about the objects that make those sounds.",
                    "label": 0
                },
                {
                    "sent": "So I'll stop here.",
                    "label": 0
                },
                {
                    "sent": "If there are any questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}