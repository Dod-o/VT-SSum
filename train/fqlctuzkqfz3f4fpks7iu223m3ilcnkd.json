{
    "id": "fqlctuzkqfz3f4fpks7iu223m3ilcnkd",
    "title": "Tom-vs-Pete Classifiers and Identity-Preserving Alignment for Face Verification",
    "info": {
        "author": [
            "Thomas Berg, Columbia University"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_berg_face_verification/",
    "segmentation": [
        [
            "This is work done with Peter Bellamar at Columbia University, Tom Versus Pete Classifiers and identity preserving alignment for phase verification.",
            "So one way of looking at the problem of face verification is we're just."
        ],
        [
            "To answer this question of how do we tell people apart?",
            "And one."
        ],
        [
            "One answer to that question is with attributes.",
            "There's been a lot of work with attributes in faces and in other realms.",
            "But if you think about faces, what what attributes are?",
            "Is there sort of semantic features?",
            "And you can build classifiers to detect things, things like gender.",
            "If you're looking at faces right?",
            "So you can separate male and female faces.",
            "You can separate people by their hair color.",
            "You can build a classifier that will detect whether someone has a beard or not, and if you have a large set of these classifiers, you can describe anyone sort of as a vector of their attributes, and you can use that to actually identify them.",
            "Which was done in this work at ICC in 2009?",
            "But there are some limits."
        ],
        [
            "Asians of this approach?",
            "The first of which is that it's just.",
            "It's difficult to come up with all these attributes, right?",
            "You start the first ones are easy gender, race, age, eye color, but your imagination starts to run dry.",
            "If you want like 500 attributes.",
            "And when you do come up with them every time you come up with a new attribute, you have to collect a new set of training data in order to build the classifier.",
            "You may use the same faces, but you need to re label them with the new attribute values, which is expensive.",
            "And also it can be difficult to get labelers to agree if you have a long hair attribute, how long is long?",
            "And a third limitation here is if you limit yourself to these nameable attributes, you're not going to find what may be sort of other discriminative features that are harder to put a name to.",
            "So in this work we try to deal with these issues, we find a very large number of these discriminative features based only on identity labels.",
            "We don't need sort of many different sets of labels.",
            "So the question sort of the intuition behind the approach is."
        ],
        [
            "You look at just two phases and say how can we tell these two people apart?",
            "That's often much easier.",
            "This is Orlando Bloom and Lucille Ball if."
        ],
        [
            "Collect a bunch of images of these two people, you notice all Lucille Ball has red hair in every image of her, so if you can build a classifier that responds to red hair, that will work as an Orlando versus Lucy classifier.",
            "And."
        ],
        [
            "If you look at a different pair of people, Stephen Fry and Brad Pitt.",
            "Stephen Fry broke his nose as a kid."
        ],
        [
            "So if you can build a classifier that can respond to a crooked nose, that'll work great as a Steve versus Brad classifier.",
            "Here's one."
        ],
        [
            "Or Tom Cruise and Pete Sampras.",
            "You do the same procedure."
        ],
        [
            "Select a bunch of images of each of them, extract some features, sift or.",
            "Whatever you want.",
            "Gabor features.",
            "Train up a classifier.",
            "In almost every case, whatever two people you pick, you'll be able to do a pretty good job of that.",
            "It's not a very difficult task, and you may not have a nice name like red hair or crooked nose for your classifier, but it'll separate those two people pretty well.",
            "And so, in this work we've created a whole bunch of these classifiers, an sort of as a generic term.",
            "We call them Tom versus P classifiers, just to emphasize the idea that it's trained on just two people.",
            "And."
        ],
        [
            "Our hypothesis about these classifiers is that they'll generalize that you can train on Tom versus Pete, but then you can run it on Jack or Jill and it will tell you something about them.",
            "So to show that, here's an example.",
            "We went online and we collected about 200 images, each of Scarlett Johansson and Wrinkle Kikuchi.",
            "An we trained up a classifier, and if you run it on those images of Scarlett Johansson, wrinkle Kikuchi.",
            "You know it.",
            "It separates them perfectly well.",
            "It's the training data, so of course it does, but that's the distribution there, separated very well.",
            "But then go online again and collect 200 images of Ali Landry Anne.",
            "This is the run that Scarlet versus wrinkle classifier on those and you get a score distribution like that.",
            "Collect 200 images of Betty White and do the same thing.",
            "Same thing for George Takei and what you can see is that you certainly don't get the perfect separation that you did with the original pair of people.",
            "But there's definitely some information here, right?",
            "There's some discriminative power if you know it was one of these three people.",
            "You could run this classifier and you'd have a reasonable guess of who it was.",
            "And if you have thousands of these classifiers, then putting them together you can do a very good job of discriminating people.",
            "So that's what we've done.",
            "We've built a lot of these classifiers, and the way we do it is."
        ],
        [
            "Left the data set.",
            "We have about 20,000 images of 120 different people on average.",
            "That's about 170 images each.",
            "And from each of those images, we've defined 11 different regions on the face in terms of where certain face features are on the eyebrows, the forehead just up there, and from each of them we extract a few SIFT descriptors.",
            "Each little square here represents one sift descriptor.",
            "The size indicates the scale.",
            "And so from that data we can build 120 choose two possible pairs of people.",
            "For each pair, we can have 11 different features and do the math.",
            "We can train about 80,000 of these Tom versus peak classifiers.",
            "And."
        ],
        [
            "Right, so the problem we're trying to approach here, though face verification, is how to tell any pair of people apart.",
            "So the.",
            "The details of the problem are like this.",
            "You get two faces which are not in that reference, that it's not among these 120 people, and the question we want to answer is, are these the same person or are they different?",
            "So what we do is we take a bunch of these Tom versus P classifiers.",
            "We run them on each of the images.",
            "In practice we use 5000 of the classifiers and so that gives you a 5000 dimensional descriptor of each image.",
            "We combine those.",
            "We take the absolute difference and the Elementwise product to get a vector that describes the pair.",
            "And then we have a second stage classifier which can terminate same pairs from different pairs.",
            "So that's sort of the overview of the whole system.",
            "What I want to talk about next is a little more detail on how we build these classifiers really, and in particular on how we align the faces to start with.",
            "We have to think about alignment because we're using these."
        ],
        [
            "Different regions of the face and so.",
            "Each classifier can only see a very small part of the face, right?",
            "If you look at the far left region where we're training classifiers and the only part of the face I see is these tiny little squares on the eyebrows, right?",
            "The reason we do that is you get more of a variety of classifiers, right?",
            "If you force a classifier to make this decision just based on the eyebrows, you learn something about the eyebrows.",
            "Another classifier learns about the mouth, so you get more variety.",
            "We also think it generalizes better when we apply it to other people because.",
            "This sort of third person who comes in they might have a nose that's similar to a nose that's in one of your reference people.",
            "That's more likely than sort of their whole face being similar.",
            "But the problem with this is that you really need good alignment because if your classifier is looking at features on the eyebrows, if you accidentally, you know you're not taking your features from the eyebrows, but from up on the forehead, then it's not going to work.",
            "And so since we are, our classifiers are defined this way in terms of the parts of the face.",
            "We also base our alignment on doing fiducial detection, detecting the parts of the face.",
            "And in particular, we're using this face part detection."
        ],
        [
            "From volume at all in CPR last year.",
            "I I won't talk about how that works, that's a separate paper, but it does quite good on these sort of unconstrained non laboratory images and there are some just some examples.",
            "So once we have all of these."
        ],
        [
            "Points one way to do alignment.",
            "Our method of alignment is a modification of this piecewise affine warp.",
            "So just to describe how the piecewise affine warp works, you get some faces in that you want to align.",
            "You detect all these parts.",
            "We have a set of 95 different parts for detecting, and then you use those parts to build a triangulation on the face.",
            "And we also have what we call the Canonical part locations, and that's just where the parts fall on an average frontal face with a neutral expression.",
            "And once we have that.",
            "All we do is find the affine transformation for each triangle from the sort of detected triangle to the Canonical triangle.",
            "We work each triangle separately.",
            "And there is the result.",
            "There is the original and the result together.",
            "It works pretty well, it corrects pose and expression fairly well.",
            "We've closed Obama's mouth, they look a little bit more frontal than they do in the originals.",
            "The problem is, in a way it's too good.",
            "If you think about each of these.",
            "Triangles you find the affine transformation it's there are six constraints, because there are three vertices, you get a perfect solution, and so we're mapping every point to exactly the same location.",
            "Everyone's eyebrows go to exactly the same place, and what that means is whether you have thick lips or thin lips.",
            "After alignment, you have sort of average thickness lips, and that means you're losing important identity, important information that can tell you about identity.",
            "So we've developed this alignment technique we call identity preserving alignment, and it's similar to the piecewise affine work.",
            "We start by detecting the parts."
        ],
        [
            "Then we.",
            "This is the different part.",
            "We estimate what we call the generic parts and what that what we mean by that is if you had an average person an average face with the same poles in the expression that are in this query image, where would the parts be?",
            "And I'll talk about this in a moment about how we find that.",
            "But once we have that, we follow the same procedure we do the triangulation, we mapped to the Canonical locations of the parts.",
            "And and that's how we get the alignment.",
            "So there are two things I want to tell you about this.",
            "First is why does getting these generic parts preserve identity, and the 2nd is how do you actually get the generic parts?",
            "It's a little hard to see the generic parts in real."
        ],
        [
            "Human faces, 'cause they're quite close to the detected parts.",
            "But if we look at these robot faces, it's easier to see.",
            "So here's two robots.",
            "One has thin eyebrows when his thick eyebrows one has a narrow nose in a wide nose.",
            "That's sort of identity information.",
            "Also, one has his mouth open.",
            "We think of that is expression, right?",
            "That's what we'd like to correct for.",
            "And if you just do the piecewise affine warp, that's the PAW.",
            "Here you detect the parts you have these Canonical locations, which are an average robot with his mouth closed, and if you just warp the detected parts to the Canonical parts.",
            "You're just warping the whole face to the average face, right?",
            "And you get these two faces that are identical.",
            "You've lost all the identity information.",
            "On the other hand."
        ],
        [
            "If you use the generic parts, you detect the parts, but you only use those to estimate the location of the generic parts.",
            "Here you can see the generic parts.",
            "They're pretty much the same, right?",
            "They have average thickness eyebrows, average with knows.",
            "The only difference is one has the mouth open and one has it closed, and.",
            "And the procedure there are the Canonical parts is to to warp the generic parts to the Canonical parts.",
            "Mostly the generic parts in the Canonical parts are the same because there's not a lot of expression here.",
            "But with the robot with his open mouth, the generic parts are going to move down to close that mouth, and that pulls the lines in black.",
            "The actual mouth that pulls that closed as well.",
            "And what you end up with is this, right?",
            "You have an image where we've preserved the differences in geometry, the eyebrows, the nose.",
            "But we've succeeded in closing the mouth."
        ],
        [
            "That's the idea.",
            "Here it is in real images.",
            "As I said, it's a little bit subtle, but most people agree with us when we say that the image on the far right.",
            "Which is the identity preserving alignment, looks more like that person than the image in the center, right?",
            "So if you're familiar enough with that faces, I hope you'll agree with that.",
            "The top ones.",
            "Ben Stiller, the one on the right, really looks like him.",
            "The one in the middle.",
            "He's kind of lost the squareness of his face, or it's a little bit wider instead of narrower.",
            "That's I hope you can see that.",
            "So the last thing is, how do you actually estimate?"
        ],
        [
            "Those parts we do that with our data set again, I told you about the images before we augment it.",
            "We have these 95 part locations for every image in there.",
            "We've separated the parts into these column inner parts in outer parts.",
            "The blue parts here are things that you can detect automatically using our algorithm.",
            "The pink parts here.",
            "They sort of describe the overall shape of the face.",
            "They're harder to detect.",
            "There's kind of not as well defined, and we.",
            "They help our algorithm, so we use them, but the way we use them you'll see is a little different.",
            "So the actual procedure for estimating those parts 1st we just run."
        ],
        [
            "Detector to get the inner parts.",
            "And then we look to our data set an for each of the 120 people.",
            "Find the face where the inner parts are as close as possible to the parts on the query image.",
            "And what that gives you is 120 different people with roughly the same pose and expression as the query image, right?",
            "And that's that's the idea behind generic parts.",
            "We take the average of those 120 sets of points using the inner points and the outer points, right?",
            "And that is an average face with the same pose and expression as the query image, and that's what the generic parts are."
        ],
        [
            "So that's the whole story.",
            "This system, again, you take the images in, we do the alignment, we run the Tom versus P classifiers to get a vector for each image.",
            "And combine them into the second stage classifier.",
            "We've tested this."
        ],
        [
            "On the label faces in the wild data set, it's a standard data set for face verification.",
            "We like it because it's images collected from the Internet.",
            "It's not laboratory images.",
            "It consists of 6000 pairs of faces.",
            "Half of them are the same person.",
            "Half of them are two different people, and justice for each pair you have to say whether it's same or different.",
            "Previous best results.",
            "The status.",
            "It's been around for."
        ],
        [
            "Four or five years.",
            "There's been a lot of work on it.",
            "The top three published results are these top scores from CPR last year, 90.57%.",
            "Our method gives us 93.1 which is a 27% reduction in the error rate.",
            "If you look at the RC curve, you can see there's a significant gap from the previous batch."
        ],
        [
            "Result.",
            "And in particular, I'm sort of in security situations, which is where a lot of people are thinking of face verification.",
            "What you're concerned with is the far left side of the graph, right where you really don't want to let the wrong person into the building, and you can see that better if you put the X axis on a log."
        ],
        [
            "And you can see in particular we have a good separation on that side."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is work done with Peter Bellamar at Columbia University, Tom Versus Pete Classifiers and identity preserving alignment for phase verification.",
                    "label": 0
                },
                {
                    "sent": "So one way of looking at the problem of face verification is we're just.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To answer this question of how do we tell people apart?",
                    "label": 0
                },
                {
                    "sent": "And one.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One answer to that question is with attributes.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of work with attributes in faces and in other realms.",
                    "label": 0
                },
                {
                    "sent": "But if you think about faces, what what attributes are?",
                    "label": 0
                },
                {
                    "sent": "Is there sort of semantic features?",
                    "label": 0
                },
                {
                    "sent": "And you can build classifiers to detect things, things like gender.",
                    "label": 0
                },
                {
                    "sent": "If you're looking at faces right?",
                    "label": 0
                },
                {
                    "sent": "So you can separate male and female faces.",
                    "label": 0
                },
                {
                    "sent": "You can separate people by their hair color.",
                    "label": 0
                },
                {
                    "sent": "You can build a classifier that will detect whether someone has a beard or not, and if you have a large set of these classifiers, you can describe anyone sort of as a vector of their attributes, and you can use that to actually identify them.",
                    "label": 0
                },
                {
                    "sent": "Which was done in this work at ICC in 2009?",
                    "label": 0
                },
                {
                    "sent": "But there are some limits.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asians of this approach?",
                    "label": 0
                },
                {
                    "sent": "The first of which is that it's just.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to come up with all these attributes, right?",
                    "label": 0
                },
                {
                    "sent": "You start the first ones are easy gender, race, age, eye color, but your imagination starts to run dry.",
                    "label": 0
                },
                {
                    "sent": "If you want like 500 attributes.",
                    "label": 0
                },
                {
                    "sent": "And when you do come up with them every time you come up with a new attribute, you have to collect a new set of training data in order to build the classifier.",
                    "label": 0
                },
                {
                    "sent": "You may use the same faces, but you need to re label them with the new attribute values, which is expensive.",
                    "label": 0
                },
                {
                    "sent": "And also it can be difficult to get labelers to agree if you have a long hair attribute, how long is long?",
                    "label": 0
                },
                {
                    "sent": "And a third limitation here is if you limit yourself to these nameable attributes, you're not going to find what may be sort of other discriminative features that are harder to put a name to.",
                    "label": 0
                },
                {
                    "sent": "So in this work we try to deal with these issues, we find a very large number of these discriminative features based only on identity labels.",
                    "label": 1
                },
                {
                    "sent": "We don't need sort of many different sets of labels.",
                    "label": 0
                },
                {
                    "sent": "So the question sort of the intuition behind the approach is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You look at just two phases and say how can we tell these two people apart?",
                    "label": 1
                },
                {
                    "sent": "That's often much easier.",
                    "label": 0
                },
                {
                    "sent": "This is Orlando Bloom and Lucille Ball if.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Collect a bunch of images of these two people, you notice all Lucille Ball has red hair in every image of her, so if you can build a classifier that responds to red hair, that will work as an Orlando versus Lucy classifier.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at a different pair of people, Stephen Fry and Brad Pitt.",
                    "label": 0
                },
                {
                    "sent": "Stephen Fry broke his nose as a kid.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you can build a classifier that can respond to a crooked nose, that'll work great as a Steve versus Brad classifier.",
                    "label": 0
                },
                {
                    "sent": "Here's one.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or Tom Cruise and Pete Sampras.",
                    "label": 0
                },
                {
                    "sent": "You do the same procedure.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Select a bunch of images of each of them, extract some features, sift or.",
                    "label": 0
                },
                {
                    "sent": "Whatever you want.",
                    "label": 0
                },
                {
                    "sent": "Gabor features.",
                    "label": 0
                },
                {
                    "sent": "Train up a classifier.",
                    "label": 0
                },
                {
                    "sent": "In almost every case, whatever two people you pick, you'll be able to do a pretty good job of that.",
                    "label": 0
                },
                {
                    "sent": "It's not a very difficult task, and you may not have a nice name like red hair or crooked nose for your classifier, but it'll separate those two people pretty well.",
                    "label": 0
                },
                {
                    "sent": "And so, in this work we've created a whole bunch of these classifiers, an sort of as a generic term.",
                    "label": 0
                },
                {
                    "sent": "We call them Tom versus P classifiers, just to emphasize the idea that it's trained on just two people.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our hypothesis about these classifiers is that they'll generalize that you can train on Tom versus Pete, but then you can run it on Jack or Jill and it will tell you something about them.",
                    "label": 0
                },
                {
                    "sent": "So to show that, here's an example.",
                    "label": 0
                },
                {
                    "sent": "We went online and we collected about 200 images, each of Scarlett Johansson and Wrinkle Kikuchi.",
                    "label": 0
                },
                {
                    "sent": "An we trained up a classifier, and if you run it on those images of Scarlett Johansson, wrinkle Kikuchi.",
                    "label": 0
                },
                {
                    "sent": "You know it.",
                    "label": 0
                },
                {
                    "sent": "It separates them perfectly well.",
                    "label": 0
                },
                {
                    "sent": "It's the training data, so of course it does, but that's the distribution there, separated very well.",
                    "label": 0
                },
                {
                    "sent": "But then go online again and collect 200 images of Ali Landry Anne.",
                    "label": 0
                },
                {
                    "sent": "This is the run that Scarlet versus wrinkle classifier on those and you get a score distribution like that.",
                    "label": 0
                },
                {
                    "sent": "Collect 200 images of Betty White and do the same thing.",
                    "label": 0
                },
                {
                    "sent": "Same thing for George Takei and what you can see is that you certainly don't get the perfect separation that you did with the original pair of people.",
                    "label": 0
                },
                {
                    "sent": "But there's definitely some information here, right?",
                    "label": 0
                },
                {
                    "sent": "There's some discriminative power if you know it was one of these three people.",
                    "label": 0
                },
                {
                    "sent": "You could run this classifier and you'd have a reasonable guess of who it was.",
                    "label": 0
                },
                {
                    "sent": "And if you have thousands of these classifiers, then putting them together you can do a very good job of discriminating people.",
                    "label": 0
                },
                {
                    "sent": "So that's what we've done.",
                    "label": 0
                },
                {
                    "sent": "We've built a lot of these classifiers, and the way we do it is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Left the data set.",
                    "label": 0
                },
                {
                    "sent": "We have about 20,000 images of 120 different people on average.",
                    "label": 0
                },
                {
                    "sent": "That's about 170 images each.",
                    "label": 0
                },
                {
                    "sent": "And from each of those images, we've defined 11 different regions on the face in terms of where certain face features are on the eyebrows, the forehead just up there, and from each of them we extract a few SIFT descriptors.",
                    "label": 0
                },
                {
                    "sent": "Each little square here represents one sift descriptor.",
                    "label": 0
                },
                {
                    "sent": "The size indicates the scale.",
                    "label": 0
                },
                {
                    "sent": "And so from that data we can build 120 choose two possible pairs of people.",
                    "label": 0
                },
                {
                    "sent": "For each pair, we can have 11 different features and do the math.",
                    "label": 0
                },
                {
                    "sent": "We can train about 80,000 of these Tom versus peak classifiers.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so the problem we're trying to approach here, though face verification, is how to tell any pair of people apart.",
                    "label": 1
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "The details of the problem are like this.",
                    "label": 0
                },
                {
                    "sent": "You get two faces which are not in that reference, that it's not among these 120 people, and the question we want to answer is, are these the same person or are they different?",
                    "label": 0
                },
                {
                    "sent": "So what we do is we take a bunch of these Tom versus P classifiers.",
                    "label": 0
                },
                {
                    "sent": "We run them on each of the images.",
                    "label": 0
                },
                {
                    "sent": "In practice we use 5000 of the classifiers and so that gives you a 5000 dimensional descriptor of each image.",
                    "label": 0
                },
                {
                    "sent": "We combine those.",
                    "label": 0
                },
                {
                    "sent": "We take the absolute difference and the Elementwise product to get a vector that describes the pair.",
                    "label": 0
                },
                {
                    "sent": "And then we have a second stage classifier which can terminate same pairs from different pairs.",
                    "label": 0
                },
                {
                    "sent": "So that's sort of the overview of the whole system.",
                    "label": 0
                },
                {
                    "sent": "What I want to talk about next is a little more detail on how we build these classifiers really, and in particular on how we align the faces to start with.",
                    "label": 0
                },
                {
                    "sent": "We have to think about alignment because we're using these.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different regions of the face and so.",
                    "label": 0
                },
                {
                    "sent": "Each classifier can only see a very small part of the face, right?",
                    "label": 1
                },
                {
                    "sent": "If you look at the far left region where we're training classifiers and the only part of the face I see is these tiny little squares on the eyebrows, right?",
                    "label": 0
                },
                {
                    "sent": "The reason we do that is you get more of a variety of classifiers, right?",
                    "label": 0
                },
                {
                    "sent": "If you force a classifier to make this decision just based on the eyebrows, you learn something about the eyebrows.",
                    "label": 0
                },
                {
                    "sent": "Another classifier learns about the mouth, so you get more variety.",
                    "label": 0
                },
                {
                    "sent": "We also think it generalizes better when we apply it to other people because.",
                    "label": 0
                },
                {
                    "sent": "This sort of third person who comes in they might have a nose that's similar to a nose that's in one of your reference people.",
                    "label": 0
                },
                {
                    "sent": "That's more likely than sort of their whole face being similar.",
                    "label": 0
                },
                {
                    "sent": "But the problem with this is that you really need good alignment because if your classifier is looking at features on the eyebrows, if you accidentally, you know you're not taking your features from the eyebrows, but from up on the forehead, then it's not going to work.",
                    "label": 0
                },
                {
                    "sent": "And so since we are, our classifiers are defined this way in terms of the parts of the face.",
                    "label": 0
                },
                {
                    "sent": "We also base our alignment on doing fiducial detection, detecting the parts of the face.",
                    "label": 1
                },
                {
                    "sent": "And in particular, we're using this face part detection.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From volume at all in CPR last year.",
                    "label": 0
                },
                {
                    "sent": "I I won't talk about how that works, that's a separate paper, but it does quite good on these sort of unconstrained non laboratory images and there are some just some examples.",
                    "label": 0
                },
                {
                    "sent": "So once we have all of these.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Points one way to do alignment.",
                    "label": 0
                },
                {
                    "sent": "Our method of alignment is a modification of this piecewise affine warp.",
                    "label": 1
                },
                {
                    "sent": "So just to describe how the piecewise affine warp works, you get some faces in that you want to align.",
                    "label": 0
                },
                {
                    "sent": "You detect all these parts.",
                    "label": 0
                },
                {
                    "sent": "We have a set of 95 different parts for detecting, and then you use those parts to build a triangulation on the face.",
                    "label": 0
                },
                {
                    "sent": "And we also have what we call the Canonical part locations, and that's just where the parts fall on an average frontal face with a neutral expression.",
                    "label": 0
                },
                {
                    "sent": "And once we have that.",
                    "label": 0
                },
                {
                    "sent": "All we do is find the affine transformation for each triangle from the sort of detected triangle to the Canonical triangle.",
                    "label": 1
                },
                {
                    "sent": "We work each triangle separately.",
                    "label": 0
                },
                {
                    "sent": "And there is the result.",
                    "label": 0
                },
                {
                    "sent": "There is the original and the result together.",
                    "label": 0
                },
                {
                    "sent": "It works pretty well, it corrects pose and expression fairly well.",
                    "label": 1
                },
                {
                    "sent": "We've closed Obama's mouth, they look a little bit more frontal than they do in the originals.",
                    "label": 0
                },
                {
                    "sent": "The problem is, in a way it's too good.",
                    "label": 0
                },
                {
                    "sent": "If you think about each of these.",
                    "label": 0
                },
                {
                    "sent": "Triangles you find the affine transformation it's there are six constraints, because there are three vertices, you get a perfect solution, and so we're mapping every point to exactly the same location.",
                    "label": 0
                },
                {
                    "sent": "Everyone's eyebrows go to exactly the same place, and what that means is whether you have thick lips or thin lips.",
                    "label": 0
                },
                {
                    "sent": "After alignment, you have sort of average thickness lips, and that means you're losing important identity, important information that can tell you about identity.",
                    "label": 0
                },
                {
                    "sent": "So we've developed this alignment technique we call identity preserving alignment, and it's similar to the piecewise affine work.",
                    "label": 0
                },
                {
                    "sent": "We start by detecting the parts.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we.",
                    "label": 0
                },
                {
                    "sent": "This is the different part.",
                    "label": 0
                },
                {
                    "sent": "We estimate what we call the generic parts and what that what we mean by that is if you had an average person an average face with the same poles in the expression that are in this query image, where would the parts be?",
                    "label": 1
                },
                {
                    "sent": "And I'll talk about this in a moment about how we find that.",
                    "label": 0
                },
                {
                    "sent": "But once we have that, we follow the same procedure we do the triangulation, we mapped to the Canonical locations of the parts.",
                    "label": 0
                },
                {
                    "sent": "And and that's how we get the alignment.",
                    "label": 0
                },
                {
                    "sent": "So there are two things I want to tell you about this.",
                    "label": 0
                },
                {
                    "sent": "First is why does getting these generic parts preserve identity, and the 2nd is how do you actually get the generic parts?",
                    "label": 1
                },
                {
                    "sent": "It's a little hard to see the generic parts in real.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Human faces, 'cause they're quite close to the detected parts.",
                    "label": 0
                },
                {
                    "sent": "But if we look at these robot faces, it's easier to see.",
                    "label": 0
                },
                {
                    "sent": "So here's two robots.",
                    "label": 0
                },
                {
                    "sent": "One has thin eyebrows when his thick eyebrows one has a narrow nose in a wide nose.",
                    "label": 0
                },
                {
                    "sent": "That's sort of identity information.",
                    "label": 0
                },
                {
                    "sent": "Also, one has his mouth open.",
                    "label": 0
                },
                {
                    "sent": "We think of that is expression, right?",
                    "label": 0
                },
                {
                    "sent": "That's what we'd like to correct for.",
                    "label": 0
                },
                {
                    "sent": "And if you just do the piecewise affine warp, that's the PAW.",
                    "label": 0
                },
                {
                    "sent": "Here you detect the parts you have these Canonical locations, which are an average robot with his mouth closed, and if you just warp the detected parts to the Canonical parts.",
                    "label": 1
                },
                {
                    "sent": "You're just warping the whole face to the average face, right?",
                    "label": 0
                },
                {
                    "sent": "And you get these two faces that are identical.",
                    "label": 0
                },
                {
                    "sent": "You've lost all the identity information.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you use the generic parts, you detect the parts, but you only use those to estimate the location of the generic parts.",
                    "label": 0
                },
                {
                    "sent": "Here you can see the generic parts.",
                    "label": 0
                },
                {
                    "sent": "They're pretty much the same, right?",
                    "label": 0
                },
                {
                    "sent": "They have average thickness eyebrows, average with knows.",
                    "label": 0
                },
                {
                    "sent": "The only difference is one has the mouth open and one has it closed, and.",
                    "label": 0
                },
                {
                    "sent": "And the procedure there are the Canonical parts is to to warp the generic parts to the Canonical parts.",
                    "label": 1
                },
                {
                    "sent": "Mostly the generic parts in the Canonical parts are the same because there's not a lot of expression here.",
                    "label": 0
                },
                {
                    "sent": "But with the robot with his open mouth, the generic parts are going to move down to close that mouth, and that pulls the lines in black.",
                    "label": 0
                },
                {
                    "sent": "The actual mouth that pulls that closed as well.",
                    "label": 0
                },
                {
                    "sent": "And what you end up with is this, right?",
                    "label": 0
                },
                {
                    "sent": "You have an image where we've preserved the differences in geometry, the eyebrows, the nose.",
                    "label": 0
                },
                {
                    "sent": "But we've succeeded in closing the mouth.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's the idea.",
                    "label": 0
                },
                {
                    "sent": "Here it is in real images.",
                    "label": 0
                },
                {
                    "sent": "As I said, it's a little bit subtle, but most people agree with us when we say that the image on the far right.",
                    "label": 0
                },
                {
                    "sent": "Which is the identity preserving alignment, looks more like that person than the image in the center, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're familiar enough with that faces, I hope you'll agree with that.",
                    "label": 0
                },
                {
                    "sent": "The top ones.",
                    "label": 0
                },
                {
                    "sent": "Ben Stiller, the one on the right, really looks like him.",
                    "label": 0
                },
                {
                    "sent": "The one in the middle.",
                    "label": 0
                },
                {
                    "sent": "He's kind of lost the squareness of his face, or it's a little bit wider instead of narrower.",
                    "label": 0
                },
                {
                    "sent": "That's I hope you can see that.",
                    "label": 0
                },
                {
                    "sent": "So the last thing is, how do you actually estimate?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Those parts we do that with our data set again, I told you about the images before we augment it.",
                    "label": 0
                },
                {
                    "sent": "We have these 95 part locations for every image in there.",
                    "label": 1
                },
                {
                    "sent": "We've separated the parts into these column inner parts in outer parts.",
                    "label": 0
                },
                {
                    "sent": "The blue parts here are things that you can detect automatically using our algorithm.",
                    "label": 0
                },
                {
                    "sent": "The pink parts here.",
                    "label": 0
                },
                {
                    "sent": "They sort of describe the overall shape of the face.",
                    "label": 0
                },
                {
                    "sent": "They're harder to detect.",
                    "label": 0
                },
                {
                    "sent": "There's kind of not as well defined, and we.",
                    "label": 0
                },
                {
                    "sent": "They help our algorithm, so we use them, but the way we use them you'll see is a little different.",
                    "label": 0
                },
                {
                    "sent": "So the actual procedure for estimating those parts 1st we just run.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detector to get the inner parts.",
                    "label": 0
                },
                {
                    "sent": "And then we look to our data set an for each of the 120 people.",
                    "label": 1
                },
                {
                    "sent": "Find the face where the inner parts are as close as possible to the parts on the query image.",
                    "label": 1
                },
                {
                    "sent": "And what that gives you is 120 different people with roughly the same pose and expression as the query image, right?",
                    "label": 1
                },
                {
                    "sent": "And that's that's the idea behind generic parts.",
                    "label": 0
                },
                {
                    "sent": "We take the average of those 120 sets of points using the inner points and the outer points, right?",
                    "label": 0
                },
                {
                    "sent": "And that is an average face with the same pose and expression as the query image, and that's what the generic parts are.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the whole story.",
                    "label": 0
                },
                {
                    "sent": "This system, again, you take the images in, we do the alignment, we run the Tom versus P classifiers to get a vector for each image.",
                    "label": 0
                },
                {
                    "sent": "And combine them into the second stage classifier.",
                    "label": 0
                },
                {
                    "sent": "We've tested this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the label faces in the wild data set, it's a standard data set for face verification.",
                    "label": 1
                },
                {
                    "sent": "We like it because it's images collected from the Internet.",
                    "label": 0
                },
                {
                    "sent": "It's not laboratory images.",
                    "label": 0
                },
                {
                    "sent": "It consists of 6000 pairs of faces.",
                    "label": 0
                },
                {
                    "sent": "Half of them are the same person.",
                    "label": 0
                },
                {
                    "sent": "Half of them are two different people, and justice for each pair you have to say whether it's same or different.",
                    "label": 0
                },
                {
                    "sent": "Previous best results.",
                    "label": 0
                },
                {
                    "sent": "The status.",
                    "label": 0
                },
                {
                    "sent": "It's been around for.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four or five years.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of work on it.",
                    "label": 0
                },
                {
                    "sent": "The top three published results are these top scores from CPR last year, 90.57%.",
                    "label": 0
                },
                {
                    "sent": "Our method gives us 93.1 which is a 27% reduction in the error rate.",
                    "label": 0
                },
                {
                    "sent": "If you look at the RC curve, you can see there's a significant gap from the previous batch.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result.",
                    "label": 0
                },
                {
                    "sent": "And in particular, I'm sort of in security situations, which is where a lot of people are thinking of face verification.",
                    "label": 0
                },
                {
                    "sent": "What you're concerned with is the far left side of the graph, right where you really don't want to let the wrong person into the building, and you can see that better if you put the X axis on a log.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see in particular we have a good separation on that side.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}