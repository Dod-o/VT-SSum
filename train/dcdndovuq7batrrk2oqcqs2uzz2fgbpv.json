{
    "id": "dcdndovuq7batrrk2oqcqs2uzz2fgbpv",
    "title": "Selective Sampling on Graphs for Classification",
    "info": {
        "author": [
            "Jiawei Han, Department of Computer Science, University of Illinois at Urbana-Champaign"
        ],
        "published": "Sept. 27, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2013_han_graphs_classification/",
    "segmentation": [
        [
            "Good afternoon.",
            "Actually, this paper was written by my PhD student change Shanku while he was doing PhD summer intern at IBM.",
            "Cheryl gores group, so that's why the actually chalu Leo that time also was doing IBM summer intern.",
            "That's the reason you know they got change angle sharag rajulu and me.",
            "OK, unfortunately change Max went to China, he could not present this.",
            "He asked me to present it, but I'm among all those students are the piece of work.",
            "This one probably is a little far apart from me from my major focus, so I present the paper.",
            "Feel free.",
            "You can ask me questions, but some I mean obviously able to answer.",
            "You did go ahead and communicate with him.",
            "OK nowadays with Skype and with email you can communicate with him right in the conference.",
            "So then I just give you the general view on what this means.",
            "Selective sampling on graphs for classification.",
            "So."
        ],
        [
            "So the first thing."
        ],
        [
            "Is.",
            "I probably assume most people know the basic concepts, but I better get a little poll so I know how far I haha deeper has shell.",
            "I do cover it OK.",
            "The first thing is how many people know or learning on graphs this concept.",
            "OK, we got a quite a quite a big crowd.",
            "I assume this one is a graph session.",
            "If you do not know learning on graphs, probably you don't want to even come here.",
            "OK, so the general idea is.",
            "We got a classification for.",
            "You know that you can think about relational data.",
            "You know the record data or multi dimensional data if you do not really discussing graphs.",
            "The most time people are doing learning they have a.",
            "One typical assumption is IID, which is independent and identically distributed.",
            "OK, that's a typical assumption in statistical learning, but once we get the graphs.",
            "This assumption does not really hope the reason is the graphs.",
            "The links were impact the other nodes.",
            "They do not really follow the general you know IID distribution those things.",
            "OK, so we have to handle it as specifically as the general philosophy is a graph impact the class labor.",
            "If you link to many people, have the similarly neighbor class laborers.",
            "Likely you were adapt similar latent class labor.",
            "It's general philosophy is kind of you.",
            "You gotta you know, sausage will fly down there, you get the connections, you know there's a chance to get science.",
            "Actually it's a higher OK."
        ],
        [
            "So that's a general philosophy, but learning on graphs.",
            "Actually, people have studied quite a lot.",
            "If you read, you know the previous, no matter KDD conference or ICMA or NIPS conference.",
            "There lots of such papers.",
            "Then the second concept is online learning.",
            "How many people know online learning?",
            "OK, we see I see even more people.",
            "OK, online learning the general philosophy is you will not get the data or at the same time you get the data.",
            "You know it's more like as in sequential mode.",
            "If you people know data streams, you can think it's more like a data streams you come in.",
            "You know in the sequence mode you'll get one labor, then you get another one again, another labor.",
            "So then you can improve your model somehow.",
            "This is like online learning, or you can think it's like a sequential learning or data stream learning or something OK, but here in this concept that we can assume the graph is known OK, but the labor?",
            "I give you the label one at a time.",
            "This is like in the transductive setting OK, so this is the online learning we are discussing."
        ],
        [
            "Then the third concept is active.",
            "Learning how people know active learning.",
            "OK, still see quite a quite a lot of people active learning the active learning.",
            "It doesn't mean you are very active, but just just mean actually.",
            "You may not know the labor, but you want to turn the learning process.",
            "You want to ask some experts or articles give me the labor OK, but remember, online learning the major thing is you don't want to keep bugging those experts.",
            "The experts expensive is not easy to obtain.",
            "You want to ask as least query as possible, but you get can build up a good model.",
            "OK, so that's a general philosophy of online learning.",
            "Now the."
        ],
        [
            "Key is.",
            "For this paper, the one integrate all these three things together.",
            "That's why you look at look at the tighter, tighter.",
            "Essentially say we want to do on line learning on graph.",
            "But also we want to do active learning graphs.",
            "We want to do online active learning graphs, or you can say on line somehow you can for the active one, you can say selective sampling, so called select the sampling is you select the sample.",
            "Some nodes you ask.",
            "People to give you a labor.",
            "OK so that's we call selective sampling on graphs.",
            "So this paper actually developed two algorithms.",
            "Why is really selective sampling on graphs and other one is on line learning on graphs, both 2 algorithms he took the the second algorithm is a byproduct in the middle."
        ],
        [
            "OK.",
            "So."
        ],
        [
            "The base, the base he actually worked on is called batch learning on graphs.",
            "That means that I first just assume I do graph learning.",
            "I don't consider online.",
            "I don't consider selective sampling or active learning.",
            "I just take all things.",
            "But this one actually has been studied.",
            "It's more like a review process so you know where it starts.",
            "So the philosophy will get a graph.",
            "You get a set of vertices, is a set of edges, and then you get you know, like.",
            "The adjacency matrix.",
            "It's kind of a graph.",
            "Then you can get a set of labels.",
            "The labor essentially is this.",
            "Why is the label you can get plus?",
            "Labor minus labor against two classes when it's plus one the negative ones minus one.",
            "But if you do not have any label on this graph, this node laborers 00 means I have no labor yet.",
            "I have a chance to ask, so that's a general assumption."
        ],
        [
            "Then this is just revealed review is card error error GC.",
            "This is a car learning with local and global consistency.",
            "This one actually was thing Joe in NIPS in 2003 published paper that paper is being very famous in graph learning.",
            "They are cite this paper.",
            "It's like, you know, quite standard paper.",
            "That they are going the most people car air at GC error means learning ergy means local and global.",
            "This C means consistency.",
            "The philosophy is you say once I get graph I want to I link to them.",
            "I want to somehow consistent the low current global.",
            "Actually once you link to the local why you want to have some local consistency for you?",
            "Also in the in general you want have a global consistency in a bigger scope.",
            "Then this formula in the middle you get 2 terms.",
            "OK, one term actually is to say you know you got the labor is why you want to see whether your true one and and the labor you got.",
            "What's the difference?",
            "You want to minimize the difference.",
            "That means the least error, the better.",
            "OK, that's why I gotta meet part.",
            "The other one is a graph regularization.",
            "OK, this regularization?",
            "He just use graph Laplace flash it that's apart.",
            "So that's essentially is being chose algorithm, not his algorithm OK?"
        ],
        [
            "And this algorithm you can do a little transformation.",
            "The transformation means you transform you using this matrix you transferring instead of using error matrix using M OK. Then the wine is transforming into this formula.",
            "Essentially this former is you can use the online rich regression OK."
        ],
        [
            "Then come to his contribution OK?"
        ],
        [
            "His contribution in Century is saying I first want to get on line learning.",
            "OK, the online learning means.",
            "I actually were.",
            "You give me one 234 you give me T labels.",
            "I grab one at a time.",
            "I learned one at a time.",
            "This is online learning.",
            "Of course, this one, his graph you based on this error GC and he derive a new algorithm.",
            "Put it online.",
            "Oh, in the."
        ],
        [
            "Right, OK, so that's why you can see that this online one becomes oh error GC.",
            "OK, just put it all onto this area or GCL algorithm.",
            "What is this all means?",
            "This all means online.",
            "How do you do online?",
            "If you look at the algorithm here inside, I actually do not quite like it style for the whole algorithm down there.",
            "You know it's hard to read code, but you can see the key part is in the algorithm itself.",
            "You see there's a four I from one 2T.",
            "You'll get a 1 cent one labor at a time.",
            "You do this on line and how do you do it?",
            "You say you first do the prediction.",
            "You predict this Y, get it, get it, get hacked, you predicted Y to see whether this.",
            "Why is good.",
            "It's wife.",
            "It's your rear labor that line that you say receive the correct label.",
            "That means you predict labor.",
            "You receive the real labor.",
            "You compare them to see it's good or bad.",
            "OK, if your prediction is.",
            "Inconsistent, that means I predicted this labor.",
            "I gotta re labor, they're different.",
            "If they're different, then I have to do something.",
            "Update my model.",
            "OK, so that's the algorithm that why is oh error GC OK, you do have this this."
        ],
        [
            "Addiction using this, but those algorithms this he has lots of lemma and theorem and he proved them in their favor.",
            "OK, if you want to read it you should read it, but I have no time to explain that.",
            "Plus I did not read the proof.",
            "You know in any detail.",
            "I have to admit you know so.",
            "But anyway, you probably know this is, yeah."
        ],
        [
            "The philosophy what he got is.",
            "In general, there is a bound.",
            "This M. There's a bounded by this formula.",
            "There are two things you provide.",
            "No one thing is efficiency.",
            "1.",
            "One thing is the mistakes you will get with this bound.",
            "He basically proof if the original area or GC algorithm is good.",
            "OK, then you do.",
            "Online learning is also good.",
            "OK, they have some correlation.",
            "The better of the offline one, the smaller arrow of the online one.",
            "OK, of course you proceed.",
            "This is of course OK, but he did have some serious proof on this."
        ],
        [
            "OK. That's his online algorithm.",
            "Now we look."
        ],
        [
            "Get his active learning part is the selective sampling part.",
            "The selective sampling para means.",
            "On line.",
            "They get they give me sample one at a time.",
            "I because of the experts is so expensive.",
            "I dare not ask labels.",
            "OK, that means you give me so many.",
            "You get a stream of the nodes coming.",
            "I dare not to ask.",
            "The reason is I asked to pay more OK then I only find somebody I really want to ask labor.",
            "That's the time I would ask.",
            "So the trick becomes when I'm going to ask.",
            "OK?",
            "So then he basically workout this method."
        ],
        [
            "Workout this method philosophy is he you try to predict something, but you have certain confidence.",
            "OK, that means you have some estimation.",
            "The escalation has some bias.",
            "The bias have some bound.",
            "If this bias bound is too big, the simply says I actually really do not know the labor.",
            "OK, that's the time I'm going to ask.",
            "OK, you Percy, the philosophy is every time I do not ask expert, I actually do some computation on my own so I know how confident this guy I can get the label if I'm not confident and stop bugging the experts, give me the label.",
            "Otherwise I don't.",
            "So that's the philosophy."
        ],
        [
            "With this philosophy, he just changed the code a little, so then you can see you know what things done.",
            "Here he calculate not only the predicted labor, yhat.",
            "Yeah, he also calculate that bond.",
            "You see that bond is greater than certain threshold.",
            "That means I really do not know what is a labor I have.",
            "I have very vague idea.",
            "I can be confident then that's the time I call it.",
            "This happens is the same as what I guess I do nothing OK, but if it happens it's different.",
            "Then I have to update my model.",
            "OK see that's the trick.",
            "Once you get this trick."
        ],
        [
            "He also get lots of lemmas and theorems and try to prove OK, but I will not go over this."
        ],
        [
            "The good thing you would look at the conclusion.",
            "OK, the good thing is the first thing is the time complexity is low.",
            "OK, you can see.",
            "Gotta log T once again log you or your Life OK, because you you gotta longer rhythmic complexity.",
            "The car part is actually the ratio.",
            "This learning ratio OK if you have to get lots of things, it's not good.",
            "You get lots of Labor.",
            "The ratio is high, is not good, but if it's a cover it slow, so the cost is very low.",
            "The second thing is.",
            "He basically say you get a larger koppa you actually get it.",
            "You know more confidence, more nodes you'll get, but of course you pay more."
        ],
        [
            "Then we look at the."
        ],
        [
            "It's the experiments he did is he got a four datasets coauthor, which actually from the BRP, but he gotta subsets, RDB RP.",
            "You got 1700 authors, OK?",
            "Then get at the edge of the graphs.",
            "The other one is Cora.",
            "Cora actually is a scientific publication.",
            "He got it like 2000.",
            "You know two or three thousand.",
            "You know these papers, the servants IMDb, which is movie database.",
            "The last one is Pub Madison Medical publication.",
            "One he got a much longer, much bigger way.",
            "You can see one in 90.",
            "No 19,000 something.",
            "OK, so with 44,000."
        ],
        [
            "Thanks now his experiments basically calculate these several things.",
            "One thing is accumulated error rate.",
            "We know the error, the lower arrow the classification is better.",
            "That's of course the second one is the number of query labels.",
            "Let me ask experts, you ask less.",
            "You're better then the third one is accumulating computation time.",
            "Of course you take less time to compute.",
            "It's better, so everything is the lower the better."
        ],
        [
            "Now he just showed show he comparing three algorithms.",
            "Why is graph perception algorithm GPA another?",
            "Is all air air GCS as his algorithm just online one.",
            "The last one is sampling, 1S SLG.",
            "Is sampling one?",
            "OK?",
            "So you pharisee.",
            "Here's online version.",
            "An active learning version."
        ],
        [
            "OK, now you look at the results.",
            "The results?",
            "These are the two results ones on Coop.",
            "OK so the interesting thing is you look at the error rate.",
            "The error rate actually oh error GC is somewhat better, it's the best you privacy but as error GC is very close, very close means I use selective sampling.",
            "I almost can compete with you.",
            "Ask everything you get.",
            "On line one, you ask all the labels.",
            "Then you look at the labor and the number of query nodes and that means you ask experts how many times.",
            "Then you'll see the last row is always the best because you always ask less queries to experts.",
            "You get almost the same performance on the error rates as online version, and it's better than GPA GPA."
        ],
        [
            "The same thing happens for IMDb and Pub Med.",
            "You'll probably see this is also very, very obvious because the pub Med Wipro can see you get a 19,000 queries.",
            "You ask 19,000 labels, but this one is five son laborers, right?",
            "So the computation time?",
            "Of course the GPA because you don't really doing this online, one asked the other the computation time.",
            "Wise GPA is always the best.",
            "Spend a little more time, but it would get benefit, right?"
        ],
        [
            "So then he looked the car part.",
            "The impact of copper.",
            "That means if I get more and more things, I almost, you know, get all the labels.",
            "You know, the ratio on the acquired acquiring labor.",
            "Of course, in general we get better, but actually, once you only ask 0.4 zero point 5, you almost reach the lower one, so the carpet does not need to be very high."
        ],
        [
            "So."
        ],
        [
            "Then the summary actually is saying this is on line learning with local and global consistency.",
            "And he basically say he did have two algorithms.",
            "Why is online version?",
            "Why is active learning selective sampling version both looks good.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon.",
                    "label": 0
                },
                {
                    "sent": "Actually, this paper was written by my PhD student change Shanku while he was doing PhD summer intern at IBM.",
                    "label": 0
                },
                {
                    "sent": "Cheryl gores group, so that's why the actually chalu Leo that time also was doing IBM summer intern.",
                    "label": 0
                },
                {
                    "sent": "That's the reason you know they got change angle sharag rajulu and me.",
                    "label": 0
                },
                {
                    "sent": "OK, unfortunately change Max went to China, he could not present this.",
                    "label": 0
                },
                {
                    "sent": "He asked me to present it, but I'm among all those students are the piece of work.",
                    "label": 0
                },
                {
                    "sent": "This one probably is a little far apart from me from my major focus, so I present the paper.",
                    "label": 0
                },
                {
                    "sent": "Feel free.",
                    "label": 0
                },
                {
                    "sent": "You can ask me questions, but some I mean obviously able to answer.",
                    "label": 0
                },
                {
                    "sent": "You did go ahead and communicate with him.",
                    "label": 0
                },
                {
                    "sent": "OK nowadays with Skype and with email you can communicate with him right in the conference.",
                    "label": 0
                },
                {
                    "sent": "So then I just give you the general view on what this means.",
                    "label": 0
                },
                {
                    "sent": "Selective sampling on graphs for classification.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "I probably assume most people know the basic concepts, but I better get a little poll so I know how far I haha deeper has shell.",
                    "label": 0
                },
                {
                    "sent": "I do cover it OK.",
                    "label": 0
                },
                {
                    "sent": "The first thing is how many people know or learning on graphs this concept.",
                    "label": 1
                },
                {
                    "sent": "OK, we got a quite a quite a big crowd.",
                    "label": 1
                },
                {
                    "sent": "I assume this one is a graph session.",
                    "label": 0
                },
                {
                    "sent": "If you do not know learning on graphs, probably you don't want to even come here.",
                    "label": 0
                },
                {
                    "sent": "OK, so the general idea is.",
                    "label": 0
                },
                {
                    "sent": "We got a classification for.",
                    "label": 0
                },
                {
                    "sent": "You know that you can think about relational data.",
                    "label": 0
                },
                {
                    "sent": "You know the record data or multi dimensional data if you do not really discussing graphs.",
                    "label": 0
                },
                {
                    "sent": "The most time people are doing learning they have a.",
                    "label": 1
                },
                {
                    "sent": "One typical assumption is IID, which is independent and identically distributed.",
                    "label": 1
                },
                {
                    "sent": "OK, that's a typical assumption in statistical learning, but once we get the graphs.",
                    "label": 0
                },
                {
                    "sent": "This assumption does not really hope the reason is the graphs.",
                    "label": 0
                },
                {
                    "sent": "The links were impact the other nodes.",
                    "label": 0
                },
                {
                    "sent": "They do not really follow the general you know IID distribution those things.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have to handle it as specifically as the general philosophy is a graph impact the class labor.",
                    "label": 0
                },
                {
                    "sent": "If you link to many people, have the similarly neighbor class laborers.",
                    "label": 0
                },
                {
                    "sent": "Likely you were adapt similar latent class labor.",
                    "label": 0
                },
                {
                    "sent": "It's general philosophy is kind of you.",
                    "label": 0
                },
                {
                    "sent": "You gotta you know, sausage will fly down there, you get the connections, you know there's a chance to get science.",
                    "label": 0
                },
                {
                    "sent": "Actually it's a higher OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's a general philosophy, but learning on graphs.",
                    "label": 0
                },
                {
                    "sent": "Actually, people have studied quite a lot.",
                    "label": 0
                },
                {
                    "sent": "If you read, you know the previous, no matter KDD conference or ICMA or NIPS conference.",
                    "label": 0
                },
                {
                    "sent": "There lots of such papers.",
                    "label": 0
                },
                {
                    "sent": "Then the second concept is online learning.",
                    "label": 1
                },
                {
                    "sent": "How many people know online learning?",
                    "label": 1
                },
                {
                    "sent": "OK, we see I see even more people.",
                    "label": 0
                },
                {
                    "sent": "OK, online learning the general philosophy is you will not get the data or at the same time you get the data.",
                    "label": 0
                },
                {
                    "sent": "You know it's more like as in sequential mode.",
                    "label": 0
                },
                {
                    "sent": "If you people know data streams, you can think it's more like a data streams you come in.",
                    "label": 0
                },
                {
                    "sent": "You know in the sequence mode you'll get one labor, then you get another one again, another labor.",
                    "label": 0
                },
                {
                    "sent": "So then you can improve your model somehow.",
                    "label": 0
                },
                {
                    "sent": "This is like online learning, or you can think it's like a sequential learning or data stream learning or something OK, but here in this concept that we can assume the graph is known OK, but the labor?",
                    "label": 1
                },
                {
                    "sent": "I give you the label one at a time.",
                    "label": 1
                },
                {
                    "sent": "This is like in the transductive setting OK, so this is the online learning we are discussing.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the third concept is active.",
                    "label": 0
                },
                {
                    "sent": "Learning how people know active learning.",
                    "label": 1
                },
                {
                    "sent": "OK, still see quite a quite a lot of people active learning the active learning.",
                    "label": 1
                },
                {
                    "sent": "It doesn't mean you are very active, but just just mean actually.",
                    "label": 0
                },
                {
                    "sent": "You may not know the labor, but you want to turn the learning process.",
                    "label": 0
                },
                {
                    "sent": "You want to ask some experts or articles give me the labor OK, but remember, online learning the major thing is you don't want to keep bugging those experts.",
                    "label": 0
                },
                {
                    "sent": "The experts expensive is not easy to obtain.",
                    "label": 1
                },
                {
                    "sent": "You want to ask as least query as possible, but you get can build up a good model.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a general philosophy of online learning.",
                    "label": 0
                },
                {
                    "sent": "Now the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Key is.",
                    "label": 0
                },
                {
                    "sent": "For this paper, the one integrate all these three things together.",
                    "label": 0
                },
                {
                    "sent": "That's why you look at look at the tighter, tighter.",
                    "label": 0
                },
                {
                    "sent": "Essentially say we want to do on line learning on graph.",
                    "label": 0
                },
                {
                    "sent": "But also we want to do active learning graphs.",
                    "label": 1
                },
                {
                    "sent": "We want to do online active learning graphs, or you can say on line somehow you can for the active one, you can say selective sampling, so called select the sampling is you select the sample.",
                    "label": 1
                },
                {
                    "sent": "Some nodes you ask.",
                    "label": 0
                },
                {
                    "sent": "People to give you a labor.",
                    "label": 0
                },
                {
                    "sent": "OK so that's we call selective sampling on graphs.",
                    "label": 1
                },
                {
                    "sent": "So this paper actually developed two algorithms.",
                    "label": 0
                },
                {
                    "sent": "Why is really selective sampling on graphs and other one is on line learning on graphs, both 2 algorithms he took the the second algorithm is a byproduct in the middle.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The base, the base he actually worked on is called batch learning on graphs.",
                    "label": 1
                },
                {
                    "sent": "That means that I first just assume I do graph learning.",
                    "label": 0
                },
                {
                    "sent": "I don't consider online.",
                    "label": 1
                },
                {
                    "sent": "I don't consider selective sampling or active learning.",
                    "label": 0
                },
                {
                    "sent": "I just take all things.",
                    "label": 0
                },
                {
                    "sent": "But this one actually has been studied.",
                    "label": 0
                },
                {
                    "sent": "It's more like a review process so you know where it starts.",
                    "label": 1
                },
                {
                    "sent": "So the philosophy will get a graph.",
                    "label": 0
                },
                {
                    "sent": "You get a set of vertices, is a set of edges, and then you get you know, like.",
                    "label": 0
                },
                {
                    "sent": "The adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "It's kind of a graph.",
                    "label": 0
                },
                {
                    "sent": "Then you can get a set of labels.",
                    "label": 0
                },
                {
                    "sent": "The labor essentially is this.",
                    "label": 0
                },
                {
                    "sent": "Why is the label you can get plus?",
                    "label": 0
                },
                {
                    "sent": "Labor minus labor against two classes when it's plus one the negative ones minus one.",
                    "label": 0
                },
                {
                    "sent": "But if you do not have any label on this graph, this node laborers 00 means I have no labor yet.",
                    "label": 0
                },
                {
                    "sent": "I have a chance to ask, so that's a general assumption.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then this is just revealed review is card error error GC.",
                    "label": 0
                },
                {
                    "sent": "This is a car learning with local and global consistency.",
                    "label": 1
                },
                {
                    "sent": "This one actually was thing Joe in NIPS in 2003 published paper that paper is being very famous in graph learning.",
                    "label": 0
                },
                {
                    "sent": "They are cite this paper.",
                    "label": 0
                },
                {
                    "sent": "It's like, you know, quite standard paper.",
                    "label": 1
                },
                {
                    "sent": "That they are going the most people car air at GC error means learning ergy means local and global.",
                    "label": 0
                },
                {
                    "sent": "This C means consistency.",
                    "label": 0
                },
                {
                    "sent": "The philosophy is you say once I get graph I want to I link to them.",
                    "label": 0
                },
                {
                    "sent": "I want to somehow consistent the low current global.",
                    "label": 0
                },
                {
                    "sent": "Actually once you link to the local why you want to have some local consistency for you?",
                    "label": 1
                },
                {
                    "sent": "Also in the in general you want have a global consistency in a bigger scope.",
                    "label": 0
                },
                {
                    "sent": "Then this formula in the middle you get 2 terms.",
                    "label": 0
                },
                {
                    "sent": "OK, one term actually is to say you know you got the labor is why you want to see whether your true one and and the labor you got.",
                    "label": 0
                },
                {
                    "sent": "What's the difference?",
                    "label": 0
                },
                {
                    "sent": "You want to minimize the difference.",
                    "label": 1
                },
                {
                    "sent": "That means the least error, the better.",
                    "label": 0
                },
                {
                    "sent": "OK, that's why I gotta meet part.",
                    "label": 0
                },
                {
                    "sent": "The other one is a graph regularization.",
                    "label": 0
                },
                {
                    "sent": "OK, this regularization?",
                    "label": 0
                },
                {
                    "sent": "He just use graph Laplace flash it that's apart.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially is being chose algorithm, not his algorithm OK?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this algorithm you can do a little transformation.",
                    "label": 0
                },
                {
                    "sent": "The transformation means you transform you using this matrix you transferring instead of using error matrix using M OK. Then the wine is transforming into this formula.",
                    "label": 0
                },
                {
                    "sent": "Essentially this former is you can use the online rich regression OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then come to his contribution OK?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His contribution in Century is saying I first want to get on line learning.",
                    "label": 0
                },
                {
                    "sent": "OK, the online learning means.",
                    "label": 0
                },
                {
                    "sent": "I actually were.",
                    "label": 0
                },
                {
                    "sent": "You give me one 234 you give me T labels.",
                    "label": 0
                },
                {
                    "sent": "I grab one at a time.",
                    "label": 0
                },
                {
                    "sent": "I learned one at a time.",
                    "label": 0
                },
                {
                    "sent": "This is online learning.",
                    "label": 0
                },
                {
                    "sent": "Of course, this one, his graph you based on this error GC and he derive a new algorithm.",
                    "label": 0
                },
                {
                    "sent": "Put it online.",
                    "label": 0
                },
                {
                    "sent": "Oh, in the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, OK, so that's why you can see that this online one becomes oh error GC.",
                    "label": 0
                },
                {
                    "sent": "OK, just put it all onto this area or GCL algorithm.",
                    "label": 0
                },
                {
                    "sent": "What is this all means?",
                    "label": 0
                },
                {
                    "sent": "This all means online.",
                    "label": 0
                },
                {
                    "sent": "How do you do online?",
                    "label": 0
                },
                {
                    "sent": "If you look at the algorithm here inside, I actually do not quite like it style for the whole algorithm down there.",
                    "label": 0
                },
                {
                    "sent": "You know it's hard to read code, but you can see the key part is in the algorithm itself.",
                    "label": 0
                },
                {
                    "sent": "You see there's a four I from one 2T.",
                    "label": 0
                },
                {
                    "sent": "You'll get a 1 cent one labor at a time.",
                    "label": 0
                },
                {
                    "sent": "You do this on line and how do you do it?",
                    "label": 0
                },
                {
                    "sent": "You say you first do the prediction.",
                    "label": 0
                },
                {
                    "sent": "You predict this Y, get it, get it, get hacked, you predicted Y to see whether this.",
                    "label": 0
                },
                {
                    "sent": "Why is good.",
                    "label": 0
                },
                {
                    "sent": "It's wife.",
                    "label": 0
                },
                {
                    "sent": "It's your rear labor that line that you say receive the correct label.",
                    "label": 1
                },
                {
                    "sent": "That means you predict labor.",
                    "label": 0
                },
                {
                    "sent": "You receive the real labor.",
                    "label": 0
                },
                {
                    "sent": "You compare them to see it's good or bad.",
                    "label": 0
                },
                {
                    "sent": "OK, if your prediction is.",
                    "label": 0
                },
                {
                    "sent": "Inconsistent, that means I predicted this labor.",
                    "label": 0
                },
                {
                    "sent": "I gotta re labor, they're different.",
                    "label": 0
                },
                {
                    "sent": "If they're different, then I have to do something.",
                    "label": 0
                },
                {
                    "sent": "Update my model.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the algorithm that why is oh error GC OK, you do have this this.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Addiction using this, but those algorithms this he has lots of lemma and theorem and he proved them in their favor.",
                    "label": 0
                },
                {
                    "sent": "OK, if you want to read it you should read it, but I have no time to explain that.",
                    "label": 0
                },
                {
                    "sent": "Plus I did not read the proof.",
                    "label": 0
                },
                {
                    "sent": "You know in any detail.",
                    "label": 0
                },
                {
                    "sent": "I have to admit you know so.",
                    "label": 0
                },
                {
                    "sent": "But anyway, you probably know this is, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The philosophy what he got is.",
                    "label": 0
                },
                {
                    "sent": "In general, there is a bound.",
                    "label": 0
                },
                {
                    "sent": "This M. There's a bounded by this formula.",
                    "label": 0
                },
                {
                    "sent": "There are two things you provide.",
                    "label": 0
                },
                {
                    "sent": "No one thing is efficiency.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "One thing is the mistakes you will get with this bound.",
                    "label": 0
                },
                {
                    "sent": "He basically proof if the original area or GC algorithm is good.",
                    "label": 0
                },
                {
                    "sent": "OK, then you do.",
                    "label": 0
                },
                {
                    "sent": "Online learning is also good.",
                    "label": 0
                },
                {
                    "sent": "OK, they have some correlation.",
                    "label": 0
                },
                {
                    "sent": "The better of the offline one, the smaller arrow of the online one.",
                    "label": 1
                },
                {
                    "sent": "OK, of course you proceed.",
                    "label": 0
                },
                {
                    "sent": "This is of course OK, but he did have some serious proof on this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. That's his online algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now we look.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get his active learning part is the selective sampling part.",
                    "label": 0
                },
                {
                    "sent": "The selective sampling para means.",
                    "label": 0
                },
                {
                    "sent": "On line.",
                    "label": 0
                },
                {
                    "sent": "They get they give me sample one at a time.",
                    "label": 0
                },
                {
                    "sent": "I because of the experts is so expensive.",
                    "label": 0
                },
                {
                    "sent": "I dare not ask labels.",
                    "label": 0
                },
                {
                    "sent": "OK, that means you give me so many.",
                    "label": 0
                },
                {
                    "sent": "You get a stream of the nodes coming.",
                    "label": 0
                },
                {
                    "sent": "I dare not to ask.",
                    "label": 0
                },
                {
                    "sent": "The reason is I asked to pay more OK then I only find somebody I really want to ask labor.",
                    "label": 0
                },
                {
                    "sent": "That's the time I would ask.",
                    "label": 0
                },
                {
                    "sent": "So the trick becomes when I'm going to ask.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So then he basically workout this method.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Workout this method philosophy is he you try to predict something, but you have certain confidence.",
                    "label": 0
                },
                {
                    "sent": "OK, that means you have some estimation.",
                    "label": 0
                },
                {
                    "sent": "The escalation has some bias.",
                    "label": 0
                },
                {
                    "sent": "The bias have some bound.",
                    "label": 0
                },
                {
                    "sent": "If this bias bound is too big, the simply says I actually really do not know the labor.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the time I'm going to ask.",
                    "label": 0
                },
                {
                    "sent": "OK, you Percy, the philosophy is every time I do not ask expert, I actually do some computation on my own so I know how confident this guy I can get the label if I'm not confident and stop bugging the experts, give me the label.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I don't.",
                    "label": 0
                },
                {
                    "sent": "So that's the philosophy.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this philosophy, he just changed the code a little, so then you can see you know what things done.",
                    "label": 0
                },
                {
                    "sent": "Here he calculate not only the predicted labor, yhat.",
                    "label": 0
                },
                {
                    "sent": "Yeah, he also calculate that bond.",
                    "label": 0
                },
                {
                    "sent": "You see that bond is greater than certain threshold.",
                    "label": 0
                },
                {
                    "sent": "That means I really do not know what is a labor I have.",
                    "label": 0
                },
                {
                    "sent": "I have very vague idea.",
                    "label": 0
                },
                {
                    "sent": "I can be confident then that's the time I call it.",
                    "label": 0
                },
                {
                    "sent": "This happens is the same as what I guess I do nothing OK, but if it happens it's different.",
                    "label": 0
                },
                {
                    "sent": "Then I have to update my model.",
                    "label": 0
                },
                {
                    "sent": "OK see that's the trick.",
                    "label": 0
                },
                {
                    "sent": "Once you get this trick.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He also get lots of lemmas and theorems and try to prove OK, but I will not go over this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The good thing you would look at the conclusion.",
                    "label": 0
                },
                {
                    "sent": "OK, the good thing is the first thing is the time complexity is low.",
                    "label": 0
                },
                {
                    "sent": "OK, you can see.",
                    "label": 0
                },
                {
                    "sent": "Gotta log T once again log you or your Life OK, because you you gotta longer rhythmic complexity.",
                    "label": 0
                },
                {
                    "sent": "The car part is actually the ratio.",
                    "label": 0
                },
                {
                    "sent": "This learning ratio OK if you have to get lots of things, it's not good.",
                    "label": 0
                },
                {
                    "sent": "You get lots of Labor.",
                    "label": 0
                },
                {
                    "sent": "The ratio is high, is not good, but if it's a cover it slow, so the cost is very low.",
                    "label": 0
                },
                {
                    "sent": "The second thing is.",
                    "label": 0
                },
                {
                    "sent": "He basically say you get a larger koppa you actually get it.",
                    "label": 0
                },
                {
                    "sent": "You know more confidence, more nodes you'll get, but of course you pay more.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we look at the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's the experiments he did is he got a four datasets coauthor, which actually from the BRP, but he gotta subsets, RDB RP.",
                    "label": 0
                },
                {
                    "sent": "You got 1700 authors, OK?",
                    "label": 0
                },
                {
                    "sent": "Then get at the edge of the graphs.",
                    "label": 0
                },
                {
                    "sent": "The other one is Cora.",
                    "label": 0
                },
                {
                    "sent": "Cora actually is a scientific publication.",
                    "label": 0
                },
                {
                    "sent": "He got it like 2000.",
                    "label": 0
                },
                {
                    "sent": "You know two or three thousand.",
                    "label": 0
                },
                {
                    "sent": "You know these papers, the servants IMDb, which is movie database.",
                    "label": 0
                },
                {
                    "sent": "The last one is Pub Madison Medical publication.",
                    "label": 0
                },
                {
                    "sent": "One he got a much longer, much bigger way.",
                    "label": 0
                },
                {
                    "sent": "You can see one in 90.",
                    "label": 0
                },
                {
                    "sent": "No 19,000 something.",
                    "label": 0
                },
                {
                    "sent": "OK, so with 44,000.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thanks now his experiments basically calculate these several things.",
                    "label": 0
                },
                {
                    "sent": "One thing is accumulated error rate.",
                    "label": 1
                },
                {
                    "sent": "We know the error, the lower arrow the classification is better.",
                    "label": 1
                },
                {
                    "sent": "That's of course the second one is the number of query labels.",
                    "label": 0
                },
                {
                    "sent": "Let me ask experts, you ask less.",
                    "label": 0
                },
                {
                    "sent": "You're better then the third one is accumulating computation time.",
                    "label": 0
                },
                {
                    "sent": "Of course you take less time to compute.",
                    "label": 1
                },
                {
                    "sent": "It's better, so everything is the lower the better.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now he just showed show he comparing three algorithms.",
                    "label": 0
                },
                {
                    "sent": "Why is graph perception algorithm GPA another?",
                    "label": 0
                },
                {
                    "sent": "Is all air air GCS as his algorithm just online one.",
                    "label": 0
                },
                {
                    "sent": "The last one is sampling, 1S SLG.",
                    "label": 0
                },
                {
                    "sent": "Is sampling one?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "So you pharisee.",
                    "label": 0
                },
                {
                    "sent": "Here's online version.",
                    "label": 0
                },
                {
                    "sent": "An active learning version.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now you look at the results.",
                    "label": 0
                },
                {
                    "sent": "The results?",
                    "label": 0
                },
                {
                    "sent": "These are the two results ones on Coop.",
                    "label": 0
                },
                {
                    "sent": "OK so the interesting thing is you look at the error rate.",
                    "label": 1
                },
                {
                    "sent": "The error rate actually oh error GC is somewhat better, it's the best you privacy but as error GC is very close, very close means I use selective sampling.",
                    "label": 1
                },
                {
                    "sent": "I almost can compete with you.",
                    "label": 0
                },
                {
                    "sent": "Ask everything you get.",
                    "label": 0
                },
                {
                    "sent": "On line one, you ask all the labels.",
                    "label": 0
                },
                {
                    "sent": "Then you look at the labor and the number of query nodes and that means you ask experts how many times.",
                    "label": 0
                },
                {
                    "sent": "Then you'll see the last row is always the best because you always ask less queries to experts.",
                    "label": 0
                },
                {
                    "sent": "You get almost the same performance on the error rates as online version, and it's better than GPA GPA.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same thing happens for IMDb and Pub Med.",
                    "label": 0
                },
                {
                    "sent": "You'll probably see this is also very, very obvious because the pub Med Wipro can see you get a 19,000 queries.",
                    "label": 0
                },
                {
                    "sent": "You ask 19,000 labels, but this one is five son laborers, right?",
                    "label": 0
                },
                {
                    "sent": "So the computation time?",
                    "label": 0
                },
                {
                    "sent": "Of course the GPA because you don't really doing this online, one asked the other the computation time.",
                    "label": 0
                },
                {
                    "sent": "Wise GPA is always the best.",
                    "label": 0
                },
                {
                    "sent": "Spend a little more time, but it would get benefit, right?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then he looked the car part.",
                    "label": 0
                },
                {
                    "sent": "The impact of copper.",
                    "label": 0
                },
                {
                    "sent": "That means if I get more and more things, I almost, you know, get all the labels.",
                    "label": 0
                },
                {
                    "sent": "You know, the ratio on the acquired acquiring labor.",
                    "label": 0
                },
                {
                    "sent": "Of course, in general we get better, but actually, once you only ask 0.4 zero point 5, you almost reach the lower one, so the carpet does not need to be very high.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the summary actually is saying this is on line learning with local and global consistency.",
                    "label": 1
                },
                {
                    "sent": "And he basically say he did have two algorithms.",
                    "label": 0
                },
                {
                    "sent": "Why is online version?",
                    "label": 1
                },
                {
                    "sent": "Why is active learning selective sampling version both looks good.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}