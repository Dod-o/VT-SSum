{
    "id": "c6jpbmwedj73l3jtt6jkizhlf3hnhlmm",
    "title": "Fast Approximate A-box Consistency Checking using Machine Learning",
    "info": {
        "author": [
            "Heiko Paulheim, Institut f\u00fcr Informatik, University of Mannheim"
        ],
        "published": "July 28, 2016",
        "recorded": "May 2016",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2016_paulheim_efficient_approximation/",
    "segmentation": [
        [
            "When I when I check the program and saw that it's a highly debated paper was like wow.",
            "I always wanted one of those.",
            "Yeah and next second I got a bit scared like what if there is an in discussions going on and people throwing like leftover vegetables from the lunch buffet at me.",
            "And so since I got a bit scared I made a last minute decision to slightly change the topic of this talk and rather choose a less controversial topic today which is."
        ],
        [
            "How learning to play jazz improvisation on the piano?",
            "I think that's controversial.",
            "No vegetables in throne.",
            "OK, so.",
            "Yeah, I was starting to learn the piano at the age of maybe 8, seven or eight.",
            "Yep, train train classical piano for a few years and then my early teenage years I got a bit bored, light plane, and Haydn and Mozart all the time.",
            "And I want to to move on and try something different and the final teacher who offered me to to learn improvisation, playing and in particular jazz improvisation playing so."
        ],
        [
            "How do you learn these things?",
            "Music and some music like notated and sheets comes with chord progressions.",
            "An there are different music scales which are subsets of all the notes you can potentially play.",
            "They form scales and different scales fit different calls, and those scales are comprised of notes and then what you learn essentially is all this theory.",
            "Like.",
            "Once you've learned this theory, you get a sheet of music like that and play along with some people.",
            "You look at the chord progressions and then you see OK. Maybe there is now I don't know progression from a major 7 two F# minor, you name it and then you look at it and you remember.",
            "OK there could play like the F minor.",
            "Dorian scale and think of which notes are in the scale and then you start picking some notes from those scales and play them.",
            "This is essentially how it works in the beginning, but it's just half of the story.",
            "OK, I will tell you the rest of the story in a minute, but then.",
            "I mean, I didn't know that at the time when I learned that as a teenager in the early 90s, but essentially this is an ontology, right?",
            "So we have an autology of music system for the whole music system, so you have courts.",
            "Courts are comprised of note scales are comprised of notes, scales match certain courts, and courts come in major and minor and all variations.",
            "And, um, once you've got that ontology and you learned all this, all this stuff and essentially what you do when you play improvisation as a reasoning task.",
            "So you are given a chord progression and then you use that theory.",
            "You use that ontology to infer the matching nodes.",
            "This essentially what you do, and then once you've got these, the result set back, you pick some of those notes and play them, and hopefully they fit OK.",
            "This is Howard."
        ],
        [
            "It works in theory.",
            "Of course you don't do that in your head.",
            "You don't run a reason there.",
            "The reason for that is it slow, right?",
            "If I did that every time I played with some people, if I if I had to remember this, this really thinking OK, this is Discord.",
            "Uh-huh that's matches that scale.",
            "That scale is comprised of those calls.",
            "Hey guys, where are you?",
            "I've got the result now, so this is not how it works."
        ],
        [
            "So essentially you need to do something different instead of doing all this formal reasoning in your head and what you do is essentially in the end you use some approximate model in your hat that is faster that is also not free of arrows in most of the time, so sometimes you may do something which is not exactly as it's written down to the theory.",
            "But then again, hey, it's Jess.",
            "Come on, it's a blue note.",
            "OK, but this is how it would work so."
        ],
        [
            "I told you about half the story to learn all that Thierry and then this is what you do in the 1st place.",
            "So you learn everything about chords and scales and notes and which courts which which scales and which notes are contained in which scales and so on and so forth.",
            "And then you play any playing and playing.",
            "After awhile you forget all about that and then what happened is you have you had the original theory and then after a while you have an approximation of that theory in your head which is much faster, which is simpler.",
            "Which is also not correct in every every piece and every every corner of the model, but it's fast enough to do real time processing to do real time playing, so this is what you need here.",
            "OK."
        ],
        [
            "So what what's been done there?",
            "What's happening in your heart is in the 1st place.",
            "You had a real formal system of formal theory that, but you did the reasoning on like you see the court, you you try to remember which scale is filling and so on and so forth.",
            "And after awhile you would sort of imitate that model by something simpler, but something more approximate.",
            "So the question that we asked ourselves for this paper is can we can we do that also for ontology reasoning?",
            "Can we like observer reasoner for awhile and then try to imitate the reasoner and do this imitation with an approximate model which is much simpler than the original reasoning process?",
            "So the setup here is we just use a reasoner and observe it for awhile.",
            "So we give it inputs.",
            "We look at what it does as outputs and then we collect those pairs of inputs and outputs.",
            "So for example, you give the reason there are some some data you see the conclusions and then you have the input and the output, and then you feed both of those inputs and output pairs into a machine learning model.",
            "And in the end used a fast machine learning model instead of the slow reasoner.",
            "That's the plan.",
            "Alright, so in this paper we restrict ourselves to 21 reasoning tasks, which is a box consistency checking.",
            "So in terms of machine learning, that's a binary classification task.",
            "So the input is in a box and a tee box, and the output is labeled which says is consistent or it's not consistent, so it's a binary classification problem, and that's actually a pretty pretty straightforward problem to solve with machine learning algorithms."
        ],
        [
            "Some assumptions here, so the first assumption is we we want to do this many times for the same tee box.",
            "So we have a lot of a boxes and we want to perform this consistency check using the same tee box.",
            "So in that case it may make sense to learn a model which is specific for this tee box, but which is essentially what happens here and it actually it's both the worth the effort of learning a model which is specific for this tee box because we have to run through this thing many many times.",
            "The other assumption is that we don't need 100% accuracy.",
            "Sometimes when you do reasoning, you need perfectly complete and sound results, sometimes you don't.",
            "So there are papers which say we use reasoning information retrieval or reasoning in recommender systems.",
            "I mean, none of those actually need 100% accuracy.",
            "You can perfectly live with 95 in those cases, right?",
            "On the other hand, you want real time results if you do product recommendation, you don't want to wait one to wait for a reason there for two minutes to finish to compute the recommendation.",
            "You want the recommendation in real time while the user's browsing, so this is the sort of tradeoff we have here.",
            "We don't need 100% accuracy, but we need fast results.",
            "And another assumption is that if we do that, if you do that approximation, I mean at some point at some point there is the cost, right?",
            "And we assume that larger parts of the ontology may actually not be needed by the reason for the majority of the cases, and same maybe for language expressivity.",
            "We've done some, we've done some empirix on the deployment of schema.org last year, and then we saw like half of the schema.org vocabulary is never used.",
            "On the web, it's just there.",
            "I mean that you find the classes that you find the properties nobody actually uses them, so half of the ontology is never ever used.",
            "So actually, the reason that doesn't need it.",
            "If you know up front, that's great.",
            "You can just remove it.",
            "If you don't know upfront what is needed for an inference, it's not so easy, but the assumption is at least larger parts may be neglectable."
        ],
        [
            "OK, so here's what we what we do.",
            "First of all, we use.",
            "As I said, we want to observe the reason there and imitate what is what it's doing.",
            "So in the 1st place we obtain some label training data, we give a boxes to a reasoner.",
            "We let it compute the consistency.",
            "We collect the label together with the A box, and then we use that as label training data.",
            "Then we feed that into machine learning classifiers, saying this is the a box.",
            "And now the reason that can say it's the reason I said it's true or false.",
            "So consistent, inconsistent and then build a binary classifier out of that.",
            "And then we use that learn model as an approximation for the reason around the validation of the result is actually quite straightforward, because you can just use test data and run a reason or two to validate what the machine learning classifier says.",
            "So you can easily compute the quality of the classifier.",
            "OK, um, one thing we need to do is that most machine learning classifiers, at least those that come out of the box and frameworks such as rapid miner or worker.",
            "They need propositional forms, so they need vector vectors of data.",
            "They usually don't work on a boxes which are graph, so we need some transformation which is done in this box here which says feature Vector Builder."
        ],
        [
            "What we use some variant of something called root path kernels, also known as what kernels they have been introduced here at this conference and four years ago.",
            "I think the paper also wanted us paperwork back.",
            "Now we use a slight variation of this because we said we actually not interested in the values of literals.",
            "As such, we're just interested in the data type because the value of a literal which string is there.",
            "If it's string X or Y actually doesn't doesn't change anything on whether the box is consistent or not, but the fact is whether there is a string or a number.",
            "Can actually change the consistency, so as long as you don't have data type rain, just this is the I think more appropriate choice here.",
            "OK, so what's happening is assume you have an RDF graph like that.",
            "Essentially for each node in the graph you compute all the paths that you can take from this from this node up to a certain length, and then these are used as features.",
            "So if you can take that given path from the node down, the feature gets the value one.",
            "If it's.",
            "If you cannot take the given power from that particular node, then the feature gets the value 0.",
            "So these are all the possible ways you can take through the path you can take through the graph up to a length of two and then for each node in the graph you can say cannot take this path or not and the feature set for one a boxes down the Union of all those, all those paths for all the nodes that you can take in this a box.",
            "So this is how we describe in a box as a set of binary features.",
            "And then we have everything we need to feed that into a machine learning classifier.",
            "We have the instance described as a set of binary features.",
            "We have the output label described as a binary feature, and then we can train a machine."
        ],
        [
            "Learning model on that.",
            "OK."
        ],
        [
            "We need data to evaluate on and we use four different datasets.",
            "Here one is we want to validate individual relation assertions and DB pedia.",
            "So we use a relation assertion and pedia plus all the types of the subject plus all the types of the object and then see is that is that particular relation assertion between these two entities.",
            "It consistent with the ontology or not.",
            "And since DB pedia itself does not define too many class disjointness is which makes it hard to discover inconsistencies.",
            "We use an extension of.",
            "Using also the mappings to Dulcer, which comes with a number of high level high level disjointed statements.",
            "I have an example on the next slide, then we do the same with Thiago, so in Jago be used individuals plus their types and also use the Delta top level ontology for top level distances.",
            "Then we look at our DFA.",
            "Our DFA documents be collected from the Web from App Data Commons and validate them against the Good Relations Ontology.",
            "So we collect all the audio fade documents from the web.",
            "Data comes corpus that use.",
            "Good relations and validate them against the ontology.",
            "And then be used the same with schema.org.",
            "So we use all the microdata documents that use schema.org out on the web, like 300 million documents and then check them against the Schema Dog Ontology as the schema.org on teologi itself does not come with the joint assist.",
            "We added some by hand.",
            "I will show you them on one of the subsequent slides, so here's one."
        ],
        [
            "Example for this DB pedia TV PDF plus dulcer data set.",
            "So we have this statement in DB Pedia.",
            "I think it's still in the.",
            "It's even there in the current version so that Tim Berners Lee got the award Royal SoC and then, you know that Royal Society is an organization, but award has the range award, and then you look at the top level assertions.",
            "Indulgence E Organization is a Social Agent award as a description and descriptions, and social agents are disjoint, so this statement is clearly inconsistent with the ontology.",
            "And this is the data set we use for the pedia with Jago, it's pretty much equivalent that we also use.",
            "Disjointness is used from Dalton OK."
        ],
        [
            "This is the.",
            "This is the data set we modified for schema.orgschema.org comes with nine top level classes and we just looked at all the pairs of those classes and the intention of those classes and see are they disjoint or not.",
            "So in action cannot be a productive place or person at the same time and so on.",
            "There were two cases where we thought they are intentionally disjoint, but actually there are subclasses of both classes, so in those cases we don't introduce the disjointness in order not to make the whole thing.",
            "Inconsistent so one both medical entity and creative work.",
            "We thought they should be disjoint, but there are things which are diet plans which are subclasses of both.",
            "The other is organization and place, which we thought should be should be disjoint.",
            "Buttinsky madaka.",
            "Local businesses like a Starbucks around the corner is both the subclass of place and.",
            "Place an organization here and therefore you cannot make them disjoint without making the whole T box invalid.",
            "So this is the number of disjoint sections we added.",
            "For ski monologue you can get all the data from the Web we published both the of the datasets we use plus also this modified schema.org ontology."
        ],
        [
            "OK then, for each of those four datasets we created three variants coming with 11111 and 1111 boxes.",
            "The reason for those numbers is that we want to inspect it.",
            "How good does a model get if we train or let's say 100 or 1000 instances?",
            "And since we want to do that in 10 fold cross validation, we need those order numbers saying 1111.",
            "So you train on 1000 and then you evaluate on the remaining 111, repeat that 10 times.",
            "You see that the data sets are not overly skewed, so this is the percentage of consistent eh boxes in the respective datasets.",
            "So for the pedia you have like not 8586% of the boxes being consistent, and this is the most skewed one.",
            "The other ones are slightly more balanced.",
            "You also see that the number of features increases, sometimes moderately, sometimes quite dramatically for ya go for the 1000 data set, you have a data set of like 4000 something features.",
            "But it's still.",
            "It's still manageable, for the reason that we use for ground truth.",
            "We use the Hermit reasoner, which gives us the which gives us the labels of true and false, and we also use that to produce the ground truth for evaluation.",
            "The reason is that you cannot, for some reason, load the DB pedia plus dollar extension in pellet breaks.",
            "For some reason.",
            "This is why we chose Hermit.",
            "Just a practical decision."
        ],
        [
            "OK, we used four different classifiers implemented in rapid miner and the vector extension of Rapidminer.",
            "We just use them in standard settings because we just wanted to know whether this works at all.",
            "We just wanted proof of concept beyond we didn't want to squeeze out the last bit of performance there, but you can observe is that if you use 1000 training examples you always get over 95% accuracy.",
            "So you gather model which does the right thing in 19 or 20 cases.",
            "And in general, decision trees give you the best results except for the DB Pedia case.",
            "For support, vector machines are slightly better.",
            "And the surprising thing is, if you look at those decision trees, they are really small, so they are never.",
            "We never observed the decision tree larger than 20 notes for these problems, which is really a bit of a surprise.",
            "So here's an example for for the pedia.",
            "So this is the decision tree that can decide whether to whether a statement and the pedia, along with the subject and object type is consistent with the ontology or not it it's not larger than that there are."
        ],
        [
            "Several reasons for these decision trees being so small on the main one is that the inconsistency is they are.",
            "They are heavily skewed, Lee distributed, so they're not equally distributed, but there are some some classes and some relations which are really responsible for the majority of inconsistencies.",
            "And since the machine learning model focuses on the majority of the cases, and the cases are so unequally distributed, you get very small models that still perform quite well in the end.",
            "OK, and then we were asking ourselves how long would it take now.",
            "So one thing is OK, it works.",
            "You get to a decent accuracy, that's good.",
            "The other thing the other claim was you are much faster than using an actual reasoner."
        ],
        [
            "So we also."
        ],
        [
            "Self, how long would it take to to do this with all the statements that aren't pedia, which are 15 million with all the instances in Jago, roughly 3 million all audio documents that use good relations round roughly 350,000 and all microdata documents using schema.org and it's 300 million.",
            "You can already mention validating 300 million different boxes with the reason it can take some time question is how much faster can we actually get?",
            "Salem to to extrapolate these numbers.",
            "Estimate what we did is.",
            "We looked at the number of a boxes and the time it takes to to build a feature vector out of in a box.",
            "We have to do that for all the boxes.",
            "Then we have the time it takes to train the actual model and then for the remaining a boxes.",
            "Except for those which we already classified for training.",
            "So this is the remaining boxes minus 1000.",
            "We need the time it takes to classify and a box with our model.",
            "And this this sum gives us the estimated time it would take with our model to to run this.",
            "Sort of thing.",
            "OK um.",
            "He will see on the the time it takes for 1000 instances using the reasoner and then this TF time.",
            "So the time to build the features, the time for training the classifier which is below is second and the time for classification, which is almost neglectable.",
            "So this number is really, really small.",
            "The majority of time is spent transforming and a box into a feature vector."
        ],
        [
            "Then if you look at the estimated numbers for all a boxes, so for Hermit for if you look at schema.org, these 300 million documents, for example, it would take 1.5 million seconds with our train model.",
            "So the sum of this it's 4100 seconds.",
            "So if you if you have difficulty imagining 1.5 million seconds, that's roughly 18 days.",
            "Where is our model would take 1 1/2 hours, so this is the order of magnitude that we get faster here."
        ],
        [
            "Right, so the summary of our findings is that you can just ask of a box consistency checking.",
            "You can approximate it quite well with this sort of approach, and if you train decision trees with 1000 labeled examples, you get to not always get above 95% accuracy, which is a pretty good result.",
            "The decision trees we learn are in fact pretty small, so you saw this example.",
            "We never observed the decision tree larger than 20 nodes.",
            "Just makes it pretty interesting to apply that sort of model in complete computation limited settings.",
            "So imagine you want to do approximate reasoning.",
            "Let's say on the sensor it's not a big problem to to use this decision tree and load it onto a sensor.",
            "You cannot load a full fledged ontology reason on a sensor, but I mean this.",
            "This model, which just takes.",
            "I don't know a few bites, a few kilobytes in memory at Max, so you can easily load it on a very small device, so smart devices and sensors are can be well equipped with these approximate models.",
            "And we saw that the approximation is really highly scalable, so you saw that microdata examples, where the reason they would take 18 days to to process all those boxes and we can do it in 90 minutes.",
            "So the question is, why does it work so well?",
            "So the learned models they concentrate on the relevant fragments of the ontology, so the ones that are important for the majority of the cases and the other reason is that the reasons for inconsistencies are not equally distributed across the concepts in the ontology and so learned models really adapt to the most frequent inconsistencies and try to try to respect those."
        ],
        [
            "So some things we want to try in the future.",
            "One thing is you can actually you saw that the transformation to feature vectors is the stuff that actually takes takes most time and you don't have to do it that way actually.",
            "So once you've learned the decision tree, you can just just translate this decision tree into a set of sparkle tests for example and fire them directly to the A box.",
            "You don't need the transformation to a feature vector anymore.",
            "Um, another thing where you could use that is the task of ontology summarization.",
            "So you learn these models.",
            "You saw that reason.",
            "You see the concepts that are used in the trees, and obviously these are the ones that are important for most reasoning test.",
            "So this should give you a starting points for summarizing ontologies and identifying the key relevant concepts in ontology.",
            "So far what we did is we just predicted consistent or inconsistent, but we do not do is giving any explanation why something is inconsistent.",
            "I mean you could try to read that from the path and the decision tree taken.",
            "For example, it would be interesting to see whether that corresponds to the explanation.",
            "An actual reason that would give.",
            "You could also think about trying to learn a model that predicts the explanation as such.",
            "So there are works on structured predictions where you don't predict a single button structure like a graph.",
            "And so you could try to learn predicting a tree that that shows the explanation for the inconsistency.",
            "And um, yeah.",
            "So so far I just said OK we used 1000 training examples and maybe that's not the end of the story so we're currently running some experiments on selecting those examples more effectively and minimizing the invocations of an actual reason is so if you use active learning, then the learner can itself decide whether it wants to have the example labeled by the reason or whether it is OK with not labeling the example and there you can.",
            "You can already see in the 1st results that you can limit number of.",
            "Reason the calls without sacrificing too much the effectiveness of the overall approach.",
            "OK, and in the end I mean, so far the evaluation has been purely purely empirical, but we also want to look at more systematically is what is the interplay between how to represent features.",
            "We just use this one method at the moment to represent features.",
            "Does it somehow interplay with the complexity of the ontology?",
            "Does it somehow interact with the paradigm useful learning, analyzing these things more systematically would be quite fascinating, because so far we just have this empirical evaluation alright."
        ],
        [
            "Man no, I'm open for questions, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When I when I check the program and saw that it's a highly debated paper was like wow.",
                    "label": 1
                },
                {
                    "sent": "I always wanted one of those.",
                    "label": 0
                },
                {
                    "sent": "Yeah and next second I got a bit scared like what if there is an in discussions going on and people throwing like leftover vegetables from the lunch buffet at me.",
                    "label": 0
                },
                {
                    "sent": "And so since I got a bit scared I made a last minute decision to slightly change the topic of this talk and rather choose a less controversial topic today which is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How learning to play jazz improvisation on the piano?",
                    "label": 1
                },
                {
                    "sent": "I think that's controversial.",
                    "label": 0
                },
                {
                    "sent": "No vegetables in throne.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I was starting to learn the piano at the age of maybe 8, seven or eight.",
                    "label": 0
                },
                {
                    "sent": "Yep, train train classical piano for a few years and then my early teenage years I got a bit bored, light plane, and Haydn and Mozart all the time.",
                    "label": 0
                },
                {
                    "sent": "And I want to to move on and try something different and the final teacher who offered me to to learn improvisation, playing and in particular jazz improvisation playing so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do you learn these things?",
                    "label": 0
                },
                {
                    "sent": "Music and some music like notated and sheets comes with chord progressions.",
                    "label": 1
                },
                {
                    "sent": "An there are different music scales which are subsets of all the notes you can potentially play.",
                    "label": 0
                },
                {
                    "sent": "They form scales and different scales fit different calls, and those scales are comprised of notes and then what you learn essentially is all this theory.",
                    "label": 1
                },
                {
                    "sent": "Like.",
                    "label": 0
                },
                {
                    "sent": "Once you've learned this theory, you get a sheet of music like that and play along with some people.",
                    "label": 0
                },
                {
                    "sent": "You look at the chord progressions and then you see OK. Maybe there is now I don't know progression from a major 7 two F# minor, you name it and then you look at it and you remember.",
                    "label": 0
                },
                {
                    "sent": "OK there could play like the F minor.",
                    "label": 0
                },
                {
                    "sent": "Dorian scale and think of which notes are in the scale and then you start picking some notes from those scales and play them.",
                    "label": 0
                },
                {
                    "sent": "This is essentially how it works in the beginning, but it's just half of the story.",
                    "label": 0
                },
                {
                    "sent": "OK, I will tell you the rest of the story in a minute, but then.",
                    "label": 0
                },
                {
                    "sent": "I mean, I didn't know that at the time when I learned that as a teenager in the early 90s, but essentially this is an ontology, right?",
                    "label": 0
                },
                {
                    "sent": "So we have an autology of music system for the whole music system, so you have courts.",
                    "label": 0
                },
                {
                    "sent": "Courts are comprised of note scales are comprised of notes, scales match certain courts, and courts come in major and minor and all variations.",
                    "label": 0
                },
                {
                    "sent": "And, um, once you've got that ontology and you learned all this, all this stuff and essentially what you do when you play improvisation as a reasoning task.",
                    "label": 0
                },
                {
                    "sent": "So you are given a chord progression and then you use that theory.",
                    "label": 0
                },
                {
                    "sent": "You use that ontology to infer the matching nodes.",
                    "label": 0
                },
                {
                    "sent": "This essentially what you do, and then once you've got these, the result set back, you pick some of those notes and play them, and hopefully they fit OK.",
                    "label": 0
                },
                {
                    "sent": "This is Howard.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It works in theory.",
                    "label": 0
                },
                {
                    "sent": "Of course you don't do that in your head.",
                    "label": 0
                },
                {
                    "sent": "You don't run a reason there.",
                    "label": 0
                },
                {
                    "sent": "The reason for that is it slow, right?",
                    "label": 0
                },
                {
                    "sent": "If I did that every time I played with some people, if I if I had to remember this, this really thinking OK, this is Discord.",
                    "label": 0
                },
                {
                    "sent": "Uh-huh that's matches that scale.",
                    "label": 0
                },
                {
                    "sent": "That scale is comprised of those calls.",
                    "label": 0
                },
                {
                    "sent": "Hey guys, where are you?",
                    "label": 0
                },
                {
                    "sent": "I've got the result now, so this is not how it works.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So essentially you need to do something different instead of doing all this formal reasoning in your head and what you do is essentially in the end you use some approximate model in your hat that is faster that is also not free of arrows in most of the time, so sometimes you may do something which is not exactly as it's written down to the theory.",
                    "label": 0
                },
                {
                    "sent": "But then again, hey, it's Jess.",
                    "label": 0
                },
                {
                    "sent": "Come on, it's a blue note.",
                    "label": 0
                },
                {
                    "sent": "OK, but this is how it would work so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I told you about half the story to learn all that Thierry and then this is what you do in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "So you learn everything about chords and scales and notes and which courts which which scales and which notes are contained in which scales and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then you play any playing and playing.",
                    "label": 0
                },
                {
                    "sent": "After awhile you forget all about that and then what happened is you have you had the original theory and then after a while you have an approximation of that theory in your head which is much faster, which is simpler.",
                    "label": 0
                },
                {
                    "sent": "Which is also not correct in every every piece and every every corner of the model, but it's fast enough to do real time processing to do real time playing, so this is what you need here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what what's been done there?",
                    "label": 0
                },
                {
                    "sent": "What's happening in your heart is in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "You had a real formal system of formal theory that, but you did the reasoning on like you see the court, you you try to remember which scale is filling and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And after awhile you would sort of imitate that model by something simpler, but something more approximate.",
                    "label": 0
                },
                {
                    "sent": "So the question that we asked ourselves for this paper is can we can we do that also for ontology reasoning?",
                    "label": 0
                },
                {
                    "sent": "Can we like observer reasoner for awhile and then try to imitate the reasoner and do this imitation with an approximate model which is much simpler than the original reasoning process?",
                    "label": 0
                },
                {
                    "sent": "So the setup here is we just use a reasoner and observe it for awhile.",
                    "label": 0
                },
                {
                    "sent": "So we give it inputs.",
                    "label": 0
                },
                {
                    "sent": "We look at what it does as outputs and then we collect those pairs of inputs and outputs.",
                    "label": 1
                },
                {
                    "sent": "So for example, you give the reason there are some some data you see the conclusions and then you have the input and the output, and then you feed both of those inputs and output pairs into a machine learning model.",
                    "label": 0
                },
                {
                    "sent": "And in the end used a fast machine learning model instead of the slow reasoner.",
                    "label": 1
                },
                {
                    "sent": "That's the plan.",
                    "label": 1
                },
                {
                    "sent": "Alright, so in this paper we restrict ourselves to 21 reasoning tasks, which is a box consistency checking.",
                    "label": 0
                },
                {
                    "sent": "So in terms of machine learning, that's a binary classification task.",
                    "label": 1
                },
                {
                    "sent": "So the input is in a box and a tee box, and the output is labeled which says is consistent or it's not consistent, so it's a binary classification problem, and that's actually a pretty pretty straightforward problem to solve with machine learning algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some assumptions here, so the first assumption is we we want to do this many times for the same tee box.",
                    "label": 0
                },
                {
                    "sent": "So we have a lot of a boxes and we want to perform this consistency check using the same tee box.",
                    "label": 0
                },
                {
                    "sent": "So in that case it may make sense to learn a model which is specific for this tee box, but which is essentially what happens here and it actually it's both the worth the effort of learning a model which is specific for this tee box because we have to run through this thing many many times.",
                    "label": 0
                },
                {
                    "sent": "The other assumption is that we don't need 100% accuracy.",
                    "label": 1
                },
                {
                    "sent": "Sometimes when you do reasoning, you need perfectly complete and sound results, sometimes you don't.",
                    "label": 0
                },
                {
                    "sent": "So there are papers which say we use reasoning information retrieval or reasoning in recommender systems.",
                    "label": 0
                },
                {
                    "sent": "I mean, none of those actually need 100% accuracy.",
                    "label": 0
                },
                {
                    "sent": "You can perfectly live with 95 in those cases, right?",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you want real time results if you do product recommendation, you don't want to wait one to wait for a reason there for two minutes to finish to compute the recommendation.",
                    "label": 0
                },
                {
                    "sent": "You want the recommendation in real time while the user's browsing, so this is the sort of tradeoff we have here.",
                    "label": 0
                },
                {
                    "sent": "We don't need 100% accuracy, but we need fast results.",
                    "label": 0
                },
                {
                    "sent": "And another assumption is that if we do that, if you do that approximation, I mean at some point at some point there is the cost, right?",
                    "label": 0
                },
                {
                    "sent": "And we assume that larger parts of the ontology may actually not be needed by the reason for the majority of the cases, and same maybe for language expressivity.",
                    "label": 1
                },
                {
                    "sent": "We've done some, we've done some empirix on the deployment of schema.org last year, and then we saw like half of the schema.org vocabulary is never used.",
                    "label": 0
                },
                {
                    "sent": "On the web, it's just there.",
                    "label": 0
                },
                {
                    "sent": "I mean that you find the classes that you find the properties nobody actually uses them, so half of the ontology is never ever used.",
                    "label": 0
                },
                {
                    "sent": "So actually, the reason that doesn't need it.",
                    "label": 0
                },
                {
                    "sent": "If you know up front, that's great.",
                    "label": 0
                },
                {
                    "sent": "You can just remove it.",
                    "label": 0
                },
                {
                    "sent": "If you don't know upfront what is needed for an inference, it's not so easy, but the assumption is at least larger parts may be neglectable.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's what we what we do.",
                    "label": 0
                },
                {
                    "sent": "First of all, we use.",
                    "label": 0
                },
                {
                    "sent": "As I said, we want to observe the reason there and imitate what is what it's doing.",
                    "label": 0
                },
                {
                    "sent": "So in the 1st place we obtain some label training data, we give a boxes to a reasoner.",
                    "label": 0
                },
                {
                    "sent": "We let it compute the consistency.",
                    "label": 0
                },
                {
                    "sent": "We collect the label together with the A box, and then we use that as label training data.",
                    "label": 0
                },
                {
                    "sent": "Then we feed that into machine learning classifiers, saying this is the a box.",
                    "label": 0
                },
                {
                    "sent": "And now the reason that can say it's the reason I said it's true or false.",
                    "label": 0
                },
                {
                    "sent": "So consistent, inconsistent and then build a binary classifier out of that.",
                    "label": 0
                },
                {
                    "sent": "And then we use that learn model as an approximation for the reason around the validation of the result is actually quite straightforward, because you can just use test data and run a reason or two to validate what the machine learning classifier says.",
                    "label": 0
                },
                {
                    "sent": "So you can easily compute the quality of the classifier.",
                    "label": 0
                },
                {
                    "sent": "OK, um, one thing we need to do is that most machine learning classifiers, at least those that come out of the box and frameworks such as rapid miner or worker.",
                    "label": 0
                },
                {
                    "sent": "They need propositional forms, so they need vector vectors of data.",
                    "label": 0
                },
                {
                    "sent": "They usually don't work on a boxes which are graph, so we need some transformation which is done in this box here which says feature Vector Builder.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we use some variant of something called root path kernels, also known as what kernels they have been introduced here at this conference and four years ago.",
                    "label": 1
                },
                {
                    "sent": "I think the paper also wanted us paperwork back.",
                    "label": 0
                },
                {
                    "sent": "Now we use a slight variation of this because we said we actually not interested in the values of literals.",
                    "label": 0
                },
                {
                    "sent": "As such, we're just interested in the data type because the value of a literal which string is there.",
                    "label": 0
                },
                {
                    "sent": "If it's string X or Y actually doesn't doesn't change anything on whether the box is consistent or not, but the fact is whether there is a string or a number.",
                    "label": 0
                },
                {
                    "sent": "Can actually change the consistency, so as long as you don't have data type rain, just this is the I think more appropriate choice here.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's happening is assume you have an RDF graph like that.",
                    "label": 0
                },
                {
                    "sent": "Essentially for each node in the graph you compute all the paths that you can take from this from this node up to a certain length, and then these are used as features.",
                    "label": 0
                },
                {
                    "sent": "So if you can take that given path from the node down, the feature gets the value one.",
                    "label": 0
                },
                {
                    "sent": "If it's.",
                    "label": 0
                },
                {
                    "sent": "If you cannot take the given power from that particular node, then the feature gets the value 0.",
                    "label": 0
                },
                {
                    "sent": "So these are all the possible ways you can take through the path you can take through the graph up to a length of two and then for each node in the graph you can say cannot take this path or not and the feature set for one a boxes down the Union of all those, all those paths for all the nodes that you can take in this a box.",
                    "label": 0
                },
                {
                    "sent": "So this is how we describe in a box as a set of binary features.",
                    "label": 0
                },
                {
                    "sent": "And then we have everything we need to feed that into a machine learning classifier.",
                    "label": 0
                },
                {
                    "sent": "We have the instance described as a set of binary features.",
                    "label": 0
                },
                {
                    "sent": "We have the output label described as a binary feature, and then we can train a machine.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning model on that.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We need data to evaluate on and we use four different datasets.",
                    "label": 0
                },
                {
                    "sent": "Here one is we want to validate individual relation assertions and DB pedia.",
                    "label": 1
                },
                {
                    "sent": "So we use a relation assertion and pedia plus all the types of the subject plus all the types of the object and then see is that is that particular relation assertion between these two entities.",
                    "label": 0
                },
                {
                    "sent": "It consistent with the ontology or not.",
                    "label": 0
                },
                {
                    "sent": "And since DB pedia itself does not define too many class disjointness is which makes it hard to discover inconsistencies.",
                    "label": 0
                },
                {
                    "sent": "We use an extension of.",
                    "label": 0
                },
                {
                    "sent": "Using also the mappings to Dulcer, which comes with a number of high level high level disjointed statements.",
                    "label": 0
                },
                {
                    "sent": "I have an example on the next slide, then we do the same with Thiago, so in Jago be used individuals plus their types and also use the Delta top level ontology for top level distances.",
                    "label": 0
                },
                {
                    "sent": "Then we look at our DFA.",
                    "label": 0
                },
                {
                    "sent": "Our DFA documents be collected from the Web from App Data Commons and validate them against the Good Relations Ontology.",
                    "label": 0
                },
                {
                    "sent": "So we collect all the audio fade documents from the web.",
                    "label": 0
                },
                {
                    "sent": "Data comes corpus that use.",
                    "label": 1
                },
                {
                    "sent": "Good relations and validate them against the ontology.",
                    "label": 0
                },
                {
                    "sent": "And then be used the same with schema.org.",
                    "label": 0
                },
                {
                    "sent": "So we use all the microdata documents that use schema.org out on the web, like 300 million documents and then check them against the Schema Dog Ontology as the schema.org on teologi itself does not come with the joint assist.",
                    "label": 1
                },
                {
                    "sent": "We added some by hand.",
                    "label": 0
                },
                {
                    "sent": "I will show you them on one of the subsequent slides, so here's one.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example for this DB pedia TV PDF plus dulcer data set.",
                    "label": 0
                },
                {
                    "sent": "So we have this statement in DB Pedia.",
                    "label": 0
                },
                {
                    "sent": "I think it's still in the.",
                    "label": 0
                },
                {
                    "sent": "It's even there in the current version so that Tim Berners Lee got the award Royal SoC and then, you know that Royal Society is an organization, but award has the range award, and then you look at the top level assertions.",
                    "label": 0
                },
                {
                    "sent": "Indulgence E Organization is a Social Agent award as a description and descriptions, and social agents are disjoint, so this statement is clearly inconsistent with the ontology.",
                    "label": 0
                },
                {
                    "sent": "And this is the data set we use for the pedia with Jago, it's pretty much equivalent that we also use.",
                    "label": 0
                },
                {
                    "sent": "Disjointness is used from Dalton OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "This is the data set we modified for schema.orgschema.org comes with nine top level classes and we just looked at all the pairs of those classes and the intention of those classes and see are they disjoint or not.",
                    "label": 0
                },
                {
                    "sent": "So in action cannot be a productive place or person at the same time and so on.",
                    "label": 0
                },
                {
                    "sent": "There were two cases where we thought they are intentionally disjoint, but actually there are subclasses of both classes, so in those cases we don't introduce the disjointness in order not to make the whole thing.",
                    "label": 0
                },
                {
                    "sent": "Inconsistent so one both medical entity and creative work.",
                    "label": 0
                },
                {
                    "sent": "We thought they should be disjoint, but there are things which are diet plans which are subclasses of both.",
                    "label": 0
                },
                {
                    "sent": "The other is organization and place, which we thought should be should be disjoint.",
                    "label": 0
                },
                {
                    "sent": "Buttinsky madaka.",
                    "label": 0
                },
                {
                    "sent": "Local businesses like a Starbucks around the corner is both the subclass of place and.",
                    "label": 0
                },
                {
                    "sent": "Place an organization here and therefore you cannot make them disjoint without making the whole T box invalid.",
                    "label": 0
                },
                {
                    "sent": "So this is the number of disjoint sections we added.",
                    "label": 0
                },
                {
                    "sent": "For ski monologue you can get all the data from the Web we published both the of the datasets we use plus also this modified schema.org ontology.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK then, for each of those four datasets we created three variants coming with 11111 and 1111 boxes.",
                    "label": 0
                },
                {
                    "sent": "The reason for those numbers is that we want to inspect it.",
                    "label": 0
                },
                {
                    "sent": "How good does a model get if we train or let's say 100 or 1000 instances?",
                    "label": 0
                },
                {
                    "sent": "And since we want to do that in 10 fold cross validation, we need those order numbers saying 1111.",
                    "label": 0
                },
                {
                    "sent": "So you train on 1000 and then you evaluate on the remaining 111, repeat that 10 times.",
                    "label": 0
                },
                {
                    "sent": "You see that the data sets are not overly skewed, so this is the percentage of consistent eh boxes in the respective datasets.",
                    "label": 0
                },
                {
                    "sent": "So for the pedia you have like not 8586% of the boxes being consistent, and this is the most skewed one.",
                    "label": 0
                },
                {
                    "sent": "The other ones are slightly more balanced.",
                    "label": 0
                },
                {
                    "sent": "You also see that the number of features increases, sometimes moderately, sometimes quite dramatically for ya go for the 1000 data set, you have a data set of like 4000 something features.",
                    "label": 0
                },
                {
                    "sent": "But it's still.",
                    "label": 0
                },
                {
                    "sent": "It's still manageable, for the reason that we use for ground truth.",
                    "label": 0
                },
                {
                    "sent": "We use the Hermit reasoner, which gives us the which gives us the labels of true and false, and we also use that to produce the ground truth for evaluation.",
                    "label": 0
                },
                {
                    "sent": "The reason is that you cannot, for some reason, load the DB pedia plus dollar extension in pellet breaks.",
                    "label": 0
                },
                {
                    "sent": "For some reason.",
                    "label": 0
                },
                {
                    "sent": "This is why we chose Hermit.",
                    "label": 0
                },
                {
                    "sent": "Just a practical decision.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, we used four different classifiers implemented in rapid miner and the vector extension of Rapidminer.",
                    "label": 0
                },
                {
                    "sent": "We just use them in standard settings because we just wanted to know whether this works at all.",
                    "label": 0
                },
                {
                    "sent": "We just wanted proof of concept beyond we didn't want to squeeze out the last bit of performance there, but you can observe is that if you use 1000 training examples you always get over 95% accuracy.",
                    "label": 0
                },
                {
                    "sent": "So you gather model which does the right thing in 19 or 20 cases.",
                    "label": 0
                },
                {
                    "sent": "And in general, decision trees give you the best results except for the DB Pedia case.",
                    "label": 0
                },
                {
                    "sent": "For support, vector machines are slightly better.",
                    "label": 0
                },
                {
                    "sent": "And the surprising thing is, if you look at those decision trees, they are really small, so they are never.",
                    "label": 0
                },
                {
                    "sent": "We never observed the decision tree larger than 20 notes for these problems, which is really a bit of a surprise.",
                    "label": 0
                },
                {
                    "sent": "So here's an example for for the pedia.",
                    "label": 0
                },
                {
                    "sent": "So this is the decision tree that can decide whether to whether a statement and the pedia, along with the subject and object type is consistent with the ontology or not it it's not larger than that there are.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Several reasons for these decision trees being so small on the main one is that the inconsistency is they are.",
                    "label": 0
                },
                {
                    "sent": "They are heavily skewed, Lee distributed, so they're not equally distributed, but there are some some classes and some relations which are really responsible for the majority of inconsistencies.",
                    "label": 0
                },
                {
                    "sent": "And since the machine learning model focuses on the majority of the cases, and the cases are so unequally distributed, you get very small models that still perform quite well in the end.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we were asking ourselves how long would it take now.",
                    "label": 0
                },
                {
                    "sent": "So one thing is OK, it works.",
                    "label": 0
                },
                {
                    "sent": "You get to a decent accuracy, that's good.",
                    "label": 0
                },
                {
                    "sent": "The other thing the other claim was you are much faster than using an actual reasoner.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Self, how long would it take to to do this with all the statements that aren't pedia, which are 15 million with all the instances in Jago, roughly 3 million all audio documents that use good relations round roughly 350,000 and all microdata documents using schema.org and it's 300 million.",
                    "label": 1
                },
                {
                    "sent": "You can already mention validating 300 million different boxes with the reason it can take some time question is how much faster can we actually get?",
                    "label": 0
                },
                {
                    "sent": "Salem to to extrapolate these numbers.",
                    "label": 0
                },
                {
                    "sent": "Estimate what we did is.",
                    "label": 0
                },
                {
                    "sent": "We looked at the number of a boxes and the time it takes to to build a feature vector out of in a box.",
                    "label": 0
                },
                {
                    "sent": "We have to do that for all the boxes.",
                    "label": 0
                },
                {
                    "sent": "Then we have the time it takes to train the actual model and then for the remaining a boxes.",
                    "label": 0
                },
                {
                    "sent": "Except for those which we already classified for training.",
                    "label": 0
                },
                {
                    "sent": "So this is the remaining boxes minus 1000.",
                    "label": 0
                },
                {
                    "sent": "We need the time it takes to classify and a box with our model.",
                    "label": 0
                },
                {
                    "sent": "And this this sum gives us the estimated time it would take with our model to to run this.",
                    "label": 0
                },
                {
                    "sent": "Sort of thing.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "He will see on the the time it takes for 1000 instances using the reasoner and then this TF time.",
                    "label": 0
                },
                {
                    "sent": "So the time to build the features, the time for training the classifier which is below is second and the time for classification, which is almost neglectable.",
                    "label": 0
                },
                {
                    "sent": "So this number is really, really small.",
                    "label": 0
                },
                {
                    "sent": "The majority of time is spent transforming and a box into a feature vector.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then if you look at the estimated numbers for all a boxes, so for Hermit for if you look at schema.org, these 300 million documents, for example, it would take 1.5 million seconds with our train model.",
                    "label": 0
                },
                {
                    "sent": "So the sum of this it's 4100 seconds.",
                    "label": 0
                },
                {
                    "sent": "So if you if you have difficulty imagining 1.5 million seconds, that's roughly 18 days.",
                    "label": 0
                },
                {
                    "sent": "Where is our model would take 1 1/2 hours, so this is the order of magnitude that we get faster here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so the summary of our findings is that you can just ask of a box consistency checking.",
                    "label": 0
                },
                {
                    "sent": "You can approximate it quite well with this sort of approach, and if you train decision trees with 1000 labeled examples, you get to not always get above 95% accuracy, which is a pretty good result.",
                    "label": 0
                },
                {
                    "sent": "The decision trees we learn are in fact pretty small, so you saw this example.",
                    "label": 0
                },
                {
                    "sent": "We never observed the decision tree larger than 20 nodes.",
                    "label": 0
                },
                {
                    "sent": "Just makes it pretty interesting to apply that sort of model in complete computation limited settings.",
                    "label": 1
                },
                {
                    "sent": "So imagine you want to do approximate reasoning.",
                    "label": 0
                },
                {
                    "sent": "Let's say on the sensor it's not a big problem to to use this decision tree and load it onto a sensor.",
                    "label": 0
                },
                {
                    "sent": "You cannot load a full fledged ontology reason on a sensor, but I mean this.",
                    "label": 0
                },
                {
                    "sent": "This model, which just takes.",
                    "label": 0
                },
                {
                    "sent": "I don't know a few bites, a few kilobytes in memory at Max, so you can easily load it on a very small device, so smart devices and sensors are can be well equipped with these approximate models.",
                    "label": 0
                },
                {
                    "sent": "And we saw that the approximation is really highly scalable, so you saw that microdata examples, where the reason they would take 18 days to to process all those boxes and we can do it in 90 minutes.",
                    "label": 0
                },
                {
                    "sent": "So the question is, why does it work so well?",
                    "label": 1
                },
                {
                    "sent": "So the learned models they concentrate on the relevant fragments of the ontology, so the ones that are important for the majority of the cases and the other reason is that the reasons for inconsistencies are not equally distributed across the concepts in the ontology and so learned models really adapt to the most frequent inconsistencies and try to try to respect those.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some things we want to try in the future.",
                    "label": 0
                },
                {
                    "sent": "One thing is you can actually you saw that the transformation to feature vectors is the stuff that actually takes takes most time and you don't have to do it that way actually.",
                    "label": 0
                },
                {
                    "sent": "So once you've learned the decision tree, you can just just translate this decision tree into a set of sparkle tests for example and fire them directly to the A box.",
                    "label": 0
                },
                {
                    "sent": "You don't need the transformation to a feature vector anymore.",
                    "label": 0
                },
                {
                    "sent": "Um, another thing where you could use that is the task of ontology summarization.",
                    "label": 0
                },
                {
                    "sent": "So you learn these models.",
                    "label": 0
                },
                {
                    "sent": "You saw that reason.",
                    "label": 0
                },
                {
                    "sent": "You see the concepts that are used in the trees, and obviously these are the ones that are important for most reasoning test.",
                    "label": 0
                },
                {
                    "sent": "So this should give you a starting points for summarizing ontologies and identifying the key relevant concepts in ontology.",
                    "label": 0
                },
                {
                    "sent": "So far what we did is we just predicted consistent or inconsistent, but we do not do is giving any explanation why something is inconsistent.",
                    "label": 0
                },
                {
                    "sent": "I mean you could try to read that from the path and the decision tree taken.",
                    "label": 0
                },
                {
                    "sent": "For example, it would be interesting to see whether that corresponds to the explanation.",
                    "label": 0
                },
                {
                    "sent": "An actual reason that would give.",
                    "label": 0
                },
                {
                    "sent": "You could also think about trying to learn a model that predicts the explanation as such.",
                    "label": 0
                },
                {
                    "sent": "So there are works on structured predictions where you don't predict a single button structure like a graph.",
                    "label": 0
                },
                {
                    "sent": "And so you could try to learn predicting a tree that that shows the explanation for the inconsistency.",
                    "label": 0
                },
                {
                    "sent": "And um, yeah.",
                    "label": 0
                },
                {
                    "sent": "So so far I just said OK we used 1000 training examples and maybe that's not the end of the story so we're currently running some experiments on selecting those examples more effectively and minimizing the invocations of an actual reason is so if you use active learning, then the learner can itself decide whether it wants to have the example labeled by the reason or whether it is OK with not labeling the example and there you can.",
                    "label": 0
                },
                {
                    "sent": "You can already see in the 1st results that you can limit number of.",
                    "label": 0
                },
                {
                    "sent": "Reason the calls without sacrificing too much the effectiveness of the overall approach.",
                    "label": 0
                },
                {
                    "sent": "OK, and in the end I mean, so far the evaluation has been purely purely empirical, but we also want to look at more systematically is what is the interplay between how to represent features.",
                    "label": 0
                },
                {
                    "sent": "We just use this one method at the moment to represent features.",
                    "label": 0
                },
                {
                    "sent": "Does it somehow interplay with the complexity of the ontology?",
                    "label": 0
                },
                {
                    "sent": "Does it somehow interact with the paradigm useful learning, analyzing these things more systematically would be quite fascinating, because so far we just have this empirical evaluation alright.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Man no, I'm open for questions, thank you.",
                    "label": 0
                }
            ]
        }
    }
}