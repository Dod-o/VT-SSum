{
    "id": "qmxdmjssqqs75cobt4y2iote2dxot2jt",
    "title": "Models and Algorithms for Dynamic Networks",
    "info": {
        "author": [
            "Desmond J. Higham, Department of Mathematics and Statistics, University of Strathclyde"
        ],
        "published": "July 2, 2012",
        "recorded": "May 2012",
        "category": [
            "Top->Computer Science->Algorithmic Information Theory",
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/complexnetworks2012_higham_dynamic_networks/",
    "segmentation": [
        [
            "So the first part."
        ],
        [
            "Some modeling trying to describe.",
            "And the features and the dynamics of a network.",
            "So we're focusing here on the case that was mentioned yesterday, where you have a fixed number of nodes and some dynamics of the interactions.",
            "So links are coming and going overtime.",
            "We're thinking in particular of communication and human social interactions, or maybe emails or twitters, or telephone conversations between a fixed set of users.",
            "So that's the context that we're thinking of.",
            "I'll talk about a recent model, but this is really using a framework that Pete and I put together a couple of years ago."
        ],
        [
            "So just taking a step back, what are we trying to do here?",
            "What's the motivation for this and what are the challenges?",
            "Well, we'd like to understand what's causing these dynamics.",
            "What makes a new link arise in the network?",
            "How do links disappear if you're given today's network?",
            "What laws of motion are telling you something about tomorrow's network?",
            "If you have a model, then you can try to calibrate the parameters of the model and if the model is statistical then there's a very nice likelihood automatically built into this process.",
            "So by comparing likelihoods you can decide which of the two models, or more than two models is most appropriate for the data.",
            "And the real reason for doing this is that we can then use that model.",
            "We can forecast what's happening in the future.",
            "We can make predictions and we can do what if simulations.",
            "We can do things on a computer that might not be ethical or unfeasible in real Life OK, so we can.",
            "We can run trials, knockout nodes, intervene with the network in some way and predict future behavior.",
            "So this is the framework that we tend to focus on.",
            "It's a discrete time, so time points.",
            "So think of them as days or hours as we go forward.",
            "And it's it's to castec.",
            "It's a Markov chain.",
            "The state space is the set of all possible networks.",
            "So today at time TK we know the adjacency matrix.",
            "AKA.",
            "Let's suppose this is a simple unweighted and directed.",
            "Network, so given today's network aka.",
            "Then there's a probability of every other possible network arising tomorrow.",
            "Now if you try and parameterized, that kind of Markov chain, then you find this lots of parameters involved.",
            "So we like to simplify things and the version that we focused on.",
            "We like to talk about in terms of birth and death of edges.",
            "So given today's network, if there's an edge in today's network, then there's going to be a probability of that edge remaining or disappearing tomorrow.",
            "And that's going to be independent over all the edges.",
            "And again, if there's an edge missing in today's network, then there's going to be a probability of that edge appearing in tomorrow's network.",
            "OK, so it's an it's an edge focused type of modeling.",
            "Once you're given today's network, all those events are then independent.",
            "So what's a good way of of putting together some rules about how edges may arise or disappear overtime?",
            "And we have various ideas that we've published.",
            "I'm going to focus on one particular case, which I think is.",
            "I think it's realistic and also we can do a little bit of mathematics so we can actually."
        ],
        [
            "Sort of proof something about it.",
            "So the idea here is called triadic closure.",
            "This is a very well studied topic in social Sciences.",
            "The idea that the more friends you have in common with somebody, the more likely you are to become friends with that person.",
            "It's a reasonable sort of hypothesis if you tend to interact with the same circle of friends, then you tend to make that that new friendship OK.",
            "So in terms of what happens to the edges.",
            "Well, given today's network, we're going to keep the death process simple, so we lose friends at some constant rate.",
            "So independently of the network, if the edges there today, then there's some probability Omega that the edge will disappear tomorrow.",
            "But here's the here's this tragic closure idea.",
            "If there's an edge missing in today's network, then this is the probability.",
            "So it's between those I&J.",
            "This is the probability of that edge arising.",
            "Between those I&J on the next day.",
            "So there are two parameters here.",
            "There's a Delta.",
            "And an epsilon.",
            "Delta is just the Basel rate state independent rate at which we may sort of arbitrarily make new friendships.",
            "Epsilon.",
            "Here is the strength of this tragic closure effect.",
            "So what we're doing here is raising today's adjacency matrix to the power two.",
            "And, as we've heard several times.",
            "Over the last couple of days, that's a way of counting the number of walks of length two or paths of length 2 between I&J.",
            "Or in other words, it's the number of neighbors that I&J have in common number of friends that they share.",
            "So the more friends Inj share, the bigger this quantity on epsilon.",
            "Then is the strength that we associate with that tried it closure effect?",
            "So it's a relatively simple although nonlinear model of edge birth overtime.",
            "We need some constraints on the parameters just to guarantee that these this overall probabilities between zero and one.",
            "So it's a Markov chain.",
            "I'm going to show you a path of the Markov chain, so the state space is, that is, the set of all networks.",
            "These are my parameters that I use all the way through, so in particular is 100 nodes.",
            "And this network."
        ],
        [
            "So here's time increasing in steps of 50 from time 0 up to time 750, and the dots are the edges in the adjacency matrix.",
            "My notation here.",
            "This is ER stands for Doctor Rainey.",
            "Just the usual tossing a coin to put the edge in.",
            "That's my initial condition with .3 as the probability of an edge.",
            "So my starting graph.",
            "Has it just placed uniformly at random with probability .3 so it's 30% dense to begin with?",
            "If you let time evolve, this is 1 path through the Markov chain.",
            "I don't expect you to spot any patterns there other than to notice that there's more and more dots appearing, so the blue is increasing, so this is becoming denser overtime.",
            "Done, in particular, if you count the edge density at the longest time 7:50, then it's around 71%.",
            "So out of all the possible edges, about 71% exist after a long time.",
            "And that's when I start with a 30% edge density at time 0.",
            "So then taking the same model exactly, just changing the initial condition."
        ],
        [
            "So now I start with a less dense network of 15% edges.",
            "Let time evolve with the same modeling parameters, the same birth and death law, then this time.",
            "Then just get get less dense and this largest time is 750.",
            "We now have around 5% of the edges present in the network OK.",
            "So those are just two independent.",
            "Paths of the Markov chain starting at two different initial conditions but with the same modeling parameters.",
            "So it's the same model, different initial data.",
            "Can we explain why we get these two different types of long-term behavior?",
            "Well, the answer is yes.",
            "Otherwise I wouldn't be showing you these."
        ],
        [
            "Experiments, so we're going to do what we call mean field and mean field is what physicists say when they don't really understand what they're doing.",
            "That's my my summary.",
            "So here's a statement which we've fairly clear is true.",
            "OK, so let's think about long-term behavior of this Markov chain.",
            "While it's agatic everything that's fairly clear because of the way that the birth and death are defined, there's always some guaranteed non zero death and nonzero birth probability.",
            "That means if you focus on a pair of nodes and look at the connectivity between those two nodes as time goes to Infinity, then the frequency with which you see an edge will tend to a constant.",
            "As time goes to Infinity.",
            "So let's call that P star.",
            "So if you look at this pair of nodes, let time go to Infinity, the frequency with which you see the edge will overtime will converge to some number P star.",
            "On the other hand, there's nothing special about any particular pair of nodes.",
            "Everything is invariant under relabeling.",
            "The dynamics don't depend on the on the on the node labeling, so it must be the same P star for every pair of nodes.",
            "OK, so in this longtime sense we must have an Erdos reyni type of structure where whatever edge concerns you that will appear with some fixed probability P star as time goes to Infinity.",
            "So in this sense, there's another trainee structure in the long time.",
            "So taking that through and doing something heuristic, Now let's just ask ourselves what would happen if we did have an Erdos reyni graph that sometime that would be defined.",
            "Solely by this scalar PK, this is the probability of seeing an edge between a pair of nodes at time K. So if we just insert this into our model.",
            "What's the corresponding value for PK at the next time point?",
            "If this really were a sensible thing to do, OK, so PK is the chance of the edge being there today.",
            "What's the chance of an edge being there tomorrow?",
            "Well, there are two cases.",
            "Either it was there and it didn't die, so 1 minus Omega is the chance of it not dying and PKS and chance of it being there yesterday.",
            "On the other hand, maybe it wasn't there and it was born, and if I go back to the model.",
            "The birth probability is a constant Delta plus epsilon times number of neighbors that they share.",
            "So one man is PK is the chance it didn't exist yesterday.",
            "This is our factor describing the chance of a birth, so there's the constant.",
            "The Basel rate Delta.",
            "There's the triadic closure strength, and now there are N -- 2 possible neighbors of these two nodes.",
            "And the chance of the appropriate pair of edges being there so that I enjoy both connected to those neighbors, is given by P K. ^2.",
            "OK, so this is our heuristic mean field approximation to the behavior of the adjacency matrix in this model.",
            "OK, so this is a scalar parameter.",
            "Now PK is just the density of the edges.",
            "It's a macro parameter that we're trying to extract from this micro scale description OK. And it's a trivial nonlinear type of iteration.",
            "It's a cubic iteration, so you can look for steady states of this, and you find that there are three real roots because it's a cubic, and this generically there are three.",
            "If you have small parameters, and as you might expect, two of them turn out to be stable.",
            "That's the dense and the sparse case, and in between them there's an unstable linearly unstable steady states, OK.",
            "So for the parameters I used for my SIM."
        ],
        [
            "Elation the study states arise where these two curves meet, where the CU meets the linear.",
            "I should say these are generated by Peter Green Rod in Nice low resolution that reading they can't afford many pixels.",
            "So these are these are peaks pictures.",
            "That's right.",
            "Yeah.",
            "So this agrees with the simulation.",
            "There's a, there's a.",
            "The less dense, stable steady state is down at around 5%, the more dense steady state is up at 72%, and the unstable intermediate state is around 23% OK. And then just to.",
            "Try to convince you a little bit more."
        ],
        [
            "Here's a lovely smooth curve in Peter Green Rd style and the jagged curve.",
            "The lovely smooth curve is this one.",
            "And the jacket, the one is just above it.",
            "So what we're doing here is with one of these is a micro scale simulation of the Markov chain.",
            "Which we then extract macro features from.",
            "So we simply count the edge density at every point in time for one path of the Markov chain.",
            "That's the jagged curve and the lovely smooth curve is just the mean field iteration, the PK plus one is a function of PK and you can see we can cause we're starting with the training with little bit of a cheat, but this macro mean field model.",
            "Very nicely follows the micro scale simulation in terms of capturing this macro feature.",
            "OK, if you didn't start with another trainee, there'd be a little bit of catch up time, but it would eventually follow the right kind of behavior."
        ],
        [
            "This bistability is really what we think is the interesting part of all this.",
            "So what we're doing here is we're starting three, sorry, five independent paths from the same initial condition.",
            "Which we specially chosen to be close to the unstable fixed point, so there's an unstable fixed point around the .23 edge density.",
            "We start with exactly the same initial condition, but three.",
            "Sorry, five different independent path.",
            "So different micro scale noise and four of these curves decide to follow down to the lower of the stable fixed points.",
            "But one of these because with the micro scale detail has enough impetus to get going and then lead itself up to this richer, denser, stable fixed point.",
            "OK, so.",
            "In a sense, we can predict what's going to happen that we think there are these two stable fixed points, but we can't tell you which one is going to show up in a particular simulation.",
            "And across this has some nice implications.",
            "If you're a mobile phone company trying to generate customers, or if you're an online social network provider trying to get a nice rich interactive structure among your users and then you want to be up here and a little bit of work just to help this help this information to get going will allow that will allow the path to head up towards the desired fixed point and then you leave it alone and it very nicely carries on.",
            "Then the self organizes into that rich state, whereas if you see this kind of behavior happening then you need to work a lot harder to get the get the desired behavior.",
            "OK.",
            "So that's a little bit about modeling, and I'll just wrap up that."
        ],
        [
            "Half of the talk with a summary and then some observations.",
            "So what we're doing here is using a stochastic modeling framework, focusing on the idea that edges can be born or can die from one time points to the next.",
            "Then we tried to build in this law of motion based on triadic closure.",
            "So the more friends two people have in common, the more likely they are to build a friendship at the next time point.",
            "Then we have this mean field analysis, which seems to do a good job of predicting the behavior of the model.",
            "At least that that particular macro scale feature.",
            "There are many things that can be done in some of these we're working on, in particular, calibrating the model to some real data.",
            "And because it's a stochastic model, as I said, it has a likelihood, so it's not particularly.",
            "Difficult to see how you might calibrate that model.",
            "Also, it's nested in the sense that epsilon equals to 0 is just completely Erdos reyni type behavior.",
            "So you can do a nested comparison, then see whether Epson equals to 0 is more realistic than epsilon, greater than zero on some datasets, so you can test innosys tickle manner for whether you're seeing triadic closure in the dynamics.",
            "We're doing discrete time and there are some interesting issues which I'll talk about later with anybody who's interested about trying to generalize this modeling framework to the case of continuous time is by no means obvious.",
            "What to do in continuous time.",
            "And we'd like to also analyze processes on this dynamic network.",
            "Person SI model Sir model.",
            "On top of that involving network, and we have a little bit of work in this direction.",
            "OK, so maybe I'll stop there for any questions on the first half.",
            "If anybody wants to chip in.",
            "Yep, sure.",
            "What you're saying is that you start with whatever you start with.",
            "Men relationships evolve, yeah?",
            "Summations.",
            "As time goes Infinity, how many people are left and then assume that everything is independent to make calculations.",
            "How many edges are left?",
            "Yeah, yeah, yeah, yeah calculation.",
            "OK.",
            "In that calculation, here is what I get.",
            "I get three points to the staple, yeah?",
            "What will happen in the true limit is something like that.",
            "Is that well?",
            "Well, there's one thing as I said, this is heuristic.",
            "I was expecting a different kind of question.",
            "On the one hand, I said this is agatic.",
            "On the other hand, I tried to convince you that there are two stable steady States and that those things don't go together, so they can't possibly mathematically be these two Delta functions both being the invariant measure.",
            "So what what we?",
            "I guess this is metastability that we're observing, and in the very, very long time you maybe see some mixture of those two.",
            "Stable steady states dominating the behavior.",
            "Answer your question.",
            "Right, OK?",
            ".",
            "Approximation tool.",
            "But in practice it seems to work.",
            "We haven't gotten.",
            "We haven't got a proof and that I'm not sure that you could well, but you can't because it's not what you said Godik, and we're trying to claim there are two measures, so that's why we didn't try and make it rigorous because it can't possibly be rigorous.",
            "But if you look at the arguments that you know, I think there's an approximation.",
            "They do seem to be reasonable.",
            "Framework, but if you think about it, there's a threshold point.",
            "Winfield is terministic.",
            "It's just that.",
            "Never, never be correct.",
            "Statistics actually.",
            "Where where you're near an unstable?",
            "Put this near me, but anyway anyway.",
            "Similarly, anywhere where you're in a network which is particularly sparse and say the traffic closures support, that's going to cover fall down because the mere details suppose you had a network that was that had no Delta and Delta is 0.",
            "The only means making friends is to make friends with people who are already friends of friends.",
            "So if we start off split into two groups, Brazilians and British people, then because none of us know each other will never make friends.",
            "Where is the Bing field they would?",
            "There are cases when actually just putting Delta back in kind of risk.",
            "But in general, anywhere where the stochastic details of the actual networks matter, the actual initial conditions, or you're close to her, or you close to a an unstable point.",
            "Actually it can only be a wish that, yeah, I think any sort of proof.",
            "Nothing really, really complicated, involving metastability and transient.",
            "It's not the kind of thing we like to get into.",
            "Weather no feel free to know.",
            "Theory of birthday.",
            "Yum.",
            "Yum, Yum.",
            "Film.",
            "Yes, sorry mark.",
            "Square films.",
            "Yeah, yeah, we discussed this, but we haven't tried it.",
            "We think the heuristics are much less valid in the case of higher powers of a.",
            "If you think of the independence assumption, this is very neat.",
            "The way this P ^2."
        ],
        [
            "Comes in, you know what's the chance of the two neighbors both being connected to the to the right nodes if you if you start raising powers, you can write down the mean field model, but we don't think it's as useful.",
            "We haven't tried that yet.",
            "We we haven't.",
            "We haven't tried it, but we just think it's interesting.",
            "But we think it's not so valid as this.",
            "Yeah yeah yeah sure yeah.",
            "Yeah yeah yeah sure yeah yeah yeah yeah yeah yeah sure.",
            "OK, so I'll press on."
        ],
        [
            "The second part of the talk is the opposite is data driven.",
            "Trying to extract things from from networks.",
            "This builds on some work with an S to and Pete and Mark Parsons as a student at Reading.",
            "This goes back to this idea of what counting and the original paper I'm aware of is Leo Katz from 1953, where he used walks to measure centrality."
        ],
        [
            "So now we're thinking of independent networks, and which nodes are important and how can messages be passed around?"
        ],
        [
            "So suppose you have."
        ],
        [
            "This kind of structure on three days.",
            "They mention this is being done directed then.",
            "If you look at how a might communicate with C on time 1A, communicate with G and then at time 2G can talk to see, but there's no way that she can talk to a with that structure.",
            "OK, so there's a lack of symmetry, even though each network is symmetric."
        ],
        [
            "Times Arrow introduces his lack of symmetry, so you have to be careful what you mean by communication.",
            "But as Mark said yesterday there's a fairly obvious idea of walking around.",
            "You can just use the edges that are available and then the next time point you can use more edges.",
            "So."
        ],
        [
            "And in this notation where we have the TCR, the time points and the corresponding adjacency matrices, you can define a dynamic walk.",
            "The length is the number of edges that you go across, so you need a sequence of time points and a sequence of edges that take you between the nodes and the edges have to exist at the appropriate times, so it's perfectly natural.",
            "Concept we allow the same time to be used by more than one edge so you can traverse."
        ],
        [
            "Two or three edges on one day and then go ahead and take as many edges like on the next day.",
            "That's the that's the way we've defined it."
        ],
        [
            "OK."
        ],
        [
            "So.",
            "The Cat Scientology is based on powering up the Matrix to count walks and it turns out there's a very similar concept in this dynamic setting.",
            "If you multiply together.",
            "The adjacency matrices at possibly different time points, then that simply combinatoric Lee counts the walks that take place using edges on the appropriate time points.",
            "So this product with some arbitrary set of time points has an IJ element that counts how many walks there are from I to J from factors or using W edges where the corresponding edges exists at those time points OK.",
            "So we'd like to look at all the possible ways to walk between I&J respecting this time ordering, so we'd like to keep track of all these kinds of walks here, so we'd like a term like this where you take a step on day zero and a step on day one, and will use that cat style down waiting the resolvement style where we multiply by Alpha squared.",
            "If there are two edges.",
            "Here's a term which takes a step on day zero step on day two, day three, and day seven.",
            "And because there are four edges, we down weight by Alpha to the four.",
            "This one takes 2 steps on day three and then one step on day nine and that has an Alpha cubed, so we'd like all the possible terms of that form where you have non increasing time indices and a corresponding power of Alpha that matches the number of edges.",
            "OK, so we'd like to put all those terms together, which might sound combinatorially difficult, but it turns out all you have to do is multiply together the matrix resolving's OK in the appropriate order.",
            "So this is generalizing the cuts resolvement into time dependence.",
            "Networks call this matrix Q and then the ijaaf entry in Q summarizes how well I can pass messages or communicate with J over that time dependent data."
        ],
        [
            "So you can sum along the Rose to see how well know Dan is communicating with all all the other nodes in the network, and you can some down the columns to see how well know Denny's receiving information from all the nodes in the network.",
            "So we call this the broadcast and the receive communicability.",
            "So it's like a centrality measure.",
            "In terms of broadcasting and then one in terms of receiving.",
            "It generalizes cats if you have one time point.",
            "It reduces to cats.",
            "Actively cheap to do because those matrixes solvents involve sparse matrices, so it's a sparse matrix.",
            "Solve that each time point.",
            "And the fact that dynamic walks are not symmetric is really mirrored in the fact that matrix multiplication is not commutative.",
            "So if you change the order of the time points, you certainly change these centrality measures.",
            "So we are respecting the order of the time."
        ],
        [
            "So here's an example.",
            "This is from some other work with the postdoc Alex months Iris, where we have another model that I haven't got time to talk about.",
            "This is the Enron datasets 150 people or so.",
            "Each each point here is a person on the horizontal axis.",
            "We just look at their total degree, how many emails they turned out on this axis.",
            "We look at the broadcast centrality.",
            "So this is what we think is a better measure of how well they can get out.",
            "Information across the network.",
            "I'm sure there are a couple of people here who stand out as having high broadcasts without a particularly high bandwidth, and it turns out this is the vice president and an executive of the company.",
            "Whereas there are three people out here who were working very hard, sending out lots of messages.",
            "But in terms of the broadcast centrality not doing particularly well, and two of these people were traders and one is unknown in terms of their their job.",
            "OK, so there's certainly different.",
            "This broadcast centrality is different to simply counting.",
            "How many messages?",
            "How many edges somebody has?",
            "It's about the timing of the edges and the follow on effect.",
            "Once you sent your message, who else is passing it on?",
            "That's what this is trying to capture."
        ],
        [
            "And so, just briefly, we have a new version of this which allows for time down waiting.",
            "The previous version treats all the walks over the whole time period as being equally important, and we only discount according to length.",
            "The number of edges, while you can also discount according to time.",
            "So it's a very old message that started along time ago.",
            "Then you might want to down weight it by its age.",
            "So by updating this iteration in this way where we introduced this scaling factor where Delta T is the interval of time between one day or one time point in the next.",
            "Then this matrix SK again is combinatorially counting all the walks between I&J, but that's before we scale a walk of length W in terms of edges by output of the W. But we also now scale.",
            "The walk that's T unit sold by E to the minus BT and so this updates both the edge waiting and also the time waiting.",
            "So this parameter B goes from zero to Infinity.",
            "0 is the previous algorithm and Infinity is just focusing on one day at a time and forgetting all the previous information.",
            "So, just briefly to show you."
        ],
        [
            "Be might be useful.",
            "This is a synthetic test using real data.",
            "The Enron data.",
            "Again, this is a bit like link prediction, but we're now doing centrality prediction.",
            "So we're trying to predict tomorrow's Katz centrality of that network using today's information and information today or earlier.",
            "We look at the correlation between our prediction for centrality and the true centrality on the next day we send those correlations over all the time points.",
            "So a bigger number means we're doing better at predicting tomorrow's centrality.",
            "And what I'm showing here is how that varies as a function of B, so B = 0 means we're using all the previous information and counting it equally.",
            "B equals Infinity, or in this case 3 means that we just using today's network to try and predict tomorrow's network OK, and you can see there's some intermediate here around .3 where we do a better job.",
            "So by using old information but not giving it the same weight as current information then we can get a better prediction both in the tense of broadcasting and receiving."
        ],
        [
            "So just to finish up what we think is new, here is formalizing a dynamic walk and using it to generalize the cat centrality.",
            "And pointing out that this gives you new information, there are some people who seem to punch above their weight.",
            "The bandwidth is relatively low, but they can get messages out across the network efficiently.",
            "We'd like to do this for weighted edges that we're interested in doing this for very large scale computations, so the linear algebra aspect and the computational side is important.",
            "This can be done in real time in principle, so we can categorise networks and then monitor what's happening and maybe maybe flag some kind of warning if the network seems to have changed.",
            "Look at who's speaking who's trending, who's going up or down in terms of their centrality measures?",
            "Maybe intervene at the appropriate places.",
            "OK, so I'll finish there and just thanks to various funding agencies.",
            "OK, thank you.",
            "Yep.",
            "So you can use like you to test.",
            "This is yeah.",
            "But if I just give you a network, just a snapshot of the network, and they don't tell you how many times steps there were, right?",
            "How easy is it to destination?",
            "If it's only one time points, then there's not really feasible.",
            "If you have a number of time points, then we just have to assume that is the discrete time interval between network samples and that's that's what we're doing.",
            "Essentially, the Enron email data is real time email, and we tend to summarize it in terms of days or hours or weeks, so that's the level at which we're doing things.",
            "So if there's no more than 10 data points, time points.",
            "That's the kind of thing that we're doing at the moment.",
            "Yeah, it's very nice, but.",
            "Respect with I mean how can you extract some useful information from it?",
            "Because it's so complicated object, let's say.",
            "So what what do you have in mind to computer completely or to the right?",
            "Well, this really."
        ],
        [
            "Yeah, yeah yeah.",
            "So this is once you take this sum this is Q * A vector of ones.",
            "So it's just a vector so."
        ],
        [
            "If you want, yeah, so in general it's this times a vector that we're trying to find.",
            "So inverting a matrix times vector that solving a linear system.",
            "This is a sparse.",
            "This is a sparse matrix, so it's one.",
            "One sparse matrix solve per time step, which is feasable you know this compared to what Google does.",
            "It all information I found this could well obtain all information about all possible paths in this, yes.",
            "Summarized summarized by this weighting factor.",
            "So in principle you could extract many many things from this quantity.",
            "Yeah, but it's still pairwise is still whatever inj units.",
            "One summary of how I&J are communicating.",
            "Yeah, so you could cluster that and you could look at the way communities evolve overtime, that's one.",
            "Possibility we think is exciting.",
            "Many countries that people expected, yeah yeah.",
            "This is the best we think this is a good static summary of current of what's going on so far.",
            "This is like a weighted network at Time K telling you what's happened so far.",
            "That's one way of describing it.",
            "What would be the typical complexity of this calculation and compute this computer while solving a linear system?",
            "It's roughly order end if there's only a fixed number of edges per node, then it scales like order, end, or you can always just replace this.",
            "Yeah, yeah.",
            "Oh yeah, so for every day, yeah, and per day.",
            "But also you can approximate you can you can approximate this by 1 plus Alpha Ray and then it's just a matrix multiplication.",
            "So that is really order N per days.",
            "Numerical analysis by Basia.",
            "Use the quadrature rule.",
            "And they solve this in a very efficient way, so they have developed now program so you can do it in seconds or something like that 400,000 nodes.",
            "Yeah.",
            "Just published in linear algebra and this application went to 10.",
            "So we had a guy from Telenor saying they can just about over the weekend.",
            "The multiply the matrix by vector of all their employees or their own customers.",
            "So they're quite happy to think about this kind of computation.",
            "What they can't do is compute and eigenvector of the adjacency matrix.",
            "That would be just too unthinkable, but they can multiply the matrix into a vector."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first part.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some modeling trying to describe.",
                    "label": 0
                },
                {
                    "sent": "And the features and the dynamics of a network.",
                    "label": 0
                },
                {
                    "sent": "So we're focusing here on the case that was mentioned yesterday, where you have a fixed number of nodes and some dynamics of the interactions.",
                    "label": 0
                },
                {
                    "sent": "So links are coming and going overtime.",
                    "label": 0
                },
                {
                    "sent": "We're thinking in particular of communication and human social interactions, or maybe emails or twitters, or telephone conversations between a fixed set of users.",
                    "label": 0
                },
                {
                    "sent": "So that's the context that we're thinking of.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about a recent model, but this is really using a framework that Pete and I put together a couple of years ago.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just taking a step back, what are we trying to do here?",
                    "label": 0
                },
                {
                    "sent": "What's the motivation for this and what are the challenges?",
                    "label": 0
                },
                {
                    "sent": "Well, we'd like to understand what's causing these dynamics.",
                    "label": 0
                },
                {
                    "sent": "What makes a new link arise in the network?",
                    "label": 0
                },
                {
                    "sent": "How do links disappear if you're given today's network?",
                    "label": 0
                },
                {
                    "sent": "What laws of motion are telling you something about tomorrow's network?",
                    "label": 0
                },
                {
                    "sent": "If you have a model, then you can try to calibrate the parameters of the model and if the model is statistical then there's a very nice likelihood automatically built into this process.",
                    "label": 0
                },
                {
                    "sent": "So by comparing likelihoods you can decide which of the two models, or more than two models is most appropriate for the data.",
                    "label": 0
                },
                {
                    "sent": "And the real reason for doing this is that we can then use that model.",
                    "label": 0
                },
                {
                    "sent": "We can forecast what's happening in the future.",
                    "label": 0
                },
                {
                    "sent": "We can make predictions and we can do what if simulations.",
                    "label": 0
                },
                {
                    "sent": "We can do things on a computer that might not be ethical or unfeasible in real Life OK, so we can.",
                    "label": 0
                },
                {
                    "sent": "We can run trials, knockout nodes, intervene with the network in some way and predict future behavior.",
                    "label": 0
                },
                {
                    "sent": "So this is the framework that we tend to focus on.",
                    "label": 0
                },
                {
                    "sent": "It's a discrete time, so time points.",
                    "label": 0
                },
                {
                    "sent": "So think of them as days or hours as we go forward.",
                    "label": 0
                },
                {
                    "sent": "And it's it's to castec.",
                    "label": 0
                },
                {
                    "sent": "It's a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "The state space is the set of all possible networks.",
                    "label": 0
                },
                {
                    "sent": "So today at time TK we know the adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "AKA.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose this is a simple unweighted and directed.",
                    "label": 0
                },
                {
                    "sent": "Network, so given today's network aka.",
                    "label": 0
                },
                {
                    "sent": "Then there's a probability of every other possible network arising tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Now if you try and parameterized, that kind of Markov chain, then you find this lots of parameters involved.",
                    "label": 0
                },
                {
                    "sent": "So we like to simplify things and the version that we focused on.",
                    "label": 0
                },
                {
                    "sent": "We like to talk about in terms of birth and death of edges.",
                    "label": 1
                },
                {
                    "sent": "So given today's network, if there's an edge in today's network, then there's going to be a probability of that edge remaining or disappearing tomorrow.",
                    "label": 0
                },
                {
                    "sent": "And that's going to be independent over all the edges.",
                    "label": 0
                },
                {
                    "sent": "And again, if there's an edge missing in today's network, then there's going to be a probability of that edge appearing in tomorrow's network.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's an it's an edge focused type of modeling.",
                    "label": 0
                },
                {
                    "sent": "Once you're given today's network, all those events are then independent.",
                    "label": 0
                },
                {
                    "sent": "So what's a good way of of putting together some rules about how edges may arise or disappear overtime?",
                    "label": 0
                },
                {
                    "sent": "And we have various ideas that we've published.",
                    "label": 0
                },
                {
                    "sent": "I'm going to focus on one particular case, which I think is.",
                    "label": 0
                },
                {
                    "sent": "I think it's realistic and also we can do a little bit of mathematics so we can actually.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of proof something about it.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is called triadic closure.",
                    "label": 0
                },
                {
                    "sent": "This is a very well studied topic in social Sciences.",
                    "label": 1
                },
                {
                    "sent": "The idea that the more friends you have in common with somebody, the more likely you are to become friends with that person.",
                    "label": 0
                },
                {
                    "sent": "It's a reasonable sort of hypothesis if you tend to interact with the same circle of friends, then you tend to make that that new friendship OK.",
                    "label": 0
                },
                {
                    "sent": "So in terms of what happens to the edges.",
                    "label": 0
                },
                {
                    "sent": "Well, given today's network, we're going to keep the death process simple, so we lose friends at some constant rate.",
                    "label": 0
                },
                {
                    "sent": "So independently of the network, if the edges there today, then there's some probability Omega that the edge will disappear tomorrow.",
                    "label": 0
                },
                {
                    "sent": "But here's the here's this tragic closure idea.",
                    "label": 0
                },
                {
                    "sent": "If there's an edge missing in today's network, then this is the probability.",
                    "label": 0
                },
                {
                    "sent": "So it's between those I&J.",
                    "label": 0
                },
                {
                    "sent": "This is the probability of that edge arising.",
                    "label": 0
                },
                {
                    "sent": "Between those I&J on the next day.",
                    "label": 0
                },
                {
                    "sent": "So there are two parameters here.",
                    "label": 0
                },
                {
                    "sent": "There's a Delta.",
                    "label": 0
                },
                {
                    "sent": "And an epsilon.",
                    "label": 0
                },
                {
                    "sent": "Delta is just the Basel rate state independent rate at which we may sort of arbitrarily make new friendships.",
                    "label": 0
                },
                {
                    "sent": "Epsilon.",
                    "label": 0
                },
                {
                    "sent": "Here is the strength of this tragic closure effect.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing here is raising today's adjacency matrix to the power two.",
                    "label": 0
                },
                {
                    "sent": "And, as we've heard several times.",
                    "label": 0
                },
                {
                    "sent": "Over the last couple of days, that's a way of counting the number of walks of length two or paths of length 2 between I&J.",
                    "label": 1
                },
                {
                    "sent": "Or in other words, it's the number of neighbors that I&J have in common number of friends that they share.",
                    "label": 0
                },
                {
                    "sent": "So the more friends Inj share, the bigger this quantity on epsilon.",
                    "label": 0
                },
                {
                    "sent": "Then is the strength that we associate with that tried it closure effect?",
                    "label": 1
                },
                {
                    "sent": "So it's a relatively simple although nonlinear model of edge birth overtime.",
                    "label": 0
                },
                {
                    "sent": "We need some constraints on the parameters just to guarantee that these this overall probabilities between zero and one.",
                    "label": 0
                },
                {
                    "sent": "So it's a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you a path of the Markov chain, so the state space is, that is, the set of all networks.",
                    "label": 0
                },
                {
                    "sent": "These are my parameters that I use all the way through, so in particular is 100 nodes.",
                    "label": 0
                },
                {
                    "sent": "And this network.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's time increasing in steps of 50 from time 0 up to time 750, and the dots are the edges in the adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "My notation here.",
                    "label": 0
                },
                {
                    "sent": "This is ER stands for Doctor Rainey.",
                    "label": 0
                },
                {
                    "sent": "Just the usual tossing a coin to put the edge in.",
                    "label": 0
                },
                {
                    "sent": "That's my initial condition with .3 as the probability of an edge.",
                    "label": 0
                },
                {
                    "sent": "So my starting graph.",
                    "label": 0
                },
                {
                    "sent": "Has it just placed uniformly at random with probability .3 so it's 30% dense to begin with?",
                    "label": 0
                },
                {
                    "sent": "If you let time evolve, this is 1 path through the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "I don't expect you to spot any patterns there other than to notice that there's more and more dots appearing, so the blue is increasing, so this is becoming denser overtime.",
                    "label": 0
                },
                {
                    "sent": "Done, in particular, if you count the edge density at the longest time 7:50, then it's around 71%.",
                    "label": 0
                },
                {
                    "sent": "So out of all the possible edges, about 71% exist after a long time.",
                    "label": 0
                },
                {
                    "sent": "And that's when I start with a 30% edge density at time 0.",
                    "label": 1
                },
                {
                    "sent": "So then taking the same model exactly, just changing the initial condition.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I start with a less dense network of 15% edges.",
                    "label": 0
                },
                {
                    "sent": "Let time evolve with the same modeling parameters, the same birth and death law, then this time.",
                    "label": 0
                },
                {
                    "sent": "Then just get get less dense and this largest time is 750.",
                    "label": 0
                },
                {
                    "sent": "We now have around 5% of the edges present in the network OK.",
                    "label": 0
                },
                {
                    "sent": "So those are just two independent.",
                    "label": 0
                },
                {
                    "sent": "Paths of the Markov chain starting at two different initial conditions but with the same modeling parameters.",
                    "label": 0
                },
                {
                    "sent": "So it's the same model, different initial data.",
                    "label": 0
                },
                {
                    "sent": "Can we explain why we get these two different types of long-term behavior?",
                    "label": 0
                },
                {
                    "sent": "Well, the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I wouldn't be showing you these.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experiments, so we're going to do what we call mean field and mean field is what physicists say when they don't really understand what they're doing.",
                    "label": 0
                },
                {
                    "sent": "That's my my summary.",
                    "label": 0
                },
                {
                    "sent": "So here's a statement which we've fairly clear is true.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's think about long-term behavior of this Markov chain.",
                    "label": 0
                },
                {
                    "sent": "While it's agatic everything that's fairly clear because of the way that the birth and death are defined, there's always some guaranteed non zero death and nonzero birth probability.",
                    "label": 0
                },
                {
                    "sent": "That means if you focus on a pair of nodes and look at the connectivity between those two nodes as time goes to Infinity, then the frequency with which you see an edge will tend to a constant.",
                    "label": 0
                },
                {
                    "sent": "As time goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So let's call that P star.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this pair of nodes, let time go to Infinity, the frequency with which you see the edge will overtime will converge to some number P star.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, there's nothing special about any particular pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "Everything is invariant under relabeling.",
                    "label": 0
                },
                {
                    "sent": "The dynamics don't depend on the on the on the node labeling, so it must be the same P star for every pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this longtime sense we must have an Erdos reyni type of structure where whatever edge concerns you that will appear with some fixed probability P star as time goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So in this sense, there's another trainee structure in the long time.",
                    "label": 0
                },
                {
                    "sent": "So taking that through and doing something heuristic, Now let's just ask ourselves what would happen if we did have an Erdos reyni graph that sometime that would be defined.",
                    "label": 0
                },
                {
                    "sent": "Solely by this scalar PK, this is the probability of seeing an edge between a pair of nodes at time K. So if we just insert this into our model.",
                    "label": 0
                },
                {
                    "sent": "What's the corresponding value for PK at the next time point?",
                    "label": 0
                },
                {
                    "sent": "If this really were a sensible thing to do, OK, so PK is the chance of the edge being there today.",
                    "label": 0
                },
                {
                    "sent": "What's the chance of an edge being there tomorrow?",
                    "label": 0
                },
                {
                    "sent": "Well, there are two cases.",
                    "label": 0
                },
                {
                    "sent": "Either it was there and it didn't die, so 1 minus Omega is the chance of it not dying and PKS and chance of it being there yesterday.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, maybe it wasn't there and it was born, and if I go back to the model.",
                    "label": 1
                },
                {
                    "sent": "The birth probability is a constant Delta plus epsilon times number of neighbors that they share.",
                    "label": 0
                },
                {
                    "sent": "So one man is PK is the chance it didn't exist yesterday.",
                    "label": 0
                },
                {
                    "sent": "This is our factor describing the chance of a birth, so there's the constant.",
                    "label": 0
                },
                {
                    "sent": "The Basel rate Delta.",
                    "label": 0
                },
                {
                    "sent": "There's the triadic closure strength, and now there are N -- 2 possible neighbors of these two nodes.",
                    "label": 0
                },
                {
                    "sent": "And the chance of the appropriate pair of edges being there so that I enjoy both connected to those neighbors, is given by P K. ^2.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is our heuristic mean field approximation to the behavior of the adjacency matrix in this model.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is a scalar parameter.",
                    "label": 0
                },
                {
                    "sent": "Now PK is just the density of the edges.",
                    "label": 0
                },
                {
                    "sent": "It's a macro parameter that we're trying to extract from this micro scale description OK. And it's a trivial nonlinear type of iteration.",
                    "label": 1
                },
                {
                    "sent": "It's a cubic iteration, so you can look for steady states of this, and you find that there are three real roots because it's a cubic, and this generically there are three.",
                    "label": 0
                },
                {
                    "sent": "If you have small parameters, and as you might expect, two of them turn out to be stable.",
                    "label": 0
                },
                {
                    "sent": "That's the dense and the sparse case, and in between them there's an unstable linearly unstable steady states, OK.",
                    "label": 0
                },
                {
                    "sent": "So for the parameters I used for my SIM.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elation the study states arise where these two curves meet, where the CU meets the linear.",
                    "label": 0
                },
                {
                    "sent": "I should say these are generated by Peter Green Rod in Nice low resolution that reading they can't afford many pixels.",
                    "label": 0
                },
                {
                    "sent": "So these are these are peaks pictures.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So this agrees with the simulation.",
                    "label": 0
                },
                {
                    "sent": "There's a, there's a.",
                    "label": 0
                },
                {
                    "sent": "The less dense, stable steady state is down at around 5%, the more dense steady state is up at 72%, and the unstable intermediate state is around 23% OK. And then just to.",
                    "label": 0
                },
                {
                    "sent": "Try to convince you a little bit more.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's a lovely smooth curve in Peter Green Rd style and the jagged curve.",
                    "label": 0
                },
                {
                    "sent": "The lovely smooth curve is this one.",
                    "label": 0
                },
                {
                    "sent": "And the jacket, the one is just above it.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing here is with one of these is a micro scale simulation of the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "Which we then extract macro features from.",
                    "label": 0
                },
                {
                    "sent": "So we simply count the edge density at every point in time for one path of the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "That's the jagged curve and the lovely smooth curve is just the mean field iteration, the PK plus one is a function of PK and you can see we can cause we're starting with the training with little bit of a cheat, but this macro mean field model.",
                    "label": 0
                },
                {
                    "sent": "Very nicely follows the micro scale simulation in terms of capturing this macro feature.",
                    "label": 0
                },
                {
                    "sent": "OK, if you didn't start with another trainee, there'd be a little bit of catch up time, but it would eventually follow the right kind of behavior.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This bistability is really what we think is the interesting part of all this.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing here is we're starting three, sorry, five independent paths from the same initial condition.",
                    "label": 0
                },
                {
                    "sent": "Which we specially chosen to be close to the unstable fixed point, so there's an unstable fixed point around the .23 edge density.",
                    "label": 1
                },
                {
                    "sent": "We start with exactly the same initial condition, but three.",
                    "label": 0
                },
                {
                    "sent": "Sorry, five different independent path.",
                    "label": 0
                },
                {
                    "sent": "So different micro scale noise and four of these curves decide to follow down to the lower of the stable fixed points.",
                    "label": 1
                },
                {
                    "sent": "But one of these because with the micro scale detail has enough impetus to get going and then lead itself up to this richer, denser, stable fixed point.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "In a sense, we can predict what's going to happen that we think there are these two stable fixed points, but we can't tell you which one is going to show up in a particular simulation.",
                    "label": 0
                },
                {
                    "sent": "And across this has some nice implications.",
                    "label": 0
                },
                {
                    "sent": "If you're a mobile phone company trying to generate customers, or if you're an online social network provider trying to get a nice rich interactive structure among your users and then you want to be up here and a little bit of work just to help this help this information to get going will allow that will allow the path to head up towards the desired fixed point and then you leave it alone and it very nicely carries on.",
                    "label": 0
                },
                {
                    "sent": "Then the self organizes into that rich state, whereas if you see this kind of behavior happening then you need to work a lot harder to get the get the desired behavior.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's a little bit about modeling, and I'll just wrap up that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Half of the talk with a summary and then some observations.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing here is using a stochastic modeling framework, focusing on the idea that edges can be born or can die from one time points to the next.",
                    "label": 0
                },
                {
                    "sent": "Then we tried to build in this law of motion based on triadic closure.",
                    "label": 1
                },
                {
                    "sent": "So the more friends two people have in common, the more likely they are to build a friendship at the next time point.",
                    "label": 1
                },
                {
                    "sent": "Then we have this mean field analysis, which seems to do a good job of predicting the behavior of the model.",
                    "label": 0
                },
                {
                    "sent": "At least that that particular macro scale feature.",
                    "label": 0
                },
                {
                    "sent": "There are many things that can be done in some of these we're working on, in particular, calibrating the model to some real data.",
                    "label": 0
                },
                {
                    "sent": "And because it's a stochastic model, as I said, it has a likelihood, so it's not particularly.",
                    "label": 0
                },
                {
                    "sent": "Difficult to see how you might calibrate that model.",
                    "label": 1
                },
                {
                    "sent": "Also, it's nested in the sense that epsilon equals to 0 is just completely Erdos reyni type behavior.",
                    "label": 0
                },
                {
                    "sent": "So you can do a nested comparison, then see whether Epson equals to 0 is more realistic than epsilon, greater than zero on some datasets, so you can test innosys tickle manner for whether you're seeing triadic closure in the dynamics.",
                    "label": 1
                },
                {
                    "sent": "We're doing discrete time and there are some interesting issues which I'll talk about later with anybody who's interested about trying to generalize this modeling framework to the case of continuous time is by no means obvious.",
                    "label": 0
                },
                {
                    "sent": "What to do in continuous time.",
                    "label": 0
                },
                {
                    "sent": "And we'd like to also analyze processes on this dynamic network.",
                    "label": 0
                },
                {
                    "sent": "Person SI model Sir model.",
                    "label": 0
                },
                {
                    "sent": "On top of that involving network, and we have a little bit of work in this direction.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe I'll stop there for any questions on the first half.",
                    "label": 0
                },
                {
                    "sent": "If anybody wants to chip in.",
                    "label": 0
                },
                {
                    "sent": "Yep, sure.",
                    "label": 0
                },
                {
                    "sent": "What you're saying is that you start with whatever you start with.",
                    "label": 0
                },
                {
                    "sent": "Men relationships evolve, yeah?",
                    "label": 0
                },
                {
                    "sent": "Summations.",
                    "label": 0
                },
                {
                    "sent": "As time goes Infinity, how many people are left and then assume that everything is independent to make calculations.",
                    "label": 0
                },
                {
                    "sent": "How many edges are left?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, yeah, yeah calculation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In that calculation, here is what I get.",
                    "label": 0
                },
                {
                    "sent": "I get three points to the staple, yeah?",
                    "label": 0
                },
                {
                    "sent": "What will happen in the true limit is something like that.",
                    "label": 0
                },
                {
                    "sent": "Is that well?",
                    "label": 0
                },
                {
                    "sent": "Well, there's one thing as I said, this is heuristic.",
                    "label": 0
                },
                {
                    "sent": "I was expecting a different kind of question.",
                    "label": 0
                },
                {
                    "sent": "On the one hand, I said this is agatic.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, I tried to convince you that there are two stable steady States and that those things don't go together, so they can't possibly mathematically be these two Delta functions both being the invariant measure.",
                    "label": 0
                },
                {
                    "sent": "So what what we?",
                    "label": 0
                },
                {
                    "sent": "I guess this is metastability that we're observing, and in the very, very long time you maybe see some mixture of those two.",
                    "label": 0
                },
                {
                    "sent": "Stable steady states dominating the behavior.",
                    "label": 0
                },
                {
                    "sent": "Answer your question.",
                    "label": 0
                },
                {
                    "sent": "Right, OK?",
                    "label": 0
                },
                {
                    "sent": ".",
                    "label": 0
                },
                {
                    "sent": "Approximation tool.",
                    "label": 0
                },
                {
                    "sent": "But in practice it seems to work.",
                    "label": 0
                },
                {
                    "sent": "We haven't gotten.",
                    "label": 0
                },
                {
                    "sent": "We haven't got a proof and that I'm not sure that you could well, but you can't because it's not what you said Godik, and we're trying to claim there are two measures, so that's why we didn't try and make it rigorous because it can't possibly be rigorous.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the arguments that you know, I think there's an approximation.",
                    "label": 0
                },
                {
                    "sent": "They do seem to be reasonable.",
                    "label": 0
                },
                {
                    "sent": "Framework, but if you think about it, there's a threshold point.",
                    "label": 0
                },
                {
                    "sent": "Winfield is terministic.",
                    "label": 0
                },
                {
                    "sent": "It's just that.",
                    "label": 0
                },
                {
                    "sent": "Never, never be correct.",
                    "label": 0
                },
                {
                    "sent": "Statistics actually.",
                    "label": 0
                },
                {
                    "sent": "Where where you're near an unstable?",
                    "label": 0
                },
                {
                    "sent": "Put this near me, but anyway anyway.",
                    "label": 0
                },
                {
                    "sent": "Similarly, anywhere where you're in a network which is particularly sparse and say the traffic closures support, that's going to cover fall down because the mere details suppose you had a network that was that had no Delta and Delta is 0.",
                    "label": 0
                },
                {
                    "sent": "The only means making friends is to make friends with people who are already friends of friends.",
                    "label": 0
                },
                {
                    "sent": "So if we start off split into two groups, Brazilians and British people, then because none of us know each other will never make friends.",
                    "label": 0
                },
                {
                    "sent": "Where is the Bing field they would?",
                    "label": 0
                },
                {
                    "sent": "There are cases when actually just putting Delta back in kind of risk.",
                    "label": 0
                },
                {
                    "sent": "But in general, anywhere where the stochastic details of the actual networks matter, the actual initial conditions, or you're close to her, or you close to a an unstable point.",
                    "label": 0
                },
                {
                    "sent": "Actually it can only be a wish that, yeah, I think any sort of proof.",
                    "label": 0
                },
                {
                    "sent": "Nothing really, really complicated, involving metastability and transient.",
                    "label": 0
                },
                {
                    "sent": "It's not the kind of thing we like to get into.",
                    "label": 0
                },
                {
                    "sent": "Weather no feel free to know.",
                    "label": 0
                },
                {
                    "sent": "Theory of birthday.",
                    "label": 0
                },
                {
                    "sent": "Yum.",
                    "label": 0
                },
                {
                    "sent": "Yum, Yum.",
                    "label": 0
                },
                {
                    "sent": "Film.",
                    "label": 0
                },
                {
                    "sent": "Yes, sorry mark.",
                    "label": 0
                },
                {
                    "sent": "Square films.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, we discussed this, but we haven't tried it.",
                    "label": 0
                },
                {
                    "sent": "We think the heuristics are much less valid in the case of higher powers of a.",
                    "label": 0
                },
                {
                    "sent": "If you think of the independence assumption, this is very neat.",
                    "label": 0
                },
                {
                    "sent": "The way this P ^2.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comes in, you know what's the chance of the two neighbors both being connected to the to the right nodes if you if you start raising powers, you can write down the mean field model, but we don't think it's as useful.",
                    "label": 0
                },
                {
                    "sent": "We haven't tried that yet.",
                    "label": 0
                },
                {
                    "sent": "We we haven't.",
                    "label": 0
                },
                {
                    "sent": "We haven't tried it, but we just think it's interesting.",
                    "label": 0
                },
                {
                    "sent": "But we think it's not so valid as this.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah sure yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah sure yeah yeah yeah yeah yeah yeah sure.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll press on.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second part of the talk is the opposite is data driven.",
                    "label": 0
                },
                {
                    "sent": "Trying to extract things from from networks.",
                    "label": 0
                },
                {
                    "sent": "This builds on some work with an S to and Pete and Mark Parsons as a student at Reading.",
                    "label": 0
                },
                {
                    "sent": "This goes back to this idea of what counting and the original paper I'm aware of is Leo Katz from 1953, where he used walks to measure centrality.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we're thinking of independent networks, and which nodes are important and how can messages be passed around?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So suppose you have.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This kind of structure on three days.",
                    "label": 0
                },
                {
                    "sent": "They mention this is being done directed then.",
                    "label": 0
                },
                {
                    "sent": "If you look at how a might communicate with C on time 1A, communicate with G and then at time 2G can talk to see, but there's no way that she can talk to a with that structure.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a lack of symmetry, even though each network is symmetric.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Times Arrow introduces his lack of symmetry, so you have to be careful what you mean by communication.",
                    "label": 1
                },
                {
                    "sent": "But as Mark said yesterday there's a fairly obvious idea of walking around.",
                    "label": 0
                },
                {
                    "sent": "You can just use the edges that are available and then the next time point you can use more edges.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this notation where we have the TCR, the time points and the corresponding adjacency matrices, you can define a dynamic walk.",
                    "label": 1
                },
                {
                    "sent": "The length is the number of edges that you go across, so you need a sequence of time points and a sequence of edges that take you between the nodes and the edges have to exist at the appropriate times, so it's perfectly natural.",
                    "label": 1
                },
                {
                    "sent": "Concept we allow the same time to be used by more than one edge so you can traverse.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two or three edges on one day and then go ahead and take as many edges like on the next day.",
                    "label": 0
                },
                {
                    "sent": "That's the that's the way we've defined it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The Cat Scientology is based on powering up the Matrix to count walks and it turns out there's a very similar concept in this dynamic setting.",
                    "label": 1
                },
                {
                    "sent": "If you multiply together.",
                    "label": 0
                },
                {
                    "sent": "The adjacency matrices at possibly different time points, then that simply combinatoric Lee counts the walks that take place using edges on the appropriate time points.",
                    "label": 0
                },
                {
                    "sent": "So this product with some arbitrary set of time points has an IJ element that counts how many walks there are from I to J from factors or using W edges where the corresponding edges exists at those time points OK.",
                    "label": 1
                },
                {
                    "sent": "So we'd like to look at all the possible ways to walk between I&J respecting this time ordering, so we'd like to keep track of all these kinds of walks here, so we'd like a term like this where you take a step on day zero and a step on day one, and will use that cat style down waiting the resolvement style where we multiply by Alpha squared.",
                    "label": 0
                },
                {
                    "sent": "If there are two edges.",
                    "label": 0
                },
                {
                    "sent": "Here's a term which takes a step on day zero step on day two, day three, and day seven.",
                    "label": 0
                },
                {
                    "sent": "And because there are four edges, we down weight by Alpha to the four.",
                    "label": 0
                },
                {
                    "sent": "This one takes 2 steps on day three and then one step on day nine and that has an Alpha cubed, so we'd like all the possible terms of that form where you have non increasing time indices and a corresponding power of Alpha that matches the number of edges.",
                    "label": 0
                },
                {
                    "sent": "OK, so we'd like to put all those terms together, which might sound combinatorially difficult, but it turns out all you have to do is multiply together the matrix resolving's OK in the appropriate order.",
                    "label": 0
                },
                {
                    "sent": "So this is generalizing the cuts resolvement into time dependence.",
                    "label": 0
                },
                {
                    "sent": "Networks call this matrix Q and then the ijaaf entry in Q summarizes how well I can pass messages or communicate with J over that time dependent data.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can sum along the Rose to see how well know Dan is communicating with all all the other nodes in the network, and you can some down the columns to see how well know Denny's receiving information from all the nodes in the network.",
                    "label": 0
                },
                {
                    "sent": "So we call this the broadcast and the receive communicability.",
                    "label": 1
                },
                {
                    "sent": "So it's like a centrality measure.",
                    "label": 0
                },
                {
                    "sent": "In terms of broadcasting and then one in terms of receiving.",
                    "label": 0
                },
                {
                    "sent": "It generalizes cats if you have one time point.",
                    "label": 0
                },
                {
                    "sent": "It reduces to cats.",
                    "label": 0
                },
                {
                    "sent": "Actively cheap to do because those matrixes solvents involve sparse matrices, so it's a sparse matrix.",
                    "label": 0
                },
                {
                    "sent": "Solve that each time point.",
                    "label": 1
                },
                {
                    "sent": "And the fact that dynamic walks are not symmetric is really mirrored in the fact that matrix multiplication is not commutative.",
                    "label": 0
                },
                {
                    "sent": "So if you change the order of the time points, you certainly change these centrality measures.",
                    "label": 0
                },
                {
                    "sent": "So we are respecting the order of the time.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "This is from some other work with the postdoc Alex months Iris, where we have another model that I haven't got time to talk about.",
                    "label": 0
                },
                {
                    "sent": "This is the Enron datasets 150 people or so.",
                    "label": 0
                },
                {
                    "sent": "Each each point here is a person on the horizontal axis.",
                    "label": 0
                },
                {
                    "sent": "We just look at their total degree, how many emails they turned out on this axis.",
                    "label": 0
                },
                {
                    "sent": "We look at the broadcast centrality.",
                    "label": 0
                },
                {
                    "sent": "So this is what we think is a better measure of how well they can get out.",
                    "label": 0
                },
                {
                    "sent": "Information across the network.",
                    "label": 0
                },
                {
                    "sent": "I'm sure there are a couple of people here who stand out as having high broadcasts without a particularly high bandwidth, and it turns out this is the vice president and an executive of the company.",
                    "label": 0
                },
                {
                    "sent": "Whereas there are three people out here who were working very hard, sending out lots of messages.",
                    "label": 0
                },
                {
                    "sent": "But in terms of the broadcast centrality not doing particularly well, and two of these people were traders and one is unknown in terms of their their job.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's certainly different.",
                    "label": 0
                },
                {
                    "sent": "This broadcast centrality is different to simply counting.",
                    "label": 0
                },
                {
                    "sent": "How many messages?",
                    "label": 0
                },
                {
                    "sent": "How many edges somebody has?",
                    "label": 0
                },
                {
                    "sent": "It's about the timing of the edges and the follow on effect.",
                    "label": 0
                },
                {
                    "sent": "Once you sent your message, who else is passing it on?",
                    "label": 0
                },
                {
                    "sent": "That's what this is trying to capture.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, just briefly, we have a new version of this which allows for time down waiting.",
                    "label": 1
                },
                {
                    "sent": "The previous version treats all the walks over the whole time period as being equally important, and we only discount according to length.",
                    "label": 0
                },
                {
                    "sent": "The number of edges, while you can also discount according to time.",
                    "label": 1
                },
                {
                    "sent": "So it's a very old message that started along time ago.",
                    "label": 0
                },
                {
                    "sent": "Then you might want to down weight it by its age.",
                    "label": 0
                },
                {
                    "sent": "So by updating this iteration in this way where we introduced this scaling factor where Delta T is the interval of time between one day or one time point in the next.",
                    "label": 0
                },
                {
                    "sent": "Then this matrix SK again is combinatorially counting all the walks between I&J, but that's before we scale a walk of length W in terms of edges by output of the W. But we also now scale.",
                    "label": 1
                },
                {
                    "sent": "The walk that's T unit sold by E to the minus BT and so this updates both the edge waiting and also the time waiting.",
                    "label": 0
                },
                {
                    "sent": "So this parameter B goes from zero to Infinity.",
                    "label": 0
                },
                {
                    "sent": "0 is the previous algorithm and Infinity is just focusing on one day at a time and forgetting all the previous information.",
                    "label": 1
                },
                {
                    "sent": "So, just briefly to show you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be might be useful.",
                    "label": 0
                },
                {
                    "sent": "This is a synthetic test using real data.",
                    "label": 0
                },
                {
                    "sent": "The Enron data.",
                    "label": 0
                },
                {
                    "sent": "Again, this is a bit like link prediction, but we're now doing centrality prediction.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to predict tomorrow's Katz centrality of that network using today's information and information today or earlier.",
                    "label": 0
                },
                {
                    "sent": "We look at the correlation between our prediction for centrality and the true centrality on the next day we send those correlations over all the time points.",
                    "label": 0
                },
                {
                    "sent": "So a bigger number means we're doing better at predicting tomorrow's centrality.",
                    "label": 0
                },
                {
                    "sent": "And what I'm showing here is how that varies as a function of B, so B = 0 means we're using all the previous information and counting it equally.",
                    "label": 0
                },
                {
                    "sent": "B equals Infinity, or in this case 3 means that we just using today's network to try and predict tomorrow's network OK, and you can see there's some intermediate here around .3 where we do a better job.",
                    "label": 0
                },
                {
                    "sent": "So by using old information but not giving it the same weight as current information then we can get a better prediction both in the tense of broadcasting and receiving.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to finish up what we think is new, here is formalizing a dynamic walk and using it to generalize the cat centrality.",
                    "label": 1
                },
                {
                    "sent": "And pointing out that this gives you new information, there are some people who seem to punch above their weight.",
                    "label": 0
                },
                {
                    "sent": "The bandwidth is relatively low, but they can get messages out across the network efficiently.",
                    "label": 1
                },
                {
                    "sent": "We'd like to do this for weighted edges that we're interested in doing this for very large scale computations, so the linear algebra aspect and the computational side is important.",
                    "label": 0
                },
                {
                    "sent": "This can be done in real time in principle, so we can categorise networks and then monitor what's happening and maybe maybe flag some kind of warning if the network seems to have changed.",
                    "label": 0
                },
                {
                    "sent": "Look at who's speaking who's trending, who's going up or down in terms of their centrality measures?",
                    "label": 0
                },
                {
                    "sent": "Maybe intervene at the appropriate places.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll finish there and just thanks to various funding agencies.",
                    "label": 1
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So you can use like you to test.",
                    "label": 0
                },
                {
                    "sent": "This is yeah.",
                    "label": 0
                },
                {
                    "sent": "But if I just give you a network, just a snapshot of the network, and they don't tell you how many times steps there were, right?",
                    "label": 0
                },
                {
                    "sent": "How easy is it to destination?",
                    "label": 0
                },
                {
                    "sent": "If it's only one time points, then there's not really feasible.",
                    "label": 0
                },
                {
                    "sent": "If you have a number of time points, then we just have to assume that is the discrete time interval between network samples and that's that's what we're doing.",
                    "label": 0
                },
                {
                    "sent": "Essentially, the Enron email data is real time email, and we tend to summarize it in terms of days or hours or weeks, so that's the level at which we're doing things.",
                    "label": 0
                },
                {
                    "sent": "So if there's no more than 10 data points, time points.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of thing that we're doing at the moment.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's very nice, but.",
                    "label": 0
                },
                {
                    "sent": "Respect with I mean how can you extract some useful information from it?",
                    "label": 0
                },
                {
                    "sent": "Because it's so complicated object, let's say.",
                    "label": 0
                },
                {
                    "sent": "So what what do you have in mind to computer completely or to the right?",
                    "label": 0
                },
                {
                    "sent": "Well, this really.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "So this is once you take this sum this is Q * A vector of ones.",
                    "label": 0
                },
                {
                    "sent": "So it's just a vector so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you want, yeah, so in general it's this times a vector that we're trying to find.",
                    "label": 0
                },
                {
                    "sent": "So inverting a matrix times vector that solving a linear system.",
                    "label": 0
                },
                {
                    "sent": "This is a sparse.",
                    "label": 0
                },
                {
                    "sent": "This is a sparse matrix, so it's one.",
                    "label": 0
                },
                {
                    "sent": "One sparse matrix solve per time step, which is feasable you know this compared to what Google does.",
                    "label": 0
                },
                {
                    "sent": "It all information I found this could well obtain all information about all possible paths in this, yes.",
                    "label": 0
                },
                {
                    "sent": "Summarized summarized by this weighting factor.",
                    "label": 0
                },
                {
                    "sent": "So in principle you could extract many many things from this quantity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it's still pairwise is still whatever inj units.",
                    "label": 0
                },
                {
                    "sent": "One summary of how I&J are communicating.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so you could cluster that and you could look at the way communities evolve overtime, that's one.",
                    "label": 0
                },
                {
                    "sent": "Possibility we think is exciting.",
                    "label": 0
                },
                {
                    "sent": "Many countries that people expected, yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "This is the best we think this is a good static summary of current of what's going on so far.",
                    "label": 1
                },
                {
                    "sent": "This is like a weighted network at Time K telling you what's happened so far.",
                    "label": 0
                },
                {
                    "sent": "That's one way of describing it.",
                    "label": 0
                },
                {
                    "sent": "What would be the typical complexity of this calculation and compute this computer while solving a linear system?",
                    "label": 0
                },
                {
                    "sent": "It's roughly order end if there's only a fixed number of edges per node, then it scales like order, end, or you can always just replace this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, so for every day, yeah, and per day.",
                    "label": 0
                },
                {
                    "sent": "But also you can approximate you can you can approximate this by 1 plus Alpha Ray and then it's just a matrix multiplication.",
                    "label": 0
                },
                {
                    "sent": "So that is really order N per days.",
                    "label": 0
                },
                {
                    "sent": "Numerical analysis by Basia.",
                    "label": 0
                },
                {
                    "sent": "Use the quadrature rule.",
                    "label": 0
                },
                {
                    "sent": "And they solve this in a very efficient way, so they have developed now program so you can do it in seconds or something like that 400,000 nodes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Just published in linear algebra and this application went to 10.",
                    "label": 0
                },
                {
                    "sent": "So we had a guy from Telenor saying they can just about over the weekend.",
                    "label": 1
                },
                {
                    "sent": "The multiply the matrix by vector of all their employees or their own customers.",
                    "label": 0
                },
                {
                    "sent": "So they're quite happy to think about this kind of computation.",
                    "label": 0
                },
                {
                    "sent": "What they can't do is compute and eigenvector of the adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "That would be just too unthinkable, but they can multiply the matrix into a vector.",
                    "label": 0
                }
            ]
        }
    }
}