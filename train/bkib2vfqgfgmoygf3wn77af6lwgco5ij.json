{
    "id": "bkib2vfqgfgmoygf3wn77af6lwgco5ij",
    "title": "High-coverage extraction of semantic assertions from text",
    "info": {
        "author": [
            "Dunja Mladeni\u0107, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Nov. 4, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Text Mining"
        ]
    },
    "url": "http://videolectures.net/sikdd2011_mladenic_assertions/",
    "segmentation": [
        [
            "As Marco mentioned, this is joint work with media Trampusch and actually it's part of his PhD thesis and it is you see it's related to the previous talk.",
            "This one is on high coverage extraction of semantic assertions from text."
        ],
        [
            "So it's completely different goal.",
            "Nevertheless, we use some similar methods.",
            "So the task here.",
            "Is what we have is text at the input and output.",
            "We would like to have semantic assertions which are made in the text.",
            "So we want to extract them out of the text.",
            "And in the approach here we do, we use simplification, which we extract only the simplest semantic assertions.",
            "So this is 1 example.",
            "If you have a sentence, John Rode the bike to work yesterday.",
            "What we want to extract out of the sentence are.",
            "Two predicates, right.",
            "John B&B is a bike."
        ],
        [
            "So I kept the slide because media prepared the slides last night and he said this is a sad panda.",
            "And the pond.",
            "I said, because nobody knows how to extract most of their search assertions while maintaining high accuracy.",
            "And as we heard in the doc, there is a precision is fairly high.",
            "Nevertheless, recall is low for the usual systems for semantic role labeling and this means they don't extract most of the assertions they extract just a small proportion of the assertions in the text."
        ],
        [
            "So this is what they just explain.",
            "If we look at the performance at the precision recall, let me just remind you precision is what we extract.",
            "Is it good?",
            "How good is what we extracted?",
            "How much of the extracted things are really correct?",
            "And recall is whatever had to be extracted is present in the text?",
            "How much of that we managed to capture and the existing system mainly work on precision.",
            "What we would like to do is.",
            "Get a bit higher recall, which means.",
            "Of course we have to sacrifice.",
            "Unfortunately some precision, but that's usually in the systems you kind of tradeoff between precision and recall, so there's the reason why we're not using existing ASIN."
        ],
        [
            "Stems for the approach and also the story here is using background knowledge so bad."
        ],
        [
            "Knowledge yes, and in our case background knowledge is ontology.",
            "We decided for Psych as a large general purpose ontology.",
            "And it uses predicate logic in line with the example we had.",
            "So something like that could be then inserted or matched with psych ontology of problem with psyches that we didn't have training data for expressing text in psychologic evened out in house.",
            "There are some examples available, so we should also work on getting that, but currently we didn't have the training data.",
            "Psych thus have natural language component, but the coverage is poor beyond single words, so."
        ],
        [
            "We can't use much of that.",
            "What we put as the glue between text an psych because I said from text we want to go into logical form for is Framenet, so we have frames.",
            "Frame that is a database or shell ontology of semantic frames and their roles, and we heard about frames in previous talk.",
            "So let me just show an example.",
            "The sentence we had, John wrote a bike to work yesterday.",
            "This is a frame which goes on.",
            "This sentence can be applied because there is.",
            "Write wrote word in there and this frame has information in it that it is invoked by the following round walk.",
            "Drive right stroll and so on, and hear a different roles you can have in the frame.",
            "So there is a mover.",
            "Means destination speed, and in this sentence we find Hoover, which is John means which is bike and destination is to work.",
            "So a good part of using frame net is that there are some.",
            "There are frames and for frames there are sentences which are labeled by this roles in the frame.",
            "So we have training data to train.",
            "Using machine learning methods.",
            "What is not brilliant about using frame rate is that ontology afraid of frames and rose is too shallow and sparse for general purpose.",
            "What we would like to do, but now we're doing research and we're limiting ourselves to."
        ],
        [
            "What is available?",
            "So the idea is putting frame net and psych together.",
            "So the text we first annotate using frame net and then we do the mapping of annotation to psych so there is text map by frame, net and then this frame that mapping is connected to psych."
        ],
        [
            "But the general goal is still the same, right?",
            "We have text and we want to get logical form out of that.",
            "So first, how do we do this semantic role labeling?"
        ],
        [
            "I said we're not using the existing system because we want to have higher recall than what they have.",
            "So we use the standard breakdown into task.",
            "We find first which frames appear in a sentence and currently it is done in rather nevet recall oriented I mentioned in the frame.",
            "If you remember there was this right.",
            "Was there are different words listed in the frame as invoking the frame?",
            "So we just check for them in the sentence and in the case of this John Rode the bike there was route.",
            "We find the normalized form of that lemma, which is right right, occurred in the frame, so that frame of moving or what was it moving or something applies to our sentence.",
            "Once we collect all the frames that can map to the sentence, we also need to detect.",
            "Overall bond there is, so we need to identify phrases that fill a role.",
            "If you remember in that frame previously we had a mover, we had the means we had destination so we need to find them in order to fill in this roles in the frame.",
            "And we need to classify rolls, decide which role they feel right, not all the roles need to be filled in the previous frame.",
            "If you remember, I think there was time or something which wasn't filled in our sentence.",
            "So there was something that wasn't filled and the last two steps are usually done together.",
            "And that's also how."
        ],
        [
            "Do them.",
            "OK, so basically this is the process we go from text parsing.",
            "It get parse trees for every node in the parse tree, extract features.",
            "Once we have features we do supervised learning using SVM and we get a model and this model is then used for this labeling, semantic role labeling and these are feature examples which are used for training machine learning.",
            "So in frame net.",
            "We have labeled sentences and this is our training data so you can see it's lemma of the frame evoking award.",
            "This was this right.",
            "There was a sentence it said John Rode the bike will amortize it.",
            "John Ride a bike in the frame there was verb right.",
            "So we match the two.",
            "There are tax of a node text of apparent node.",
            "Was it active or passive voice of sentence and part of speech tagging?"
        ],
        [
            "OK, so now we assume we mapped this text onto frames.",
            "Now we're mapping frames in psych.",
            "Approximately 600 frames are kind of interesting.",
            "They're action related, and that can be mapped to psych nicely.",
            "The mapping was done in a semi supervised way.",
            "We used psych natural language component to identify possible matching for a frame, and then we choose the best candidate by."
        ],
        [
            "Tent.",
            "So in general, each frame has about 5 to 10 rolls.",
            "We saw an example frame which had, I think four or five, but they can be more.",
            "So there are several roles to map.",
            "It's too much work to do manually, so we did automatically by computing similarity between frame net roles and cycles, namely, psych has also some of the kind of frames and roles defined, so we can try to map measure similarity between cycles and frame net roles, and this is used in usual way using bag of words, description of the rolls."
        ],
        [
            "So these are all feeling filling the roles mapping is essentially word sense disambiguation and currently we did a quick solution here.",
            "We just wanted to get the whole work done vertical, so at several steps we just decided for a very basic solution.",
            "But there is also a word sense disambiguation approach which is being worked on in our Department.",
            "That's artificial intelligence laboratory, by the way.",
            "So we hope to use that later an make.",
            "The whole approach bit more rich or advanced.",
            "So it's a two step approach.",
            "We first identify the headword of a role filler and then use Sykes Natural language processing."
        ],
        [
            "Predicates to map method."
        ],
        [
            "So very kind of preliminary evaluation on some sample of frames.",
            "So for three, parsing accuracy is 90%, so these are now different steps we're doing right.",
            "From text we do parsing.",
            "It's 90%, that's fine, that's parser we're using then semantic role labeling, which we're doing is about 65% precision.",
            "Then there is a frame night psych alignment we achieved about 45.",
            "Percent accuracy on that.",
            "We did test.",
            "What is the maximum?",
            "Basically 75 would be maximum which could be achieved and then with more sense disambiguation about 60% accuracy.",
            "So you can see that there is a lot of space."
        ],
        [
            "As for further improvement, this is an example just to show you that we really get Ourmedia got his hands really dirty working on getting some real things, so this is a sentence.",
            "If we look at the first sentence to understand and appreciate the Bush administration's policy regarding Israeli Prime Minister and so on, this is a fact which extract it from the first sentence in annotation as used by psych.",
            "So you can see there is some organization policy and there is object improved, comprehending and then there is a we for which psych didn't know what it means, but it says in the text in the sentence V and then there is this organization policy was evaluating.",
            "Um?",
            "And then again, there is V. There is some exercising health or attractive control over something which was performed and so on.",
            "So predicates along some of them are really that long also inside.",
            "So we use what is there.",
            "This is from the second sentence is an example.",
            "If you keep reading this example.",
            "So this is just to give you a taste that.",
            "How it looks?",
            "What is happening if you have text and what we get at the output?"
        ],
        [
            "That's it, I can take some questions if there are and then for more I'll have to.",
            "Get you to Meteor who is currently actually an internship at Facebook, so that's why he can't be here.",
            "Yes.",
            "Pregnant, yes, the goal here is to have high recoil, right?",
            "To have high recall than usual.",
            "They are limited them to detect only."
        ],
        [
            "Sensors that fit into the frames, so you're basically already limited by the framing.",
            "So what's in the frame net?",
            "So there are for this particular frame.",
            "If you look at it, there are these different words, and if you can find any of this in a sentence, then you then you can match it, you can say.",
            "If you don't, then you cannot.",
            "But then you are limited.",
            "I don't know how big is this pregnant so, but it's fairly big.",
            "I mean, for the testing we used really.",
            "Like 1021 case, 10 frames in another 2025, but there are much more many more.",
            "The problem is also that we are limited in the sense of we can use those frames which have possibility of being matched to psych.",
            "Right, so there is also this limitation.",
            "But at the end you have to do something if you don't have frames.",
            "Right, it's a kind of additional knowledge.",
            "It's hard to get high recall if you use something like this, 'cause then you're automatically limited.",
            "I said I see what you're saying.",
            "I see what you're saying but.",
            "It's not the problem in that sense.",
            "There are enough frames which match.",
            "Yeah, and they have, yeah.",
            "Introduce bias into strains, but I don't know this whole collection either, but some are generally.",
            "From there it is designed in such a way that.",
            "Basically at the end, yeah, so it has this or the content of sentence is eventually some frames and covers the settings.",
            "Any other question or comment?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As Marco mentioned, this is joint work with media Trampusch and actually it's part of his PhD thesis and it is you see it's related to the previous talk.",
                    "label": 0
                },
                {
                    "sent": "This one is on high coverage extraction of semantic assertions from text.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's completely different goal.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, we use some similar methods.",
                    "label": 0
                },
                {
                    "sent": "So the task here.",
                    "label": 0
                },
                {
                    "sent": "Is what we have is text at the input and output.",
                    "label": 0
                },
                {
                    "sent": "We would like to have semantic assertions which are made in the text.",
                    "label": 0
                },
                {
                    "sent": "So we want to extract them out of the text.",
                    "label": 0
                },
                {
                    "sent": "And in the approach here we do, we use simplification, which we extract only the simplest semantic assertions.",
                    "label": 1
                },
                {
                    "sent": "So this is 1 example.",
                    "label": 1
                },
                {
                    "sent": "If you have a sentence, John Rode the bike to work yesterday.",
                    "label": 0
                },
                {
                    "sent": "What we want to extract out of the sentence are.",
                    "label": 0
                },
                {
                    "sent": "Two predicates, right.",
                    "label": 0
                },
                {
                    "sent": "John B&B is a bike.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I kept the slide because media prepared the slides last night and he said this is a sad panda.",
                    "label": 0
                },
                {
                    "sent": "And the pond.",
                    "label": 0
                },
                {
                    "sent": "I said, because nobody knows how to extract most of their search assertions while maintaining high accuracy.",
                    "label": 1
                },
                {
                    "sent": "And as we heard in the doc, there is a precision is fairly high.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, recall is low for the usual systems for semantic role labeling and this means they don't extract most of the assertions they extract just a small proportion of the assertions in the text.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what they just explain.",
                    "label": 0
                },
                {
                    "sent": "If we look at the performance at the precision recall, let me just remind you precision is what we extract.",
                    "label": 0
                },
                {
                    "sent": "Is it good?",
                    "label": 0
                },
                {
                    "sent": "How good is what we extracted?",
                    "label": 0
                },
                {
                    "sent": "How much of the extracted things are really correct?",
                    "label": 0
                },
                {
                    "sent": "And recall is whatever had to be extracted is present in the text?",
                    "label": 0
                },
                {
                    "sent": "How much of that we managed to capture and the existing system mainly work on precision.",
                    "label": 0
                },
                {
                    "sent": "What we would like to do is.",
                    "label": 0
                },
                {
                    "sent": "Get a bit higher recall, which means.",
                    "label": 0
                },
                {
                    "sent": "Of course we have to sacrifice.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately some precision, but that's usually in the systems you kind of tradeoff between precision and recall, so there's the reason why we're not using existing ASIN.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stems for the approach and also the story here is using background knowledge so bad.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Knowledge yes, and in our case background knowledge is ontology.",
                    "label": 0
                },
                {
                    "sent": "We decided for Psych as a large general purpose ontology.",
                    "label": 0
                },
                {
                    "sent": "And it uses predicate logic in line with the example we had.",
                    "label": 1
                },
                {
                    "sent": "So something like that could be then inserted or matched with psych ontology of problem with psyches that we didn't have training data for expressing text in psychologic evened out in house.",
                    "label": 0
                },
                {
                    "sent": "There are some examples available, so we should also work on getting that, but currently we didn't have the training data.",
                    "label": 0
                },
                {
                    "sent": "Psych thus have natural language component, but the coverage is poor beyond single words, so.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can't use much of that.",
                    "label": 0
                },
                {
                    "sent": "What we put as the glue between text an psych because I said from text we want to go into logical form for is Framenet, so we have frames.",
                    "label": 0
                },
                {
                    "sent": "Frame that is a database or shell ontology of semantic frames and their roles, and we heard about frames in previous talk.",
                    "label": 1
                },
                {
                    "sent": "So let me just show an example.",
                    "label": 1
                },
                {
                    "sent": "The sentence we had, John wrote a bike to work yesterday.",
                    "label": 0
                },
                {
                    "sent": "This is a frame which goes on.",
                    "label": 0
                },
                {
                    "sent": "This sentence can be applied because there is.",
                    "label": 0
                },
                {
                    "sent": "Write wrote word in there and this frame has information in it that it is invoked by the following round walk.",
                    "label": 0
                },
                {
                    "sent": "Drive right stroll and so on, and hear a different roles you can have in the frame.",
                    "label": 0
                },
                {
                    "sent": "So there is a mover.",
                    "label": 0
                },
                {
                    "sent": "Means destination speed, and in this sentence we find Hoover, which is John means which is bike and destination is to work.",
                    "label": 0
                },
                {
                    "sent": "So a good part of using frame net is that there are some.",
                    "label": 0
                },
                {
                    "sent": "There are frames and for frames there are sentences which are labeled by this roles in the frame.",
                    "label": 0
                },
                {
                    "sent": "So we have training data to train.",
                    "label": 0
                },
                {
                    "sent": "Using machine learning methods.",
                    "label": 1
                },
                {
                    "sent": "What is not brilliant about using frame rate is that ontology afraid of frames and rose is too shallow and sparse for general purpose.",
                    "label": 0
                },
                {
                    "sent": "What we would like to do, but now we're doing research and we're limiting ourselves to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is available?",
                    "label": 0
                },
                {
                    "sent": "So the idea is putting frame net and psych together.",
                    "label": 0
                },
                {
                    "sent": "So the text we first annotate using frame net and then we do the mapping of annotation to psych so there is text map by frame, net and then this frame that mapping is connected to psych.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the general goal is still the same, right?",
                    "label": 0
                },
                {
                    "sent": "We have text and we want to get logical form out of that.",
                    "label": 0
                },
                {
                    "sent": "So first, how do we do this semantic role labeling?",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I said we're not using the existing system because we want to have higher recall than what they have.",
                    "label": 0
                },
                {
                    "sent": "So we use the standard breakdown into task.",
                    "label": 1
                },
                {
                    "sent": "We find first which frames appear in a sentence and currently it is done in rather nevet recall oriented I mentioned in the frame.",
                    "label": 1
                },
                {
                    "sent": "If you remember there was this right.",
                    "label": 0
                },
                {
                    "sent": "Was there are different words listed in the frame as invoking the frame?",
                    "label": 0
                },
                {
                    "sent": "So we just check for them in the sentence and in the case of this John Rode the bike there was route.",
                    "label": 0
                },
                {
                    "sent": "We find the normalized form of that lemma, which is right right, occurred in the frame, so that frame of moving or what was it moving or something applies to our sentence.",
                    "label": 0
                },
                {
                    "sent": "Once we collect all the frames that can map to the sentence, we also need to detect.",
                    "label": 1
                },
                {
                    "sent": "Overall bond there is, so we need to identify phrases that fill a role.",
                    "label": 0
                },
                {
                    "sent": "If you remember in that frame previously we had a mover, we had the means we had destination so we need to find them in order to fill in this roles in the frame.",
                    "label": 0
                },
                {
                    "sent": "And we need to classify rolls, decide which role they feel right, not all the roles need to be filled in the previous frame.",
                    "label": 1
                },
                {
                    "sent": "If you remember, I think there was time or something which wasn't filled in our sentence.",
                    "label": 0
                },
                {
                    "sent": "So there was something that wasn't filled and the last two steps are usually done together.",
                    "label": 0
                },
                {
                    "sent": "And that's also how.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do them.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically this is the process we go from text parsing.",
                    "label": 0
                },
                {
                    "sent": "It get parse trees for every node in the parse tree, extract features.",
                    "label": 1
                },
                {
                    "sent": "Once we have features we do supervised learning using SVM and we get a model and this model is then used for this labeling, semantic role labeling and these are feature examples which are used for training machine learning.",
                    "label": 0
                },
                {
                    "sent": "So in frame net.",
                    "label": 1
                },
                {
                    "sent": "We have labeled sentences and this is our training data so you can see it's lemma of the frame evoking award.",
                    "label": 0
                },
                {
                    "sent": "This was this right.",
                    "label": 0
                },
                {
                    "sent": "There was a sentence it said John Rode the bike will amortize it.",
                    "label": 0
                },
                {
                    "sent": "John Ride a bike in the frame there was verb right.",
                    "label": 0
                },
                {
                    "sent": "So we match the two.",
                    "label": 0
                },
                {
                    "sent": "There are tax of a node text of apparent node.",
                    "label": 1
                },
                {
                    "sent": "Was it active or passive voice of sentence and part of speech tagging?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we assume we mapped this text onto frames.",
                    "label": 0
                },
                {
                    "sent": "Now we're mapping frames in psych.",
                    "label": 0
                },
                {
                    "sent": "Approximately 600 frames are kind of interesting.",
                    "label": 0
                },
                {
                    "sent": "They're action related, and that can be mapped to psych nicely.",
                    "label": 0
                },
                {
                    "sent": "The mapping was done in a semi supervised way.",
                    "label": 1
                },
                {
                    "sent": "We used psych natural language component to identify possible matching for a frame, and then we choose the best candidate by.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tent.",
                    "label": 0
                },
                {
                    "sent": "So in general, each frame has about 5 to 10 rolls.",
                    "label": 1
                },
                {
                    "sent": "We saw an example frame which had, I think four or five, but they can be more.",
                    "label": 0
                },
                {
                    "sent": "So there are several roles to map.",
                    "label": 1
                },
                {
                    "sent": "It's too much work to do manually, so we did automatically by computing similarity between frame net roles and cycles, namely, psych has also some of the kind of frames and roles defined, so we can try to map measure similarity between cycles and frame net roles, and this is used in usual way using bag of words, description of the rolls.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are all feeling filling the roles mapping is essentially word sense disambiguation and currently we did a quick solution here.",
                    "label": 1
                },
                {
                    "sent": "We just wanted to get the whole work done vertical, so at several steps we just decided for a very basic solution.",
                    "label": 0
                },
                {
                    "sent": "But there is also a word sense disambiguation approach which is being worked on in our Department.",
                    "label": 0
                },
                {
                    "sent": "That's artificial intelligence laboratory, by the way.",
                    "label": 0
                },
                {
                    "sent": "So we hope to use that later an make.",
                    "label": 0
                },
                {
                    "sent": "The whole approach bit more rich or advanced.",
                    "label": 0
                },
                {
                    "sent": "So it's a two step approach.",
                    "label": 0
                },
                {
                    "sent": "We first identify the headword of a role filler and then use Sykes Natural language processing.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Predicates to map method.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So very kind of preliminary evaluation on some sample of frames.",
                    "label": 0
                },
                {
                    "sent": "So for three, parsing accuracy is 90%, so these are now different steps we're doing right.",
                    "label": 0
                },
                {
                    "sent": "From text we do parsing.",
                    "label": 0
                },
                {
                    "sent": "It's 90%, that's fine, that's parser we're using then semantic role labeling, which we're doing is about 65% precision.",
                    "label": 1
                },
                {
                    "sent": "Then there is a frame night psych alignment we achieved about 45.",
                    "label": 0
                },
                {
                    "sent": "Percent accuracy on that.",
                    "label": 0
                },
                {
                    "sent": "We did test.",
                    "label": 0
                },
                {
                    "sent": "What is the maximum?",
                    "label": 1
                },
                {
                    "sent": "Basically 75 would be maximum which could be achieved and then with more sense disambiguation about 60% accuracy.",
                    "label": 0
                },
                {
                    "sent": "So you can see that there is a lot of space.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As for further improvement, this is an example just to show you that we really get Ourmedia got his hands really dirty working on getting some real things, so this is a sentence.",
                    "label": 0
                },
                {
                    "sent": "If we look at the first sentence to understand and appreciate the Bush administration's policy regarding Israeli Prime Minister and so on, this is a fact which extract it from the first sentence in annotation as used by psych.",
                    "label": 1
                },
                {
                    "sent": "So you can see there is some organization policy and there is object improved, comprehending and then there is a we for which psych didn't know what it means, but it says in the text in the sentence V and then there is this organization policy was evaluating.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then again, there is V. There is some exercising health or attractive control over something which was performed and so on.",
                    "label": 0
                },
                {
                    "sent": "So predicates along some of them are really that long also inside.",
                    "label": 0
                },
                {
                    "sent": "So we use what is there.",
                    "label": 0
                },
                {
                    "sent": "This is from the second sentence is an example.",
                    "label": 0
                },
                {
                    "sent": "If you keep reading this example.",
                    "label": 0
                },
                {
                    "sent": "So this is just to give you a taste that.",
                    "label": 0
                },
                {
                    "sent": "How it looks?",
                    "label": 0
                },
                {
                    "sent": "What is happening if you have text and what we get at the output?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, I can take some questions if there are and then for more I'll have to.",
                    "label": 0
                },
                {
                    "sent": "Get you to Meteor who is currently actually an internship at Facebook, so that's why he can't be here.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Pregnant, yes, the goal here is to have high recoil, right?",
                    "label": 0
                },
                {
                    "sent": "To have high recall than usual.",
                    "label": 0
                },
                {
                    "sent": "They are limited them to detect only.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sensors that fit into the frames, so you're basically already limited by the framing.",
                    "label": 0
                },
                {
                    "sent": "So what's in the frame net?",
                    "label": 0
                },
                {
                    "sent": "So there are for this particular frame.",
                    "label": 0
                },
                {
                    "sent": "If you look at it, there are these different words, and if you can find any of this in a sentence, then you then you can match it, you can say.",
                    "label": 0
                },
                {
                    "sent": "If you don't, then you cannot.",
                    "label": 0
                },
                {
                    "sent": "But then you are limited.",
                    "label": 0
                },
                {
                    "sent": "I don't know how big is this pregnant so, but it's fairly big.",
                    "label": 0
                },
                {
                    "sent": "I mean, for the testing we used really.",
                    "label": 0
                },
                {
                    "sent": "Like 1021 case, 10 frames in another 2025, but there are much more many more.",
                    "label": 0
                },
                {
                    "sent": "The problem is also that we are limited in the sense of we can use those frames which have possibility of being matched to psych.",
                    "label": 0
                },
                {
                    "sent": "Right, so there is also this limitation.",
                    "label": 0
                },
                {
                    "sent": "But at the end you have to do something if you don't have frames.",
                    "label": 0
                },
                {
                    "sent": "Right, it's a kind of additional knowledge.",
                    "label": 0
                },
                {
                    "sent": "It's hard to get high recall if you use something like this, 'cause then you're automatically limited.",
                    "label": 0
                },
                {
                    "sent": "I said I see what you're saying.",
                    "label": 0
                },
                {
                    "sent": "I see what you're saying but.",
                    "label": 0
                },
                {
                    "sent": "It's not the problem in that sense.",
                    "label": 0
                },
                {
                    "sent": "There are enough frames which match.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and they have, yeah.",
                    "label": 0
                },
                {
                    "sent": "Introduce bias into strains, but I don't know this whole collection either, but some are generally.",
                    "label": 0
                },
                {
                    "sent": "From there it is designed in such a way that.",
                    "label": 0
                },
                {
                    "sent": "Basically at the end, yeah, so it has this or the content of sentence is eventually some frames and covers the settings.",
                    "label": 0
                },
                {
                    "sent": "Any other question or comment?",
                    "label": 0
                }
            ]
        }
    }
}