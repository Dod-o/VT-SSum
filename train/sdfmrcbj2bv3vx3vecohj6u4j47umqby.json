{
    "id": "sdfmrcbj2bv3vx3vecohj6u4j47umqby",
    "title": "Multilayer Neural Networks",
    "info": {
        "author": [
            "L\u00e9on Bottou, Facebook"
        ],
        "published": "Sept. 13, 2015",
        "recorded": "August 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2015_bottou_multilayer_networks/",
    "segmentation": [
        [
            "You can go to formulas that are about twice as big.",
            "The guarantee risk is twice as big as what you can see, but to do this you have to use a measure of capacity that are so complicated that actually more complicated than running the experiments.",
            "Just finding the capacity or measuring the capacity of a familiar function is something you can do analytically anymore and it becomes too complex.",
            "So so in fact this concept exists, but getting to the merger of the capacity that's close enough to give you a good good estimate is not something practical.",
            "So This is why I say we don't care, but it remains that when you take sets that are embedded, the capacity can only increase.",
            "That remains.",
            "And that's true for all of them.",
            "So so yesterday.",
            "I spoke a lot about optimization and I stayed in the domain of batch optimization.",
            "So basically you optimize a single function without leveraging the structure and I told you at the end two things.",
            "That even though they are good methods like conjugate gradients, LB of GS, One has to be suspicious about them.",
            "Because they don't exploit the structure of the learning problem very well, and because optimizing the training error is not the same as optimizing the testing error.",
            "And I told you, but still this gives a lot of ideas about simple things we can do to get neural networks to work better speaking, and this is where we had a discussion about measuring the size of the weights, the size of the gradients, and making sure that everything is reasonable, that the gradients propagate properly and that basically merger things use the ample time that you have while your system is training to measure useful things and make sure that nothing is completely off the charts.",
            "So I would like now to go to the stochastic gradient."
        ],
        [
            "And.",
            "So we have this.",
            "Function here.",
            "This is the training error.",
            "And the number of training examples can be large billions.",
            "Billions is not heard unheard of at all.",
            "And examples are redundant, otherwise there is nothing to learn.",
            "We know that.",
            "Doubling the number of examples bring a little more information, but not that much.",
            "So do we need to all the examples in the first optimization iterations so there is an algorithm that folks are going that works actually quite well, which is to start with a small training set, optimize that, then use that to one.",
            "Start with double the training set side, optimize that, then double optimize that, then dollar optimize that?",
            "It's not bad at all if you do these things.",
            "Now.",
            "All examples may not be available simultaneously.",
            "Sometimes they come on the fly, like if you have a clickstream on the website you know you're not going to have all examples right away.",
            "In quantity of too large to store retrieve Clickstream again."
        ],
        [
            "So.",
            "That goes the ID of offline versus online optimization, so you minimize the cost.",
            "Let's say a regularizer.",
            "That's suspiciously like this VM actually.",
            "Plus it's running error and offline.",
            "You process all the examples together.",
            "So basically, if you do a gradient dissent, you're going to compute the gradient of all of this.",
            "You sum over all the examples, and you make a repeat.",
            "Or you can push them 1 by 1.",
            "So you pick a random example and you just take.",
            "An estimate of this gradient.",
            "That's based on the simple single example."
        ],
        [
            "So.",
            "You get the trajectory that's about like this.",
            "You know, if you remember the trajectories of a batch gradient, you get something extremely noisy.",
            "And, uh.",
            "I thought about trying to show some proofs of these things, but actually I lost the time by speaking about that Nick, so I'm not going to do that unless you ask for it.",
            "But basically the estimate of the gradient is very noisy.",
            "Now what's going to happen and you can show it in half a page.",
            "Is that?",
            "If you have a constant again constant learning rate, you're going to decrease exponentially, like a real gradient up to a point.",
            "That's basically the noise level that you have in your gradient.",
            "And inside this noise level you just flying over the optimum.",
            "So therefore you need to decrease the gains, typically like 1 / T. In order to go to the optimum, if you actually want to go to the optimum.",
            "Decrease both the X -- X star and F of X assuming sufficient convexity business.",
            "F of X is a minimum unique style I'm going to.",
            "Ofx my new cipher fix star is going to decrease.",
            "Exponentially FX minus F of X size.",
            "Is what you can show is that.",
            "F of X T -- a certain constant.",
            "Is going to decrease exponentially go to zero, but that constant is higher than 4/5 star and this constant depends on either.",
            "This is what you can show very easily.",
            "Now, why is such noisy process attractive?",
            "Well, obviously you is much."
        ],
        [
            "Easier to compute if this if N is 1 billion, this is 1 billion times faster."
        ],
        [
            "Again, let's go back to redundant example.",
            "When you have redundant examples that increase the computer cost of offline learning because you have to go over all of them.",
            "But it doesn't really change the computing cost of online learning, because you do them randomly.",
            "So imagine that I said that contains 10 copies of the same one.",
            "Another examples, it's a mistake somebody made a mistake.",
            "10 copies of the same or not examples.",
            "If you do batch gradient descent well.",
            "Computation is 10 times larger than necessary because you're going to both 10 times over the same examples before getting a gradient.",
            "And you're not going to be able to use a 10 times larger learning rate.",
            "If you do stochastic lessons, it makes no difference because you pull randomly from you set and whether you have 10 copies of the same data or not, you have exactly the same distribution.",
            "So all this has to be made more precise.",
            "So let's go back where the situation where you have unlimited data.",
            "We have a meaning that data is not really unlimited, but the computing time is limited.",
            "And what we can, which we think a specified time budget and think about the kind of tradeoffs.",
            "If you optimize more thoroughly, which is probably a good thing.",
            "But we must save time by other means.",
            "So we can use less examples, which is a bad thing.",
            "Or we could use a simpler model, which might be a bad thing if unless the model the simpler model is actually better for the program that we don't want advance.",
            "Or Conversely, if you optimize less precisely, which is probably a bad thing.",
            "Well, you have the time to use more example, which is probably a very good thing or more refined model which may be good.",
            "And if you use more example actually is good because that allows you to use a more refined model again because of the structural with minimization argument.",
            "So the trade offs can be much more complicated than what you see in the case where this number of examples limited and these tradeoffs depend on the algorithm, because they depend how much time do you lose or how much time do you spend.",
            "If you want to optimize more thoroughly.",
            "So.",
            "Give us the computing time here is intestinal.",
            "Suppose this is a classification problem.",
            "There is the base error.",
            "That's the best one you ever going to achieve on that problem.",
            "OK, if you have a 10,000 examples, is going to be like this is going to be going to learn fast, but then it's going to plateau auto certain level because you don't have enough examples.",
            "If you increase number of examples, you're probably going to go like this.",
            "That's the typical batch algorithm going to be like this.",
            "If you have 1,000,000 examples, you're going to be 100 times slower than this, but you're going to go lower.",
            "Now you can change a lot of other things.",
            "You can change optimization algorithm.",
            "You can change your model and you get a lot of curves like this.",
            "And what you're really interested in is this.",
            "The bottom of the envelope.",
            "These are the good combinations.",
            "And look how bad this is.",
            "The good combination depends really on how much time you have.",
            "If you have very little time or don't try to use all your examples, there is no time for that.",
            "If you have more time, maybe you can use more examples, but you have questions about which optimizer in which model someone needs to sort this out much better.",
            "So again, in general this is very hard to do, but we can learn things by looking at a simple case, so we're going to come back to the convex set up simple, strongly convex, smooth, or look all nice properties, because these are these other cases we can understand and then we can try to extrapolate what's happening in the real world.",
            "So I'm going to take a family of linearly parameterized, smooth, convex lawston, strongly convex.",
            "No typical, not even as VM actually think squared loss of them like that.",
            "And I'm going to compare three iterative optimization algorithm, gradient distant, the 2nd order gradient descent, which is basically using the Hessian matrix to try to go faster.",
            "And the stochastic gradient descent.",
            "What do I get?",
            "OK, well the gradient descent to describe their ID best feed achieved when he to equal 1 over Lambda Max we saw that last time.",
            "The 2nd order you try to use the optimal scaling.",
            "And when you have the optimal scaling, well it's nice because it becomes a circle.",
            "You can go direct to the optimum if it's quality or close.",
            "And stochastic is this thing where you have this noisy approximation and decreasing learning rate in it over T. And our ethos, will we get there?",
            "Is there is a calculation about what's best for for this simple case?",
            "And you can analyze this and you're going to have to believe some of the formulas because each of them can be quite a handful to show properly.",
            "So time pair, iteration gradient decent N because it's number of examples to compute the gradient, you have to go over all of them.",
            "Same for the Newton's DDS one.",
            "Just pick one example and I'm going to change that later.",
            "Iterations to get a certain accuracy row.",
            "But you see that the ground is sent.",
            "You have this exponential decrease, so it's going to be log one over rho.",
            "If you do a nutone and is quatic you go straight to optimum, but if it's not quadratic and its most enough in the 3rd and 4th derivatives, you typically get something like log log one overall, which is a lot less than log one.",
            "Overall, this is awfully fast.",
            "You can get a very good accuracy extremely quickly.",
            "SGD one overall at best?",
            "And you can show that something like SGD cannot be better than one overall.",
            "And there is a constant on top that's important to consent will matter.",
            "And time to reach a certain accuracy while you multiply the two.",
            "And you can see that you don't optimize much faster than a simple guarantee sent and stochastic gradient for optimization is completely hopeless.",
            "If your life depends on optimization, do not use stochastic gradient descent.",
            "But now look at my curves.",
            "Here there is something I called the excess 0, which is how far I am from the very optimal one.",
            "And I'm trying to estimate the time before I reach a certain excess error.",
            "And where there is a Alpha here between one and two, let's say Alpha equal 1 for simplicity, the power for the grand dissent is currently one over epsilon.",
            "Log one over epsilon.",
            "For the Newton University on Logon, overseen on log log, one over epsilon.",
            "Well.",
            "Is the same.",
            "This log logs.",
            "We don't care.",
            "4G DS one of epsilon without the logs and look look certainly as GD looks good.",
            "So that means that when you're using this Newton algorithm, the only thing that's happening is that you overfit faster.",
            "In terms of learning, you don't much matter, and that's not silly actually, because when you do stochastic gradient you're trying to learn.",
            "With the examples you've seen.",
            "And that's going to work well if what you've learned in the example you've seen is predictive of the example you're going to see in the future.",
            "While here you learning with a fixed set of examples, but you want to measure an example that you want to see in the future.",
            "So the same kind of.",
            "In essentially between.",
            "This line, which is the optimization of training error and this line, which is the time to the access testing error.",
            "You have the mathematics are in between.",
            "And they limit you to something like one over epsilon.",
            "You can only be worse.",
            "Yes.",
            "OK, the variance would use stochastic gradient there.",
            "Things that can see all the training set to start with because you have to compute the reference point and the optimizer training error.",
            "So the variance reduce are going the optimizer training or like long log one over role.",
            "But the able to cheat on the end and make it this much smaller.",
            "If you do everything right.",
            "Which is a very nice data property.",
            "But when you go there, you still see the same kind of things.",
            "So if you look in testing it all is going to be about the same and the only thing you can change is with the constant.",
            "So that means that when we're playing all these games to make optimization for learning faster, we playing with the constants are based on the testing here, or we're going to be in one over epsilon.",
            "So think about it, I'm going to use a fancy 2nd order algorithm that's going to cost me 5 times more per iteration.",
            "OK. Well, five times is a constant.",
            "So I better hope that the constant that I have here or here, whatever on that line is 5 times better, otherwise I lose.",
            "A constant can be your GPU.",
            "GPU is a constant like 50.",
            "A constant can be an optimization.",
            "So that means that designing.",
            "Optimization algorithm for learning that are much better than, let's say, SGD as a baseline is hard because you're fighting with the constants you fighting with the engineers who are using GPU.",
            "Is not the same like when people went to Newton from gradient decent.",
            "Well don't care about the GPU.",
            "You have an order of magnitude better.",
            "You're going to blow out if you run this on Matlab and this on the GPU.",
            "The Matlab will win.",
            "Not true in here anymore.",
            "Is changing This is why the impact of accelerating machines machines that go faster and faster is so important in machine learning?"
        ],
        [
            "So let's take a practical illustration.",
            "This is again a completely convex problem.",
            "Actually, this is Elsie one.",
            "These are VMS with L2 regularization and log loss.",
            "If you trend withdrawn, which is the part of liblinear that was before the the coordinate ascent?",
            "That's a super linear algorithm.",
            "Here you have the optimization accuracy and the training time, and you see it's below a line.",
            "It's concave.",
            "That means that the more accuracy you want, the faster it goes.",
            "It's going to give you, well, you can get 12 decimal digits in less than one minute.",
            "Except we don't care.",
            "If we take a stochastic gradient well, it starts very quickly because at the beginning it seems very few examples.",
            "But then if you want accuracy that's more than six or 7 digits is going to be, you're going to hit a wall.",
            "Is going to take forever and might I say here is we speaking minutes here we speaking hours and here we speaking month.",
            "Now look at the testing error here.",
            "The testing error you get with this optimization accuracy.",
            "Well because down and go through basic role so you get the SM taught.",
            "Long before you hit the wall.",
            "And the kind of bonds that are showing before that tend to prove that this is how this is happening, and This is why stochastic gradient is such a good baseline, doesn't mean it's not going to be improved.",
            "Doesn't mean it's the best one.",
            "It just says it's a good baseline."
        ],
        [
            "Now.",
            "Suppose you want to quickly achieve a good training set performance.",
            "Well.",
            "You take a super linear algorithm very fast one.",
            "And you initialize with SGD, you take a Jeep off and then you branch there.",
            "So you get something like this.",
            "Yeah.",
            "What?",
            "The same.",
            "Measure.",
            "Optimization accuracy.",
            "Yes.",
            "And then you can say that when they are going to different, that can be slightly different, but in practice you don't see a difference and all this has been repeated enough that there is no.",
            "This is a couple thousand iterations.",
            "You don't see robust in that stuff.",
            "So if you do something like SVG you see in a little corner of the paper that say oh, in practice we initialize it with SGD for the first pass.",
            "And the site is the same because of this because you get on the learning problem, you go much faster at the beginning and then you can optimize on the train on the training set, but up to constants.",
            "And again I say up to constants and constant matter.",
            "So what I'm saying is not completely true.",
            "Up to constants, you can say that when you start switching to the Super linear algorithm is when you start overfitting.",
            "Well, actually no, not necessarily, because the HD constant can be a bit bad and sometimes you can.",
            "You can shave the constant by by using a better algorithm.",
            "So now all our tricks will be about shaving the constants."
        ],
        [
            "So improved algorithm how to shave the constants in stochastic gradient."
        ],
        [
            "A lot of tricks, certain other tricks which is using the hidden metrics, momentum and acceleration mini batch parallel there all about constants.",
            "2nd order is constant because when you have a learning problem and look at the testing error, this is no longer changing.",
            "The order of the optimization complexity is changing the constant.",
            "Momentum acceleration that we connected to signal tricks by using mathematics.",
            "I'm not going to describe but the mention.",
            "Mini batch techniques.",
            "Actually the and parallel training, the more from the implementation point of view.",
            "You're going faster because you implement it better.",
            "And those concerns too.",
            "Yes.",
            "Nesterov acceleration.",
            "Yeah, the there's some family of methods.",
            "So question to ask ourselves when we read the paper about this.",
            "Do they quickly achieve good tests?",
            "Are also good training yours.",
            "In most paper, the experiments target the test errors and the theory targets the training error.",
            "Doesn't mean that the proposed method is bad or useless.",
            "Doesn't mean that they're dishonest, because very often they said.",
            "You just mean that the theoretical argument is repeated over salt.",
            "And the first version was my PhD advisor and she had an informal theorem that I always remember Fogelman's theorem.",
            "Unfortunate Theorem is that.",
            "That was back proper then, but she meant great on this central stochastic gradient descent.",
            "You can always make stochastic gradient descent and backdrop slower.",
            "That means that all these papers will perform very well compared to the implementation or the one they chose of stochastic gradient descent because it can always be slower.",
            "But it's very mean to say that, but is it true?",
            "So you think about the neural network.",
            "There are plenty of ways where you can slightly this adjust the the the weights, initialize and make it.",
            "Twice slower, three times slower.",
            "Just just like that with nothing.",
            "If you look at the papers that restarted the stochastic gradient list, one of the paper is the Pegasus Paper.",
            "Nice algorithm and it analysis.",
            "So this is good paper.",
            "But what they do is that the advocate, the projection technique and the projection technique essentially does that when the learning rate is too high, so they quizlet 1 / T so it's very high at the beginning.",
            "But when learning that is too high, the projection saves you.",
            "So basically you're doing nothing until learning that is the right value, and then you're learning.",
            "So basically if you start with the right learning rate, you go twice faster.",
            "Right away.",
            "And well, they are stochastic resonance available to start the right way.",
            "Mean people could always compare with the one that just this pressure.",
            "Normal pressure on people you know.",
            "They find one day that they take a program and OK, it works and they don't work very much on the baseline.",
            "They work on their algorithm.",
            "So, so you always have to be a little bit careful about these things to say it's OK.",
            "They say that they're not stupid.",
            "The analysis is interesting.",
            "The idea is good, but the experiments be careful."
        ],
        [
            "Now let's go with certain other tricks.",
            "Rescaling the gradient with suitable approximation of the Hessian, but you have to use a positive approximation of metrics.",
            "Natural gradient goes to some tricks.",
            "They're pretty much the same.",
            "But the problem that you have in stochastic gradient when you do that is that you have to multiply the gradient biometrics or by an approximation of the metrics.",
            "At each direction.",
            "A billion times.",
            "If you have a billion training examples instead of just one at the end of a billion.",
            "So the cost of Newton.",
            "For stochastic gradient can be very high unless you use mini batches.",
            "Unimportant cases dragon it's killing, so dragon is killing is the same as using a different learning rate per weight per unit per layer.",
            "We discussed that already.",
            "The best technique is periodic adjustment of the learning rates by looking at average Guardian average weighted.",
            "I made my my points yesterday."
        ],
        [
            "Momentum acceleration.",
            "While there is easy assets give out nice paper, comparing them and reformulating nestier frustration in a way that resembles momentum.",
            "The reason why it works?",
            "It's actually very subtle, and it comes back to analysis by Nesterov that you can see in this book about elementary lessons about convex optimization.",
            "I'm.",
            "I can explain this in 2 words.",
            "So basically the book is trying to show bounce.",
            "Theoretical bounds in the optimization.",
            "Of function of a certain family so they look for instance at the class of functions that are convex and smooth.",
            "And they show lower bound, saying that you cannot optimal fine optimization algorithm that has a guarantee that's better than 1 / T square where T square is the number of teams, enough iterations of the complexity essentially.",
            "And they do that by showing by constructing functions.",
            "That resist, so if you run your algorithm, you have, uh, algorithm queries, an Oracle that gives for algorithms as the right to propose a point, and the Oracle gives value for function and the gradient.",
            "That's called the 1st order Oracle.",
            "And you invent the quite a crazy Oracle.",
            "That's going to keep the list of all functions that are compatible with all the previous answers.",
            "An edge at this time you're going to get the worst one.",
            "That's called the resisting Oracle, and by doing this you exhibit a function that's maximally resisting, and you can show that there is no way you can optimize.",
            "Do these processing less than one over the square.",
            "And therefore you can say that if you have an algorithm that guarantees that you're going to get an accuracy epsilon.",
            "Then there is a function on which this algorithm has to make more than one over epsilon square root of epsilon steps.",
            "Now if you look at the the gradient descent, the normal gradient descent.",
            "On this is not one of the squares 1 / T slower.",
            "And so next year I've tried to play with it and invented this idea of using the last two gradients in a kind of strange way.",
            "And when you do that, you get the one over the square.",
            "So this is the optimal algorithm up to constants.",
            "And you also have a theory that comes from numerous key showing that conjugate gradient is not minimax optimal, so therefore conjugate gradient.",
            "There are functions that are going to lead you astray even though it's going to work well in on average.",
            "So so you can discuss so.",
            "So that was something very surprising for people in optimization that you can actually define an algorithm and show that it has some optimality properties that cannot be beaten.",
            "And of course well, you can use momentum and try to do that in our network, except that it stochastic and it's going to be a big mess to make it work properly.",
            "So OK fine."
        ],
        [
            "Yep.",
            "The nested off also stochastic gram decent people tried to extend the idea of acceleration to stochastic with some result.",
            "The Nesterov is for total for gradient algorithm.",
            "The nasty of paper.",
            "Now you can use the same techniques for stochastic gradient, but the bounds are not the same, and in particular where for batch gradient you would change the order of the algorithm.",
            "For stochastic think basically you don't see the whole training set.",
            "You cannot better than over T anyway, so it's not good if you wanna party square.",
            "What's happening that the constant that's on top, which is typically for stochastic gradient is Kappa.",
            "Square Kappa is the condition number of vision goes down to Kappa.",
            "So we're changing the constant, so for real condition problem is going to work quite well.",
            "So that means that when you use momentum, it's a kind of way of.",
            "Taking some advantage of signature properties in a way that's economical.",
            "But it doesn't have to be diagonal aligned.",
            "So if you do, let's say one word per weight, which is a second order matrix that diagonally aligned well if you cost function is is not aligned with the axis, or it's not going to work that well, well, momentum can work.",
            "Not as well as doing the real 2nd order, but it can work in accelerating that set up.",
            "So This is why often people combine both.",
            "Now the adjusting the momentum parameter is quite hard.",
            "Hard to do because in principle you need to adjust it according to the properties of the Hessian, which you don't know in advance.",
            "So you're going to have to do trial and errors, and sometimes the trial in euros can cost you more than not doing it.",
            "So many batches actually go to you.",
            "If you stochastic gradient use a noisy gradient based on a single example.",
            "If you use a mini batch Locust gradient, we use a noisy gradient based on a small batch of examples.",
            "If you think about it.",
            "That means that the standard deviation of the noise is going to be or let's say, the variance of the noise is going to be divided by the size of the batch of example.",
            "But turns out that when you do the stochastic gradient in the in the constant, you have a term that happens to be the variance of the noise.",
            "So.",
            "You're going to reduce the variance of the noise.",
            "At the expense of step that are 10 times more expensive, so mathematically, as long as the mini batch is small enough that you're not going to the actual batch, it doesn't do anything.",
            "But practically, it's not true at all, because mini batches are well suited to modern hardware and they also provide an opportunity to use in order info.",
            "So the first one."
        ],
        [
            "Is what we were told you that if you take the linear brick, for instance, forward is WX backward GW or Jezero vector gradient is just the dot product.",
            "But if you have multiple examples sometimes so these are matrix vector matrix vectors, outer product.",
            "If you have multiple examples, X become a vector.",
            "Sorry, XP, metrics.",
            "It was a vector.",
            "Here it becomes a matrix, the gradients becomes a matrix instead of the rector.",
            "All these things become matrix matrix product and there is something that you can see in the literature literature about glass even as a single CPU using matrix matrix is much faster than a lot of metrics vectors because you can optimize the placement of things in the cache.",
            "Typically you can expect a factor of 10 easily with these kind of things.",
            "Now if you use GPU's, that's even worse.",
            "Yes.",
            "The trick.",
            "Which tricks momentum?",
            "They all use convexity because this only thing we can only know how to prove.",
            "If you close to an attraction bussing close to the end, you can say, OK, Aquatic approximation holds and sort of sort of convex locali.",
            "But in terms of how you're going to traverse the landscape of critical points and everything.",
            "No ID.",
            "Actually, actually.",
            "It's not.",
            "I don't think it's the right recipe.",
            "There is a old paper by people were using statistical physics methods, so there is a simple ski saving paper where it shows that in the case of multiyear network and assuming you actually learn the function, that's another network that's unknown with the same geometry.",
            "So you can look at the overlaps between the values, units and everything, so you can do statistical physics.",
            "The good strategy is to keep the learning rate constant and high at some moment.",
            "And at some point you lower it, you start lowering it, and that's very consistent with the ID of.",
            "Let's take a validation set.",
            "Constant learning rate.",
            "Go until things stop optimizing the validation set, and they're not going to go, and they're just going to stop.",
            "They going to start being unstable.",
            "Then you are a little bit and you go down a little bit, and that's the kind of following you kind of fashion structure that they exhibit in this paper.",
            "So the idea of statistical physics approximation to understand the structure of the non convex function as usual spoke about it.",
            "It's coming back, but it's leverage is very strong assumption that are far from real.",
            "But in practice it sort of works well.",
            "So in practice, this is what I'm doing.",
            "Typically start, let it let it cook for certain time.",
            "When the validation error stabilizes, athletic little bit more, typically it doesn't go up that quickly, and then I divide the learning rate by some value and I do it again.",
            "I know you go stole two and I sometimes 10 you know doesn't matter.",
            "So, but this is not something of that kind.",
            "This is a computational optimization.",
            "This is something in pretty much at the hardware level at the implementation level, but it's also a constant when you do something like this, you competing with equal arms on equal basis with improvements of the algorithm.",
            "So now it's a very difficult problem to decide where to put your brain cycles.",
            "Are you going to put your brain cycles in working in a nice GPU implementation on working in a nice optimization method?",
            "It's not obvious at all.",
            "So the second thing?"
        ],
        [
            "Is that mini batches provide an opportunity to use some other information?",
            "Certain information you're going to use a kind of estimate of the Hessian matrix that you can estimate on the fly here, and I'm going to describe that a little bit later.",
            "At least one instance of that.",
            "And you want to multiply every gradient with that matrix.",
            "So even if it's low rank matrix is going to be costly.",
            "So if you do it one per example.",
            "That's very costly, so if you eat once every 1000 examples, well, OK, you amortized it.",
            "So suppose you have a rank K approximation of duration metrics, so it's going to cost you about K times more than K + 1 times more than a matrix vector product.",
            "Well, if you do it for every example you are going this right from the bat.",
            "Cave times slower.",
            "And you better win the fact OK as well.",
            "If you do it every 1000 examples, well, it's going to be 1000 + K. In this case, let's say 10 or 50 you find."
        ],
        [
            "Then there is something that I've seen done.",
            "It just gives me the creeps.",
            "Excessive LB of GS.",
            "40 = 1 two three pick examples for the mini batch T. Initialize net with the previous weights.",
            "Optimize with albc and get another one.",
            "And repeat.",
            "I've seen people do that with some success.",
            "And.",
            "Gives you the creeps because this doesn't work at all for convex model.",
            "In the convex model you have one optimum.",
            "So every call to LGS is going to give you the optimum for that mini batch.",
            "So the last value you have is the optimum for the last mini batch for the last set of examples.",
            "Like you ignored all the previous examples.",
            "You know, and that is not like that.",
            "There are so many points where you can stop on.",
            "There's so many local minima and everything that when you do this, you somehow prime the process in some areas and then it works better still gives me the creeps.",
            "Yeah, pretty much.",
            "And that works too, which is very very strange.",
            "That tells you how little we understand what's happening in there."
        ],
        [
            "There are things like Martin's vision field training, which is a kind of nickname for his particular version of using second order information.",
            "And I'm going to try to describe it in a very simple way, knowing that you have to be careful because you need a lot of refinements to make this work well.",
            "You take a lot of mini batches and you.",
            "Take a mini batch that is going to be special.",
            "All the curvature information is going to be on that mini batch and the reason for doing this is that if you estimate parts of the cavity on different mini batches could be different.",
            "Going to mix up things.",
            "So now you pick examples for for all T123 you pick examples for humidity.",
            "You compute the gradient on the mini batch T so far is very close to the meaning of gradient.",
            "But instead of doing a gradient step, you're going to minimize D, transpose HD Lambda squared plus GTD by country gradient, where HD.",
            "Is evaluated directly using red and measured in mini Batch 0, so that means that here you have an estimate of the curvature.",
            "Or mini batch 0.",
            "So that gives you the form of a power below it, but on mini Batch 0.",
            "And use a fast way to compute the Hessian vector product that you can do in our network.",
            "Here you have a kind of regularization because this is not always worked out well.",
            "And there you have the gradient on your current mini batch.",
            "So that means that you basically trying to correct if you just do this optimization here and then compute the revertive respect to D in that stuff.",
            "You're going to basically correct.",
            "The gradient on the mini batch using Asian estimated on the mini Batch 0.",
            "If you take the Devils disrespect to D. You're going to have HD plus of two HD, +2 Lambda D plus GT equals 0.",
            "So basically the D is going to be GT minus GT times.",
            "Edge plus Lambda identity to the minus one.",
            "So basically you're doing kind of a Newton here, except that the curvature is estimated on the 1st mini batch.",
            "That's a way to avoid some noise in the process, and then you do the update dirty piece one is RWT plus D and you do it again.",
            "So of course there is a cost in doing this, but it better be amortized on mini batches and if you play everything right it works, it works.",
            "Yes.",
            "Or can you repeat the question?",
            "I'm sorry.",
            "The selection to optimize the mini batch.",
            "The mini batch size you mean?",
            "Information.",
            "OK, in all I describe, I assume that picked randomly.",
            "There are some people who are trying to carve smart mini batches.",
            "But that's all another completely different story.",
            "And I'm not.",
            "I'm not ready to talk about this at this moment."
        ],
        [
            "Pilot training.",
            "Nuclear we know yet.",
            "The best line is lock free stochastic gradient as you shared memory, each process to access the way through the shared memory.",
            "Each processor runs at GD and different examples read and write to the weight memory are in synchronized.",
            "Synchronization issues are just another kind of noise and this is a very strong contender.",
            "And I think you should ask to do that long ago the the Google guys are famous for doing this on big clusters using distributed shared memory and this dissent.",
            "It's actually a strong contender.",
            "People do that in GPU sometimes, except that it's very difficult to do that properly on GPS.",
            "Bottom OK, this so far.",
            "As to my knowledge, none of those sophisticated methods.",
            "The tech a pretty fine neural network.",
            "Tim, is it?",
            "Go much faster than that.",
            "Yes.",
            "The synchronous here.",
            "I say.",
            "Read and write to wait memory are in synchronized."
        ],
        [
            "Yeah, you you tend to hit the weights a lot, so there are proofs about this.",
            "There's a hog wild proof in the case where you have a very sparse updates.",
            "But it also works when they're not sparse.",
            "It's also works in CNN's but.",
            "Just another kind of noise.",
            "Now for the last half hour, I'm going to look at trying to use deep networks for complex tasks.",
            "Yes.",
            "Yeah.",
            "Well.",
            "So so to say that, more bluntly, if you look at the Google Paper that did that on a cluster, which is a very sophisticated engineering fact.",
            "In the corner you see that basically they use something like 10,000 computers or 1000 and forgot the exact number.",
            "But if you work the number you realize that the speedup is something like 10.",
            "So that's quite costly.",
            "You need to have a lot of computers.",
            "Maybe it makes sense if you have a lot of computers.",
            "I don't know exactly.",
            "They are the economy, color range, but they certainly made progress in between.",
            "But this is not obvious at all to do on a large number of processors.",
            "Yeah.",
            "Resilient back propagation.",
            "Which one is that?",
            "Increase.",
            "What you mean by go down the cost function you mean, Oh yes, yes yes you you every so often you estimate the cost function on the whole set and you see if it's going down or up because you cannot do that every direction, correct?",
            "It's normally used in a match set.",
            "Well, the first part of what you describe is taking just the direction of the graduate notice size.",
            "And if you look about it is pretty consistent with what I say that we want an update that has a size that consistent with the size of the weights.",
            "So you ignore the length of the gradient, and you're going to each time say I'm have a direction.",
            "I'm going to go 110th of the length of my weights in that direction.",
            "That's consistent with this idea.",
            "Now things can be bizarre if you do this on different layers because you when you re scale differently in different layers.",
            "You also change the rotation.",
            "This is what I notice then the heuristic to adapt the running rate.",
            "While it's not unreasonable.",
            "You could try yeah, sure, yes.",
            "Yes.",
            "Yes, this is.",
            "This has been tried in various ways.",
            "He's been tried most successfully in this VMS because SVM is a quality cost.",
            "Taklon but you can test the SVM in linear cost essentially.",
            "So basically selecting examples that are informative is not too costly in a normal network to select examples.",
            "If you run the full neural network is going to be pretty much the same cost as doing the backdrop.",
            "So there are two routes there.",
            "One is to select examples using another network smaller.",
            "But then you have to make sure that the smaller network does something.",
            "That's going to help you find examples are informative for the large network which is supposedly Sparta is not obvious.",
            "Another approach is to use this as a parallel implementation method so you have a bunch of machines.",
            "They all have a copy of the network and they going to sift through the example to find one that is a strong gradient, and when they find one they send that to the central machine with going to learn that one update the weights and redistribute.",
            "This is hard to get to work right.",
            "So I know that we tried with Alec Agarwal for a long time to get these things to work and it really depends on a lot of details on the optimization so we could get the paper and show that it works, but I wouldn't guarantee that it's going to work for everybody.",
            "So you see what I mean?",
            "So so you could write slightly this on this paper that looks impressive that way, but it's not clear that that would work very well for in a robust manner.",
            "So I go back to the last part complex task."
        ],
        [
            "And I go back to how to design computers that at the beginning of my lecture.",
            "And our computers, all the ones that we have to emulate, mathematical logic becausw in mathematical logic.",
            "There is a very well known procedure to reduce complex tasks to combination of simple tasks.",
            "That's called programming.",
            "If a complicated task, you divide it in simple tasks and you program each simple task in some way recursively.",
            "That's very good for plenty of reasons.",
            "One of them is that you can cope collaborate with people you know.",
            "You say OK, now speak my task in this particular element, you're going to do that one.",
            "You're going to do that one.",
            "You're going to do that one, and as long as you do the task correctly.",
            "And my.",
            "Splitting of the problem is correct.",
            "I'm going to have the correct solution and we don't know how to do that very well in machine learning."
        ],
        [
            "So we're using complex task to combination of simple task is an engineering necessity.",
            "If you do engineering you need to do that.",
            "And simple running tasks.",
            "You have classification, regression, clustering, multi arm bandits and many other 8 pages papers.",
            "Complex learning tax.",
            "Reading checks.",
            "When you need to deal with segmentation, recognition, interpretation of the letters until you get an amount and you know what to do with it.",
            "Passing visual scene, finding objects, finding their relations and doing something useful with them.",
            "Composing personalized web pages, which is dealing with feedback because if you personalize a web page for somebody, well, he's going to see something different so the clicks and the interaction of the user with the web page will be different and you change your training data and you can have a cycle of things.",
            "But natural language understanding, which is even hard to define by itself or strong AI, we can dream.",
            "This is a complex task.",
            "We have no way.",
            "To reduce such complex task to a succession of simple learning tasks, because we have no way to say the simplest axis is done strictly.",
            "When you reduce a complex tasks into simple tasks, this is true under the assumption that the simple task is done correctly 100% of the time, yes.",
            "But in the work and reduction algorithm Lankford, there's a huge effort to try to keep the balance and everything together, but he has a certain nice little setup, but it is still playing in this game at this level.",
            "Many match pretty much.",
            "And every time there is a reduction, there is a little loss somewhere.",
            "So it's actually quite hard to do, like if you think about programming computer.",
            "It's provocative, but programming is for the average mind.",
            "It's not that hard.",
            "Lots of people can program something that sort of work, market, other bugs.",
            "There are lots of bugs, sure, but because lots of people can do it, that means that you can have an industry and you have computer science and industry.",
            "If.",
            "You want to do that with John Langford Productions?",
            "Well, you need a lot of junk foods.",
            "But there are a couple of people who can do it better.",
            "I don't know age on Hall.",
            "No, I'm exaggerating.",
            "Of course a little bit.",
            "This is very smart.",
            "This is the right direction.",
            "But this is not something that I'm unable to an industry as of now.",
            "And he's making good progress.",
            "You know that might work in the end, but right now it's not there yet."
        ],
        [
            "So a lot of machine learning is about Bayesian inference.",
            "It's a bit a couple years ago.",
            "Bayesian inference was.",
            "40% of lips there is a strong appeal to Bayesian inference.",
            "Now it's reduced little bit because deep learning took a lot of Bayesian inference and some nasty people say that now they reduced to try to learn the hyperparameters, but but it's true that Bayesian inference is very attractive, and if you have the computing time, it can give very good solutions.",
            "But the appeal of Bayesian inference is not really that.",
            "You get better solution that your first language.",
            "You have a language with Escrib complex model with similar ones and you have generic algorithms.",
            "Of course if you build.",
            "A complex model with simple ones.",
            "The generic algorithm, often intractable and they have to resort to nasty approximations and everything.",
            "But it's still a language that's completely absent.",
            "In the traditional machine learning, if you deal with SVM, there is no such language.",
            "If you deal with deep learning, there is not much of it.",
            "And also it's an important question to try to find this language, because otherwise we won't be able to progress."
        ],
        [
            "So let's look at St."
        ],
        [
            "Our problems.",
            "Let's go back to one of my pet example with in check amounts.",
            "The input is a scan check image.",
            "The output is a positive real number.",
            "The amount 3 to 45.",
            "The direct approach is to collect examples.",
            "Images A month.",
            "Images amount trend from scratch with the big CNN's.",
            "Tough luck.",
            "Maybe it's possible because we didn't really try now, maybe with GPU's and everything or clusters GPU's you can do something like this, but you need a lot of examples because that machine will have to find that this is the amount.",
            "Understand how to pass the characters and transform this into real.",
            "Eliminate this task not read this, not read that.",
            "It's not going to be so easy.",
            "So you split the problem."
        ],
        [
            "You're going to say, well, I'm doing engineering, so I know that I need to look at the amount field.",
            "Then I need to segment the amount field into isolated characters.",
            "I need to recognize the other characters and translate the character string into an amount.",
            "So we can define the model for each sub task.",
            "Which are fairly complex recognition model like CNN's and engineer location and segmentation models to find the fields and segment them.",
            "You collect data and trends so you collect data for each sub task.",
            "You train each subtask separately, and you put them together.",
            "This sort of works.",
            "But you can do much better."
        ],
        [
            "You have interactions.",
            "You look at the amount field, but you can make mistakes here.",
            "If you make slight mistakes, you can segment the amount feeling too isolated characters, but you know a bad amount field is one you cannot segment very well and a bad segmentation is something you cannot recognize very well.",
            "So in principle, whenever you go to the next level well, you say if I cannot really see all the characters.",
            "Maybe my segmentation was wrong and I don't have another expensive segmentation.",
            "Maybe my amount field was wrong.",
            "So you want to interact.",
            "Every level and at this moment what we did, this trend is transistor and this trend is just put them in sequence."
        ],
        [
            "So I describe independent training.",
            "You train each submodel separately.",
            "Fine, you can do sequential training with which one with independent training.",
            "Then we labeled output of sub model N. So you and you transfer Model N + 1 with that.",
            "So you trend the location field and then you label that with proper segments.",
            "And and then you turn the segments and you label the segments the various segments you get with proper characters and what's the reason why is going to help?",
            "It's big cause if you segment or for instance like the thing that segments are fit into characters is not very good.",
            "Let's say he cut the top of the Five 5.",
            "And the bar is always cut because of some flow in the segmenter.",
            "But if you label them right, the next thing which is the recognizer can learn to recognize the five, even if the top is missing.",
            "So that's going to work better.",
            "Now you still have the problem of tracking.",
            "Multi purpose is backtracking is still there.",
            "Now the global training is the best you pre train with sequential learning and you train also models together with examples from the whole problem problems.",
            "So you initialize every little part you put them together.",
            "And now you see this as a huge multi.",
            "The huge deep network and you pretend you compute the gradients everywhere you optimize everything.",
            "That actually works better and we offer evidence that it works better."
        ],
        [
            "So the problem is that when you go in complicated things like check amount, well what you have between the modules are not vectors.",
            "Is a complex set of possible fields with each labeled with some scores or a complex set of possible segmentations, each level with some score.",
            "So in a multilayer network you have a layer and layer communicate vectors.",
            "Well, in what we call the graphs on network, the layer communicates graphs and the graph service clear semantic in each graph of path between the start node in the end node describes a possible alternative with its cost."
        ],
        [
            "So let me give an example.",
            "Suppose you want to segment addition of an image containing various characters.",
            "So you got a segmentation module and what it does it gets it produces one of these graphs and if you look at this graph you will start node here and then down here and every path between the start and the end describes a possible segmentation.",
            "And every arc there as a cost, which is an estimate of basically actually.",
            "Maybe every node here, because you are an estimate of how good this split between possible character is.",
            "And then you go to a character score.",
            "The character score is going to replace every little image here by your score.",
            "That tells you whether this is a character.",
            "So there's this is a three.",
            "We scored 01.",
            "This is a four with Core 3.4 high scores.",
            "In that case means bad thing is inverted.",
            "Its Youngs convention here.",
            "I don't know why you want to call them energy and they have to be low while other people called them score and they have to be high then change anything.",
            "And now if you take a path, you can add this course and you get the score for.",
            "A path, but this time this core instead of being just being something that depends on the.",
            "Primary, your segmentation heuristics depends on the recognizer.",
            "When you have this path, you find the best parts of it are being of the best segmentation.",
            "OK, now let's trend that."
        ],
        [
            "I'm going to come back to this.",
            "You actually might win that I need to.",
            "On now I need to to go back to the training objectives for classification.",
            "You have X, which is an input material check image and why, which is the output classes and amount is a class.",
            "You have a lot of classes in that case.",
            "If you do a generative model, you're going to define the model PW of XY is going to some.",
            "That's going to be an approximate of P of X&Y is going to be normalizing that way, meaning that the sum over all X of P of XY is going to be 1.",
            "So you modeling each class and you optimize the likelihood.",
            "If you do discriminative training, we do some you want to try to estimate P of Y given X.",
            "So you're going to define the function PW of XY.",
            "Is going to normalize it by doing the sum of RY of PW of XY equal 1.",
            "We need that for every X the sum of the score is 1.",
            "And you need to optimize the likelihood.",
            "And if you look at the difference between the two, the only difference is the normalization.",
            "This is quite interesting."
        ],
        [
            "So if you look at probabilistic models in the case of hidden Markov models, you have a generative hidden Markov models.",
            "B of XY.",
            "This P of XY with given the weight is the sum of all possible sequences.",
            "Of levels now level is a path in a graph, so it's going to be a sequence of the product of the probabilities, the emission probabilities, the transition probabilities for breathing from a set to the next, which is pretty much a score on an energy or whatever, and emission probability.",
            "And because it's constructed with priorities, that ensures normalization.",
            "The sum over X of these things is going to be 1.",
            "If you make a discriminant hidden Markov model, you try to have P of Y given XW and if you do the same kind of things.",
            "The output of this classifier must be normalized to get the proper some to work, and so that you lost function works.",
            "So you need to have some over St of PST, so this is probability of transitioning from state T -- 1 to set St in the graph.",
            "Given that you observe XD and given the whites and for this 2721 properly think that the summer Y of this value is 1 unit P of T given S T -- 1 blah blah blah to some over the possible St to be one.",
            "The output of the local classifier must be normalized, and this is a bad idea.",
            "Example.",
            "This was an example.",
            "I don't remember exactly why.",
            "Look at this this thing here.",
            "Here you want a classifier that's going to tell you which digit is that.",
            "It's not a digit, it's nothing.",
            "So you normalize it, you prevent the classifier from telling you well, this is not a digit, all those corsello.",
            "You want this.",
            "The sum of this being a one or two or three or four or five or nine to be one, while in fact you would like all this cost to be 0 to be most informative.",
            "So when you do this normalization, your classifier is not able.",
            "To tell.",
            "That this is not the proper digit and should be eliminated.",
            "And that's a big problem that doesn't work that well."
        ],
        [
            "So.",
            "The way we did it in the 90s was to say, OK, probabilities are screwed up.",
            "We cannot do that.",
            "Let's just use course or energy the measure, the add and multiply probabilities, but they're not normalized.",
            "Discover Path is the product of the.",
            "Of course the score for sub graph is the sum of the past scores and we trend by maximizing the log and you take the score.",
            "Of, let's say a bath.",
            "Divide by those sun.",
            "Of this course of all the path, so we normalize at the very end.",
            "Turns out that this is a semi CRF.",
            "Except that instead of being a CRF with linear classifier, overtime is a CRF of topological architecture that looks at least in the check amount at different ways."
        ],
        [
            "So how does it translate in our system here?",
            "So you remember this that I described?",
            "And here is how it's going to go.",
            "In fact, have the segmenter is similar.",
            "You have the segmentation path here.",
            "You have listed convolutional Nets to try to classify each of the examples.",
            "Giving this graph here.",
            "So in this graph that at this low value of values path.",
            "So for instance this these three here could be a five with core to three, or could be a three with calls U .1 remembering that case law schools are better.",
            "And once you have this graph here, which I called the interpretation graph, you're going to do two things.",
            "One is take a little bit to take the best path.",
            "This is the answer of your system.",
            "Which in that case happens to be 341, happens to be wrong.",
            "It took that one.",
            "And does and you add this course that discovered the answer of your system?",
            "But then you're going to use the desired answer.",
            "You have the supervision.",
            "You know this is 34.",
            "And say I'm going to select all the paths that are compatible with the desired answer.",
            "Think of it, Abby.",
            "And see this is my best answer that's compatible with the truth.",
            "It has a higher score.",
            "And if this course I interpreted that mynewsla probabilities, I can just take the difference optimize.",
            "Yes.",
            "How do you train it?",
            "The problem is that the class does not.",
            "The digit should be trend with examples of miss segmentation.",
            "Now the example of Mystic Mentation they going to change.",
            "So in fact this is what you're doing here.",
            "You authorizing the local classifier to set this is none of the things I know by having all its course slow, or this output slow, or discourse high whatever.",
            "Or is energy is high, or discourse low and give fine.",
            "And you're going to trend the classifier to do that within the whole structure.",
            "To do that exactly when this is needed.",
            "Now what are described here?",
            "I see graphs with checks but yes.",
            "On here.",
            "Things that.",
            "So, so that's interesting because basically when you pre trend in all Nets, let's say you're going to pretend this on segmented image that you collect some where they're going to be.",
            "Like you said that you tend to be overconfident, and then we want to make to see a digit everywhere.",
            "But when you start training them within this whole harness, then we have to be smarter.",
            "So they will have to develop scores that actually mean something and have this additional information.",
            "This is not a digit."
        ],
        [
            "So if you compare this in a CRF, well, this cost function is about the same.",
            "But here we have a Yorkie called cost to find model is that there is cheap insurance, meaning that just a forward prop.",
            "Scoop of nights."
        ],
        [
            "So 95 there was a check without that work that way, that was done by a lot of people, including Yoshua.",
            "Was industry diploid 96's purpose is about 15% of all U S6 for 15 years so that that was a real thing.",
            "It actually worked.",
            "You would start with a check graph.",
            "We feel look at the whole segment, character Connoisseur, composer Viterbi fact only the top part was trend.",
            "We we trained on 1/4 million check images which was huge at the time and we turned down to the character recognizer and that's about it.",
            "The rest was too just too hard."
        ],
        [
            "But even doing though, so the training is this kind of things.",
            "We don't use a Viterbi user forward.",
            "Instead it's a bit more stable about case.",
            "And you have a vast improvement in the performance when you do this.",
            "So.",
            "Yes.",
            "Yeah, yeah.",
            "Oh sorry."
        ],
        [
            "Actually, I didn't describe this here, so you have this difference here and then you have the gradient of the loss function, which is plus one.",
            "So it's a difference, so it's going to be plus 1 -- 1.",
            "Here the sun minus 1 -- 1 + 1 + 1 + 1 In the Viterbi transformer that selects a graph along the graph.",
            "You still have the back propagation of plus one and zero over the other ones.",
            "Then when you go here, you have to send them so you get basically minus negative signal on the wrong path and a positive signal on the components of the wrong path and a positive signal component to the correct path.",
            "These gradients can go back into the neural networks.",
            "Here you can update the neural networks and if you have if you have terms that come from the segmenter, you could also do that if you wanted to.",
            "So yes, you back propagate the gradient to the whole graph, which is a fair amount of bookkeeping if you think about it.",
            "OK."
        ],
        [
            "And the interesting part is that you can define something that's called the graph.",
            "Transition Break takes an input graph and output grafana structure.",
            "That's called a graph transducer.",
            "That's the way she know about graph theory exists and you have a graph composition operation that you can define abstractly that tells how you do graph transformations.",
            "Then you can most of these bricks here."
        ],
        [
            "Actually, all of them in that case, except the forward I implemented with the same brick.",
            "So the the similar 2000 lines of code are running in every little thing.",
            "The only thing that's different are two methods that are defined in the graph transformer."
        ],
        [
            "So that was a complex task address with a lot of engineering.",
            "Basically we split the tasks in various steps a priori.",
            "And and we we went for that, and then trained for that.",
            "And then at the end we relax a little bit and let the network speed by themselves or something.",
            "And maybe the big surprise of deep learning, at least the initial one when people started to do unsupervised learning that we don't need to do that."
        ],
        [
            "Because I'm.",
            "Turns out.",
            "So if you remember the beginning of deep learning, there was a lot about unsupervised pretraining.",
            "That was sort of abandoned because now people use GPU and lots of data, but still everybody says unsupervised pretraining there is something to be done about this.",
            "I have a problem with unsupervised that I'm going to describe later.",
            "Actually, maybe I'm not going to have the time to describe it, But anyway I'd like to see the unsupervised training as an auxiliary task.",
            "You define another task and you hope that it's going to help.",
            "And if you think about an interesting problem that we want to solve is a problem for which labels are expensive.",
            "If you want to solve a particular problem, a complex one, you wouldn't solve it.",
            "It was easy to get the labels, so it's going to be a program to get labeled data.",
            "But you can see that in the vicinity of an interesting task there are problems that are not that interesting, for which labels are easy.",
            "So there."
        ],
        [
            "An example that comes from Matt Miller in 2006.",
            "At the time it was more like a thought example.",
            "Suppose you want to recognize the face of 1 million person at that time.",
            "It was something that was not really feasible.",
            "How many label image per person can we open at that time?",
            "There was no Facebook.",
            "Well, that's very difficult.",
            "You're not going to have 100 the labeled images for one million persons.",
            "So the auxiliary tasks that can define A2 face image representing the same person.",
            "And here we have a lot of examples because we take the movies and app interfaces with two faces in the same frame, the different people.",
            "Well, you have the case of mirrors in the case of Twins, but that's something you can bound, you know.",
            "And if you have two faces in successive frames, they likely to be the same person, except different lighting, different angles.",
            "Things are going to change, so training a system to recognize whether two faces image are the same person is much easier if you mention just to collect the data.",
            "So you contribute something like the face that kind of feature extractor.",
            "Let's think you become big set of convolutions here.",
            "Same here.",
            "Shared weights and a discriminator.",
            "That's going to take the output features and say some person or not.",
            "And you trained that way on this huge amount of data.",
            "Easy to get.",
            "Then, well, you just take your convolutional layer, put the classifier on top and say this is John.",
            "The same features that are useful to see that these two faces are the same person are going to be useful to say who this person is.",
            "And you're going to be able to add the new persons very easily."
        ],
        [
            "It's been done in NLP by owner so."
        ],
        [
            "Uncle Bear, so I'm not I'm going to skip that."
        ],
        [
            "It's going to be too long."
        ],
        [
            "Actually doubles."
        ],
        [
            "It's been done by Maxim, who is somewhere hiding there for object recognition.",
            "So you take dogs in image net, nice little doc centered in the image.",
            "But you have a lot of images, like 1 million dogs.",
            "The dogs in Pascal work, you have 10,000 images, and they're more like this.",
            "You see, this is a dog.",
            "This is not a dog.",
            "Oh, these are dogs and this is not a dog.",
            "So they're more challenging and the question is, can we leverage the?",
            "The convolutional layers that you learn on something like this to treat that.",
            "And so well."
        ],
        [
            "Maximon colleagues.",
            "Build this kind of big things where you trained on image net first and then you did take VO.",
            "Can you take patches and you add additional layers on top of the convolutional layers and you trend adaptation layers leaving the convolutional layers pretty much frozen.",
            "And when you do this, you get state of the art in classification on Pascal walk.",
            "And in fact."
        ],
        [
            "At the time my scheme, Joseph, Ivan, and I did that.",
            "A lot of people did that at the same times, like I think there was a transfer for Caltech 256 by Rob Ferguson modular, maybe a couple months before then.",
            "There's a Pascal detection by rose gifts.",
            "We can now couple more now, and this idea of transferring features you learn something on image retinal on large data set that's labeled but not very interesting.",
            "Now imagine it is not very interesting, in fact.",
            "The 1000 classes of the Challenger reasonable, but if you look at the 20,000 classes you know there is a class that's called regional manager.",
            "Another one is district manager.",
            "How do you distinguish original manager from a district manager?",
            "But they still you trend with that and you get good features.",
            "So, so it's not that far from the unsupervised learning, you know."
        ],
        [
            "So.",
            "So yes, and supervisory tasks.",
            "So the unsupervised pretraining I don't like it to see that some supervise and here is why."
        ],
        [
            "What is a cluster?",
            "The assumption that the shape of the density within the underlying categories you see something like this.",
            "Maybe it means that you have two categories.",
            "This is called the cluster assumption.",
            "No."
        ],
        [
            "You know, if you look at an image is a bunch of pixels and square grid, no images in our retina didn't like that the receptors they know square root density varies everything.",
            "So so basically the you have the square grid with RGB pixels is a kind of idealized version of what's in your eyes and so you would like something that works the same if you do arbitrary transform of the input space.",
            "So I take my 2 images here and I'm going to change the inputs.",
            "Best Buy a smooth function that's going to compress the points here and split apart the points here.",
            "And when I do this while the base boundary between the two classes remains.",
            "But my yellow do cluster, they just one cluster anymore.",
            "So when you look at this, the cluster structure of data is not really something that inherent in the data, because you can destroy it by re parameterising the input.",
            "Or you can you can create it artificially.",
            "The cluster structure is in fact.",
            "The structure that you put inside by feature rising your data in a particular way.",
            "So sometimes you build it.",
            "I think it is.",
            "It's it's.",
            "It's incorrect to believe this really unsupervised.",
            "You just leverage assumptions that you put in your system by other means."
        ],
        [
            "You can still change it.",
            "If you have a zero in between, it's going to be hard.",
            "No."
        ],
        [
            "Counter example here.",
            "This was quite well separated.",
            "The best boundary is here.",
            "With a big O in between.",
            "Well, you can collapse to 0.",
            "Sure, but you know.",
            "They're not like that.",
            "Don't forget, in addition that you don't have this yellow distribution, we just have a couple points so you don't know if it's zero.",
            "We just don't have enough points to get something in between inside.",
            "So, So what I'm meant to say is that in unsupervised learning or in clustering there is a lot of it.",
            "That is something that you put inside by feature rising or choosing particular feature particular access to represent your data."
        ],
        [
            "So so for me, unsupervised learning is comparable to using really cheap labels like X One X2 are close X One X3 are not close.",
            "And when you choose the feature space, you choose how you represent the data.",
            "This is what you're choosing, you choosing the metric, and you're using the proximity in your data.",
            "That means you say you're choosing a kernel.",
            "Is a similarity measure essentially?"
        ],
        [
            "OK, so I'm going to stop here.",
            "Jump overall."
        ],
        [
            "And with my conclusion.",
            "So.",
            "There going to be lots of neural.",
            "Net applications in the coming years.",
            "I wrote that two years ago, so is this when we inside it.",
            "So learning perceptual tasks with no net works quite well.",
            "Data and compute power here."
        ],
        [
            "Now the statistical machine Learning Research program was.",
            "The following is being set up in the 2000s or in the 90s discussing the models.",
            "What models can we use?",
            "Water the approximation properties and what are the structures we can define models discussing the loss functions, what kind of loss can we invent?",
            "What are the asymptotic consistency effects or loss functions for structural things like just like those are described?",
            "Discuss the learning algorithm optimization, large scale and discussing the generalization like capacity control structures and so on and.",
            "Done.",
            "I mean, there are a lot of details looking around that could be improved and could be surprises, but if you look at the big lines this is what machine learning is achieved in the last 20 years."
        ],
        [
            "Now.",
            "Oh I think.",
            "OK, that's this.",
            "Depends a lot of what I didn't say.",
            "I think the new objective study what we should look at this complex problems the real bottleneck that we have now is that we know quite well are to solve a particular problem for which we have data in abundant quantity.",
            "And are we going to be able to do something reasonably well?",
            "But when we have lots of data that are clearly in the same category.",
            "But they're not exactly the same when we have to do transfer learning between one and another one.",
            "When you have to combine learning systems that do different things in order to get to achieve a big task, these are the things we don't know how to do.",
            "And I think This is why the big payoff is going to be.",
            "That's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can go to formulas that are about twice as big.",
                    "label": 0
                },
                {
                    "sent": "The guarantee risk is twice as big as what you can see, but to do this you have to use a measure of capacity that are so complicated that actually more complicated than running the experiments.",
                    "label": 0
                },
                {
                    "sent": "Just finding the capacity or measuring the capacity of a familiar function is something you can do analytically anymore and it becomes too complex.",
                    "label": 0
                },
                {
                    "sent": "So so in fact this concept exists, but getting to the merger of the capacity that's close enough to give you a good good estimate is not something practical.",
                    "label": 0
                },
                {
                    "sent": "So This is why I say we don't care, but it remains that when you take sets that are embedded, the capacity can only increase.",
                    "label": 0
                },
                {
                    "sent": "That remains.",
                    "label": 0
                },
                {
                    "sent": "And that's true for all of them.",
                    "label": 0
                },
                {
                    "sent": "So so yesterday.",
                    "label": 0
                },
                {
                    "sent": "I spoke a lot about optimization and I stayed in the domain of batch optimization.",
                    "label": 0
                },
                {
                    "sent": "So basically you optimize a single function without leveraging the structure and I told you at the end two things.",
                    "label": 0
                },
                {
                    "sent": "That even though they are good methods like conjugate gradients, LB of GS, One has to be suspicious about them.",
                    "label": 0
                },
                {
                    "sent": "Because they don't exploit the structure of the learning problem very well, and because optimizing the training error is not the same as optimizing the testing error.",
                    "label": 0
                },
                {
                    "sent": "And I told you, but still this gives a lot of ideas about simple things we can do to get neural networks to work better speaking, and this is where we had a discussion about measuring the size of the weights, the size of the gradients, and making sure that everything is reasonable, that the gradients propagate properly and that basically merger things use the ample time that you have while your system is training to measure useful things and make sure that nothing is completely off the charts.",
                    "label": 0
                },
                {
                    "sent": "So I would like now to go to the stochastic gradient.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So we have this.",
                    "label": 0
                },
                {
                    "sent": "Function here.",
                    "label": 0
                },
                {
                    "sent": "This is the training error.",
                    "label": 0
                },
                {
                    "sent": "And the number of training examples can be large billions.",
                    "label": 0
                },
                {
                    "sent": "Billions is not heard unheard of at all.",
                    "label": 0
                },
                {
                    "sent": "And examples are redundant, otherwise there is nothing to learn.",
                    "label": 0
                },
                {
                    "sent": "We know that.",
                    "label": 0
                },
                {
                    "sent": "Doubling the number of examples bring a little more information, but not that much.",
                    "label": 0
                },
                {
                    "sent": "So do we need to all the examples in the first optimization iterations so there is an algorithm that folks are going that works actually quite well, which is to start with a small training set, optimize that, then use that to one.",
                    "label": 0
                },
                {
                    "sent": "Start with double the training set side, optimize that, then double optimize that, then dollar optimize that?",
                    "label": 0
                },
                {
                    "sent": "It's not bad at all if you do these things.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "All examples may not be available simultaneously.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they come on the fly, like if you have a clickstream on the website you know you're not going to have all examples right away.",
                    "label": 0
                },
                {
                    "sent": "In quantity of too large to store retrieve Clickstream again.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That goes the ID of offline versus online optimization, so you minimize the cost.",
                    "label": 0
                },
                {
                    "sent": "Let's say a regularizer.",
                    "label": 0
                },
                {
                    "sent": "That's suspiciously like this VM actually.",
                    "label": 0
                },
                {
                    "sent": "Plus it's running error and offline.",
                    "label": 0
                },
                {
                    "sent": "You process all the examples together.",
                    "label": 0
                },
                {
                    "sent": "So basically, if you do a gradient dissent, you're going to compute the gradient of all of this.",
                    "label": 0
                },
                {
                    "sent": "You sum over all the examples, and you make a repeat.",
                    "label": 0
                },
                {
                    "sent": "Or you can push them 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "So you pick a random example and you just take.",
                    "label": 0
                },
                {
                    "sent": "An estimate of this gradient.",
                    "label": 0
                },
                {
                    "sent": "That's based on the simple single example.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You get the trajectory that's about like this.",
                    "label": 0
                },
                {
                    "sent": "You know, if you remember the trajectories of a batch gradient, you get something extremely noisy.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                },
                {
                    "sent": "I thought about trying to show some proofs of these things, but actually I lost the time by speaking about that Nick, so I'm not going to do that unless you ask for it.",
                    "label": 0
                },
                {
                    "sent": "But basically the estimate of the gradient is very noisy.",
                    "label": 0
                },
                {
                    "sent": "Now what's going to happen and you can show it in half a page.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "If you have a constant again constant learning rate, you're going to decrease exponentially, like a real gradient up to a point.",
                    "label": 0
                },
                {
                    "sent": "That's basically the noise level that you have in your gradient.",
                    "label": 0
                },
                {
                    "sent": "And inside this noise level you just flying over the optimum.",
                    "label": 0
                },
                {
                    "sent": "So therefore you need to decrease the gains, typically like 1 / T. In order to go to the optimum, if you actually want to go to the optimum.",
                    "label": 0
                },
                {
                    "sent": "Decrease both the X -- X star and F of X assuming sufficient convexity business.",
                    "label": 0
                },
                {
                    "sent": "F of X is a minimum unique style I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Ofx my new cipher fix star is going to decrease.",
                    "label": 0
                },
                {
                    "sent": "Exponentially FX minus F of X size.",
                    "label": 0
                },
                {
                    "sent": "Is what you can show is that.",
                    "label": 0
                },
                {
                    "sent": "F of X T -- a certain constant.",
                    "label": 0
                },
                {
                    "sent": "Is going to decrease exponentially go to zero, but that constant is higher than 4/5 star and this constant depends on either.",
                    "label": 0
                },
                {
                    "sent": "This is what you can show very easily.",
                    "label": 0
                },
                {
                    "sent": "Now, why is such noisy process attractive?",
                    "label": 0
                },
                {
                    "sent": "Well, obviously you is much.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easier to compute if this if N is 1 billion, this is 1 billion times faster.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, let's go back to redundant example.",
                    "label": 0
                },
                {
                    "sent": "When you have redundant examples that increase the computer cost of offline learning because you have to go over all of them.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't really change the computing cost of online learning, because you do them randomly.",
                    "label": 0
                },
                {
                    "sent": "So imagine that I said that contains 10 copies of the same one.",
                    "label": 0
                },
                {
                    "sent": "Another examples, it's a mistake somebody made a mistake.",
                    "label": 0
                },
                {
                    "sent": "10 copies of the same or not examples.",
                    "label": 0
                },
                {
                    "sent": "If you do batch gradient descent well.",
                    "label": 0
                },
                {
                    "sent": "Computation is 10 times larger than necessary because you're going to both 10 times over the same examples before getting a gradient.",
                    "label": 0
                },
                {
                    "sent": "And you're not going to be able to use a 10 times larger learning rate.",
                    "label": 0
                },
                {
                    "sent": "If you do stochastic lessons, it makes no difference because you pull randomly from you set and whether you have 10 copies of the same data or not, you have exactly the same distribution.",
                    "label": 0
                },
                {
                    "sent": "So all this has to be made more precise.",
                    "label": 0
                },
                {
                    "sent": "So let's go back where the situation where you have unlimited data.",
                    "label": 0
                },
                {
                    "sent": "We have a meaning that data is not really unlimited, but the computing time is limited.",
                    "label": 0
                },
                {
                    "sent": "And what we can, which we think a specified time budget and think about the kind of tradeoffs.",
                    "label": 0
                },
                {
                    "sent": "If you optimize more thoroughly, which is probably a good thing.",
                    "label": 0
                },
                {
                    "sent": "But we must save time by other means.",
                    "label": 0
                },
                {
                    "sent": "So we can use less examples, which is a bad thing.",
                    "label": 0
                },
                {
                    "sent": "Or we could use a simpler model, which might be a bad thing if unless the model the simpler model is actually better for the program that we don't want advance.",
                    "label": 0
                },
                {
                    "sent": "Or Conversely, if you optimize less precisely, which is probably a bad thing.",
                    "label": 0
                },
                {
                    "sent": "Well, you have the time to use more example, which is probably a very good thing or more refined model which may be good.",
                    "label": 0
                },
                {
                    "sent": "And if you use more example actually is good because that allows you to use a more refined model again because of the structural with minimization argument.",
                    "label": 0
                },
                {
                    "sent": "So the trade offs can be much more complicated than what you see in the case where this number of examples limited and these tradeoffs depend on the algorithm, because they depend how much time do you lose or how much time do you spend.",
                    "label": 0
                },
                {
                    "sent": "If you want to optimize more thoroughly.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Give us the computing time here is intestinal.",
                    "label": 0
                },
                {
                    "sent": "Suppose this is a classification problem.",
                    "label": 0
                },
                {
                    "sent": "There is the base error.",
                    "label": 0
                },
                {
                    "sent": "That's the best one you ever going to achieve on that problem.",
                    "label": 0
                },
                {
                    "sent": "OK, if you have a 10,000 examples, is going to be like this is going to be going to learn fast, but then it's going to plateau auto certain level because you don't have enough examples.",
                    "label": 0
                },
                {
                    "sent": "If you increase number of examples, you're probably going to go like this.",
                    "label": 0
                },
                {
                    "sent": "That's the typical batch algorithm going to be like this.",
                    "label": 0
                },
                {
                    "sent": "If you have 1,000,000 examples, you're going to be 100 times slower than this, but you're going to go lower.",
                    "label": 0
                },
                {
                    "sent": "Now you can change a lot of other things.",
                    "label": 0
                },
                {
                    "sent": "You can change optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can change your model and you get a lot of curves like this.",
                    "label": 0
                },
                {
                    "sent": "And what you're really interested in is this.",
                    "label": 0
                },
                {
                    "sent": "The bottom of the envelope.",
                    "label": 0
                },
                {
                    "sent": "These are the good combinations.",
                    "label": 0
                },
                {
                    "sent": "And look how bad this is.",
                    "label": 0
                },
                {
                    "sent": "The good combination depends really on how much time you have.",
                    "label": 0
                },
                {
                    "sent": "If you have very little time or don't try to use all your examples, there is no time for that.",
                    "label": 0
                },
                {
                    "sent": "If you have more time, maybe you can use more examples, but you have questions about which optimizer in which model someone needs to sort this out much better.",
                    "label": 0
                },
                {
                    "sent": "So again, in general this is very hard to do, but we can learn things by looking at a simple case, so we're going to come back to the convex set up simple, strongly convex, smooth, or look all nice properties, because these are these other cases we can understand and then we can try to extrapolate what's happening in the real world.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to take a family of linearly parameterized, smooth, convex lawston, strongly convex.",
                    "label": 0
                },
                {
                    "sent": "No typical, not even as VM actually think squared loss of them like that.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to compare three iterative optimization algorithm, gradient distant, the 2nd order gradient descent, which is basically using the Hessian matrix to try to go faster.",
                    "label": 0
                },
                {
                    "sent": "And the stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "What do I get?",
                    "label": 0
                },
                {
                    "sent": "OK, well the gradient descent to describe their ID best feed achieved when he to equal 1 over Lambda Max we saw that last time.",
                    "label": 0
                },
                {
                    "sent": "The 2nd order you try to use the optimal scaling.",
                    "label": 0
                },
                {
                    "sent": "And when you have the optimal scaling, well it's nice because it becomes a circle.",
                    "label": 0
                },
                {
                    "sent": "You can go direct to the optimum if it's quality or close.",
                    "label": 0
                },
                {
                    "sent": "And stochastic is this thing where you have this noisy approximation and decreasing learning rate in it over T. And our ethos, will we get there?",
                    "label": 0
                },
                {
                    "sent": "Is there is a calculation about what's best for for this simple case?",
                    "label": 0
                },
                {
                    "sent": "And you can analyze this and you're going to have to believe some of the formulas because each of them can be quite a handful to show properly.",
                    "label": 0
                },
                {
                    "sent": "So time pair, iteration gradient decent N because it's number of examples to compute the gradient, you have to go over all of them.",
                    "label": 0
                },
                {
                    "sent": "Same for the Newton's DDS one.",
                    "label": 0
                },
                {
                    "sent": "Just pick one example and I'm going to change that later.",
                    "label": 0
                },
                {
                    "sent": "Iterations to get a certain accuracy row.",
                    "label": 0
                },
                {
                    "sent": "But you see that the ground is sent.",
                    "label": 0
                },
                {
                    "sent": "You have this exponential decrease, so it's going to be log one over rho.",
                    "label": 0
                },
                {
                    "sent": "If you do a nutone and is quatic you go straight to optimum, but if it's not quadratic and its most enough in the 3rd and 4th derivatives, you typically get something like log log one overall, which is a lot less than log one.",
                    "label": 0
                },
                {
                    "sent": "Overall, this is awfully fast.",
                    "label": 0
                },
                {
                    "sent": "You can get a very good accuracy extremely quickly.",
                    "label": 0
                },
                {
                    "sent": "SGD one overall at best?",
                    "label": 0
                },
                {
                    "sent": "And you can show that something like SGD cannot be better than one overall.",
                    "label": 0
                },
                {
                    "sent": "And there is a constant on top that's important to consent will matter.",
                    "label": 0
                },
                {
                    "sent": "And time to reach a certain accuracy while you multiply the two.",
                    "label": 0
                },
                {
                    "sent": "And you can see that you don't optimize much faster than a simple guarantee sent and stochastic gradient for optimization is completely hopeless.",
                    "label": 0
                },
                {
                    "sent": "If your life depends on optimization, do not use stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "But now look at my curves.",
                    "label": 0
                },
                {
                    "sent": "Here there is something I called the excess 0, which is how far I am from the very optimal one.",
                    "label": 0
                },
                {
                    "sent": "And I'm trying to estimate the time before I reach a certain excess error.",
                    "label": 0
                },
                {
                    "sent": "And where there is a Alpha here between one and two, let's say Alpha equal 1 for simplicity, the power for the grand dissent is currently one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "Log one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "For the Newton University on Logon, overseen on log log, one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Is the same.",
                    "label": 0
                },
                {
                    "sent": "This log logs.",
                    "label": 0
                },
                {
                    "sent": "We don't care.",
                    "label": 0
                },
                {
                    "sent": "4G DS one of epsilon without the logs and look look certainly as GD looks good.",
                    "label": 0
                },
                {
                    "sent": "So that means that when you're using this Newton algorithm, the only thing that's happening is that you overfit faster.",
                    "label": 0
                },
                {
                    "sent": "In terms of learning, you don't much matter, and that's not silly actually, because when you do stochastic gradient you're trying to learn.",
                    "label": 0
                },
                {
                    "sent": "With the examples you've seen.",
                    "label": 0
                },
                {
                    "sent": "And that's going to work well if what you've learned in the example you've seen is predictive of the example you're going to see in the future.",
                    "label": 0
                },
                {
                    "sent": "While here you learning with a fixed set of examples, but you want to measure an example that you want to see in the future.",
                    "label": 0
                },
                {
                    "sent": "So the same kind of.",
                    "label": 0
                },
                {
                    "sent": "In essentially between.",
                    "label": 0
                },
                {
                    "sent": "This line, which is the optimization of training error and this line, which is the time to the access testing error.",
                    "label": 0
                },
                {
                    "sent": "You have the mathematics are in between.",
                    "label": 0
                },
                {
                    "sent": "And they limit you to something like one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "You can only be worse.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK, the variance would use stochastic gradient there.",
                    "label": 0
                },
                {
                    "sent": "Things that can see all the training set to start with because you have to compute the reference point and the optimizer training error.",
                    "label": 0
                },
                {
                    "sent": "So the variance reduce are going the optimizer training or like long log one over role.",
                    "label": 0
                },
                {
                    "sent": "But the able to cheat on the end and make it this much smaller.",
                    "label": 0
                },
                {
                    "sent": "If you do everything right.",
                    "label": 0
                },
                {
                    "sent": "Which is a very nice data property.",
                    "label": 0
                },
                {
                    "sent": "But when you go there, you still see the same kind of things.",
                    "label": 0
                },
                {
                    "sent": "So if you look in testing it all is going to be about the same and the only thing you can change is with the constant.",
                    "label": 0
                },
                {
                    "sent": "So that means that when we're playing all these games to make optimization for learning faster, we playing with the constants are based on the testing here, or we're going to be in one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "So think about it, I'm going to use a fancy 2nd order algorithm that's going to cost me 5 times more per iteration.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, five times is a constant.",
                    "label": 0
                },
                {
                    "sent": "So I better hope that the constant that I have here or here, whatever on that line is 5 times better, otherwise I lose.",
                    "label": 0
                },
                {
                    "sent": "A constant can be your GPU.",
                    "label": 0
                },
                {
                    "sent": "GPU is a constant like 50.",
                    "label": 0
                },
                {
                    "sent": "A constant can be an optimization.",
                    "label": 0
                },
                {
                    "sent": "So that means that designing.",
                    "label": 0
                },
                {
                    "sent": "Optimization algorithm for learning that are much better than, let's say, SGD as a baseline is hard because you're fighting with the constants you fighting with the engineers who are using GPU.",
                    "label": 0
                },
                {
                    "sent": "Is not the same like when people went to Newton from gradient decent.",
                    "label": 0
                },
                {
                    "sent": "Well don't care about the GPU.",
                    "label": 0
                },
                {
                    "sent": "You have an order of magnitude better.",
                    "label": 0
                },
                {
                    "sent": "You're going to blow out if you run this on Matlab and this on the GPU.",
                    "label": 0
                },
                {
                    "sent": "The Matlab will win.",
                    "label": 0
                },
                {
                    "sent": "Not true in here anymore.",
                    "label": 0
                },
                {
                    "sent": "Is changing This is why the impact of accelerating machines machines that go faster and faster is so important in machine learning?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's take a practical illustration.",
                    "label": 0
                },
                {
                    "sent": "This is again a completely convex problem.",
                    "label": 0
                },
                {
                    "sent": "Actually, this is Elsie one.",
                    "label": 0
                },
                {
                    "sent": "These are VMS with L2 regularization and log loss.",
                    "label": 0
                },
                {
                    "sent": "If you trend withdrawn, which is the part of liblinear that was before the the coordinate ascent?",
                    "label": 0
                },
                {
                    "sent": "That's a super linear algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here you have the optimization accuracy and the training time, and you see it's below a line.",
                    "label": 0
                },
                {
                    "sent": "It's concave.",
                    "label": 0
                },
                {
                    "sent": "That means that the more accuracy you want, the faster it goes.",
                    "label": 0
                },
                {
                    "sent": "It's going to give you, well, you can get 12 decimal digits in less than one minute.",
                    "label": 0
                },
                {
                    "sent": "Except we don't care.",
                    "label": 0
                },
                {
                    "sent": "If we take a stochastic gradient well, it starts very quickly because at the beginning it seems very few examples.",
                    "label": 0
                },
                {
                    "sent": "But then if you want accuracy that's more than six or 7 digits is going to be, you're going to hit a wall.",
                    "label": 0
                },
                {
                    "sent": "Is going to take forever and might I say here is we speaking minutes here we speaking hours and here we speaking month.",
                    "label": 0
                },
                {
                    "sent": "Now look at the testing error here.",
                    "label": 0
                },
                {
                    "sent": "The testing error you get with this optimization accuracy.",
                    "label": 0
                },
                {
                    "sent": "Well because down and go through basic role so you get the SM taught.",
                    "label": 0
                },
                {
                    "sent": "Long before you hit the wall.",
                    "label": 0
                },
                {
                    "sent": "And the kind of bonds that are showing before that tend to prove that this is how this is happening, and This is why stochastic gradient is such a good baseline, doesn't mean it's not going to be improved.",
                    "label": 0
                },
                {
                    "sent": "Doesn't mean it's the best one.",
                    "label": 0
                },
                {
                    "sent": "It just says it's a good baseline.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Suppose you want to quickly achieve a good training set performance.",
                    "label": 1
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "You take a super linear algorithm very fast one.",
                    "label": 1
                },
                {
                    "sent": "And you initialize with SGD, you take a Jeep off and then you branch there.",
                    "label": 0
                },
                {
                    "sent": "So you get something like this.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "The same.",
                    "label": 0
                },
                {
                    "sent": "Measure.",
                    "label": 0
                },
                {
                    "sent": "Optimization accuracy.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "And then you can say that when they are going to different, that can be slightly different, but in practice you don't see a difference and all this has been repeated enough that there is no.",
                    "label": 0
                },
                {
                    "sent": "This is a couple thousand iterations.",
                    "label": 0
                },
                {
                    "sent": "You don't see robust in that stuff.",
                    "label": 0
                },
                {
                    "sent": "So if you do something like SVG you see in a little corner of the paper that say oh, in practice we initialize it with SGD for the first pass.",
                    "label": 0
                },
                {
                    "sent": "And the site is the same because of this because you get on the learning problem, you go much faster at the beginning and then you can optimize on the train on the training set, but up to constants.",
                    "label": 0
                },
                {
                    "sent": "And again I say up to constants and constant matter.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is not completely true.",
                    "label": 0
                },
                {
                    "sent": "Up to constants, you can say that when you start switching to the Super linear algorithm is when you start overfitting.",
                    "label": 0
                },
                {
                    "sent": "Well, actually no, not necessarily, because the HD constant can be a bit bad and sometimes you can.",
                    "label": 0
                },
                {
                    "sent": "You can shave the constant by by using a better algorithm.",
                    "label": 0
                },
                {
                    "sent": "So now all our tricks will be about shaving the constants.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So improved algorithm how to shave the constants in stochastic gradient.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A lot of tricks, certain other tricks which is using the hidden metrics, momentum and acceleration mini batch parallel there all about constants.",
                    "label": 0
                },
                {
                    "sent": "2nd order is constant because when you have a learning problem and look at the testing error, this is no longer changing.",
                    "label": 0
                },
                {
                    "sent": "The order of the optimization complexity is changing the constant.",
                    "label": 0
                },
                {
                    "sent": "Momentum acceleration that we connected to signal tricks by using mathematics.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to describe but the mention.",
                    "label": 0
                },
                {
                    "sent": "Mini batch techniques.",
                    "label": 0
                },
                {
                    "sent": "Actually the and parallel training, the more from the implementation point of view.",
                    "label": 0
                },
                {
                    "sent": "You're going faster because you implement it better.",
                    "label": 0
                },
                {
                    "sent": "And those concerns too.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Nesterov acceleration.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the there's some family of methods.",
                    "label": 0
                },
                {
                    "sent": "So question to ask ourselves when we read the paper about this.",
                    "label": 0
                },
                {
                    "sent": "Do they quickly achieve good tests?",
                    "label": 1
                },
                {
                    "sent": "Are also good training yours.",
                    "label": 1
                },
                {
                    "sent": "In most paper, the experiments target the test errors and the theory targets the training error.",
                    "label": 1
                },
                {
                    "sent": "Doesn't mean that the proposed method is bad or useless.",
                    "label": 0
                },
                {
                    "sent": "Doesn't mean that they're dishonest, because very often they said.",
                    "label": 1
                },
                {
                    "sent": "You just mean that the theoretical argument is repeated over salt.",
                    "label": 0
                },
                {
                    "sent": "And the first version was my PhD advisor and she had an informal theorem that I always remember Fogelman's theorem.",
                    "label": 0
                },
                {
                    "sent": "Unfortunate Theorem is that.",
                    "label": 0
                },
                {
                    "sent": "That was back proper then, but she meant great on this central stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "You can always make stochastic gradient descent and backdrop slower.",
                    "label": 0
                },
                {
                    "sent": "That means that all these papers will perform very well compared to the implementation or the one they chose of stochastic gradient descent because it can always be slower.",
                    "label": 0
                },
                {
                    "sent": "But it's very mean to say that, but is it true?",
                    "label": 0
                },
                {
                    "sent": "So you think about the neural network.",
                    "label": 0
                },
                {
                    "sent": "There are plenty of ways where you can slightly this adjust the the the weights, initialize and make it.",
                    "label": 0
                },
                {
                    "sent": "Twice slower, three times slower.",
                    "label": 0
                },
                {
                    "sent": "Just just like that with nothing.",
                    "label": 0
                },
                {
                    "sent": "If you look at the papers that restarted the stochastic gradient list, one of the paper is the Pegasus Paper.",
                    "label": 0
                },
                {
                    "sent": "Nice algorithm and it analysis.",
                    "label": 0
                },
                {
                    "sent": "So this is good paper.",
                    "label": 0
                },
                {
                    "sent": "But what they do is that the advocate, the projection technique and the projection technique essentially does that when the learning rate is too high, so they quizlet 1 / T so it's very high at the beginning.",
                    "label": 0
                },
                {
                    "sent": "But when learning that is too high, the projection saves you.",
                    "label": 0
                },
                {
                    "sent": "So basically you're doing nothing until learning that is the right value, and then you're learning.",
                    "label": 0
                },
                {
                    "sent": "So basically if you start with the right learning rate, you go twice faster.",
                    "label": 0
                },
                {
                    "sent": "Right away.",
                    "label": 0
                },
                {
                    "sent": "And well, they are stochastic resonance available to start the right way.",
                    "label": 0
                },
                {
                    "sent": "Mean people could always compare with the one that just this pressure.",
                    "label": 0
                },
                {
                    "sent": "Normal pressure on people you know.",
                    "label": 0
                },
                {
                    "sent": "They find one day that they take a program and OK, it works and they don't work very much on the baseline.",
                    "label": 0
                },
                {
                    "sent": "They work on their algorithm.",
                    "label": 0
                },
                {
                    "sent": "So, so you always have to be a little bit careful about these things to say it's OK.",
                    "label": 0
                },
                {
                    "sent": "They say that they're not stupid.",
                    "label": 0
                },
                {
                    "sent": "The analysis is interesting.",
                    "label": 0
                },
                {
                    "sent": "The idea is good, but the experiments be careful.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's go with certain other tricks.",
                    "label": 0
                },
                {
                    "sent": "Rescaling the gradient with suitable approximation of the Hessian, but you have to use a positive approximation of metrics.",
                    "label": 1
                },
                {
                    "sent": "Natural gradient goes to some tricks.",
                    "label": 0
                },
                {
                    "sent": "They're pretty much the same.",
                    "label": 0
                },
                {
                    "sent": "But the problem that you have in stochastic gradient when you do that is that you have to multiply the gradient biometrics or by an approximation of the metrics.",
                    "label": 0
                },
                {
                    "sent": "At each direction.",
                    "label": 0
                },
                {
                    "sent": "A billion times.",
                    "label": 0
                },
                {
                    "sent": "If you have a billion training examples instead of just one at the end of a billion.",
                    "label": 0
                },
                {
                    "sent": "So the cost of Newton.",
                    "label": 0
                },
                {
                    "sent": "For stochastic gradient can be very high unless you use mini batches.",
                    "label": 1
                },
                {
                    "sent": "Unimportant cases dragon it's killing, so dragon is killing is the same as using a different learning rate per weight per unit per layer.",
                    "label": 1
                },
                {
                    "sent": "We discussed that already.",
                    "label": 0
                },
                {
                    "sent": "The best technique is periodic adjustment of the learning rates by looking at average Guardian average weighted.",
                    "label": 0
                },
                {
                    "sent": "I made my my points yesterday.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Momentum acceleration.",
                    "label": 0
                },
                {
                    "sent": "While there is easy assets give out nice paper, comparing them and reformulating nestier frustration in a way that resembles momentum.",
                    "label": 0
                },
                {
                    "sent": "The reason why it works?",
                    "label": 0
                },
                {
                    "sent": "It's actually very subtle, and it comes back to analysis by Nesterov that you can see in this book about elementary lessons about convex optimization.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "I can explain this in 2 words.",
                    "label": 0
                },
                {
                    "sent": "So basically the book is trying to show bounce.",
                    "label": 0
                },
                {
                    "sent": "Theoretical bounds in the optimization.",
                    "label": 0
                },
                {
                    "sent": "Of function of a certain family so they look for instance at the class of functions that are convex and smooth.",
                    "label": 0
                },
                {
                    "sent": "And they show lower bound, saying that you cannot optimal fine optimization algorithm that has a guarantee that's better than 1 / T square where T square is the number of teams, enough iterations of the complexity essentially.",
                    "label": 0
                },
                {
                    "sent": "And they do that by showing by constructing functions.",
                    "label": 0
                },
                {
                    "sent": "That resist, so if you run your algorithm, you have, uh, algorithm queries, an Oracle that gives for algorithms as the right to propose a point, and the Oracle gives value for function and the gradient.",
                    "label": 0
                },
                {
                    "sent": "That's called the 1st order Oracle.",
                    "label": 0
                },
                {
                    "sent": "And you invent the quite a crazy Oracle.",
                    "label": 0
                },
                {
                    "sent": "That's going to keep the list of all functions that are compatible with all the previous answers.",
                    "label": 0
                },
                {
                    "sent": "An edge at this time you're going to get the worst one.",
                    "label": 0
                },
                {
                    "sent": "That's called the resisting Oracle, and by doing this you exhibit a function that's maximally resisting, and you can show that there is no way you can optimize.",
                    "label": 0
                },
                {
                    "sent": "Do these processing less than one over the square.",
                    "label": 0
                },
                {
                    "sent": "And therefore you can say that if you have an algorithm that guarantees that you're going to get an accuracy epsilon.",
                    "label": 0
                },
                {
                    "sent": "Then there is a function on which this algorithm has to make more than one over epsilon square root of epsilon steps.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at the the gradient descent, the normal gradient descent.",
                    "label": 0
                },
                {
                    "sent": "On this is not one of the squares 1 / T slower.",
                    "label": 0
                },
                {
                    "sent": "And so next year I've tried to play with it and invented this idea of using the last two gradients in a kind of strange way.",
                    "label": 0
                },
                {
                    "sent": "And when you do that, you get the one over the square.",
                    "label": 0
                },
                {
                    "sent": "So this is the optimal algorithm up to constants.",
                    "label": 0
                },
                {
                    "sent": "And you also have a theory that comes from numerous key showing that conjugate gradient is not minimax optimal, so therefore conjugate gradient.",
                    "label": 0
                },
                {
                    "sent": "There are functions that are going to lead you astray even though it's going to work well in on average.",
                    "label": 0
                },
                {
                    "sent": "So so you can discuss so.",
                    "label": 0
                },
                {
                    "sent": "So that was something very surprising for people in optimization that you can actually define an algorithm and show that it has some optimality properties that cannot be beaten.",
                    "label": 0
                },
                {
                    "sent": "And of course well, you can use momentum and try to do that in our network, except that it stochastic and it's going to be a big mess to make it work properly.",
                    "label": 0
                },
                {
                    "sent": "So OK fine.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "The nested off also stochastic gram decent people tried to extend the idea of acceleration to stochastic with some result.",
                    "label": 0
                },
                {
                    "sent": "The Nesterov is for total for gradient algorithm.",
                    "label": 0
                },
                {
                    "sent": "The nasty of paper.",
                    "label": 0
                },
                {
                    "sent": "Now you can use the same techniques for stochastic gradient, but the bounds are not the same, and in particular where for batch gradient you would change the order of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "For stochastic think basically you don't see the whole training set.",
                    "label": 0
                },
                {
                    "sent": "You cannot better than over T anyway, so it's not good if you wanna party square.",
                    "label": 0
                },
                {
                    "sent": "What's happening that the constant that's on top, which is typically for stochastic gradient is Kappa.",
                    "label": 0
                },
                {
                    "sent": "Square Kappa is the condition number of vision goes down to Kappa.",
                    "label": 0
                },
                {
                    "sent": "So we're changing the constant, so for real condition problem is going to work quite well.",
                    "label": 0
                },
                {
                    "sent": "So that means that when you use momentum, it's a kind of way of.",
                    "label": 0
                },
                {
                    "sent": "Taking some advantage of signature properties in a way that's economical.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't have to be diagonal aligned.",
                    "label": 0
                },
                {
                    "sent": "So if you do, let's say one word per weight, which is a second order matrix that diagonally aligned well if you cost function is is not aligned with the axis, or it's not going to work that well, well, momentum can work.",
                    "label": 0
                },
                {
                    "sent": "Not as well as doing the real 2nd order, but it can work in accelerating that set up.",
                    "label": 0
                },
                {
                    "sent": "So This is why often people combine both.",
                    "label": 0
                },
                {
                    "sent": "Now the adjusting the momentum parameter is quite hard.",
                    "label": 0
                },
                {
                    "sent": "Hard to do because in principle you need to adjust it according to the properties of the Hessian, which you don't know in advance.",
                    "label": 0
                },
                {
                    "sent": "So you're going to have to do trial and errors, and sometimes the trial in euros can cost you more than not doing it.",
                    "label": 0
                },
                {
                    "sent": "So many batches actually go to you.",
                    "label": 0
                },
                {
                    "sent": "If you stochastic gradient use a noisy gradient based on a single example.",
                    "label": 1
                },
                {
                    "sent": "If you use a mini batch Locust gradient, we use a noisy gradient based on a small batch of examples.",
                    "label": 0
                },
                {
                    "sent": "If you think about it.",
                    "label": 0
                },
                {
                    "sent": "That means that the standard deviation of the noise is going to be or let's say, the variance of the noise is going to be divided by the size of the batch of example.",
                    "label": 0
                },
                {
                    "sent": "But turns out that when you do the stochastic gradient in the in the constant, you have a term that happens to be the variance of the noise.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You're going to reduce the variance of the noise.",
                    "label": 0
                },
                {
                    "sent": "At the expense of step that are 10 times more expensive, so mathematically, as long as the mini batch is small enough that you're not going to the actual batch, it doesn't do anything.",
                    "label": 0
                },
                {
                    "sent": "But practically, it's not true at all, because mini batches are well suited to modern hardware and they also provide an opportunity to use in order info.",
                    "label": 1
                },
                {
                    "sent": "So the first one.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is what we were told you that if you take the linear brick, for instance, forward is WX backward GW or Jezero vector gradient is just the dot product.",
                    "label": 0
                },
                {
                    "sent": "But if you have multiple examples sometimes so these are matrix vector matrix vectors, outer product.",
                    "label": 0
                },
                {
                    "sent": "If you have multiple examples, X become a vector.",
                    "label": 0
                },
                {
                    "sent": "Sorry, XP, metrics.",
                    "label": 0
                },
                {
                    "sent": "It was a vector.",
                    "label": 0
                },
                {
                    "sent": "Here it becomes a matrix, the gradients becomes a matrix instead of the rector.",
                    "label": 0
                },
                {
                    "sent": "All these things become matrix matrix product and there is something that you can see in the literature literature about glass even as a single CPU using matrix matrix is much faster than a lot of metrics vectors because you can optimize the placement of things in the cache.",
                    "label": 0
                },
                {
                    "sent": "Typically you can expect a factor of 10 easily with these kind of things.",
                    "label": 0
                },
                {
                    "sent": "Now if you use GPU's, that's even worse.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The trick.",
                    "label": 0
                },
                {
                    "sent": "Which tricks momentum?",
                    "label": 0
                },
                {
                    "sent": "They all use convexity because this only thing we can only know how to prove.",
                    "label": 0
                },
                {
                    "sent": "If you close to an attraction bussing close to the end, you can say, OK, Aquatic approximation holds and sort of sort of convex locali.",
                    "label": 0
                },
                {
                    "sent": "But in terms of how you're going to traverse the landscape of critical points and everything.",
                    "label": 0
                },
                {
                    "sent": "No ID.",
                    "label": 0
                },
                {
                    "sent": "Actually, actually.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "I don't think it's the right recipe.",
                    "label": 0
                },
                {
                    "sent": "There is a old paper by people were using statistical physics methods, so there is a simple ski saving paper where it shows that in the case of multiyear network and assuming you actually learn the function, that's another network that's unknown with the same geometry.",
                    "label": 0
                },
                {
                    "sent": "So you can look at the overlaps between the values, units and everything, so you can do statistical physics.",
                    "label": 0
                },
                {
                    "sent": "The good strategy is to keep the learning rate constant and high at some moment.",
                    "label": 0
                },
                {
                    "sent": "And at some point you lower it, you start lowering it, and that's very consistent with the ID of.",
                    "label": 0
                },
                {
                    "sent": "Let's take a validation set.",
                    "label": 0
                },
                {
                    "sent": "Constant learning rate.",
                    "label": 0
                },
                {
                    "sent": "Go until things stop optimizing the validation set, and they're not going to go, and they're just going to stop.",
                    "label": 0
                },
                {
                    "sent": "They going to start being unstable.",
                    "label": 0
                },
                {
                    "sent": "Then you are a little bit and you go down a little bit, and that's the kind of following you kind of fashion structure that they exhibit in this paper.",
                    "label": 0
                },
                {
                    "sent": "So the idea of statistical physics approximation to understand the structure of the non convex function as usual spoke about it.",
                    "label": 0
                },
                {
                    "sent": "It's coming back, but it's leverage is very strong assumption that are far from real.",
                    "label": 0
                },
                {
                    "sent": "But in practice it sort of works well.",
                    "label": 0
                },
                {
                    "sent": "So in practice, this is what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "Typically start, let it let it cook for certain time.",
                    "label": 0
                },
                {
                    "sent": "When the validation error stabilizes, athletic little bit more, typically it doesn't go up that quickly, and then I divide the learning rate by some value and I do it again.",
                    "label": 0
                },
                {
                    "sent": "I know you go stole two and I sometimes 10 you know doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So, but this is not something of that kind.",
                    "label": 0
                },
                {
                    "sent": "This is a computational optimization.",
                    "label": 0
                },
                {
                    "sent": "This is something in pretty much at the hardware level at the implementation level, but it's also a constant when you do something like this, you competing with equal arms on equal basis with improvements of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So now it's a very difficult problem to decide where to put your brain cycles.",
                    "label": 0
                },
                {
                    "sent": "Are you going to put your brain cycles in working in a nice GPU implementation on working in a nice optimization method?",
                    "label": 0
                },
                {
                    "sent": "It's not obvious at all.",
                    "label": 0
                },
                {
                    "sent": "So the second thing?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that mini batches provide an opportunity to use some other information?",
                    "label": 1
                },
                {
                    "sent": "Certain information you're going to use a kind of estimate of the Hessian matrix that you can estimate on the fly here, and I'm going to describe that a little bit later.",
                    "label": 0
                },
                {
                    "sent": "At least one instance of that.",
                    "label": 0
                },
                {
                    "sent": "And you want to multiply every gradient with that matrix.",
                    "label": 0
                },
                {
                    "sent": "So even if it's low rank matrix is going to be costly.",
                    "label": 0
                },
                {
                    "sent": "So if you do it one per example.",
                    "label": 0
                },
                {
                    "sent": "That's very costly, so if you eat once every 1000 examples, well, OK, you amortized it.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have a rank K approximation of duration metrics, so it's going to cost you about K times more than K + 1 times more than a matrix vector product.",
                    "label": 0
                },
                {
                    "sent": "Well, if you do it for every example you are going this right from the bat.",
                    "label": 0
                },
                {
                    "sent": "Cave times slower.",
                    "label": 0
                },
                {
                    "sent": "And you better win the fact OK as well.",
                    "label": 0
                },
                {
                    "sent": "If you do it every 1000 examples, well, it's going to be 1000 + K. In this case, let's say 10 or 50 you find.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then there is something that I've seen done.",
                    "label": 0
                },
                {
                    "sent": "It just gives me the creeps.",
                    "label": 0
                },
                {
                    "sent": "Excessive LB of GS.",
                    "label": 0
                },
                {
                    "sent": "40 = 1 two three pick examples for the mini batch T. Initialize net with the previous weights.",
                    "label": 1
                },
                {
                    "sent": "Optimize with albc and get another one.",
                    "label": 0
                },
                {
                    "sent": "And repeat.",
                    "label": 0
                },
                {
                    "sent": "I've seen people do that with some success.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Gives you the creeps because this doesn't work at all for convex model.",
                    "label": 0
                },
                {
                    "sent": "In the convex model you have one optimum.",
                    "label": 0
                },
                {
                    "sent": "So every call to LGS is going to give you the optimum for that mini batch.",
                    "label": 0
                },
                {
                    "sent": "So the last value you have is the optimum for the last mini batch for the last set of examples.",
                    "label": 0
                },
                {
                    "sent": "Like you ignored all the previous examples.",
                    "label": 0
                },
                {
                    "sent": "You know, and that is not like that.",
                    "label": 0
                },
                {
                    "sent": "There are so many points where you can stop on.",
                    "label": 0
                },
                {
                    "sent": "There's so many local minima and everything that when you do this, you somehow prime the process in some areas and then it works better still gives me the creeps.",
                    "label": 0
                },
                {
                    "sent": "Yeah, pretty much.",
                    "label": 0
                },
                {
                    "sent": "And that works too, which is very very strange.",
                    "label": 0
                },
                {
                    "sent": "That tells you how little we understand what's happening in there.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are things like Martin's vision field training, which is a kind of nickname for his particular version of using second order information.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to try to describe it in a very simple way, knowing that you have to be careful because you need a lot of refinements to make this work well.",
                    "label": 1
                },
                {
                    "sent": "You take a lot of mini batches and you.",
                    "label": 0
                },
                {
                    "sent": "Take a mini batch that is going to be special.",
                    "label": 0
                },
                {
                    "sent": "All the curvature information is going to be on that mini batch and the reason for doing this is that if you estimate parts of the cavity on different mini batches could be different.",
                    "label": 0
                },
                {
                    "sent": "Going to mix up things.",
                    "label": 1
                },
                {
                    "sent": "So now you pick examples for for all T123 you pick examples for humidity.",
                    "label": 0
                },
                {
                    "sent": "You compute the gradient on the mini batch T so far is very close to the meaning of gradient.",
                    "label": 0
                },
                {
                    "sent": "But instead of doing a gradient step, you're going to minimize D, transpose HD Lambda squared plus GTD by country gradient, where HD.",
                    "label": 1
                },
                {
                    "sent": "Is evaluated directly using red and measured in mini Batch 0, so that means that here you have an estimate of the curvature.",
                    "label": 0
                },
                {
                    "sent": "Or mini batch 0.",
                    "label": 0
                },
                {
                    "sent": "So that gives you the form of a power below it, but on mini Batch 0.",
                    "label": 0
                },
                {
                    "sent": "And use a fast way to compute the Hessian vector product that you can do in our network.",
                    "label": 0
                },
                {
                    "sent": "Here you have a kind of regularization because this is not always worked out well.",
                    "label": 0
                },
                {
                    "sent": "And there you have the gradient on your current mini batch.",
                    "label": 0
                },
                {
                    "sent": "So that means that you basically trying to correct if you just do this optimization here and then compute the revertive respect to D in that stuff.",
                    "label": 0
                },
                {
                    "sent": "You're going to basically correct.",
                    "label": 0
                },
                {
                    "sent": "The gradient on the mini batch using Asian estimated on the mini Batch 0.",
                    "label": 0
                },
                {
                    "sent": "If you take the Devils disrespect to D. You're going to have HD plus of two HD, +2 Lambda D plus GT equals 0.",
                    "label": 0
                },
                {
                    "sent": "So basically the D is going to be GT minus GT times.",
                    "label": 0
                },
                {
                    "sent": "Edge plus Lambda identity to the minus one.",
                    "label": 0
                },
                {
                    "sent": "So basically you're doing kind of a Newton here, except that the curvature is estimated on the 1st mini batch.",
                    "label": 0
                },
                {
                    "sent": "That's a way to avoid some noise in the process, and then you do the update dirty piece one is RWT plus D and you do it again.",
                    "label": 0
                },
                {
                    "sent": "So of course there is a cost in doing this, but it better be amortized on mini batches and if you play everything right it works, it works.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Or can you repeat the question?",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "The selection to optimize the mini batch.",
                    "label": 0
                },
                {
                    "sent": "The mini batch size you mean?",
                    "label": 0
                },
                {
                    "sent": "Information.",
                    "label": 0
                },
                {
                    "sent": "OK, in all I describe, I assume that picked randomly.",
                    "label": 0
                },
                {
                    "sent": "There are some people who are trying to carve smart mini batches.",
                    "label": 0
                },
                {
                    "sent": "But that's all another completely different story.",
                    "label": 0
                },
                {
                    "sent": "And I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not ready to talk about this at this moment.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pilot training.",
                    "label": 0
                },
                {
                    "sent": "Nuclear we know yet.",
                    "label": 0
                },
                {
                    "sent": "The best line is lock free stochastic gradient as you shared memory, each process to access the way through the shared memory.",
                    "label": 1
                },
                {
                    "sent": "Each processor runs at GD and different examples read and write to the weight memory are in synchronized.",
                    "label": 1
                },
                {
                    "sent": "Synchronization issues are just another kind of noise and this is a very strong contender.",
                    "label": 0
                },
                {
                    "sent": "And I think you should ask to do that long ago the the Google guys are famous for doing this on big clusters using distributed shared memory and this dissent.",
                    "label": 0
                },
                {
                    "sent": "It's actually a strong contender.",
                    "label": 0
                },
                {
                    "sent": "People do that in GPU sometimes, except that it's very difficult to do that properly on GPS.",
                    "label": 0
                },
                {
                    "sent": "Bottom OK, this so far.",
                    "label": 0
                },
                {
                    "sent": "As to my knowledge, none of those sophisticated methods.",
                    "label": 0
                },
                {
                    "sent": "The tech a pretty fine neural network.",
                    "label": 0
                },
                {
                    "sent": "Tim, is it?",
                    "label": 0
                },
                {
                    "sent": "Go much faster than that.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The synchronous here.",
                    "label": 0
                },
                {
                    "sent": "I say.",
                    "label": 0
                },
                {
                    "sent": "Read and write to wait memory are in synchronized.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, you you tend to hit the weights a lot, so there are proofs about this.",
                    "label": 0
                },
                {
                    "sent": "There's a hog wild proof in the case where you have a very sparse updates.",
                    "label": 0
                },
                {
                    "sent": "But it also works when they're not sparse.",
                    "label": 0
                },
                {
                    "sent": "It's also works in CNN's but.",
                    "label": 0
                },
                {
                    "sent": "Just another kind of noise.",
                    "label": 0
                },
                {
                    "sent": "Now for the last half hour, I'm going to look at trying to use deep networks for complex tasks.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So so to say that, more bluntly, if you look at the Google Paper that did that on a cluster, which is a very sophisticated engineering fact.",
                    "label": 0
                },
                {
                    "sent": "In the corner you see that basically they use something like 10,000 computers or 1000 and forgot the exact number.",
                    "label": 0
                },
                {
                    "sent": "But if you work the number you realize that the speedup is something like 10.",
                    "label": 0
                },
                {
                    "sent": "So that's quite costly.",
                    "label": 0
                },
                {
                    "sent": "You need to have a lot of computers.",
                    "label": 0
                },
                {
                    "sent": "Maybe it makes sense if you have a lot of computers.",
                    "label": 0
                },
                {
                    "sent": "I don't know exactly.",
                    "label": 0
                },
                {
                    "sent": "They are the economy, color range, but they certainly made progress in between.",
                    "label": 0
                },
                {
                    "sent": "But this is not obvious at all to do on a large number of processors.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Resilient back propagation.",
                    "label": 0
                },
                {
                    "sent": "Which one is that?",
                    "label": 0
                },
                {
                    "sent": "Increase.",
                    "label": 0
                },
                {
                    "sent": "What you mean by go down the cost function you mean, Oh yes, yes yes you you every so often you estimate the cost function on the whole set and you see if it's going down or up because you cannot do that every direction, correct?",
                    "label": 0
                },
                {
                    "sent": "It's normally used in a match set.",
                    "label": 0
                },
                {
                    "sent": "Well, the first part of what you describe is taking just the direction of the graduate notice size.",
                    "label": 0
                },
                {
                    "sent": "And if you look about it is pretty consistent with what I say that we want an update that has a size that consistent with the size of the weights.",
                    "label": 0
                },
                {
                    "sent": "So you ignore the length of the gradient, and you're going to each time say I'm have a direction.",
                    "label": 0
                },
                {
                    "sent": "I'm going to go 110th of the length of my weights in that direction.",
                    "label": 0
                },
                {
                    "sent": "That's consistent with this idea.",
                    "label": 0
                },
                {
                    "sent": "Now things can be bizarre if you do this on different layers because you when you re scale differently in different layers.",
                    "label": 0
                },
                {
                    "sent": "You also change the rotation.",
                    "label": 0
                },
                {
                    "sent": "This is what I notice then the heuristic to adapt the running rate.",
                    "label": 0
                },
                {
                    "sent": "While it's not unreasonable.",
                    "label": 0
                },
                {
                    "sent": "You could try yeah, sure, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, this is.",
                    "label": 0
                },
                {
                    "sent": "This has been tried in various ways.",
                    "label": 0
                },
                {
                    "sent": "He's been tried most successfully in this VMS because SVM is a quality cost.",
                    "label": 0
                },
                {
                    "sent": "Taklon but you can test the SVM in linear cost essentially.",
                    "label": 0
                },
                {
                    "sent": "So basically selecting examples that are informative is not too costly in a normal network to select examples.",
                    "label": 0
                },
                {
                    "sent": "If you run the full neural network is going to be pretty much the same cost as doing the backdrop.",
                    "label": 0
                },
                {
                    "sent": "So there are two routes there.",
                    "label": 0
                },
                {
                    "sent": "One is to select examples using another network smaller.",
                    "label": 0
                },
                {
                    "sent": "But then you have to make sure that the smaller network does something.",
                    "label": 0
                },
                {
                    "sent": "That's going to help you find examples are informative for the large network which is supposedly Sparta is not obvious.",
                    "label": 0
                },
                {
                    "sent": "Another approach is to use this as a parallel implementation method so you have a bunch of machines.",
                    "label": 0
                },
                {
                    "sent": "They all have a copy of the network and they going to sift through the example to find one that is a strong gradient, and when they find one they send that to the central machine with going to learn that one update the weights and redistribute.",
                    "label": 0
                },
                {
                    "sent": "This is hard to get to work right.",
                    "label": 0
                },
                {
                    "sent": "So I know that we tried with Alec Agarwal for a long time to get these things to work and it really depends on a lot of details on the optimization so we could get the paper and show that it works, but I wouldn't guarantee that it's going to work for everybody.",
                    "label": 0
                },
                {
                    "sent": "So you see what I mean?",
                    "label": 0
                },
                {
                    "sent": "So so you could write slightly this on this paper that looks impressive that way, but it's not clear that that would work very well for in a robust manner.",
                    "label": 0
                },
                {
                    "sent": "So I go back to the last part complex task.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I go back to how to design computers that at the beginning of my lecture.",
                    "label": 1
                },
                {
                    "sent": "And our computers, all the ones that we have to emulate, mathematical logic becausw in mathematical logic.",
                    "label": 1
                },
                {
                    "sent": "There is a very well known procedure to reduce complex tasks to combination of simple tasks.",
                    "label": 0
                },
                {
                    "sent": "That's called programming.",
                    "label": 0
                },
                {
                    "sent": "If a complicated task, you divide it in simple tasks and you program each simple task in some way recursively.",
                    "label": 0
                },
                {
                    "sent": "That's very good for plenty of reasons.",
                    "label": 0
                },
                {
                    "sent": "One of them is that you can cope collaborate with people you know.",
                    "label": 0
                },
                {
                    "sent": "You say OK, now speak my task in this particular element, you're going to do that one.",
                    "label": 0
                },
                {
                    "sent": "You're going to do that one.",
                    "label": 0
                },
                {
                    "sent": "You're going to do that one, and as long as you do the task correctly.",
                    "label": 0
                },
                {
                    "sent": "And my.",
                    "label": 0
                },
                {
                    "sent": "Splitting of the problem is correct.",
                    "label": 0
                },
                {
                    "sent": "I'm going to have the correct solution and we don't know how to do that very well in machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're using complex task to combination of simple task is an engineering necessity.",
                    "label": 1
                },
                {
                    "sent": "If you do engineering you need to do that.",
                    "label": 0
                },
                {
                    "sent": "And simple running tasks.",
                    "label": 0
                },
                {
                    "sent": "You have classification, regression, clustering, multi arm bandits and many other 8 pages papers.",
                    "label": 1
                },
                {
                    "sent": "Complex learning tax.",
                    "label": 1
                },
                {
                    "sent": "Reading checks.",
                    "label": 1
                },
                {
                    "sent": "When you need to deal with segmentation, recognition, interpretation of the letters until you get an amount and you know what to do with it.",
                    "label": 0
                },
                {
                    "sent": "Passing visual scene, finding objects, finding their relations and doing something useful with them.",
                    "label": 0
                },
                {
                    "sent": "Composing personalized web pages, which is dealing with feedback because if you personalize a web page for somebody, well, he's going to see something different so the clicks and the interaction of the user with the web page will be different and you change your training data and you can have a cycle of things.",
                    "label": 1
                },
                {
                    "sent": "But natural language understanding, which is even hard to define by itself or strong AI, we can dream.",
                    "label": 0
                },
                {
                    "sent": "This is a complex task.",
                    "label": 0
                },
                {
                    "sent": "We have no way.",
                    "label": 0
                },
                {
                    "sent": "To reduce such complex task to a succession of simple learning tasks, because we have no way to say the simplest axis is done strictly.",
                    "label": 0
                },
                {
                    "sent": "When you reduce a complex tasks into simple tasks, this is true under the assumption that the simple task is done correctly 100% of the time, yes.",
                    "label": 0
                },
                {
                    "sent": "But in the work and reduction algorithm Lankford, there's a huge effort to try to keep the balance and everything together, but he has a certain nice little setup, but it is still playing in this game at this level.",
                    "label": 0
                },
                {
                    "sent": "Many match pretty much.",
                    "label": 0
                },
                {
                    "sent": "And every time there is a reduction, there is a little loss somewhere.",
                    "label": 0
                },
                {
                    "sent": "So it's actually quite hard to do, like if you think about programming computer.",
                    "label": 0
                },
                {
                    "sent": "It's provocative, but programming is for the average mind.",
                    "label": 0
                },
                {
                    "sent": "It's not that hard.",
                    "label": 0
                },
                {
                    "sent": "Lots of people can program something that sort of work, market, other bugs.",
                    "label": 0
                },
                {
                    "sent": "There are lots of bugs, sure, but because lots of people can do it, that means that you can have an industry and you have computer science and industry.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                },
                {
                    "sent": "You want to do that with John Langford Productions?",
                    "label": 0
                },
                {
                    "sent": "Well, you need a lot of junk foods.",
                    "label": 0
                },
                {
                    "sent": "But there are a couple of people who can do it better.",
                    "label": 0
                },
                {
                    "sent": "I don't know age on Hall.",
                    "label": 0
                },
                {
                    "sent": "No, I'm exaggerating.",
                    "label": 0
                },
                {
                    "sent": "Of course a little bit.",
                    "label": 0
                },
                {
                    "sent": "This is very smart.",
                    "label": 0
                },
                {
                    "sent": "This is the right direction.",
                    "label": 0
                },
                {
                    "sent": "But this is not something that I'm unable to an industry as of now.",
                    "label": 0
                },
                {
                    "sent": "And he's making good progress.",
                    "label": 0
                },
                {
                    "sent": "You know that might work in the end, but right now it's not there yet.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a lot of machine learning is about Bayesian inference.",
                    "label": 1
                },
                {
                    "sent": "It's a bit a couple years ago.",
                    "label": 0
                },
                {
                    "sent": "Bayesian inference was.",
                    "label": 1
                },
                {
                    "sent": "40% of lips there is a strong appeal to Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "Now it's reduced little bit because deep learning took a lot of Bayesian inference and some nasty people say that now they reduced to try to learn the hyperparameters, but but it's true that Bayesian inference is very attractive, and if you have the computing time, it can give very good solutions.",
                    "label": 1
                },
                {
                    "sent": "But the appeal of Bayesian inference is not really that.",
                    "label": 1
                },
                {
                    "sent": "You get better solution that your first language.",
                    "label": 0
                },
                {
                    "sent": "You have a language with Escrib complex model with similar ones and you have generic algorithms.",
                    "label": 0
                },
                {
                    "sent": "Of course if you build.",
                    "label": 0
                },
                {
                    "sent": "A complex model with simple ones.",
                    "label": 0
                },
                {
                    "sent": "The generic algorithm, often intractable and they have to resort to nasty approximations and everything.",
                    "label": 0
                },
                {
                    "sent": "But it's still a language that's completely absent.",
                    "label": 0
                },
                {
                    "sent": "In the traditional machine learning, if you deal with SVM, there is no such language.",
                    "label": 0
                },
                {
                    "sent": "If you deal with deep learning, there is not much of it.",
                    "label": 0
                },
                {
                    "sent": "And also it's an important question to try to find this language, because otherwise we won't be able to progress.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at St.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our problems.",
                    "label": 0
                },
                {
                    "sent": "Let's go back to one of my pet example with in check amounts.",
                    "label": 1
                },
                {
                    "sent": "The input is a scan check image.",
                    "label": 1
                },
                {
                    "sent": "The output is a positive real number.",
                    "label": 0
                },
                {
                    "sent": "The amount 3 to 45.",
                    "label": 0
                },
                {
                    "sent": "The direct approach is to collect examples.",
                    "label": 1
                },
                {
                    "sent": "Images A month.",
                    "label": 0
                },
                {
                    "sent": "Images amount trend from scratch with the big CNN's.",
                    "label": 0
                },
                {
                    "sent": "Tough luck.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's possible because we didn't really try now, maybe with GPU's and everything or clusters GPU's you can do something like this, but you need a lot of examples because that machine will have to find that this is the amount.",
                    "label": 0
                },
                {
                    "sent": "Understand how to pass the characters and transform this into real.",
                    "label": 0
                },
                {
                    "sent": "Eliminate this task not read this, not read that.",
                    "label": 0
                },
                {
                    "sent": "It's not going to be so easy.",
                    "label": 0
                },
                {
                    "sent": "So you split the problem.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You're going to say, well, I'm doing engineering, so I know that I need to look at the amount field.",
                    "label": 0
                },
                {
                    "sent": "Then I need to segment the amount field into isolated characters.",
                    "label": 1
                },
                {
                    "sent": "I need to recognize the other characters and translate the character string into an amount.",
                    "label": 0
                },
                {
                    "sent": "So we can define the model for each sub task.",
                    "label": 0
                },
                {
                    "sent": "Which are fairly complex recognition model like CNN's and engineer location and segmentation models to find the fields and segment them.",
                    "label": 1
                },
                {
                    "sent": "You collect data and trends so you collect data for each sub task.",
                    "label": 0
                },
                {
                    "sent": "You train each subtask separately, and you put them together.",
                    "label": 0
                },
                {
                    "sent": "This sort of works.",
                    "label": 0
                },
                {
                    "sent": "But you can do much better.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have interactions.",
                    "label": 0
                },
                {
                    "sent": "You look at the amount field, but you can make mistakes here.",
                    "label": 0
                },
                {
                    "sent": "If you make slight mistakes, you can segment the amount feeling too isolated characters, but you know a bad amount field is one you cannot segment very well and a bad segmentation is something you cannot recognize very well.",
                    "label": 0
                },
                {
                    "sent": "So in principle, whenever you go to the next level well, you say if I cannot really see all the characters.",
                    "label": 0
                },
                {
                    "sent": "Maybe my segmentation was wrong and I don't have another expensive segmentation.",
                    "label": 0
                },
                {
                    "sent": "Maybe my amount field was wrong.",
                    "label": 0
                },
                {
                    "sent": "So you want to interact.",
                    "label": 0
                },
                {
                    "sent": "Every level and at this moment what we did, this trend is transistor and this trend is just put them in sequence.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I describe independent training.",
                    "label": 1
                },
                {
                    "sent": "You train each submodel separately.",
                    "label": 1
                },
                {
                    "sent": "Fine, you can do sequential training with which one with independent training.",
                    "label": 1
                },
                {
                    "sent": "Then we labeled output of sub model N. So you and you transfer Model N + 1 with that.",
                    "label": 0
                },
                {
                    "sent": "So you trend the location field and then you label that with proper segments.",
                    "label": 0
                },
                {
                    "sent": "And and then you turn the segments and you label the segments the various segments you get with proper characters and what's the reason why is going to help?",
                    "label": 0
                },
                {
                    "sent": "It's big cause if you segment or for instance like the thing that segments are fit into characters is not very good.",
                    "label": 0
                },
                {
                    "sent": "Let's say he cut the top of the Five 5.",
                    "label": 0
                },
                {
                    "sent": "And the bar is always cut because of some flow in the segmenter.",
                    "label": 0
                },
                {
                    "sent": "But if you label them right, the next thing which is the recognizer can learn to recognize the five, even if the top is missing.",
                    "label": 0
                },
                {
                    "sent": "So that's going to work better.",
                    "label": 1
                },
                {
                    "sent": "Now you still have the problem of tracking.",
                    "label": 0
                },
                {
                    "sent": "Multi purpose is backtracking is still there.",
                    "label": 0
                },
                {
                    "sent": "Now the global training is the best you pre train with sequential learning and you train also models together with examples from the whole problem problems.",
                    "label": 1
                },
                {
                    "sent": "So you initialize every little part you put them together.",
                    "label": 0
                },
                {
                    "sent": "And now you see this as a huge multi.",
                    "label": 0
                },
                {
                    "sent": "The huge deep network and you pretend you compute the gradients everywhere you optimize everything.",
                    "label": 0
                },
                {
                    "sent": "That actually works better and we offer evidence that it works better.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem is that when you go in complicated things like check amount, well what you have between the modules are not vectors.",
                    "label": 0
                },
                {
                    "sent": "Is a complex set of possible fields with each labeled with some scores or a complex set of possible segmentations, each level with some score.",
                    "label": 0
                },
                {
                    "sent": "So in a multilayer network you have a layer and layer communicate vectors.",
                    "label": 1
                },
                {
                    "sent": "Well, in what we call the graphs on network, the layer communicates graphs and the graph service clear semantic in each graph of path between the start node in the end node describes a possible alternative with its cost.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me give an example.",
                    "label": 0
                },
                {
                    "sent": "Suppose you want to segment addition of an image containing various characters.",
                    "label": 0
                },
                {
                    "sent": "So you got a segmentation module and what it does it gets it produces one of these graphs and if you look at this graph you will start node here and then down here and every path between the start and the end describes a possible segmentation.",
                    "label": 0
                },
                {
                    "sent": "And every arc there as a cost, which is an estimate of basically actually.",
                    "label": 0
                },
                {
                    "sent": "Maybe every node here, because you are an estimate of how good this split between possible character is.",
                    "label": 0
                },
                {
                    "sent": "And then you go to a character score.",
                    "label": 0
                },
                {
                    "sent": "The character score is going to replace every little image here by your score.",
                    "label": 0
                },
                {
                    "sent": "That tells you whether this is a character.",
                    "label": 0
                },
                {
                    "sent": "So there's this is a three.",
                    "label": 0
                },
                {
                    "sent": "We scored 01.",
                    "label": 0
                },
                {
                    "sent": "This is a four with Core 3.4 high scores.",
                    "label": 0
                },
                {
                    "sent": "In that case means bad thing is inverted.",
                    "label": 0
                },
                {
                    "sent": "Its Youngs convention here.",
                    "label": 0
                },
                {
                    "sent": "I don't know why you want to call them energy and they have to be low while other people called them score and they have to be high then change anything.",
                    "label": 0
                },
                {
                    "sent": "And now if you take a path, you can add this course and you get the score for.",
                    "label": 0
                },
                {
                    "sent": "A path, but this time this core instead of being just being something that depends on the.",
                    "label": 0
                },
                {
                    "sent": "Primary, your segmentation heuristics depends on the recognizer.",
                    "label": 0
                },
                {
                    "sent": "When you have this path, you find the best parts of it are being of the best segmentation.",
                    "label": 0
                },
                {
                    "sent": "OK, now let's trend that.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to come back to this.",
                    "label": 0
                },
                {
                    "sent": "You actually might win that I need to.",
                    "label": 0
                },
                {
                    "sent": "On now I need to to go back to the training objectives for classification.",
                    "label": 0
                },
                {
                    "sent": "You have X, which is an input material check image and why, which is the output classes and amount is a class.",
                    "label": 0
                },
                {
                    "sent": "You have a lot of classes in that case.",
                    "label": 0
                },
                {
                    "sent": "If you do a generative model, you're going to define the model PW of XY is going to some.",
                    "label": 0
                },
                {
                    "sent": "That's going to be an approximate of P of X&Y is going to be normalizing that way, meaning that the sum over all X of P of XY is going to be 1.",
                    "label": 0
                },
                {
                    "sent": "So you modeling each class and you optimize the likelihood.",
                    "label": 1
                },
                {
                    "sent": "If you do discriminative training, we do some you want to try to estimate P of Y given X.",
                    "label": 1
                },
                {
                    "sent": "So you're going to define the function PW of XY.",
                    "label": 0
                },
                {
                    "sent": "Is going to normalize it by doing the sum of RY of PW of XY equal 1.",
                    "label": 1
                },
                {
                    "sent": "We need that for every X the sum of the score is 1.",
                    "label": 1
                },
                {
                    "sent": "And you need to optimize the likelihood.",
                    "label": 0
                },
                {
                    "sent": "And if you look at the difference between the two, the only difference is the normalization.",
                    "label": 0
                },
                {
                    "sent": "This is quite interesting.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you look at probabilistic models in the case of hidden Markov models, you have a generative hidden Markov models.",
                    "label": 1
                },
                {
                    "sent": "B of XY.",
                    "label": 0
                },
                {
                    "sent": "This P of XY with given the weight is the sum of all possible sequences.",
                    "label": 0
                },
                {
                    "sent": "Of levels now level is a path in a graph, so it's going to be a sequence of the product of the probabilities, the emission probabilities, the transition probabilities for breathing from a set to the next, which is pretty much a score on an energy or whatever, and emission probability.",
                    "label": 1
                },
                {
                    "sent": "And because it's constructed with priorities, that ensures normalization.",
                    "label": 0
                },
                {
                    "sent": "The sum over X of these things is going to be 1.",
                    "label": 1
                },
                {
                    "sent": "If you make a discriminant hidden Markov model, you try to have P of Y given XW and if you do the same kind of things.",
                    "label": 0
                },
                {
                    "sent": "The output of this classifier must be normalized to get the proper some to work, and so that you lost function works.",
                    "label": 0
                },
                {
                    "sent": "So you need to have some over St of PST, so this is probability of transitioning from state T -- 1 to set St in the graph.",
                    "label": 0
                },
                {
                    "sent": "Given that you observe XD and given the whites and for this 2721 properly think that the summer Y of this value is 1 unit P of T given S T -- 1 blah blah blah to some over the possible St to be one.",
                    "label": 0
                },
                {
                    "sent": "The output of the local classifier must be normalized, and this is a bad idea.",
                    "label": 1
                },
                {
                    "sent": "Example.",
                    "label": 0
                },
                {
                    "sent": "This was an example.",
                    "label": 0
                },
                {
                    "sent": "I don't remember exactly why.",
                    "label": 0
                },
                {
                    "sent": "Look at this this thing here.",
                    "label": 0
                },
                {
                    "sent": "Here you want a classifier that's going to tell you which digit is that.",
                    "label": 0
                },
                {
                    "sent": "It's not a digit, it's nothing.",
                    "label": 0
                },
                {
                    "sent": "So you normalize it, you prevent the classifier from telling you well, this is not a digit, all those corsello.",
                    "label": 0
                },
                {
                    "sent": "You want this.",
                    "label": 0
                },
                {
                    "sent": "The sum of this being a one or two or three or four or five or nine to be one, while in fact you would like all this cost to be 0 to be most informative.",
                    "label": 0
                },
                {
                    "sent": "So when you do this normalization, your classifier is not able.",
                    "label": 0
                },
                {
                    "sent": "To tell.",
                    "label": 0
                },
                {
                    "sent": "That this is not the proper digit and should be eliminated.",
                    "label": 0
                },
                {
                    "sent": "And that's a big problem that doesn't work that well.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The way we did it in the 90s was to say, OK, probabilities are screwed up.",
                    "label": 1
                },
                {
                    "sent": "We cannot do that.",
                    "label": 1
                },
                {
                    "sent": "Let's just use course or energy the measure, the add and multiply probabilities, but they're not normalized.",
                    "label": 1
                },
                {
                    "sent": "Discover Path is the product of the.",
                    "label": 1
                },
                {
                    "sent": "Of course the score for sub graph is the sum of the past scores and we trend by maximizing the log and you take the score.",
                    "label": 1
                },
                {
                    "sent": "Of, let's say a bath.",
                    "label": 0
                },
                {
                    "sent": "Divide by those sun.",
                    "label": 0
                },
                {
                    "sent": "Of this course of all the path, so we normalize at the very end.",
                    "label": 0
                },
                {
                    "sent": "Turns out that this is a semi CRF.",
                    "label": 0
                },
                {
                    "sent": "Except that instead of being a CRF with linear classifier, overtime is a CRF of topological architecture that looks at least in the check amount at different ways.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how does it translate in our system here?",
                    "label": 0
                },
                {
                    "sent": "So you remember this that I described?",
                    "label": 0
                },
                {
                    "sent": "And here is how it's going to go.",
                    "label": 0
                },
                {
                    "sent": "In fact, have the segmenter is similar.",
                    "label": 0
                },
                {
                    "sent": "You have the segmentation path here.",
                    "label": 0
                },
                {
                    "sent": "You have listed convolutional Nets to try to classify each of the examples.",
                    "label": 0
                },
                {
                    "sent": "Giving this graph here.",
                    "label": 0
                },
                {
                    "sent": "So in this graph that at this low value of values path.",
                    "label": 0
                },
                {
                    "sent": "So for instance this these three here could be a five with core to three, or could be a three with calls U .1 remembering that case law schools are better.",
                    "label": 0
                },
                {
                    "sent": "And once you have this graph here, which I called the interpretation graph, you're going to do two things.",
                    "label": 0
                },
                {
                    "sent": "One is take a little bit to take the best path.",
                    "label": 0
                },
                {
                    "sent": "This is the answer of your system.",
                    "label": 0
                },
                {
                    "sent": "Which in that case happens to be 341, happens to be wrong.",
                    "label": 0
                },
                {
                    "sent": "It took that one.",
                    "label": 0
                },
                {
                    "sent": "And does and you add this course that discovered the answer of your system?",
                    "label": 0
                },
                {
                    "sent": "But then you're going to use the desired answer.",
                    "label": 0
                },
                {
                    "sent": "You have the supervision.",
                    "label": 0
                },
                {
                    "sent": "You know this is 34.",
                    "label": 0
                },
                {
                    "sent": "And say I'm going to select all the paths that are compatible with the desired answer.",
                    "label": 0
                },
                {
                    "sent": "Think of it, Abby.",
                    "label": 0
                },
                {
                    "sent": "And see this is my best answer that's compatible with the truth.",
                    "label": 0
                },
                {
                    "sent": "It has a higher score.",
                    "label": 0
                },
                {
                    "sent": "And if this course I interpreted that mynewsla probabilities, I can just take the difference optimize.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "How do you train it?",
                    "label": 0
                },
                {
                    "sent": "The problem is that the class does not.",
                    "label": 0
                },
                {
                    "sent": "The digit should be trend with examples of miss segmentation.",
                    "label": 0
                },
                {
                    "sent": "Now the example of Mystic Mentation they going to change.",
                    "label": 0
                },
                {
                    "sent": "So in fact this is what you're doing here.",
                    "label": 0
                },
                {
                    "sent": "You authorizing the local classifier to set this is none of the things I know by having all its course slow, or this output slow, or discourse high whatever.",
                    "label": 0
                },
                {
                    "sent": "Or is energy is high, or discourse low and give fine.",
                    "label": 0
                },
                {
                    "sent": "And you're going to trend the classifier to do that within the whole structure.",
                    "label": 0
                },
                {
                    "sent": "To do that exactly when this is needed.",
                    "label": 0
                },
                {
                    "sent": "Now what are described here?",
                    "label": 0
                },
                {
                    "sent": "I see graphs with checks but yes.",
                    "label": 0
                },
                {
                    "sent": "On here.",
                    "label": 0
                },
                {
                    "sent": "Things that.",
                    "label": 0
                },
                {
                    "sent": "So, so that's interesting because basically when you pre trend in all Nets, let's say you're going to pretend this on segmented image that you collect some where they're going to be.",
                    "label": 0
                },
                {
                    "sent": "Like you said that you tend to be overconfident, and then we want to make to see a digit everywhere.",
                    "label": 0
                },
                {
                    "sent": "But when you start training them within this whole harness, then we have to be smarter.",
                    "label": 0
                },
                {
                    "sent": "So they will have to develop scores that actually mean something and have this additional information.",
                    "label": 0
                },
                {
                    "sent": "This is not a digit.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you compare this in a CRF, well, this cost function is about the same.",
                    "label": 1
                },
                {
                    "sent": "But here we have a Yorkie called cost to find model is that there is cheap insurance, meaning that just a forward prop.",
                    "label": 0
                },
                {
                    "sent": "Scoop of nights.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So 95 there was a check without that work that way, that was done by a lot of people, including Yoshua.",
                    "label": 0
                },
                {
                    "sent": "Was industry diploid 96's purpose is about 15% of all U S6 for 15 years so that that was a real thing.",
                    "label": 1
                },
                {
                    "sent": "It actually worked.",
                    "label": 0
                },
                {
                    "sent": "You would start with a check graph.",
                    "label": 0
                },
                {
                    "sent": "We feel look at the whole segment, character Connoisseur, composer Viterbi fact only the top part was trend.",
                    "label": 0
                },
                {
                    "sent": "We we trained on 1/4 million check images which was huge at the time and we turned down to the character recognizer and that's about it.",
                    "label": 0
                },
                {
                    "sent": "The rest was too just too hard.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But even doing though, so the training is this kind of things.",
                    "label": 0
                },
                {
                    "sent": "We don't use a Viterbi user forward.",
                    "label": 0
                },
                {
                    "sent": "Instead it's a bit more stable about case.",
                    "label": 0
                },
                {
                    "sent": "And you have a vast improvement in the performance when you do this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, I didn't describe this here, so you have this difference here and then you have the gradient of the loss function, which is plus one.",
                    "label": 0
                },
                {
                    "sent": "So it's a difference, so it's going to be plus 1 -- 1.",
                    "label": 0
                },
                {
                    "sent": "Here the sun minus 1 -- 1 + 1 + 1 + 1 In the Viterbi transformer that selects a graph along the graph.",
                    "label": 0
                },
                {
                    "sent": "You still have the back propagation of plus one and zero over the other ones.",
                    "label": 0
                },
                {
                    "sent": "Then when you go here, you have to send them so you get basically minus negative signal on the wrong path and a positive signal on the components of the wrong path and a positive signal component to the correct path.",
                    "label": 0
                },
                {
                    "sent": "These gradients can go back into the neural networks.",
                    "label": 0
                },
                {
                    "sent": "Here you can update the neural networks and if you have if you have terms that come from the segmenter, you could also do that if you wanted to.",
                    "label": 0
                },
                {
                    "sent": "So yes, you back propagate the gradient to the whole graph, which is a fair amount of bookkeeping if you think about it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the interesting part is that you can define something that's called the graph.",
                    "label": 0
                },
                {
                    "sent": "Transition Break takes an input graph and output grafana structure.",
                    "label": 0
                },
                {
                    "sent": "That's called a graph transducer.",
                    "label": 1
                },
                {
                    "sent": "That's the way she know about graph theory exists and you have a graph composition operation that you can define abstractly that tells how you do graph transformations.",
                    "label": 0
                },
                {
                    "sent": "Then you can most of these bricks here.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, all of them in that case, except the forward I implemented with the same brick.",
                    "label": 0
                },
                {
                    "sent": "So the the similar 2000 lines of code are running in every little thing.",
                    "label": 0
                },
                {
                    "sent": "The only thing that's different are two methods that are defined in the graph transformer.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was a complex task address with a lot of engineering.",
                    "label": 0
                },
                {
                    "sent": "Basically we split the tasks in various steps a priori.",
                    "label": 0
                },
                {
                    "sent": "And and we we went for that, and then trained for that.",
                    "label": 0
                },
                {
                    "sent": "And then at the end we relax a little bit and let the network speed by themselves or something.",
                    "label": 0
                },
                {
                    "sent": "And maybe the big surprise of deep learning, at least the initial one when people started to do unsupervised learning that we don't need to do that.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because I'm.",
                    "label": 0
                },
                {
                    "sent": "Turns out.",
                    "label": 0
                },
                {
                    "sent": "So if you remember the beginning of deep learning, there was a lot about unsupervised pretraining.",
                    "label": 0
                },
                {
                    "sent": "That was sort of abandoned because now people use GPU and lots of data, but still everybody says unsupervised pretraining there is something to be done about this.",
                    "label": 0
                },
                {
                    "sent": "I have a problem with unsupervised that I'm going to describe later.",
                    "label": 0
                },
                {
                    "sent": "Actually, maybe I'm not going to have the time to describe it, But anyway I'd like to see the unsupervised training as an auxiliary task.",
                    "label": 0
                },
                {
                    "sent": "You define another task and you hope that it's going to help.",
                    "label": 0
                },
                {
                    "sent": "And if you think about an interesting problem that we want to solve is a problem for which labels are expensive.",
                    "label": 0
                },
                {
                    "sent": "If you want to solve a particular problem, a complex one, you wouldn't solve it.",
                    "label": 0
                },
                {
                    "sent": "It was easy to get the labels, so it's going to be a program to get labeled data.",
                    "label": 0
                },
                {
                    "sent": "But you can see that in the vicinity of an interesting task there are problems that are not that interesting, for which labels are easy.",
                    "label": 1
                },
                {
                    "sent": "So there.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An example that comes from Matt Miller in 2006.",
                    "label": 0
                },
                {
                    "sent": "At the time it was more like a thought example.",
                    "label": 0
                },
                {
                    "sent": "Suppose you want to recognize the face of 1 million person at that time.",
                    "label": 0
                },
                {
                    "sent": "It was something that was not really feasible.",
                    "label": 0
                },
                {
                    "sent": "How many label image per person can we open at that time?",
                    "label": 1
                },
                {
                    "sent": "There was no Facebook.",
                    "label": 0
                },
                {
                    "sent": "Well, that's very difficult.",
                    "label": 1
                },
                {
                    "sent": "You're not going to have 100 the labeled images for one million persons.",
                    "label": 1
                },
                {
                    "sent": "So the auxiliary tasks that can define A2 face image representing the same person.",
                    "label": 0
                },
                {
                    "sent": "And here we have a lot of examples because we take the movies and app interfaces with two faces in the same frame, the different people.",
                    "label": 0
                },
                {
                    "sent": "Well, you have the case of mirrors in the case of Twins, but that's something you can bound, you know.",
                    "label": 0
                },
                {
                    "sent": "And if you have two faces in successive frames, they likely to be the same person, except different lighting, different angles.",
                    "label": 1
                },
                {
                    "sent": "Things are going to change, so training a system to recognize whether two faces image are the same person is much easier if you mention just to collect the data.",
                    "label": 0
                },
                {
                    "sent": "So you contribute something like the face that kind of feature extractor.",
                    "label": 0
                },
                {
                    "sent": "Let's think you become big set of convolutions here.",
                    "label": 0
                },
                {
                    "sent": "Same here.",
                    "label": 0
                },
                {
                    "sent": "Shared weights and a discriminator.",
                    "label": 0
                },
                {
                    "sent": "That's going to take the output features and say some person or not.",
                    "label": 0
                },
                {
                    "sent": "And you trained that way on this huge amount of data.",
                    "label": 0
                },
                {
                    "sent": "Easy to get.",
                    "label": 0
                },
                {
                    "sent": "Then, well, you just take your convolutional layer, put the classifier on top and say this is John.",
                    "label": 0
                },
                {
                    "sent": "The same features that are useful to see that these two faces are the same person are going to be useful to say who this person is.",
                    "label": 0
                },
                {
                    "sent": "And you're going to be able to add the new persons very easily.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's been done in NLP by owner so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uncle Bear, so I'm not I'm going to skip that.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's going to be too long.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually doubles.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's been done by Maxim, who is somewhere hiding there for object recognition.",
                    "label": 0
                },
                {
                    "sent": "So you take dogs in image net, nice little doc centered in the image.",
                    "label": 1
                },
                {
                    "sent": "But you have a lot of images, like 1 million dogs.",
                    "label": 1
                },
                {
                    "sent": "The dogs in Pascal work, you have 10,000 images, and they're more like this.",
                    "label": 0
                },
                {
                    "sent": "You see, this is a dog.",
                    "label": 0
                },
                {
                    "sent": "This is not a dog.",
                    "label": 0
                },
                {
                    "sent": "Oh, these are dogs and this is not a dog.",
                    "label": 0
                },
                {
                    "sent": "So they're more challenging and the question is, can we leverage the?",
                    "label": 0
                },
                {
                    "sent": "The convolutional layers that you learn on something like this to treat that.",
                    "label": 0
                },
                {
                    "sent": "And so well.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maximon colleagues.",
                    "label": 0
                },
                {
                    "sent": "Build this kind of big things where you trained on image net first and then you did take VO.",
                    "label": 0
                },
                {
                    "sent": "Can you take patches and you add additional layers on top of the convolutional layers and you trend adaptation layers leaving the convolutional layers pretty much frozen.",
                    "label": 0
                },
                {
                    "sent": "And when you do this, you get state of the art in classification on Pascal walk.",
                    "label": 0
                },
                {
                    "sent": "And in fact.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the time my scheme, Joseph, Ivan, and I did that.",
                    "label": 0
                },
                {
                    "sent": "A lot of people did that at the same times, like I think there was a transfer for Caltech 256 by Rob Ferguson modular, maybe a couple months before then.",
                    "label": 0
                },
                {
                    "sent": "There's a Pascal detection by rose gifts.",
                    "label": 0
                },
                {
                    "sent": "We can now couple more now, and this idea of transferring features you learn something on image retinal on large data set that's labeled but not very interesting.",
                    "label": 0
                },
                {
                    "sent": "Now imagine it is not very interesting, in fact.",
                    "label": 0
                },
                {
                    "sent": "The 1000 classes of the Challenger reasonable, but if you look at the 20,000 classes you know there is a class that's called regional manager.",
                    "label": 0
                },
                {
                    "sent": "Another one is district manager.",
                    "label": 0
                },
                {
                    "sent": "How do you distinguish original manager from a district manager?",
                    "label": 0
                },
                {
                    "sent": "But they still you trend with that and you get good features.",
                    "label": 0
                },
                {
                    "sent": "So, so it's not that far from the unsupervised learning, you know.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So yes, and supervisory tasks.",
                    "label": 0
                },
                {
                    "sent": "So the unsupervised pretraining I don't like it to see that some supervise and here is why.",
                    "label": 1
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is a cluster?",
                    "label": 0
                },
                {
                    "sent": "The assumption that the shape of the density within the underlying categories you see something like this.",
                    "label": 0
                },
                {
                    "sent": "Maybe it means that you have two categories.",
                    "label": 0
                },
                {
                    "sent": "This is called the cluster assumption.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, if you look at an image is a bunch of pixels and square grid, no images in our retina didn't like that the receptors they know square root density varies everything.",
                    "label": 0
                },
                {
                    "sent": "So so basically the you have the square grid with RGB pixels is a kind of idealized version of what's in your eyes and so you would like something that works the same if you do arbitrary transform of the input space.",
                    "label": 0
                },
                {
                    "sent": "So I take my 2 images here and I'm going to change the inputs.",
                    "label": 0
                },
                {
                    "sent": "Best Buy a smooth function that's going to compress the points here and split apart the points here.",
                    "label": 0
                },
                {
                    "sent": "And when I do this while the base boundary between the two classes remains.",
                    "label": 0
                },
                {
                    "sent": "But my yellow do cluster, they just one cluster anymore.",
                    "label": 0
                },
                {
                    "sent": "So when you look at this, the cluster structure of data is not really something that inherent in the data, because you can destroy it by re parameterising the input.",
                    "label": 0
                },
                {
                    "sent": "Or you can you can create it artificially.",
                    "label": 0
                },
                {
                    "sent": "The cluster structure is in fact.",
                    "label": 0
                },
                {
                    "sent": "The structure that you put inside by feature rising your data in a particular way.",
                    "label": 0
                },
                {
                    "sent": "So sometimes you build it.",
                    "label": 0
                },
                {
                    "sent": "I think it is.",
                    "label": 0
                },
                {
                    "sent": "It's it's.",
                    "label": 0
                },
                {
                    "sent": "It's incorrect to believe this really unsupervised.",
                    "label": 0
                },
                {
                    "sent": "You just leverage assumptions that you put in your system by other means.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can still change it.",
                    "label": 0
                },
                {
                    "sent": "If you have a zero in between, it's going to be hard.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Counter example here.",
                    "label": 0
                },
                {
                    "sent": "This was quite well separated.",
                    "label": 0
                },
                {
                    "sent": "The best boundary is here.",
                    "label": 0
                },
                {
                    "sent": "With a big O in between.",
                    "label": 0
                },
                {
                    "sent": "Well, you can collapse to 0.",
                    "label": 0
                },
                {
                    "sent": "Sure, but you know.",
                    "label": 0
                },
                {
                    "sent": "They're not like that.",
                    "label": 0
                },
                {
                    "sent": "Don't forget, in addition that you don't have this yellow distribution, we just have a couple points so you don't know if it's zero.",
                    "label": 0
                },
                {
                    "sent": "We just don't have enough points to get something in between inside.",
                    "label": 0
                },
                {
                    "sent": "So, So what I'm meant to say is that in unsupervised learning or in clustering there is a lot of it.",
                    "label": 0
                },
                {
                    "sent": "That is something that you put inside by feature rising or choosing particular feature particular access to represent your data.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so for me, unsupervised learning is comparable to using really cheap labels like X One X2 are close X One X3 are not close.",
                    "label": 0
                },
                {
                    "sent": "And when you choose the feature space, you choose how you represent the data.",
                    "label": 0
                },
                {
                    "sent": "This is what you're choosing, you choosing the metric, and you're using the proximity in your data.",
                    "label": 0
                },
                {
                    "sent": "That means you say you're choosing a kernel.",
                    "label": 0
                },
                {
                    "sent": "Is a similarity measure essentially?",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to stop here.",
                    "label": 0
                },
                {
                    "sent": "Jump overall.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And with my conclusion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There going to be lots of neural.",
                    "label": 0
                },
                {
                    "sent": "Net applications in the coming years.",
                    "label": 1
                },
                {
                    "sent": "I wrote that two years ago, so is this when we inside it.",
                    "label": 1
                },
                {
                    "sent": "So learning perceptual tasks with no net works quite well.",
                    "label": 1
                },
                {
                    "sent": "Data and compute power here.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the statistical machine Learning Research program was.",
                    "label": 1
                },
                {
                    "sent": "The following is being set up in the 2000s or in the 90s discussing the models.",
                    "label": 0
                },
                {
                    "sent": "What models can we use?",
                    "label": 0
                },
                {
                    "sent": "Water the approximation properties and what are the structures we can define models discussing the loss functions, what kind of loss can we invent?",
                    "label": 1
                },
                {
                    "sent": "What are the asymptotic consistency effects or loss functions for structural things like just like those are described?",
                    "label": 1
                },
                {
                    "sent": "Discuss the learning algorithm optimization, large scale and discussing the generalization like capacity control structures and so on and.",
                    "label": 0
                },
                {
                    "sent": "Done.",
                    "label": 0
                },
                {
                    "sent": "I mean, there are a lot of details looking around that could be improved and could be surprises, but if you look at the big lines this is what machine learning is achieved in the last 20 years.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Oh I think.",
                    "label": 0
                },
                {
                    "sent": "OK, that's this.",
                    "label": 0
                },
                {
                    "sent": "Depends a lot of what I didn't say.",
                    "label": 0
                },
                {
                    "sent": "I think the new objective study what we should look at this complex problems the real bottleneck that we have now is that we know quite well are to solve a particular problem for which we have data in abundant quantity.",
                    "label": 0
                },
                {
                    "sent": "And are we going to be able to do something reasonably well?",
                    "label": 0
                },
                {
                    "sent": "But when we have lots of data that are clearly in the same category.",
                    "label": 0
                },
                {
                    "sent": "But they're not exactly the same when we have to do transfer learning between one and another one.",
                    "label": 0
                },
                {
                    "sent": "When you have to combine learning systems that do different things in order to get to achieve a big task, these are the things we don't know how to do.",
                    "label": 0
                },
                {
                    "sent": "And I think This is why the big payoff is going to be.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                }
            ]
        }
    }
}