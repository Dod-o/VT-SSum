{
    "id": "eed6r3ura3mfeszfwptj32ujnw3plak5",
    "title": "Semantic Multimedia Information Retrieval Based on Contextual Descriptions",
    "info": {
        "introducer": [
            "Jens Lehmann, Department of Business Information Systems, University of Leipzig"
        ],
        "author": [
            "Nadine Steinmetz, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2013_steinmetz_semantic/",
    "segmentation": [
        [
            "I want to present a joint work that has been together but has been done together with how exact?"
        ],
        [
            "Before I introduce the actual approach, I want to give you a kind of a big picture of the work that we are doing and put some in our research research group because the work that I want to present as a part of what we are part of, a framework that we are developing in our research group.",
            "After that I want to introduce the challenges that we are facing with video metadata and then.",
            "I will talk about the actual context, well modeled.",
            "Of course, we evaluated our approach and I will present the evaluation results and conclude."
        ],
        [
            "So the motivation we are doing.",
            "Video analysis.",
            "We start with Visual video analysis.",
            "We we are doing a scene cut detection to find content related segments within within a video document.",
            "And then we try to extract text from a video using OCR optical character recognition and speech to text algorithms.",
            "And also we try to extract visual content concept from the video and all this textual metadata that we extract is then semantically analyzed."
        ],
        [
            "So just to give you an short example, we have a video.",
            "This is from from a Ted Talk, a slide from a Ted talk."
        ],
        [
            "We have a title and we have a speaker information.",
            "This is authoritative metadata."
        ],
        [
            "Sometimes we also have user generated text like in this case computation, Hobbs, Thomas and 16151.",
            "This is non authoritative metadata.",
            "It can be by the author, but in most cases it is by any user."
        ],
        [
            "Additionally, we have the text extracted that can be seen in the video, the OCR metadata."
        ],
        [
            "And we have the speech to text information.",
            "And what we are then doing is."
        ],
        [
            "So trying to identify identify named entities and disintegrate those entities to provide all this information in a video search engine."
        ],
        [
            "And to refer to yesterday's keynote by David Karger, here's our screenshot we are doing.",
            "Or we are providing all this information and actual semantic application.",
            "This is one of the screenshots of our one of our video search engine's.",
            "And here you can see that an entity is selected for the search within the archive and all the yellow or orange hits are hits within the videos that weather.",
            "Actual chosen entity can be found in in the single videos.",
            "So this is the big picture.",
            "We are working on in our research group and we have certain challenges working with."
        ],
        [
            "Video metadata."
        ],
        [
            "Um?",
            "So we have automatic automatically extracted metadata.",
            "There is a big advantage of this metadata.",
            "We have time reference metadata that can be used to provide an search within the videos and you have a minimum effort to extract this this metadata because and in libraries there are many people who are annotating documents but with videos it's it's pretty.",
            "It's pretty complex and time consuming, but a big disadvantage of this automatic extraction algorithm is the error rate.",
            "So just to give."
        ],
        [
            "In example we have this slide from the from the."
        ],
        [
            "Sample and there is the terms abstraction in this in this light that can be seen, but the OCR software extracts subsurface due to some errors we don't know.",
            "So this is this is actually this is incorrect information that we have to take into account for the subsequent subsequently.",
            "Further analysis process is."
        ],
        [
            "So this just to give you some numbers.",
            "Video OCR has up to 65% error rates and speech to text is a bit better than there are up to 50% error rate.",
            "When extracting text over the whole video."
        ],
        [
            "So we are facing some challenges by processing the video metadata.",
            "What we what we want to do is a context driven.",
            "This immigration on all this textual information.",
            "But the context that we that we can create is heterogeneous regarding to the characteristics of the different metadata that we want to take into account in one context.",
            "So we have different sources.",
            "We have different reliabilities.",
            "Different text types and also we have these error rates that can be dragged through the whole process, so we have to find a solution to handle this."
        ],
        [
            "So we developed an contextual model that takes into account contextual description for the metadata types."
        ],
        [
            "To for the further analysis process is so just to come back to this.",
            "To this example we have here authoritative metadata with the title and the speaker and we can extract."
        ],
        [
            "Some items, some some some terms from from all text or from all metadata types.",
            "And then we can create a context and then we start disambiguating the terms that can be found in the context and every disambiguated term is influencing the next this immigration step.",
            "Because if you have a disintegrated term you can you have an entity that influences the disintegration of the next of the next term.",
            "So the problem is if you start with and probably incorrect term.",
            "Then you drag all this error through the whole.",
            "This immigration process within this context, and what we need here."
        ],
        [
            "It's a dissimilation order.",
            "What is the prospectively best or most correct term within a context and what where we where we want to start to give or to get achieve good result?"
        ],
        [
            "So what we what we developed is scoring method of metadata items within a context.",
            "We calculate a confidence value for the metadata items too.",
            "To be able to order the metadata items within a context and this confidence value consists of several characteristics different scores.",
            "That I will describe in detail."
        ],
        [
            "So the first scorer is the source, reliable as our reliability as I already set up automatic text extraction algorithms, have a rather low reliability, but you can expect a high reliability by authoritative sources.",
            "That's where we."
        ],
        [
            "We ranked so metadata items that come from authoritative sources.",
            "The hyest then.",
            "Also we we have this non authoritative metadata like the text from from users.",
            "We empirically rank these these items a bit lower than authoritative sources and then we have the reliabilities for the automatic speech recognition and for the OCR for the optical character recognition.",
            "They are derived from the error rates that I presented."
        ],
        [
            "So the next score is called the source diversity to come back to this example, we have the terms abstraction in displayed in the video and the OCR algorithm says that it's subsurface.",
            "Um?"
        ],
        [
            "We have four different on in this.",
            "In this example we have four different source types and no other source says there is subsurface mentioned anywhere in in the video or in the context."
        ],
        [
            "So we have just one source of out of four saying that subsurface belongs to the context."
        ],
        [
            "And the other example is that we have Thomas hops that is extracted correctly by their OCR."
        ],
        [
            "Software and also by the IS."
        ],
        [
            "Um algorithm, and so we have two sources that agree or confirm the same textual information and that hires the prospective correctness of this term."
        ],
        [
            "The third score, or the third characteristic that we identified is the text type.",
            "We identified three different text types within video metadata.",
            "We have key terms that are mostly given by authoritative sources like speaker information, publication place, or any other locations or other key terms.",
            "We have natural language text.",
            "Like from descriptive text or from automatic speech recognition, and also from the OCR.",
            "And we have text."
        ],
        [
            "So what we want to do on this textual information is extracting he terms or the keywords from from all this text and we have to do some work on the different text types."
        ],
        [
            "Or at the in the first.",
            "In the first case.",
            "In the case of key terms, we're already done."
        ],
        [
            "Cousin, if there's information that the speakers charge Dyson, we can also take George Dyson as textual information.",
            "We don't have to do anything with that."
        ],
        [
            "The next in the next text type for natural language text we have to do and."
        ],
        [
            "Part of speech tagging.",
            "We have this example text."
        ],
        [
            "And then we can do and part of speech part of speech tagging on on this textual information to find out what what terms are nouns or what are combined nouns to find out what are the important terms within this.",
            "When Windows texture information."
        ],
        [
            "But there is a accuracy rate or a lower accuracy rate of 0 or 56% so."
        ],
        [
            "That is why we determine the confidence for this.",
            "For natural language text to this core."
        ],
        [
            "And for tax, we have the problem that tags that occur at the same time stem may belong together different or separate text that were attacked by the same user at the same time.",
            "Stem may be combined, or they can.",
            "They can be a named entity, but only in in the combination.",
            "So we have to do a grouping of all the text that occur at the same time stamp."
        ],
        [
            "And we found out also empirically that we can achieve a precision of 70% with this grouping algorithm."
        ],
        [
            "And so we found out this the confidence score for the text type of tags."
        ],
        [
            "The 4th characteristics is is called class cardinality.",
            "This comes from the classes that we can assign the cloud Ontology classes that we can assign to certain key terms within a text.",
            "To classify that we can we can use a so-called named entity recognition tagger to find out if there."
        ],
        [
            "This person in this."
        ],
        [
            "Case in a text, and in this case we can restrict the incessant the instances of an ontology or the entity candidates for this term to the intense instances of their class person from the from the knowledge base that we are using.",
            "So we we can restrict the entity candidates and that hires the lower that decreases the ambiguity.",
            "And so we can.",
            "We can have a higher confidence for this for this term."
        ],
        [
            "So for example for the DB PEDIA version 3.8.",
            "We have a confidence of 0.854 four person 0.964 organization because the class on the organization has less instances then the class person.",
            "And items that are not assigned to any class to or to any to any class that have trivially the confidence of 0.",
            "So."
        ],
        [
            "At the end we can and can calculate a confidence value for all the key terms that we have within our context.",
            "At the moment we are all the weights for all the scores are distributed evenly."
        ],
        [
            "And then we calculate a total score.",
            "A total confidence score, and we can reorder."
        ],
        [
            "All the terms within a context and then we can start with the prospectively most confident Q term and then proceed."
        ],
        [
            "Proceed with the disintegration processes of the following terms and then.",
            "Yes, then we we get the discourse setting can see on the on the right side or then the scores that are achieved by this entity during the during this immigration process.",
            "So on the left you have the confidence value that we calculated before the disintegration process.",
            "And on the on the right you you see the scores that are achieved during the disambiguation process process.",
            "All scores are ranged between zero and one, so at the end of the dissemination process we have two different two different confidence values or two different values that we can use to decide if this is probably correct the simulation.",
            "Or not."
        ],
        [
            "So the benefits.",
            "Off of the approach is that we begin that the simulation process within a context with the prospectively most correct term.",
            "And after this immigration process we have two different scores or two different measurements to decide if we want to take into account this the same weighted term on this entity for the assignment or not."
        ],
        [
            "OK, so we've evaluated our approach."
        ],
        [
            "The problem with evaluating named entity mapping or word sense.",
            "This immigration is that we need a ground truth.",
            "And in this case we needed a Crown truth that represents different sources with different reliabilities, different text types and so on.",
            "And to the best of our knowledge, we didn't find such a such a data set.",
            "So we created one on our own.",
            "We used video metadata of five Ted talks.",
            "We did a scene cut detection on this and we identified 211 content based segments.",
            "Overall there are 8 / 800 meta data items within this.",
            "Within this data set and we identified.",
            "Over 2500 entities in this data set so."
        ],
        [
            "This is what the data set looks like.",
            "Looks like we have the source information in the second column and textual information.",
            "Then we have a video ID and the last column represents a segment ID so that you can assign the texture information to certain segments within a video."
        ],
        [
            "And this is what the groundtruth looks like.",
            "We also have this the video ID, the segment ideas second column.",
            "Then we have the identified entity which is at DB pedia entity in this case.",
            "And then we also have the source information.",
            "And you can download the data set and at this URL."
        ],
        [
            "So our result.",
            "We compared our approach, which we call the Contag are two three different other approaches we."
        ],
        [
            "Used a web service of DPS Spotlight."
        ],
        [
            "Used Vicki Machine and at this point I want to thank cloud your Juliano who processed the data and we turned the analysis results to me."
        ],
        [
            "And we used a simple anyar.",
            "It's and it's our own approach, but just not using the approach of ordering the metadata items according to the confidence value."
        ],
        [
            "And the contactor is already set as the approach that I just presented.",
            "So as you can see, especially on the on the sources that have a probably low confidence, we could achieve much better result.",
            "For I will evaluated the our results according to the sources that are the 1st four rows and then we also evaluated according to the segments overall sources and over the video also overall sources.",
            "So.",
            "These are the results."
        ],
        [
            "Beside these recurrent precision measures, we also had some further evaluation findings.",
            "When we create a context for a for a metadata item, we have this in the best case we have these two values.",
            "These two calculated scores.",
            "The first one is the confidence score.",
            "The Predis immigration score, and the 2nd order.",
            "This immigration score is the one that achieved entity achieved during the disintegration score.",
            "So now we can have."
        ],
        [
            "A measure to decide if we take this into account for the context and use this item as a context item for this immigration process or not, and what we found out is that.",
            "Items that are retrieved from sources with the lower confidence as a as an OCR are best December waited with with metadata items with a pretty high confidence predis immigration score, and for authoritative sources in text that's not so important to have high confidence is the disintegration score is is not so important as we found out for creating.",
            "Offered I'm dynamically creating a context form for meta data item and what we also."
        ],
        [
            "I found out is that we also mentioned that we use content based segments for the as context boundary for for the disambiguation process, and we evaluated this against a video based based approach so that we take the whole video as a context.",
            "So the video context boundary is at the maximum and we found out that the segment base.",
            "Approach is is better than in comparison to the video based approach.",
            "Even though our videos from the datasets are very homogeneous because all the videos are have the same topic throughout all of the of the video.",
            "But we we also that we achieve better results using just the segment's context boundary."
        ],
        [
            "So contributions.",
            "We are using contextual descriptions of video metadata to bring metadata in in a certain order to achieve better this immigration results on this.",
            "Sometimes not so reliable information.",
            "We introduced our context model which scores the video video metadata an.",
            "As I already said, bring some into your order.",
            "We VE?",
            "We evaluated our approach on an data set that we created for this special purpose and as I have shown, we could could approve recall and precision, especially on the text information with the lower confidence."
        ],
        [
            "So ongoing work is right now the waiting of single confidence chorus we also we already experienced that source diversity though the one where other sources have to confirm if this term is perspectively correct, it's a good.",
            "It's a good measure to find out if if if we could take this as an assignment for the for the video search engine or not.",
            "We also defined additional additional confidence scores.",
            "For example, the number of tokens within this term.",
            "And what we are working right now on is a negative context.",
            "Scoring.",
            "That means usually at this immigration process takes into account information from the context and scores an entity candidate account according to the positive hints within this context.",
            "But we don't take into account negative hint.",
            "So what we are right now working on is kind of a penalty for for entity candidates that are linked.",
            "Or that are related to a negative context that is created.",
            "Also dynamically.",
            "We use different knowledge bases for this approach.",
            "We use DB pedia but we also have project with.",
            "With the German authoritie files for example.",
            "And what we also want to do is the comprehension of the user context for the non authoritative metadata and also the authoritative metadata you can take into account information that we can get from the user profile that you that can be used for the context and maybe improves disambiguation.",
            "This immigration process.",
            "OK."
        ],
        [
            "That's it.",
            "So thanks to him very good talk.",
            "There is just one confusion I have because you talk you.",
            "You have two sub tasks.",
            "You have the new task, the recognition of entities and the correct typing and you have the nail task.",
            "The disambiguation?",
            "So the entity linking.",
            "We've in this case the PRI, so that the figures you show for the comparisons what you consider as As for the precision, recall and F1 is if the entity has been correctly recognized type and disseminated right.",
            "Type we believe this type of this Type 2 to the NER Tiger.",
            "We just take that as a given.",
            "So you evaluate the nail parts to disagree.",
            "Disambiguation just said, yeah, there's just this immigration part, where the ground truth consists of the December rated entities and we check if this entity is is this immigrated correctly or not OK, so my question is you show that we've discovering and the fact that you give.",
            "Importance to different metadata items.",
            "You can then improve the design with the context of disambiguation part, but do you know if this has also an influence on the recognition part?",
            "So whether you will be able to recognize more or less good entities and get less false alarms specifically.",
            "Tell you.",
            "OK, we didn't evaluate then because do and somehow you have to rely on the ground truth at at this at this point, but we think about this week because of the ground.",
            "Truth is you have the boundary spot for the terms in the ground truth and we have to think about.",
            "Using maybe other ground truth or other annotations to to show if this is this correctly annotated or not.",
            "You explained that you iteratively basically go through with this application scores based on the confidence values you obtained.",
            "So would it also be an option to like first compute all the dislocations question and then refine all of them in one step instead of doing the iterative approach you described?",
            "If I understood it correctly?",
            "1st first this immigrate to terms and then order them and then optimize the scores of all of them.",
            "Basically OK.",
            "I think that the approach relies on the assumption that we start with the most correct with the most correct information that we have, and so the process then takes into account already disseminated entity.",
            "If we have already disintegrated entity.",
            "This strengthens kind of the context and then it's influenced the influential.",
            "Part of this of this entity is much higher than just a term that is not disseminated so far, so the assumption is that we start with the most correct one and not in in a random order.",
            "OK, does this answer your question?",
            "Yes, I think we can also talk further offline OK?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to present a joint work that has been together but has been done together with how exact?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before I introduce the actual approach, I want to give you a kind of a big picture of the work that we are doing and put some in our research research group because the work that I want to present as a part of what we are part of, a framework that we are developing in our research group.",
                    "label": 0
                },
                {
                    "sent": "After that I want to introduce the challenges that we are facing with video metadata and then.",
                    "label": 0
                },
                {
                    "sent": "I will talk about the actual context, well modeled.",
                    "label": 0
                },
                {
                    "sent": "Of course, we evaluated our approach and I will present the evaluation results and conclude.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the motivation we are doing.",
                    "label": 0
                },
                {
                    "sent": "Video analysis.",
                    "label": 0
                },
                {
                    "sent": "We start with Visual video analysis.",
                    "label": 0
                },
                {
                    "sent": "We we are doing a scene cut detection to find content related segments within within a video document.",
                    "label": 0
                },
                {
                    "sent": "And then we try to extract text from a video using OCR optical character recognition and speech to text algorithms.",
                    "label": 1
                },
                {
                    "sent": "And also we try to extract visual content concept from the video and all this textual metadata that we extract is then semantically analyzed.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to give you an short example, we have a video.",
                    "label": 0
                },
                {
                    "sent": "This is from from a Ted Talk, a slide from a Ted talk.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a title and we have a speaker information.",
                    "label": 0
                },
                {
                    "sent": "This is authoritative metadata.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sometimes we also have user generated text like in this case computation, Hobbs, Thomas and 16151.",
                    "label": 0
                },
                {
                    "sent": "This is non authoritative metadata.",
                    "label": 1
                },
                {
                    "sent": "It can be by the author, but in most cases it is by any user.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additionally, we have the text extracted that can be seen in the video, the OCR metadata.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have the speech to text information.",
                    "label": 0
                },
                {
                    "sent": "And what we are then doing is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So trying to identify identify named entities and disintegrate those entities to provide all this information in a video search engine.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to refer to yesterday's keynote by David Karger, here's our screenshot we are doing.",
                    "label": 0
                },
                {
                    "sent": "Or we are providing all this information and actual semantic application.",
                    "label": 0
                },
                {
                    "sent": "This is one of the screenshots of our one of our video search engine's.",
                    "label": 0
                },
                {
                    "sent": "And here you can see that an entity is selected for the search within the archive and all the yellow or orange hits are hits within the videos that weather.",
                    "label": 0
                },
                {
                    "sent": "Actual chosen entity can be found in in the single videos.",
                    "label": 0
                },
                {
                    "sent": "So this is the big picture.",
                    "label": 0
                },
                {
                    "sent": "We are working on in our research group and we have certain challenges working with.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Video metadata.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we have automatic automatically extracted metadata.",
                    "label": 0
                },
                {
                    "sent": "There is a big advantage of this metadata.",
                    "label": 0
                },
                {
                    "sent": "We have time reference metadata that can be used to provide an search within the videos and you have a minimum effort to extract this this metadata because and in libraries there are many people who are annotating documents but with videos it's it's pretty.",
                    "label": 0
                },
                {
                    "sent": "It's pretty complex and time consuming, but a big disadvantage of this automatic extraction algorithm is the error rate.",
                    "label": 0
                },
                {
                    "sent": "So just to give.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In example we have this slide from the from the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample and there is the terms abstraction in this in this light that can be seen, but the OCR software extracts subsurface due to some errors we don't know.",
                    "label": 0
                },
                {
                    "sent": "So this is this is actually this is incorrect information that we have to take into account for the subsequent subsequently.",
                    "label": 0
                },
                {
                    "sent": "Further analysis process is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this just to give you some numbers.",
                    "label": 0
                },
                {
                    "sent": "Video OCR has up to 65% error rates and speech to text is a bit better than there are up to 50% error rate.",
                    "label": 1
                },
                {
                    "sent": "When extracting text over the whole video.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we are facing some challenges by processing the video metadata.",
                    "label": 0
                },
                {
                    "sent": "What we what we want to do is a context driven.",
                    "label": 0
                },
                {
                    "sent": "This immigration on all this textual information.",
                    "label": 0
                },
                {
                    "sent": "But the context that we that we can create is heterogeneous regarding to the characteristics of the different metadata that we want to take into account in one context.",
                    "label": 0
                },
                {
                    "sent": "So we have different sources.",
                    "label": 0
                },
                {
                    "sent": "We have different reliabilities.",
                    "label": 0
                },
                {
                    "sent": "Different text types and also we have these error rates that can be dragged through the whole process, so we have to find a solution to handle this.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we developed an contextual model that takes into account contextual description for the metadata types.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To for the further analysis process is so just to come back to this.",
                    "label": 0
                },
                {
                    "sent": "To this example we have here authoritative metadata with the title and the speaker and we can extract.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some items, some some some terms from from all text or from all metadata types.",
                    "label": 0
                },
                {
                    "sent": "And then we can create a context and then we start disambiguating the terms that can be found in the context and every disambiguated term is influencing the next this immigration step.",
                    "label": 0
                },
                {
                    "sent": "Because if you have a disintegrated term you can you have an entity that influences the disintegration of the next of the next term.",
                    "label": 0
                },
                {
                    "sent": "So the problem is if you start with and probably incorrect term.",
                    "label": 0
                },
                {
                    "sent": "Then you drag all this error through the whole.",
                    "label": 0
                },
                {
                    "sent": "This immigration process within this context, and what we need here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a dissimilation order.",
                    "label": 0
                },
                {
                    "sent": "What is the prospectively best or most correct term within a context and what where we where we want to start to give or to get achieve good result?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we what we developed is scoring method of metadata items within a context.",
                    "label": 1
                },
                {
                    "sent": "We calculate a confidence value for the metadata items too.",
                    "label": 1
                },
                {
                    "sent": "To be able to order the metadata items within a context and this confidence value consists of several characteristics different scores.",
                    "label": 0
                },
                {
                    "sent": "That I will describe in detail.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first scorer is the source, reliable as our reliability as I already set up automatic text extraction algorithms, have a rather low reliability, but you can expect a high reliability by authoritative sources.",
                    "label": 0
                },
                {
                    "sent": "That's where we.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We ranked so metadata items that come from authoritative sources.",
                    "label": 0
                },
                {
                    "sent": "The hyest then.",
                    "label": 0
                },
                {
                    "sent": "Also we we have this non authoritative metadata like the text from from users.",
                    "label": 0
                },
                {
                    "sent": "We empirically rank these these items a bit lower than authoritative sources and then we have the reliabilities for the automatic speech recognition and for the OCR for the optical character recognition.",
                    "label": 1
                },
                {
                    "sent": "They are derived from the error rates that I presented.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the next score is called the source diversity to come back to this example, we have the terms abstraction in displayed in the video and the OCR algorithm says that it's subsurface.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have four different on in this.",
                    "label": 0
                },
                {
                    "sent": "In this example we have four different source types and no other source says there is subsurface mentioned anywhere in in the video or in the context.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have just one source of out of four saying that subsurface belongs to the context.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the other example is that we have Thomas hops that is extracted correctly by their OCR.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Software and also by the IS.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um algorithm, and so we have two sources that agree or confirm the same textual information and that hires the prospective correctness of this term.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The third score, or the third characteristic that we identified is the text type.",
                    "label": 0
                },
                {
                    "sent": "We identified three different text types within video metadata.",
                    "label": 1
                },
                {
                    "sent": "We have key terms that are mostly given by authoritative sources like speaker information, publication place, or any other locations or other key terms.",
                    "label": 1
                },
                {
                    "sent": "We have natural language text.",
                    "label": 0
                },
                {
                    "sent": "Like from descriptive text or from automatic speech recognition, and also from the OCR.",
                    "label": 0
                },
                {
                    "sent": "And we have text.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we want to do on this textual information is extracting he terms or the keywords from from all this text and we have to do some work on the different text types.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or at the in the first.",
                    "label": 0
                },
                {
                    "sent": "In the first case.",
                    "label": 0
                },
                {
                    "sent": "In the case of key terms, we're already done.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cousin, if there's information that the speakers charge Dyson, we can also take George Dyson as textual information.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do anything with that.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next in the next text type for natural language text we have to do and.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part of speech tagging.",
                    "label": 0
                },
                {
                    "sent": "We have this example text.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can do and part of speech part of speech tagging on on this textual information to find out what what terms are nouns or what are combined nouns to find out what are the important terms within this.",
                    "label": 0
                },
                {
                    "sent": "When Windows texture information.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But there is a accuracy rate or a lower accuracy rate of 0 or 56% so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is why we determine the confidence for this.",
                    "label": 0
                },
                {
                    "sent": "For natural language text to this core.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for tax, we have the problem that tags that occur at the same time stem may belong together different or separate text that were attacked by the same user at the same time.",
                    "label": 0
                },
                {
                    "sent": "Stem may be combined, or they can.",
                    "label": 0
                },
                {
                    "sent": "They can be a named entity, but only in in the combination.",
                    "label": 0
                },
                {
                    "sent": "So we have to do a grouping of all the text that occur at the same time stamp.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we found out also empirically that we can achieve a precision of 70% with this grouping algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we found out this the confidence score for the text type of tags.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The 4th characteristics is is called class cardinality.",
                    "label": 0
                },
                {
                    "sent": "This comes from the classes that we can assign the cloud Ontology classes that we can assign to certain key terms within a text.",
                    "label": 0
                },
                {
                    "sent": "To classify that we can we can use a so-called named entity recognition tagger to find out if there.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This person in this.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Case in a text, and in this case we can restrict the incessant the instances of an ontology or the entity candidates for this term to the intense instances of their class person from the from the knowledge base that we are using.",
                    "label": 0
                },
                {
                    "sent": "So we we can restrict the entity candidates and that hires the lower that decreases the ambiguity.",
                    "label": 0
                },
                {
                    "sent": "And so we can.",
                    "label": 0
                },
                {
                    "sent": "We can have a higher confidence for this for this term.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example for the DB PEDIA version 3.8.",
                    "label": 0
                },
                {
                    "sent": "We have a confidence of 0.854 four person 0.964 organization because the class on the organization has less instances then the class person.",
                    "label": 0
                },
                {
                    "sent": "And items that are not assigned to any class to or to any to any class that have trivially the confidence of 0.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the end we can and can calculate a confidence value for all the key terms that we have within our context.",
                    "label": 0
                },
                {
                    "sent": "At the moment we are all the weights for all the scores are distributed evenly.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we calculate a total score.",
                    "label": 0
                },
                {
                    "sent": "A total confidence score, and we can reorder.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the terms within a context and then we can start with the prospectively most confident Q term and then proceed.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proceed with the disintegration processes of the following terms and then.",
                    "label": 0
                },
                {
                    "sent": "Yes, then we we get the discourse setting can see on the on the right side or then the scores that are achieved by this entity during the during this immigration process.",
                    "label": 0
                },
                {
                    "sent": "So on the left you have the confidence value that we calculated before the disintegration process.",
                    "label": 0
                },
                {
                    "sent": "And on the on the right you you see the scores that are achieved during the disambiguation process process.",
                    "label": 0
                },
                {
                    "sent": "All scores are ranged between zero and one, so at the end of the dissemination process we have two different two different confidence values or two different values that we can use to decide if this is probably correct the simulation.",
                    "label": 0
                },
                {
                    "sent": "Or not.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the benefits.",
                    "label": 0
                },
                {
                    "sent": "Off of the approach is that we begin that the simulation process within a context with the prospectively most correct term.",
                    "label": 0
                },
                {
                    "sent": "And after this immigration process we have two different scores or two different measurements to decide if we want to take into account this the same weighted term on this entity for the assignment or not.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we've evaluated our approach.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem with evaluating named entity mapping or word sense.",
                    "label": 0
                },
                {
                    "sent": "This immigration is that we need a ground truth.",
                    "label": 0
                },
                {
                    "sent": "And in this case we needed a Crown truth that represents different sources with different reliabilities, different text types and so on.",
                    "label": 0
                },
                {
                    "sent": "And to the best of our knowledge, we didn't find such a such a data set.",
                    "label": 0
                },
                {
                    "sent": "So we created one on our own.",
                    "label": 0
                },
                {
                    "sent": "We used video metadata of five Ted talks.",
                    "label": 1
                },
                {
                    "sent": "We did a scene cut detection on this and we identified 211 content based segments.",
                    "label": 0
                },
                {
                    "sent": "Overall there are 8 / 800 meta data items within this.",
                    "label": 0
                },
                {
                    "sent": "Within this data set and we identified.",
                    "label": 0
                },
                {
                    "sent": "Over 2500 entities in this data set so.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what the data set looks like.",
                    "label": 0
                },
                {
                    "sent": "Looks like we have the source information in the second column and textual information.",
                    "label": 0
                },
                {
                    "sent": "Then we have a video ID and the last column represents a segment ID so that you can assign the texture information to certain segments within a video.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what the groundtruth looks like.",
                    "label": 0
                },
                {
                    "sent": "We also have this the video ID, the segment ideas second column.",
                    "label": 0
                },
                {
                    "sent": "Then we have the identified entity which is at DB pedia entity in this case.",
                    "label": 0
                },
                {
                    "sent": "And then we also have the source information.",
                    "label": 0
                },
                {
                    "sent": "And you can download the data set and at this URL.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our result.",
                    "label": 0
                },
                {
                    "sent": "We compared our approach, which we call the Contag are two three different other approaches we.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Used a web service of DPS Spotlight.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Used Vicki Machine and at this point I want to thank cloud your Juliano who processed the data and we turned the analysis results to me.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we used a simple anyar.",
                    "label": 0
                },
                {
                    "sent": "It's and it's our own approach, but just not using the approach of ordering the metadata items according to the confidence value.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the contactor is already set as the approach that I just presented.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, especially on the on the sources that have a probably low confidence, we could achieve much better result.",
                    "label": 0
                },
                {
                    "sent": "For I will evaluated the our results according to the sources that are the 1st four rows and then we also evaluated according to the segments overall sources and over the video also overall sources.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "These are the results.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Beside these recurrent precision measures, we also had some further evaluation findings.",
                    "label": 1
                },
                {
                    "sent": "When we create a context for a for a metadata item, we have this in the best case we have these two values.",
                    "label": 0
                },
                {
                    "sent": "These two calculated scores.",
                    "label": 0
                },
                {
                    "sent": "The first one is the confidence score.",
                    "label": 0
                },
                {
                    "sent": "The Predis immigration score, and the 2nd order.",
                    "label": 0
                },
                {
                    "sent": "This immigration score is the one that achieved entity achieved during the disintegration score.",
                    "label": 0
                },
                {
                    "sent": "So now we can have.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A measure to decide if we take this into account for the context and use this item as a context item for this immigration process or not, and what we found out is that.",
                    "label": 0
                },
                {
                    "sent": "Items that are retrieved from sources with the lower confidence as a as an OCR are best December waited with with metadata items with a pretty high confidence predis immigration score, and for authoritative sources in text that's not so important to have high confidence is the disintegration score is is not so important as we found out for creating.",
                    "label": 0
                },
                {
                    "sent": "Offered I'm dynamically creating a context form for meta data item and what we also.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I found out is that we also mentioned that we use content based segments for the as context boundary for for the disambiguation process, and we evaluated this against a video based based approach so that we take the whole video as a context.",
                    "label": 0
                },
                {
                    "sent": "So the video context boundary is at the maximum and we found out that the segment base.",
                    "label": 0
                },
                {
                    "sent": "Approach is is better than in comparison to the video based approach.",
                    "label": 0
                },
                {
                    "sent": "Even though our videos from the datasets are very homogeneous because all the videos are have the same topic throughout all of the of the video.",
                    "label": 0
                },
                {
                    "sent": "But we we also that we achieve better results using just the segment's context boundary.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So contributions.",
                    "label": 0
                },
                {
                    "sent": "We are using contextual descriptions of video metadata to bring metadata in in a certain order to achieve better this immigration results on this.",
                    "label": 1
                },
                {
                    "sent": "Sometimes not so reliable information.",
                    "label": 0
                },
                {
                    "sent": "We introduced our context model which scores the video video metadata an.",
                    "label": 0
                },
                {
                    "sent": "As I already said, bring some into your order.",
                    "label": 0
                },
                {
                    "sent": "We VE?",
                    "label": 0
                },
                {
                    "sent": "We evaluated our approach on an data set that we created for this special purpose and as I have shown, we could could approve recall and precision, especially on the text information with the lower confidence.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So ongoing work is right now the waiting of single confidence chorus we also we already experienced that source diversity though the one where other sources have to confirm if this term is perspectively correct, it's a good.",
                    "label": 0
                },
                {
                    "sent": "It's a good measure to find out if if if we could take this as an assignment for the for the video search engine or not.",
                    "label": 0
                },
                {
                    "sent": "We also defined additional additional confidence scores.",
                    "label": 1
                },
                {
                    "sent": "For example, the number of tokens within this term.",
                    "label": 1
                },
                {
                    "sent": "And what we are working right now on is a negative context.",
                    "label": 0
                },
                {
                    "sent": "Scoring.",
                    "label": 0
                },
                {
                    "sent": "That means usually at this immigration process takes into account information from the context and scores an entity candidate account according to the positive hints within this context.",
                    "label": 0
                },
                {
                    "sent": "But we don't take into account negative hint.",
                    "label": 0
                },
                {
                    "sent": "So what we are right now working on is kind of a penalty for for entity candidates that are linked.",
                    "label": 1
                },
                {
                    "sent": "Or that are related to a negative context that is created.",
                    "label": 0
                },
                {
                    "sent": "Also dynamically.",
                    "label": 0
                },
                {
                    "sent": "We use different knowledge bases for this approach.",
                    "label": 1
                },
                {
                    "sent": "We use DB pedia but we also have project with.",
                    "label": 0
                },
                {
                    "sent": "With the German authoritie files for example.",
                    "label": 0
                },
                {
                    "sent": "And what we also want to do is the comprehension of the user context for the non authoritative metadata and also the authoritative metadata you can take into account information that we can get from the user profile that you that can be used for the context and maybe improves disambiguation.",
                    "label": 0
                },
                {
                    "sent": "This immigration process.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "So thanks to him very good talk.",
                    "label": 0
                },
                {
                    "sent": "There is just one confusion I have because you talk you.",
                    "label": 0
                },
                {
                    "sent": "You have two sub tasks.",
                    "label": 0
                },
                {
                    "sent": "You have the new task, the recognition of entities and the correct typing and you have the nail task.",
                    "label": 0
                },
                {
                    "sent": "The disambiguation?",
                    "label": 0
                },
                {
                    "sent": "So the entity linking.",
                    "label": 0
                },
                {
                    "sent": "We've in this case the PRI, so that the figures you show for the comparisons what you consider as As for the precision, recall and F1 is if the entity has been correctly recognized type and disseminated right.",
                    "label": 0
                },
                {
                    "sent": "Type we believe this type of this Type 2 to the NER Tiger.",
                    "label": 0
                },
                {
                    "sent": "We just take that as a given.",
                    "label": 0
                },
                {
                    "sent": "So you evaluate the nail parts to disagree.",
                    "label": 0
                },
                {
                    "sent": "Disambiguation just said, yeah, there's just this immigration part, where the ground truth consists of the December rated entities and we check if this entity is is this immigrated correctly or not OK, so my question is you show that we've discovering and the fact that you give.",
                    "label": 0
                },
                {
                    "sent": "Importance to different metadata items.",
                    "label": 0
                },
                {
                    "sent": "You can then improve the design with the context of disambiguation part, but do you know if this has also an influence on the recognition part?",
                    "label": 0
                },
                {
                    "sent": "So whether you will be able to recognize more or less good entities and get less false alarms specifically.",
                    "label": 0
                },
                {
                    "sent": "Tell you.",
                    "label": 0
                },
                {
                    "sent": "OK, we didn't evaluate then because do and somehow you have to rely on the ground truth at at this at this point, but we think about this week because of the ground.",
                    "label": 0
                },
                {
                    "sent": "Truth is you have the boundary spot for the terms in the ground truth and we have to think about.",
                    "label": 0
                },
                {
                    "sent": "Using maybe other ground truth or other annotations to to show if this is this correctly annotated or not.",
                    "label": 0
                },
                {
                    "sent": "You explained that you iteratively basically go through with this application scores based on the confidence values you obtained.",
                    "label": 0
                },
                {
                    "sent": "So would it also be an option to like first compute all the dislocations question and then refine all of them in one step instead of doing the iterative approach you described?",
                    "label": 0
                },
                {
                    "sent": "If I understood it correctly?",
                    "label": 0
                },
                {
                    "sent": "1st first this immigrate to terms and then order them and then optimize the scores of all of them.",
                    "label": 0
                },
                {
                    "sent": "Basically OK.",
                    "label": 0
                },
                {
                    "sent": "I think that the approach relies on the assumption that we start with the most correct with the most correct information that we have, and so the process then takes into account already disseminated entity.",
                    "label": 0
                },
                {
                    "sent": "If we have already disintegrated entity.",
                    "label": 0
                },
                {
                    "sent": "This strengthens kind of the context and then it's influenced the influential.",
                    "label": 0
                },
                {
                    "sent": "Part of this of this entity is much higher than just a term that is not disseminated so far, so the assumption is that we start with the most correct one and not in in a random order.",
                    "label": 0
                },
                {
                    "sent": "OK, does this answer your question?",
                    "label": 0
                },
                {
                    "sent": "Yes, I think we can also talk further offline OK?",
                    "label": 0
                }
            ]
        }
    }
}