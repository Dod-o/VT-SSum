{
    "id": "didlt5wdzqfnjcxiu55dymantjewn2uy",
    "title": "Measuring the Quality of Multi-document Cluster Headlines",
    "info": {
        "author": [
            "Frank Van Kesteren, University of Twente"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "July 2006",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/iiia06_kesteren_mqmdc/",
    "segmentation": [
        [
            "Come to this session for today so we have two calls, the first of which would be by Frank Van Kesteren and will be about measuring the quality of multi documents.",
            "Cluster headlines.",
            "Hello.",
            "I did this research as part of my internship at.",
            "You know, together with Vessel Cry also mentioned."
        ],
        [
            "What will I tell?",
            "First, we'll give you some background on this research.",
            "I will just mean that I'll explain my internship.",
            "Actually, let me give some motivation for this.",
            "The rest of this experiment.",
            "What does the experimental setup mode with my resource and the conclusion sense on future?"
        ],
        [
            "Work.",
            "OK, first backgrounds.",
            "The research was part of a larger research project called Novalis.",
            "Novalis is a multifaceted information browser, which means that it consists of several types of documents.",
            "For example newspaper articles and annotated videos.",
            "All these documents are clustered automatically by topic and some extra metadata is generated for it.",
            "For example, proper names are extracted, keywords bigrams, that sort of things.",
            "Twitter you can search novelist using an office browser and.",
            "Yeah, search for keywords and you were presented with a list of the clusters and the classes are represented by their headline."
        ],
        [
            "And that is why headline is important, because a good headline enables an efficient navigation in case of the.",
            "This browser.",
            "So.",
            "But the headlines, do we use?",
            "Well?",
            "We have two options.",
            "The first option we actually used before was a list of keywords and bigrams.",
            "Extracted from the cluster, so this headline gives a lot of information because, yeah, they sort of most important words in the documents.",
            "However, our opinion is that it's not really clear what it is about.",
            "Still you got those words, but not the relations between them.",
            "For example, after Liverpool yadda yadda Cruyff and Surprising 5 one you expect it's about football game but.",
            "Is not really sure, so the alternative is well formed sentences.",
            "So that's the thing.",
            "You can see there.",
            "But this gives the problem of course that you have to generate death."
        ],
        [
            "And there are several options.",
            "Had to do that at.",
            "You know, we experimented with several methods.",
            "Before I explain them.",
            "For before we started running these methods, first we took all the documents in the clusters, all the sentences and ordered the sentences on relevance.",
            "So the first sentence is most salient to the cluster.",
            "OK, the method we tried was first.",
            "Yeah, for completeness we included the old method of just listing the.",
            "Keywords and bigrams.",
            "And the second option is the non face selection from the list of sentences or the sentence we took the first 5 sentences or the experiment that.",
            "Extracted all the noun phrases and the best non traders were selected on based off the number of keywords that were in there.",
            "Another option not selecting the best document headline.",
            "All the documents in a cluster.",
            "Her most of the times from newspaper articles and those sort of things.",
            "So they had already and headline title.",
            "So one option was just to pick one of these titles and.",
            "Use that test the headline for the entire cluster.",
            "Ford methods we tried plus compressing the most salient sentence.",
            "So pick the first sentence from the list and remove an important part of us.",
            "Just a rule based approach.",
            "Yeah.",
            "In by which we try to make a sentence shorter.",
            "An last options we tried.",
            "I must change the cluster.",
            "What I mean by that is.",
            "Generation of the clusters.",
            "Automatically and it happened a lot that there are some documents that did not completely belong to the cluster, so we try to re cluster a cluster.",
            "So we kept only the most important documents.",
            "And try to extract the headline from these documents.",
            "This didn't actually work very well because the ordering of the sentence is already solved.",
            "The problem actually of the important documents."
        ],
        [
            "From these methods manual, elevation detected that the third method was the best.",
            "Actually her selecting a document headline from.",
            "Twister.",
            "Note that this means that we have no influence on the length of the headline.",
            "That line is just one of the titles that an author gave to his document, so we cannot implement them."
        ],
        [
            "So in itself is not very interesting, but we also did automatic activation use Rouge one recall.",
            "We do use Russia because that was standard evaluation, used a lot for measuring the quality of summaries and becausw headline can be seen as an extremely short summary before we could use Rolshoven recall as well for our problem.",
            "Well, how did we do that?",
            "We picked 100 clusters and manually created a headline for them the models.",
            "And.",
            "Breanne on an average of these clusters 60 methods or variants of the one I just mentioned.",
            "And after that we manually evaluated this by giving them a score from one to five and automatically using the Russian recall."
        ],
        [
            "So what did you find?",
            "I stopped the manual evaluation, gave.",
            "#3 the meta tree as the best option, so selecting the best document headline but recall gave us the noun phrase selection as the best option.",
            "Well, in itself, that doesn't say much, but to be also.",
            "Calculated the correlation between them and there's a 0.21 is very low.",
            "Yeah, well."
        ],
        [
            "We wanted of course, Nope.",
            "How did this happen?",
            "Why?",
            "So I have a hypothesis was that Russia one recall does not work well with headlines of different lengths.",
            "Longer headline gets better recall, of course.",
            "So we wanted to try to solutions to test this hypothesis was correct the first month experiment with Jean Precision instead of recall.",
            "Tradition should negate the length of the sentence, so we thought it might help.",
            "And the second option was implementing a penalty for Russian recall for the length of the headline."
        ],
        [
            "Experimental setup was that we took a subset of the 100 clusters of 10 disk clusters.",
            "And for every ten of these clusters we ask 5 persons to create a headline.",
            "Emmanuel Headline we use five models here to solve the problem of variability in the headline.",
            "You can think of that one person.",
            "Just use different source.",
            "We also asked 5 these five annotators to manually get headlines of the methods we used.",
            "And this results in a high correlation between these annotators.",
            "So before that, this was a reliable source.",
            "Next, we determined the correlation between these average manual quality scores and delicious course.",
            "In this case, Russia precision and the Russian recall with."
        ],
        [
            "Penalty.",
            "So what was the penalty we applied?",
            "It was modeled after the penalties used in blue shirt blue.",
            "Bruce is based on blue.",
            "Reply brief penalty when the generated headline was shorter than the shortest models, so one of the five models shorted in that one.",
            "And link penalty similar if the generated line was longer then along this model."
        ],
        [
            "Well, how do they calculate it?",
            "We just copied them from blue actually, so it's not really.",
            "Thought about but important here is that we used the sum of the length of all the generated headlines for one method.",
            "So if one generated headline was very short, this doesn't.",
            "Great absurd penalty for that.",
            "Cluster.",
            "However, we use the same over the length of the shortest model for the brevity penalty, and of course the length of the longest models for the length penalty."
        ],
        [
            "Further, we also, according to our hypothesis, was the sentence length important.",
            "So we also determine the correlation between the sentence length Andrew Scores."
        ],
        [
            "Well, what about our results?",
            "What is the incentive?",
            "Here is a list of the activation methods and the correlation with the manual quality and the sentence length.",
            "And 1st row.",
            "Is the original set up?",
            "And you see the local correlation there at a high correlation with the sentence length we want to lower the sentence length.",
            "Increase the correlation with the quality."
        ],
        [
            "Every time I look at the precision, you see that the correlation with the manual quality isn't it increased.",
            "However, the sentence length is, yeah, it's negative, but it's still a high correlation and it's negative cause longer sentence.",
            "Get the lower blue score."
        ],
        [
            "When looking at the brevity penalty, you see that there's actually little change.",
            "And this was the cause.",
            "The brief dependence is only applied when the generated headline is shorter than the shortest model.",
            "But we found that it never almost never happened 'cause the manual headlines were already fairly short, so not much change there."
        ],
        [
            "The final shot is the recall one plus.",
            "Link penalty.",
            "What we see here is actually what we want.",
            "Correlation with the manual quality compared with the original.",
            "Recall increased some double and the correlation with the sentence length is almost 0, so I think this is the way to go."
        ],
        [
            "So what are the conclusions?",
            "Bridges that position improves quality correlation between the manual and automatically.",
            "Between manual and automatic activation, however, the correlation with the length is just assign anyone recall and a length penalty doubles the correlation and minimize.",
            "The coloration of length."
        ],
        [
            "However, is a higher score, as you could see, it's still a weak correlation, so further research research should improve use of this penalty score."
        ],
        [
            "That's also presentation or any questions.",
            "There's plenty of time for questions.",
            "So I actually have a question.",
            "In machine translation there is the same issue of automatic measures or the quality of the translation.",
            "And there is a very strong difference between the correlation coefficients that one gets at the sentence level, which are very low.",
            "Basically in the same range as the one you're showing, and the correlation coefficients that one gets at the system level.",
            "That is, when the score is used to compare different systems on a large number of sentences, and this one can be very high in the high.",
            "90s OK. Did you do I need any?",
            "No, we only corrected correlation with the manual evaluation, but not with other systems like what you know I mean.",
            "The correlation between.",
            "The average score given not on a single headline, but on a whole set of headlines in order to rank different sentences have gains.",
            "Yeah, a single number reference.",
            "Yeah we did that.",
            "I believe it don't have the numbers here.",
            "These were higher but.",
            "Yeah, they thought it didn't say really much because you want to check one headline.",
            "Normally you want to know the quality of 1 headline.",
            "I see, so that's what we wanted to try.",
            "We wanted to see if there was a method to.",
            "Find out that information.",
            "Specific reason to just take your experiments to lose 1 only?",
            "After do the similar things which used to.",
            "Yeah, I know there's the time.",
            "We can also explain that visual etc.",
            "Any other questions?",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come to this session for today so we have two calls, the first of which would be by Frank Van Kesteren and will be about measuring the quality of multi documents.",
                    "label": 1
                },
                {
                    "sent": "Cluster headlines.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "I did this research as part of my internship at.",
                    "label": 0
                },
                {
                    "sent": "You know, together with Vessel Cry also mentioned.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What will I tell?",
                    "label": 0
                },
                {
                    "sent": "First, we'll give you some background on this research.",
                    "label": 0
                },
                {
                    "sent": "I will just mean that I'll explain my internship.",
                    "label": 0
                },
                {
                    "sent": "Actually, let me give some motivation for this.",
                    "label": 0
                },
                {
                    "sent": "The rest of this experiment.",
                    "label": 0
                },
                {
                    "sent": "What does the experimental setup mode with my resource and the conclusion sense on future?",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "OK, first backgrounds.",
                    "label": 0
                },
                {
                    "sent": "The research was part of a larger research project called Novalis.",
                    "label": 0
                },
                {
                    "sent": "Novalis is a multifaceted information browser, which means that it consists of several types of documents.",
                    "label": 1
                },
                {
                    "sent": "For example newspaper articles and annotated videos.",
                    "label": 0
                },
                {
                    "sent": "All these documents are clustered automatically by topic and some extra metadata is generated for it.",
                    "label": 0
                },
                {
                    "sent": "For example, proper names are extracted, keywords bigrams, that sort of things.",
                    "label": 0
                },
                {
                    "sent": "Twitter you can search novelist using an office browser and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, search for keywords and you were presented with a list of the clusters and the classes are represented by their headline.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is why headline is important, because a good headline enables an efficient navigation in case of the.",
                    "label": 0
                },
                {
                    "sent": "This browser.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But the headlines, do we use?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "We have two options.",
                    "label": 0
                },
                {
                    "sent": "The first option we actually used before was a list of keywords and bigrams.",
                    "label": 1
                },
                {
                    "sent": "Extracted from the cluster, so this headline gives a lot of information because, yeah, they sort of most important words in the documents.",
                    "label": 0
                },
                {
                    "sent": "However, our opinion is that it's not really clear what it is about.",
                    "label": 0
                },
                {
                    "sent": "Still you got those words, but not the relations between them.",
                    "label": 0
                },
                {
                    "sent": "For example, after Liverpool yadda yadda Cruyff and Surprising 5 one you expect it's about football game but.",
                    "label": 1
                },
                {
                    "sent": "Is not really sure, so the alternative is well formed sentences.",
                    "label": 0
                },
                {
                    "sent": "So that's the thing.",
                    "label": 0
                },
                {
                    "sent": "You can see there.",
                    "label": 0
                },
                {
                    "sent": "But this gives the problem of course that you have to generate death.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are several options.",
                    "label": 0
                },
                {
                    "sent": "Had to do that at.",
                    "label": 0
                },
                {
                    "sent": "You know, we experimented with several methods.",
                    "label": 0
                },
                {
                    "sent": "Before I explain them.",
                    "label": 0
                },
                {
                    "sent": "For before we started running these methods, first we took all the documents in the clusters, all the sentences and ordered the sentences on relevance.",
                    "label": 0
                },
                {
                    "sent": "So the first sentence is most salient to the cluster.",
                    "label": 0
                },
                {
                    "sent": "OK, the method we tried was first.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for completeness we included the old method of just listing the.",
                    "label": 0
                },
                {
                    "sent": "Keywords and bigrams.",
                    "label": 0
                },
                {
                    "sent": "And the second option is the non face selection from the list of sentences or the sentence we took the first 5 sentences or the experiment that.",
                    "label": 0
                },
                {
                    "sent": "Extracted all the noun phrases and the best non traders were selected on based off the number of keywords that were in there.",
                    "label": 0
                },
                {
                    "sent": "Another option not selecting the best document headline.",
                    "label": 1
                },
                {
                    "sent": "All the documents in a cluster.",
                    "label": 0
                },
                {
                    "sent": "Her most of the times from newspaper articles and those sort of things.",
                    "label": 0
                },
                {
                    "sent": "So they had already and headline title.",
                    "label": 0
                },
                {
                    "sent": "So one option was just to pick one of these titles and.",
                    "label": 0
                },
                {
                    "sent": "Use that test the headline for the entire cluster.",
                    "label": 1
                },
                {
                    "sent": "Ford methods we tried plus compressing the most salient sentence.",
                    "label": 0
                },
                {
                    "sent": "So pick the first sentence from the list and remove an important part of us.",
                    "label": 0
                },
                {
                    "sent": "Just a rule based approach.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "In by which we try to make a sentence shorter.",
                    "label": 0
                },
                {
                    "sent": "An last options we tried.",
                    "label": 0
                },
                {
                    "sent": "I must change the cluster.",
                    "label": 0
                },
                {
                    "sent": "What I mean by that is.",
                    "label": 0
                },
                {
                    "sent": "Generation of the clusters.",
                    "label": 0
                },
                {
                    "sent": "Automatically and it happened a lot that there are some documents that did not completely belong to the cluster, so we try to re cluster a cluster.",
                    "label": 0
                },
                {
                    "sent": "So we kept only the most important documents.",
                    "label": 0
                },
                {
                    "sent": "And try to extract the headline from these documents.",
                    "label": 0
                },
                {
                    "sent": "This didn't actually work very well because the ordering of the sentence is already solved.",
                    "label": 0
                },
                {
                    "sent": "The problem actually of the important documents.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From these methods manual, elevation detected that the third method was the best.",
                    "label": 0
                },
                {
                    "sent": "Actually her selecting a document headline from.",
                    "label": 0
                },
                {
                    "sent": "Twister.",
                    "label": 0
                },
                {
                    "sent": "Note that this means that we have no influence on the length of the headline.",
                    "label": 0
                },
                {
                    "sent": "That line is just one of the titles that an author gave to his document, so we cannot implement them.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in itself is not very interesting, but we also did automatic activation use Rouge one recall.",
                    "label": 0
                },
                {
                    "sent": "We do use Russia because that was standard evaluation, used a lot for measuring the quality of summaries and becausw headline can be seen as an extremely short summary before we could use Rolshoven recall as well for our problem.",
                    "label": 0
                },
                {
                    "sent": "Well, how did we do that?",
                    "label": 0
                },
                {
                    "sent": "We picked 100 clusters and manually created a headline for them the models.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Breanne on an average of these clusters 60 methods or variants of the one I just mentioned.",
                    "label": 1
                },
                {
                    "sent": "And after that we manually evaluated this by giving them a score from one to five and automatically using the Russian recall.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what did you find?",
                    "label": 0
                },
                {
                    "sent": "I stopped the manual evaluation, gave.",
                    "label": 0
                },
                {
                    "sent": "#3 the meta tree as the best option, so selecting the best document headline but recall gave us the noun phrase selection as the best option.",
                    "label": 1
                },
                {
                    "sent": "Well, in itself, that doesn't say much, but to be also.",
                    "label": 0
                },
                {
                    "sent": "Calculated the correlation between them and there's a 0.21 is very low.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We wanted of course, Nope.",
                    "label": 0
                },
                {
                    "sent": "How did this happen?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "So I have a hypothesis was that Russia one recall does not work well with headlines of different lengths.",
                    "label": 1
                },
                {
                    "sent": "Longer headline gets better recall, of course.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to try to solutions to test this hypothesis was correct the first month experiment with Jean Precision instead of recall.",
                    "label": 0
                },
                {
                    "sent": "Tradition should negate the length of the sentence, so we thought it might help.",
                    "label": 1
                },
                {
                    "sent": "And the second option was implementing a penalty for Russian recall for the length of the headline.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experimental setup was that we took a subset of the 100 clusters of 10 disk clusters.",
                    "label": 1
                },
                {
                    "sent": "And for every ten of these clusters we ask 5 persons to create a headline.",
                    "label": 0
                },
                {
                    "sent": "Emmanuel Headline we use five models here to solve the problem of variability in the headline.",
                    "label": 0
                },
                {
                    "sent": "You can think of that one person.",
                    "label": 0
                },
                {
                    "sent": "Just use different source.",
                    "label": 0
                },
                {
                    "sent": "We also asked 5 these five annotators to manually get headlines of the methods we used.",
                    "label": 1
                },
                {
                    "sent": "And this results in a high correlation between these annotators.",
                    "label": 1
                },
                {
                    "sent": "So before that, this was a reliable source.",
                    "label": 0
                },
                {
                    "sent": "Next, we determined the correlation between these average manual quality scores and delicious course.",
                    "label": 0
                },
                {
                    "sent": "In this case, Russia precision and the Russian recall with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Penalty.",
                    "label": 0
                },
                {
                    "sent": "So what was the penalty we applied?",
                    "label": 0
                },
                {
                    "sent": "It was modeled after the penalties used in blue shirt blue.",
                    "label": 1
                },
                {
                    "sent": "Bruce is based on blue.",
                    "label": 0
                },
                {
                    "sent": "Reply brief penalty when the generated headline was shorter than the shortest models, so one of the five models shorted in that one.",
                    "label": 1
                },
                {
                    "sent": "And link penalty similar if the generated line was longer then along this model.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, how do they calculate it?",
                    "label": 0
                },
                {
                    "sent": "We just copied them from blue actually, so it's not really.",
                    "label": 0
                },
                {
                    "sent": "Thought about but important here is that we used the sum of the length of all the generated headlines for one method.",
                    "label": 1
                },
                {
                    "sent": "So if one generated headline was very short, this doesn't.",
                    "label": 0
                },
                {
                    "sent": "Great absurd penalty for that.",
                    "label": 0
                },
                {
                    "sent": "Cluster.",
                    "label": 1
                },
                {
                    "sent": "However, we use the same over the length of the shortest model for the brevity penalty, and of course the length of the longest models for the length penalty.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Further, we also, according to our hypothesis, was the sentence length important.",
                    "label": 0
                },
                {
                    "sent": "So we also determine the correlation between the sentence length Andrew Scores.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, what about our results?",
                    "label": 0
                },
                {
                    "sent": "What is the incentive?",
                    "label": 0
                },
                {
                    "sent": "Here is a list of the activation methods and the correlation with the manual quality and the sentence length.",
                    "label": 1
                },
                {
                    "sent": "And 1st row.",
                    "label": 0
                },
                {
                    "sent": "Is the original set up?",
                    "label": 0
                },
                {
                    "sent": "And you see the local correlation there at a high correlation with the sentence length we want to lower the sentence length.",
                    "label": 0
                },
                {
                    "sent": "Increase the correlation with the quality.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Every time I look at the precision, you see that the correlation with the manual quality isn't it increased.",
                    "label": 1
                },
                {
                    "sent": "However, the sentence length is, yeah, it's negative, but it's still a high correlation and it's negative cause longer sentence.",
                    "label": 0
                },
                {
                    "sent": "Get the lower blue score.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When looking at the brevity penalty, you see that there's actually little change.",
                    "label": 0
                },
                {
                    "sent": "And this was the cause.",
                    "label": 0
                },
                {
                    "sent": "The brief dependence is only applied when the generated headline is shorter than the shortest model.",
                    "label": 0
                },
                {
                    "sent": "But we found that it never almost never happened 'cause the manual headlines were already fairly short, so not much change there.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The final shot is the recall one plus.",
                    "label": 0
                },
                {
                    "sent": "Link penalty.",
                    "label": 0
                },
                {
                    "sent": "What we see here is actually what we want.",
                    "label": 0
                },
                {
                    "sent": "Correlation with the manual quality compared with the original.",
                    "label": 1
                },
                {
                    "sent": "Recall increased some double and the correlation with the sentence length is almost 0, so I think this is the way to go.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the conclusions?",
                    "label": 0
                },
                {
                    "sent": "Bridges that position improves quality correlation between the manual and automatically.",
                    "label": 0
                },
                {
                    "sent": "Between manual and automatic activation, however, the correlation with the length is just assign anyone recall and a length penalty doubles the correlation and minimize.",
                    "label": 1
                },
                {
                    "sent": "The coloration of length.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, is a higher score, as you could see, it's still a weak correlation, so further research research should improve use of this penalty score.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's also presentation or any questions.",
                    "label": 0
                },
                {
                    "sent": "There's plenty of time for questions.",
                    "label": 0
                },
                {
                    "sent": "So I actually have a question.",
                    "label": 0
                },
                {
                    "sent": "In machine translation there is the same issue of automatic measures or the quality of the translation.",
                    "label": 0
                },
                {
                    "sent": "And there is a very strong difference between the correlation coefficients that one gets at the sentence level, which are very low.",
                    "label": 0
                },
                {
                    "sent": "Basically in the same range as the one you're showing, and the correlation coefficients that one gets at the system level.",
                    "label": 0
                },
                {
                    "sent": "That is, when the score is used to compare different systems on a large number of sentences, and this one can be very high in the high.",
                    "label": 0
                },
                {
                    "sent": "90s OK. Did you do I need any?",
                    "label": 0
                },
                {
                    "sent": "No, we only corrected correlation with the manual evaluation, but not with other systems like what you know I mean.",
                    "label": 0
                },
                {
                    "sent": "The correlation between.",
                    "label": 0
                },
                {
                    "sent": "The average score given not on a single headline, but on a whole set of headlines in order to rank different sentences have gains.",
                    "label": 0
                },
                {
                    "sent": "Yeah, a single number reference.",
                    "label": 0
                },
                {
                    "sent": "Yeah we did that.",
                    "label": 0
                },
                {
                    "sent": "I believe it don't have the numbers here.",
                    "label": 0
                },
                {
                    "sent": "These were higher but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, they thought it didn't say really much because you want to check one headline.",
                    "label": 0
                },
                {
                    "sent": "Normally you want to know the quality of 1 headline.",
                    "label": 0
                },
                {
                    "sent": "I see, so that's what we wanted to try.",
                    "label": 0
                },
                {
                    "sent": "We wanted to see if there was a method to.",
                    "label": 0
                },
                {
                    "sent": "Find out that information.",
                    "label": 0
                },
                {
                    "sent": "Specific reason to just take your experiments to lose 1 only?",
                    "label": 0
                },
                {
                    "sent": "After do the similar things which used to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I know there's the time.",
                    "label": 0
                },
                {
                    "sent": "We can also explain that visual etc.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}