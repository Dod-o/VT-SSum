{
    "id": "gcaov5rfreynvni3lv2rtsgmos7npr3o",
    "title": "How much structure do we see in noise (a topological perspective)?",
    "info": {
        "author": [
            "Primo\u017e \u0160kraba, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "March 10, 2016",
        "recorded": "March 2016",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/solomon_skraba_structure_in_noise/",
    "segmentation": [
        [
            "This talk, or rather the seminar, is basically too.",
            "Conveys some of the ideas that I've been working on.",
            "Let's say now for the last two or three years, the ideas and the problems behind this kind of go back further, but ultimately they ask.",
            "Kind of very standard questions from probability and statistics as applied to kind of.",
            "A topological perspective, which I'll describe and essentially the core ideas.",
            "How can we start to look at statistics probability?",
            "Things like this on what are essentially combinatorial objects.",
            "They may come from some sort of continuous space, but ultimately they're going to be common tutorial and we're going to see exactly what this means."
        ],
        [
            "OK, so much of what I'll be describing is joint work with Matt Scale, who's at Ohio State and Omar Bobrosky, who's postdoc at Duke, but.",
            "Questions along this line are also with Yogesh, who is probabilist from India and basically we've been asking other questions that I won't kind of cover in this seminar, but kind of our upcoming papers."
        ],
        [
            "OK, so.",
            "Ultimately, I think in data analysis in general.",
            "You know, it really depends on what kind of data we're looking at, but today I think we're going to concentrate mostly on spatial data, or rather geometric data, depending on how you want to look at it and when we're doing data analysis.",
            "Ultimately, the question we're asking is.",
            "We're looking for some sort of structure in this data, right?",
            "So in this case you might say, well, maybe there are four clusters here, and maybe you would say there's more.",
            "Maybe you'd say there's less, but actually in this case I can tell you there are actually 4 because I generated these points using something called a materne cluster model, right?",
            "And you know.",
            "There's plenty of techniques out there that given this data in the plane, would return these four clusters, But so this is one form of structure that data can have, but it can also have higher dimensional structure, and that's actually what we're going to talk about."
        ],
        [
            "Today, so kind of the prototypical example I like is this kind of data, and if I ask you what this looks like, hopefully you would say that it's a noisy circle, right?",
            "So that it's, you know.",
            "And actually, that's the way I generated this data.",
            "I took a circle and I ran, added random noise, and this is kind of what it gets, right?",
            "So if I were to give you data like this, hopefully you would say, come back or whatever method you would use would come back and say, OK, this actually looks like a noisy circle.",
            "And you know, I think everyone here has seen clustering.",
            "Kind of it's.",
            "I would say actually everywhere today, but you know these kind of higher dimensional models or maybe a little less common, but I would actually argue that these types of structures are just as important as kind of these, as these cluster models and here's kind of a."
        ],
        [
            "Prototypical example here.",
            "I have rainfall data from Nottingham Castle over 30 years.",
            "Forget about the index, and essentially what I did is.",
            "I took each point and its previous point and use these two things as.",
            "As a as coordinates and I plotted them right and you can see well it looks like a circle, and that's not terribly surprising because, well, you know this is periodic, and if I were to look at something periodic, it should roughly look like a circle.",
            "So these are kind of large scale structures that we would hope to find given this data, but that's not what this seminar is about.",
            "How to find these things?",
            "This actually asks the converse question.",
            "Right so."
        ],
        [
            "Let's say I don't have any structure right?",
            "Let's say I just have noise.",
            "And I apply these same techniques.",
            "They're still going to give me an answer and so I need some form of null hypothesis in order to be able to distinguish between what's real structure and what's noise, right?",
            "So here are two point processes, or rather just to point samples, and the question is which one is more random right?",
            "Is is there any structure here or is there any structure here right?",
            "And we may be actually tempted to say that the one on the right is more random, whereas strictly, probabilistically speaking.",
            "This is actually more random.",
            "This is generated using something called apasan process, which is I would say are kind of.",
            "Most random model that we have, right?",
            "If I were just to say I have some random points.",
            "This is the model I would use, whereas there what I did was I took a grid right which is something very very structured and just perturbed it right.",
            "But if we just looked at it, we might be tempted to say Oh well, you know that's actually more random, so you know.",
            "Just looking at these at these points is not always the best way to kind of measure randomness, right?"
        ],
        [
            "OK, so using this kind of completely random points, there's actually two different ways of slightly slightly different ways of actually generating these points are two different models.",
            "The first one is called the Bernoulli model, and here we choose endpoints and throw them uniformly into this thing, right?",
            "So I have a bag of endpoints and I just throw them at the square and wherever they land, they land.",
            "Usually we use something that's called Poisson, which is a little easier to work with.",
            "Where basically the number of points isn't exact but is distributed with some distribution, usually exponential, and there are various technical reasons why that's easier to use, but generally anything that's true in person is true in Bernoulli and vice versa.",
            "I mean, there's up to epsilon.",
            "It's always kind of true.",
            "OK, so."
        ],
        [
            "As Marco said, the motivation behind a lot of this work is that we want to look for these structures.",
            "These topological structures and topological structures generally.",
            "Well, you know the first question would be what is the?"
        ],
        [
            "Elogy Welt apologies.",
            "This mathematical study of how spaces are connected and we've already seen 2 examples of this in previous examples, right?",
            "So the first one is clusters, which are just components, so this is what's called 0 dimensional homology, which counts the number of components.",
            "We've also seen 1 dimensional homology which counts the number of holes of space as, so if it looks like an annulus, it has one component in one hole, right?",
            "But it might have several holes and.",
            "Also there's higher dimensional versions of this, right?",
            "So a sphere has 2 dimensional homology because it encloses a space, right?",
            "Or a Taurus is also kind of encloses a space and then you have 3 dimensional 4 dimensional and so forth, even though those are things that we can't really draw.",
            "So for the most part, we're going to concentrate today on one dimensional homology.",
            "So how many holes does a space have?",
            "But before we do that, let's go back to take a step back and look."
        ],
        [
            "It's components, right?",
            "So the study of noise.",
            "Let's say you know how much structure and noise is actually goes back probably 2030 years, and is in the form of random graphs, right?",
            "So there's many different ways to make random graphs.",
            "We're going to concentrate today on geometric random graphs."
        ],
        [
            "Which is I take a pass on point process, right?",
            "So I've, you know, throw down these points.",
            "They land wherever they land and then I'm going to build a graph based on them and the way I'm going to do it is I'm just going to look at the distances between the points and if they are within a certain radius then I'm going to connect them right.",
            "So each time I throw down points.",
            "Obviously I'm going to get a different graph.",
            "OK, so kind of what?"
        ],
        [
            "Formal definition is, well, a random geometric graph has two parameters right.",
            "The number of points and the radius that you're going to build it at.",
            "And you know, basically given these two things, an instantiation, we can build our graph.",
            "Now, one thing that we always well, not always, but usually the first thing we do is we make the radius right.",
            "At what scale we build this, we make it a function of the number of points, and then when we do our analysis, we let the number of points go to Infinity, which obviously in real life we never have an infinite amount of data.",
            "But in this case we can actually do the analysis, whereas for finite N. Things become much, much messier.",
            "OK."
        ],
        [
            "So there's a classical result, so let's say this is the 1st result on connectivity, right?",
            "So the first thing that you might ask is, well, how many components does this graph have at some R?",
            "And maybe the second question you ask is when do I only have one component right?",
            "When is this graph completely connected?",
            "So there's this very classical result by Penrose that says that if you choose R, something like log in over North.",
            "Right?",
            "Plus just a little bit.",
            "It's almost surely connected, right?",
            "The probability of you being connected goes to one very, very quickly as you as you make see bigger and bigger and bigger, right?",
            "So you're just adding a little bit of a constant at the end.",
            "You go a little bit past log North over North and it becomes connected with probability one.",
            "OK, so this is now probably I don't know 20 years old this result people have looked at other models with graphs.",
            "There's a lot of results in a lot of work.",
            "Also in let's say under the name.",
            "Percolation it also comes under a bunch of other names and people understand this.",
            "Connectivity quite well, but you know, as I said before, we're not just interested in components were interested in these higher dimensional things.",
            "So like the number of holes and this doesn't really tell us anything about the number of holes.",
            "First of all, if we even want to talk about these things, we need to go beyond a graph."
        ],
        [
            "We need to go to what are called simplicial complexes, and these are just higher dimensional analogs of graph, so you know if we have zero in one dimension, we have vertices and edges.",
            "That's a graph.",
            "If we add triangles, then, then we have a 2 dimensional simplicial complex, a 3 dimensional thing would be a tetrahedra, and then again, as before you have.",
            "Higher and higher dimensional things, right?",
            "So since we're going to be interested in holes, we have to go up to triangles, right?",
            "Because?",
            "Holes are going to be kind of defined by things that aren't filled in right, and I can."
        ],
        [
            "Do the same thing.",
            "I can put my points at random.",
            "I can choose a radius and I build my graph and then for some of the triangles I build them.",
            "I I put in the triangles and then I can start to ask.",
            "Oh look, you know, here's a whole.",
            "There's a whole kind of here.",
            "There's a bunch of different holes here, right?",
            "So I can ask about, well, you know how many holes are there, for example?"
        ],
        [
            "OK, but how do I actually decide to fill in the triangle?",
            "Well, that's there are two different ways.",
            "One is called a check complex.",
            "One is called the RIPS complex rips.",
            "Complex is actually easier to do in some sense because we just build our graph and then every time there are three edges arranged in a triangle, we put it in the check.",
            "Complex is a little more complicated, but not much.",
            "It's what it says is, well, I'm going to look at these balls of radius R around each point.",
            "And the graph that I described before is just the intersection graph, which means that if 2 balls intersect, I put the edge in.",
            "And by analogy I put in triangles when 3 balls intersect.",
            "So here we have.",
            "Here we have a triangle 'cause these three balls intersect, and here we don't because there's no intersection, so you know why we do it this way well.",
            "There's a variety of reasons, but ultimately you can just think of it as just kind of a generative process to get to some random space.",
            "OK, so you know this also isn't a completely new problem, people."
        ],
        [
            "I have looked at it so for the number of holes mat Cal.",
            "Basically I guess five years ago or so looked at this and prove the following results that says that OK if I have if my radius is too small, something like 1 / N to something.",
            "There's not enough points close together to actually form a hole.",
            "If it's too big, right?",
            "If my radius is too big, everything is covered, right?",
            "I've covered my entire unit square, so again, there can't be any holes, but in the middle here a lot of things can happen, right?",
            "So?",
            "Here we know that it's non zero and we know with high probability that it will be non 0 but we don't really know much else.",
            "There were some results on, you know roughly how many there were, but not much more was known than that."
        ],
        [
            "OK, so the reason for these three things is actually kind of something that comes up very often when people look at geometric processes, so.",
            "Generally people look at what are called regimes.",
            "So again I said you know the number of points we're going to let them go to Infinity, and we have three regimes.",
            "We have the subcritical.",
            "Critical and supercritical right?",
            "So what?",
            "The subcritical is, is essentially you take a value which is the number of points times the radius to the power of whatever dimension you're in, right?",
            "So what is that?",
            "That's really just the volume.",
            "So R to the D is something like the volume of a ball, and you're saying that the total volume that you're putting of all the balls around these points is going to 0, right?",
            "So all of these points.",
            "These balls are kind of shrinking twords points, so you get something that looks like dust.",
            "In the Super critical regime, well, you know all the balls are kind of expanding fast enough.",
            "That your total volume goes to Infinity.",
            "So you've covered your entire space, but in the middle.",
            "Here it goes towards some constant.",
            "And here is where a lot of interesting things happen.",
            "But this is also kind of the hardest thing to analyze right?",
            "Because?",
            "Here it's going to depend a little bit on what the constant is.",
            "It's kind of a narrow region.",
            "It's something that's quite fragile, so you know this is where most of the work happens, but it's also the hardest."
        ],
        [
            "OK, so one last thing before we kind of get really started with the material is that for some processes there's two almost equivalent viewpoints, so the one we're going to be using today is actually this unit hypercube where we're just going to put points more and more and more points in right.",
            "But there's I just wanted to point out there's another one where basically you put a point process on your entire Euclidean space, and then you just look at a window centered at the origin and you increase the window size.",
            "So you look at a bigger and bigger and bigger piece of Euclidian space.",
            "So these two are equivalent up to scaling.",
            "And depending on what you're trying to prove.",
            "One may be easier than the other, but in this case we're just going to stick with this kind of, I think more.",
            "More kind of intuitive model, which is just this little square that we throw points into."
        ],
        [
            "OK, so.",
            "Now the question is how do we measure structure right?",
            "So the title was how much structure can we see?",
            "We know what our noise model is now, but now how much structure can we see well?",
            "We could certainly count the number of holes, but you know, these are geometric graphs, so it might makes more sense to ask something about how big these holes are.",
            "So this is where a tool called persistence comes in.",
            "So persistence is, I would say, kind of or persistent technologies.",
            "The main tool that's used in topological data analysis and it's kind of a very simple idea what we're going to do here is not 2 dimensional, but it's just one dimensional function, and we're going to look at."
        ],
        [
            "Sublevel sets of this function right?",
            "So if I take this sublevel set well, the function doesn't cross it so I have nothing here and then as I increase."
        ],
        [
            "That well, now I get this one point and so I keep tracking of this.",
            "I see I have one component here, right?",
            "And then."
        ],
        [
            "I raise it up.",
            "This one point becomes an interval, but it's still one component."
        ],
        [
            "Write a new local minimum means a new component and then you know."
        ],
        [
            "I keep going up these two things."
        ],
        [
            "Become intervals and then eventually they merge.",
            "So in some sense, this is measuring something about the size of these kind of little wells."
        ],
        [
            "And how do we you know?",
            "How do we actually?"
        ],
        [
            "What do we actually compute out of this?",
            "Well, we're going to keep track of the components as we go through the sublevel sets, right so?"
        ],
        [
            "From here to here.",
            "I keep this bar here because it exists.",
            "This component exists from here to here and then a new component or appears.",
            "So I add a new point and."
        ],
        [
            "And as I go up, well, you know.",
            "Now I keep tracking these things and then once they merge."
        ],
        [
            "I always then you know I kill one of them off and I always kill off the one that's more recent.",
            "That's just the way it works then."
        ],
        [
            "As I go up, I in 0 dimensions.",
            "I have one component that lives forever, right?",
            "I just have this one component at the end, so this is what's called."
        ],
        [
            "Persistence barcode right?",
            "So this is the output of what we compute, right?"
        ],
        [
            "And one of the nice bits about this bar code is that it's stable.",
            "So if I didn't give you this one nice function, but I give you this.",
            "PL kind of noisy function right then?"
        ],
        [
            "The bar code would look something like this, right?",
            "'cause there's."
        ],
        [
            "A lot more of these little components that are going to appear and the point is that these long bars look roughly about the same right?",
            "They might not start or end that exactly the same place, but.",
            "You can actually formalize exactly how far off they are going to be, but today, where we're kind of asking is well, if I want to know what a long bar is, I need to know what a short bar is, and so I'm going to ask well, how long can these things be?"
        ],
        [
            "Right and just for various convenience sake.",
            "So I'm not going to.",
            "I'm going to either show it as a bar or what's called a persistence diagram, which is just the mapping that's a bar.",
            "The beginning of the Barber goes through the X axis and the end of the bar goes to the Y axis.",
            "For some things, it's just easier to see.",
            "In this diagram case, but otherwise they're completely equivalent.",
            "OK."
        ],
        [
            "So here I showed a function, But what we're going to be interested here are particularly distance functions, right?",
            "So I'm going to have some points in space and then I'm going to grow balls around them of different radii, and I'm going to get the sequence of spaces right and I'm going to track how many components there are, right?",
            "So components keep kind of dying off as these little points get connected, and then at some point I see kind of 1 big.",
            "Annulus kind of appear and then it keeps you know it's still there and then it gets filled in and these are the 1 dimensional bits, right?",
            "So this part right?",
            "The 0 dimensional part has actually been covered by all of the random graph theory that people have done.",
            "So what we're really going to be interested in today is just this bit right?",
            "So here for example, it's a little hard to see, but there's a little hole here, right, so?",
            "What we want to be able to say is, well, you know this long bar is really significant.",
            "And given some noise model and these things are short, right?",
            "So we want to somehow formalize how short these things can be."
        ],
        [
            "So this is part of kind of some longer line of thoughts that says, well, you know if I have some generative point process and I compute this persistence diagrams if I just put in noise, right?",
            "What does it look like?",
            "What does the diagram of noise actually look like so we know some things?",
            "Now let's say 2, three years ago, we didn't.",
            "This, but now you know we know a few things and you know, but we still don't understand everything.",
            "So today we're going."
        ],
        [
            "Look at one very specific point of this.",
            "What does this thing look like, right?",
            "And specifically going to look at the lifetime.",
            "So what's the lifetime?",
            "Well, it's you know, pick your favorite point.",
            "Look at sex asses.",
            "That's the birth and it's the Y axis is the death right?",
            "And so generally the way people look at it is they say, OK, I'm going to."
        ],
        [
            "Measure death minus birthright.",
            "So I'm going to measure the distance from the to the diagonal here, right?",
            "For various reasons.",
            "I'll explain we're not going to do this, but we're going to use relative lifetime, which is going to be the Y axis divided by the X axis, right?",
            "So in this case, the lowest value you can have is 1, right?",
            "Because everything?",
            "Has to do, it has to be born before it can die and then you know you have kind of these lines that illustrate.",
            "Everything above here has bigger than persistence for everything in between.",
            "Here is between 4:00 and 2:00, and everything here is between 2:00 and 1:00.",
            "So one of the main reasons for this, well, OK, the first question we can ask is.",
            "Does it even matter which one we take?",
            "Right?",
            "I mean if we increase one, the other one almost certainly increases as well, so you know, is there really a point and?"
        ],
        [
            "The short answer is yes.",
            "Well, these things represent different cycles, right?",
            "So here's one whole.",
            "This is a relative.",
            "This is the biggest relative hole here, and this is the biggest kind of absolute difference whole.",
            "And this is so the blue is always the absolute difference in the red is the relative one, and we can see that these are different things, right?",
            "So I mean here for the low number of points, we could actually argue that the absolute difference is more meaningful.",
            "But you know, I mean which is more meaningful is up for debate.",
            "Since this is actually in noise, but we can see that they are measuring different things so."
        ],
        [
            "There's actually kind of a nicer reason for wanting to use this, and that's kind of taking this very nice example of, you know, some points sampled on a circle perfectly of some radius R. So if I want just the absolute difference, it's going to be some function of our right?",
            "Because these things are going to connect, you know, it's going to have something to do with the distance between these points and R, Whereas this thing, right?",
            "The relative one.",
            "Well, it's born at some function of R, and it dies at R. So it's are essentially cancels out and we have just one number, so this is a scale free.",
            "Quantity which is always nice right?",
            "It's one less parameter we have to estimate.",
            "If we use this and you know there's."
        ],
        [
            "You can construct kind of very bad examples of outliers, right?",
            "So I put two outliers here, right?",
            "And if I were to measure the persistence of this big triangle right, it's actually bigger than this thing, but the relative one is smaller.",
            "And the explanation for this is that this thing, actually the relative one, also kind of, takes into account not just how long it lives, but also how many points you have when it's born.",
            "Just that's kind of just a geometric consequence.",
            "So there are cases where this absolute thing.",
            "Makes sense, but in a lot of cases this relative measure can actually bring you some nice information and actually makes for more interesting analysis as well."
        ],
        [
            "OK.",
            "So here are some basic definitions, just to recall, right?",
            "So we're going to have a cycle.",
            "For the people that know topology in the audience, I'm going to do the horrible thing of using a cycle and homology class interchangeably, mostly because for the purposes of this analysis, it doesn't matter.",
            "So birth is just going to be the birth of this cycle.",
            "Death is going to be the death of this cycle.",
            "And then we're going to look at this."
        ],
        [
            "But if persistence and the question we're going to answer is, you know if I throw points down at random, what's the biggest one of these I see right?",
            "So I had this whole persistence diagram, and under this measure, what's the biggest, most?",
            "The biggest one of over all of those points that we expect to see?"
        ],
        [
            "And our result was basically that it should look something like log in over log, log in right.",
            "So this basically says that there exist constants, right?",
            "That it's always going to be of this order.",
            "You know 4 N large enough right?",
            "So this is kind of the big result of the paper that we that we put up on archive and submitted last year.",
            "OK."
        ],
        [
            "So the first thing we should do is, well, this is very nice mathematical analysis, But we should do some experiments to verify.",
            "And here's the kind of sampling.",
            "So this scale is log in over log, log in and to give you an idea.",
            "Three is somewhere around like 50 points, 5 is going to be something like 10,000,000 points, and that's the beauty of having a log log N factor.",
            "You have to go to a lot of very large number of scales in order to actually see anything.",
            "And you know, you can see that the line, if it's actually quite nicely there is quite a bit.",
            "It doesn't quite converge, but I'll address that at the end and you might say, well, it kind of looks like it's going down here a bit, but that's actually just because there's very few points here, and if you do things on a Taurus rather than a square, this thing kind of straightens out."
        ],
        [
            "Act OK.",
            "So kind of going back to this analysis of how do we actually get to this result?",
            "The big problem is that you know when people generally look at these types of processes.",
            "They stick to one regime.",
            "But here we're letting our go from zero to Infinity, right?",
            "So we have to basically cross all of these regimes, so that's what makes this kind of difficult."
        ],
        [
            "Yeah, so here we're just going to go quickly over how we actually the rest of the talk is how we prove something like this.",
            "Because I think it's.",
            "Surprisingly accessible, there's a few kind of.",
            "Deep theorems in there, but for the most part, it's kind of surprisingly straightforward, so the lower bound right?",
            "So we want to show that there exists a cycle of at least this much.",
            "So how do we do this?",
            "Well, we assume we have our person point process on the plane and we're going to put a grid on it.",
            "So a bunch of little boxes arranged in an annulus, right so?",
            "If I do this, I can now compute the probability of actually seeing a cycle like this, right?",
            "So what do I want?",
            "I want at least one point per box, because if I have one point per box, then when I put the balls around it, I've basically made this annulus right, but the second thing is I don't want any points inside right?",
            "Because if there are no points inside here, well then this thing isn't going to get filled in for at least R, so I can.",
            "Lower bound, the birth upper bounded death, and then I just take the.",
            "One over the other an I have a lower bound for my persistence, so that's basically it."
        ],
        [
            "The trick, of course, is choosing your constants carefully, right?",
            "What is our?",
            "What is L?",
            "And so you.",
            "You spend some time on this and then once you figure it out, you just write it out as though it's obvious and you write it down and you say, OK, well, we do this and you know the persistence is going to be of this size and then we just have to verify that you know.",
            "With as N goes to Infinity that this happens with probability one.",
            "And you can do it.",
            "I'm not going to bore you with the computations because it's kind of just manipulations that you have to do and check to see that it really does go to one.",
            "OK, so that's the lower bound.",
            "That's all.",
            "There really is to it, except you know, our points don't always live in the plane, right?",
            "We have higher dimensional data.",
            "We have 3 dimensional data.",
            "We have 10,000 dimensional data."
        ],
        [
            "So how do we actually specify this thing for higher dimensions, right?",
            "Well, I do the same thing right for this one dimensional case, but I put little boxes and I require there are no points to be in this big box.",
            "Around this thing because that will tell me that the death that nothing else can kill this earlier than this earlier than I want.",
            "And it turns out that the same constants go through, right?",
            "So you choose L and you choose these sizes the same way.",
            "And nothing really changes every you know, the persistence is the same of the same order, and it still goes to the probability still goes to one."
        ],
        [
            "OK, so now the tricky part is the upper bound right?",
            "So we know.",
            "From you know the thing that I had before, that we know that before this right, there's nothing here, right?",
            "This is the Super critical.",
            "We know we have nothing here.",
            "This is dust and we know we have something here.",
            "So we have a trivial upper bound of log, right?",
            "So it's not bad, right?",
            "Were off by a factor of log log in which.",
            "Maybe OK, but for probabilists is you know a very wide gap, so you know we have this trivial bound, right?",
            "'cause the most anything can live is from here to here, so you know that's fine.",
            "But this actually highlights another point of why we why we should use this kind of relative thing when we're studying noise.",
            "Well, you know, if I just take the difference between these two.",
            "So the longest something could live well, it's just going to be of the same order as here, right?",
            "Because?",
            "Everything's everything is going to 0, but this goes to zero.",
            "Much faster than this, so you know if I take this absolute one.",
            "The one that's going to dominate is just going to be some triangle is essentially going to be outliers.",
            "I showed before, right?",
            "It's just going to be something that just appears at the very end, so that's not terribly informative."
        ],
        [
            "Right, so we want a better one.",
            "We want to close it.",
            "We want to close the gap so we want sharp upper bound, right?",
            "So how do we do this while we divide the persistence classes into what we call early and late board?"
        ],
        [
            "And the idea here is we pick this our star again.",
            "Magical constant right?",
            "And we say everything that's born after this is called late born and everything born before is early born right and the nice bit is, well, half of it's very easy.",
            "The late born things.",
            "If we do the math.",
            "Essentially they're born 2 lights too, actually.",
            "Affect our upper bound.",
            "Right, so the late boring things aren't really a factor there.",
            "You know, even if it appears right here, it'll never really achieve this thing so.",
            "Now we have the early born and this is really where all the work comes in, right?"
        ],
        [
            "So we have four steps I'm going to not go through them in this kind of very specific way, but kind of give you the idea behind it."
        ],
        [
            "So the first thing we realize is that OK, early born are relatively small radii.",
            "It's not quite the dust phase, there are components.",
            "Things have started coming together, but you don't have this big one component, right?",
            "So it turns out that you can bound the number of vertices in a component at these small R, right?",
            "And this is kind of a standard thing and I would say geometric probability.",
            "That says that you know if your radius is small enough, the number of vertices per component is going to be of this order, right?",
            "So you don't have anything more than with this.",
            "Then with this number of vertices, right?",
            "OK, so that's a start, right?",
            "So we know there can't be any big components in the early born ones, right?"
        ],
        [
            "So now the OK.",
            "So now we have a bound on the number of vertices an we have a bound on the edge length, so this edge length is basically going to give us a bound on simplex volume, right?",
            "So in the graph it's going to give us a bound on the length of any one edge, right?",
            "That's actually kind of tautological, but it's also going to give us a bound on.",
            "The volume of any triangle.",
            "Whereas this we want to take this bound on the number of vertices and we want to turn it into a bound on the number of simplices, right?",
            "So in this case, the way to think about it is I have N vertices.",
            "How many edges can I have right so?",
            "And this is really where the topology comes in because up till now we've basically just done probability."
        ],
        [
            "So this is the result where after we're saying if I have this many vertices.",
            "How many high dimensional simplices can I actually have?",
            "So if I had a graph, essentially if I have N vertices, how many edges can I have?",
            "So the trivial bound here, right?",
            "Is let me go back.",
            "So the trivial bounds here is M squared, right?",
            "So if I've M vertices I can have em squared edges?",
            "This is too many, because then the triangles I can have mcubed and so forth, right?",
            "So that's far too loose, abound, and actually what I want is I want to show that there's a linear number of.",
            "At of edges, for example, are linear number of triangles.",
            "In that cycle, when I'm in this thing that kind of surrounds this whole and the way I do it is, well, OK.",
            "I"
        ],
        [
            "Put down these.",
            "This is the intersection graph of these union of balls, right?",
            "So this, so I'm not just going to look at this, but I'm going to look."
        ],
        [
            "Something bigger, right?",
            "I'm going to inflate these balls, which means I'm going to add more edges."
        ],
        [
            "Right?",
            "So now I have a lot more edges and I can show that in this bigger graph, right?",
            "I can choose a subset that has this property that's kind of has.",
            "At most M vertices and at most M edges, right?",
            "And the way I do this."
        ],
        [
            "Is actually a nice standard construction from.",
            "Computational geometry, and I think pretty much everyone has used this without knowing it at some point, so it's what's called an epsilon net, and so you want to pick a subset of your space such that it's called what's called an epsilon cover and epsilon sparse.",
            "So let's just go through the algorithm on how you build this so you."
        ],
        [
            "Pick a point at random.",
            "Draw ball of radius R around it, mark every."
        ],
        [
            "That's within this right?"
        ],
        [
            "Take pic and unmarked points.",
            "Do the same thing."
        ],
        [
            "Pick an unmarked point."
        ],
        [
            "Keep doing this right until all the points are marked and then you take."
        ],
        [
            "Just the subsets of the centers of these balls, right?",
            "And that's your epsilon net, and the point is it covers everything.",
            "It covers all the points and it's epsilon sparse right?",
            "No2 red points here are closer than epsilon and there's a nice consequences that if you have this epsilon net right."
        ],
        [
            "Vertex will only be part of a constant number of simplices, and that's actually just a simple packing argument that says that you know if things are sparse, then you can't fit too many of them together, right?",
            "You could in two dimensions, you can only pack six points together like this, such that there are, you know, within some radius R of each other.",
            "That they're all within the, you know, they all have to be within our of this red point and they have to be at least are distant from each other.",
            "So the most you can pack is 6 in two dimensions.",
            "In higher dimensions it goes up, but it's always a constant number, OK?"
        ],
        [
            "So going back to what this means for us, right?",
            "So we started off with our balls here, right in our graph.",
            "And you know we have our subset and the key point to say that these two things you know, whatever.",
            "Kind of cycle we have here in this red cycle are actually the same.",
            "Basically, well, topologically it's.",
            "The proof is encoded in this diagram, but the idea ultimately is is that you know because it's an epsilon cover.",
            "If I just look at the bigger balls around these red points, I've essentially covered everything inside the small of all of these smaller points and so I can actually show that these two cycles are kind of go around the same hole is the idea.",
            "OK, so there is actually a formal proof for this, but I think that would kind of.",
            "Take that actually involves a lot of setup and machinery that's I don't think kind of crucial for this for this idea."
        ],
        [
            "So now we have kind of our basic result, right?",
            "So we know that.",
            "Each of our kind of things that go around the whole right.",
            "These cycles that represent these holes are of size M, where M is the number of vertices.",
            "We know the volume of any one simplex because we know kind of the upper bound on the edge length, and so we can get a volume on the case cycle right?",
            "So this would be if I have a cycle, this is a bound on the total length of the cycle, right?",
            "So you just multiply these two together.",
            "Each thing you know if there is most this many edges and each one is at most this long.",
            "The total length is certainly bounded by the product.",
            "Alright, so OK, now we know how long it can be.",
            "Well, that actually tells us a lot and."
        ],
        [
            "The reason is there's this.",
            "Very very deep deep theorem called that was proven by Federal Fleming called.",
            "That's basically an isoperimetric inequality that says, well, if I have something of length X right then.",
            "The latest I could.",
            "Kind of the biggest volume and the biggest fill in radius, which is exactly what you would think it means, is going to be exactly 1 / K over this volume, right?",
            "So if I have something of length L?",
            "R is going to be essentially just the fill in radius is going to be exactly kind of.",
            "R right, it's going to be linear 'cause K here is going to be one and we know that right?",
            "So if I take a circle right the length is 2\u03c0 R. Right and R is the radius, so we know that in this in these nice cases this.",
            "This relation holds, but actually it holds in much more generality, and that's really where the.",
            "Kind of thing is, and if you're interested in this, which I highly recommend, Larry Goose notes on it, because while this is fairly unreadable, this is quite straightforward."
        ],
        [
            "OK, so now we just in the same way as the lower bound.",
            "We just have to put everything together, right?",
            "We have our lower bound, our upper bound on the volume.",
            "We have our upper bound on the number or lower bound on the number of vertices.",
            "Here we know everything is around the order M. So now we putting these two together, it gives us our volume on the cycle length, which tells us are filling radius and the filling radius is essentially our death time, right?",
            "So when, when do things get covered and taking one over the other right?",
            "So our choice of our here is going to tell us our birth time.",
            "Our choice of.",
            "Well, from that we're going to compute this upper bound on R, which is R. Which is going to be our death time and we take one over the other and we essentially get exactly the same answer before right?",
            "So I mean.",
            "There's a lot of kind of constants here.",
            "You have to choose correctly, but the idea is really just, you know, bound the number of vertices balance how many.",
            "Edges there are in this cycle bounds how long each edge can be an.",
            "That will tell you how big a hole can actually be."
        ],
        [
            "OK, so this is kind of the most general results, so this is the result we actually have in the paper that works in any dimension.",
            "The key point here is this one over I, so this says, well, I has to be bigger than one or bigger than zero rather.",
            "So this doesn't work for graphs.",
            "This doesn't apply to graphs, but for holes.",
            "This is going to be 1 four if we're looking for voids in three dimension, it's going to be 2.",
            "If we're looking for whatever 3 dimensional holes look like, it's going to be 3 and so forth, right?",
            "And the interesting bit is that the rate does not depend on the ambient dimension.",
            "This was actually quite surprising for us.",
            "So the constants here certainly do, right?",
            "I mean, you know what thing is?",
            "There's something in front here that's going to depend on dimension and I and whole bunch of other things.",
            "But you know the general function of N doesn't really matter, right?",
            "It doesn't depend on these things, which is also surprising, and the other kind of interesting bit is that you know these.",
            "Whether you know TJ, we often build either check or rips complexes, but in this case the order is actually exactly the same.",
            "Mostly because these two things are related by a constant factor, so anywhere where there's a constant factor right, it's going from the top and the bottom, and it's not really going to matter.",
            "OK, so that's our general result."
        ],
        [
            "So you know we.",
            "Did a few more experiments right?",
            "So we looked for, you know if I'm in 3D, what?",
            "How many?",
            "How big are the voids that I can get?",
            "And again, you know it fits quite well with what we would expect it to."
        ],
        [
            "You know, even to higher dimensions like 4D and you'll notice that the range of things kind of get smaller and smaller because it gets harder and harder to do it for that many points.",
            "But you know the general kind of relationship holds."
        ],
        [
            "So that's kind of where we're at now, so.",
            "You know there's other work that we're doing right where we want to characterize, you know, let's say not the maximum butt holes of a certain size.",
            "How many of those can we expect?",
            "So there's a general or writing up a general result that says that you know for a certain size of holes, it should really go to some sort of normal distribution for this maximum one.",
            "We know what it looks like, but we don't know something that's perhaps even more.",
            "That's quite basic.",
            "Which is we have upper and lower bounds, but we don't have a law of large numbers which says that you know if I if I just take this and take into Infinity, does it converge to an actual constant, right?",
            "So that's a law of large numbers.",
            "And why would we experiment certainly suggest this, right?",
            "So here I have the histogram.",
            "At 400 points, the green thing is the histogram at 5000 points and the red is at 2 million points, and it certainly start.",
            "Looks like it's getting more concentrated right?",
            "But we don't really have a proof for this.",
            "And why would you really care about a proof for this?",
            "Well, if you want to do kind of statistical inference based on this, you would really want there to be a law of large numbers, right?",
            "You would really want there to be some form of convergence so that you could actually start to say things like.",
            "Can I estimate this reasonably right then?",
            "The other question is kind of other distributions, right so?",
            "If I don't have possum, but I have Gaussian or kind of uniform heavy tailed or something like this, what will this maximum look like?",
            "So the interesting thing is that preliminary calculations seem to suggest that it always looks like the Pasan case, which is something that.",
            "Is surprising and I don't really fully understand why that should be the case, but it seems like this scaling factor of log in over log log N. Is actually quite should show up in a lot of places where there isn't structure where it's just a noise.",
            "So if you see something that doesn't scale like this, right?",
            "So you could think about taking denser and denser subsamples if it grows kind of much faster than this you can be almost sure that it's not coming from some form of noise.",
            "OK, and actually with that I'm going to."
        ],
        [
            "So actually quite early so with that, I'll take any questions.",
            "The question was that whether I considered Vietoris rips complexes on a random set of points we actually use check complexes, but it's yeah that's not there.",
            "Yes, so so the question is, what about other ways to build these kinds of complex?",
            "Is there a lot of them?",
            "One of them probably the most.",
            "The first one to be studied for graphs is the airdash rainy model where you just put in edges at random with probability P. There's been a lot of work on kind of higher dimensional analogs of this, so the higher one version of this is that you build.",
            "Airdox Rennie model and then you throw in.",
            "You basically build the clique complex, so you throw in all possible simplices that you can.",
            "This has been studied.",
            "In some cases.",
            "The other model is called a lineal machine model, which is essentially you take a complete K -- 1 skeleton and then you start putting in K faces.",
            "There's a lot known about that one.",
            "On yeah, so in some sense in some sense I'm going to say those those types of models are easier because everything is independent.",
            "Here you have all of this kind of dependence based on, you know.",
            "Just based on geometry right there, there's no real geometry to constrain you, whereas here.",
            "You know it's very hard to make kind of.",
            "Statements about real independence of simplices, right?",
            "You can do some things, but not very many, so in some sense this is harder, and this is also why we have fewer results, so there a lot more is known, right?",
            "So there's a lot known even about how much happy groups and things like that.",
            "But this is sort of considering, yeah.",
            "Because we are assuming that our our points are sampled along some lower dimensional space and so you know, we expect geometry to play a role.",
            "So I got exactly this.",
            "Discount of this normalization class yes look I'm divided by log book them as far as I remember this is.",
            "Distance for eldership Well no for airdash.",
            "I mean, in our dash there's in our destiny.",
            "There's no distance, right?",
            "So I'm not sure.",
            "I can't recall exactly what the mean distances for geometric model, but I don't think it's log in over log log.",
            "Well, it's a problem, right?",
            "You take endpoints.",
            "And distance is the number of edges in distance?",
            "OK, yes, would you have?",
            "Or complex networks?",
            "To pass from OK, I see.",
            "So you want to take your saying the graph distance in an airdash?",
            "Ronnie would be something like log in over log log.",
            "At so, I'm sure that's true at some that might be true at the critical thresholds I'm not.",
            "I don't particularly call if it's exactly that.",
            "But if it is, it would well.",
            "In some sense, it wouldn't be terribly surprising because a lot of these kinds of scaling limits are log in over, you know, have some log in factor in a log log factor, and you know there's only so many ways you can combine these, but I don't think it's.",
            "I mean.",
            "It's I mean it is.",
            "It would be surprising if there was an actual.",
            "Connection between these right so?",
            "Yeah, I mean I could think of some reasons why it would be the case, right?",
            "So you could take for example in order for any graph.",
            "And if you were, you can always embed it into a high enough space and build your complete simplicial complex on it, right?",
            "So embedded into end dimensional space and then look at this distance filtration and that might give you some connection, but it's certainly not an obvious one.",
            "Let me put it this way.",
            "OK. Any other questions?",
            "Just.",
            "Remember, you were trying to use this right on some real data.",
            "Yeah, some examples yes.",
            "Well, so this was really just to try to understand what the null hypothesis should be, but really, I mean ultimately the real problem here is that.",
            "Well, let me put it this way often.",
            "The problem is that you know we're given a set of points and we get one diagram right?",
            "And so from one diagram it's very hard to decide what's noise and what's signal.",
            "So you know, we could always re sample.",
            "But you know, even if we re sample, we really can't be sure what's.",
            "Which which part is noise in which part isn't right, because for the simple fact that these constants, you're never really going to be able to just calculate them.",
            "But what this seems to suggest there's something that kind of shows up in toy examples is that if we were to take, let's say random subsamples, right, the noise should actually give us some form of.",
            "Should be kind of should form its own cluster in some sense, and these types of results give us hope that that's actually going to be true where.",
            "Where this where we kind of see these kinds of structures so?",
            "It's I can give several examples of things in three dimensions or kind of these continue more kind of heavily sampled processes in higher dimensions, so the one part where this really doesn't work well is when you have sparse data in high dimensions, because that's.",
            "You know, there just isn't enough information there to build these kinds of global structures, so either it should be kind of you know mid dimensional like maybe you know up to let's say 6 seven dimensions or it needs to be kind of on some very low dimensional thing in high dimensions, right?",
            "So kind of a prototypical example of where this where we couldn't find structure is in text data for a variety of reasons.",
            "One is, I think that.",
            "The metric that we use, which is the cosine metric, is kind of a little too rough, so the.",
            "The band of where we would actually see a signal is not kind of wide enough.",
            "So it kind of gets lost in the noise and the other bit is that you know.",
            "We need well with a better metric.",
            "We would widen the gap, but we would also kind of not necessarily even need more points.",
            "Well, more points would certainly help, but we would need kind of better representation so that we could actually.",
            "Compute all a lot more because it's lower rank.",
            "But even low rank representations are quite big, right?",
            "So the problem is the problem actually isn't in computing these things.",
            "It's the current problem is kind of.",
            "From a technical standpoint, is how to actually construct our representation, right?",
            "So graph?",
            "You know is N squared, which is, let's say, feasable.",
            "If you cut off early enough.",
            "Triangles you know if I only care bout holes I already have N cubed just to build the thing because I need to look at all of the triangles and so forth.",
            "Higher dimensions are, you know, kind of scales, exponentially, badly and one of the key problems I think, is that you know.",
            "I don't think we can go to the scale yet, where we would actually start to see structure.",
            "Essentially, I think for these very large datasets, essentially we're cutting it off.",
            "You know, even for the graph case, you cut it off early enough that everything is essentially.",
            "Still in the dust phase.",
            "So you see some small components and things you know we can just go to the beginning of the critical regime and you know you start to see these small components and things, but you don't kind of have.",
            "A sense of this global structure of that might appear at at bigger radii, where for example the example I would give is you know, for example, between topics for Wikipedia, right?",
            "So there's this kind of nasty combination of a rough metric plus, which means that any approximation you do is going to be going to further degrade your signal.",
            "But you know, you kind of want to make things efficient so that you can actually put in enough data that you will actually be able to see the structure.",
            "So there's still work to be done there, right?",
            "But I think.",
            "You know, yeah.",
            "This.",
            "Global.",
            "Ventra generated so that seems very friendly, so so we looked at that right, but again you have these big components and a bunch of very small components, right?",
            "That's and I mean there's certainly something to be said about, you know, looking at.",
            "Looking at the what's it called.",
            "Things like sizes of the components and.",
            "You know, if you have some sort of generative process, what can you say about these things?",
            "And you can say a variety of things that you know that are along these lines, but.",
            "From what?",
            "We've seen I don't think there is very much.",
            "There might be some kind of circular structure, but I think that would be it.",
            "I can see kind of graphs splitting apart and coming back together, but it's not.",
            "You know, I don't think you'll.",
            "I think these graphs are still sparse enough that you won't actually get kind of bigger holes and things like this.",
            "I mean if they are, they are very small and you know it would certainly be interesting to look at them, but for their we don't just care bout the diagram, we actually want to look at the representatives themselves, and that's something that's still being worked on exactly.",
            "You know.",
            "How can, given some persistent point, how can I pull that back to a cycle that actually means something for that?",
            "So that's not in.",
            "That's not an obvious step, right?",
            "So I think with.",
            "With that right?",
            "You will be able to do.",
            "You'll actually be able to get some information out of graphs like this one.",
            "Other point I will make though, if you do something like this on these graphs you can get.",
            "You can still use it as a signature for the graph, right?",
            "So in the sense that let's say you have two very large components that have the same number of points, it would be.",
            "This is kind of a strictly more informative.",
            "Feature than saying just use, let's say all the degrees or something like this.",
            "And kind of another bit of work that's that's going on now is actually.",
            "Trying to quantify what the statistical power of these kinds of tests of this feature is right so.",
            "You know, in that sense, I don't really even care bout persistent things.",
            "I really care about how all the little things come together, right?",
            "You could think about, well, you know, a power law graph is going to have a very different thing than a geometric graph for this kind of thing.",
            "And if you can actually show that.",
            "This type of thing has a bigger statistical power than what people already use.",
            "I think that's kind of a valid contribution, so.",
            "Yeah, could you use it to post process?",
            "Yes, so we've been thinking about this.",
            "One of the things we want to do is to look at a trained network and what you could do is you could pull back points and look if you know if you what kind of structures you've actually destroyed, right?",
            "Yeah, so we've thought about this, but we haven't done it yet.",
            "Yeah yeah yes.",
            "Popular contribution.",
            "OK, are there any other questions?",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This talk, or rather the seminar, is basically too.",
                    "label": 0
                },
                {
                    "sent": "Conveys some of the ideas that I've been working on.",
                    "label": 0
                },
                {
                    "sent": "Let's say now for the last two or three years, the ideas and the problems behind this kind of go back further, but ultimately they ask.",
                    "label": 0
                },
                {
                    "sent": "Kind of very standard questions from probability and statistics as applied to kind of.",
                    "label": 0
                },
                {
                    "sent": "A topological perspective, which I'll describe and essentially the core ideas.",
                    "label": 1
                },
                {
                    "sent": "How can we start to look at statistics probability?",
                    "label": 0
                },
                {
                    "sent": "Things like this on what are essentially combinatorial objects.",
                    "label": 0
                },
                {
                    "sent": "They may come from some sort of continuous space, but ultimately they're going to be common tutorial and we're going to see exactly what this means.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so much of what I'll be describing is joint work with Matt Scale, who's at Ohio State and Omar Bobrosky, who's postdoc at Duke, but.",
                    "label": 0
                },
                {
                    "sent": "Questions along this line are also with Yogesh, who is probabilist from India and basically we've been asking other questions that I won't kind of cover in this seminar, but kind of our upcoming papers.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, I think in data analysis in general.",
                    "label": 0
                },
                {
                    "sent": "You know, it really depends on what kind of data we're looking at, but today I think we're going to concentrate mostly on spatial data, or rather geometric data, depending on how you want to look at it and when we're doing data analysis.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, the question we're asking is.",
                    "label": 0
                },
                {
                    "sent": "We're looking for some sort of structure in this data, right?",
                    "label": 0
                },
                {
                    "sent": "So in this case you might say, well, maybe there are four clusters here, and maybe you would say there's more.",
                    "label": 0
                },
                {
                    "sent": "Maybe you'd say there's less, but actually in this case I can tell you there are actually 4 because I generated these points using something called a materne cluster model, right?",
                    "label": 0
                },
                {
                    "sent": "And you know.",
                    "label": 0
                },
                {
                    "sent": "There's plenty of techniques out there that given this data in the plane, would return these four clusters, But so this is one form of structure that data can have, but it can also have higher dimensional structure, and that's actually what we're going to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today, so kind of the prototypical example I like is this kind of data, and if I ask you what this looks like, hopefully you would say that it's a noisy circle, right?",
                    "label": 0
                },
                {
                    "sent": "So that it's, you know.",
                    "label": 0
                },
                {
                    "sent": "And actually, that's the way I generated this data.",
                    "label": 0
                },
                {
                    "sent": "I took a circle and I ran, added random noise, and this is kind of what it gets, right?",
                    "label": 0
                },
                {
                    "sent": "So if I were to give you data like this, hopefully you would say, come back or whatever method you would use would come back and say, OK, this actually looks like a noisy circle.",
                    "label": 0
                },
                {
                    "sent": "And you know, I think everyone here has seen clustering.",
                    "label": 0
                },
                {
                    "sent": "Kind of it's.",
                    "label": 0
                },
                {
                    "sent": "I would say actually everywhere today, but you know these kind of higher dimensional models or maybe a little less common, but I would actually argue that these types of structures are just as important as kind of these, as these cluster models and here's kind of a.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prototypical example here.",
                    "label": 0
                },
                {
                    "sent": "I have rainfall data from Nottingham Castle over 30 years.",
                    "label": 0
                },
                {
                    "sent": "Forget about the index, and essentially what I did is.",
                    "label": 0
                },
                {
                    "sent": "I took each point and its previous point and use these two things as.",
                    "label": 0
                },
                {
                    "sent": "As a as coordinates and I plotted them right and you can see well it looks like a circle, and that's not terribly surprising because, well, you know this is periodic, and if I were to look at something periodic, it should roughly look like a circle.",
                    "label": 0
                },
                {
                    "sent": "So these are kind of large scale structures that we would hope to find given this data, but that's not what this seminar is about.",
                    "label": 0
                },
                {
                    "sent": "How to find these things?",
                    "label": 0
                },
                {
                    "sent": "This actually asks the converse question.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say I don't have any structure right?",
                    "label": 0
                },
                {
                    "sent": "Let's say I just have noise.",
                    "label": 0
                },
                {
                    "sent": "And I apply these same techniques.",
                    "label": 0
                },
                {
                    "sent": "They're still going to give me an answer and so I need some form of null hypothesis in order to be able to distinguish between what's real structure and what's noise, right?",
                    "label": 0
                },
                {
                    "sent": "So here are two point processes, or rather just to point samples, and the question is which one is more random right?",
                    "label": 0
                },
                {
                    "sent": "Is is there any structure here or is there any structure here right?",
                    "label": 0
                },
                {
                    "sent": "And we may be actually tempted to say that the one on the right is more random, whereas strictly, probabilistically speaking.",
                    "label": 0
                },
                {
                    "sent": "This is actually more random.",
                    "label": 0
                },
                {
                    "sent": "This is generated using something called apasan process, which is I would say are kind of.",
                    "label": 0
                },
                {
                    "sent": "Most random model that we have, right?",
                    "label": 0
                },
                {
                    "sent": "If I were just to say I have some random points.",
                    "label": 0
                },
                {
                    "sent": "This is the model I would use, whereas there what I did was I took a grid right which is something very very structured and just perturbed it right.",
                    "label": 0
                },
                {
                    "sent": "But if we just looked at it, we might be tempted to say Oh well, you know that's actually more random, so you know.",
                    "label": 0
                },
                {
                    "sent": "Just looking at these at these points is not always the best way to kind of measure randomness, right?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so using this kind of completely random points, there's actually two different ways of slightly slightly different ways of actually generating these points are two different models.",
                    "label": 0
                },
                {
                    "sent": "The first one is called the Bernoulli model, and here we choose endpoints and throw them uniformly into this thing, right?",
                    "label": 1
                },
                {
                    "sent": "So I have a bag of endpoints and I just throw them at the square and wherever they land, they land.",
                    "label": 1
                },
                {
                    "sent": "Usually we use something that's called Poisson, which is a little easier to work with.",
                    "label": 0
                },
                {
                    "sent": "Where basically the number of points isn't exact but is distributed with some distribution, usually exponential, and there are various technical reasons why that's easier to use, but generally anything that's true in person is true in Bernoulli and vice versa.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's up to epsilon.",
                    "label": 0
                },
                {
                    "sent": "It's always kind of true.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As Marco said, the motivation behind a lot of this work is that we want to look for these structures.",
                    "label": 0
                },
                {
                    "sent": "These topological structures and topological structures generally.",
                    "label": 0
                },
                {
                    "sent": "Well, you know the first question would be what is the?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Elogy Welt apologies.",
                    "label": 0
                },
                {
                    "sent": "This mathematical study of how spaces are connected and we've already seen 2 examples of this in previous examples, right?",
                    "label": 1
                },
                {
                    "sent": "So the first one is clusters, which are just components, so this is what's called 0 dimensional homology, which counts the number of components.",
                    "label": 0
                },
                {
                    "sent": "We've also seen 1 dimensional homology which counts the number of holes of space as, so if it looks like an annulus, it has one component in one hole, right?",
                    "label": 0
                },
                {
                    "sent": "But it might have several holes and.",
                    "label": 0
                },
                {
                    "sent": "Also there's higher dimensional versions of this, right?",
                    "label": 0
                },
                {
                    "sent": "So a sphere has 2 dimensional homology because it encloses a space, right?",
                    "label": 0
                },
                {
                    "sent": "Or a Taurus is also kind of encloses a space and then you have 3 dimensional 4 dimensional and so forth, even though those are things that we can't really draw.",
                    "label": 0
                },
                {
                    "sent": "So for the most part, we're going to concentrate today on one dimensional homology.",
                    "label": 0
                },
                {
                    "sent": "So how many holes does a space have?",
                    "label": 0
                },
                {
                    "sent": "But before we do that, let's go back to take a step back and look.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's components, right?",
                    "label": 0
                },
                {
                    "sent": "So the study of noise.",
                    "label": 0
                },
                {
                    "sent": "Let's say you know how much structure and noise is actually goes back probably 2030 years, and is in the form of random graphs, right?",
                    "label": 0
                },
                {
                    "sent": "So there's many different ways to make random graphs.",
                    "label": 0
                },
                {
                    "sent": "We're going to concentrate today on geometric random graphs.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is I take a pass on point process, right?",
                    "label": 0
                },
                {
                    "sent": "So I've, you know, throw down these points.",
                    "label": 0
                },
                {
                    "sent": "They land wherever they land and then I'm going to build a graph based on them and the way I'm going to do it is I'm just going to look at the distances between the points and if they are within a certain radius then I'm going to connect them right.",
                    "label": 0
                },
                {
                    "sent": "So each time I throw down points.",
                    "label": 0
                },
                {
                    "sent": "Obviously I'm going to get a different graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so kind of what?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Formal definition is, well, a random geometric graph has two parameters right.",
                    "label": 1
                },
                {
                    "sent": "The number of points and the radius that you're going to build it at.",
                    "label": 0
                },
                {
                    "sent": "And you know, basically given these two things, an instantiation, we can build our graph.",
                    "label": 0
                },
                {
                    "sent": "Now, one thing that we always well, not always, but usually the first thing we do is we make the radius right.",
                    "label": 0
                },
                {
                    "sent": "At what scale we build this, we make it a function of the number of points, and then when we do our analysis, we let the number of points go to Infinity, which obviously in real life we never have an infinite amount of data.",
                    "label": 0
                },
                {
                    "sent": "But in this case we can actually do the analysis, whereas for finite N. Things become much, much messier.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a classical result, so let's say this is the 1st result on connectivity, right?",
                    "label": 0
                },
                {
                    "sent": "So the first thing that you might ask is, well, how many components does this graph have at some R?",
                    "label": 0
                },
                {
                    "sent": "And maybe the second question you ask is when do I only have one component right?",
                    "label": 0
                },
                {
                    "sent": "When is this graph completely connected?",
                    "label": 0
                },
                {
                    "sent": "So there's this very classical result by Penrose that says that if you choose R, something like log in over North.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Plus just a little bit.",
                    "label": 0
                },
                {
                    "sent": "It's almost surely connected, right?",
                    "label": 0
                },
                {
                    "sent": "The probability of you being connected goes to one very, very quickly as you as you make see bigger and bigger and bigger, right?",
                    "label": 0
                },
                {
                    "sent": "So you're just adding a little bit of a constant at the end.",
                    "label": 0
                },
                {
                    "sent": "You go a little bit past log North over North and it becomes connected with probability one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is now probably I don't know 20 years old this result people have looked at other models with graphs.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of results in a lot of work.",
                    "label": 0
                },
                {
                    "sent": "Also in let's say under the name.",
                    "label": 0
                },
                {
                    "sent": "Percolation it also comes under a bunch of other names and people understand this.",
                    "label": 0
                },
                {
                    "sent": "Connectivity quite well, but you know, as I said before, we're not just interested in components were interested in these higher dimensional things.",
                    "label": 0
                },
                {
                    "sent": "So like the number of holes and this doesn't really tell us anything about the number of holes.",
                    "label": 0
                },
                {
                    "sent": "First of all, if we even want to talk about these things, we need to go beyond a graph.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We need to go to what are called simplicial complexes, and these are just higher dimensional analogs of graph, so you know if we have zero in one dimension, we have vertices and edges.",
                    "label": 0
                },
                {
                    "sent": "That's a graph.",
                    "label": 0
                },
                {
                    "sent": "If we add triangles, then, then we have a 2 dimensional simplicial complex, a 3 dimensional thing would be a tetrahedra, and then again, as before you have.",
                    "label": 0
                },
                {
                    "sent": "Higher and higher dimensional things, right?",
                    "label": 0
                },
                {
                    "sent": "So since we're going to be interested in holes, we have to go up to triangles, right?",
                    "label": 0
                },
                {
                    "sent": "Because?",
                    "label": 0
                },
                {
                    "sent": "Holes are going to be kind of defined by things that aren't filled in right, and I can.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do the same thing.",
                    "label": 0
                },
                {
                    "sent": "I can put my points at random.",
                    "label": 0
                },
                {
                    "sent": "I can choose a radius and I build my graph and then for some of the triangles I build them.",
                    "label": 0
                },
                {
                    "sent": "I I put in the triangles and then I can start to ask.",
                    "label": 0
                },
                {
                    "sent": "Oh look, you know, here's a whole.",
                    "label": 0
                },
                {
                    "sent": "There's a whole kind of here.",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of different holes here, right?",
                    "label": 0
                },
                {
                    "sent": "So I can ask about, well, you know how many holes are there, for example?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, but how do I actually decide to fill in the triangle?",
                    "label": 0
                },
                {
                    "sent": "Well, that's there are two different ways.",
                    "label": 0
                },
                {
                    "sent": "One is called a check complex.",
                    "label": 0
                },
                {
                    "sent": "One is called the RIPS complex rips.",
                    "label": 0
                },
                {
                    "sent": "Complex is actually easier to do in some sense because we just build our graph and then every time there are three edges arranged in a triangle, we put it in the check.",
                    "label": 0
                },
                {
                    "sent": "Complex is a little more complicated, but not much.",
                    "label": 0
                },
                {
                    "sent": "It's what it says is, well, I'm going to look at these balls of radius R around each point.",
                    "label": 0
                },
                {
                    "sent": "And the graph that I described before is just the intersection graph, which means that if 2 balls intersect, I put the edge in.",
                    "label": 0
                },
                {
                    "sent": "And by analogy I put in triangles when 3 balls intersect.",
                    "label": 0
                },
                {
                    "sent": "So here we have.",
                    "label": 0
                },
                {
                    "sent": "Here we have a triangle 'cause these three balls intersect, and here we don't because there's no intersection, so you know why we do it this way well.",
                    "label": 0
                },
                {
                    "sent": "There's a variety of reasons, but ultimately you can just think of it as just kind of a generative process to get to some random space.",
                    "label": 0
                },
                {
                    "sent": "OK, so you know this also isn't a completely new problem, people.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have looked at it so for the number of holes mat Cal.",
                    "label": 0
                },
                {
                    "sent": "Basically I guess five years ago or so looked at this and prove the following results that says that OK if I have if my radius is too small, something like 1 / N to something.",
                    "label": 0
                },
                {
                    "sent": "There's not enough points close together to actually form a hole.",
                    "label": 0
                },
                {
                    "sent": "If it's too big, right?",
                    "label": 0
                },
                {
                    "sent": "If my radius is too big, everything is covered, right?",
                    "label": 0
                },
                {
                    "sent": "I've covered my entire unit square, so again, there can't be any holes, but in the middle here a lot of things can happen, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "Here we know that it's non zero and we know with high probability that it will be non 0 but we don't really know much else.",
                    "label": 0
                },
                {
                    "sent": "There were some results on, you know roughly how many there were, but not much more was known than that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the reason for these three things is actually kind of something that comes up very often when people look at geometric processes, so.",
                    "label": 0
                },
                {
                    "sent": "Generally people look at what are called regimes.",
                    "label": 0
                },
                {
                    "sent": "So again I said you know the number of points we're going to let them go to Infinity, and we have three regimes.",
                    "label": 0
                },
                {
                    "sent": "We have the subcritical.",
                    "label": 0
                },
                {
                    "sent": "Critical and supercritical right?",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "The subcritical is, is essentially you take a value which is the number of points times the radius to the power of whatever dimension you're in, right?",
                    "label": 0
                },
                {
                    "sent": "So what is that?",
                    "label": 0
                },
                {
                    "sent": "That's really just the volume.",
                    "label": 0
                },
                {
                    "sent": "So R to the D is something like the volume of a ball, and you're saying that the total volume that you're putting of all the balls around these points is going to 0, right?",
                    "label": 0
                },
                {
                    "sent": "So all of these points.",
                    "label": 0
                },
                {
                    "sent": "These balls are kind of shrinking twords points, so you get something that looks like dust.",
                    "label": 0
                },
                {
                    "sent": "In the Super critical regime, well, you know all the balls are kind of expanding fast enough.",
                    "label": 0
                },
                {
                    "sent": "That your total volume goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So you've covered your entire space, but in the middle.",
                    "label": 0
                },
                {
                    "sent": "Here it goes towards some constant.",
                    "label": 0
                },
                {
                    "sent": "And here is where a lot of interesting things happen.",
                    "label": 0
                },
                {
                    "sent": "But this is also kind of the hardest thing to analyze right?",
                    "label": 0
                },
                {
                    "sent": "Because?",
                    "label": 0
                },
                {
                    "sent": "Here it's going to depend a little bit on what the constant is.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a narrow region.",
                    "label": 0
                },
                {
                    "sent": "It's something that's quite fragile, so you know this is where most of the work happens, but it's also the hardest.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one last thing before we kind of get really started with the material is that for some processes there's two almost equivalent viewpoints, so the one we're going to be using today is actually this unit hypercube where we're just going to put points more and more and more points in right.",
                    "label": 0
                },
                {
                    "sent": "But there's I just wanted to point out there's another one where basically you put a point process on your entire Euclidean space, and then you just look at a window centered at the origin and you increase the window size.",
                    "label": 0
                },
                {
                    "sent": "So you look at a bigger and bigger and bigger piece of Euclidian space.",
                    "label": 0
                },
                {
                    "sent": "So these two are equivalent up to scaling.",
                    "label": 0
                },
                {
                    "sent": "And depending on what you're trying to prove.",
                    "label": 0
                },
                {
                    "sent": "One may be easier than the other, but in this case we're just going to stick with this kind of, I think more.",
                    "label": 0
                },
                {
                    "sent": "More kind of intuitive model, which is just this little square that we throw points into.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how do we measure structure right?",
                    "label": 0
                },
                {
                    "sent": "So the title was how much structure can we see?",
                    "label": 0
                },
                {
                    "sent": "We know what our noise model is now, but now how much structure can we see well?",
                    "label": 0
                },
                {
                    "sent": "We could certainly count the number of holes, but you know, these are geometric graphs, so it might makes more sense to ask something about how big these holes are.",
                    "label": 0
                },
                {
                    "sent": "So this is where a tool called persistence comes in.",
                    "label": 0
                },
                {
                    "sent": "So persistence is, I would say, kind of or persistent technologies.",
                    "label": 0
                },
                {
                    "sent": "The main tool that's used in topological data analysis and it's kind of a very simple idea what we're going to do here is not 2 dimensional, but it's just one dimensional function, and we're going to look at.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sublevel sets of this function right?",
                    "label": 0
                },
                {
                    "sent": "So if I take this sublevel set well, the function doesn't cross it so I have nothing here and then as I increase.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That well, now I get this one point and so I keep tracking of this.",
                    "label": 0
                },
                {
                    "sent": "I see I have one component here, right?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I raise it up.",
                    "label": 0
                },
                {
                    "sent": "This one point becomes an interval, but it's still one component.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write a new local minimum means a new component and then you know.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I keep going up these two things.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Become intervals and then eventually they merge.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, this is measuring something about the size of these kind of little wells.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how do we you know?",
                    "label": 0
                },
                {
                    "sent": "How do we actually?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What do we actually compute out of this?",
                    "label": 0
                },
                {
                    "sent": "Well, we're going to keep track of the components as we go through the sublevel sets, right so?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From here to here.",
                    "label": 0
                },
                {
                    "sent": "I keep this bar here because it exists.",
                    "label": 0
                },
                {
                    "sent": "This component exists from here to here and then a new component or appears.",
                    "label": 0
                },
                {
                    "sent": "So I add a new point and.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I go up, well, you know.",
                    "label": 0
                },
                {
                    "sent": "Now I keep tracking these things and then once they merge.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I always then you know I kill one of them off and I always kill off the one that's more recent.",
                    "label": 0
                },
                {
                    "sent": "That's just the way it works then.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I go up, I in 0 dimensions.",
                    "label": 0
                },
                {
                    "sent": "I have one component that lives forever, right?",
                    "label": 0
                },
                {
                    "sent": "I just have this one component at the end, so this is what's called.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Persistence barcode right?",
                    "label": 0
                },
                {
                    "sent": "So this is the output of what we compute, right?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one of the nice bits about this bar code is that it's stable.",
                    "label": 0
                },
                {
                    "sent": "So if I didn't give you this one nice function, but I give you this.",
                    "label": 0
                },
                {
                    "sent": "PL kind of noisy function right then?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The bar code would look something like this, right?",
                    "label": 0
                },
                {
                    "sent": "'cause there's.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot more of these little components that are going to appear and the point is that these long bars look roughly about the same right?",
                    "label": 0
                },
                {
                    "sent": "They might not start or end that exactly the same place, but.",
                    "label": 0
                },
                {
                    "sent": "You can actually formalize exactly how far off they are going to be, but today, where we're kind of asking is well, if I want to know what a long bar is, I need to know what a short bar is, and so I'm going to ask well, how long can these things be?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right and just for various convenience sake.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to either show it as a bar or what's called a persistence diagram, which is just the mapping that's a bar.",
                    "label": 0
                },
                {
                    "sent": "The beginning of the Barber goes through the X axis and the end of the bar goes to the Y axis.",
                    "label": 0
                },
                {
                    "sent": "For some things, it's just easier to see.",
                    "label": 0
                },
                {
                    "sent": "In this diagram case, but otherwise they're completely equivalent.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I showed a function, But what we're going to be interested here are particularly distance functions, right?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to have some points in space and then I'm going to grow balls around them of different radii, and I'm going to get the sequence of spaces right and I'm going to track how many components there are, right?",
                    "label": 0
                },
                {
                    "sent": "So components keep kind of dying off as these little points get connected, and then at some point I see kind of 1 big.",
                    "label": 0
                },
                {
                    "sent": "Annulus kind of appear and then it keeps you know it's still there and then it gets filled in and these are the 1 dimensional bits, right?",
                    "label": 0
                },
                {
                    "sent": "So this part right?",
                    "label": 0
                },
                {
                    "sent": "The 0 dimensional part has actually been covered by all of the random graph theory that people have done.",
                    "label": 0
                },
                {
                    "sent": "So what we're really going to be interested in today is just this bit right?",
                    "label": 0
                },
                {
                    "sent": "So here for example, it's a little hard to see, but there's a little hole here, right, so?",
                    "label": 0
                },
                {
                    "sent": "What we want to be able to say is, well, you know this long bar is really significant.",
                    "label": 0
                },
                {
                    "sent": "And given some noise model and these things are short, right?",
                    "label": 0
                },
                {
                    "sent": "So we want to somehow formalize how short these things can be.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is part of kind of some longer line of thoughts that says, well, you know if I have some generative point process and I compute this persistence diagrams if I just put in noise, right?",
                    "label": 0
                },
                {
                    "sent": "What does it look like?",
                    "label": 1
                },
                {
                    "sent": "What does the diagram of noise actually look like so we know some things?",
                    "label": 1
                },
                {
                    "sent": "Now let's say 2, three years ago, we didn't.",
                    "label": 0
                },
                {
                    "sent": "This, but now you know we know a few things and you know, but we still don't understand everything.",
                    "label": 0
                },
                {
                    "sent": "So today we're going.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at one very specific point of this.",
                    "label": 0
                },
                {
                    "sent": "What does this thing look like, right?",
                    "label": 0
                },
                {
                    "sent": "And specifically going to look at the lifetime.",
                    "label": 0
                },
                {
                    "sent": "So what's the lifetime?",
                    "label": 0
                },
                {
                    "sent": "Well, it's you know, pick your favorite point.",
                    "label": 0
                },
                {
                    "sent": "Look at sex asses.",
                    "label": 0
                },
                {
                    "sent": "That's the birth and it's the Y axis is the death right?",
                    "label": 0
                },
                {
                    "sent": "And so generally the way people look at it is they say, OK, I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measure death minus birthright.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to measure the distance from the to the diagonal here, right?",
                    "label": 0
                },
                {
                    "sent": "For various reasons.",
                    "label": 0
                },
                {
                    "sent": "I'll explain we're not going to do this, but we're going to use relative lifetime, which is going to be the Y axis divided by the X axis, right?",
                    "label": 0
                },
                {
                    "sent": "So in this case, the lowest value you can have is 1, right?",
                    "label": 0
                },
                {
                    "sent": "Because everything?",
                    "label": 0
                },
                {
                    "sent": "Has to do, it has to be born before it can die and then you know you have kind of these lines that illustrate.",
                    "label": 0
                },
                {
                    "sent": "Everything above here has bigger than persistence for everything in between.",
                    "label": 0
                },
                {
                    "sent": "Here is between 4:00 and 2:00, and everything here is between 2:00 and 1:00.",
                    "label": 0
                },
                {
                    "sent": "So one of the main reasons for this, well, OK, the first question we can ask is.",
                    "label": 0
                },
                {
                    "sent": "Does it even matter which one we take?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "I mean if we increase one, the other one almost certainly increases as well, so you know, is there really a point and?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The short answer is yes.",
                    "label": 0
                },
                {
                    "sent": "Well, these things represent different cycles, right?",
                    "label": 0
                },
                {
                    "sent": "So here's one whole.",
                    "label": 0
                },
                {
                    "sent": "This is a relative.",
                    "label": 0
                },
                {
                    "sent": "This is the biggest relative hole here, and this is the biggest kind of absolute difference whole.",
                    "label": 0
                },
                {
                    "sent": "And this is so the blue is always the absolute difference in the red is the relative one, and we can see that these are different things, right?",
                    "label": 0
                },
                {
                    "sent": "So I mean here for the low number of points, we could actually argue that the absolute difference is more meaningful.",
                    "label": 0
                },
                {
                    "sent": "But you know, I mean which is more meaningful is up for debate.",
                    "label": 0
                },
                {
                    "sent": "Since this is actually in noise, but we can see that they are measuring different things so.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's actually kind of a nicer reason for wanting to use this, and that's kind of taking this very nice example of, you know, some points sampled on a circle perfectly of some radius R. So if I want just the absolute difference, it's going to be some function of our right?",
                    "label": 0
                },
                {
                    "sent": "Because these things are going to connect, you know, it's going to have something to do with the distance between these points and R, Whereas this thing, right?",
                    "label": 0
                },
                {
                    "sent": "The relative one.",
                    "label": 0
                },
                {
                    "sent": "Well, it's born at some function of R, and it dies at R. So it's are essentially cancels out and we have just one number, so this is a scale free.",
                    "label": 0
                },
                {
                    "sent": "Quantity which is always nice right?",
                    "label": 0
                },
                {
                    "sent": "It's one less parameter we have to estimate.",
                    "label": 0
                },
                {
                    "sent": "If we use this and you know there's.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can construct kind of very bad examples of outliers, right?",
                    "label": 0
                },
                {
                    "sent": "So I put two outliers here, right?",
                    "label": 0
                },
                {
                    "sent": "And if I were to measure the persistence of this big triangle right, it's actually bigger than this thing, but the relative one is smaller.",
                    "label": 0
                },
                {
                    "sent": "And the explanation for this is that this thing, actually the relative one, also kind of, takes into account not just how long it lives, but also how many points you have when it's born.",
                    "label": 0
                },
                {
                    "sent": "Just that's kind of just a geometric consequence.",
                    "label": 0
                },
                {
                    "sent": "So there are cases where this absolute thing.",
                    "label": 0
                },
                {
                    "sent": "Makes sense, but in a lot of cases this relative measure can actually bring you some nice information and actually makes for more interesting analysis as well.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here are some basic definitions, just to recall, right?",
                    "label": 0
                },
                {
                    "sent": "So we're going to have a cycle.",
                    "label": 0
                },
                {
                    "sent": "For the people that know topology in the audience, I'm going to do the horrible thing of using a cycle and homology class interchangeably, mostly because for the purposes of this analysis, it doesn't matter.",
                    "label": 1
                },
                {
                    "sent": "So birth is just going to be the birth of this cycle.",
                    "label": 1
                },
                {
                    "sent": "Death is going to be the death of this cycle.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to look at this.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But if persistence and the question we're going to answer is, you know if I throw points down at random, what's the biggest one of these I see right?",
                    "label": 0
                },
                {
                    "sent": "So I had this whole persistence diagram, and under this measure, what's the biggest, most?",
                    "label": 0
                },
                {
                    "sent": "The biggest one of over all of those points that we expect to see?",
                    "label": 1
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our result was basically that it should look something like log in over log, log in right.",
                    "label": 0
                },
                {
                    "sent": "So this basically says that there exist constants, right?",
                    "label": 1
                },
                {
                    "sent": "That it's always going to be of this order.",
                    "label": 0
                },
                {
                    "sent": "You know 4 N large enough right?",
                    "label": 0
                },
                {
                    "sent": "So this is kind of the big result of the paper that we that we put up on archive and submitted last year.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing we should do is, well, this is very nice mathematical analysis, But we should do some experiments to verify.",
                    "label": 0
                },
                {
                    "sent": "And here's the kind of sampling.",
                    "label": 0
                },
                {
                    "sent": "So this scale is log in over log, log in and to give you an idea.",
                    "label": 0
                },
                {
                    "sent": "Three is somewhere around like 50 points, 5 is going to be something like 10,000,000 points, and that's the beauty of having a log log N factor.",
                    "label": 0
                },
                {
                    "sent": "You have to go to a lot of very large number of scales in order to actually see anything.",
                    "label": 0
                },
                {
                    "sent": "And you know, you can see that the line, if it's actually quite nicely there is quite a bit.",
                    "label": 0
                },
                {
                    "sent": "It doesn't quite converge, but I'll address that at the end and you might say, well, it kind of looks like it's going down here a bit, but that's actually just because there's very few points here, and if you do things on a Taurus rather than a square, this thing kind of straightens out.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Act OK.",
                    "label": 0
                },
                {
                    "sent": "So kind of going back to this analysis of how do we actually get to this result?",
                    "label": 0
                },
                {
                    "sent": "The big problem is that you know when people generally look at these types of processes.",
                    "label": 0
                },
                {
                    "sent": "They stick to one regime.",
                    "label": 0
                },
                {
                    "sent": "But here we're letting our go from zero to Infinity, right?",
                    "label": 0
                },
                {
                    "sent": "So we have to basically cross all of these regimes, so that's what makes this kind of difficult.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so here we're just going to go quickly over how we actually the rest of the talk is how we prove something like this.",
                    "label": 0
                },
                {
                    "sent": "Because I think it's.",
                    "label": 0
                },
                {
                    "sent": "Surprisingly accessible, there's a few kind of.",
                    "label": 0
                },
                {
                    "sent": "Deep theorems in there, but for the most part, it's kind of surprisingly straightforward, so the lower bound right?",
                    "label": 0
                },
                {
                    "sent": "So we want to show that there exists a cycle of at least this much.",
                    "label": 0
                },
                {
                    "sent": "So how do we do this?",
                    "label": 0
                },
                {
                    "sent": "Well, we assume we have our person point process on the plane and we're going to put a grid on it.",
                    "label": 0
                },
                {
                    "sent": "So a bunch of little boxes arranged in an annulus, right so?",
                    "label": 0
                },
                {
                    "sent": "If I do this, I can now compute the probability of actually seeing a cycle like this, right?",
                    "label": 0
                },
                {
                    "sent": "So what do I want?",
                    "label": 0
                },
                {
                    "sent": "I want at least one point per box, because if I have one point per box, then when I put the balls around it, I've basically made this annulus right, but the second thing is I don't want any points inside right?",
                    "label": 1
                },
                {
                    "sent": "Because if there are no points inside here, well then this thing isn't going to get filled in for at least R, so I can.",
                    "label": 0
                },
                {
                    "sent": "Lower bound, the birth upper bounded death, and then I just take the.",
                    "label": 0
                },
                {
                    "sent": "One over the other an I have a lower bound for my persistence, so that's basically it.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The trick, of course, is choosing your constants carefully, right?",
                    "label": 1
                },
                {
                    "sent": "What is our?",
                    "label": 0
                },
                {
                    "sent": "What is L?",
                    "label": 0
                },
                {
                    "sent": "And so you.",
                    "label": 0
                },
                {
                    "sent": "You spend some time on this and then once you figure it out, you just write it out as though it's obvious and you write it down and you say, OK, well, we do this and you know the persistence is going to be of this size and then we just have to verify that you know.",
                    "label": 0
                },
                {
                    "sent": "With as N goes to Infinity that this happens with probability one.",
                    "label": 0
                },
                {
                    "sent": "And you can do it.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to bore you with the computations because it's kind of just manipulations that you have to do and check to see that it really does go to one.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the lower bound.",
                    "label": 0
                },
                {
                    "sent": "That's all.",
                    "label": 0
                },
                {
                    "sent": "There really is to it, except you know, our points don't always live in the plane, right?",
                    "label": 0
                },
                {
                    "sent": "We have higher dimensional data.",
                    "label": 0
                },
                {
                    "sent": "We have 3 dimensional data.",
                    "label": 0
                },
                {
                    "sent": "We have 10,000 dimensional data.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we actually specify this thing for higher dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "Well, I do the same thing right for this one dimensional case, but I put little boxes and I require there are no points to be in this big box.",
                    "label": 0
                },
                {
                    "sent": "Around this thing because that will tell me that the death that nothing else can kill this earlier than this earlier than I want.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the same constants go through, right?",
                    "label": 0
                },
                {
                    "sent": "So you choose L and you choose these sizes the same way.",
                    "label": 0
                },
                {
                    "sent": "And nothing really changes every you know, the persistence is the same of the same order, and it still goes to the probability still goes to one.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now the tricky part is the upper bound right?",
                    "label": 0
                },
                {
                    "sent": "So we know.",
                    "label": 0
                },
                {
                    "sent": "From you know the thing that I had before, that we know that before this right, there's nothing here, right?",
                    "label": 0
                },
                {
                    "sent": "This is the Super critical.",
                    "label": 0
                },
                {
                    "sent": "We know we have nothing here.",
                    "label": 0
                },
                {
                    "sent": "This is dust and we know we have something here.",
                    "label": 0
                },
                {
                    "sent": "So we have a trivial upper bound of log, right?",
                    "label": 0
                },
                {
                    "sent": "So it's not bad, right?",
                    "label": 0
                },
                {
                    "sent": "Were off by a factor of log log in which.",
                    "label": 0
                },
                {
                    "sent": "Maybe OK, but for probabilists is you know a very wide gap, so you know we have this trivial bound, right?",
                    "label": 0
                },
                {
                    "sent": "'cause the most anything can live is from here to here, so you know that's fine.",
                    "label": 0
                },
                {
                    "sent": "But this actually highlights another point of why we why we should use this kind of relative thing when we're studying noise.",
                    "label": 0
                },
                {
                    "sent": "Well, you know, if I just take the difference between these two.",
                    "label": 0
                },
                {
                    "sent": "So the longest something could live well, it's just going to be of the same order as here, right?",
                    "label": 0
                },
                {
                    "sent": "Because?",
                    "label": 0
                },
                {
                    "sent": "Everything's everything is going to 0, but this goes to zero.",
                    "label": 0
                },
                {
                    "sent": "Much faster than this, so you know if I take this absolute one.",
                    "label": 0
                },
                {
                    "sent": "The one that's going to dominate is just going to be some triangle is essentially going to be outliers.",
                    "label": 0
                },
                {
                    "sent": "I showed before, right?",
                    "label": 0
                },
                {
                    "sent": "It's just going to be something that just appears at the very end, so that's not terribly informative.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so we want a better one.",
                    "label": 0
                },
                {
                    "sent": "We want to close it.",
                    "label": 0
                },
                {
                    "sent": "We want to close the gap so we want sharp upper bound, right?",
                    "label": 0
                },
                {
                    "sent": "So how do we do this while we divide the persistence classes into what we call early and late board?",
                    "label": 1
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the idea here is we pick this our star again.",
                    "label": 0
                },
                {
                    "sent": "Magical constant right?",
                    "label": 0
                },
                {
                    "sent": "And we say everything that's born after this is called late born and everything born before is early born right and the nice bit is, well, half of it's very easy.",
                    "label": 0
                },
                {
                    "sent": "The late born things.",
                    "label": 0
                },
                {
                    "sent": "If we do the math.",
                    "label": 0
                },
                {
                    "sent": "Essentially they're born 2 lights too, actually.",
                    "label": 0
                },
                {
                    "sent": "Affect our upper bound.",
                    "label": 0
                },
                {
                    "sent": "Right, so the late boring things aren't really a factor there.",
                    "label": 0
                },
                {
                    "sent": "You know, even if it appears right here, it'll never really achieve this thing so.",
                    "label": 0
                },
                {
                    "sent": "Now we have the early born and this is really where all the work comes in, right?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have four steps I'm going to not go through them in this kind of very specific way, but kind of give you the idea behind it.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first thing we realize is that OK, early born are relatively small radii.",
                    "label": 0
                },
                {
                    "sent": "It's not quite the dust phase, there are components.",
                    "label": 0
                },
                {
                    "sent": "Things have started coming together, but you don't have this big one component, right?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that you can bound the number of vertices in a component at these small R, right?",
                    "label": 1
                },
                {
                    "sent": "And this is kind of a standard thing and I would say geometric probability.",
                    "label": 0
                },
                {
                    "sent": "That says that you know if your radius is small enough, the number of vertices per component is going to be of this order, right?",
                    "label": 1
                },
                {
                    "sent": "So you don't have anything more than with this.",
                    "label": 1
                },
                {
                    "sent": "Then with this number of vertices, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a start, right?",
                    "label": 0
                },
                {
                    "sent": "So we know there can't be any big components in the early born ones, right?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the OK.",
                    "label": 0
                },
                {
                    "sent": "So now we have a bound on the number of vertices an we have a bound on the edge length, so this edge length is basically going to give us a bound on simplex volume, right?",
                    "label": 0
                },
                {
                    "sent": "So in the graph it's going to give us a bound on the length of any one edge, right?",
                    "label": 0
                },
                {
                    "sent": "That's actually kind of tautological, but it's also going to give us a bound on.",
                    "label": 0
                },
                {
                    "sent": "The volume of any triangle.",
                    "label": 1
                },
                {
                    "sent": "Whereas this we want to take this bound on the number of vertices and we want to turn it into a bound on the number of simplices, right?",
                    "label": 1
                },
                {
                    "sent": "So in this case, the way to think about it is I have N vertices.",
                    "label": 0
                },
                {
                    "sent": "How many edges can I have right so?",
                    "label": 0
                },
                {
                    "sent": "And this is really where the topology comes in because up till now we've basically just done probability.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the result where after we're saying if I have this many vertices.",
                    "label": 0
                },
                {
                    "sent": "How many high dimensional simplices can I actually have?",
                    "label": 0
                },
                {
                    "sent": "So if I had a graph, essentially if I have N vertices, how many edges can I have?",
                    "label": 0
                },
                {
                    "sent": "So the trivial bound here, right?",
                    "label": 0
                },
                {
                    "sent": "Is let me go back.",
                    "label": 0
                },
                {
                    "sent": "So the trivial bounds here is M squared, right?",
                    "label": 0
                },
                {
                    "sent": "So if I've M vertices I can have em squared edges?",
                    "label": 0
                },
                {
                    "sent": "This is too many, because then the triangles I can have mcubed and so forth, right?",
                    "label": 0
                },
                {
                    "sent": "So that's far too loose, abound, and actually what I want is I want to show that there's a linear number of.",
                    "label": 0
                },
                {
                    "sent": "At of edges, for example, are linear number of triangles.",
                    "label": 1
                },
                {
                    "sent": "In that cycle, when I'm in this thing that kind of surrounds this whole and the way I do it is, well, OK.",
                    "label": 0
                },
                {
                    "sent": "I",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Put down these.",
                    "label": 0
                },
                {
                    "sent": "This is the intersection graph of these union of balls, right?",
                    "label": 0
                },
                {
                    "sent": "So this, so I'm not just going to look at this, but I'm going to look.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something bigger, right?",
                    "label": 0
                },
                {
                    "sent": "I'm going to inflate these balls, which means I'm going to add more edges.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So now I have a lot more edges and I can show that in this bigger graph, right?",
                    "label": 0
                },
                {
                    "sent": "I can choose a subset that has this property that's kind of has.",
                    "label": 0
                },
                {
                    "sent": "At most M vertices and at most M edges, right?",
                    "label": 0
                },
                {
                    "sent": "And the way I do this.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is actually a nice standard construction from.",
                    "label": 0
                },
                {
                    "sent": "Computational geometry, and I think pretty much everyone has used this without knowing it at some point, so it's what's called an epsilon net, and so you want to pick a subset of your space such that it's called what's called an epsilon cover and epsilon sparse.",
                    "label": 1
                },
                {
                    "sent": "So let's just go through the algorithm on how you build this so you.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pick a point at random.",
                    "label": 0
                },
                {
                    "sent": "Draw ball of radius R around it, mark every.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's within this right?",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take pic and unmarked points.",
                    "label": 0
                },
                {
                    "sent": "Do the same thing.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pick an unmarked point.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Keep doing this right until all the points are marked and then you take.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just the subsets of the centers of these balls, right?",
                    "label": 0
                },
                {
                    "sent": "And that's your epsilon net, and the point is it covers everything.",
                    "label": 0
                },
                {
                    "sent": "It covers all the points and it's epsilon sparse right?",
                    "label": 0
                },
                {
                    "sent": "No2 red points here are closer than epsilon and there's a nice consequences that if you have this epsilon net right.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vertex will only be part of a constant number of simplices, and that's actually just a simple packing argument that says that you know if things are sparse, then you can't fit too many of them together, right?",
                    "label": 1
                },
                {
                    "sent": "You could in two dimensions, you can only pack six points together like this, such that there are, you know, within some radius R of each other.",
                    "label": 0
                },
                {
                    "sent": "That they're all within the, you know, they all have to be within our of this red point and they have to be at least are distant from each other.",
                    "label": 0
                },
                {
                    "sent": "So the most you can pack is 6 in two dimensions.",
                    "label": 0
                },
                {
                    "sent": "In higher dimensions it goes up, but it's always a constant number, OK?",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So going back to what this means for us, right?",
                    "label": 0
                },
                {
                    "sent": "So we started off with our balls here, right in our graph.",
                    "label": 0
                },
                {
                    "sent": "And you know we have our subset and the key point to say that these two things you know, whatever.",
                    "label": 0
                },
                {
                    "sent": "Kind of cycle we have here in this red cycle are actually the same.",
                    "label": 0
                },
                {
                    "sent": "Basically, well, topologically it's.",
                    "label": 0
                },
                {
                    "sent": "The proof is encoded in this diagram, but the idea ultimately is is that you know because it's an epsilon cover.",
                    "label": 0
                },
                {
                    "sent": "If I just look at the bigger balls around these red points, I've essentially covered everything inside the small of all of these smaller points and so I can actually show that these two cycles are kind of go around the same hole is the idea.",
                    "label": 0
                },
                {
                    "sent": "OK, so there is actually a formal proof for this, but I think that would kind of.",
                    "label": 0
                },
                {
                    "sent": "Take that actually involves a lot of setup and machinery that's I don't think kind of crucial for this for this idea.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we have kind of our basic result, right?",
                    "label": 0
                },
                {
                    "sent": "So we know that.",
                    "label": 0
                },
                {
                    "sent": "Each of our kind of things that go around the whole right.",
                    "label": 0
                },
                {
                    "sent": "These cycles that represent these holes are of size M, where M is the number of vertices.",
                    "label": 0
                },
                {
                    "sent": "We know the volume of any one simplex because we know kind of the upper bound on the edge length, and so we can get a volume on the case cycle right?",
                    "label": 1
                },
                {
                    "sent": "So this would be if I have a cycle, this is a bound on the total length of the cycle, right?",
                    "label": 0
                },
                {
                    "sent": "So you just multiply these two together.",
                    "label": 0
                },
                {
                    "sent": "Each thing you know if there is most this many edges and each one is at most this long.",
                    "label": 0
                },
                {
                    "sent": "The total length is certainly bounded by the product.",
                    "label": 0
                },
                {
                    "sent": "Alright, so OK, now we know how long it can be.",
                    "label": 0
                },
                {
                    "sent": "Well, that actually tells us a lot and.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason is there's this.",
                    "label": 0
                },
                {
                    "sent": "Very very deep deep theorem called that was proven by Federal Fleming called.",
                    "label": 0
                },
                {
                    "sent": "That's basically an isoperimetric inequality that says, well, if I have something of length X right then.",
                    "label": 0
                },
                {
                    "sent": "The latest I could.",
                    "label": 0
                },
                {
                    "sent": "Kind of the biggest volume and the biggest fill in radius, which is exactly what you would think it means, is going to be exactly 1 / K over this volume, right?",
                    "label": 0
                },
                {
                    "sent": "So if I have something of length L?",
                    "label": 0
                },
                {
                    "sent": "R is going to be essentially just the fill in radius is going to be exactly kind of.",
                    "label": 0
                },
                {
                    "sent": "R right, it's going to be linear 'cause K here is going to be one and we know that right?",
                    "label": 0
                },
                {
                    "sent": "So if I take a circle right the length is 2\u03c0 R. Right and R is the radius, so we know that in this in these nice cases this.",
                    "label": 0
                },
                {
                    "sent": "This relation holds, but actually it holds in much more generality, and that's really where the.",
                    "label": 0
                },
                {
                    "sent": "Kind of thing is, and if you're interested in this, which I highly recommend, Larry Goose notes on it, because while this is fairly unreadable, this is quite straightforward.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now we just in the same way as the lower bound.",
                    "label": 0
                },
                {
                    "sent": "We just have to put everything together, right?",
                    "label": 0
                },
                {
                    "sent": "We have our lower bound, our upper bound on the volume.",
                    "label": 0
                },
                {
                    "sent": "We have our upper bound on the number or lower bound on the number of vertices.",
                    "label": 0
                },
                {
                    "sent": "Here we know everything is around the order M. So now we putting these two together, it gives us our volume on the cycle length, which tells us are filling radius and the filling radius is essentially our death time, right?",
                    "label": 0
                },
                {
                    "sent": "So when, when do things get covered and taking one over the other right?",
                    "label": 0
                },
                {
                    "sent": "So our choice of our here is going to tell us our birth time.",
                    "label": 0
                },
                {
                    "sent": "Our choice of.",
                    "label": 0
                },
                {
                    "sent": "Well, from that we're going to compute this upper bound on R, which is R. Which is going to be our death time and we take one over the other and we essentially get exactly the same answer before right?",
                    "label": 0
                },
                {
                    "sent": "So I mean.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of kind of constants here.",
                    "label": 0
                },
                {
                    "sent": "You have to choose correctly, but the idea is really just, you know, bound the number of vertices balance how many.",
                    "label": 0
                },
                {
                    "sent": "Edges there are in this cycle bounds how long each edge can be an.",
                    "label": 0
                },
                {
                    "sent": "That will tell you how big a hole can actually be.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is kind of the most general results, so this is the result we actually have in the paper that works in any dimension.",
                    "label": 0
                },
                {
                    "sent": "The key point here is this one over I, so this says, well, I has to be bigger than one or bigger than zero rather.",
                    "label": 0
                },
                {
                    "sent": "So this doesn't work for graphs.",
                    "label": 0
                },
                {
                    "sent": "This doesn't apply to graphs, but for holes.",
                    "label": 0
                },
                {
                    "sent": "This is going to be 1 four if we're looking for voids in three dimension, it's going to be 2.",
                    "label": 0
                },
                {
                    "sent": "If we're looking for whatever 3 dimensional holes look like, it's going to be 3 and so forth, right?",
                    "label": 0
                },
                {
                    "sent": "And the interesting bit is that the rate does not depend on the ambient dimension.",
                    "label": 0
                },
                {
                    "sent": "This was actually quite surprising for us.",
                    "label": 0
                },
                {
                    "sent": "So the constants here certainly do, right?",
                    "label": 1
                },
                {
                    "sent": "I mean, you know what thing is?",
                    "label": 0
                },
                {
                    "sent": "There's something in front here that's going to depend on dimension and I and whole bunch of other things.",
                    "label": 0
                },
                {
                    "sent": "But you know the general function of N doesn't really matter, right?",
                    "label": 0
                },
                {
                    "sent": "It doesn't depend on these things, which is also surprising, and the other kind of interesting bit is that you know these.",
                    "label": 1
                },
                {
                    "sent": "Whether you know TJ, we often build either check or rips complexes, but in this case the order is actually exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Mostly because these two things are related by a constant factor, so anywhere where there's a constant factor right, it's going from the top and the bottom, and it's not really going to matter.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's our general result.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you know we.",
                    "label": 0
                },
                {
                    "sent": "Did a few more experiments right?",
                    "label": 0
                },
                {
                    "sent": "So we looked for, you know if I'm in 3D, what?",
                    "label": 0
                },
                {
                    "sent": "How many?",
                    "label": 0
                },
                {
                    "sent": "How big are the voids that I can get?",
                    "label": 0
                },
                {
                    "sent": "And again, you know it fits quite well with what we would expect it to.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, even to higher dimensions like 4D and you'll notice that the range of things kind of get smaller and smaller because it gets harder and harder to do it for that many points.",
                    "label": 0
                },
                {
                    "sent": "But you know the general kind of relationship holds.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's kind of where we're at now, so.",
                    "label": 0
                },
                {
                    "sent": "You know there's other work that we're doing right where we want to characterize, you know, let's say not the maximum butt holes of a certain size.",
                    "label": 0
                },
                {
                    "sent": "How many of those can we expect?",
                    "label": 0
                },
                {
                    "sent": "So there's a general or writing up a general result that says that you know for a certain size of holes, it should really go to some sort of normal distribution for this maximum one.",
                    "label": 0
                },
                {
                    "sent": "We know what it looks like, but we don't know something that's perhaps even more.",
                    "label": 0
                },
                {
                    "sent": "That's quite basic.",
                    "label": 0
                },
                {
                    "sent": "Which is we have upper and lower bounds, but we don't have a law of large numbers which says that you know if I if I just take this and take into Infinity, does it converge to an actual constant, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a law of large numbers.",
                    "label": 1
                },
                {
                    "sent": "And why would we experiment certainly suggest this, right?",
                    "label": 0
                },
                {
                    "sent": "So here I have the histogram.",
                    "label": 0
                },
                {
                    "sent": "At 400 points, the green thing is the histogram at 5000 points and the red is at 2 million points, and it certainly start.",
                    "label": 0
                },
                {
                    "sent": "Looks like it's getting more concentrated right?",
                    "label": 0
                },
                {
                    "sent": "But we don't really have a proof for this.",
                    "label": 1
                },
                {
                    "sent": "And why would you really care about a proof for this?",
                    "label": 0
                },
                {
                    "sent": "Well, if you want to do kind of statistical inference based on this, you would really want there to be a law of large numbers, right?",
                    "label": 0
                },
                {
                    "sent": "You would really want there to be some form of convergence so that you could actually start to say things like.",
                    "label": 1
                },
                {
                    "sent": "Can I estimate this reasonably right then?",
                    "label": 0
                },
                {
                    "sent": "The other question is kind of other distributions, right so?",
                    "label": 0
                },
                {
                    "sent": "If I don't have possum, but I have Gaussian or kind of uniform heavy tailed or something like this, what will this maximum look like?",
                    "label": 0
                },
                {
                    "sent": "So the interesting thing is that preliminary calculations seem to suggest that it always looks like the Pasan case, which is something that.",
                    "label": 0
                },
                {
                    "sent": "Is surprising and I don't really fully understand why that should be the case, but it seems like this scaling factor of log in over log log N. Is actually quite should show up in a lot of places where there isn't structure where it's just a noise.",
                    "label": 0
                },
                {
                    "sent": "So if you see something that doesn't scale like this, right?",
                    "label": 0
                },
                {
                    "sent": "So you could think about taking denser and denser subsamples if it grows kind of much faster than this you can be almost sure that it's not coming from some form of noise.",
                    "label": 0
                },
                {
                    "sent": "OK, and actually with that I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So actually quite early so with that, I'll take any questions.",
                    "label": 0
                },
                {
                    "sent": "The question was that whether I considered Vietoris rips complexes on a random set of points we actually use check complexes, but it's yeah that's not there.",
                    "label": 0
                },
                {
                    "sent": "Yes, so so the question is, what about other ways to build these kinds of complex?",
                    "label": 0
                },
                {
                    "sent": "Is there a lot of them?",
                    "label": 0
                },
                {
                    "sent": "One of them probably the most.",
                    "label": 0
                },
                {
                    "sent": "The first one to be studied for graphs is the airdash rainy model where you just put in edges at random with probability P. There's been a lot of work on kind of higher dimensional analogs of this, so the higher one version of this is that you build.",
                    "label": 0
                },
                {
                    "sent": "Airdox Rennie model and then you throw in.",
                    "label": 0
                },
                {
                    "sent": "You basically build the clique complex, so you throw in all possible simplices that you can.",
                    "label": 0
                },
                {
                    "sent": "This has been studied.",
                    "label": 0
                },
                {
                    "sent": "In some cases.",
                    "label": 0
                },
                {
                    "sent": "The other model is called a lineal machine model, which is essentially you take a complete K -- 1 skeleton and then you start putting in K faces.",
                    "label": 0
                },
                {
                    "sent": "There's a lot known about that one.",
                    "label": 0
                },
                {
                    "sent": "On yeah, so in some sense in some sense I'm going to say those those types of models are easier because everything is independent.",
                    "label": 0
                },
                {
                    "sent": "Here you have all of this kind of dependence based on, you know.",
                    "label": 0
                },
                {
                    "sent": "Just based on geometry right there, there's no real geometry to constrain you, whereas here.",
                    "label": 0
                },
                {
                    "sent": "You know it's very hard to make kind of.",
                    "label": 0
                },
                {
                    "sent": "Statements about real independence of simplices, right?",
                    "label": 0
                },
                {
                    "sent": "You can do some things, but not very many, so in some sense this is harder, and this is also why we have fewer results, so there a lot more is known, right?",
                    "label": 0
                },
                {
                    "sent": "So there's a lot known even about how much happy groups and things like that.",
                    "label": 0
                },
                {
                    "sent": "But this is sort of considering, yeah.",
                    "label": 0
                },
                {
                    "sent": "Because we are assuming that our our points are sampled along some lower dimensional space and so you know, we expect geometry to play a role.",
                    "label": 0
                },
                {
                    "sent": "So I got exactly this.",
                    "label": 0
                },
                {
                    "sent": "Discount of this normalization class yes look I'm divided by log book them as far as I remember this is.",
                    "label": 0
                },
                {
                    "sent": "Distance for eldership Well no for airdash.",
                    "label": 0
                },
                {
                    "sent": "I mean, in our dash there's in our destiny.",
                    "label": 0
                },
                {
                    "sent": "There's no distance, right?",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "I can't recall exactly what the mean distances for geometric model, but I don't think it's log in over log log.",
                    "label": 0
                },
                {
                    "sent": "Well, it's a problem, right?",
                    "label": 0
                },
                {
                    "sent": "You take endpoints.",
                    "label": 0
                },
                {
                    "sent": "And distance is the number of edges in distance?",
                    "label": 0
                },
                {
                    "sent": "OK, yes, would you have?",
                    "label": 0
                },
                {
                    "sent": "Or complex networks?",
                    "label": 0
                },
                {
                    "sent": "To pass from OK, I see.",
                    "label": 0
                },
                {
                    "sent": "So you want to take your saying the graph distance in an airdash?",
                    "label": 0
                },
                {
                    "sent": "Ronnie would be something like log in over log log.",
                    "label": 0
                },
                {
                    "sent": "At so, I'm sure that's true at some that might be true at the critical thresholds I'm not.",
                    "label": 0
                },
                {
                    "sent": "I don't particularly call if it's exactly that.",
                    "label": 0
                },
                {
                    "sent": "But if it is, it would well.",
                    "label": 0
                },
                {
                    "sent": "In some sense, it wouldn't be terribly surprising because a lot of these kinds of scaling limits are log in over, you know, have some log in factor in a log log factor, and you know there's only so many ways you can combine these, but I don't think it's.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "It's I mean it is.",
                    "label": 0
                },
                {
                    "sent": "It would be surprising if there was an actual.",
                    "label": 0
                },
                {
                    "sent": "Connection between these right so?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean I could think of some reasons why it would be the case, right?",
                    "label": 0
                },
                {
                    "sent": "So you could take for example in order for any graph.",
                    "label": 0
                },
                {
                    "sent": "And if you were, you can always embed it into a high enough space and build your complete simplicial complex on it, right?",
                    "label": 0
                },
                {
                    "sent": "So embedded into end dimensional space and then look at this distance filtration and that might give you some connection, but it's certainly not an obvious one.",
                    "label": 0
                },
                {
                    "sent": "Let me put it this way.",
                    "label": 0
                },
                {
                    "sent": "OK. Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Just.",
                    "label": 0
                },
                {
                    "sent": "Remember, you were trying to use this right on some real data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, some examples yes.",
                    "label": 0
                },
                {
                    "sent": "Well, so this was really just to try to understand what the null hypothesis should be, but really, I mean ultimately the real problem here is that.",
                    "label": 0
                },
                {
                    "sent": "Well, let me put it this way often.",
                    "label": 0
                },
                {
                    "sent": "The problem is that you know we're given a set of points and we get one diagram right?",
                    "label": 0
                },
                {
                    "sent": "And so from one diagram it's very hard to decide what's noise and what's signal.",
                    "label": 0
                },
                {
                    "sent": "So you know, we could always re sample.",
                    "label": 0
                },
                {
                    "sent": "But you know, even if we re sample, we really can't be sure what's.",
                    "label": 0
                },
                {
                    "sent": "Which which part is noise in which part isn't right, because for the simple fact that these constants, you're never really going to be able to just calculate them.",
                    "label": 0
                },
                {
                    "sent": "But what this seems to suggest there's something that kind of shows up in toy examples is that if we were to take, let's say random subsamples, right, the noise should actually give us some form of.",
                    "label": 0
                },
                {
                    "sent": "Should be kind of should form its own cluster in some sense, and these types of results give us hope that that's actually going to be true where.",
                    "label": 0
                },
                {
                    "sent": "Where this where we kind of see these kinds of structures so?",
                    "label": 0
                },
                {
                    "sent": "It's I can give several examples of things in three dimensions or kind of these continue more kind of heavily sampled processes in higher dimensions, so the one part where this really doesn't work well is when you have sparse data in high dimensions, because that's.",
                    "label": 0
                },
                {
                    "sent": "You know, there just isn't enough information there to build these kinds of global structures, so either it should be kind of you know mid dimensional like maybe you know up to let's say 6 seven dimensions or it needs to be kind of on some very low dimensional thing in high dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "So kind of a prototypical example of where this where we couldn't find structure is in text data for a variety of reasons.",
                    "label": 0
                },
                {
                    "sent": "One is, I think that.",
                    "label": 0
                },
                {
                    "sent": "The metric that we use, which is the cosine metric, is kind of a little too rough, so the.",
                    "label": 0
                },
                {
                    "sent": "The band of where we would actually see a signal is not kind of wide enough.",
                    "label": 0
                },
                {
                    "sent": "So it kind of gets lost in the noise and the other bit is that you know.",
                    "label": 0
                },
                {
                    "sent": "We need well with a better metric.",
                    "label": 0
                },
                {
                    "sent": "We would widen the gap, but we would also kind of not necessarily even need more points.",
                    "label": 0
                },
                {
                    "sent": "Well, more points would certainly help, but we would need kind of better representation so that we could actually.",
                    "label": 0
                },
                {
                    "sent": "Compute all a lot more because it's lower rank.",
                    "label": 0
                },
                {
                    "sent": "But even low rank representations are quite big, right?",
                    "label": 0
                },
                {
                    "sent": "So the problem is the problem actually isn't in computing these things.",
                    "label": 0
                },
                {
                    "sent": "It's the current problem is kind of.",
                    "label": 0
                },
                {
                    "sent": "From a technical standpoint, is how to actually construct our representation, right?",
                    "label": 0
                },
                {
                    "sent": "So graph?",
                    "label": 0
                },
                {
                    "sent": "You know is N squared, which is, let's say, feasable.",
                    "label": 0
                },
                {
                    "sent": "If you cut off early enough.",
                    "label": 0
                },
                {
                    "sent": "Triangles you know if I only care bout holes I already have N cubed just to build the thing because I need to look at all of the triangles and so forth.",
                    "label": 0
                },
                {
                    "sent": "Higher dimensions are, you know, kind of scales, exponentially, badly and one of the key problems I think, is that you know.",
                    "label": 0
                },
                {
                    "sent": "I don't think we can go to the scale yet, where we would actually start to see structure.",
                    "label": 0
                },
                {
                    "sent": "Essentially, I think for these very large datasets, essentially we're cutting it off.",
                    "label": 0
                },
                {
                    "sent": "You know, even for the graph case, you cut it off early enough that everything is essentially.",
                    "label": 0
                },
                {
                    "sent": "Still in the dust phase.",
                    "label": 0
                },
                {
                    "sent": "So you see some small components and things you know we can just go to the beginning of the critical regime and you know you start to see these small components and things, but you don't kind of have.",
                    "label": 0
                },
                {
                    "sent": "A sense of this global structure of that might appear at at bigger radii, where for example the example I would give is you know, for example, between topics for Wikipedia, right?",
                    "label": 0
                },
                {
                    "sent": "So there's this kind of nasty combination of a rough metric plus, which means that any approximation you do is going to be going to further degrade your signal.",
                    "label": 0
                },
                {
                    "sent": "But you know, you kind of want to make things efficient so that you can actually put in enough data that you will actually be able to see the structure.",
                    "label": 0
                },
                {
                    "sent": "So there's still work to be done there, right?",
                    "label": 0
                },
                {
                    "sent": "But I think.",
                    "label": 0
                },
                {
                    "sent": "You know, yeah.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Global.",
                    "label": 0
                },
                {
                    "sent": "Ventra generated so that seems very friendly, so so we looked at that right, but again you have these big components and a bunch of very small components, right?",
                    "label": 0
                },
                {
                    "sent": "That's and I mean there's certainly something to be said about, you know, looking at.",
                    "label": 0
                },
                {
                    "sent": "Looking at the what's it called.",
                    "label": 0
                },
                {
                    "sent": "Things like sizes of the components and.",
                    "label": 0
                },
                {
                    "sent": "You know, if you have some sort of generative process, what can you say about these things?",
                    "label": 0
                },
                {
                    "sent": "And you can say a variety of things that you know that are along these lines, but.",
                    "label": 0
                },
                {
                    "sent": "From what?",
                    "label": 0
                },
                {
                    "sent": "We've seen I don't think there is very much.",
                    "label": 0
                },
                {
                    "sent": "There might be some kind of circular structure, but I think that would be it.",
                    "label": 0
                },
                {
                    "sent": "I can see kind of graphs splitting apart and coming back together, but it's not.",
                    "label": 0
                },
                {
                    "sent": "You know, I don't think you'll.",
                    "label": 0
                },
                {
                    "sent": "I think these graphs are still sparse enough that you won't actually get kind of bigger holes and things like this.",
                    "label": 0
                },
                {
                    "sent": "I mean if they are, they are very small and you know it would certainly be interesting to look at them, but for their we don't just care bout the diagram, we actually want to look at the representatives themselves, and that's something that's still being worked on exactly.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "How can, given some persistent point, how can I pull that back to a cycle that actually means something for that?",
                    "label": 0
                },
                {
                    "sent": "So that's not in.",
                    "label": 0
                },
                {
                    "sent": "That's not an obvious step, right?",
                    "label": 0
                },
                {
                    "sent": "So I think with.",
                    "label": 0
                },
                {
                    "sent": "With that right?",
                    "label": 0
                },
                {
                    "sent": "You will be able to do.",
                    "label": 0
                },
                {
                    "sent": "You'll actually be able to get some information out of graphs like this one.",
                    "label": 0
                },
                {
                    "sent": "Other point I will make though, if you do something like this on these graphs you can get.",
                    "label": 0
                },
                {
                    "sent": "You can still use it as a signature for the graph, right?",
                    "label": 0
                },
                {
                    "sent": "So in the sense that let's say you have two very large components that have the same number of points, it would be.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a strictly more informative.",
                    "label": 0
                },
                {
                    "sent": "Feature than saying just use, let's say all the degrees or something like this.",
                    "label": 0
                },
                {
                    "sent": "And kind of another bit of work that's that's going on now is actually.",
                    "label": 0
                },
                {
                    "sent": "Trying to quantify what the statistical power of these kinds of tests of this feature is right so.",
                    "label": 0
                },
                {
                    "sent": "You know, in that sense, I don't really even care bout persistent things.",
                    "label": 0
                },
                {
                    "sent": "I really care about how all the little things come together, right?",
                    "label": 0
                },
                {
                    "sent": "You could think about, well, you know, a power law graph is going to have a very different thing than a geometric graph for this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "And if you can actually show that.",
                    "label": 0
                },
                {
                    "sent": "This type of thing has a bigger statistical power than what people already use.",
                    "label": 0
                },
                {
                    "sent": "I think that's kind of a valid contribution, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, could you use it to post process?",
                    "label": 0
                },
                {
                    "sent": "Yes, so we've been thinking about this.",
                    "label": 0
                },
                {
                    "sent": "One of the things we want to do is to look at a trained network and what you could do is you could pull back points and look if you know if you what kind of structures you've actually destroyed, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we've thought about this, but we haven't done it yet.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yes.",
                    "label": 0
                },
                {
                    "sent": "Popular contribution.",
                    "label": 0
                },
                {
                    "sent": "OK, are there any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}