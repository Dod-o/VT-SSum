{
    "id": "wsl6dcasbdv2yak3p22yxzc3vmitff75",
    "title": "Comparing Probabilistic Models for Melodic Sequences",
    "info": {
        "produced by": [
            "Data & Web Mining Lab"
        ],
        "author": [
            "Athina Spiliopoulou, School of Informatics, University of Edinburgh"
        ],
        "published": "Nov. 30, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning->Dirichlet Processes",
            "Top->Computer Science->Machine Learning->Markov Processes",
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_spiliopoulou_melodic/",
    "segmentation": [
        [
            "So my name means I can ask for your folio.",
            "I'm a PhD student at the University of Edinburgh and this is joint work with my supervisor, Amos Storkey.",
            "So I'm going to start by asking you to consider the following.",
            "Imagine that someone comes along gives you a set of music thesis and asks you to create new music that has similar style, right?",
            "How would you go about doing this and?"
        ],
        [
            "I guess this is exactly the problem that we're interested in in this work, so we want to learn a generic model for music directly from music sequences.",
            "And we want to do so in an automated way, because while we are a bit lazy and we don't want to have to re engineer the musical features or rebuild our model the next time someone comes along and brings us a different genre.",
            "And this is an interesting problem for machine learning, because structure is one of the fundamentals of music.",
            "But at the same time we have several challenging structural aspects that we want to capture.",
            "So for instance, here in the red and the blue boxes we see repetition of a phrase, but this repetition occurs in different points in time.",
            "And also so we need to be able to capture temporal dependencies and long distance dependencies.",
            "And we also have different variations, so here we have substitution of this last note.",
            "Whereas here we have a splitting of this last node and also some shuffling of the nodes.",
            "Additionally, in music we have several components that interact with one another, so here we can see that although the melody line is.",
            "Almost the same.",
            "The chords that are being played are different, right?",
            "And also for instance in the second case we can see the influence from the meter where the new note the duration of the two nodes is the same as the duration of the original note, so that the piece can respect the metrical boundaries."
        ],
        [
            "So we use a set of Scottish and Irish trees from the Nottingham Folk music database and what we're interested in modeling is the melody line that is the main tune that is being played.",
            "So we have a sequence of nodes and we want to be able to model the Peach and the duration of these nodes.",
            "To do so, we discretize time in eighth time steps and we represent pitch using two octaves C4 to be 5, which gives rise to a 24 value multinomial variable at each time step, and we extend this representation with two extra values.",
            "So we have the first one represents musical rest or silence, and the second one denotes continuation of the event.",
            "So in the blue case here we have.",
            "She eighth note, and this is represented by the corresponding Peach, whereas the red case we have a deep quarter note which is longer, so this is represented by the corresponding pitch at the first time step, followed by continuation at the second time step.",
            "So this is an implicit way of modeling duration.",
            "Right, and here is how.",
            "Sample.",
            "Music sounds like.",
            "Was that?",
            "Could you hear that the bug?",
            "So how do we do?"
        ],
        [
            "This problem or their current state of the art in automated melody generation is the variable length Markov model, and this model learns a conditional probability distribution of the next time step given the past.",
            "Only now the past that the length of the history that we consider is not fixed but depends on the actual context that we observe.",
            "So to learn this model, we build a probabilistic suffix tree and the nodes of the tree are denoted by the context.",
            "And are identified by the empirical probability distribution of the next time step given that context, right?",
            "So this probability here is proportional to the number of times that we observed one following zero in our data.",
            "Now the tree is not complete.",
            "We see that these nodes are not added in the tree because we only had the context that we observe frequently enough in the data.",
            "So here if we want to predict the next time step and we observe 00, then we would use this conditional probability distribution.",
            "Whereas if we observed 01, we would use the shorter context and so we would use this conditional probability distribution, which is only conditioned on just one time step.",
            "And here is a sample from this model.",
            "Which is the current state of the art.",
            "Right and I should say that all the samples that I'm going to play are conditioned on the 1st phrase from the music piece that we listen to in the beginning.",
            "So you may have noticed that there are few inharmonious notes in there and one of the problems with this model is that it's sensitive to the smoothing technique that we use.",
            "So in standard form we use additive smoothing, which generally assigns much of the probability mass too improbable events, and This is why we have these few inharmonious notes in there.",
            "So we decided to."
        ],
        [
            "Proposed a Bayesian approach to smoothing in this context.",
            "So here we propose the DSLAM variable length Markov model and what happens is that the prior for its node is now sampled from Adidas LED distribution that is centered at the parent node.",
            "So here we have the posterior of.",
            "The posterior of the next time step, given the context zero and data, is additional distribution where we have the prior of the parent.",
            "This is the expectation of apparent distribution and we also have the accounts associated with it.",
            "With this context as before, so this is similar to interpolation with lower order models only.",
            "In this case we have a Bayesian formulation.",
            "And it's a bit more.",
            "Um?",
            "Right?"
        ],
        [
            "So the problem with additional AVM is that it's fully observed, and for this reason it doesn't have any facility for learning unobserved variables, right?",
            "But when modeling music, we know that there are unobserved variables which influence what is being observed.",
            "So when modeling melody, we know that the chords and the key influence what is being played, even if these quantities are not explicitly denoted in our data.",
            "For this reason, we decided to also apply a form of restricted Boltzmann machine in the music problem, because this model has been shown to be a good latent feature extractor in other datasets, such as images.",
            "So looking at this figure, a restricted Boltzmann machine with correspond to just a single time step.",
            "We have a set of visible units.",
            "A set of hidden units and all the undirected connections between the two.",
            "Right, this is an energy based model, which means that the joint probability of the visible and hidden configuration is defined in terms of an energy function.",
            "Which assigns low energy to probable configurations and high energy to improbable ones.",
            "So now in the context of the music modeling were dealing with sequential data, so we want our models to be able to capture temporal dependencies, and This is why we extend.",
            "We extended the restricted Boltzmann machine so that the hidden hidden units at each time step receive input from a whole subsequence.",
            "So here three time steps rather than a single time step, right?",
            "And how does this work well?",
            "Um, it's hidden unit.",
            "Learns."
        ],
        [
            "A weight matrix, right?",
            "So this is 26 by three were 26 is the number of visible units that we have, and three is the number of time steps from which our unit receives input and you can see here a weight matrix for just a single unit.",
            "So because the model is time convolutional, what we do is we effectively take this weight matrix and do elementwise multiplication and addition with our visible configuration, right?",
            "So here I have three different visible configurations.",
            "And we can see that this unit would be highly responsive to this first phase, right?",
            "Because the same, the weights here are high, so it's going to prefer these three nodes.",
            "It would also respond to this configuration because these weights are also quite high.",
            "But it would probably have a very low probability of turning on if we solve this configuration."
        ],
        [
            "So having described the.",
            "Models and the problem we come to the difficult issue of evaluation and this is very much an open problem because it's very difficult to say what is a good generative model for music.",
            "So obviously we can listen to model generations, but we don't know of any rigorous way of assessing the musical subtlety of the music that generated music.",
            "So in the absence of an appropriate human evaluation paradigm, we used two proxies for quantitative evaluation.",
            "First, we assess the models in the prediction task where we basically compute the prediction log.",
            "Likelihood of future time steps in test sequences under the models, and Secondly we generated samples from the models and we computed the sort order statistics of samples and of test sequences.",
            "And then compare these using the callback later versions.",
            "In order to see how well the samples match our data.",
            "Finally, for the time convolutional RBM, we examined the qualitative evaluation where we basically looked at the latent structure that the model has learned and try to understand whether this corresponds to underlying musical features."
        ],
        [
            "Now, regarding the prediction task, this figure here shows the prediction log likelihood of 20 future time steps under 4 movies.",
            "So the black line here, which is fairly steady throughout time, is the empirical marginal distribution.",
            "That is, the probability of a node is proportional to the number of times we have observed these nodes in our training data, right?",
            "And this is the baseline that we use because it's the maximum likelihood model.",
            "If we ignore any temporal dependencies.",
            "So what we can see here is that the time convolutional RBM, which is the blue line and the dish levier men, which is the Scion line, perform much better than the standard PM in all future time steps.",
            "And also we can see how the models behave in time.",
            "So for the first 10 time steps the model perform better than the two proposed models perform better than the empirical marginal distribution.",
            "But as we try to predict.",
            "Further into the future, the information upon which we condition is forgotten.",
            "And the models converge to a steady state distribution, which in the case of the time convolutional RBM and the dish left variable length Markov model is close to the empirical marginal, whereas for the VMM is worse."
        ],
        [
            "Now, with respect to the comparison of statistics, what we're trying to do here is we have two populations.",
            "The samples generated from the model and the test pieces.",
            "And we want to see how well these if these are similar, right?",
            "So for single order statistics, we would compute the empirical probability of a single note in our samples and in our test sequences and compute the KL divergent between the two.",
            "For 2nd order statistics we compute the empirical probability over all possible combinations of two subsequent nodes and so on and here.",
            "Obviously the lower the KL divergent, the better our model matches the data and here we can see that for order one statistics that there is less variable length.",
            "Markov model performs the best, but for higher order statistics that this RBM time convolutional restricted Boltzmann machine performs better.",
            "And the variable length Markov model is always worse."
        ],
        [
            "OK, so.",
            "Um, now with you regarding the qualitative evaluation of the time convolutional RBM.",
            "This figure here shows 6 features that the model has learned, so these these are the weight matrices for six hidden units.",
            "Here we can observe some interesting structure, so the top filters so we're relationship to the octave.",
            "So both filters correspond to similar configuration of the scale nodes.",
            "Only the first unit.",
            "Is mostly selective to notes from the lower octave, whereas the second unit is selective to note 4 notes from the higher octave.",
            "Right in the middle features we can see a relation to the cords.",
            "So here in the all time steps we see the notes from the the filter is selective to notes from the G major chord that is the BNG whereas at the even time step this filter is selected to notes from the A minor chord that is is A&C.",
            "And for filter for this is vice versa.",
            "And finally, in the bottom row we can see the degree of selectivity that different units may have.",
            "So Unit 5 is highly selective to downward upward movement through the scale, whereas Unit 6 is more broad and would respond to several configurations of the scale nodes.",
            "Right, so to understand a bit more how the model behave, we also looked at visible configurations that tend to activate the hidden units, and this bottom figure here shows two sites configurations for the hidden Unit 5.",
            "So at the first glance, these two configurations are different, but they both of them the arpeggio DB&G.",
            "Which is a frequent motif in this genre and in the first case these important notes, so it's followed by continuation, whereas in the second case these an eighth note and there is a scene that is between the."
        ],
        [
            "So to conclude, I hope at least that I convinced you that the music problem is interesting.",
            "In this work we introduce two models, the Dish live variable length Markov model, and the time convolutional restricted Boltzmann machine.",
            "For tackling this problem and using two proxies for quantitative evaluation, we show that the models outperform the current state of the art in automated melody generation, and now it's time for.",
            "For music, again.",
            "So here is a sample from the dish left variable length mark model.",
            "And here is a sample from the time convolutional restricted Boltzmann scene.",
            "Right so finally for future work, an interesting direction is to look at models that can deal with Inter an entropy similarity, because basically music.",
            "Every piece is a new composition, so novelty is there by default.",
            "And yeah, we can.",
            "We can talk about we have some work on that, but I'm not going to go into detail right now so."
        ],
        [
            "Thank you.",
            "That was very interesting.",
            "Question right in the back there.",
            "Hello.",
            "I have two questions.",
            "The first is you only showed us monophonic melodies.",
            "So my question is, what do you think we should need?",
            "It needs to be changed to be polyphonic, the other is.",
            "You talked about both cards at the beginning, but now you only shout monophonic melodies.",
            "So what is the?",
            "How do you specify the the harmonic scale on which you work?",
            "Or is it automatically detected?",
            "But what scale?",
            "Or what harmonic system do you use or so?",
            "So what do you do with the scaled right?",
            "If if I understand I'll answer the second question first, so the music pieces that we use here.",
            "Are all in the key of G, so this is not that does not differ, but generally in the literature you know there are approaches where it can detect the key from the music, so you could have some preprocessing step if you had music from different keys.",
            "And with regards to polyphonic music.",
            "Typically what has been done in the literature is that you learn a model for the chord progression and then you condition your.",
            "Melody model on the court and this can be easily done using, for instance, the deerslayer variable length Markov model, where he learned Irish levy MM for the chords like for the chord progression.",
            "'cause again you have a sequence and then in your tree you somehow include these chords.",
            "Your conditional probability distribution over notes in the melody, right?",
            "So this is the simplest approach that I can think of.",
            "But yeah we haven't tried polyphonic music yet.",
            "Change the parts in the background or I mean the key is clear, but.",
            "So do you have there weren't no chords here that in the music that I played with another question from.",
            "So sorry for being non accurate.",
            "It was along time when I started harmonium music but my questions I am not sure if maybe you answer it already but there is such a thing like harmonik donation and so on.",
            "And I could imagine if you are a violation statistician I would put some priors on certain configurations of.",
            "An adult which corresponds to some cards which are inherent in a certain type of music in a certain notation.",
            "So you mention about preprocessing, right learning the termination of a piece of music, right?",
            "Yeah, we don't do this right.",
            "We by default the music that we're looking at is just in the key of G, But so This is why I stress the word automated because.",
            "The main goal is to try to keep the models as generic as possible so that we don't need to change all these priors.",
            "If we're dealing with different genres, right?",
            "So we want it to be as generic as possible, and of course we simplify the problem here.",
            "So obviously in the future we need to find some way of addressing these problems.",
            "But yeah, at the moment were so we're trying to keep the musical information as low as possible.",
            "Automated system would include different stages of preprocessing.",
            "Yes, yes.",
            "Cool question.",
            "About the position task, I was wondering if someone is using technique of time series prediction multiple step add time series prediction.",
            "For doing similar stuff in the music, yeah.",
            "I mean it's a prediction test.",
            "Again, you're considering this prediction task.",
            "The only thing that I've seen for prediction, well, I mean there is literature they have done recurrent neural networks where you again you predict the next time step and there are.",
            "Hierarchical Hmm's so that there is literature there but the variable life market model still outperforms this, so it's it's quite as surprising.",
            "I'm going to have to stop there.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So my name means I can ask for your folio.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at the University of Edinburgh and this is joint work with my supervisor, Amos Storkey.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to start by asking you to consider the following.",
                    "label": 0
                },
                {
                    "sent": "Imagine that someone comes along gives you a set of music thesis and asks you to create new music that has similar style, right?",
                    "label": 0
                },
                {
                    "sent": "How would you go about doing this and?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I guess this is exactly the problem that we're interested in in this work, so we want to learn a generic model for music directly from music sequences.",
                    "label": 1
                },
                {
                    "sent": "And we want to do so in an automated way, because while we are a bit lazy and we don't want to have to re engineer the musical features or rebuild our model the next time someone comes along and brings us a different genre.",
                    "label": 0
                },
                {
                    "sent": "And this is an interesting problem for machine learning, because structure is one of the fundamentals of music.",
                    "label": 1
                },
                {
                    "sent": "But at the same time we have several challenging structural aspects that we want to capture.",
                    "label": 0
                },
                {
                    "sent": "So for instance, here in the red and the blue boxes we see repetition of a phrase, but this repetition occurs in different points in time.",
                    "label": 0
                },
                {
                    "sent": "And also so we need to be able to capture temporal dependencies and long distance dependencies.",
                    "label": 0
                },
                {
                    "sent": "And we also have different variations, so here we have substitution of this last note.",
                    "label": 0
                },
                {
                    "sent": "Whereas here we have a splitting of this last node and also some shuffling of the nodes.",
                    "label": 0
                },
                {
                    "sent": "Additionally, in music we have several components that interact with one another, so here we can see that although the melody line is.",
                    "label": 1
                },
                {
                    "sent": "Almost the same.",
                    "label": 0
                },
                {
                    "sent": "The chords that are being played are different, right?",
                    "label": 0
                },
                {
                    "sent": "And also for instance in the second case we can see the influence from the meter where the new note the duration of the two nodes is the same as the duration of the original note, so that the piece can respect the metrical boundaries.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we use a set of Scottish and Irish trees from the Nottingham Folk music database and what we're interested in modeling is the melody line that is the main tune that is being played.",
                    "label": 1
                },
                {
                    "sent": "So we have a sequence of nodes and we want to be able to model the Peach and the duration of these nodes.",
                    "label": 0
                },
                {
                    "sent": "To do so, we discretize time in eighth time steps and we represent pitch using two octaves C4 to be 5, which gives rise to a 24 value multinomial variable at each time step, and we extend this representation with two extra values.",
                    "label": 0
                },
                {
                    "sent": "So we have the first one represents musical rest or silence, and the second one denotes continuation of the event.",
                    "label": 0
                },
                {
                    "sent": "So in the blue case here we have.",
                    "label": 0
                },
                {
                    "sent": "She eighth note, and this is represented by the corresponding Peach, whereas the red case we have a deep quarter note which is longer, so this is represented by the corresponding pitch at the first time step, followed by continuation at the second time step.",
                    "label": 0
                },
                {
                    "sent": "So this is an implicit way of modeling duration.",
                    "label": 0
                },
                {
                    "sent": "Right, and here is how.",
                    "label": 0
                },
                {
                    "sent": "Sample.",
                    "label": 0
                },
                {
                    "sent": "Music sounds like.",
                    "label": 0
                },
                {
                    "sent": "Was that?",
                    "label": 0
                },
                {
                    "sent": "Could you hear that the bug?",
                    "label": 0
                },
                {
                    "sent": "So how do we do?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problem or their current state of the art in automated melody generation is the variable length Markov model, and this model learns a conditional probability distribution of the next time step given the past.",
                    "label": 1
                },
                {
                    "sent": "Only now the past that the length of the history that we consider is not fixed but depends on the actual context that we observe.",
                    "label": 1
                },
                {
                    "sent": "So to learn this model, we build a probabilistic suffix tree and the nodes of the tree are denoted by the context.",
                    "label": 0
                },
                {
                    "sent": "And are identified by the empirical probability distribution of the next time step given that context, right?",
                    "label": 0
                },
                {
                    "sent": "So this probability here is proportional to the number of times that we observed one following zero in our data.",
                    "label": 0
                },
                {
                    "sent": "Now the tree is not complete.",
                    "label": 1
                },
                {
                    "sent": "We see that these nodes are not added in the tree because we only had the context that we observe frequently enough in the data.",
                    "label": 0
                },
                {
                    "sent": "So here if we want to predict the next time step and we observe 00, then we would use this conditional probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Whereas if we observed 01, we would use the shorter context and so we would use this conditional probability distribution, which is only conditioned on just one time step.",
                    "label": 0
                },
                {
                    "sent": "And here is a sample from this model.",
                    "label": 0
                },
                {
                    "sent": "Which is the current state of the art.",
                    "label": 0
                },
                {
                    "sent": "Right and I should say that all the samples that I'm going to play are conditioned on the 1st phrase from the music piece that we listen to in the beginning.",
                    "label": 0
                },
                {
                    "sent": "So you may have noticed that there are few inharmonious notes in there and one of the problems with this model is that it's sensitive to the smoothing technique that we use.",
                    "label": 0
                },
                {
                    "sent": "So in standard form we use additive smoothing, which generally assigns much of the probability mass too improbable events, and This is why we have these few inharmonious notes in there.",
                    "label": 0
                },
                {
                    "sent": "So we decided to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proposed a Bayesian approach to smoothing in this context.",
                    "label": 0
                },
                {
                    "sent": "So here we propose the DSLAM variable length Markov model and what happens is that the prior for its node is now sampled from Adidas LED distribution that is centered at the parent node.",
                    "label": 1
                },
                {
                    "sent": "So here we have the posterior of.",
                    "label": 0
                },
                {
                    "sent": "The posterior of the next time step, given the context zero and data, is additional distribution where we have the prior of the parent.",
                    "label": 0
                },
                {
                    "sent": "This is the expectation of apparent distribution and we also have the accounts associated with it.",
                    "label": 0
                },
                {
                    "sent": "With this context as before, so this is similar to interpolation with lower order models only.",
                    "label": 0
                },
                {
                    "sent": "In this case we have a Bayesian formulation.",
                    "label": 0
                },
                {
                    "sent": "And it's a bit more.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem with additional AVM is that it's fully observed, and for this reason it doesn't have any facility for learning unobserved variables, right?",
                    "label": 0
                },
                {
                    "sent": "But when modeling music, we know that there are unobserved variables which influence what is being observed.",
                    "label": 0
                },
                {
                    "sent": "So when modeling melody, we know that the chords and the key influence what is being played, even if these quantities are not explicitly denoted in our data.",
                    "label": 0
                },
                {
                    "sent": "For this reason, we decided to also apply a form of restricted Boltzmann machine in the music problem, because this model has been shown to be a good latent feature extractor in other datasets, such as images.",
                    "label": 0
                },
                {
                    "sent": "So looking at this figure, a restricted Boltzmann machine with correspond to just a single time step.",
                    "label": 0
                },
                {
                    "sent": "We have a set of visible units.",
                    "label": 0
                },
                {
                    "sent": "A set of hidden units and all the undirected connections between the two.",
                    "label": 0
                },
                {
                    "sent": "Right, this is an energy based model, which means that the joint probability of the visible and hidden configuration is defined in terms of an energy function.",
                    "label": 0
                },
                {
                    "sent": "Which assigns low energy to probable configurations and high energy to improbable ones.",
                    "label": 0
                },
                {
                    "sent": "So now in the context of the music modeling were dealing with sequential data, so we want our models to be able to capture temporal dependencies, and This is why we extend.",
                    "label": 0
                },
                {
                    "sent": "We extended the restricted Boltzmann machine so that the hidden hidden units at each time step receive input from a whole subsequence.",
                    "label": 1
                },
                {
                    "sent": "So here three time steps rather than a single time step, right?",
                    "label": 0
                },
                {
                    "sent": "And how does this work well?",
                    "label": 0
                },
                {
                    "sent": "Um, it's hidden unit.",
                    "label": 0
                },
                {
                    "sent": "Learns.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A weight matrix, right?",
                    "label": 0
                },
                {
                    "sent": "So this is 26 by three were 26 is the number of visible units that we have, and three is the number of time steps from which our unit receives input and you can see here a weight matrix for just a single unit.",
                    "label": 0
                },
                {
                    "sent": "So because the model is time convolutional, what we do is we effectively take this weight matrix and do elementwise multiplication and addition with our visible configuration, right?",
                    "label": 0
                },
                {
                    "sent": "So here I have three different visible configurations.",
                    "label": 0
                },
                {
                    "sent": "And we can see that this unit would be highly responsive to this first phase, right?",
                    "label": 0
                },
                {
                    "sent": "Because the same, the weights here are high, so it's going to prefer these three nodes.",
                    "label": 0
                },
                {
                    "sent": "It would also respond to this configuration because these weights are also quite high.",
                    "label": 0
                },
                {
                    "sent": "But it would probably have a very low probability of turning on if we solve this configuration.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So having described the.",
                    "label": 0
                },
                {
                    "sent": "Models and the problem we come to the difficult issue of evaluation and this is very much an open problem because it's very difficult to say what is a good generative model for music.",
                    "label": 1
                },
                {
                    "sent": "So obviously we can listen to model generations, but we don't know of any rigorous way of assessing the musical subtlety of the music that generated music.",
                    "label": 1
                },
                {
                    "sent": "So in the absence of an appropriate human evaluation paradigm, we used two proxies for quantitative evaluation.",
                    "label": 0
                },
                {
                    "sent": "First, we assess the models in the prediction task where we basically compute the prediction log.",
                    "label": 0
                },
                {
                    "sent": "Likelihood of future time steps in test sequences under the models, and Secondly we generated samples from the models and we computed the sort order statistics of samples and of test sequences.",
                    "label": 0
                },
                {
                    "sent": "And then compare these using the callback later versions.",
                    "label": 0
                },
                {
                    "sent": "In order to see how well the samples match our data.",
                    "label": 0
                },
                {
                    "sent": "Finally, for the time convolutional RBM, we examined the qualitative evaluation where we basically looked at the latent structure that the model has learned and try to understand whether this corresponds to underlying musical features.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, regarding the prediction task, this figure here shows the prediction log likelihood of 20 future time steps under 4 movies.",
                    "label": 1
                },
                {
                    "sent": "So the black line here, which is fairly steady throughout time, is the empirical marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "That is, the probability of a node is proportional to the number of times we have observed these nodes in our training data, right?",
                    "label": 0
                },
                {
                    "sent": "And this is the baseline that we use because it's the maximum likelihood model.",
                    "label": 0
                },
                {
                    "sent": "If we ignore any temporal dependencies.",
                    "label": 0
                },
                {
                    "sent": "So what we can see here is that the time convolutional RBM, which is the blue line and the dish levier men, which is the Scion line, perform much better than the standard PM in all future time steps.",
                    "label": 1
                },
                {
                    "sent": "And also we can see how the models behave in time.",
                    "label": 0
                },
                {
                    "sent": "So for the first 10 time steps the model perform better than the two proposed models perform better than the empirical marginal distribution.",
                    "label": 1
                },
                {
                    "sent": "But as we try to predict.",
                    "label": 0
                },
                {
                    "sent": "Further into the future, the information upon which we condition is forgotten.",
                    "label": 0
                },
                {
                    "sent": "And the models converge to a steady state distribution, which in the case of the time convolutional RBM and the dish left variable length Markov model is close to the empirical marginal, whereas for the VMM is worse.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, with respect to the comparison of statistics, what we're trying to do here is we have two populations.",
                    "label": 0
                },
                {
                    "sent": "The samples generated from the model and the test pieces.",
                    "label": 0
                },
                {
                    "sent": "And we want to see how well these if these are similar, right?",
                    "label": 0
                },
                {
                    "sent": "So for single order statistics, we would compute the empirical probability of a single note in our samples and in our test sequences and compute the KL divergent between the two.",
                    "label": 0
                },
                {
                    "sent": "For 2nd order statistics we compute the empirical probability over all possible combinations of two subsequent nodes and so on and here.",
                    "label": 0
                },
                {
                    "sent": "Obviously the lower the KL divergent, the better our model matches the data and here we can see that for order one statistics that there is less variable length.",
                    "label": 0
                },
                {
                    "sent": "Markov model performs the best, but for higher order statistics that this RBM time convolutional restricted Boltzmann machine performs better.",
                    "label": 0
                },
                {
                    "sent": "And the variable length Markov model is always worse.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Um, now with you regarding the qualitative evaluation of the time convolutional RBM.",
                    "label": 0
                },
                {
                    "sent": "This figure here shows 6 features that the model has learned, so these these are the weight matrices for six hidden units.",
                    "label": 0
                },
                {
                    "sent": "Here we can observe some interesting structure, so the top filters so we're relationship to the octave.",
                    "label": 0
                },
                {
                    "sent": "So both filters correspond to similar configuration of the scale nodes.",
                    "label": 0
                },
                {
                    "sent": "Only the first unit.",
                    "label": 0
                },
                {
                    "sent": "Is mostly selective to notes from the lower octave, whereas the second unit is selective to note 4 notes from the higher octave.",
                    "label": 0
                },
                {
                    "sent": "Right in the middle features we can see a relation to the cords.",
                    "label": 0
                },
                {
                    "sent": "So here in the all time steps we see the notes from the the filter is selective to notes from the G major chord that is the BNG whereas at the even time step this filter is selected to notes from the A minor chord that is is A&C.",
                    "label": 0
                },
                {
                    "sent": "And for filter for this is vice versa.",
                    "label": 0
                },
                {
                    "sent": "And finally, in the bottom row we can see the degree of selectivity that different units may have.",
                    "label": 0
                },
                {
                    "sent": "So Unit 5 is highly selective to downward upward movement through the scale, whereas Unit 6 is more broad and would respond to several configurations of the scale nodes.",
                    "label": 0
                },
                {
                    "sent": "Right, so to understand a bit more how the model behave, we also looked at visible configurations that tend to activate the hidden units, and this bottom figure here shows two sites configurations for the hidden Unit 5.",
                    "label": 0
                },
                {
                    "sent": "So at the first glance, these two configurations are different, but they both of them the arpeggio DB&G.",
                    "label": 0
                },
                {
                    "sent": "Which is a frequent motif in this genre and in the first case these important notes, so it's followed by continuation, whereas in the second case these an eighth note and there is a scene that is between the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, I hope at least that I convinced you that the music problem is interesting.",
                    "label": 0
                },
                {
                    "sent": "In this work we introduce two models, the Dish live variable length Markov model, and the time convolutional restricted Boltzmann machine.",
                    "label": 1
                },
                {
                    "sent": "For tackling this problem and using two proxies for quantitative evaluation, we show that the models outperform the current state of the art in automated melody generation, and now it's time for.",
                    "label": 0
                },
                {
                    "sent": "For music, again.",
                    "label": 0
                },
                {
                    "sent": "So here is a sample from the dish left variable length mark model.",
                    "label": 0
                },
                {
                    "sent": "And here is a sample from the time convolutional restricted Boltzmann scene.",
                    "label": 0
                },
                {
                    "sent": "Right so finally for future work, an interesting direction is to look at models that can deal with Inter an entropy similarity, because basically music.",
                    "label": 0
                },
                {
                    "sent": "Every piece is a new composition, so novelty is there by default.",
                    "label": 0
                },
                {
                    "sent": "And yeah, we can.",
                    "label": 0
                },
                {
                    "sent": "We can talk about we have some work on that, but I'm not going to go into detail right now so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "That was very interesting.",
                    "label": 0
                },
                {
                    "sent": "Question right in the back there.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                },
                {
                    "sent": "I have two questions.",
                    "label": 0
                },
                {
                    "sent": "The first is you only showed us monophonic melodies.",
                    "label": 0
                },
                {
                    "sent": "So my question is, what do you think we should need?",
                    "label": 0
                },
                {
                    "sent": "It needs to be changed to be polyphonic, the other is.",
                    "label": 0
                },
                {
                    "sent": "You talked about both cards at the beginning, but now you only shout monophonic melodies.",
                    "label": 0
                },
                {
                    "sent": "So what is the?",
                    "label": 0
                },
                {
                    "sent": "How do you specify the the harmonic scale on which you work?",
                    "label": 0
                },
                {
                    "sent": "Or is it automatically detected?",
                    "label": 0
                },
                {
                    "sent": "But what scale?",
                    "label": 0
                },
                {
                    "sent": "Or what harmonic system do you use or so?",
                    "label": 0
                },
                {
                    "sent": "So what do you do with the scaled right?",
                    "label": 0
                },
                {
                    "sent": "If if I understand I'll answer the second question first, so the music pieces that we use here.",
                    "label": 0
                },
                {
                    "sent": "Are all in the key of G, so this is not that does not differ, but generally in the literature you know there are approaches where it can detect the key from the music, so you could have some preprocessing step if you had music from different keys.",
                    "label": 0
                },
                {
                    "sent": "And with regards to polyphonic music.",
                    "label": 0
                },
                {
                    "sent": "Typically what has been done in the literature is that you learn a model for the chord progression and then you condition your.",
                    "label": 0
                },
                {
                    "sent": "Melody model on the court and this can be easily done using, for instance, the deerslayer variable length Markov model, where he learned Irish levy MM for the chords like for the chord progression.",
                    "label": 0
                },
                {
                    "sent": "'cause again you have a sequence and then in your tree you somehow include these chords.",
                    "label": 0
                },
                {
                    "sent": "Your conditional probability distribution over notes in the melody, right?",
                    "label": 0
                },
                {
                    "sent": "So this is the simplest approach that I can think of.",
                    "label": 0
                },
                {
                    "sent": "But yeah we haven't tried polyphonic music yet.",
                    "label": 0
                },
                {
                    "sent": "Change the parts in the background or I mean the key is clear, but.",
                    "label": 0
                },
                {
                    "sent": "So do you have there weren't no chords here that in the music that I played with another question from.",
                    "label": 0
                },
                {
                    "sent": "So sorry for being non accurate.",
                    "label": 0
                },
                {
                    "sent": "It was along time when I started harmonium music but my questions I am not sure if maybe you answer it already but there is such a thing like harmonik donation and so on.",
                    "label": 0
                },
                {
                    "sent": "And I could imagine if you are a violation statistician I would put some priors on certain configurations of.",
                    "label": 0
                },
                {
                    "sent": "An adult which corresponds to some cards which are inherent in a certain type of music in a certain notation.",
                    "label": 0
                },
                {
                    "sent": "So you mention about preprocessing, right learning the termination of a piece of music, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, we don't do this right.",
                    "label": 0
                },
                {
                    "sent": "We by default the music that we're looking at is just in the key of G, But so This is why I stress the word automated because.",
                    "label": 0
                },
                {
                    "sent": "The main goal is to try to keep the models as generic as possible so that we don't need to change all these priors.",
                    "label": 0
                },
                {
                    "sent": "If we're dealing with different genres, right?",
                    "label": 0
                },
                {
                    "sent": "So we want it to be as generic as possible, and of course we simplify the problem here.",
                    "label": 0
                },
                {
                    "sent": "So obviously in the future we need to find some way of addressing these problems.",
                    "label": 0
                },
                {
                    "sent": "But yeah, at the moment were so we're trying to keep the musical information as low as possible.",
                    "label": 0
                },
                {
                    "sent": "Automated system would include different stages of preprocessing.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Cool question.",
                    "label": 0
                },
                {
                    "sent": "About the position task, I was wondering if someone is using technique of time series prediction multiple step add time series prediction.",
                    "label": 0
                },
                {
                    "sent": "For doing similar stuff in the music, yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean it's a prediction test.",
                    "label": 0
                },
                {
                    "sent": "Again, you're considering this prediction task.",
                    "label": 0
                },
                {
                    "sent": "The only thing that I've seen for prediction, well, I mean there is literature they have done recurrent neural networks where you again you predict the next time step and there are.",
                    "label": 0
                },
                {
                    "sent": "Hierarchical Hmm's so that there is literature there but the variable life market model still outperforms this, so it's it's quite as surprising.",
                    "label": 0
                },
                {
                    "sent": "I'm going to have to stop there.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}