{
    "id": "vvy3rocr4eg6rzmecyvjivsxfupqvrxn",
    "title": "Graphical Models, Variational Methods, and Message-Passing",
    "info": {
        "author": [
            "Martin J. Wainwright, UC Berkeley"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "July 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/mlss06tw_wainwright_gmvmm/",
    "segmentation": [
        [
            "Alright, so I guess I just like to begin by thanking the organizers for the opportunity to be here.",
            "It's a real pleasure to be part of this summer school.",
            "I've been enjoying myself thoroughly so far.",
            "OK, so I'm going to be talking in this part about graphical models, message passing algorithms and variational methods.",
            "And there will be a bit of overlap with the talk of Sam roll ice, but I'll also be moving on to some more advanced topics.",
            "Sort of building on the foundation that Sam built for us over the past couple days.",
            "So for those of you interested, if you look at my webpage, there's copies of these slides also.",
            "Fortunately, copies of films of course lectures so much more detail than I'll give here.",
            "This will be somewhat more high level than a full length course for obvious reasons, but if you're interested in more details, you can have a look at this web page there."
        ],
        [
            "So sort of reviewing part of what Sam said.",
            "Graphical models are really a framework for describing systems that are statistical in nature, but there also large scale and multivariate.",
            "So you want to think about many random variables and all interacting in possibly quite complex ways.",
            "And graphical models are actually this Mike.",
            "Funny, by the way, feels funny to me.",
            "Can people hear me properly?",
            "OK, so they're actually using studied in many fields.",
            "Of course they are widely used in machine learning, but historically at least they were used much earlier in other fields, primarily in statistical physics to model things like crystals and magnets.",
            "And gas is basically very large systems where lots of things are interacting and it's only more recently that they've proven very useful in.",
            "Other fields of engineering and computer science, so I'll talk a bit about applications in computer vision.",
            "Many applications in machine learning, lots in bioinformatics and computational biology.",
            "And also to sort of illustrate other applications that you might not be aware of, but that are very relevant given you're using computers and wireless devices, I'll talk a bit about how graphical models play a role in communication systems."
        ],
        [
            "Just some broad questions before we get into details.",
            "It's useful to think there's there's several kinds of questions or issues to think about when you're considering using a graphical model, and will get into a bit of detail on each of these.",
            "First, I would call a representational issue.",
            "It's really an issue of your given some phenomenon.",
            "It might be an image, it might be a text database.",
            "You might be trying to track a vehicle.",
            "What you really want to understand is what graphical models are useful for capturing or modeling the particular phenomenon that you're interested in.",
            "So it's really a representational issue.",
            "It's trying to understand how does what classes of models are useful for what purposes.",
            "Basically, there's a tautology that no model can be good for everything.",
            "If someone tells you this model is good for everything, they're lying to you.",
            "It's probably useless.",
            "In fact, models are generally good for specific purposes, but you need to understand what the sort of tradeoffs between different models are.",
            "They're also statistical issues with these models.",
            "They are essentially statistical models for fitting random variables, probabilistic systems, and so, as Sam spoke about, one important issue is really that of inference.",
            "At a high level, you want to think about this is how do you move from data.",
            "You're observing some data in the real world.",
            "And you'd like to somehow, on the basis of measurements you'd like to make inferences.",
            "You'd like to draw conclusions about some underlying hidden phenomenon, and I'll give you some examples of that in the next few slides.",
            "As Sam also spoke about there's issues of how you fit parameters.",
            "How do you choose the best model to fit your data?",
            "And somewhat more broadly, the question of model selection, how do you actually choose the class of models it's appropriate.",
            "The third sort of interrelated issue is really a computational one.",
            "And that has to do with the fact is, as I mentioned, these models are typically very large scale.",
            "You're not just interested in things with 1, two, or three subcomponents, you're interested in things with hundreds, thousands, possibly millions of interacting components, so computation issues of storage and efficiency really become critical.",
            "And so we're going to see is that the graphical models really helped to clarify some of the links.",
            "There's some very deep and nice connections, very powerful connections between the structure of the graphs that you use.",
            "Sam was mentioning last time chains and trees will be talking about somewhat more general graphs and will see their connections between the structure and sort of what the inherent computational complexity of applying and using these models is.",
            "So anyway.",
            "Feel free to jump in with questions whenever you feel so inclined.",
            "You think about a speakers, you should try and control your speaker somewhat.",
            "This is what I tell my students.",
            "If your speaker goes too quickly, then you should throw questions in the way to slow them down.",
            "If your speaker goes too slowly, then you should fall asleep in Jan and start making noises that will encourage your speaker to go more quickly."
        ],
        [
            "OK, so this is just an outline.",
            "Again, part of this is actually piggybacking on what Sam spoke about, so I'm going to go through this parts of it a bit more quickly than I would normally.",
            "In particular, this message passing Sam already spoke about on trees.",
            "I'm actually going to prevent it from a slightly different perspective, so you'll be seeing the same material, but from a somewhat different view, and I think that can be useful.",
            "It's often useful to see things from different points of view.",
            "It gives you a deeper understanding, so in this first part I'll sort of be talking bout the basic properties.",
            "And in the second part of these talks will move on to more advanced methods.",
            "Things that are sort of being used in cutting edge applique."
        ],
        [
            "Patiens so the first example, probably the simplest 1 one that Sam is already spoken about, is a hidden Markov model.",
            "So again, remember graphical models are based on a graph, so you've got a set of nodes like this.",
            "And you want to think that a random variable is sitting is associated with each node.",
            "So here you have a very natural change structure.",
            "It's natural to think about these nodes evolving in time an you could use this kind of model to describe, for instance, if you were trying to track a vehicle that could be the position of the vehicle at different time steps time one time, 2 * 3 and these colored nodes here is.",
            "Sam told us these represent observations you don't observe directly the vehicle, but you might be able to have a video camera that could make measurements.",
            "Maybe an infrared sensor.",
            "You might have acoustic sensors, so you.",
            "Be given observations and you'd like to do things you like to actually draw inferences about what's going on in this hidden part here.",
            "So these models are really a workhorse that they're a real workhorse in the graphical model world.",
            "Only one of the earliest graphical models, and they're widely used, for instance in computational biology, in speech and text processing, in control theory for things like tracking signal processing.",
            "But a wide range of uses, and one thing that's very nice about them.",
            "This is something again that Sam mentioned is to review.",
            "Is that the problem of inference that is moving from the observations here that you've made to make inferences about what's going on here.",
            "What's nice is that this is tractable by very fast linear time algorithms, and that was the belief propagation or the sum product algorithm that Sam mentioned.",
            "Now have a look at this model.",
            "This is again a graphical model, but it's it's a slight elaboration of a hidden Markov model.",
            "It's something that's called a coupled hidden Markov model.",
            "So the way you want to think about this is you now have.",
            "In this case I just have three chains, one here, evolving a second one, and a third one.",
            "But what's interesting about it is that you then make an observation down here, and this observation is actually tying together it's coupling or tying together all the chains.",
            "So why might this be useful?",
            "One application which this has been used a lot is, for instance, if you're trying to do Fusion of video and audio streams, you can imagine that you have a video sequence that's evolving like this.",
            "You might have another video sequence from another camera, and you might have an audio stream and they're all evolving in time together.",
            "But then you're making observations of them and those observations sort of couple them together.",
            "It says that those three things the two cameras and the audio stream we're all going to evolve together, so that's that's the kind of phenomenon that this model could.",
            "Start to allow you to capture what you want to understand.",
            "The high level is that this model is actually quite different than this model.",
            "It's a richer model.",
            "It allows you to model A broader class of phenomena, but you pay a price for that.",
            "It doesn't come for free, and the price you pay is in terms of computational complexity of inference of moving from these observations to trying to figure out what's going on up here.",
            "In this case, it was very easy by message passing algorithms in this case.",
            "In general, it's actually intractable.",
            "It's a very hard problem, and So what we're going to see later on is that this sort of motivates what are known as approximate methods for doing inference.",
            "Not exactly, but nearly exactly.",
            "For more complex models like this."
        ],
        [
            "OK, so a second example, a sort of 2D example you can think of a hidden Markov model is essentially 1D, something evolving in time.",
            "A 2 dimensional example would be if you think about trying to model images.",
            "And here I've shown you a nice picture of what people call a natural image.",
            "I don't know quite what that means.",
            "I guess most people would agree this is natural to picture of a mountain and things like that.",
            "So why might you be interested in sort of modeling natural images?",
            "There's many reasons why you might be interested.",
            "One might be that you'd be interested in doing classification.",
            "You might be like to detect, for instance, different kinds of landscape or scenery.",
            "Here you'd like to say this is a Lake.",
            "This is a field, and this is a mountain.",
            "You might like to do segmentation as well.",
            "You'd like to segment the Sky here from the mountain etc, and so sort of natural way to do that is to start building a graphical model that describes the structure of this kind of image.",
            "Lot of structure in this image, right?",
            "It doesn't look like television noise.",
            "It doesn't look dis completely throwing down pixels at random.",
            "You can see there's lots of smoothness here.",
            "So sort of the most natural model, and historically the earliest one would be too.",
            "You've got an image here and you could think about storing it.",
            "You've got a whole bunch of pixels, maybe it's 400 by 400 pixels.",
            "An you could build your graphical model by putting a node.",
            "Here you put one node for every pixel here and then you put a random variable at that node that tells you what's the grayscale level that I'm looking at.",
            "Right, So what this model would start to say is these edges?",
            "We'll get more precise about this a bit later, but these edges tell you there's going to be relations between pixels that are nearby in the image, so this model is going to allow us to start capturing some of the structure that you see in images, natural images that you don't see, for instance, in television noise.",
            "So this is one of actually the earliest models that was used in image processing and computer vision.",
            "But in many ways at least, the initial use of this wasn't so successful, and a lot of the reason was is because it's very hard to do exact computation in this kind of model.",
            "It's not at all the tree.",
            "Member of tree is something that doesn't have cycles in the graph and this has lots of cycles.",
            "If you were an Ant you could walk around a lot of cycles like this and those cycles in the graph actually make it very hard to do exact computation.",
            "So people I think initially were very excited by using these models.",
            "This is sort of back in the late 70s, early 80s and then I think they became a bit discouraged because you know the model is great, but you can't really do anything with it.",
            "You can apply certain kinds of very computationally intensive methods, but they're just much too slow to be of interest in practical applications.",
            "What we'll come back to later is sort of approximate methods that you can apply to models like this.",
            "At least historically, what did happen is people started moving away from models that looked like this, and they moved into models that were again trees.",
            "And so this is 1 example of the tree model in which you sort of think about having many scales.",
            "For those of you who know something about wavelets, you can think about this as representing a core scale of information.",
            "These four nodes would be medium scales of information and then down here you'd have fine scale, so it's what's known as a multi resolution or a multiscale transform.",
            "So these became quite popular and they're still used again.",
            "What's nice is that you can run very fast algorithms on them.",
            "What's not nice is that these models are not as rich as these.",
            "They can cause water known as boundary artifacts.",
            "So again, there's always this tension.",
            "This tradeoff between how complex your model is, what you can represent with it, and issues of computation.",
            "What can you solve efficiently in different models?"
        ],
        [
            "3rd example again from computer vision and this is one that's the topical interest.",
            "A lot of work is being done currently.",
            "On this there's a fairly long paper looking at methods exactly like this that I see.",
            "See the Computer Vision conference at looking at these kinds of techniques for disparity computation."
        ],
        [
            "Let me just show you a picture first.",
            "So this is what's known as a stereo pair.",
            "How many of you have seen stereo pairs before?",
            "OK, so two or three?",
            "Essentially, what this is is it's 2 copies of the same image, so it's a picture of a cathedral if I'm not mistaken, it's a cathedral in the city where Alex Small's parents are from.",
            "That's just a coincidence, but a nice one, but it's not exactly the same picture.",
            "It's the picture taken from 2 slightly shifted cameras.",
            "So you want to think about the cameras like your eyes.",
            "Your eyes are slightly shifted.",
            "Offset like this, you can think about your eyes is taking two slightly different pictures of the same image.",
            "So the people that study stereo and they can do what's called Fusion.",
            "I don't know if I can teach it to you, just on the spur of the moment like this, but if you stare you can actually do it on your paper as well as up here.",
            "If you stare at this and kind of cross your eyes to make the images come together.",
            "If you fuse them to make one image, what you should see is that this should be very much in front.",
            "You should see an appearance of depth.",
            "This should be in front and you should see the ceiling going backwards.",
            "You should see a 3 dimensional image by combining 22 dimensional images.",
            "Yeah, that's a good suggestion.",
            "Sam here is.",
            "Doing tricks with his thumb and I don't know it makes you look a bit stupid if you sit there doing it.",
            "But when you finally get it, it can be worthwhile for sure.",
            "And they're actually whole books of these things.",
            "If I have some friends who study stereo and all they do is go around all day doing this, they look completely insane.",
            "But anyway, so the point is we can do that and other mammals.",
            "Monkeys can do this, but we're in machine learning.",
            "We'd like to make computers do this right?",
            "And it's an interesting problem.",
            "'cause it's saying that there's enough information in these two shifted copies for you to recover depth.",
            "But how do you do this automatically?",
            "And So what will discuss a bit later is that you can actually formulate this very naturally as.",
            "As a problem in a Markov random field and it's a Markov random field in which you measure the shifts between the two images and you try and optimize those shifts, and so we'll get into a bit more details of this kind of model later.",
            "This sort of high level, it's people use things like lattice models.",
            "What's tricky is again that trying to find the optimal shift, trying to sort of shift things around to make the match in the best way.",
            "This, again, is computationally intractable, but we'll see later that people are in practice using message passing algorithms.",
            "These are approximate methods here that are doing very well for this problem."
        ],
        [
            "OK, so just one last example before I move on.",
            "This last example has to do with problems of communication.",
            "And so some of you might be aware of this if you studied communication engineering, you might be aware of these things, but certainly all of you have, I suspect, experience with devices that use this kind of technology.",
            "So as I sort of was mentioning yesterday, someone asked about a killer application for graphical models.",
            "This certainly is 1 killer application.",
            "This is an area where graphical models and message passing have really revolutionized the field in the last 10 years.",
            "So the basic problem here is you want to imagine that you're trying to communicate a source of information.",
            "Maybe you're just talking to your friend on the phone.",
            "But we're going to idealize this is you're just trying to send, let's say, is zero.",
            "You want to send your friend a zero or a one?",
            "That would be the simplest kind of communication you could do.",
            "And the catch is that.",
            "The channel that you have by channel we just mean something like a wireless phone that you speak over the channel doesn't work perfectly.",
            "If you send a 0 maybe it will flip that zero to be a one.",
            "So your friends not quite sure what you sent.",
            "Maybe you sent to 0, maybe a one he or she isn't quite sure.",
            "The idea here is that what you'd like to do is be clever and start doing things like Tom was actually mentioning.",
            "These are called.",
            "These are error correcting codes you'd like to add redundancy to what you transmit.",
            "So the simplest thing to do would be to send 05 times.",
            "And as long as at most two of the bits got flipped, then your friend could say, well, there's more zeros than ones, and I can decode correctly.",
            "So that's a very simple example of an error correcting code.",
            "It's called a repetition code.",
            "It's a very stupid example of an error correcting code.",
            "That's not what's used in practice.",
            "That's a very bad thing to do.",
            "But it illustrates the principle and this kind of problem of communicating like this has lots of applications.",
            "The Rovers that were sent to Mars that were wandering around they were using these codes to transmit information back to Earth.",
            "Berkeley lots of people are working on sensor networks, nodes, networks have lots of little devices and there's a lot of error control coding that goes into those.",
            "Your wireless card for those that have you are using wireless right now is using error correcting coding.",
            "Your hard drive is also using error correcting coding, so this is all around you.",
            "Even if you don't know about it.",
            "So the high level the key thing is that Shannon back in the 40s sort of laid out a very beautiful theory.",
            "That said, how well you can ever expect to do this, but he was a theorist.",
            "He just said in principle you can do this, but he didn't give any indication of how you could actually in practice do it.",
            "And so what's exciting is that graphical models.",
            "This is where graphical models come in.",
            "They've really enabled people to solve this kind of problem as near to optimally as possible, and so graphical models are being used.",
            "For instance in your wireless cards."
        ],
        [
            "Right now.",
            "Let me skip this just in the interest of time."
        ],
        [
            "OK, so that's sort of some illustrative examples of applications and with graphical models arise, that's by no means exhaustive.",
            "I sort of chose some examples, I think not to intersect so much with other speakers, but other people talking, for instance, about text about bioinformatics.",
            "In all of these applications.",
            "Again, graphical models have have a role to play.",
            "So any questions about those applications?",
            "OK, so.",
            "Let's move on."
        ],
        [
            "To the basics of graphical models.",
            "This again is reviewing a bit what Sam taught us over the past couple of days.",
            "So I'll be focusing mainly on undirected models.",
            "I'll talk briefly about directed models that Sam also spoke about, but primarily about undirected models.",
            "And I'll explain why in a couple of slides.",
            "So again, an undirected model that just means the graph that you're looking at.",
            "It means the edges don't have arrows on them.",
            "There's no direction to them, there's just a link like that with no no directionality.",
            "So again, you want to have a graph, a set of nodes, circles and edges, and you've got random variables at each node.",
            "And so what's important here is what turns out to be important is what are known as the cliques of the graph.",
            "So cliques of the graph or are just friends, it's a clique is a set of nodes that all talk to each other that all share edges.",
            "So for instance here 123.",
            "This is a clique 1.",
            "Two is also a clique, but 123 is a maximal clique.",
            "Because this is the biggest step that I can make of things that all talk to each other.",
            "Similarly, 4 Seven is a maximal clique, 456 is a maximal clique.",
            "So that's going to be important because cliques are going to find sort of the notion of locality.",
            "What's key in graphical models is what do you mean by local and cliques tell you what it means to be local, what's local to you, is what you can talk to in one step.",
            "That's what's in your clique.",
            "Well, it's related to what's in your clique.",
            "Something else that's also important is what's known as a vertex cut set, and this again is a very intuitive notion.",
            "It's just saying it's a subset of vertices that if you snip these out, you took scissors and went, snip, snip, snip, snip, snip.",
            "Then the graph would break into two or more pieces, so it's saying if you cut those out then the graph breaks apart and so we're going to see is that these two things.",
            "These two notion cliques and cut sets these play an important role in how we describe undirected graphical models."
        ],
        [
            "So.",
            "The way these graphical models work is that what you're doing is you're using the graph.",
            "Describe what you believe about the dependencies that you see in your random variables.",
            "Right in many applications there's again this notion of locality.",
            "If you have a collection of sensors, your intuition is that sensor should interact locally in a spatial sense that a sensor here should interact with one here, but it shouldn't interact directly with something on the other side of the room which interact with its neighbors, and so the graph here is specifying this neighborhood structure.",
            "And in a more precise sense, you use the graph to impose constraints on the random vector, and there's two different ways to do this.",
            "They seem different at first, but they turn out to be equivalent.",
            "And the first is, by the notion of Markov properties.",
            "So you say that.",
            "The random vector X, so this is all the random variables.",
            "It's Markov if subsets of variables XA and XB become conditionally independent whenever you have a vertex cut set.",
            "So what this means is that if you observe the values of the random variables here right, you're conditioning on them when you observe them.",
            "Then it says that this subset of variables XA becomes conditionally independent of this subset, so it's sort of capturing the fact that when you condition that's breaking the graph.",
            "And in terms of the random variables, it's breaking them apart because they become independent.",
            "So you're all will have heard last time from Sam about the simple example of when you have an HMM.",
            "This is the simplest example of a Markov property you think about the present here, and this is the future, and this is the past.",
            "So if you condition on the present, that's a cut set that will break the graph into two.",
            "Then as Sam told us, the past and the future become conditionally independent.",
            "Sounds kind of mystical, but that's just a special case of the Markov property that I just stated.",
            "This is something past and future and present.",
            "That's a special case of this, but we're interested in this actually for more general graphs.",
            "And you can get much richer Markov properties in more general graphs.",
            "So that's the Markov property.",
            "That's one way that you can use the graph to constrain the form of the distribution.",
            "The other way to constrain the form of the distribution is is in terms of how the distribution might factorize.",
            "So let's just skip back to this example.",
            "Let's imagine that you had binary variables, so variables that took value 0 and 1 zero and 1 zero and one at every one of these nodes.",
            "Right, so in general, how many numbers would you need to represent a distribution over that set of random variables?",
            "Right, so 2 to 7 -- 1 right?",
            "Because you've got 2 to the seven possible configurations in your whole graph.",
            "But then, probability distributions have to sum to one, so you lose 1 degree of freedom.",
            "Right, so two to seven.",
            "This is a toy problem.",
            "Again, this is not something practical that's already getting big.",
            "If you thought about something that, for instance, modeling an image, just a binary image, that was, let's say 400 by 400, you'd be looking at 2 to 400 ^2.",
            "That's a very big number, that's an understatement.",
            "That's more than the number of atoms in the entire universe.",
            "The entire visible universe.",
            "So what it's saying is that in less, you start exploding structure.",
            "There's no way you could ever even store.",
            "You can't store a vector that has 2 to 400 squared elements.",
            "If you can, then I'd like a version of your computer, please.",
            "So the point here is that we're going to use the graph to constrain the form of the distribution we're going to impose it to be local, so it's going to drop the number of degrees of freedom, so we're losing something in doing that.",
            "We're losing.",
            "We can't express all distributions anymore, but we're gaining a lot because we can actually do things with this model.",
            "We can store it, we can apply it, and we can do inference.",
            "And so the way we constraint is by saying things have to decompose into local functions.",
            "These are called compatibility functions or potential functions.",
            "And these functions are local in the sense that they depend only on the random variables in the clique.",
            "So there be a function for 123 function for 345 etc.",
            "So you've got a local product of functions."
        ],
        [
            "So just to look at a simple example, let's go back to this image model that we had before.",
            "Now I'm trying to model a baboon and again I'm using just a simple lattice model.",
            "I'm thinking about these being grayscale values.",
            "They might be 0, one or they might be 01 to 255.",
            "And So what you want to think about is the cliques.",
            "Here the maximal cliques are just edges, just pairs of nodes.",
            "So what it means is that you're sort of allowed a function of pairwise interaction term that's going to sit on every one of these edges.",
            "And that term is going to tell you how is this pixel value related to this pixel value.",
            "So simple case if I just had three grayscales, I'd have a three by three matrix.",
            "I might look at an interaction of this form.",
            "I could have one number a along the diagonal and then B on the off diagonal.",
            "And so there's sort of two parameters here, and if I set a larger than B.",
            "What that would tell you is that you're more likely to have values on the diagonal values that are equal then values on the off diagonal.",
            "So this would start imposing a kind of smoothness constraint.",
            "It would say pixels that are nearby, like pixels on this nose are likely to have close grayscale values, so it's a very simple kind of thing that you're imposing, but it's a start.",
            "That's how compatibility functions work.",
            "They sort of tell you about local interactions between the pixels."
        ],
        [
            "OK, so let me say something briefly about directed graphical models.",
            "Again, just recapping what Sam did.",
            "For directed models, you have now arrows on the edges, and the semantics are somewhat different.",
            "You really think about the parents?",
            "For instance, if I focus on this blue note here, it's parents are these red nodes and you think about the factorization is taking place over conditional distributions of the child given its parents.",
            "So in some ways it's kind of parent to child.",
            "It's a generational factorization, child conditioned on its parents.",
            "So these models are useful for they can express certain kinds of causal relations.",
            "Sam mentioned something called the explaining away phenomenon, so there's certain kinds of things that directed graphical models can express that undirected ones cannot, but vice versa.",
            "So there's some things that undirected models can express the directed ones can't.",
            "So one model is not better than the other.",
            "It really depends on what kind of application you're looking at, and it takes experience and intuition to sort of figure out what's most appropriate for what you're trying to model.",
            "Purposes of this talk.",
            "I'm going to focus mainly on undirected models, as I mentioned before, and the reason being that when it comes time to doing inference, the first step when you're given a directed graphical model is actually to convert it to an undirected model.",
            "So from the computational point of view, if you're given a directed model, you typically convert it first to an undirected model, and since I'll be talking primarily about computation in the later part of the talk, I'll sort of assume that you've converted this directed model.",
            "If you remember, Sam mentioned this, it has a quirky name.",
            "The procedure is called moralization because what you do is you marry all the parents the parents have had an illegitimate child and were moral people.",
            "So we marry the parents.",
            "Does anyone actually know who coined that term?",
            "It's very you guys know who coined that term.",
            "Try and find out.",
            "It's curious, but.",
            "OK, so we'll talk mainly about."
        ],
        [
            "Erected models but you should understand that for instance in HMM can be thought as both the directed and an undirected model member.",
            "Before we've got a sequence of states evolving in time and we've got some observations here.",
            "And so the way you want to think the natural way to parameterise this model with compatibility's is you would put for instance a marginal probability distribution at this node.",
            "That sort of tells you how you start out the chain.",
            "And then you want to move from X1 to X2.",
            "So you need a transition that tells you how to go from X1 to X2.",
            "So you have a conditional transition.",
            "This is a conditional probability table that tells you how to move forward and so on recursively forward.",
            "So this would be a special case of the kind of parent to child directed factorization."
        ],
        [
            "Let me just mention one last thing that I don't believe Sam mentioned, but something that you should be familiar with because it's something that you will see in many papers.",
            "Sort of a third kind of graph that you can use to represent graphical models, and these are called factor graphs.",
            "Um, factor graphs are a bit funny because.",
            "There's sort of a subset of the community.",
            "I won't mention any names because I'm being filmed, but there are some people who are almost religious about factor graphs.",
            "They sort of believe that the factor graph is the way to go, and you should never use anything but a factor graph.",
            "I don't quite believe that.",
            "I think they're useful for some things, but.",
            "And other things that are kind of clunky, but let's go and try and understand them, but they are useful for certain things, so the way they work is essentially in addition to the circular nodes here that are representing random variables.",
            "Those are things that we had before you now have a second kind of node.",
            "Typically represented as square nodes that are actually explicitly representing the factors.",
            "This is why it's called a factor graph.",
            "These guys represent those functions.",
            "Those compatibility functions that I was telling you the distribution broke into.",
            "So you might have a model like this.",
            "You would have X one X5X3X7.",
            "These are all random variables.",
            "And they're connected to this square node, and you sort of think there's a factor sitting there.",
            "I call him Cy 1357, 'cause he's a factor that is.",
            "Depends just on these variables in its neighborhood.",
            "This is useful because you can just look at this graph and you can read right away that it factors into a product of three terms, one for this, one for this and one for this, and you can sort of read by looking at the neighborhoods what the terms depend on.",
            "Sometimes this is an example where I think factor graphs are silly.",
            "If you had one of these lattice or grid models, all you'd be doing is putting an extra node on every edge.",
            "It doesn't really add much, it just clutters the picture.",
            "This is a case where I don't think they're useful, but this is a case where they actually are very useful that they allow you to make a distinction that an ordinary under undirected graph can't.",
            "And, um.",
            "Can anyone sort of read the different semantics?",
            "In both cases I've got 3 random variables.",
            "But the semantics of the distributions that these two models are telling you are slightly different.",
            "Right, so the semantics here are telling you there's one joint factor that's a triplet factor over X1X2 and X3, so it's a function over three variables, Whereas the guy in the bottom is telling you there are actually three functions, but they're all pairwise function between X1X2X2X3 and then X 3X1.",
            "So this in some sense is a special case of this model, right?",
            "I could write this in this form if I wanted, but this this has finer grained information.",
            "It's what it's actually telling you is that there's No 3 way interaction here.",
            "Anne, this is very relevant.",
            "For instance, in medical diagnosis, if you're running medical experiments, you might have multiple factors.",
            "You might have something like age, smoking and diet, and you might be concerned.",
            "Do I just have pairwise interactions between these factors?",
            "Just just one interaction?",
            "Being smoking and age 1 between age and diet?",
            "Or do all three of them interact together simultaneously?",
            "So statisticians, for instance, spend a lot of time trying to figure out how do I distinguish this kind of interaction set up with this pairwise interactions from something where you have a 3 way interaction?",
            "OK, so any questions about sort of those three styles of models I talked a fair bit about undirected models first.",
            "Talked about Markov properties in factorization, talked briefly about directed models and then this sort of 3rd hybrid style of factor graphs which sort of give you finer control of the actual factorization.",
            "I will take full breath to presentation high, concrete, grave, Queen merge.",
            "Those factors function into one vector, so you mean.",
            "2 grand can we merge 3 pressure bouncing into one vector?",
            "100%?",
            "So are you asking about these three?",
            "Yes, so yes so.",
            "This in fact is a special case of this because as you are pointing out, you could sort of imagine merging all of these three.",
            "You could take the product and think about that as a new super function.",
            "That's a function of all three.",
            "Right, so this is a particular case of this model, and you could do that, but in some ways you would have lost information in doing that because you would have lost the fact that the interactions are really only in pairs.",
            "There's no actual function, that's a function of all three.",
            "There's a finer kind of decomposition that's going on.",
            "So that's why factor graphs are useful because they really emphasize the factorization they explicitly tell you where the factors sit, whereas if you look at undirected graphs, it can be somewhat ambiguous.",
            "Krishna.",
            "So you said there is some problem that was somebody.",
            "Unless you can represent with undirected graph and cannot be corrected graph and the other way around is true too.",
            "So can and all those very only represented by factor graph.",
            "Um, another question is.",
            "How practical is it to make an mixcraft?",
            "OK.",
            "So the first question was I sort of mentioned before that there's some some models that can be represented by directed graphs and not by undirected and others by undirected, not by directed.",
            "And then the question was.",
            "Can factor graphs represent everything?",
            "Not strictly because.",
            "It's somewhat technical point, but there's a very different semantics to having undirected edges versus directed edges.",
            "Let me just actually give an example of something that you can represent with a directed graph, but not with an undirected graph.",
            "This is sort of a classical example that you'll see a lot if you read the literature.",
            "So you can sort of imagine you have two random variables.",
            "The random variables here are going to be coin tosses.",
            "So I'm going to flip a coin.",
            "I get ahead or retail and I'm going to assume these coins are actually independent.",
            "I'm just going to flip one coin and Sam is going to flip a coin.",
            "But then I'm going to have a device and this device is going to be a Bell, so I'm going to draw a graphical model with arrows.",
            "So these are going to be the parents and the child.",
            "And so the Bell here is going to ring.",
            "You can think about this like a slot machine, right?",
            "You're going to win some money if both coins come up heads.",
            "Right, so 2 coins flipped their independent and if you get lucky they're both heads.",
            "You're going to win a big pile of money.",
            "What's interesting about this model is that the coins.",
            "If you don't condition on anything, the coins are actually independent, right?",
            "Because I'm flipping one Sam's flipping one.",
            "What's interesting is that if you condition on something, let's suppose that you're watching your friend at this machine and all of a sudden the Bell rings.",
            "Right, so I'm going to color color it into mean that you observe that the Bell rings.",
            "All of a sudden these random variables are the coins independent anymore.",
            "After you've seen the Bell Rang.",
            "It's useful to think about this a bit.",
            "The coins aren't going to be independent anymore.",
            "So this is a kind of phenomenon where you have random variables that are independent marginally without condition.",
            "Then you observe something and they become independent.",
            "The first time you see this in probability theory, it seems a bit weird.",
            "Undergraduate students often get confused with this, but this is something that that under directed graphical models capture very naturally, but undirected ones do not.",
            "There's other examples to go the other way, but I won't get into them for the interests of time.",
            "I'm sorry I've forgotten your second question, I.",
            "Yes, the second question is how practical is it to make mixed model?",
            "So mixed models do exist.",
            "They are often called chain graphs, and in some models that certainly practical in some models it would be the most natural thing to do.",
            "I haven't gone into details, but there's some setups where it's very natural to use a directed factorization and it's kind of artificial to use an undirected one, and other setups where it's very natural to use the undirected one, so people sometimes do have sort of mixed settings and they use graphs that have a combination of directed edges in undirected edges they can get a bit tricky though, but it certainly is done.",
            "OK.",
            "So any other questions about sort of different representations etc."
        ],
        [
            "OK, so let me just state one last thing.",
            "This is actually a very important result, but we won't go into detail what you just want to take away is sort of the practical consequences of this result.",
            "Remember, I introduced undirected graphs by saying that you can use the graph to impose constraints on the distribution in two different ways.",
            "You can either talk about these Markov properties you can talk about, for instance in a chain you can talk about past, present, and future more general graphs you can talk about.",
            "Markov properties, things being separated by vertex cut sets.",
            "Or you can talk about factorization properties.",
            "So these things at the surface at least seem like very different kinds of constraints.",
            "But what sort of fundamental theorem this area due to Hammersley Clifford originally in the 70s is that under suitable conditions these are actually the same restriction.",
            "It doesn't matter if you use your graph to impose the Markov properties, or you use it to impose the factorization properties.",
            "You sort of get the same class of models depending.",
            "It doesn't matter which way you go.",
            "Is a very elegant result mathematically, but practically speaking it's also very important because it means that you as a modeler you can choose whether you want to think about things in terms of Markov properties.",
            "Sometimes it's very natural to think about Markov properties because you have a very natural notion of when different variables become conditionally independent, and so whenever you have conditional independence that things become independent when you observe something else.",
            "You're very naturally lead into Markov properties and cut sets.",
            "And so that would be one way that you could go about actually getting the graph structure is via conditional independence and Markov properties.",
            "Equally useful is to think directly in terms of factorization.",
            "In many ways sort of in a physical sense, this is the most natural.",
            "You just think about, for instance nodes in a network and you think about what neighbors are being talked to, and these functions are telling you exactly the neighborhood structure it's telling you who talks to who, who depends sort of locally on who.",
            "So both perspectives were useful and this results nice because it says essentially you can use both interchangeably.",
            "What we're going to see in this in the next wireless is actually from a computational perspective.",
            "It's the factorization that's particularly useful, and this is going to make connections again to things that Sam mentioned having to do with the distributive law having to do with moving sums and products you can already see there's a product here and soon we're going to be taking some nations.",
            "We're going to get sums and products, and that's going to be important for computational purposes."
        ],
        [
            "OK, so let me move on to exact message passing on trees.",
            "Again, this is slightly recapping what Sam did, but I believe I'm doing it from a somewhat different perspective, so I hope you'll bear with me.",
            "I'm going to begin not by talking about trees.",
            "I'm going to begin by talking about completely general graphs.",
            "And I'm going to talk about an algorithm that's known as the elimination algorithm.",
            "You'll see why it's for obvious reasons.",
            "To be clear, this is not a good algorithm.",
            "Do not go and use this algorithm.",
            "This is a bad algorithm.",
            "This is a pedagogical algorithm.",
            "It's useful for illustrating the concepts an for seeing how graph structure is actually linked to the complexity of performing inference, but it's not something that you will implement in practice, but what it does suggest is good algorithms.",
            "Things that are actually efficient, and this is where we're going to get into message passing algorithms on trees, and then I'll talk a bit more.",
            "Generally about the notion of junction trees.",
            "So what we're going to see in this section is sort of this nice connection between the graph structure on one hand and the intrinsic difficulty.",
            "How hard is it to solve these kinds of summation or maximization problems that you'd like to solve in application?"
        ],
        [
            "It's.",
            "OK, so from a computational point of view, let's again focus just on an undirected model, because as I said, you'd always convert a directed model by moralizing to an undirected 1 first.",
            "An we can imagine that you've sort of got a factorization over cliques of the graph.",
            "You've got these local functions again.",
            "And maybe just to make things interesting.",
            "Maybe like in the hidden Markov model.",
            "I also have noisy observations at every node, so these axes would be sort of hidden quantities and maybe someone has actually allowed you to observe these wise.",
            "So these would be noisy observations.",
            "Maybe you're looking at an image and you're taking it from a telescope, you don't see the actual image, you see a sort of noisy version of the image, and that would be the wise.",
            "This is what you have in your hand.",
            "So what's interesting here?",
            "What are things that are of interest to compute?",
            "One thing I haven't spoken about yet is this Z that's sitting there.",
            "It's called, it's just the normalization constant.",
            "The only reason it's sitting there is because this is a probability distribution.",
            "So if you sum or you integrate over all the variables, you should get one.",
            "So you have to divide by something to be sure that you get one.",
            "So it looks kind of unimportant, right?",
            "I mean, who cares?",
            "It's just a normalization.",
            "Certainly that's what I thought when I first saw it.",
            "I mean, who cares?",
            "But unfortunately it turns out to be very important.",
            "It turns out to be extremely important when you're trying to learn models from data.",
            "This turns out to be essentially the log likelihood of the data.",
            "Other things that you'd like to compute.",
            "These are things that Sam mentioned.",
            "Often you have a very big graph.",
            "For instance, I might have an image and it could be very large, but I might be interested just in what's going on in a particular region of the image.",
            "Maybe there's some object there, maybe I'm trying to detect something, so I'd like to sort of focus in on that part of the image, and I'd like to compute some kind of summary statistic about a certain part of the model.",
            "So one kind of summary statistic would be a marginal distribution where you're essentially integrating or summing out the rest of the graph.",
            "So you're just concentrating focusing on one part of the graph, and this is the problem that Sam spoke about yesterday for chains and trees.",
            "Another problem that you might be interested in is.",
            "For instance, in the error correcting code coding problem, your friends talking to you over the wireless phone, and you have a bad service provider and you're getting a lot of static, so you receive a garbled message from your friend.",
            "You don't know exactly what they're saying, but you can sort of think what you'd like to do is search over the possible set of messages that your friend might have sent you, and you'd like to find the one that's most likely the one that is has the highest probability.",
            "So in terms of a graphical model, if you modeled this setup like this, this would be a mode or most probable configuration of the graphical model.",
            "So what's relevant here?",
            "At some level, these seem like simple things.",
            "To get this, all you do is compute a sum or an integral.",
            "This is just a summation.",
            "This is a maximization, but again, you want to remember that the curse of dimensionality is going to come to bite us.",
            "So.",
            "We're not interested in models with just two or three variables.",
            "We're interested models with hundreds of variables, and so just going back to the example we had before.",
            "If you just think about binary models, right?",
            "This is simplest example.",
            "Very toy.",
            "You're getting complexity.",
            "This going to scale essentially like 2 to the N, where N is the number of nodes in your graph.",
            "So that's very bad you're going to any brute force method is going to show quite quickly, essentially by the time N = 20.",
            "You're not going to be able to do anything.",
            "So what we're going to see is in a minute that some kinds of graphs, more general graphs and trees can actually be solved quite efficiently.",
            "And then moving on later, we're going to see that for more general graphs, you can start thinking about approximate methods to solve problems like computing a huge summation like this.",
            "And we want approximate methods that are fast, so we can actually apply them in practice."
        ],
        [
            "OK, so let's let's move on to the elimination algorithm.",
            "This is a very simple algorithm and.",
            "Essentially it's just as Sam set exploiting one idea.",
            "It's exploding the fact that the sum and product operations are distributive, which just means that you can move sums and products around.",
            "So let's imagine that we have this graph.",
            "Here I've just got six variables, so it's a toy problem.",
            "And what this graph is telling me is that the maximal cliques are 1213343524, and then there's a three clique 246.",
            "Right, So what I've learned is that this model says that this distribution should factor into a product of local terms like this.",
            "These are one term for every maximal clique in this graph.",
            "And what we're thinking about here is, let's imagine you want to compute a marginal distribution.",
            "Let's say I'm sitting here at this node.",
            "This might be a sensor network.",
            "You might have a bunch of sensors.",
            "These could all be sensors that are measuring things in the environment.",
            "I might be interested in.",
            "For instance, I'm giving a midterm tomorrow and I have a pile of photocopied midterms on my desk.",
            "And some of my students are.",
            "Let's say more dishonest than studious, and they'd like to come in and steal one of the midterms to make photo copies of so I could, for instance, rig my office with sensor networks at various junctures, and maybe the midterms are sitting right there, so I'd be very interested.",
            "For instance, if a student managed actually managed to get to the midterms, I'd like an alarm to go off so you can imagine I'd like to compute something like the probability of student appearing at this place.",
            "That could be one interpretation of this marginal.",
            "So what's going on here is you have a big summits over many random variables, so it looks kind of unpleasant at first, but you can see with a bit of algebra you can just start pushing the sum inside an, for instance, 6 the sum over X6.",
            "I can push it all the way.",
            "There's only one term.",
            "This last term that depends on 6.",
            "Similarly, the sums over X5.",
            "There's just these terms, so I can keep sort of pushing the summation further and further inside the product.",
            "So this is the distributive property and this is what's going to allow you to save substantial computation."
        ],
        [
            "Chen so there's useful way to thinking to think about this.",
            "Actually, in terms of graphical operations, right?",
            "We're talking about summing over variables, but it's useful to think about it, as after you've summed over a variable what you're allowed to do is you're allowed to sort of cut that variable out of the graph.",
            "I can eliminate it from the graph.",
            "That's where the name elimination comes from.",
            "An I can strip these edges off, so once I've sort of done the work of summing this guy, then I get I get to get.",
            "I'm allowed to get rid of this part of the graph, so I've.",
            "The graph shrinks a bit.",
            "It's getting reduced.",
            "So that."
        ],
        [
            "One step of elimination.",
            "And so I eliminate and if you sort of look analytically what happens, I get rid of this node.",
            "I get rid of these edges and if you look carefully, you'll see that there's a kind of modification to the compatibility or potential function on this edge.",
            "So it is a kind of gets tweaked a little bit by the operation, but that's OK, it's still on the same graph.",
            "It's a slightly different, so you can use a twiddle for it."
        ],
        [
            "And then I can recurse this operation.",
            "I could for instance some 5."
        ],
        [
            "And strip 5 and I could then some four and strip out four.",
            "And now I'm down just."
        ],
        [
            "Triangle graph and I could sum that out and at the end of the day I'd have my answer.",
            "Um?",
            "So you can do a little calculation here to see exactly how much you saved in terms of exploding this distributive law and doing the elimination in this way.",
            "Does anyone have?",
            "Was there anything special about the order in which I was illuminating nodes here?",
            "Anyone have any intuition about that?",
            "So if you remember, I eliminated first 6, then five, then four, then three, then two.",
            "Was that important?",
            "Could I have illuminated three to start with?",
            "Free.",
            "Sorry, maybe put the mic on.",
            "Add the children first.",
            "Yes.",
            "Well, why couldn't I just sum out three right away?",
            "The.",
            "I would say you cannot.",
            "As you would catch the crime, I would do what to the graph, cut it.",
            "While you're worried that five would split off here.",
            "It would if I would actually get recouple diff.",
            "It's useful to actually go through this.",
            "Go through this exercise, do it in a different order and see what happens to the graph.",
            "Um?",
            "What sort of key here you want to be very clear about this is when you some you end up modifying terms.",
            "This term changed a bit because of the effect of summing this out.",
            "Right and it changed a bit, but what's important is that there already was a potential term sitting there.",
            "Right, it got tweaked a little.",
            "It changed, but I didn't add any new potential term.",
            "Nothing new was added, it just changed a bit.",
            "But it's useful to think about what if you summed this out?",
            "Think about doing it here.",
            "What effect would that have on the coupling of the graph?",
            "I won't go into details now, but that's that's useful to think about it.",
            "The break the order in which I did this matters a lot.",
            "I was nice to you and I chose a good order.",
            "Roughly speaking, that you can sort of see I was essentially moving outside to in.",
            "I was starting at the outside 6.",
            "Then I got rid of five and I sort of collapse the graph inward.",
            "But you can do this elimination in any ordering you want, but not order.",
            "Not all orderings are equal.",
            "Some orderings are much better than others, so this is an optimal ordering.",
            "Some orderings can be very bad, so it's useful to play with this example just a little bit on your own to understand why the order in which you do this might matter."
        ],
        [
            "Right, so the sort of summary here is the basic step is very simple.",
            "We're distributing some in product to do partial summations in some order, so you're fixing an elimination ordering and you're using distributive law as much as you can with that order.",
            "What sort of key graphically is that?",
            "The minute that you sum over a particular variable?",
            "You get to eliminate that node and its edges from the graph.",
            "That's a good thing that makes you happy.",
            "The graph is shrinking.",
            "But the bad thing that you have to be careful about is you have to join all of its neighbors with extra edges as you join these extra edges.",
            "For instance, one example of where this happened was right here.",
            "I didn't have an edge here initially.",
            "But once I sum over this X4 at this point there's going to be an edge that's added here.",
            "You can see that edge has to be added because you get a new coupling term.",
            "And I'm doing that.",
            "It's going to start making your graph more and more connected.",
            "It's going to actually increase the size of the cliques.",
            "Here it's making actually a three clique there that didn't exist before.",
            "So what it turns out is if you do a bit of algebra to figure out how much did you pay to do all of this at the end of the day, how much you pay depends very much on how big the cliques got in this new graph that gets created as you sort of shrink the graph down.",
            "What sort of matters is how many edges did you have to add as you were eliminating?",
            "So here I ended up having to actually create a new three clique.",
            "I already had a three click here, but the biggest click that I would have gotten in this graph is actually a three clique.",
            "There's nothing bigger than that.",
            "There's no four cliques here.",
            "If you choose a different elimination ordering, you'll see that you will get a four clique.",
            "So the key thing is that elimination ordering matters a lot.",
            "There are good orderings and bad ones.",
            "Unfortunately, the figuring out which is the optimal ordering, that's not an easy problem.",
            "It's actually an NP hard problem in general, but practically speaking there are a lot of heuristics to find reasonable orderings.",
            "You might not find the best one, but you can certainly find reasonable ones.",
            "So that's that's the elimination algorithm.",
            "The intuition you want to take away from this is that there's really a nice correspondence between analytically on your sort of manipulating the factors in this distribution, you're performing summations and that sort of shrinking things down.",
            "It's making new factors and shrinking them, and there's a very nice graph theoretic correspondence that you're watching.",
            "This residual graph sort of shrink and shrink down, for instance to the target point.",
            "Here I was interested in X1.",
            "So there's a nice correspondence between the factorization in the summation and the graph theoretic properties here.",
            "So what we're going to see is that some kinds of graphs are actually nice graphs in that they have good elimination orderings, and some graphs are not nice graphs.",
            "They don't have good elimination orderings, and so essentially the elimination algorithm is.",
            "It's useful because it gives you an algorithmic way to understand why'd's graph structure, affect how complex it is to, for instance, some and perform marginalization.",
            "It sort of tells you that the way in which the graph is connected controls how this elimination behaves.",
            "And that determines in the end how much computational complexity you pay."
        ],
        [
            "So any questions on that before I move on?",
            "I want to move on with that kind of intuition.",
            "I'd like to move on to talking about trees which are sort of the simplest case of graphs that have a very nice elimination ordering.",
            "Yeah, kind of assumption.",
            "Did you make on the original quick size?",
            "I mean how many clicks you have or you didn't say anything about it.",
            "Right, so here I was.",
            "Just giving you one example an I had some two clicks into, three clique, but so in general you'd have to start with whatever model you were given whatever you used.",
            "Sorry number, please write if you gave me a graph that to start with had let's say clique sizes of Alpha N or something, it wouldn't be actually a very useful model because you noticed or things you'd have to pay complexity two to the Alpha N for binary variables.",
            "We could generate bigger clicks, that's why, yes, so that's the key point that elimination can only make things worse for you, and the issue is how much worse does it make it for you?",
            "This example would actually, I mean, it made a new three clique.",
            "It added this edge, but I already had a three clique, so it didn't really make things any worse at all.",
            "For me, things were sort of, there was no additional sort of jump in complexity.",
            "What we'll see is that trees are the simplest case of no jump in complexity, but other graphs there's a huge jump in complexity between this graph and the residual graph.",
            "What you get after illuminating.",
            "So any other questions about elimination?",
            "Again, I encourage you just display with this example.",
            "It's a simple example, but it actually has all the basic ingredients that you need just to get intuition of how this works.",
            "This is not what you'd implement, but it's useful just to play with because it sort of gives you a feeling for what's going on.",
            "Why why graph structure actually matters here.",
            "OK, so let's move on to the sum product algorithm.",
            "Let me first talk about it on trees and then I'm going to talk about a more general class of graphs that are called junction trees.",
            "And so this first part just talking about ordinary trees.",
            "This is recapping what Sam did yesterday, but again, I'm going to follow the elimination perspective.",
            "So it's from a somewhat different point of view.",
            "So again, remember the tree is just simply an undirected graph here that has no cycles.",
            "And you can always choose a particular node in a tree to be a root.",
            "You think about this being the root, and then you sort of move outwards and you hit the nodes on the edge, and these are called leaves for the obvious reason.",
            "So what you want to think about this is again, a point that Sam made.",
            "Yesterday's elimination is fine, but remember elimination.",
            "I sort of presuppose that I was sitting at node one and I cared about node one, and that's all I cared about in this case.",
            "But it could be the case that I care bout node one and node 7.",
            "Or maybe I care bout all nodes simultaneously.",
            "That's quite possible.",
            "If I gave you a noisy image from a telescope, you might care about.",
            "For instance, removing the noise.",
            "It's called denoising.",
            "You don't care about just one node, you care about all the pixels you'd like to actually do things simultaneously over all the nodes at once.",
            "So if you sort of think about this a bit, if you think about running elimination, you see right away that you're being very stupid.",
            "For violating the basic principle of algorithms, you're not recycling your computations.",
            "You're doing the same computations again and again and again.",
            "You only need to do them once.",
            "So really the sum product algorithm is just a clever way to run elimination simultaneously for every node of a tree.",
            "That's all it's doing.",
            "It's cleverly running the elimination for every node, but it's doing it in a way that you don't waste computation that you only do the computation the minimal number of times needed.",
            "And you sort of want to understand.",
            "I guess my brain is of limited capacity, so I always look for useful things like this.",
            "There are many algorithms in the literature that you might read about.",
            "I know that people here from different backgrounds you have different applications in mind, so some of you might have heard of things like the Alpha beta algorithm, the forward backward algorithm.",
            "These are things that are used in speech processing, bioinformatics.",
            "Other people might have heard about common filtering peeling algorithms.",
            "If you're a physicist, you would have heard about the transfer matrix method.",
            "Essentially, these are all special cases of this sum product algorithm, so it sort of says if you make the effort to understand what this some product or belief propagation algorithm is doing, then sort of for free.",
            "You understand what all of these guys are doing because they're all this particular cases for different kinds of models.",
            "This is for an HMM, typically discrete.",
            "This is typically for a Gauss Markov process on a chain or a tree.",
            "All of these cases, these algorithms, again, are particular cases of this kind of formalism, so there's a useful compression that goes on here.",
            "OK, so what's the connection to elimination?",
            "What you want to think about is let's first suppose that I was just fixated on this route.",
            "Let's call this guy the root.",
            "In trees are sort of a very natural elimination ordering.",
            "It's sort of obvious when you look at them and it's called leaf stripping because you sort of think I'm gonna start the leaves and I'm going to sum the leaves off and that allows me to strip this edge strip this edge strip this strip strip so it's sort of think that you're starting at the top of the tree and you're ripping the leaves, and then you rip the branches off and you recurse all the way down to the root.",
            "So it's basically just dynamic programming.",
            "As Sam set, except it's actually now dynamic programming on a tree as opposed to dynamic program."
        ],
        [
            "On a chain.",
            "Flex, let's understand how some product would work on a tree.",
            "Let's think about.",
            "Let's write our distribution over the tree.",
            "We've got pairwise terms for every edge, and there's no specific reason for doing this.",
            "This is just convention, but I'm also going to allow you to have a single function at every node.",
            "I'll allow you some function of the random variable at that node that might represent an observation.",
            "Just to be clear, I'm not going to put observations.",
            "You know, before I had X given Y, I'm going to drop that out now, because why is fixed?",
            "That's something you observe an.",
            "Just to keep the notation clean, we can just think about it in this form.",
            "So the simplest example of a tree is just two nodes, like this S&T.",
            "And So what?",
            "You want to think about is if you did elimination, you'd sum over this node T an if you sort of looked at what would happen, you're summing over X of T. You sort of end up with a certain output of a computation that X of T did, and what you want to think about that people refer to as a message.",
            "It's something that T has to send to S. Right, so you want to sort of thing T. He's sitting here doing this local computation.",
            "And then he's going to finish his computation.",
            "He's going to relay the output.",
            "Along the edge and pass it to S. That's the message that's passed.",
            "And so the message is, is this a vector or in general it's going to be a function that would be passed along the edge?",
            "And so you can see this guy can compute his marginal by taking his local function and then multiplying it by the message.",
            "So that's where the messages come from.",
            "And now you want to just think about Recursing on this.",
            "It's quite simple.",
            "Again, we're doing the kind of leaf stripping, elimination, ordering, and so you want to think.",
            "Well before I got to this point, I must have eliminated all these children that are sitting here of this node T. Right, so these guys were leaves in this graph, so I must have illuminated them first according to my ordering, and when I did that, I must have passed messages along these edges from WTV to T and utility.",
            "And So what happens is you're going to whole product of messages from the children.",
            "And this guy, what he's going to take the product.",
            "And then he's again going to some out the effect of X of T. So this is my first step in blue.",
            "The read here is just accounting for the effect of the children.",
            "That's sort of recursing one step.",
            "And that's basically it.",
            "You've just done a little recursion and what you get at the end of the day is that the message update equation should be of this form that what gets passed from node T to node S, it's going to be a function of S. Sort of.",
            "This guy is summarizing to ask what he needs to know about this part of the graph, and the way it works is you take this product over the incoming messages so you have a product here.",
            "And then X of T has to do his work.",
            "He has to sum things out.",
            "So this.",
            "This is why it's called sum product algorithm, also known as belief propagation in some communities.",
            "Right, so in general, you sort of think about this going on node S has got many neighbors.",
            "It's going to get messages from its neighbor T. It's got some other neighbor B and some other neighbor a, so it's going to actually combine its local evidence, and it's going to combine messages from each one of these subtrees here, here and here.",
            "And at the end of the day, these messages are going to sort of summarize the necessary information that needs to compute its marginal distributions."
        ],
        [
            "So any questions about that sort of derivation?",
            "What you want to understand is that you sort of moving just in a hierarchy.",
            "Do one edge first.",
            "Then you think of Recursing one edge plus the children that were coming into that edge before."
        ],
        [
            "And then recursing one more.",
            "You sort of think about node S actually has many children itself, and they all are passing messages in."
        ],
        [
            "So the sort of upshot here is that this is a completely parallel algorithm at the end of the day, there's not going to be any root.",
            "All of the nodes are just sitting there locali, they're just doing their local computations and their passing messages along edges.",
            "And what's nice about it is that you can show that will always converge after a finite number of steps on a tree, this is.",
            "And it is correct.",
            "It will yield the exact things, so it's very important that it's a parallel algorithm.",
            "Everyone is just doing the dumb local thing, and practically that parallelism is key.",
            "That's why this algorithm is in your wireless cards right now.",
            "Because because you can parallelize it, you can implement it very efficiently in a chip.",
            "So a lot of people spend lots of time implementing this algorithm in hardware in Silicon or field programmable gate arrays.",
            "And the only reason they can do that is because it's a local dumb algorithm.",
            "It's just doing local things, but what's very nice is that on trees, these local things are actually optimal.",
            "It's the right thing to do.",
            "So what you want to understand is that it's parallel message updates.",
            "Every node is just sitting there.",
            "Collecting messages from these neighbors along these edges.",
            "Taking a product.",
            "Performs a summation and then it relays that message along this outgoing edge and it's going to do that.",
            "It's going to relay one message along every one of its outgoing edges, but it just sits there doing that locali and once it converges then you just take a product like this and you get the marginals."
        ],
        [
            "So let me just wrap up this first part by talking very briefly about the Max product algorithm.",
            "If you understand the sum product algorithm, there's not much more to much more work to do here.",
            "That's the nice thing.",
            "The key observation is that basic distributive property that we spoke about.",
            "Applies also to doing Maxima in product.",
            "It's not just summations and products.",
            "So for instance, if I wanted to maximize the function over X1X2 and X1X3, I can just as easily start pushing the maximums inside like this so I can start distributing Maxima over products.",
            "And essentially you just go through the same argument everywhere you see a summation, you put a Max and what you get is called Max product and it again generalizes things like the Viterbi algorithm that many of you will be familiar with.",
            "So this is just saying that again, it's the same idea you're just doing everything with Max instead of summations.",
            "OK, so let's wrap up here for the first part.",
            "Any questions I guess just before we break about the sum product algorithm.",
            "Yeah, will you be talking about graphical codes for this?",
            "Not in terrible depth, but I'm happy to chat offline if you're interested.",
            "So the question is about graphical codes, things that sort of are being used in communication.",
            "You might have heard of Turbo codes or low density parity check codes.",
            "These again are special cases of graphical models and the algorithm that's implemented is exactly this sum product algorithm.",
            "But the codes are not trees.",
            "It turns out there's for certain reason trees are not good and you have to move beyond trees, and that's sort of where we're heading.",
            "There's many cases where trees are not a rich enough model class.",
            "You want richer models, so you have to move beyond simple tree models."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so I guess I just like to begin by thanking the organizers for the opportunity to be here.",
                    "label": 0
                },
                {
                    "sent": "It's a real pleasure to be part of this summer school.",
                    "label": 0
                },
                {
                    "sent": "I've been enjoying myself thoroughly so far.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to be talking in this part about graphical models, message passing algorithms and variational methods.",
                    "label": 1
                },
                {
                    "sent": "And there will be a bit of overlap with the talk of Sam roll ice, but I'll also be moving on to some more advanced topics.",
                    "label": 0
                },
                {
                    "sent": "Sort of building on the foundation that Sam built for us over the past couple days.",
                    "label": 0
                },
                {
                    "sent": "So for those of you interested, if you look at my webpage, there's copies of these slides also.",
                    "label": 1
                },
                {
                    "sent": "Fortunately, copies of films of course lectures so much more detail than I'll give here.",
                    "label": 0
                },
                {
                    "sent": "This will be somewhat more high level than a full length course for obvious reasons, but if you're interested in more details, you can have a look at this web page there.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So sort of reviewing part of what Sam said.",
                    "label": 0
                },
                {
                    "sent": "Graphical models are really a framework for describing systems that are statistical in nature, but there also large scale and multivariate.",
                    "label": 1
                },
                {
                    "sent": "So you want to think about many random variables and all interacting in possibly quite complex ways.",
                    "label": 1
                },
                {
                    "sent": "And graphical models are actually this Mike.",
                    "label": 0
                },
                {
                    "sent": "Funny, by the way, feels funny to me.",
                    "label": 0
                },
                {
                    "sent": "Can people hear me properly?",
                    "label": 0
                },
                {
                    "sent": "OK, so they're actually using studied in many fields.",
                    "label": 1
                },
                {
                    "sent": "Of course they are widely used in machine learning, but historically at least they were used much earlier in other fields, primarily in statistical physics to model things like crystals and magnets.",
                    "label": 0
                },
                {
                    "sent": "And gas is basically very large systems where lots of things are interacting and it's only more recently that they've proven very useful in.",
                    "label": 1
                },
                {
                    "sent": "Other fields of engineering and computer science, so I'll talk a bit about applications in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Many applications in machine learning, lots in bioinformatics and computational biology.",
                    "label": 0
                },
                {
                    "sent": "And also to sort of illustrate other applications that you might not be aware of, but that are very relevant given you're using computers and wireless devices, I'll talk a bit about how graphical models play a role in communication systems.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just some broad questions before we get into details.",
                    "label": 1
                },
                {
                    "sent": "It's useful to think there's there's several kinds of questions or issues to think about when you're considering using a graphical model, and will get into a bit of detail on each of these.",
                    "label": 0
                },
                {
                    "sent": "First, I would call a representational issue.",
                    "label": 0
                },
                {
                    "sent": "It's really an issue of your given some phenomenon.",
                    "label": 0
                },
                {
                    "sent": "It might be an image, it might be a text database.",
                    "label": 0
                },
                {
                    "sent": "You might be trying to track a vehicle.",
                    "label": 0
                },
                {
                    "sent": "What you really want to understand is what graphical models are useful for capturing or modeling the particular phenomenon that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So it's really a representational issue.",
                    "label": 0
                },
                {
                    "sent": "It's trying to understand how does what classes of models are useful for what purposes.",
                    "label": 1
                },
                {
                    "sent": "Basically, there's a tautology that no model can be good for everything.",
                    "label": 0
                },
                {
                    "sent": "If someone tells you this model is good for everything, they're lying to you.",
                    "label": 0
                },
                {
                    "sent": "It's probably useless.",
                    "label": 0
                },
                {
                    "sent": "In fact, models are generally good for specific purposes, but you need to understand what the sort of tradeoffs between different models are.",
                    "label": 1
                },
                {
                    "sent": "They're also statistical issues with these models.",
                    "label": 0
                },
                {
                    "sent": "They are essentially statistical models for fitting random variables, probabilistic systems, and so, as Sam spoke about, one important issue is really that of inference.",
                    "label": 0
                },
                {
                    "sent": "At a high level, you want to think about this is how do you move from data.",
                    "label": 0
                },
                {
                    "sent": "You're observing some data in the real world.",
                    "label": 1
                },
                {
                    "sent": "And you'd like to somehow, on the basis of measurements you'd like to make inferences.",
                    "label": 0
                },
                {
                    "sent": "You'd like to draw conclusions about some underlying hidden phenomenon, and I'll give you some examples of that in the next few slides.",
                    "label": 1
                },
                {
                    "sent": "As Sam also spoke about there's issues of how you fit parameters.",
                    "label": 0
                },
                {
                    "sent": "How do you choose the best model to fit your data?",
                    "label": 1
                },
                {
                    "sent": "And somewhat more broadly, the question of model selection, how do you actually choose the class of models it's appropriate.",
                    "label": 0
                },
                {
                    "sent": "The third sort of interrelated issue is really a computational one.",
                    "label": 0
                },
                {
                    "sent": "And that has to do with the fact is, as I mentioned, these models are typically very large scale.",
                    "label": 0
                },
                {
                    "sent": "You're not just interested in things with 1, two, or three subcomponents, you're interested in things with hundreds, thousands, possibly millions of interacting components, so computation issues of storage and efficiency really become critical.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to see is that the graphical models really helped to clarify some of the links.",
                    "label": 0
                },
                {
                    "sent": "There's some very deep and nice connections, very powerful connections between the structure of the graphs that you use.",
                    "label": 0
                },
                {
                    "sent": "Sam was mentioning last time chains and trees will be talking about somewhat more general graphs and will see their connections between the structure and sort of what the inherent computational complexity of applying and using these models is.",
                    "label": 0
                },
                {
                    "sent": "So anyway.",
                    "label": 0
                },
                {
                    "sent": "Feel free to jump in with questions whenever you feel so inclined.",
                    "label": 0
                },
                {
                    "sent": "You think about a speakers, you should try and control your speaker somewhat.",
                    "label": 0
                },
                {
                    "sent": "This is what I tell my students.",
                    "label": 0
                },
                {
                    "sent": "If your speaker goes too quickly, then you should throw questions in the way to slow them down.",
                    "label": 0
                },
                {
                    "sent": "If your speaker goes too slowly, then you should fall asleep in Jan and start making noises that will encourage your speaker to go more quickly.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is just an outline.",
                    "label": 0
                },
                {
                    "sent": "Again, part of this is actually piggybacking on what Sam spoke about, so I'm going to go through this parts of it a bit more quickly than I would normally.",
                    "label": 0
                },
                {
                    "sent": "In particular, this message passing Sam already spoke about on trees.",
                    "label": 0
                },
                {
                    "sent": "I'm actually going to prevent it from a slightly different perspective, so you'll be seeing the same material, but from a somewhat different view, and I think that can be useful.",
                    "label": 0
                },
                {
                    "sent": "It's often useful to see things from different points of view.",
                    "label": 0
                },
                {
                    "sent": "It gives you a deeper understanding, so in this first part I'll sort of be talking bout the basic properties.",
                    "label": 0
                },
                {
                    "sent": "And in the second part of these talks will move on to more advanced methods.",
                    "label": 0
                },
                {
                    "sent": "Things that are sort of being used in cutting edge applique.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Patiens so the first example, probably the simplest 1 one that Sam is already spoken about, is a hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "So again, remember graphical models are based on a graph, so you've got a set of nodes like this.",
                    "label": 0
                },
                {
                    "sent": "And you want to think that a random variable is sitting is associated with each node.",
                    "label": 0
                },
                {
                    "sent": "So here you have a very natural change structure.",
                    "label": 0
                },
                {
                    "sent": "It's natural to think about these nodes evolving in time an you could use this kind of model to describe, for instance, if you were trying to track a vehicle that could be the position of the vehicle at different time steps time one time, 2 * 3 and these colored nodes here is.",
                    "label": 0
                },
                {
                    "sent": "Sam told us these represent observations you don't observe directly the vehicle, but you might be able to have a video camera that could make measurements.",
                    "label": 0
                },
                {
                    "sent": "Maybe an infrared sensor.",
                    "label": 0
                },
                {
                    "sent": "You might have acoustic sensors, so you.",
                    "label": 0
                },
                {
                    "sent": "Be given observations and you'd like to do things you like to actually draw inferences about what's going on in this hidden part here.",
                    "label": 0
                },
                {
                    "sent": "So these models are really a workhorse that they're a real workhorse in the graphical model world.",
                    "label": 0
                },
                {
                    "sent": "Only one of the earliest graphical models, and they're widely used, for instance in computational biology, in speech and text processing, in control theory for things like tracking signal processing.",
                    "label": 1
                },
                {
                    "sent": "But a wide range of uses, and one thing that's very nice about them.",
                    "label": 0
                },
                {
                    "sent": "This is something again that Sam mentioned is to review.",
                    "label": 0
                },
                {
                    "sent": "Is that the problem of inference that is moving from the observations here that you've made to make inferences about what's going on here.",
                    "label": 0
                },
                {
                    "sent": "What's nice is that this is tractable by very fast linear time algorithms, and that was the belief propagation or the sum product algorithm that Sam mentioned.",
                    "label": 0
                },
                {
                    "sent": "Now have a look at this model.",
                    "label": 1
                },
                {
                    "sent": "This is again a graphical model, but it's it's a slight elaboration of a hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "It's something that's called a coupled hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "So the way you want to think about this is you now have.",
                    "label": 0
                },
                {
                    "sent": "In this case I just have three chains, one here, evolving a second one, and a third one.",
                    "label": 0
                },
                {
                    "sent": "But what's interesting about it is that you then make an observation down here, and this observation is actually tying together it's coupling or tying together all the chains.",
                    "label": 0
                },
                {
                    "sent": "So why might this be useful?",
                    "label": 0
                },
                {
                    "sent": "One application which this has been used a lot is, for instance, if you're trying to do Fusion of video and audio streams, you can imagine that you have a video sequence that's evolving like this.",
                    "label": 0
                },
                {
                    "sent": "You might have another video sequence from another camera, and you might have an audio stream and they're all evolving in time together.",
                    "label": 0
                },
                {
                    "sent": "But then you're making observations of them and those observations sort of couple them together.",
                    "label": 0
                },
                {
                    "sent": "It says that those three things the two cameras and the audio stream we're all going to evolve together, so that's that's the kind of phenomenon that this model could.",
                    "label": 0
                },
                {
                    "sent": "Start to allow you to capture what you want to understand.",
                    "label": 0
                },
                {
                    "sent": "The high level is that this model is actually quite different than this model.",
                    "label": 0
                },
                {
                    "sent": "It's a richer model.",
                    "label": 0
                },
                {
                    "sent": "It allows you to model A broader class of phenomena, but you pay a price for that.",
                    "label": 0
                },
                {
                    "sent": "It doesn't come for free, and the price you pay is in terms of computational complexity of inference of moving from these observations to trying to figure out what's going on up here.",
                    "label": 0
                },
                {
                    "sent": "In this case, it was very easy by message passing algorithms in this case.",
                    "label": 0
                },
                {
                    "sent": "In general, it's actually intractable.",
                    "label": 0
                },
                {
                    "sent": "It's a very hard problem, and So what we're going to see later on is that this sort of motivates what are known as approximate methods for doing inference.",
                    "label": 0
                },
                {
                    "sent": "Not exactly, but nearly exactly.",
                    "label": 0
                },
                {
                    "sent": "For more complex models like this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so a second example, a sort of 2D example you can think of a hidden Markov model is essentially 1D, something evolving in time.",
                    "label": 0
                },
                {
                    "sent": "A 2 dimensional example would be if you think about trying to model images.",
                    "label": 0
                },
                {
                    "sent": "And here I've shown you a nice picture of what people call a natural image.",
                    "label": 1
                },
                {
                    "sent": "I don't know quite what that means.",
                    "label": 0
                },
                {
                    "sent": "I guess most people would agree this is natural to picture of a mountain and things like that.",
                    "label": 0
                },
                {
                    "sent": "So why might you be interested in sort of modeling natural images?",
                    "label": 0
                },
                {
                    "sent": "There's many reasons why you might be interested.",
                    "label": 0
                },
                {
                    "sent": "One might be that you'd be interested in doing classification.",
                    "label": 0
                },
                {
                    "sent": "You might be like to detect, for instance, different kinds of landscape or scenery.",
                    "label": 0
                },
                {
                    "sent": "Here you'd like to say this is a Lake.",
                    "label": 0
                },
                {
                    "sent": "This is a field, and this is a mountain.",
                    "label": 0
                },
                {
                    "sent": "You might like to do segmentation as well.",
                    "label": 0
                },
                {
                    "sent": "You'd like to segment the Sky here from the mountain etc, and so sort of natural way to do that is to start building a graphical model that describes the structure of this kind of image.",
                    "label": 0
                },
                {
                    "sent": "Lot of structure in this image, right?",
                    "label": 0
                },
                {
                    "sent": "It doesn't look like television noise.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look dis completely throwing down pixels at random.",
                    "label": 0
                },
                {
                    "sent": "You can see there's lots of smoothness here.",
                    "label": 0
                },
                {
                    "sent": "So sort of the most natural model, and historically the earliest one would be too.",
                    "label": 0
                },
                {
                    "sent": "You've got an image here and you could think about storing it.",
                    "label": 0
                },
                {
                    "sent": "You've got a whole bunch of pixels, maybe it's 400 by 400 pixels.",
                    "label": 0
                },
                {
                    "sent": "An you could build your graphical model by putting a node.",
                    "label": 0
                },
                {
                    "sent": "Here you put one node for every pixel here and then you put a random variable at that node that tells you what's the grayscale level that I'm looking at.",
                    "label": 0
                },
                {
                    "sent": "Right, So what this model would start to say is these edges?",
                    "label": 0
                },
                {
                    "sent": "We'll get more precise about this a bit later, but these edges tell you there's going to be relations between pixels that are nearby in the image, so this model is going to allow us to start capturing some of the structure that you see in images, natural images that you don't see, for instance, in television noise.",
                    "label": 0
                },
                {
                    "sent": "So this is one of actually the earliest models that was used in image processing and computer vision.",
                    "label": 1
                },
                {
                    "sent": "But in many ways at least, the initial use of this wasn't so successful, and a lot of the reason was is because it's very hard to do exact computation in this kind of model.",
                    "label": 0
                },
                {
                    "sent": "It's not at all the tree.",
                    "label": 0
                },
                {
                    "sent": "Member of tree is something that doesn't have cycles in the graph and this has lots of cycles.",
                    "label": 0
                },
                {
                    "sent": "If you were an Ant you could walk around a lot of cycles like this and those cycles in the graph actually make it very hard to do exact computation.",
                    "label": 0
                },
                {
                    "sent": "So people I think initially were very excited by using these models.",
                    "label": 0
                },
                {
                    "sent": "This is sort of back in the late 70s, early 80s and then I think they became a bit discouraged because you know the model is great, but you can't really do anything with it.",
                    "label": 0
                },
                {
                    "sent": "You can apply certain kinds of very computationally intensive methods, but they're just much too slow to be of interest in practical applications.",
                    "label": 0
                },
                {
                    "sent": "What we'll come back to later is sort of approximate methods that you can apply to models like this.",
                    "label": 0
                },
                {
                    "sent": "At least historically, what did happen is people started moving away from models that looked like this, and they moved into models that were again trees.",
                    "label": 0
                },
                {
                    "sent": "And so this is 1 example of the tree model in which you sort of think about having many scales.",
                    "label": 0
                },
                {
                    "sent": "For those of you who know something about wavelets, you can think about this as representing a core scale of information.",
                    "label": 0
                },
                {
                    "sent": "These four nodes would be medium scales of information and then down here you'd have fine scale, so it's what's known as a multi resolution or a multiscale transform.",
                    "label": 0
                },
                {
                    "sent": "So these became quite popular and they're still used again.",
                    "label": 0
                },
                {
                    "sent": "What's nice is that you can run very fast algorithms on them.",
                    "label": 0
                },
                {
                    "sent": "What's not nice is that these models are not as rich as these.",
                    "label": 0
                },
                {
                    "sent": "They can cause water known as boundary artifacts.",
                    "label": 0
                },
                {
                    "sent": "So again, there's always this tension.",
                    "label": 0
                },
                {
                    "sent": "This tradeoff between how complex your model is, what you can represent with it, and issues of computation.",
                    "label": 0
                },
                {
                    "sent": "What can you solve efficiently in different models?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3rd example again from computer vision and this is one that's the topical interest.",
                    "label": 0
                },
                {
                    "sent": "A lot of work is being done currently.",
                    "label": 0
                },
                {
                    "sent": "On this there's a fairly long paper looking at methods exactly like this that I see.",
                    "label": 0
                },
                {
                    "sent": "See the Computer Vision conference at looking at these kinds of techniques for disparity computation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me just show you a picture first.",
                    "label": 0
                },
                {
                    "sent": "So this is what's known as a stereo pair.",
                    "label": 0
                },
                {
                    "sent": "How many of you have seen stereo pairs before?",
                    "label": 1
                },
                {
                    "sent": "OK, so two or three?",
                    "label": 0
                },
                {
                    "sent": "Essentially, what this is is it's 2 copies of the same image, so it's a picture of a cathedral if I'm not mistaken, it's a cathedral in the city where Alex Small's parents are from.",
                    "label": 0
                },
                {
                    "sent": "That's just a coincidence, but a nice one, but it's not exactly the same picture.",
                    "label": 0
                },
                {
                    "sent": "It's the picture taken from 2 slightly shifted cameras.",
                    "label": 0
                },
                {
                    "sent": "So you want to think about the cameras like your eyes.",
                    "label": 0
                },
                {
                    "sent": "Your eyes are slightly shifted.",
                    "label": 0
                },
                {
                    "sent": "Offset like this, you can think about your eyes is taking two slightly different pictures of the same image.",
                    "label": 0
                },
                {
                    "sent": "So the people that study stereo and they can do what's called Fusion.",
                    "label": 0
                },
                {
                    "sent": "I don't know if I can teach it to you, just on the spur of the moment like this, but if you stare you can actually do it on your paper as well as up here.",
                    "label": 0
                },
                {
                    "sent": "If you stare at this and kind of cross your eyes to make the images come together.",
                    "label": 0
                },
                {
                    "sent": "If you fuse them to make one image, what you should see is that this should be very much in front.",
                    "label": 0
                },
                {
                    "sent": "You should see an appearance of depth.",
                    "label": 0
                },
                {
                    "sent": "This should be in front and you should see the ceiling going backwards.",
                    "label": 0
                },
                {
                    "sent": "You should see a 3 dimensional image by combining 22 dimensional images.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's a good suggestion.",
                    "label": 0
                },
                {
                    "sent": "Sam here is.",
                    "label": 0
                },
                {
                    "sent": "Doing tricks with his thumb and I don't know it makes you look a bit stupid if you sit there doing it.",
                    "label": 0
                },
                {
                    "sent": "But when you finally get it, it can be worthwhile for sure.",
                    "label": 0
                },
                {
                    "sent": "And they're actually whole books of these things.",
                    "label": 0
                },
                {
                    "sent": "If I have some friends who study stereo and all they do is go around all day doing this, they look completely insane.",
                    "label": 0
                },
                {
                    "sent": "But anyway, so the point is we can do that and other mammals.",
                    "label": 0
                },
                {
                    "sent": "Monkeys can do this, but we're in machine learning.",
                    "label": 0
                },
                {
                    "sent": "We'd like to make computers do this right?",
                    "label": 0
                },
                {
                    "sent": "And it's an interesting problem.",
                    "label": 0
                },
                {
                    "sent": "'cause it's saying that there's enough information in these two shifted copies for you to recover depth.",
                    "label": 0
                },
                {
                    "sent": "But how do you do this automatically?",
                    "label": 0
                },
                {
                    "sent": "And So what will discuss a bit later is that you can actually formulate this very naturally as.",
                    "label": 0
                },
                {
                    "sent": "As a problem in a Markov random field and it's a Markov random field in which you measure the shifts between the two images and you try and optimize those shifts, and so we'll get into a bit more details of this kind of model later.",
                    "label": 0
                },
                {
                    "sent": "This sort of high level, it's people use things like lattice models.",
                    "label": 0
                },
                {
                    "sent": "What's tricky is again that trying to find the optimal shift, trying to sort of shift things around to make the match in the best way.",
                    "label": 0
                },
                {
                    "sent": "This, again, is computationally intractable, but we'll see later that people are in practice using message passing algorithms.",
                    "label": 0
                },
                {
                    "sent": "These are approximate methods here that are doing very well for this problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just one last example before I move on.",
                    "label": 0
                },
                {
                    "sent": "This last example has to do with problems of communication.",
                    "label": 0
                },
                {
                    "sent": "And so some of you might be aware of this if you studied communication engineering, you might be aware of these things, but certainly all of you have, I suspect, experience with devices that use this kind of technology.",
                    "label": 0
                },
                {
                    "sent": "So as I sort of was mentioning yesterday, someone asked about a killer application for graphical models.",
                    "label": 0
                },
                {
                    "sent": "This certainly is 1 killer application.",
                    "label": 0
                },
                {
                    "sent": "This is an area where graphical models and message passing have really revolutionized the field in the last 10 years.",
                    "label": 0
                },
                {
                    "sent": "So the basic problem here is you want to imagine that you're trying to communicate a source of information.",
                    "label": 0
                },
                {
                    "sent": "Maybe you're just talking to your friend on the phone.",
                    "label": 0
                },
                {
                    "sent": "But we're going to idealize this is you're just trying to send, let's say, is zero.",
                    "label": 0
                },
                {
                    "sent": "You want to send your friend a zero or a one?",
                    "label": 0
                },
                {
                    "sent": "That would be the simplest kind of communication you could do.",
                    "label": 0
                },
                {
                    "sent": "And the catch is that.",
                    "label": 0
                },
                {
                    "sent": "The channel that you have by channel we just mean something like a wireless phone that you speak over the channel doesn't work perfectly.",
                    "label": 0
                },
                {
                    "sent": "If you send a 0 maybe it will flip that zero to be a one.",
                    "label": 0
                },
                {
                    "sent": "So your friends not quite sure what you sent.",
                    "label": 0
                },
                {
                    "sent": "Maybe you sent to 0, maybe a one he or she isn't quite sure.",
                    "label": 0
                },
                {
                    "sent": "The idea here is that what you'd like to do is be clever and start doing things like Tom was actually mentioning.",
                    "label": 0
                },
                {
                    "sent": "These are called.",
                    "label": 0
                },
                {
                    "sent": "These are error correcting codes you'd like to add redundancy to what you transmit.",
                    "label": 0
                },
                {
                    "sent": "So the simplest thing to do would be to send 05 times.",
                    "label": 0
                },
                {
                    "sent": "And as long as at most two of the bits got flipped, then your friend could say, well, there's more zeros than ones, and I can decode correctly.",
                    "label": 0
                },
                {
                    "sent": "So that's a very simple example of an error correcting code.",
                    "label": 0
                },
                {
                    "sent": "It's called a repetition code.",
                    "label": 0
                },
                {
                    "sent": "It's a very stupid example of an error correcting code.",
                    "label": 0
                },
                {
                    "sent": "That's not what's used in practice.",
                    "label": 0
                },
                {
                    "sent": "That's a very bad thing to do.",
                    "label": 0
                },
                {
                    "sent": "But it illustrates the principle and this kind of problem of communicating like this has lots of applications.",
                    "label": 0
                },
                {
                    "sent": "The Rovers that were sent to Mars that were wandering around they were using these codes to transmit information back to Earth.",
                    "label": 0
                },
                {
                    "sent": "Berkeley lots of people are working on sensor networks, nodes, networks have lots of little devices and there's a lot of error control coding that goes into those.",
                    "label": 0
                },
                {
                    "sent": "Your wireless card for those that have you are using wireless right now is using error correcting coding.",
                    "label": 0
                },
                {
                    "sent": "Your hard drive is also using error correcting coding, so this is all around you.",
                    "label": 0
                },
                {
                    "sent": "Even if you don't know about it.",
                    "label": 0
                },
                {
                    "sent": "So the high level the key thing is that Shannon back in the 40s sort of laid out a very beautiful theory.",
                    "label": 0
                },
                {
                    "sent": "That said, how well you can ever expect to do this, but he was a theorist.",
                    "label": 0
                },
                {
                    "sent": "He just said in principle you can do this, but he didn't give any indication of how you could actually in practice do it.",
                    "label": 0
                },
                {
                    "sent": "And so what's exciting is that graphical models.",
                    "label": 0
                },
                {
                    "sent": "This is where graphical models come in.",
                    "label": 0
                },
                {
                    "sent": "They've really enabled people to solve this kind of problem as near to optimally as possible, and so graphical models are being used.",
                    "label": 0
                },
                {
                    "sent": "For instance in your wireless cards.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "Let me skip this just in the interest of time.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's sort of some illustrative examples of applications and with graphical models arise, that's by no means exhaustive.",
                    "label": 0
                },
                {
                    "sent": "I sort of chose some examples, I think not to intersect so much with other speakers, but other people talking, for instance, about text about bioinformatics.",
                    "label": 0
                },
                {
                    "sent": "In all of these applications.",
                    "label": 0
                },
                {
                    "sent": "Again, graphical models have have a role to play.",
                    "label": 0
                },
                {
                    "sent": "So any questions about those applications?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's move on.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the basics of graphical models.",
                    "label": 0
                },
                {
                    "sent": "This again is reviewing a bit what Sam taught us over the past couple of days.",
                    "label": 0
                },
                {
                    "sent": "So I'll be focusing mainly on undirected models.",
                    "label": 0
                },
                {
                    "sent": "I'll talk briefly about directed models that Sam also spoke about, but primarily about undirected models.",
                    "label": 0
                },
                {
                    "sent": "And I'll explain why in a couple of slides.",
                    "label": 0
                },
                {
                    "sent": "So again, an undirected model that just means the graph that you're looking at.",
                    "label": 0
                },
                {
                    "sent": "It means the edges don't have arrows on them.",
                    "label": 0
                },
                {
                    "sent": "There's no direction to them, there's just a link like that with no no directionality.",
                    "label": 0
                },
                {
                    "sent": "So again, you want to have a graph, a set of nodes, circles and edges, and you've got random variables at each node.",
                    "label": 0
                },
                {
                    "sent": "And so what's important here is what turns out to be important is what are known as the cliques of the graph.",
                    "label": 0
                },
                {
                    "sent": "So cliques of the graph or are just friends, it's a clique is a set of nodes that all talk to each other that all share edges.",
                    "label": 0
                },
                {
                    "sent": "So for instance here 123.",
                    "label": 0
                },
                {
                    "sent": "This is a clique 1.",
                    "label": 1
                },
                {
                    "sent": "Two is also a clique, but 123 is a maximal clique.",
                    "label": 0
                },
                {
                    "sent": "Because this is the biggest step that I can make of things that all talk to each other.",
                    "label": 0
                },
                {
                    "sent": "Similarly, 4 Seven is a maximal clique, 456 is a maximal clique.",
                    "label": 0
                },
                {
                    "sent": "So that's going to be important because cliques are going to find sort of the notion of locality.",
                    "label": 0
                },
                {
                    "sent": "What's key in graphical models is what do you mean by local and cliques tell you what it means to be local, what's local to you, is what you can talk to in one step.",
                    "label": 0
                },
                {
                    "sent": "That's what's in your clique.",
                    "label": 0
                },
                {
                    "sent": "Well, it's related to what's in your clique.",
                    "label": 1
                },
                {
                    "sent": "Something else that's also important is what's known as a vertex cut set, and this again is a very intuitive notion.",
                    "label": 1
                },
                {
                    "sent": "It's just saying it's a subset of vertices that if you snip these out, you took scissors and went, snip, snip, snip, snip, snip.",
                    "label": 0
                },
                {
                    "sent": "Then the graph would break into two or more pieces, so it's saying if you cut those out then the graph breaks apart and so we're going to see is that these two things.",
                    "label": 1
                },
                {
                    "sent": "These two notion cliques and cut sets these play an important role in how we describe undirected graphical models.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The way these graphical models work is that what you're doing is you're using the graph.",
                    "label": 0
                },
                {
                    "sent": "Describe what you believe about the dependencies that you see in your random variables.",
                    "label": 0
                },
                {
                    "sent": "Right in many applications there's again this notion of locality.",
                    "label": 0
                },
                {
                    "sent": "If you have a collection of sensors, your intuition is that sensor should interact locally in a spatial sense that a sensor here should interact with one here, but it shouldn't interact directly with something on the other side of the room which interact with its neighbors, and so the graph here is specifying this neighborhood structure.",
                    "label": 0
                },
                {
                    "sent": "And in a more precise sense, you use the graph to impose constraints on the random vector, and there's two different ways to do this.",
                    "label": 1
                },
                {
                    "sent": "They seem different at first, but they turn out to be equivalent.",
                    "label": 0
                },
                {
                    "sent": "And the first is, by the notion of Markov properties.",
                    "label": 0
                },
                {
                    "sent": "So you say that.",
                    "label": 0
                },
                {
                    "sent": "The random vector X, so this is all the random variables.",
                    "label": 0
                },
                {
                    "sent": "It's Markov if subsets of variables XA and XB become conditionally independent whenever you have a vertex cut set.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that if you observe the values of the random variables here right, you're conditioning on them when you observe them.",
                    "label": 0
                },
                {
                    "sent": "Then it says that this subset of variables XA becomes conditionally independent of this subset, so it's sort of capturing the fact that when you condition that's breaking the graph.",
                    "label": 0
                },
                {
                    "sent": "And in terms of the random variables, it's breaking them apart because they become independent.",
                    "label": 0
                },
                {
                    "sent": "So you're all will have heard last time from Sam about the simple example of when you have an HMM.",
                    "label": 0
                },
                {
                    "sent": "This is the simplest example of a Markov property you think about the present here, and this is the future, and this is the past.",
                    "label": 0
                },
                {
                    "sent": "So if you condition on the present, that's a cut set that will break the graph into two.",
                    "label": 0
                },
                {
                    "sent": "Then as Sam told us, the past and the future become conditionally independent.",
                    "label": 0
                },
                {
                    "sent": "Sounds kind of mystical, but that's just a special case of the Markov property that I just stated.",
                    "label": 0
                },
                {
                    "sent": "This is something past and future and present.",
                    "label": 0
                },
                {
                    "sent": "That's a special case of this, but we're interested in this actually for more general graphs.",
                    "label": 0
                },
                {
                    "sent": "And you can get much richer Markov properties in more general graphs.",
                    "label": 1
                },
                {
                    "sent": "So that's the Markov property.",
                    "label": 0
                },
                {
                    "sent": "That's one way that you can use the graph to constrain the form of the distribution.",
                    "label": 0
                },
                {
                    "sent": "The other way to constrain the form of the distribution is is in terms of how the distribution might factorize.",
                    "label": 0
                },
                {
                    "sent": "So let's just skip back to this example.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine that you had binary variables, so variables that took value 0 and 1 zero and 1 zero and one at every one of these nodes.",
                    "label": 0
                },
                {
                    "sent": "Right, so in general, how many numbers would you need to represent a distribution over that set of random variables?",
                    "label": 0
                },
                {
                    "sent": "Right, so 2 to 7 -- 1 right?",
                    "label": 0
                },
                {
                    "sent": "Because you've got 2 to the seven possible configurations in your whole graph.",
                    "label": 0
                },
                {
                    "sent": "But then, probability distributions have to sum to one, so you lose 1 degree of freedom.",
                    "label": 0
                },
                {
                    "sent": "Right, so two to seven.",
                    "label": 0
                },
                {
                    "sent": "This is a toy problem.",
                    "label": 0
                },
                {
                    "sent": "Again, this is not something practical that's already getting big.",
                    "label": 0
                },
                {
                    "sent": "If you thought about something that, for instance, modeling an image, just a binary image, that was, let's say 400 by 400, you'd be looking at 2 to 400 ^2.",
                    "label": 0
                },
                {
                    "sent": "That's a very big number, that's an understatement.",
                    "label": 0
                },
                {
                    "sent": "That's more than the number of atoms in the entire universe.",
                    "label": 0
                },
                {
                    "sent": "The entire visible universe.",
                    "label": 0
                },
                {
                    "sent": "So what it's saying is that in less, you start exploding structure.",
                    "label": 0
                },
                {
                    "sent": "There's no way you could ever even store.",
                    "label": 0
                },
                {
                    "sent": "You can't store a vector that has 2 to 400 squared elements.",
                    "label": 0
                },
                {
                    "sent": "If you can, then I'd like a version of your computer, please.",
                    "label": 0
                },
                {
                    "sent": "So the point here is that we're going to use the graph to constrain the form of the distribution we're going to impose it to be local, so it's going to drop the number of degrees of freedom, so we're losing something in doing that.",
                    "label": 0
                },
                {
                    "sent": "We're losing.",
                    "label": 0
                },
                {
                    "sent": "We can't express all distributions anymore, but we're gaining a lot because we can actually do things with this model.",
                    "label": 0
                },
                {
                    "sent": "We can store it, we can apply it, and we can do inference.",
                    "label": 0
                },
                {
                    "sent": "And so the way we constraint is by saying things have to decompose into local functions.",
                    "label": 0
                },
                {
                    "sent": "These are called compatibility functions or potential functions.",
                    "label": 0
                },
                {
                    "sent": "And these functions are local in the sense that they depend only on the random variables in the clique.",
                    "label": 0
                },
                {
                    "sent": "So there be a function for 123 function for 345 etc.",
                    "label": 0
                },
                {
                    "sent": "So you've got a local product of functions.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to look at a simple example, let's go back to this image model that we had before.",
                    "label": 0
                },
                {
                    "sent": "Now I'm trying to model a baboon and again I'm using just a simple lattice model.",
                    "label": 0
                },
                {
                    "sent": "I'm thinking about these being grayscale values.",
                    "label": 0
                },
                {
                    "sent": "They might be 0, one or they might be 01 to 255.",
                    "label": 0
                },
                {
                    "sent": "And So what you want to think about is the cliques.",
                    "label": 0
                },
                {
                    "sent": "Here the maximal cliques are just edges, just pairs of nodes.",
                    "label": 0
                },
                {
                    "sent": "So what it means is that you're sort of allowed a function of pairwise interaction term that's going to sit on every one of these edges.",
                    "label": 0
                },
                {
                    "sent": "And that term is going to tell you how is this pixel value related to this pixel value.",
                    "label": 0
                },
                {
                    "sent": "So simple case if I just had three grayscales, I'd have a three by three matrix.",
                    "label": 0
                },
                {
                    "sent": "I might look at an interaction of this form.",
                    "label": 0
                },
                {
                    "sent": "I could have one number a along the diagonal and then B on the off diagonal.",
                    "label": 0
                },
                {
                    "sent": "And so there's sort of two parameters here, and if I set a larger than B.",
                    "label": 0
                },
                {
                    "sent": "What that would tell you is that you're more likely to have values on the diagonal values that are equal then values on the off diagonal.",
                    "label": 0
                },
                {
                    "sent": "So this would start imposing a kind of smoothness constraint.",
                    "label": 0
                },
                {
                    "sent": "It would say pixels that are nearby, like pixels on this nose are likely to have close grayscale values, so it's a very simple kind of thing that you're imposing, but it's a start.",
                    "label": 0
                },
                {
                    "sent": "That's how compatibility functions work.",
                    "label": 0
                },
                {
                    "sent": "They sort of tell you about local interactions between the pixels.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me say something briefly about directed graphical models.",
                    "label": 1
                },
                {
                    "sent": "Again, just recapping what Sam did.",
                    "label": 0
                },
                {
                    "sent": "For directed models, you have now arrows on the edges, and the semantics are somewhat different.",
                    "label": 0
                },
                {
                    "sent": "You really think about the parents?",
                    "label": 0
                },
                {
                    "sent": "For instance, if I focus on this blue note here, it's parents are these red nodes and you think about the factorization is taking place over conditional distributions of the child given its parents.",
                    "label": 0
                },
                {
                    "sent": "So in some ways it's kind of parent to child.",
                    "label": 0
                },
                {
                    "sent": "It's a generational factorization, child conditioned on its parents.",
                    "label": 0
                },
                {
                    "sent": "So these models are useful for they can express certain kinds of causal relations.",
                    "label": 0
                },
                {
                    "sent": "Sam mentioned something called the explaining away phenomenon, so there's certain kinds of things that directed graphical models can express that undirected ones cannot, but vice versa.",
                    "label": 0
                },
                {
                    "sent": "So there's some things that undirected models can express the directed ones can't.",
                    "label": 0
                },
                {
                    "sent": "So one model is not better than the other.",
                    "label": 0
                },
                {
                    "sent": "It really depends on what kind of application you're looking at, and it takes experience and intuition to sort of figure out what's most appropriate for what you're trying to model.",
                    "label": 0
                },
                {
                    "sent": "Purposes of this talk.",
                    "label": 0
                },
                {
                    "sent": "I'm going to focus mainly on undirected models, as I mentioned before, and the reason being that when it comes time to doing inference, the first step when you're given a directed graphical model is actually to convert it to an undirected model.",
                    "label": 0
                },
                {
                    "sent": "So from the computational point of view, if you're given a directed model, you typically convert it first to an undirected model, and since I'll be talking primarily about computation in the later part of the talk, I'll sort of assume that you've converted this directed model.",
                    "label": 0
                },
                {
                    "sent": "If you remember, Sam mentioned this, it has a quirky name.",
                    "label": 0
                },
                {
                    "sent": "The procedure is called moralization because what you do is you marry all the parents the parents have had an illegitimate child and were moral people.",
                    "label": 0
                },
                {
                    "sent": "So we marry the parents.",
                    "label": 0
                },
                {
                    "sent": "Does anyone actually know who coined that term?",
                    "label": 0
                },
                {
                    "sent": "It's very you guys know who coined that term.",
                    "label": 0
                },
                {
                    "sent": "Try and find out.",
                    "label": 0
                },
                {
                    "sent": "It's curious, but.",
                    "label": 0
                },
                {
                    "sent": "OK, so we'll talk mainly about.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Erected models but you should understand that for instance in HMM can be thought as both the directed and an undirected model member.",
                    "label": 1
                },
                {
                    "sent": "Before we've got a sequence of states evolving in time and we've got some observations here.",
                    "label": 0
                },
                {
                    "sent": "And so the way you want to think the natural way to parameterise this model with compatibility's is you would put for instance a marginal probability distribution at this node.",
                    "label": 0
                },
                {
                    "sent": "That sort of tells you how you start out the chain.",
                    "label": 0
                },
                {
                    "sent": "And then you want to move from X1 to X2.",
                    "label": 0
                },
                {
                    "sent": "So you need a transition that tells you how to go from X1 to X2.",
                    "label": 0
                },
                {
                    "sent": "So you have a conditional transition.",
                    "label": 0
                },
                {
                    "sent": "This is a conditional probability table that tells you how to move forward and so on recursively forward.",
                    "label": 0
                },
                {
                    "sent": "So this would be a special case of the kind of parent to child directed factorization.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me just mention one last thing that I don't believe Sam mentioned, but something that you should be familiar with because it's something that you will see in many papers.",
                    "label": 0
                },
                {
                    "sent": "Sort of a third kind of graph that you can use to represent graphical models, and these are called factor graphs.",
                    "label": 0
                },
                {
                    "sent": "Um, factor graphs are a bit funny because.",
                    "label": 0
                },
                {
                    "sent": "There's sort of a subset of the community.",
                    "label": 0
                },
                {
                    "sent": "I won't mention any names because I'm being filmed, but there are some people who are almost religious about factor graphs.",
                    "label": 0
                },
                {
                    "sent": "They sort of believe that the factor graph is the way to go, and you should never use anything but a factor graph.",
                    "label": 0
                },
                {
                    "sent": "I don't quite believe that.",
                    "label": 0
                },
                {
                    "sent": "I think they're useful for some things, but.",
                    "label": 0
                },
                {
                    "sent": "And other things that are kind of clunky, but let's go and try and understand them, but they are useful for certain things, so the way they work is essentially in addition to the circular nodes here that are representing random variables.",
                    "label": 0
                },
                {
                    "sent": "Those are things that we had before you now have a second kind of node.",
                    "label": 0
                },
                {
                    "sent": "Typically represented as square nodes that are actually explicitly representing the factors.",
                    "label": 1
                },
                {
                    "sent": "This is why it's called a factor graph.",
                    "label": 1
                },
                {
                    "sent": "These guys represent those functions.",
                    "label": 0
                },
                {
                    "sent": "Those compatibility functions that I was telling you the distribution broke into.",
                    "label": 0
                },
                {
                    "sent": "So you might have a model like this.",
                    "label": 0
                },
                {
                    "sent": "You would have X one X5X3X7.",
                    "label": 0
                },
                {
                    "sent": "These are all random variables.",
                    "label": 0
                },
                {
                    "sent": "And they're connected to this square node, and you sort of think there's a factor sitting there.",
                    "label": 0
                },
                {
                    "sent": "I call him Cy 1357, 'cause he's a factor that is.",
                    "label": 0
                },
                {
                    "sent": "Depends just on these variables in its neighborhood.",
                    "label": 0
                },
                {
                    "sent": "This is useful because you can just look at this graph and you can read right away that it factors into a product of three terms, one for this, one for this and one for this, and you can sort of read by looking at the neighborhoods what the terms depend on.",
                    "label": 0
                },
                {
                    "sent": "Sometimes this is an example where I think factor graphs are silly.",
                    "label": 0
                },
                {
                    "sent": "If you had one of these lattice or grid models, all you'd be doing is putting an extra node on every edge.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really add much, it just clutters the picture.",
                    "label": 0
                },
                {
                    "sent": "This is a case where I don't think they're useful, but this is a case where they actually are very useful that they allow you to make a distinction that an ordinary under undirected graph can't.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "Can anyone sort of read the different semantics?",
                    "label": 0
                },
                {
                    "sent": "In both cases I've got 3 random variables.",
                    "label": 0
                },
                {
                    "sent": "But the semantics of the distributions that these two models are telling you are slightly different.",
                    "label": 0
                },
                {
                    "sent": "Right, so the semantics here are telling you there's one joint factor that's a triplet factor over X1X2 and X3, so it's a function over three variables, Whereas the guy in the bottom is telling you there are actually three functions, but they're all pairwise function between X1X2X2X3 and then X 3X1.",
                    "label": 0
                },
                {
                    "sent": "So this in some sense is a special case of this model, right?",
                    "label": 0
                },
                {
                    "sent": "I could write this in this form if I wanted, but this this has finer grained information.",
                    "label": 0
                },
                {
                    "sent": "It's what it's actually telling you is that there's No 3 way interaction here.",
                    "label": 0
                },
                {
                    "sent": "Anne, this is very relevant.",
                    "label": 0
                },
                {
                    "sent": "For instance, in medical diagnosis, if you're running medical experiments, you might have multiple factors.",
                    "label": 0
                },
                {
                    "sent": "You might have something like age, smoking and diet, and you might be concerned.",
                    "label": 1
                },
                {
                    "sent": "Do I just have pairwise interactions between these factors?",
                    "label": 0
                },
                {
                    "sent": "Just just one interaction?",
                    "label": 0
                },
                {
                    "sent": "Being smoking and age 1 between age and diet?",
                    "label": 0
                },
                {
                    "sent": "Or do all three of them interact together simultaneously?",
                    "label": 0
                },
                {
                    "sent": "So statisticians, for instance, spend a lot of time trying to figure out how do I distinguish this kind of interaction set up with this pairwise interactions from something where you have a 3 way interaction?",
                    "label": 0
                },
                {
                    "sent": "OK, so any questions about sort of those three styles of models I talked a fair bit about undirected models first.",
                    "label": 0
                },
                {
                    "sent": "Talked about Markov properties in factorization, talked briefly about directed models and then this sort of 3rd hybrid style of factor graphs which sort of give you finer control of the actual factorization.",
                    "label": 0
                },
                {
                    "sent": "I will take full breath to presentation high, concrete, grave, Queen merge.",
                    "label": 0
                },
                {
                    "sent": "Those factors function into one vector, so you mean.",
                    "label": 0
                },
                {
                    "sent": "2 grand can we merge 3 pressure bouncing into one vector?",
                    "label": 0
                },
                {
                    "sent": "100%?",
                    "label": 0
                },
                {
                    "sent": "So are you asking about these three?",
                    "label": 0
                },
                {
                    "sent": "Yes, so yes so.",
                    "label": 0
                },
                {
                    "sent": "This in fact is a special case of this because as you are pointing out, you could sort of imagine merging all of these three.",
                    "label": 0
                },
                {
                    "sent": "You could take the product and think about that as a new super function.",
                    "label": 0
                },
                {
                    "sent": "That's a function of all three.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is a particular case of this model, and you could do that, but in some ways you would have lost information in doing that because you would have lost the fact that the interactions are really only in pairs.",
                    "label": 0
                },
                {
                    "sent": "There's no actual function, that's a function of all three.",
                    "label": 0
                },
                {
                    "sent": "There's a finer kind of decomposition that's going on.",
                    "label": 0
                },
                {
                    "sent": "So that's why factor graphs are useful because they really emphasize the factorization they explicitly tell you where the factors sit, whereas if you look at undirected graphs, it can be somewhat ambiguous.",
                    "label": 0
                },
                {
                    "sent": "Krishna.",
                    "label": 0
                },
                {
                    "sent": "So you said there is some problem that was somebody.",
                    "label": 0
                },
                {
                    "sent": "Unless you can represent with undirected graph and cannot be corrected graph and the other way around is true too.",
                    "label": 0
                },
                {
                    "sent": "So can and all those very only represented by factor graph.",
                    "label": 0
                },
                {
                    "sent": "Um, another question is.",
                    "label": 0
                },
                {
                    "sent": "How practical is it to make an mixcraft?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the first question was I sort of mentioned before that there's some some models that can be represented by directed graphs and not by undirected and others by undirected, not by directed.",
                    "label": 0
                },
                {
                    "sent": "And then the question was.",
                    "label": 0
                },
                {
                    "sent": "Can factor graphs represent everything?",
                    "label": 1
                },
                {
                    "sent": "Not strictly because.",
                    "label": 0
                },
                {
                    "sent": "It's somewhat technical point, but there's a very different semantics to having undirected edges versus directed edges.",
                    "label": 0
                },
                {
                    "sent": "Let me just actually give an example of something that you can represent with a directed graph, but not with an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "This is sort of a classical example that you'll see a lot if you read the literature.",
                    "label": 0
                },
                {
                    "sent": "So you can sort of imagine you have two random variables.",
                    "label": 0
                },
                {
                    "sent": "The random variables here are going to be coin tosses.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to flip a coin.",
                    "label": 0
                },
                {
                    "sent": "I get ahead or retail and I'm going to assume these coins are actually independent.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to flip one coin and Sam is going to flip a coin.",
                    "label": 0
                },
                {
                    "sent": "But then I'm going to have a device and this device is going to be a Bell, so I'm going to draw a graphical model with arrows.",
                    "label": 0
                },
                {
                    "sent": "So these are going to be the parents and the child.",
                    "label": 0
                },
                {
                    "sent": "And so the Bell here is going to ring.",
                    "label": 0
                },
                {
                    "sent": "You can think about this like a slot machine, right?",
                    "label": 0
                },
                {
                    "sent": "You're going to win some money if both coins come up heads.",
                    "label": 0
                },
                {
                    "sent": "Right, so 2 coins flipped their independent and if you get lucky they're both heads.",
                    "label": 0
                },
                {
                    "sent": "You're going to win a big pile of money.",
                    "label": 0
                },
                {
                    "sent": "What's interesting about this model is that the coins.",
                    "label": 0
                },
                {
                    "sent": "If you don't condition on anything, the coins are actually independent, right?",
                    "label": 0
                },
                {
                    "sent": "Because I'm flipping one Sam's flipping one.",
                    "label": 0
                },
                {
                    "sent": "What's interesting is that if you condition on something, let's suppose that you're watching your friend at this machine and all of a sudden the Bell rings.",
                    "label": 0
                },
                {
                    "sent": "Right, so I'm going to color color it into mean that you observe that the Bell rings.",
                    "label": 0
                },
                {
                    "sent": "All of a sudden these random variables are the coins independent anymore.",
                    "label": 0
                },
                {
                    "sent": "After you've seen the Bell Rang.",
                    "label": 0
                },
                {
                    "sent": "It's useful to think about this a bit.",
                    "label": 0
                },
                {
                    "sent": "The coins aren't going to be independent anymore.",
                    "label": 0
                },
                {
                    "sent": "So this is a kind of phenomenon where you have random variables that are independent marginally without condition.",
                    "label": 0
                },
                {
                    "sent": "Then you observe something and they become independent.",
                    "label": 0
                },
                {
                    "sent": "The first time you see this in probability theory, it seems a bit weird.",
                    "label": 0
                },
                {
                    "sent": "Undergraduate students often get confused with this, but this is something that that under directed graphical models capture very naturally, but undirected ones do not.",
                    "label": 0
                },
                {
                    "sent": "There's other examples to go the other way, but I won't get into them for the interests of time.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I've forgotten your second question, I.",
                    "label": 0
                },
                {
                    "sent": "Yes, the second question is how practical is it to make mixed model?",
                    "label": 0
                },
                {
                    "sent": "So mixed models do exist.",
                    "label": 0
                },
                {
                    "sent": "They are often called chain graphs, and in some models that certainly practical in some models it would be the most natural thing to do.",
                    "label": 0
                },
                {
                    "sent": "I haven't gone into details, but there's some setups where it's very natural to use a directed factorization and it's kind of artificial to use an undirected one, and other setups where it's very natural to use the undirected one, so people sometimes do have sort of mixed settings and they use graphs that have a combination of directed edges in undirected edges they can get a bit tricky though, but it certainly is done.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So any other questions about sort of different representations etc.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me just state one last thing.",
                    "label": 0
                },
                {
                    "sent": "This is actually a very important result, but we won't go into detail what you just want to take away is sort of the practical consequences of this result.",
                    "label": 0
                },
                {
                    "sent": "Remember, I introduced undirected graphs by saying that you can use the graph to impose constraints on the distribution in two different ways.",
                    "label": 0
                },
                {
                    "sent": "You can either talk about these Markov properties you can talk about, for instance in a chain you can talk about past, present, and future more general graphs you can talk about.",
                    "label": 0
                },
                {
                    "sent": "Markov properties, things being separated by vertex cut sets.",
                    "label": 0
                },
                {
                    "sent": "Or you can talk about factorization properties.",
                    "label": 0
                },
                {
                    "sent": "So these things at the surface at least seem like very different kinds of constraints.",
                    "label": 0
                },
                {
                    "sent": "But what sort of fundamental theorem this area due to Hammersley Clifford originally in the 70s is that under suitable conditions these are actually the same restriction.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter if you use your graph to impose the Markov properties, or you use it to impose the factorization properties.",
                    "label": 1
                },
                {
                    "sent": "You sort of get the same class of models depending.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter which way you go.",
                    "label": 0
                },
                {
                    "sent": "Is a very elegant result mathematically, but practically speaking it's also very important because it means that you as a modeler you can choose whether you want to think about things in terms of Markov properties.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's very natural to think about Markov properties because you have a very natural notion of when different variables become conditionally independent, and so whenever you have conditional independence that things become independent when you observe something else.",
                    "label": 0
                },
                {
                    "sent": "You're very naturally lead into Markov properties and cut sets.",
                    "label": 0
                },
                {
                    "sent": "And so that would be one way that you could go about actually getting the graph structure is via conditional independence and Markov properties.",
                    "label": 0
                },
                {
                    "sent": "Equally useful is to think directly in terms of factorization.",
                    "label": 0
                },
                {
                    "sent": "In many ways sort of in a physical sense, this is the most natural.",
                    "label": 0
                },
                {
                    "sent": "You just think about, for instance nodes in a network and you think about what neighbors are being talked to, and these functions are telling you exactly the neighborhood structure it's telling you who talks to who, who depends sort of locally on who.",
                    "label": 0
                },
                {
                    "sent": "So both perspectives were useful and this results nice because it says essentially you can use both interchangeably.",
                    "label": 0
                },
                {
                    "sent": "What we're going to see in this in the next wireless is actually from a computational perspective.",
                    "label": 0
                },
                {
                    "sent": "It's the factorization that's particularly useful, and this is going to make connections again to things that Sam mentioned having to do with the distributive law having to do with moving sums and products you can already see there's a product here and soon we're going to be taking some nations.",
                    "label": 0
                },
                {
                    "sent": "We're going to get sums and products, and that's going to be important for computational purposes.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me move on to exact message passing on trees.",
                    "label": 1
                },
                {
                    "sent": "Again, this is slightly recapping what Sam did, but I believe I'm doing it from a somewhat different perspective, so I hope you'll bear with me.",
                    "label": 0
                },
                {
                    "sent": "I'm going to begin not by talking about trees.",
                    "label": 0
                },
                {
                    "sent": "I'm going to begin by talking about completely general graphs.",
                    "label": 1
                },
                {
                    "sent": "And I'm going to talk about an algorithm that's known as the elimination algorithm.",
                    "label": 0
                },
                {
                    "sent": "You'll see why it's for obvious reasons.",
                    "label": 0
                },
                {
                    "sent": "To be clear, this is not a good algorithm.",
                    "label": 0
                },
                {
                    "sent": "Do not go and use this algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is a bad algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is a pedagogical algorithm.",
                    "label": 1
                },
                {
                    "sent": "It's useful for illustrating the concepts an for seeing how graph structure is actually linked to the complexity of performing inference, but it's not something that you will implement in practice, but what it does suggest is good algorithms.",
                    "label": 0
                },
                {
                    "sent": "Things that are actually efficient, and this is where we're going to get into message passing algorithms on trees, and then I'll talk a bit more.",
                    "label": 0
                },
                {
                    "sent": "Generally about the notion of junction trees.",
                    "label": 1
                },
                {
                    "sent": "So what we're going to see in this section is sort of this nice connection between the graph structure on one hand and the intrinsic difficulty.",
                    "label": 0
                },
                {
                    "sent": "How hard is it to solve these kinds of summation or maximization problems that you'd like to solve in application?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "OK, so from a computational point of view, let's again focus just on an undirected model, because as I said, you'd always convert a directed model by moralizing to an undirected 1 first.",
                    "label": 0
                },
                {
                    "sent": "An we can imagine that you've sort of got a factorization over cliques of the graph.",
                    "label": 0
                },
                {
                    "sent": "You've got these local functions again.",
                    "label": 0
                },
                {
                    "sent": "And maybe just to make things interesting.",
                    "label": 0
                },
                {
                    "sent": "Maybe like in the hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "I also have noisy observations at every node, so these axes would be sort of hidden quantities and maybe someone has actually allowed you to observe these wise.",
                    "label": 0
                },
                {
                    "sent": "So these would be noisy observations.",
                    "label": 0
                },
                {
                    "sent": "Maybe you're looking at an image and you're taking it from a telescope, you don't see the actual image, you see a sort of noisy version of the image, and that would be the wise.",
                    "label": 0
                },
                {
                    "sent": "This is what you have in your hand.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting here?",
                    "label": 0
                },
                {
                    "sent": "What are things that are of interest to compute?",
                    "label": 1
                },
                {
                    "sent": "One thing I haven't spoken about yet is this Z that's sitting there.",
                    "label": 0
                },
                {
                    "sent": "It's called, it's just the normalization constant.",
                    "label": 1
                },
                {
                    "sent": "The only reason it's sitting there is because this is a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you sum or you integrate over all the variables, you should get one.",
                    "label": 0
                },
                {
                    "sent": "So you have to divide by something to be sure that you get one.",
                    "label": 0
                },
                {
                    "sent": "So it looks kind of unimportant, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, who cares?",
                    "label": 0
                },
                {
                    "sent": "It's just a normalization.",
                    "label": 0
                },
                {
                    "sent": "Certainly that's what I thought when I first saw it.",
                    "label": 0
                },
                {
                    "sent": "I mean, who cares?",
                    "label": 0
                },
                {
                    "sent": "But unfortunately it turns out to be very important.",
                    "label": 1
                },
                {
                    "sent": "It turns out to be extremely important when you're trying to learn models from data.",
                    "label": 0
                },
                {
                    "sent": "This turns out to be essentially the log likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "Other things that you'd like to compute.",
                    "label": 0
                },
                {
                    "sent": "These are things that Sam mentioned.",
                    "label": 0
                },
                {
                    "sent": "Often you have a very big graph.",
                    "label": 0
                },
                {
                    "sent": "For instance, I might have an image and it could be very large, but I might be interested just in what's going on in a particular region of the image.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's some object there, maybe I'm trying to detect something, so I'd like to sort of focus in on that part of the image, and I'd like to compute some kind of summary statistic about a certain part of the model.",
                    "label": 0
                },
                {
                    "sent": "So one kind of summary statistic would be a marginal distribution where you're essentially integrating or summing out the rest of the graph.",
                    "label": 0
                },
                {
                    "sent": "So you're just concentrating focusing on one part of the graph, and this is the problem that Sam spoke about yesterday for chains and trees.",
                    "label": 0
                },
                {
                    "sent": "Another problem that you might be interested in is.",
                    "label": 0
                },
                {
                    "sent": "For instance, in the error correcting code coding problem, your friends talking to you over the wireless phone, and you have a bad service provider and you're getting a lot of static, so you receive a garbled message from your friend.",
                    "label": 0
                },
                {
                    "sent": "You don't know exactly what they're saying, but you can sort of think what you'd like to do is search over the possible set of messages that your friend might have sent you, and you'd like to find the one that's most likely the one that is has the highest probability.",
                    "label": 0
                },
                {
                    "sent": "So in terms of a graphical model, if you modeled this setup like this, this would be a mode or most probable configuration of the graphical model.",
                    "label": 1
                },
                {
                    "sent": "So what's relevant here?",
                    "label": 0
                },
                {
                    "sent": "At some level, these seem like simple things.",
                    "label": 0
                },
                {
                    "sent": "To get this, all you do is compute a sum or an integral.",
                    "label": 0
                },
                {
                    "sent": "This is just a summation.",
                    "label": 0
                },
                {
                    "sent": "This is a maximization, but again, you want to remember that the curse of dimensionality is going to come to bite us.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We're not interested in models with just two or three variables.",
                    "label": 0
                },
                {
                    "sent": "We're interested models with hundreds of variables, and so just going back to the example we had before.",
                    "label": 0
                },
                {
                    "sent": "If you just think about binary models, right?",
                    "label": 0
                },
                {
                    "sent": "This is simplest example.",
                    "label": 0
                },
                {
                    "sent": "Very toy.",
                    "label": 0
                },
                {
                    "sent": "You're getting complexity.",
                    "label": 0
                },
                {
                    "sent": "This going to scale essentially like 2 to the N, where N is the number of nodes in your graph.",
                    "label": 0
                },
                {
                    "sent": "So that's very bad you're going to any brute force method is going to show quite quickly, essentially by the time N = 20.",
                    "label": 0
                },
                {
                    "sent": "You're not going to be able to do anything.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to see is in a minute that some kinds of graphs, more general graphs and trees can actually be solved quite efficiently.",
                    "label": 0
                },
                {
                    "sent": "And then moving on later, we're going to see that for more general graphs, you can start thinking about approximate methods to solve problems like computing a huge summation like this.",
                    "label": 0
                },
                {
                    "sent": "And we want approximate methods that are fast, so we can actually apply them in practice.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's let's move on to the elimination algorithm.",
                    "label": 1
                },
                {
                    "sent": "This is a very simple algorithm and.",
                    "label": 0
                },
                {
                    "sent": "Essentially it's just as Sam set exploiting one idea.",
                    "label": 0
                },
                {
                    "sent": "It's exploding the fact that the sum and product operations are distributive, which just means that you can move sums and products around.",
                    "label": 1
                },
                {
                    "sent": "So let's imagine that we have this graph.",
                    "label": 0
                },
                {
                    "sent": "Here I've just got six variables, so it's a toy problem.",
                    "label": 0
                },
                {
                    "sent": "And what this graph is telling me is that the maximal cliques are 1213343524, and then there's a three clique 246.",
                    "label": 0
                },
                {
                    "sent": "Right, So what I've learned is that this model says that this distribution should factor into a product of local terms like this.",
                    "label": 0
                },
                {
                    "sent": "These are one term for every maximal clique in this graph.",
                    "label": 0
                },
                {
                    "sent": "And what we're thinking about here is, let's imagine you want to compute a marginal distribution.",
                    "label": 1
                },
                {
                    "sent": "Let's say I'm sitting here at this node.",
                    "label": 1
                },
                {
                    "sent": "This might be a sensor network.",
                    "label": 0
                },
                {
                    "sent": "You might have a bunch of sensors.",
                    "label": 0
                },
                {
                    "sent": "These could all be sensors that are measuring things in the environment.",
                    "label": 0
                },
                {
                    "sent": "I might be interested in.",
                    "label": 0
                },
                {
                    "sent": "For instance, I'm giving a midterm tomorrow and I have a pile of photocopied midterms on my desk.",
                    "label": 0
                },
                {
                    "sent": "And some of my students are.",
                    "label": 0
                },
                {
                    "sent": "Let's say more dishonest than studious, and they'd like to come in and steal one of the midterms to make photo copies of so I could, for instance, rig my office with sensor networks at various junctures, and maybe the midterms are sitting right there, so I'd be very interested.",
                    "label": 0
                },
                {
                    "sent": "For instance, if a student managed actually managed to get to the midterms, I'd like an alarm to go off so you can imagine I'd like to compute something like the probability of student appearing at this place.",
                    "label": 0
                },
                {
                    "sent": "That could be one interpretation of this marginal.",
                    "label": 0
                },
                {
                    "sent": "So what's going on here is you have a big summits over many random variables, so it looks kind of unpleasant at first, but you can see with a bit of algebra you can just start pushing the sum inside an, for instance, 6 the sum over X6.",
                    "label": 0
                },
                {
                    "sent": "I can push it all the way.",
                    "label": 0
                },
                {
                    "sent": "There's only one term.",
                    "label": 0
                },
                {
                    "sent": "This last term that depends on 6.",
                    "label": 0
                },
                {
                    "sent": "Similarly, the sums over X5.",
                    "label": 0
                },
                {
                    "sent": "There's just these terms, so I can keep sort of pushing the summation further and further inside the product.",
                    "label": 0
                },
                {
                    "sent": "So this is the distributive property and this is what's going to allow you to save substantial computation.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chen so there's useful way to thinking to think about this.",
                    "label": 0
                },
                {
                    "sent": "Actually, in terms of graphical operations, right?",
                    "label": 0
                },
                {
                    "sent": "We're talking about summing over variables, but it's useful to think about it, as after you've summed over a variable what you're allowed to do is you're allowed to sort of cut that variable out of the graph.",
                    "label": 0
                },
                {
                    "sent": "I can eliminate it from the graph.",
                    "label": 1
                },
                {
                    "sent": "That's where the name elimination comes from.",
                    "label": 0
                },
                {
                    "sent": "An I can strip these edges off, so once I've sort of done the work of summing this guy, then I get I get to get.",
                    "label": 0
                },
                {
                    "sent": "I'm allowed to get rid of this part of the graph, so I've.",
                    "label": 0
                },
                {
                    "sent": "The graph shrinks a bit.",
                    "label": 0
                },
                {
                    "sent": "It's getting reduced.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One step of elimination.",
                    "label": 0
                },
                {
                    "sent": "And so I eliminate and if you sort of look analytically what happens, I get rid of this node.",
                    "label": 0
                },
                {
                    "sent": "I get rid of these edges and if you look carefully, you'll see that there's a kind of modification to the compatibility or potential function on this edge.",
                    "label": 0
                },
                {
                    "sent": "So it is a kind of gets tweaked a little bit by the operation, but that's OK, it's still on the same graph.",
                    "label": 0
                },
                {
                    "sent": "It's a slightly different, so you can use a twiddle for it.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I can recurse this operation.",
                    "label": 0
                },
                {
                    "sent": "I could for instance some 5.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And strip 5 and I could then some four and strip out four.",
                    "label": 0
                },
                {
                    "sent": "And now I'm down just.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triangle graph and I could sum that out and at the end of the day I'd have my answer.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So you can do a little calculation here to see exactly how much you saved in terms of exploding this distributive law and doing the elimination in this way.",
                    "label": 0
                },
                {
                    "sent": "Does anyone have?",
                    "label": 0
                },
                {
                    "sent": "Was there anything special about the order in which I was illuminating nodes here?",
                    "label": 0
                },
                {
                    "sent": "Anyone have any intuition about that?",
                    "label": 0
                },
                {
                    "sent": "So if you remember, I eliminated first 6, then five, then four, then three, then two.",
                    "label": 0
                },
                {
                    "sent": "Was that important?",
                    "label": 0
                },
                {
                    "sent": "Could I have illuminated three to start with?",
                    "label": 0
                },
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "Sorry, maybe put the mic on.",
                    "label": 0
                },
                {
                    "sent": "Add the children first.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Well, why couldn't I just sum out three right away?",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "I would say you cannot.",
                    "label": 0
                },
                {
                    "sent": "As you would catch the crime, I would do what to the graph, cut it.",
                    "label": 0
                },
                {
                    "sent": "While you're worried that five would split off here.",
                    "label": 0
                },
                {
                    "sent": "It would if I would actually get recouple diff.",
                    "label": 0
                },
                {
                    "sent": "It's useful to actually go through this.",
                    "label": 0
                },
                {
                    "sent": "Go through this exercise, do it in a different order and see what happens to the graph.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What sort of key here you want to be very clear about this is when you some you end up modifying terms.",
                    "label": 0
                },
                {
                    "sent": "This term changed a bit because of the effect of summing this out.",
                    "label": 0
                },
                {
                    "sent": "Right and it changed a bit, but what's important is that there already was a potential term sitting there.",
                    "label": 0
                },
                {
                    "sent": "Right, it got tweaked a little.",
                    "label": 0
                },
                {
                    "sent": "It changed, but I didn't add any new potential term.",
                    "label": 0
                },
                {
                    "sent": "Nothing new was added, it just changed a bit.",
                    "label": 0
                },
                {
                    "sent": "But it's useful to think about what if you summed this out?",
                    "label": 0
                },
                {
                    "sent": "Think about doing it here.",
                    "label": 0
                },
                {
                    "sent": "What effect would that have on the coupling of the graph?",
                    "label": 0
                },
                {
                    "sent": "I won't go into details now, but that's that's useful to think about it.",
                    "label": 0
                },
                {
                    "sent": "The break the order in which I did this matters a lot.",
                    "label": 0
                },
                {
                    "sent": "I was nice to you and I chose a good order.",
                    "label": 0
                },
                {
                    "sent": "Roughly speaking, that you can sort of see I was essentially moving outside to in.",
                    "label": 0
                },
                {
                    "sent": "I was starting at the outside 6.",
                    "label": 0
                },
                {
                    "sent": "Then I got rid of five and I sort of collapse the graph inward.",
                    "label": 0
                },
                {
                    "sent": "But you can do this elimination in any ordering you want, but not order.",
                    "label": 0
                },
                {
                    "sent": "Not all orderings are equal.",
                    "label": 0
                },
                {
                    "sent": "Some orderings are much better than others, so this is an optimal ordering.",
                    "label": 0
                },
                {
                    "sent": "Some orderings can be very bad, so it's useful to play with this example just a little bit on your own to understand why the order in which you do this might matter.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so the sort of summary here is the basic step is very simple.",
                    "label": 0
                },
                {
                    "sent": "We're distributing some in product to do partial summations in some order, so you're fixing an elimination ordering and you're using distributive law as much as you can with that order.",
                    "label": 1
                },
                {
                    "sent": "What sort of key graphically is that?",
                    "label": 1
                },
                {
                    "sent": "The minute that you sum over a particular variable?",
                    "label": 1
                },
                {
                    "sent": "You get to eliminate that node and its edges from the graph.",
                    "label": 0
                },
                {
                    "sent": "That's a good thing that makes you happy.",
                    "label": 0
                },
                {
                    "sent": "The graph is shrinking.",
                    "label": 0
                },
                {
                    "sent": "But the bad thing that you have to be careful about is you have to join all of its neighbors with extra edges as you join these extra edges.",
                    "label": 0
                },
                {
                    "sent": "For instance, one example of where this happened was right here.",
                    "label": 0
                },
                {
                    "sent": "I didn't have an edge here initially.",
                    "label": 0
                },
                {
                    "sent": "But once I sum over this X4 at this point there's going to be an edge that's added here.",
                    "label": 0
                },
                {
                    "sent": "You can see that edge has to be added because you get a new coupling term.",
                    "label": 0
                },
                {
                    "sent": "And I'm doing that.",
                    "label": 1
                },
                {
                    "sent": "It's going to start making your graph more and more connected.",
                    "label": 0
                },
                {
                    "sent": "It's going to actually increase the size of the cliques.",
                    "label": 0
                },
                {
                    "sent": "Here it's making actually a three clique there that didn't exist before.",
                    "label": 0
                },
                {
                    "sent": "So what it turns out is if you do a bit of algebra to figure out how much did you pay to do all of this at the end of the day, how much you pay depends very much on how big the cliques got in this new graph that gets created as you sort of shrink the graph down.",
                    "label": 0
                },
                {
                    "sent": "What sort of matters is how many edges did you have to add as you were eliminating?",
                    "label": 0
                },
                {
                    "sent": "So here I ended up having to actually create a new three clique.",
                    "label": 0
                },
                {
                    "sent": "I already had a three click here, but the biggest click that I would have gotten in this graph is actually a three clique.",
                    "label": 0
                },
                {
                    "sent": "There's nothing bigger than that.",
                    "label": 0
                },
                {
                    "sent": "There's no four cliques here.",
                    "label": 0
                },
                {
                    "sent": "If you choose a different elimination ordering, you'll see that you will get a four clique.",
                    "label": 0
                },
                {
                    "sent": "So the key thing is that elimination ordering matters a lot.",
                    "label": 0
                },
                {
                    "sent": "There are good orderings and bad ones.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the figuring out which is the optimal ordering, that's not an easy problem.",
                    "label": 1
                },
                {
                    "sent": "It's actually an NP hard problem in general, but practically speaking there are a lot of heuristics to find reasonable orderings.",
                    "label": 0
                },
                {
                    "sent": "You might not find the best one, but you can certainly find reasonable ones.",
                    "label": 0
                },
                {
                    "sent": "So that's that's the elimination algorithm.",
                    "label": 0
                },
                {
                    "sent": "The intuition you want to take away from this is that there's really a nice correspondence between analytically on your sort of manipulating the factors in this distribution, you're performing summations and that sort of shrinking things down.",
                    "label": 0
                },
                {
                    "sent": "It's making new factors and shrinking them, and there's a very nice graph theoretic correspondence that you're watching.",
                    "label": 0
                },
                {
                    "sent": "This residual graph sort of shrink and shrink down, for instance to the target point.",
                    "label": 0
                },
                {
                    "sent": "Here I was interested in X1.",
                    "label": 0
                },
                {
                    "sent": "So there's a nice correspondence between the factorization in the summation and the graph theoretic properties here.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to see is that some kinds of graphs are actually nice graphs in that they have good elimination orderings, and some graphs are not nice graphs.",
                    "label": 0
                },
                {
                    "sent": "They don't have good elimination orderings, and so essentially the elimination algorithm is.",
                    "label": 0
                },
                {
                    "sent": "It's useful because it gives you an algorithmic way to understand why'd's graph structure, affect how complex it is to, for instance, some and perform marginalization.",
                    "label": 0
                },
                {
                    "sent": "It sort of tells you that the way in which the graph is connected controls how this elimination behaves.",
                    "label": 0
                },
                {
                    "sent": "And that determines in the end how much computational complexity you pay.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So any questions on that before I move on?",
                    "label": 0
                },
                {
                    "sent": "I want to move on with that kind of intuition.",
                    "label": 0
                },
                {
                    "sent": "I'd like to move on to talking about trees which are sort of the simplest case of graphs that have a very nice elimination ordering.",
                    "label": 0
                },
                {
                    "sent": "Yeah, kind of assumption.",
                    "label": 0
                },
                {
                    "sent": "Did you make on the original quick size?",
                    "label": 0
                },
                {
                    "sent": "I mean how many clicks you have or you didn't say anything about it.",
                    "label": 0
                },
                {
                    "sent": "Right, so here I was.",
                    "label": 0
                },
                {
                    "sent": "Just giving you one example an I had some two clicks into, three clique, but so in general you'd have to start with whatever model you were given whatever you used.",
                    "label": 0
                },
                {
                    "sent": "Sorry number, please write if you gave me a graph that to start with had let's say clique sizes of Alpha N or something, it wouldn't be actually a very useful model because you noticed or things you'd have to pay complexity two to the Alpha N for binary variables.",
                    "label": 0
                },
                {
                    "sent": "We could generate bigger clicks, that's why, yes, so that's the key point that elimination can only make things worse for you, and the issue is how much worse does it make it for you?",
                    "label": 0
                },
                {
                    "sent": "This example would actually, I mean, it made a new three clique.",
                    "label": 0
                },
                {
                    "sent": "It added this edge, but I already had a three clique, so it didn't really make things any worse at all.",
                    "label": 0
                },
                {
                    "sent": "For me, things were sort of, there was no additional sort of jump in complexity.",
                    "label": 0
                },
                {
                    "sent": "What we'll see is that trees are the simplest case of no jump in complexity, but other graphs there's a huge jump in complexity between this graph and the residual graph.",
                    "label": 0
                },
                {
                    "sent": "What you get after illuminating.",
                    "label": 0
                },
                {
                    "sent": "So any other questions about elimination?",
                    "label": 0
                },
                {
                    "sent": "Again, I encourage you just display with this example.",
                    "label": 0
                },
                {
                    "sent": "It's a simple example, but it actually has all the basic ingredients that you need just to get intuition of how this works.",
                    "label": 0
                },
                {
                    "sent": "This is not what you'd implement, but it's useful just to play with because it sort of gives you a feeling for what's going on.",
                    "label": 0
                },
                {
                    "sent": "Why why graph structure actually matters here.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's move on to the sum product algorithm.",
                    "label": 0
                },
                {
                    "sent": "Let me first talk about it on trees and then I'm going to talk about a more general class of graphs that are called junction trees.",
                    "label": 0
                },
                {
                    "sent": "And so this first part just talking about ordinary trees.",
                    "label": 0
                },
                {
                    "sent": "This is recapping what Sam did yesterday, but again, I'm going to follow the elimination perspective.",
                    "label": 0
                },
                {
                    "sent": "So it's from a somewhat different point of view.",
                    "label": 0
                },
                {
                    "sent": "So again, remember the tree is just simply an undirected graph here that has no cycles.",
                    "label": 1
                },
                {
                    "sent": "And you can always choose a particular node in a tree to be a root.",
                    "label": 0
                },
                {
                    "sent": "You think about this being the root, and then you sort of move outwards and you hit the nodes on the edge, and these are called leaves for the obvious reason.",
                    "label": 0
                },
                {
                    "sent": "So what you want to think about this is again, a point that Sam made.",
                    "label": 0
                },
                {
                    "sent": "Yesterday's elimination is fine, but remember elimination.",
                    "label": 0
                },
                {
                    "sent": "I sort of presuppose that I was sitting at node one and I cared about node one, and that's all I cared about in this case.",
                    "label": 0
                },
                {
                    "sent": "But it could be the case that I care bout node one and node 7.",
                    "label": 0
                },
                {
                    "sent": "Or maybe I care bout all nodes simultaneously.",
                    "label": 1
                },
                {
                    "sent": "That's quite possible.",
                    "label": 0
                },
                {
                    "sent": "If I gave you a noisy image from a telescope, you might care about.",
                    "label": 0
                },
                {
                    "sent": "For instance, removing the noise.",
                    "label": 0
                },
                {
                    "sent": "It's called denoising.",
                    "label": 0
                },
                {
                    "sent": "You don't care about just one node, you care about all the pixels you'd like to actually do things simultaneously over all the nodes at once.",
                    "label": 0
                },
                {
                    "sent": "So if you sort of think about this a bit, if you think about running elimination, you see right away that you're being very stupid.",
                    "label": 0
                },
                {
                    "sent": "For violating the basic principle of algorithms, you're not recycling your computations.",
                    "label": 0
                },
                {
                    "sent": "You're doing the same computations again and again and again.",
                    "label": 0
                },
                {
                    "sent": "You only need to do them once.",
                    "label": 0
                },
                {
                    "sent": "So really the sum product algorithm is just a clever way to run elimination simultaneously for every node of a tree.",
                    "label": 0
                },
                {
                    "sent": "That's all it's doing.",
                    "label": 0
                },
                {
                    "sent": "It's cleverly running the elimination for every node, but it's doing it in a way that you don't waste computation that you only do the computation the minimal number of times needed.",
                    "label": 0
                },
                {
                    "sent": "And you sort of want to understand.",
                    "label": 0
                },
                {
                    "sent": "I guess my brain is of limited capacity, so I always look for useful things like this.",
                    "label": 0
                },
                {
                    "sent": "There are many algorithms in the literature that you might read about.",
                    "label": 0
                },
                {
                    "sent": "I know that people here from different backgrounds you have different applications in mind, so some of you might have heard of things like the Alpha beta algorithm, the forward backward algorithm.",
                    "label": 0
                },
                {
                    "sent": "These are things that are used in speech processing, bioinformatics.",
                    "label": 1
                },
                {
                    "sent": "Other people might have heard about common filtering peeling algorithms.",
                    "label": 1
                },
                {
                    "sent": "If you're a physicist, you would have heard about the transfer matrix method.",
                    "label": 0
                },
                {
                    "sent": "Essentially, these are all special cases of this sum product algorithm, so it sort of says if you make the effort to understand what this some product or belief propagation algorithm is doing, then sort of for free.",
                    "label": 0
                },
                {
                    "sent": "You understand what all of these guys are doing because they're all this particular cases for different kinds of models.",
                    "label": 0
                },
                {
                    "sent": "This is for an HMM, typically discrete.",
                    "label": 1
                },
                {
                    "sent": "This is typically for a Gauss Markov process on a chain or a tree.",
                    "label": 0
                },
                {
                    "sent": "All of these cases, these algorithms, again, are particular cases of this kind of formalism, so there's a useful compression that goes on here.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the connection to elimination?",
                    "label": 0
                },
                {
                    "sent": "What you want to think about is let's first suppose that I was just fixated on this route.",
                    "label": 0
                },
                {
                    "sent": "Let's call this guy the root.",
                    "label": 0
                },
                {
                    "sent": "In trees are sort of a very natural elimination ordering.",
                    "label": 0
                },
                {
                    "sent": "It's sort of obvious when you look at them and it's called leaf stripping because you sort of think I'm gonna start the leaves and I'm going to sum the leaves off and that allows me to strip this edge strip this edge strip this strip strip so it's sort of think that you're starting at the top of the tree and you're ripping the leaves, and then you rip the branches off and you recurse all the way down to the root.",
                    "label": 0
                },
                {
                    "sent": "So it's basically just dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "As Sam set, except it's actually now dynamic programming on a tree as opposed to dynamic program.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On a chain.",
                    "label": 0
                },
                {
                    "sent": "Flex, let's understand how some product would work on a tree.",
                    "label": 1
                },
                {
                    "sent": "Let's think about.",
                    "label": 0
                },
                {
                    "sent": "Let's write our distribution over the tree.",
                    "label": 0
                },
                {
                    "sent": "We've got pairwise terms for every edge, and there's no specific reason for doing this.",
                    "label": 1
                },
                {
                    "sent": "This is just convention, but I'm also going to allow you to have a single function at every node.",
                    "label": 0
                },
                {
                    "sent": "I'll allow you some function of the random variable at that node that might represent an observation.",
                    "label": 0
                },
                {
                    "sent": "Just to be clear, I'm not going to put observations.",
                    "label": 0
                },
                {
                    "sent": "You know, before I had X given Y, I'm going to drop that out now, because why is fixed?",
                    "label": 0
                },
                {
                    "sent": "That's something you observe an.",
                    "label": 0
                },
                {
                    "sent": "Just to keep the notation clean, we can just think about it in this form.",
                    "label": 1
                },
                {
                    "sent": "So the simplest example of a tree is just two nodes, like this S&T.",
                    "label": 0
                },
                {
                    "sent": "And So what?",
                    "label": 0
                },
                {
                    "sent": "You want to think about is if you did elimination, you'd sum over this node T an if you sort of looked at what would happen, you're summing over X of T. You sort of end up with a certain output of a computation that X of T did, and what you want to think about that people refer to as a message.",
                    "label": 0
                },
                {
                    "sent": "It's something that T has to send to S. Right, so you want to sort of thing T. He's sitting here doing this local computation.",
                    "label": 0
                },
                {
                    "sent": "And then he's going to finish his computation.",
                    "label": 0
                },
                {
                    "sent": "He's going to relay the output.",
                    "label": 0
                },
                {
                    "sent": "Along the edge and pass it to S. That's the message that's passed.",
                    "label": 0
                },
                {
                    "sent": "And so the message is, is this a vector or in general it's going to be a function that would be passed along the edge?",
                    "label": 0
                },
                {
                    "sent": "And so you can see this guy can compute his marginal by taking his local function and then multiplying it by the message.",
                    "label": 0
                },
                {
                    "sent": "So that's where the messages come from.",
                    "label": 0
                },
                {
                    "sent": "And now you want to just think about Recursing on this.",
                    "label": 0
                },
                {
                    "sent": "It's quite simple.",
                    "label": 0
                },
                {
                    "sent": "Again, we're doing the kind of leaf stripping, elimination, ordering, and so you want to think.",
                    "label": 0
                },
                {
                    "sent": "Well before I got to this point, I must have eliminated all these children that are sitting here of this node T. Right, so these guys were leaves in this graph, so I must have illuminated them first according to my ordering, and when I did that, I must have passed messages along these edges from WTV to T and utility.",
                    "label": 1
                },
                {
                    "sent": "And So what happens is you're going to whole product of messages from the children.",
                    "label": 0
                },
                {
                    "sent": "And this guy, what he's going to take the product.",
                    "label": 0
                },
                {
                    "sent": "And then he's again going to some out the effect of X of T. So this is my first step in blue.",
                    "label": 1
                },
                {
                    "sent": "The read here is just accounting for the effect of the children.",
                    "label": 0
                },
                {
                    "sent": "That's sort of recursing one step.",
                    "label": 0
                },
                {
                    "sent": "And that's basically it.",
                    "label": 0
                },
                {
                    "sent": "You've just done a little recursion and what you get at the end of the day is that the message update equation should be of this form that what gets passed from node T to node S, it's going to be a function of S. Sort of.",
                    "label": 0
                },
                {
                    "sent": "This guy is summarizing to ask what he needs to know about this part of the graph, and the way it works is you take this product over the incoming messages so you have a product here.",
                    "label": 0
                },
                {
                    "sent": "And then X of T has to do his work.",
                    "label": 0
                },
                {
                    "sent": "He has to sum things out.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "This is why it's called sum product algorithm, also known as belief propagation in some communities.",
                    "label": 0
                },
                {
                    "sent": "Right, so in general, you sort of think about this going on node S has got many neighbors.",
                    "label": 0
                },
                {
                    "sent": "It's going to get messages from its neighbor T. It's got some other neighbor B and some other neighbor a, so it's going to actually combine its local evidence, and it's going to combine messages from each one of these subtrees here, here and here.",
                    "label": 0
                },
                {
                    "sent": "And at the end of the day, these messages are going to sort of summarize the necessary information that needs to compute its marginal distributions.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So any questions about that sort of derivation?",
                    "label": 0
                },
                {
                    "sent": "What you want to understand is that you sort of moving just in a hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Do one edge first.",
                    "label": 0
                },
                {
                    "sent": "Then you think of Recursing one edge plus the children that were coming into that edge before.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then recursing one more.",
                    "label": 0
                },
                {
                    "sent": "You sort of think about node S actually has many children itself, and they all are passing messages in.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the sort of upshot here is that this is a completely parallel algorithm at the end of the day, there's not going to be any root.",
                    "label": 0
                },
                {
                    "sent": "All of the nodes are just sitting there locali, they're just doing their local computations and their passing messages along edges.",
                    "label": 0
                },
                {
                    "sent": "And what's nice about it is that you can show that will always converge after a finite number of steps on a tree, this is.",
                    "label": 1
                },
                {
                    "sent": "And it is correct.",
                    "label": 0
                },
                {
                    "sent": "It will yield the exact things, so it's very important that it's a parallel algorithm.",
                    "label": 0
                },
                {
                    "sent": "Everyone is just doing the dumb local thing, and practically that parallelism is key.",
                    "label": 0
                },
                {
                    "sent": "That's why this algorithm is in your wireless cards right now.",
                    "label": 0
                },
                {
                    "sent": "Because because you can parallelize it, you can implement it very efficiently in a chip.",
                    "label": 0
                },
                {
                    "sent": "So a lot of people spend lots of time implementing this algorithm in hardware in Silicon or field programmable gate arrays.",
                    "label": 0
                },
                {
                    "sent": "And the only reason they can do that is because it's a local dumb algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's just doing local things, but what's very nice is that on trees, these local things are actually optimal.",
                    "label": 0
                },
                {
                    "sent": "It's the right thing to do.",
                    "label": 0
                },
                {
                    "sent": "So what you want to understand is that it's parallel message updates.",
                    "label": 0
                },
                {
                    "sent": "Every node is just sitting there.",
                    "label": 0
                },
                {
                    "sent": "Collecting messages from these neighbors along these edges.",
                    "label": 0
                },
                {
                    "sent": "Taking a product.",
                    "label": 0
                },
                {
                    "sent": "Performs a summation and then it relays that message along this outgoing edge and it's going to do that.",
                    "label": 0
                },
                {
                    "sent": "It's going to relay one message along every one of its outgoing edges, but it just sits there doing that locali and once it converges then you just take a product like this and you get the marginals.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me just wrap up this first part by talking very briefly about the Max product algorithm.",
                    "label": 0
                },
                {
                    "sent": "If you understand the sum product algorithm, there's not much more to much more work to do here.",
                    "label": 0
                },
                {
                    "sent": "That's the nice thing.",
                    "label": 0
                },
                {
                    "sent": "The key observation is that basic distributive property that we spoke about.",
                    "label": 0
                },
                {
                    "sent": "Applies also to doing Maxima in product.",
                    "label": 0
                },
                {
                    "sent": "It's not just summations and products.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if I wanted to maximize the function over X1X2 and X1X3, I can just as easily start pushing the maximums inside like this so I can start distributing Maxima over products.",
                    "label": 0
                },
                {
                    "sent": "And essentially you just go through the same argument everywhere you see a summation, you put a Max and what you get is called Max product and it again generalizes things like the Viterbi algorithm that many of you will be familiar with.",
                    "label": 0
                },
                {
                    "sent": "So this is just saying that again, it's the same idea you're just doing everything with Max instead of summations.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's wrap up here for the first part.",
                    "label": 0
                },
                {
                    "sent": "Any questions I guess just before we break about the sum product algorithm.",
                    "label": 0
                },
                {
                    "sent": "Yeah, will you be talking about graphical codes for this?",
                    "label": 0
                },
                {
                    "sent": "Not in terrible depth, but I'm happy to chat offline if you're interested.",
                    "label": 0
                },
                {
                    "sent": "So the question is about graphical codes, things that sort of are being used in communication.",
                    "label": 0
                },
                {
                    "sent": "You might have heard of Turbo codes or low density parity check codes.",
                    "label": 0
                },
                {
                    "sent": "These again are special cases of graphical models and the algorithm that's implemented is exactly this sum product algorithm.",
                    "label": 0
                },
                {
                    "sent": "But the codes are not trees.",
                    "label": 0
                },
                {
                    "sent": "It turns out there's for certain reason trees are not good and you have to move beyond trees, and that's sort of where we're heading.",
                    "label": 0
                },
                {
                    "sent": "There's many cases where trees are not a rich enough model class.",
                    "label": 0
                },
                {
                    "sent": "You want richer models, so you have to move beyond simple tree models.",
                    "label": 0
                }
            ]
        }
    }
}