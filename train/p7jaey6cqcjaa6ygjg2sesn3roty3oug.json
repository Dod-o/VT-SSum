{
    "id": "p7jaey6cqcjaa6ygjg2sesn3roty3oug",
    "title": "A near-optimal algorithm for finite partial-monitoring games against adversarial opponents",
    "info": {
        "author": [
            "G\u00e1bor Bart\u00f3k, Department of Computer Science, ETH Zurich"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_bartok_opponents/",
    "segmentation": [
        [
            "Alright, so Sebastian algorithm was algorithm where he randomized.",
            "So he seems to like randomization just for the fun of it.",
            "And my main take home message will be do not randomize when you don't need to.",
            "So, so first the model of."
        ],
        [
            "Partial monitoring is almost bandits accepted.",
            "Your feedback is not necessarily the loss you receive, but some structured feedback.",
            "So the game proceeds as follows.",
            "The learner chooses an action.",
            "The environment, reason, outcome and then the learner suffers a loss and receive some feedback based on loss function and feedback function.",
            "Both of them are available to the learner in the beginning."
        ],
        [
            "OK, and so the the the performance measure is the usual the expected regret.",
            "In this case the the our loss compared to the loss of the best extraction in hindsight."
        ],
        [
            "OK, so some previous results.",
            "It turns out that some partial return games proved to be harder than banded games or full information games, so there are only four kinds of games in terms of what is the exponent in the time horizon.",
            "In the regret there are hopeless games with the hard games.",
            "With the two Certeza games with the square root of T and trivial again with zero regret, and I will focus on this class, the easy class where the so called local.",
            "Local of the regulated condition hold OK, so this this work was only for stochastic opponent, so IID opponents.",
            "Then later Sasha and info still prove the same thing for adverse aerial opponents.",
            "So they have their algorithm called Neighborhood Watch, which relies on on a 2 step exponential way.",
            "So there are local games, so the game is played to local games and then there are two steps.",
            "First of all, the local games chosen, but based on exponential weights and then within the local game and actually chosen based on exponential weights and they regret bound in their regret bound the number of actions is out is out from the square root, so we know that at least for the bandit case this is suboptimal.",
            "By the way, the work before that.",
            "Did not really care about the bound in terms of the number of actions, so the those were even more loud loose, so.",
            "In this work I am trying to get a better record regret bound for locali observable game in terms of the number of actions."
        ],
        [
            "So the new algorithm, called Global X3, differs in two main points from the neighborhood Watch algorithm.",
            "First of all, he chooses the local game in in a deterministic fashion instead of randomly, because it turns out that we do not need randomization to choose the local game and also the local games are defined a little bit differently.",
            "Come to the poster please.",
            "So here I pulled these gains point local gains.",
            "And then within the point local games we use basically the same algorithm as Sasha to figure out which action to choose."
        ],
        [
            "OK, so a bit more detailed so consider this probability simplex as the the relative frequency of outcomes that the adversary chooses and then that the actions will induce a cell.",
            "The composition itself corresponds to under which relative frequency of outcomes and action is optimal.",
            "And So what we do is that we have these point local games, so I don't have them so so we have these point local games.",
            "These these actions correspond to appoint local game and then we try to figure out where the relative frequency lies in the game based on."
        ],
        [
            "Um?"
        ],
        [
            "Figuring out the differences between expected losses.",
            "This is the local observability condition that neighboring action pairs.",
            "The loss difference between neighboring action pairs can be estimated well, so based on that we can.",
            "We can figure out largely."
        ],
        [
            "The relative frequency lies and based on this estimate we can actually deterministically choose which local game to play.",
            "So the choice of the local game is not random and I can't emphasize more."
        ],
        [
            "OK, and then within the point local games we do basically the same as Sunshine and Dean, so so the main trick is that well, here we don't have estimates for the losses, but we have estimates for loss differences.",
            "And it turns out that with the tricky update we can actually have a shifted loss estimate for all the actions and then use X3 as usual.",
            "So the unbiased estimates are unbiased in terms of the loss differences now."
        ],
        [
            "And so this is the violent.",
            "This is the exact bound and this is.",
            "This is what we should know about it.",
            "So N prime is now the size of the largest point local game, so it can even be less than N. The number of action and then and then the T is under squared.",
            "The end time is under the square root and unfortunately there is this size of M which is the number of action pairs that are needed for tracking P but.",
            "Of a lot that this will be less than an and also less than the number of outcomes.",
            "And there is this epsilon G which is kind of which corresponds to kind of the structure of the game, and it has to be there no matter what, maybe with a smaller.",
            "Exponent, but in some form these epsilon G has to be there.",
            "Thank you.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so Sebastian algorithm was algorithm where he randomized.",
                    "label": 0
                },
                {
                    "sent": "So he seems to like randomization just for the fun of it.",
                    "label": 0
                },
                {
                    "sent": "And my main take home message will be do not randomize when you don't need to.",
                    "label": 0
                },
                {
                    "sent": "So, so first the model of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Partial monitoring is almost bandits accepted.",
                    "label": 1
                },
                {
                    "sent": "Your feedback is not necessarily the loss you receive, but some structured feedback.",
                    "label": 0
                },
                {
                    "sent": "So the game proceeds as follows.",
                    "label": 0
                },
                {
                    "sent": "The learner chooses an action.",
                    "label": 0
                },
                {
                    "sent": "The environment, reason, outcome and then the learner suffers a loss and receive some feedback based on loss function and feedback function.",
                    "label": 0
                },
                {
                    "sent": "Both of them are available to the learner in the beginning.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and so the the the performance measure is the usual the expected regret.",
                    "label": 0
                },
                {
                    "sent": "In this case the the our loss compared to the loss of the best extraction in hindsight.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so some previous results.",
                    "label": 0
                },
                {
                    "sent": "It turns out that some partial return games proved to be harder than banded games or full information games, so there are only four kinds of games in terms of what is the exponent in the time horizon.",
                    "label": 0
                },
                {
                    "sent": "In the regret there are hopeless games with the hard games.",
                    "label": 0
                },
                {
                    "sent": "With the two Certeza games with the square root of T and trivial again with zero regret, and I will focus on this class, the easy class where the so called local.",
                    "label": 0
                },
                {
                    "sent": "Local of the regulated condition hold OK, so this this work was only for stochastic opponent, so IID opponents.",
                    "label": 0
                },
                {
                    "sent": "Then later Sasha and info still prove the same thing for adverse aerial opponents.",
                    "label": 0
                },
                {
                    "sent": "So they have their algorithm called Neighborhood Watch, which relies on on a 2 step exponential way.",
                    "label": 0
                },
                {
                    "sent": "So there are local games, so the game is played to local games and then there are two steps.",
                    "label": 0
                },
                {
                    "sent": "First of all, the local games chosen, but based on exponential weights and then within the local game and actually chosen based on exponential weights and they regret bound in their regret bound the number of actions is out is out from the square root, so we know that at least for the bandit case this is suboptimal.",
                    "label": 0
                },
                {
                    "sent": "By the way, the work before that.",
                    "label": 0
                },
                {
                    "sent": "Did not really care about the bound in terms of the number of actions, so the those were even more loud loose, so.",
                    "label": 0
                },
                {
                    "sent": "In this work I am trying to get a better record regret bound for locali observable game in terms of the number of actions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the new algorithm, called Global X3, differs in two main points from the neighborhood Watch algorithm.",
                    "label": 1
                },
                {
                    "sent": "First of all, he chooses the local game in in a deterministic fashion instead of randomly, because it turns out that we do not need randomization to choose the local game and also the local games are defined a little bit differently.",
                    "label": 0
                },
                {
                    "sent": "Come to the poster please.",
                    "label": 0
                },
                {
                    "sent": "So here I pulled these gains point local gains.",
                    "label": 0
                },
                {
                    "sent": "And then within the point local games we use basically the same algorithm as Sasha to figure out which action to choose.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so a bit more detailed so consider this probability simplex as the the relative frequency of outcomes that the adversary chooses and then that the actions will induce a cell.",
                    "label": 0
                },
                {
                    "sent": "The composition itself corresponds to under which relative frequency of outcomes and action is optimal.",
                    "label": 0
                },
                {
                    "sent": "And So what we do is that we have these point local games, so I don't have them so so we have these point local games.",
                    "label": 0
                },
                {
                    "sent": "These these actions correspond to appoint local game and then we try to figure out where the relative frequency lies in the game based on.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Figuring out the differences between expected losses.",
                    "label": 0
                },
                {
                    "sent": "This is the local observability condition that neighboring action pairs.",
                    "label": 1
                },
                {
                    "sent": "The loss difference between neighboring action pairs can be estimated well, so based on that we can.",
                    "label": 0
                },
                {
                    "sent": "We can figure out largely.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The relative frequency lies and based on this estimate we can actually deterministically choose which local game to play.",
                    "label": 0
                },
                {
                    "sent": "So the choice of the local game is not random and I can't emphasize more.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then within the point local games we do basically the same as Sunshine and Dean, so so the main trick is that well, here we don't have estimates for the losses, but we have estimates for loss differences.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that with the tricky update we can actually have a shifted loss estimate for all the actions and then use X3 as usual.",
                    "label": 0
                },
                {
                    "sent": "So the unbiased estimates are unbiased in terms of the loss differences now.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so this is the violent.",
                    "label": 0
                },
                {
                    "sent": "This is the exact bound and this is.",
                    "label": 0
                },
                {
                    "sent": "This is what we should know about it.",
                    "label": 0
                },
                {
                    "sent": "So N prime is now the size of the largest point local game, so it can even be less than N. The number of action and then and then the T is under squared.",
                    "label": 0
                },
                {
                    "sent": "The end time is under the square root and unfortunately there is this size of M which is the number of action pairs that are needed for tracking P but.",
                    "label": 0
                },
                {
                    "sent": "Of a lot that this will be less than an and also less than the number of outcomes.",
                    "label": 0
                },
                {
                    "sent": "And there is this epsilon G which is kind of which corresponds to kind of the structure of the game, and it has to be there no matter what, maybe with a smaller.",
                    "label": 0
                },
                {
                    "sent": "Exponent, but in some form these epsilon G has to be there.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}