{
    "id": "u6avhpatbg3k3rl627qbd7towawgglyx",
    "title": "A Novel Lexicalized HMM-Based Learning Framework for Web Opinion Mining",
    "info": {
        "author": [
            "Wei Jin, Computer Science Department, North Dakota State University"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Social Computing",
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/icml09_jin_nlhmmblfwom/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "My name is Luigi and I'm working at the Department of Computer Science at North Dakota State University and today.",
            "What my talk will be focused on novel lexicalized hmm based learning framework for web opening."
        ],
        [
            "Mining.",
            "Excuse me so first I will give you a brief introduction of what the web opening mining is and also I will discuss several related work and introduce a lexicalized hmm based learning framework.",
            "Finally, I will present the experimental results, and is followed by the conclusion."
        ],
        [
            "We have known the web contains a large amount of information and this information can be divided into two categories.",
            "The one is facts, so when we search effects we use the current search engine.",
            "So typically we type a sequence of keywords and the search engine will return us a ranked list of documents which are assumed to be relevant to your query.",
            "Another type of information is the opinions, so opinions are the ideas or thoughts expressed by people concerning, uh, for example, a particular product or particular event.",
            "So opinions are hard to express with keywords, and the current search ranking strategies.",
            "They're good at documenting ranking and keyword matching.",
            "However, they might not be appropriate so appropriate for opinion, search and also we notice that E Commerce is becoming more and more popular.",
            "So that means more and more products are sold on the web.",
            "And more and more people buy products online and it has become a common practice that the merchants will ask their customers to share their opinions and the hands on exercise authority experience in on products they have purchased.",
            "However, reading through all this, customer views would be difficult, especially for popular items.",
            "The number of reviews can be up to hundreds or even thousands, so this paper is particularly focused on designing a framework that.",
            "Can automatically extract product entities and open expressions from the product reviews.",
            "So also this this task might also benefit."
        ],
        [
            "Many other applications like business and as placement.",
            "They are also interested in how the opinions are from their customers concerning any products.",
            "So basically this framework should be able to extract, learn and classify product entities and open expressions automatically from a product reviews.",
            "For instance, this is our opinion sentence.",
            "Battery life is quite impressive.",
            "If a product is a camera.",
            "So what I mean about the product entities here is the battery life is support DOT entity and impressive.",
            "Here is the open expression and here particularly is a positive opinion.",
            "And so in our system, the goal is we should be able to automatically idente."
        ],
        [
            "I find these things and the further determine the opinions priority is positive or negative.",
            "And generally speaking, they involve the following three sequential tasks.",
            "First task is to identify and extract product entities that have been commented on.",
            "And also we need to the identify extract opening sentences and further determine if the openings are positive or negative.",
            "So there are several related work, but I won't get into much detail here.",
            "So basically speaking, the previously proposed approaches they either used the rule based language processing techniques or they use the statistical approach such as Association rule mining to extract high frequency feature keywords, an high frequency opinion, keywords, the difference of our approaches which we propose our learning framework.",
            "Which is extremely useful in web and text mining due to the complexity and flexibility of natural languages and also the system can identify complex product specific features and infrequently mentioned features which were ignored or underlies about previous approaches.",
            "So this picture shows you the architectural overview of the."
        ],
        [
            "So technique, so after the preprocessing step we obtained the review corpus and we split it into two sets, one full evaluation and the other for the training and also to further reduce manual effort of labeling a large amount of documents.",
            "We introduce a new technique which is based on the bootstrapping.",
            "A strategy and after that the trend classifier can be used to check the new incoming documents and provide all the information we need."
        ],
        [
            "So now let's look at the first task that is identification of the product entities and open expressions.",
            "So we have defined the following for entity categories, which are components, functions, features and opinions concerning a particular product.",
            "So the detailed description I will get into detail because of the time limit.",
            "So also in order to."
        ],
        [
            "To identify this.",
            "Entities we have further defined the tags so these attacks can be used to denote the different entity categories such as the product feature.",
            "If you tag in this way, it will tell you this product entity Authority, product feature and also the opening positive operating negative and background words."
        ],
        [
            "Another thing to note is that an entity here can be a single word or phrase.",
            "So for example, battery life is a phrase, right?",
            "So here we are.",
            "Saying that a word W in the entity may take one of the following full patterns to represent to present itself so W could be an independent entity.",
            "So this means this entity is a single word.",
            "Oh, it is beginning component entity or at the middle or at the end.",
            "So like battery life, battery is the beginning component of this entity and the life is the edit the end.",
            "So we have also defined the pattern text in order to capture phrases internal.",
            "Formation patterns using this for pattern tags."
        ],
        [
            "So this slide shows you they are example of hybrid tech representation and basic tag representation.",
            "The hybrid tech present mean that we use both the basic tag and pattern tag to denote each word, the entity category and the pattern.",
            "So like here."
        ],
        [
            "I love the ease of the transferring the picture to my computer, so is all the transfer account picture.",
            "The whole is is the first picture feature, sorry.",
            "So Alpha."
        ],
        [
            "This definition we will use our lexicalized HMM and the difference from the traditional item is that we integrate part of speech and the lexical patterns here.",
            "So now an observable stepped in the pair which contains a word and a part of speech over that word, and now given the sequence of given a sequence of words and the corresponding parts of speech, the goal is to find appropriate hybrid text that maximizes the conditional probability.",
            "And after several probabilistic formulation transformations, you can come up with a very generalized model.",
            "However, this model involves too many parameters, so we have to simplify it."
        ],
        [
            "We use the two types of approximations.",
            "First is based on the independent hypothesis of 1st order HMM.",
            "The second approximation combined the part of speech information with the lexicalization technique.",
            "So specifically the following three hypothesis are made.",
            "Like the assignment of current attack is supposed to depend not only on the previous tag, but also previous words and disappearance of current part of speech is supposed to depend both on the current attack and previous words and the pyramids of current world is assumed to depend not only with the current current attack on the part of speech, but also the previous words in terms of the data.",
            "Sparseness.",
            "In our experiments we we set these parameters JL&K to be one.",
            "And also the maximum likelihood estimation is used to estimate these probabilities."
        ],
        [
            "One problem that should be addressed is zero probability for the MLP technique.",
            "This could happen for any cases that are are not observed in the training data, so we used the linear interpolation smoothing technique which means to smooth high order.",
            "Models with the relevant low order models or smooth the lexicalized parameters using the United non lexical probabilities, so eventually we will get this type of formulation, and then we we have the three interpolation coefficients.",
            "You can use this to smooth the data is not too large.",
            "Training sets not large enough.",
            "So for decoding you can use the the vertebra rhythm to find the hybrid text sequence, including the entity category tag as well."
        ],
        [
            "The pattern tag.",
            "So now let's move to the second task that is identifying and extracting opening sentences.",
            "So opinion sentences are defined here as sentences that express your opinion on product entities and the following two type of centers are not considered at the opening sentences if they only describe product entity, but without expressing reviewers opinions.",
            "Oh, if that express the opinions or another product models entities.",
            "So there's two types of sentences are not considered as opinion sentences.",
            "The last task is the opening orientation classification.",
            "When thing I want to point out here is that opinion orientation is not simply equal to opinion, entity, word or phrase is orientation."
        ],
        [
            "So the following is an example.",
            "So suppose the opening sentence.",
            "Or if you wrote it, I can tell you right now that the auto mode and the program moves are not that good.",
            "So I'm talking about a camera product using this as an example.",
            "So the actually they reviewers expressed their negative comment on both auto mode and program modes even in the presence of opinion entity here is so good.",
            "Good is opening word or phrase so why?",
            "Because there was a note here, right so?",
            "In order to handle this food, so we have to capture different sentence context so different language constructs.",
            "So we use several language rules to address this.",
            "Particularly here we will look for the any negative word occurrence within five word window in front of."
        ],
        [
            "Opening entity and if they occur there, we need to change opening orientation to the opposite of the original opening word orientation, right?",
            "So here is the detailed algorithm.",
            "As I said, we will consider any negation words and also several exceptions we should we should handle here.",
            "And also we will consider the conjunction words like but and we always the prepositions like except or apart from.",
            "So this is.",
            "The language rules.",
            "So if you are familiar with the natural language processing domain, the rule based techniques still has a lot of applications.",
            "Oh OK, no less."
        ],
        [
            "Look at it experiments.",
            "So for the corpus we used Amazon's the digital camera reviews and the first 1616 unique.",
            "Cameras listed in an Amazon.com during November 2007 were crowd after the preprocessing.",
            "We obtained 1717, twenty added review documents.",
            "So we split into two sets, one set for the manual tagging and the other side is for the bootstrapping which I will describe shortly and also we observed two challenges here.",
            "First is people use inconsistent terminology even for just describing the same product entity because.",
            "The people are not professional writers or the product experts, so they use different terminology, like here.",
            "There are several words, but there there meaning the same thing.",
            "And also we are proposing to recognize rarely mentioned entities because we we we consider this already mentioned that it could be also very important product descriptors because most generic features may be satisfied by most products.",
            "However, product specific products basic features can be better able to differentiate different products, right?",
            "So in order to address this and to further reduce the effort of menu labeling of large set of training documents, this is hard to accomplish because if you ask some experts to to keep tagging or larger among training set is very time consuming."
        ],
        [
            "However, consumer, so we introduce our bootstrapping technique here to enable self direct learning.",
            "So this is the how the bootstrapping are designed.",
            "So basically speaking, the bootstrapping program will generate two child processes so the parent process will act as master and the rest of them will act as workers and we split the training document into two halves.",
            "Each half will be used as seeds for each workers lexicalized hmm and.",
            "Each worker will trace on hmm and after that it will be used to tag the bootstrapping documents.",
            "And one thing to note here is because both Hmm's training documents are different because it is random.",
            "Selection is different.",
            "So after the tagging step the results might not be consistent.",
            "So in this case, after the tagging step we, the master, will inspect every sentence.",
            "Text body each of the actual memes and only extract the opening sentence is that are agreed upon by both classifiers.",
            "If it's a newly discovered sentence and agreed upon, then we consider this a valid.",
            "It's very high confidence data, so we added into the training set to further train these lexicalized action.",
            "This process can be repeated until no new data would discovered.",
            "All you observe that the performance has a little change."
        ],
        [
            "So this slide shows you the evaluation for the bootstrapping result evaluation, so you might observe that you know after just a number of cycles, the bootstrapping algorithm actually provides are relatively relatively satisfying performance.",
            "All."
        ],
        [
            "For the evaluation, we used the largest full datasets and performed are four fold cross validation and we have measured the recall precision an F score for the product entities, opening sentences, extraction and the.",
            "The entity opening pairs orientation classification.",
            "These three components and this has been achieved by comparing the results tagged by the system with the manually tag, the truth data and only our exact match is considered as a correct recognition.",
            "Here I mean exact match.",
            "For example the entity recognition.",
            "This means the exact same word or some fries.",
            "Identified as well as classified correctly and also this each identify the entity should occur in the same document.",
            "Some sentence and Sam position.",
            "So this is a very strict evaluation."
        ],
        [
            "For the baseline, we have implemented our rule based baseline system.",
            "This is motivated by turning paper in ACL 2002 and when the newspaper in KDD 2004, basically speaking, we used the number of rules to identify opening bearing words.",
            "So any nouns matching these rules or any adjectives matching visuals will be extracted as opening words and the product entities respectively.",
            "And for the adjective semantic orientations.",
            "We used The Who and use bootstrapping approach proposed, including the paper to in 2004.",
            "So this is about the baseline.",
            "Following several slides showed you."
        ],
        [
            "Who are the evaluation result?",
            "We have experimented with different combinations of parameters and we have observed that the strategy that.",
            "Combine the user lexicalized hmm integrating part of speech."
        ],
        [
            "As well as the bootstrapping strategy has achieved the best performance."
        ],
        [
            "And this table shows you some self learned vocabulary."
        ],
        [
            "So all the words or phrases are that are followed by this* symbol.",
            "These are the self learn vocabulary.",
            "So then they have never occur in the training set.",
            "And also you might notice that some very complex for this can be effectively extracted.",
            "So like automatic.",
            "Point and shoot mode so and also the the the number after the = means the number of occurrences of this particular word.",
            "So this is the last slide to conclude."
        ],
        [
            "So in this paper we introduce our robust machine learning approach for web opening, mining and extraction.",
            "And it can self learn new vocabulary, discover new product entities and open expressions based on the pattern it has learned from the training data.",
            "And.",
            "Either can also identify complex product entities and open expressions as well as the infrequently mentioned entities.",
            "And the bootstrapping approach can be used in situations in which.",
            "Obtaining the large training set could be expensive and hard to accomplish.",
            "The future directions involve the expansion of the datasets and we also researching the role for pronoun resolution in improving many results as well as any alternative sequence labeling techniques that have been proposed like conditional random fields and so on.",
            "So that's it.",
            "Thank you."
        ],
        [
            "Suicide two questions.",
            "Once a general question because I'm gonna say something 2nd.",
            "Extended series sentiment analysis and opinion mining.",
            "The same sort of thing or different ways of looking sentiment analysis.",
            "This is saving feature.",
            "You have sent him an analysis.",
            "Actually, I admit the background a little bit.",
            "The opinion mining can be divided into two categories.",
            "The first is the document level and the 2nd is a feature level.",
            "So sentiment analysis is the term is used in the document level, appending mining.",
            "So basically the task of sentiment analysis currently is your determine if this whole document is positive or negative, right so?",
            "Like a movie review, you decide all this reviewer expresses are positive opinion on this movie or not.",
            "So it's the document level, so the granularity would be larger.",
            "However, this feature level opinion mining is kind of capturing the finer granularity about the exact entities so they're focused on how.",
            "These entities are commented on by each review and the polarity of these openings, but the one thing you are right, so they're both handling the polarity so positive or negative.",
            "The difference is the granularity.",
            "So here what I'm talking about is about the feature level and the sentiment analysis.",
            "This term actually is used in language domain is about the document level in in a larger scope.",
            "Does this mean if you want extended beyond, cameras are going to have to train your system?",
            "Like if you want for washing machines and 1%?",
            "That's a good question.",
            "It's a very good question.",
            "We are also considering this that you are mentioning are domain specific or independent domains.",
            "Yeah, so actually in 2004 the quality papers that are very famous author.",
            "I mean it's very very very good professor.",
            "He's doing the opinion mining and he used Association rule mining which I think is a very generalized model which means the domain independent.",
            "So however the machine learning until now I still haven't.",
            "Go to idea about how make how to make the system to cross domain.",
            "I mean how to make it you know to.",
            "To to to omit the step of the training.",
            "Individual systems concerning each of the particular products.",
            "So currently we still ask some people who are really good at cameras that they like two different brands of cameras, so they did the tagging step.",
            "But I still think eventually the machine learning strategy should be able to.",
            "Or we can design a way to make it to perform in a cross domain manner.",
            "Looking for a system that takes 3, three reviews and fills out the summarizing review form.",
            "It was one more question.",
            "You're especially using hidden Markov models for doing information extraction, and you're also integrating other source of information that are non independent.",
            "So my question is why aren't you using conditional random fields which clearly superior to hidden model model for information extraction and have the benefit being discriminative of being able to learn essentially optimally from non independent source of information you mean according to random fields has the feature of learning independent domain?",
            "No, sorry, integrate multiple features, multiple predictors which don't have to, with no assumption of independence.",
            "OK, yeah, yeah, that's a good suggestion.",
            "We are experimenting the conditional random fields.",
            "I think that's thank you for your suggestion.",
            "Yeah, that's the also one of the future direction.",
            "Time for one more question.",
            "I have one more in the I didn't quite understand what you were measuring in the end in the evaluation.",
            "And this is 4 fold cross validation and so so one camera was in the test set always.",
            "Yeah, So what was then measured in?",
            "What gives you a plus in both gives you aminos minus in this in this evaluation of this one camera.",
            "The full form.",
            "Secure the.",
            "That's true, these easy manual labeling that step the experts will attack.",
            "This is opening words that impressive said positive opinion.",
            "The excellent as a positive opinion.",
            "Battery life is a product feature.",
            "Maybe all the focus is a product functionality.",
            "So for about the for example the camera.",
            "So this is the training data and is the truth data ground truth we consider for the tag tagging parts once.",
            "Once the best classifier is obtained.",
            "We use it to train the new incoming the test set.",
            "We extract 1 camera at the testing camera.",
            "Then we ask the classifier to tag it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Luigi and I'm working at the Department of Computer Science at North Dakota State University and today.",
                    "label": 1
                },
                {
                    "sent": "What my talk will be focused on novel lexicalized hmm based learning framework for web opening.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mining.",
                    "label": 0
                },
                {
                    "sent": "Excuse me so first I will give you a brief introduction of what the web opening mining is and also I will discuss several related work and introduce a lexicalized hmm based learning framework.",
                    "label": 1
                },
                {
                    "sent": "Finally, I will present the experimental results, and is followed by the conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have known the web contains a large amount of information and this information can be divided into two categories.",
                    "label": 0
                },
                {
                    "sent": "The one is facts, so when we search effects we use the current search engine.",
                    "label": 0
                },
                {
                    "sent": "So typically we type a sequence of keywords and the search engine will return us a ranked list of documents which are assumed to be relevant to your query.",
                    "label": 0
                },
                {
                    "sent": "Another type of information is the opinions, so opinions are the ideas or thoughts expressed by people concerning, uh, for example, a particular product or particular event.",
                    "label": 0
                },
                {
                    "sent": "So opinions are hard to express with keywords, and the current search ranking strategies.",
                    "label": 1
                },
                {
                    "sent": "They're good at documenting ranking and keyword matching.",
                    "label": 1
                },
                {
                    "sent": "However, they might not be appropriate so appropriate for opinion, search and also we notice that E Commerce is becoming more and more popular.",
                    "label": 1
                },
                {
                    "sent": "So that means more and more products are sold on the web.",
                    "label": 1
                },
                {
                    "sent": "And more and more people buy products online and it has become a common practice that the merchants will ask their customers to share their opinions and the hands on exercise authority experience in on products they have purchased.",
                    "label": 0
                },
                {
                    "sent": "However, reading through all this, customer views would be difficult, especially for popular items.",
                    "label": 0
                },
                {
                    "sent": "The number of reviews can be up to hundreds or even thousands, so this paper is particularly focused on designing a framework that.",
                    "label": 1
                },
                {
                    "sent": "Can automatically extract product entities and open expressions from the product reviews.",
                    "label": 0
                },
                {
                    "sent": "So also this this task might also benefit.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many other applications like business and as placement.",
                    "label": 0
                },
                {
                    "sent": "They are also interested in how the opinions are from their customers concerning any products.",
                    "label": 0
                },
                {
                    "sent": "So basically this framework should be able to extract, learn and classify product entities and open expressions automatically from a product reviews.",
                    "label": 0
                },
                {
                    "sent": "For instance, this is our opinion sentence.",
                    "label": 0
                },
                {
                    "sent": "Battery life is quite impressive.",
                    "label": 0
                },
                {
                    "sent": "If a product is a camera.",
                    "label": 0
                },
                {
                    "sent": "So what I mean about the product entities here is the battery life is support DOT entity and impressive.",
                    "label": 0
                },
                {
                    "sent": "Here is the open expression and here particularly is a positive opinion.",
                    "label": 0
                },
                {
                    "sent": "And so in our system, the goal is we should be able to automatically idente.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I find these things and the further determine the opinions priority is positive or negative.",
                    "label": 1
                },
                {
                    "sent": "And generally speaking, they involve the following three sequential tasks.",
                    "label": 0
                },
                {
                    "sent": "First task is to identify and extract product entities that have been commented on.",
                    "label": 1
                },
                {
                    "sent": "And also we need to the identify extract opening sentences and further determine if the openings are positive or negative.",
                    "label": 0
                },
                {
                    "sent": "So there are several related work, but I won't get into much detail here.",
                    "label": 0
                },
                {
                    "sent": "So basically speaking, the previously proposed approaches they either used the rule based language processing techniques or they use the statistical approach such as Association rule mining to extract high frequency feature keywords, an high frequency opinion, keywords, the difference of our approaches which we propose our learning framework.",
                    "label": 0
                },
                {
                    "sent": "Which is extremely useful in web and text mining due to the complexity and flexibility of natural languages and also the system can identify complex product specific features and infrequently mentioned features which were ignored or underlies about previous approaches.",
                    "label": 0
                },
                {
                    "sent": "So this picture shows you the architectural overview of the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So technique, so after the preprocessing step we obtained the review corpus and we split it into two sets, one full evaluation and the other for the training and also to further reduce manual effort of labeling a large amount of documents.",
                    "label": 0
                },
                {
                    "sent": "We introduce a new technique which is based on the bootstrapping.",
                    "label": 0
                },
                {
                    "sent": "A strategy and after that the trend classifier can be used to check the new incoming documents and provide all the information we need.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's look at the first task that is identification of the product entities and open expressions.",
                    "label": 0
                },
                {
                    "sent": "So we have defined the following for entity categories, which are components, functions, features and opinions concerning a particular product.",
                    "label": 0
                },
                {
                    "sent": "So the detailed description I will get into detail because of the time limit.",
                    "label": 0
                },
                {
                    "sent": "So also in order to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To identify this.",
                    "label": 0
                },
                {
                    "sent": "Entities we have further defined the tags so these attacks can be used to denote the different entity categories such as the product feature.",
                    "label": 1
                },
                {
                    "sent": "If you tag in this way, it will tell you this product entity Authority, product feature and also the opening positive operating negative and background words.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing to note is that an entity here can be a single word or phrase.",
                    "label": 0
                },
                {
                    "sent": "So for example, battery life is a phrase, right?",
                    "label": 0
                },
                {
                    "sent": "So here we are.",
                    "label": 0
                },
                {
                    "sent": "Saying that a word W in the entity may take one of the following full patterns to represent to present itself so W could be an independent entity.",
                    "label": 0
                },
                {
                    "sent": "So this means this entity is a single word.",
                    "label": 0
                },
                {
                    "sent": "Oh, it is beginning component entity or at the middle or at the end.",
                    "label": 0
                },
                {
                    "sent": "So like battery life, battery is the beginning component of this entity and the life is the edit the end.",
                    "label": 0
                },
                {
                    "sent": "So we have also defined the pattern text in order to capture phrases internal.",
                    "label": 0
                },
                {
                    "sent": "Formation patterns using this for pattern tags.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this slide shows you they are example of hybrid tech representation and basic tag representation.",
                    "label": 0
                },
                {
                    "sent": "The hybrid tech present mean that we use both the basic tag and pattern tag to denote each word, the entity category and the pattern.",
                    "label": 0
                },
                {
                    "sent": "So like here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I love the ease of the transferring the picture to my computer, so is all the transfer account picture.",
                    "label": 1
                },
                {
                    "sent": "The whole is is the first picture feature, sorry.",
                    "label": 0
                },
                {
                    "sent": "So Alpha.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This definition we will use our lexicalized HMM and the difference from the traditional item is that we integrate part of speech and the lexical patterns here.",
                    "label": 0
                },
                {
                    "sent": "So now an observable stepped in the pair which contains a word and a part of speech over that word, and now given the sequence of given a sequence of words and the corresponding parts of speech, the goal is to find appropriate hybrid text that maximizes the conditional probability.",
                    "label": 0
                },
                {
                    "sent": "And after several probabilistic formulation transformations, you can come up with a very generalized model.",
                    "label": 0
                },
                {
                    "sent": "However, this model involves too many parameters, so we have to simplify it.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use the two types of approximations.",
                    "label": 0
                },
                {
                    "sent": "First is based on the independent hypothesis of 1st order HMM.",
                    "label": 0
                },
                {
                    "sent": "The second approximation combined the part of speech information with the lexicalization technique.",
                    "label": 0
                },
                {
                    "sent": "So specifically the following three hypothesis are made.",
                    "label": 0
                },
                {
                    "sent": "Like the assignment of current attack is supposed to depend not only on the previous tag, but also previous words and disappearance of current part of speech is supposed to depend both on the current attack and previous words and the pyramids of current world is assumed to depend not only with the current current attack on the part of speech, but also the previous words in terms of the data.",
                    "label": 0
                },
                {
                    "sent": "Sparseness.",
                    "label": 0
                },
                {
                    "sent": "In our experiments we we set these parameters JL&K to be one.",
                    "label": 0
                },
                {
                    "sent": "And also the maximum likelihood estimation is used to estimate these probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One problem that should be addressed is zero probability for the MLP technique.",
                    "label": 0
                },
                {
                    "sent": "This could happen for any cases that are are not observed in the training data, so we used the linear interpolation smoothing technique which means to smooth high order.",
                    "label": 0
                },
                {
                    "sent": "Models with the relevant low order models or smooth the lexicalized parameters using the United non lexical probabilities, so eventually we will get this type of formulation, and then we we have the three interpolation coefficients.",
                    "label": 0
                },
                {
                    "sent": "You can use this to smooth the data is not too large.",
                    "label": 0
                },
                {
                    "sent": "Training sets not large enough.",
                    "label": 0
                },
                {
                    "sent": "So for decoding you can use the the vertebra rhythm to find the hybrid text sequence, including the entity category tag as well.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The pattern tag.",
                    "label": 0
                },
                {
                    "sent": "So now let's move to the second task that is identifying and extracting opening sentences.",
                    "label": 0
                },
                {
                    "sent": "So opinion sentences are defined here as sentences that express your opinion on product entities and the following two type of centers are not considered at the opening sentences if they only describe product entity, but without expressing reviewers opinions.",
                    "label": 0
                },
                {
                    "sent": "Oh, if that express the opinions or another product models entities.",
                    "label": 0
                },
                {
                    "sent": "So there's two types of sentences are not considered as opinion sentences.",
                    "label": 0
                },
                {
                    "sent": "The last task is the opening orientation classification.",
                    "label": 0
                },
                {
                    "sent": "When thing I want to point out here is that opinion orientation is not simply equal to opinion, entity, word or phrase is orientation.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the following is an example.",
                    "label": 0
                },
                {
                    "sent": "So suppose the opening sentence.",
                    "label": 0
                },
                {
                    "sent": "Or if you wrote it, I can tell you right now that the auto mode and the program moves are not that good.",
                    "label": 0
                },
                {
                    "sent": "So I'm talking about a camera product using this as an example.",
                    "label": 0
                },
                {
                    "sent": "So the actually they reviewers expressed their negative comment on both auto mode and program modes even in the presence of opinion entity here is so good.",
                    "label": 0
                },
                {
                    "sent": "Good is opening word or phrase so why?",
                    "label": 0
                },
                {
                    "sent": "Because there was a note here, right so?",
                    "label": 0
                },
                {
                    "sent": "In order to handle this food, so we have to capture different sentence context so different language constructs.",
                    "label": 0
                },
                {
                    "sent": "So we use several language rules to address this.",
                    "label": 0
                },
                {
                    "sent": "Particularly here we will look for the any negative word occurrence within five word window in front of.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Opening entity and if they occur there, we need to change opening orientation to the opposite of the original opening word orientation, right?",
                    "label": 0
                },
                {
                    "sent": "So here is the detailed algorithm.",
                    "label": 0
                },
                {
                    "sent": "As I said, we will consider any negation words and also several exceptions we should we should handle here.",
                    "label": 0
                },
                {
                    "sent": "And also we will consider the conjunction words like but and we always the prepositions like except or apart from.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "The language rules.",
                    "label": 0
                },
                {
                    "sent": "So if you are familiar with the natural language processing domain, the rule based techniques still has a lot of applications.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, no less.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at it experiments.",
                    "label": 0
                },
                {
                    "sent": "So for the corpus we used Amazon's the digital camera reviews and the first 1616 unique.",
                    "label": 0
                },
                {
                    "sent": "Cameras listed in an Amazon.com during November 2007 were crowd after the preprocessing.",
                    "label": 0
                },
                {
                    "sent": "We obtained 1717, twenty added review documents.",
                    "label": 0
                },
                {
                    "sent": "So we split into two sets, one set for the manual tagging and the other side is for the bootstrapping which I will describe shortly and also we observed two challenges here.",
                    "label": 0
                },
                {
                    "sent": "First is people use inconsistent terminology even for just describing the same product entity because.",
                    "label": 0
                },
                {
                    "sent": "The people are not professional writers or the product experts, so they use different terminology, like here.",
                    "label": 0
                },
                {
                    "sent": "There are several words, but there there meaning the same thing.",
                    "label": 0
                },
                {
                    "sent": "And also we are proposing to recognize rarely mentioned entities because we we we consider this already mentioned that it could be also very important product descriptors because most generic features may be satisfied by most products.",
                    "label": 0
                },
                {
                    "sent": "However, product specific products basic features can be better able to differentiate different products, right?",
                    "label": 0
                },
                {
                    "sent": "So in order to address this and to further reduce the effort of menu labeling of large set of training documents, this is hard to accomplish because if you ask some experts to to keep tagging or larger among training set is very time consuming.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, consumer, so we introduce our bootstrapping technique here to enable self direct learning.",
                    "label": 0
                },
                {
                    "sent": "So this is the how the bootstrapping are designed.",
                    "label": 0
                },
                {
                    "sent": "So basically speaking, the bootstrapping program will generate two child processes so the parent process will act as master and the rest of them will act as workers and we split the training document into two halves.",
                    "label": 0
                },
                {
                    "sent": "Each half will be used as seeds for each workers lexicalized hmm and.",
                    "label": 0
                },
                {
                    "sent": "Each worker will trace on hmm and after that it will be used to tag the bootstrapping documents.",
                    "label": 0
                },
                {
                    "sent": "And one thing to note here is because both Hmm's training documents are different because it is random.",
                    "label": 0
                },
                {
                    "sent": "Selection is different.",
                    "label": 0
                },
                {
                    "sent": "So after the tagging step the results might not be consistent.",
                    "label": 0
                },
                {
                    "sent": "So in this case, after the tagging step we, the master, will inspect every sentence.",
                    "label": 0
                },
                {
                    "sent": "Text body each of the actual memes and only extract the opening sentence is that are agreed upon by both classifiers.",
                    "label": 0
                },
                {
                    "sent": "If it's a newly discovered sentence and agreed upon, then we consider this a valid.",
                    "label": 0
                },
                {
                    "sent": "It's very high confidence data, so we added into the training set to further train these lexicalized action.",
                    "label": 0
                },
                {
                    "sent": "This process can be repeated until no new data would discovered.",
                    "label": 0
                },
                {
                    "sent": "All you observe that the performance has a little change.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this slide shows you the evaluation for the bootstrapping result evaluation, so you might observe that you know after just a number of cycles, the bootstrapping algorithm actually provides are relatively relatively satisfying performance.",
                    "label": 0
                },
                {
                    "sent": "All.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the evaluation, we used the largest full datasets and performed are four fold cross validation and we have measured the recall precision an F score for the product entities, opening sentences, extraction and the.",
                    "label": 0
                },
                {
                    "sent": "The entity opening pairs orientation classification.",
                    "label": 0
                },
                {
                    "sent": "These three components and this has been achieved by comparing the results tagged by the system with the manually tag, the truth data and only our exact match is considered as a correct recognition.",
                    "label": 0
                },
                {
                    "sent": "Here I mean exact match.",
                    "label": 0
                },
                {
                    "sent": "For example the entity recognition.",
                    "label": 0
                },
                {
                    "sent": "This means the exact same word or some fries.",
                    "label": 0
                },
                {
                    "sent": "Identified as well as classified correctly and also this each identify the entity should occur in the same document.",
                    "label": 0
                },
                {
                    "sent": "Some sentence and Sam position.",
                    "label": 0
                },
                {
                    "sent": "So this is a very strict evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the baseline, we have implemented our rule based baseline system.",
                    "label": 0
                },
                {
                    "sent": "This is motivated by turning paper in ACL 2002 and when the newspaper in KDD 2004, basically speaking, we used the number of rules to identify opening bearing words.",
                    "label": 0
                },
                {
                    "sent": "So any nouns matching these rules or any adjectives matching visuals will be extracted as opening words and the product entities respectively.",
                    "label": 0
                },
                {
                    "sent": "And for the adjective semantic orientations.",
                    "label": 0
                },
                {
                    "sent": "We used The Who and use bootstrapping approach proposed, including the paper to in 2004.",
                    "label": 0
                },
                {
                    "sent": "So this is about the baseline.",
                    "label": 0
                },
                {
                    "sent": "Following several slides showed you.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who are the evaluation result?",
                    "label": 0
                },
                {
                    "sent": "We have experimented with different combinations of parameters and we have observed that the strategy that.",
                    "label": 0
                },
                {
                    "sent": "Combine the user lexicalized hmm integrating part of speech.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As well as the bootstrapping strategy has achieved the best performance.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this table shows you some self learned vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So all the words or phrases are that are followed by this* symbol.",
                    "label": 0
                },
                {
                    "sent": "These are the self learn vocabulary.",
                    "label": 0
                },
                {
                    "sent": "So then they have never occur in the training set.",
                    "label": 0
                },
                {
                    "sent": "And also you might notice that some very complex for this can be effectively extracted.",
                    "label": 0
                },
                {
                    "sent": "So like automatic.",
                    "label": 0
                },
                {
                    "sent": "Point and shoot mode so and also the the the number after the = means the number of occurrences of this particular word.",
                    "label": 0
                },
                {
                    "sent": "So this is the last slide to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this paper we introduce our robust machine learning approach for web opening, mining and extraction.",
                    "label": 0
                },
                {
                    "sent": "And it can self learn new vocabulary, discover new product entities and open expressions based on the pattern it has learned from the training data.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Either can also identify complex product entities and open expressions as well as the infrequently mentioned entities.",
                    "label": 0
                },
                {
                    "sent": "And the bootstrapping approach can be used in situations in which.",
                    "label": 0
                },
                {
                    "sent": "Obtaining the large training set could be expensive and hard to accomplish.",
                    "label": 0
                },
                {
                    "sent": "The future directions involve the expansion of the datasets and we also researching the role for pronoun resolution in improving many results as well as any alternative sequence labeling techniques that have been proposed like conditional random fields and so on.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suicide two questions.",
                    "label": 0
                },
                {
                    "sent": "Once a general question because I'm gonna say something 2nd.",
                    "label": 0
                },
                {
                    "sent": "Extended series sentiment analysis and opinion mining.",
                    "label": 1
                },
                {
                    "sent": "The same sort of thing or different ways of looking sentiment analysis.",
                    "label": 0
                },
                {
                    "sent": "This is saving feature.",
                    "label": 0
                },
                {
                    "sent": "You have sent him an analysis.",
                    "label": 0
                },
                {
                    "sent": "Actually, I admit the background a little bit.",
                    "label": 0
                },
                {
                    "sent": "The opinion mining can be divided into two categories.",
                    "label": 0
                },
                {
                    "sent": "The first is the document level and the 2nd is a feature level.",
                    "label": 0
                },
                {
                    "sent": "So sentiment analysis is the term is used in the document level, appending mining.",
                    "label": 0
                },
                {
                    "sent": "So basically the task of sentiment analysis currently is your determine if this whole document is positive or negative, right so?",
                    "label": 0
                },
                {
                    "sent": "Like a movie review, you decide all this reviewer expresses are positive opinion on this movie or not.",
                    "label": 0
                },
                {
                    "sent": "So it's the document level, so the granularity would be larger.",
                    "label": 0
                },
                {
                    "sent": "However, this feature level opinion mining is kind of capturing the finer granularity about the exact entities so they're focused on how.",
                    "label": 0
                },
                {
                    "sent": "These entities are commented on by each review and the polarity of these openings, but the one thing you are right, so they're both handling the polarity so positive or negative.",
                    "label": 0
                },
                {
                    "sent": "The difference is the granularity.",
                    "label": 0
                },
                {
                    "sent": "So here what I'm talking about is about the feature level and the sentiment analysis.",
                    "label": 0
                },
                {
                    "sent": "This term actually is used in language domain is about the document level in in a larger scope.",
                    "label": 0
                },
                {
                    "sent": "Does this mean if you want extended beyond, cameras are going to have to train your system?",
                    "label": 0
                },
                {
                    "sent": "Like if you want for washing machines and 1%?",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "It's a very good question.",
                    "label": 0
                },
                {
                    "sent": "We are also considering this that you are mentioning are domain specific or independent domains.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so actually in 2004 the quality papers that are very famous author.",
                    "label": 0
                },
                {
                    "sent": "I mean it's very very very good professor.",
                    "label": 0
                },
                {
                    "sent": "He's doing the opinion mining and he used Association rule mining which I think is a very generalized model which means the domain independent.",
                    "label": 1
                },
                {
                    "sent": "So however the machine learning until now I still haven't.",
                    "label": 0
                },
                {
                    "sent": "Go to idea about how make how to make the system to cross domain.",
                    "label": 0
                },
                {
                    "sent": "I mean how to make it you know to.",
                    "label": 0
                },
                {
                    "sent": "To to to omit the step of the training.",
                    "label": 1
                },
                {
                    "sent": "Individual systems concerning each of the particular products.",
                    "label": 0
                },
                {
                    "sent": "So currently we still ask some people who are really good at cameras that they like two different brands of cameras, so they did the tagging step.",
                    "label": 0
                },
                {
                    "sent": "But I still think eventually the machine learning strategy should be able to.",
                    "label": 0
                },
                {
                    "sent": "Or we can design a way to make it to perform in a cross domain manner.",
                    "label": 0
                },
                {
                    "sent": "Looking for a system that takes 3, three reviews and fills out the summarizing review form.",
                    "label": 0
                },
                {
                    "sent": "It was one more question.",
                    "label": 0
                },
                {
                    "sent": "You're especially using hidden Markov models for doing information extraction, and you're also integrating other source of information that are non independent.",
                    "label": 0
                },
                {
                    "sent": "So my question is why aren't you using conditional random fields which clearly superior to hidden model model for information extraction and have the benefit being discriminative of being able to learn essentially optimally from non independent source of information you mean according to random fields has the feature of learning independent domain?",
                    "label": 0
                },
                {
                    "sent": "No, sorry, integrate multiple features, multiple predictors which don't have to, with no assumption of independence.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, yeah, that's a good suggestion.",
                    "label": 0
                },
                {
                    "sent": "We are experimenting the conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "I think that's thank you for your suggestion.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's the also one of the future direction.",
                    "label": 0
                },
                {
                    "sent": "Time for one more question.",
                    "label": 0
                },
                {
                    "sent": "I have one more in the I didn't quite understand what you were measuring in the end in the evaluation.",
                    "label": 0
                },
                {
                    "sent": "And this is 4 fold cross validation and so so one camera was in the test set always.",
                    "label": 0
                },
                {
                    "sent": "Yeah, So what was then measured in?",
                    "label": 0
                },
                {
                    "sent": "What gives you a plus in both gives you aminos minus in this in this evaluation of this one camera.",
                    "label": 0
                },
                {
                    "sent": "The full form.",
                    "label": 0
                },
                {
                    "sent": "Secure the.",
                    "label": 0
                },
                {
                    "sent": "That's true, these easy manual labeling that step the experts will attack.",
                    "label": 0
                },
                {
                    "sent": "This is opening words that impressive said positive opinion.",
                    "label": 0
                },
                {
                    "sent": "The excellent as a positive opinion.",
                    "label": 0
                },
                {
                    "sent": "Battery life is a product feature.",
                    "label": 0
                },
                {
                    "sent": "Maybe all the focus is a product functionality.",
                    "label": 0
                },
                {
                    "sent": "So for about the for example the camera.",
                    "label": 0
                },
                {
                    "sent": "So this is the training data and is the truth data ground truth we consider for the tag tagging parts once.",
                    "label": 0
                },
                {
                    "sent": "Once the best classifier is obtained.",
                    "label": 0
                },
                {
                    "sent": "We use it to train the new incoming the test set.",
                    "label": 0
                },
                {
                    "sent": "We extract 1 camera at the testing camera.",
                    "label": 0
                },
                {
                    "sent": "Then we ask the classifier to tag it.",
                    "label": 0
                }
            ]
        }
    }
}