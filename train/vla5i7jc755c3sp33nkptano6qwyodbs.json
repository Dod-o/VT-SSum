{
    "id": "vla5i7jc755c3sp33nkptano6qwyodbs",
    "title": "Algorithm For Classification Of Textual Documents Represented By Tandem Analysis",
    "info": {
        "author": [
            "Jasminka Dob\u0161a, Faculty of Organization and Informatics, Varazdin, University of Zagreb"
        ],
        "published": "Dec. 1, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2014_dobsa_textual_documents/",
    "segmentation": [
        [
            "My topic is little bit different from the previous one, so originally I'm mathematician, so I'm interested in algorithms, mathematical algorithms, so the name of my presentation is algorithm for classification of textual documents represented by the analysis and coming from faculty organization and Informatics University of."
        ],
        [
            "Targeted so I'm going to give introduction in the topic presented.",
            "The aim of research description of algorithm, design of experiment and results and conclusion and further."
        ],
        [
            "Work.",
            "So in term document matrix documents are represented by terms which occur in the document.",
            "So sometimes these representations are not optimal due to the synonyms and Polish them.",
            "So the aim of dimensional dimensionality, reduction of original term document matrix is to represent documents in more compact way which could save memory space.",
            "Beat up some task, reduce effect of noise in the data and so on."
        ],
        [
            "So mad at the flat and semantic indexing is benchmark in that field, but it has some disadvantages in full full filling, the task of classification since its application could remove the structure of the classes in the collection of documents.",
            "So in this research, dimensional dimensionality reduction of original representation by turn document matrix is obtained sequentially in two steps in procedure.",
            "Called tandem analysis.",
            "So the first step in fact is LSI and the second step is motivated by this fact that we want to preserve that structure of classes in the data."
        ],
        [
            "So the aim is introduction of algorithm for classification of textual documents which is carried out in 2 steps.",
            "In first step classification is done by representations of in backwards and in second step classification is done by representations.",
            "In lower dimensional space obtained by Tentomon analysis.",
            "So representation of textual documents in the space of reduced dimension is also conducted in 2 steps.",
            "First step is representations, so documents are represented by metevelis side and in the next step this representations in LSI space are projected on the.",
            "On the columns of membership in matrix which defines membership of documents in classes."
        ],
        [
            "So notation, so we have turned document metrics.",
            "It's M by N where M is number of indexing.",
            "Tirman is number of documents in Collection, M is membership matrix.",
            "It's by K there is number of documents and K is number of classes in connection in the collection of documents.",
            "So the element of that matrix is 1.",
            "An IJ is 1 if document I belongs to class J or it's 0 address."
        ],
        [
            "So this is the procedure of dimension reduction.",
            "So at the 1st place we have megaverse representation is matrix of dimension N by N. Then we conduct SVD decomposition.",
            "Then we have LSI representation it's metric of dimension K by North.",
            "There K is usually much lower than M and then we project columns.",
            "Project data representation on columns of membership matrix.",
            "In the sense of least squares, and we obtain tandem analysis, representation and the resulting matrix is also of dimension K by N. Same dimension as LSI representation."
        ],
        [
            "So why do we conduct 2 steps of classification becausw so projection of LS representation of documents on the column space of membership matrix A is accomplished by solving the least square problem here this representation.",
            "Here we have representation in LSI.",
            "Space is membership matrix and Z is.",
            "Is the solution of the least square problem, so this this difference in Norm should achieve minimum?",
            "So the solution of the set problem it is now it's the sea of that form and the representation of documents in tandem analysis.",
            "Given by this matrix B."
        ],
        [
            "So for representation of document documents of train metrics, we use membership matrix M train.",
            "But for representation of test documents, we are not allowed to use membership metrics because we don't have.",
            "We could not use that inorganic phase.",
            "So this matrix M test is approximated by results of the first step of classification.",
            "So my original idea was this.",
            "This should be approximated by an OK in N. For example, it shouldn't be very very good.",
            "But it was so."
        ],
        [
            "That it is not like that.",
            "So I have used Reuters collection for experiment mode of the split.",
            "So I have removed stop words.",
            "Is the only that words appearing in more than four documents as indexing terms?",
            "So for classifications KNN algorithm with K is 10 and SVM algorithm is used in the first step and in the second step is only used SVM algorithm.",
            "LSI methods is conducted for K is 19 and representations obtained by 10 analysis also use LSI with case 19."
        ],
        [
            "So here are the results.",
            "So the first column represents F1 version measure for bag of words representation, SVM algorithm.",
            "The Second Orange column represents back averts representation K and an algorithm.",
            "K is then.",
            "A third column, Gray, is LSI.",
            "So SVM algorithm on LSI representations and the last two columns present the results of 1 measure for representation given by tandem analysis.",
            "So this 4th this yellow is suggest representation by tandem analysis.",
            "We're in the first step.",
            "First use K An algorithm with K is 10 and.",
            "In the last column that blue, I have modified that tandem analysis.",
            "So I have modified to the first step of classification.",
            "I will explain that later so we can see that the representation by backwards are the best, but we also can see that by tandem analysis we can improve results of classification in comparison to LSI methods.",
            "It's in the five classes out of 10.",
            "So this modification did not result with the better F1 measure.",
            "It has some effects on.",
            "Usually it resulted with battery core and lower precision."
        ],
        [
            "So modification is I called that method method Tak and 10 fuzzy becausw.",
            "I have used KNN algorithm and instead of categorical decision in the first step that some document is in the class or is not in the class I just use proportion of documents then and ears documents to some specific document which are in that class.",
            "So it would be 0.33 out of 10.",
            "The nearest documents are.",
            "I know that class.",
            "So this modification did not result in improvement of 1 measure, but it has some impact on recall.",
            "Usually, but."
        ],
        [
            "Evola comment this.",
            "More comprehensive in this case, where SVM issues used in both steps so we have results of precision recall and F1 version.",
            "For 10 large it's classes here we have big averts representations, tandem analysis representation, and we have also tandem analysis modified.",
            "Also, we don't not make categorical decision in the first step in that modified, but let's see what this happening here.",
            "What is interesting that the results obtained by bag of words representation and tandem analysis exactly the same precision, same recall, same F1 measure, same.",
            "But here in backwards we have representation but with almost 10,000 features.",
            "And here we have only night in features.",
            "So just it's just drill minery paper.",
            "I didn't use smaller number of LSI.",
            "Maybe I should try that too.",
            "Because let's tandem analysis inherits dimension from LSI.",
            "So this modification."
        ],
        [
            "I have just modified it.",
            "Prediction is that element of membership matrix MIK is 0.5.",
            "If the prediction is between between minus zero Point 6 and 0.6.",
            "Because maybe the classifier is not sure in which class if the document is in the class or is not in the class."
        ],
        [
            "So in the conclusion representations by documents by tandem analysis can improve performance of classification in comparison to LSI methods, I think that classification is not good.",
            "Good task for tandem analysis.",
            "Because this cause, as we saw in that results.",
            "That results, it looks like that results obtained by tandem analysis are limited by that first step of classification.",
            "So I think that.",
            "It would be better to try.",
            "The.",
            "To try with the information retrieval task or cross lingual information retrieval.",
            "And that in the future also algorithm of tandem analysis could be compared with algorithm of simultaneous performance of both dimension dimensionality reduction steps.",
            "Becausw LSI could deteriorate some and maybe some that the second step of tendam analysis could not could not improve that in this so.",
            "There are already algorithms which do that simultaneously so.",
            "That is, the next steps step in this research.",
            "That's it, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My topic is little bit different from the previous one, so originally I'm mathematician, so I'm interested in algorithms, mathematical algorithms, so the name of my presentation is algorithm for classification of textual documents represented by the analysis and coming from faculty organization and Informatics University of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Targeted so I'm going to give introduction in the topic presented.",
                    "label": 0
                },
                {
                    "sent": "The aim of research description of algorithm, design of experiment and results and conclusion and further.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "So in term document matrix documents are represented by terms which occur in the document.",
                    "label": 1
                },
                {
                    "sent": "So sometimes these representations are not optimal due to the synonyms and Polish them.",
                    "label": 1
                },
                {
                    "sent": "So the aim of dimensional dimensionality, reduction of original term document matrix is to represent documents in more compact way which could save memory space.",
                    "label": 1
                },
                {
                    "sent": "Beat up some task, reduce effect of noise in the data and so on.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So mad at the flat and semantic indexing is benchmark in that field, but it has some disadvantages in full full filling, the task of classification since its application could remove the structure of the classes in the collection of documents.",
                    "label": 1
                },
                {
                    "sent": "So in this research, dimensional dimensionality reduction of original representation by turn document matrix is obtained sequentially in two steps in procedure.",
                    "label": 0
                },
                {
                    "sent": "Called tandem analysis.",
                    "label": 0
                },
                {
                    "sent": "So the first step in fact is LSI and the second step is motivated by this fact that we want to preserve that structure of classes in the data.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the aim is introduction of algorithm for classification of textual documents which is carried out in 2 steps.",
                    "label": 1
                },
                {
                    "sent": "In first step classification is done by representations of in backwards and in second step classification is done by representations.",
                    "label": 0
                },
                {
                    "sent": "In lower dimensional space obtained by Tentomon analysis.",
                    "label": 0
                },
                {
                    "sent": "So representation of textual documents in the space of reduced dimension is also conducted in 2 steps.",
                    "label": 1
                },
                {
                    "sent": "First step is representations, so documents are represented by metevelis side and in the next step this representations in LSI space are projected on the.",
                    "label": 0
                },
                {
                    "sent": "On the columns of membership in matrix which defines membership of documents in classes.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So notation, so we have turned document metrics.",
                    "label": 0
                },
                {
                    "sent": "It's M by N where M is number of indexing.",
                    "label": 0
                },
                {
                    "sent": "Tirman is number of documents in Collection, M is membership matrix.",
                    "label": 1
                },
                {
                    "sent": "It's by K there is number of documents and K is number of classes in connection in the collection of documents.",
                    "label": 1
                },
                {
                    "sent": "So the element of that matrix is 1.",
                    "label": 0
                },
                {
                    "sent": "An IJ is 1 if document I belongs to class J or it's 0 address.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the procedure of dimension reduction.",
                    "label": 0
                },
                {
                    "sent": "So at the 1st place we have megaverse representation is matrix of dimension N by N. Then we conduct SVD decomposition.",
                    "label": 0
                },
                {
                    "sent": "Then we have LSI representation it's metric of dimension K by North.",
                    "label": 1
                },
                {
                    "sent": "There K is usually much lower than M and then we project columns.",
                    "label": 0
                },
                {
                    "sent": "Project data representation on columns of membership matrix.",
                    "label": 1
                },
                {
                    "sent": "In the sense of least squares, and we obtain tandem analysis, representation and the resulting matrix is also of dimension K by N. Same dimension as LSI representation.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why do we conduct 2 steps of classification becausw so projection of LS representation of documents on the column space of membership matrix A is accomplished by solving the least square problem here this representation.",
                    "label": 1
                },
                {
                    "sent": "Here we have representation in LSI.",
                    "label": 0
                },
                {
                    "sent": "Space is membership matrix and Z is.",
                    "label": 0
                },
                {
                    "sent": "Is the solution of the least square problem, so this this difference in Norm should achieve minimum?",
                    "label": 1
                },
                {
                    "sent": "So the solution of the set problem it is now it's the sea of that form and the representation of documents in tandem analysis.",
                    "label": 0
                },
                {
                    "sent": "Given by this matrix B.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for representation of document documents of train metrics, we use membership matrix M train.",
                    "label": 1
                },
                {
                    "sent": "But for representation of test documents, we are not allowed to use membership metrics because we don't have.",
                    "label": 0
                },
                {
                    "sent": "We could not use that inorganic phase.",
                    "label": 0
                },
                {
                    "sent": "So this matrix M test is approximated by results of the first step of classification.",
                    "label": 1
                },
                {
                    "sent": "So my original idea was this.",
                    "label": 0
                },
                {
                    "sent": "This should be approximated by an OK in N. For example, it shouldn't be very very good.",
                    "label": 0
                },
                {
                    "sent": "But it was so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That it is not like that.",
                    "label": 0
                },
                {
                    "sent": "So I have used Reuters collection for experiment mode of the split.",
                    "label": 0
                },
                {
                    "sent": "So I have removed stop words.",
                    "label": 0
                },
                {
                    "sent": "Is the only that words appearing in more than four documents as indexing terms?",
                    "label": 0
                },
                {
                    "sent": "So for classifications KNN algorithm with K is 10 and SVM algorithm is used in the first step and in the second step is only used SVM algorithm.",
                    "label": 1
                },
                {
                    "sent": "LSI methods is conducted for K is 19 and representations obtained by 10 analysis also use LSI with case 19.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results.",
                    "label": 0
                },
                {
                    "sent": "So the first column represents F1 version measure for bag of words representation, SVM algorithm.",
                    "label": 0
                },
                {
                    "sent": "The Second Orange column represents back averts representation K and an algorithm.",
                    "label": 0
                },
                {
                    "sent": "K is then.",
                    "label": 0
                },
                {
                    "sent": "A third column, Gray, is LSI.",
                    "label": 0
                },
                {
                    "sent": "So SVM algorithm on LSI representations and the last two columns present the results of 1 measure for representation given by tandem analysis.",
                    "label": 1
                },
                {
                    "sent": "So this 4th this yellow is suggest representation by tandem analysis.",
                    "label": 0
                },
                {
                    "sent": "We're in the first step.",
                    "label": 0
                },
                {
                    "sent": "First use K An algorithm with K is 10 and.",
                    "label": 0
                },
                {
                    "sent": "In the last column that blue, I have modified that tandem analysis.",
                    "label": 0
                },
                {
                    "sent": "So I have modified to the first step of classification.",
                    "label": 1
                },
                {
                    "sent": "I will explain that later so we can see that the representation by backwards are the best, but we also can see that by tandem analysis we can improve results of classification in comparison to LSI methods.",
                    "label": 0
                },
                {
                    "sent": "It's in the five classes out of 10.",
                    "label": 0
                },
                {
                    "sent": "So this modification did not result with the better F1 measure.",
                    "label": 0
                },
                {
                    "sent": "It has some effects on.",
                    "label": 0
                },
                {
                    "sent": "Usually it resulted with battery core and lower precision.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So modification is I called that method method Tak and 10 fuzzy becausw.",
                    "label": 0
                },
                {
                    "sent": "I have used KNN algorithm and instead of categorical decision in the first step that some document is in the class or is not in the class I just use proportion of documents then and ears documents to some specific document which are in that class.",
                    "label": 1
                },
                {
                    "sent": "So it would be 0.33 out of 10.",
                    "label": 0
                },
                {
                    "sent": "The nearest documents are.",
                    "label": 0
                },
                {
                    "sent": "I know that class.",
                    "label": 0
                },
                {
                    "sent": "So this modification did not result in improvement of 1 measure, but it has some impact on recall.",
                    "label": 1
                },
                {
                    "sent": "Usually, but.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evola comment this.",
                    "label": 0
                },
                {
                    "sent": "More comprehensive in this case, where SVM issues used in both steps so we have results of precision recall and F1 version.",
                    "label": 1
                },
                {
                    "sent": "For 10 large it's classes here we have big averts representations, tandem analysis representation, and we have also tandem analysis modified.",
                    "label": 0
                },
                {
                    "sent": "Also, we don't not make categorical decision in the first step in that modified, but let's see what this happening here.",
                    "label": 0
                },
                {
                    "sent": "What is interesting that the results obtained by bag of words representation and tandem analysis exactly the same precision, same recall, same F1 measure, same.",
                    "label": 1
                },
                {
                    "sent": "But here in backwards we have representation but with almost 10,000 features.",
                    "label": 0
                },
                {
                    "sent": "And here we have only night in features.",
                    "label": 0
                },
                {
                    "sent": "So just it's just drill minery paper.",
                    "label": 0
                },
                {
                    "sent": "I didn't use smaller number of LSI.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should try that too.",
                    "label": 0
                },
                {
                    "sent": "Because let's tandem analysis inherits dimension from LSI.",
                    "label": 0
                },
                {
                    "sent": "So this modification.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have just modified it.",
                    "label": 0
                },
                {
                    "sent": "Prediction is that element of membership matrix MIK is 0.5.",
                    "label": 0
                },
                {
                    "sent": "If the prediction is between between minus zero Point 6 and 0.6.",
                    "label": 0
                },
                {
                    "sent": "Because maybe the classifier is not sure in which class if the document is in the class or is not in the class.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the conclusion representations by documents by tandem analysis can improve performance of classification in comparison to LSI methods, I think that classification is not good.",
                    "label": 1
                },
                {
                    "sent": "Good task for tandem analysis.",
                    "label": 0
                },
                {
                    "sent": "Because this cause, as we saw in that results.",
                    "label": 0
                },
                {
                    "sent": "That results, it looks like that results obtained by tandem analysis are limited by that first step of classification.",
                    "label": 0
                },
                {
                    "sent": "So I think that.",
                    "label": 0
                },
                {
                    "sent": "It would be better to try.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "To try with the information retrieval task or cross lingual information retrieval.",
                    "label": 0
                },
                {
                    "sent": "And that in the future also algorithm of tandem analysis could be compared with algorithm of simultaneous performance of both dimension dimensionality reduction steps.",
                    "label": 1
                },
                {
                    "sent": "Becausw LSI could deteriorate some and maybe some that the second step of tendam analysis could not could not improve that in this so.",
                    "label": 0
                },
                {
                    "sent": "There are already algorithms which do that simultaneously so.",
                    "label": 0
                },
                {
                    "sent": "That is, the next steps step in this research.",
                    "label": 0
                },
                {
                    "sent": "That's it, thank you.",
                    "label": 0
                }
            ]
        }
    }
}