{
    "id": "3pqlgzbl5bqv7lrtfxmneoarwqze5alk",
    "title": "The Catch-Up Phenomenon in Bayesian Inference",
    "info": {
        "author": [
            "Peter Gr\u00fcnwald, Centrum Wiskunde & Informatica (CWI)"
        ],
        "published": "July 30, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/uai08_grunwald_cup/",
    "segmentation": [
        [
            "So first of all, I would like to thank the organizers of Fuying for inviting me here.",
            "It's really an honor to be here.",
            "So this is joint work with my students Tim Stephen and voucher or also in this room.",
            "And this is 1 talk where there is a picture which says at all.",
            "So I'm not referring to the ketchup bottle.",
            "That's just to remember the title of this talk, but graph here.",
            "So if at some point you don't follow anymore, you fall asleep or whatever when this graph comes up, wake up, because if you understand this graph then you understood the essence of this talk."
        ],
        [
            "Talk about model selection, so I guess we're all familiar with the setting.",
            "You have some data, for example points in a plane.",
            "You want to find some function which relates the X data to the Y data here.",
            "Very simple approach is to do least squares with straight lines."
        ],
        [
            "So then you would get a line like this, but maybe you want to be more ambitious, because if you look at this line it might catch some of the trend in the data, but perhaps not all of the trends.",
            "So maybe you want to learn a function from a larger space.",
            "Let's say the space of polynomials of arbitrary degree, but then you run into the problem of overfitting, because if you have a polynomial of.",
            "If you have N data points, there's always a polynomial of degree N which goes exactly through these points in which has squared error zero.",
            "So if you just pick the polynomial which best fits the data."
        ],
        [
            "Longest of all polynomials you will pick something like this, which may work very well on your training set, but will probably generalize very badly if you use it to predict future data.",
            "Probably probably the predictions will be very bad, so in model selection problems you are."
        ],
        [
            "Usually interested in some kind of tradeoff between goodness of fit and complexity.",
            "So in this example want something like this a third degree polynomial which doesn't go exactly through all the points, but which is reasonably close and which is also reasonably smooth.",
            "So somehow you want to trade off smoothness, perhaps degree of the polynomial, and how well it fits the data.",
            "That's the general setting, but of course you can apply this not only to pollen."
        ],
        [
            "Almost, but to me."
        ],
        [
            "Any other settings as well.",
            "And in general, suppose just that data sequence Y12Y N. And we want to know.",
            "Playing a set of candidate models best fits our data best, explains our data, not best fits our data.",
            "So in this talk I look at several examples of this.",
            "And invariably for simplicity, I'll assume that all the models are parametric.",
            "So each sub model can be described as a set family of probability distributions paralyzed, parametrised by some Theta in Euclidean space.",
            "OK. OK. Um so, and I also assume that all these models are probability sets of probability distribution.",
            "So to get the polynomials into that framework, I'll have to make some probabilistic additional assumptions.",
            "The standard assumption is of course that you assume that errors are normally distributed, then a set of K degree polynomials becomes a set of.",
            "Conditional distributions for Y given X with K parameters.",
            "But you could also do model section for example to learn not just the parameters of a Gaussian mixture, but the number of components of the mixture.",
            "Or if your data is for example text, you might want to learn some Markov chain to predict future text, and you might want to do model selection to find the order of the.",
            "Best Markov chain.",
            "Or you might want to learn the number of bins in a histogram.",
            "For your data and of course there are many other examples as well."
        ],
        [
            "So in general model selection method.",
            "Is defined here simply as a function from data sequences to models or other indices of models?",
            "So.",
            "I'll always denote model selection methods by K. Hat so K head is a function to data of arbitrary length and K head of white to the NY 12.",
            "N is simply the model chosen.",
            "Your method for the particular data I."
        ],
        [
            "No.",
            "In statistics, there is a long going discussion about various methods for model selection.",
            "Of course there are many, many methods for doing model selection, which is called the AIC Bics dilemma.",
            "And to explain what it is, our first talk only about AIC MBC.",
            "Two particular model selection methods.",
            "And then I'll generalize to other methods.",
            "So AIC is one of the oldest model selection methods still in use.",
            "The Akaike information criterion.",
            "And it simply works by picking the model for the given data.",
            "Such that.",
            "The minus log of the probability of the data according to the maximum likelihood.",
            "The best fitting distribution within the model.",
            "Plus, a complexity penalty is minimized, so you don't just pick the best fitting model that would be without the K term, which you add a term which depends on the number of parameters, and it's a very simple term.",
            "It's just the number of parameters key.",
            "So this is what AIC does and clearly.",
            "If a model gets more complex, it will usually fit the data better.",
            "But maybe you will select still not very complex model because of this penalty K right?",
            "So the first term gets smaller if K gets larger because.",
            "The probability of the data according to maximum likelihood gets larger and the second term gets larger as you get more.",
            "As you increase the number of parameters.",
            "Now another method is the so-called BICS type method.",
            "The basic information criterion and this tells you to select the model which minimizes the minus log probability of the data according to the best fitting distribution in the model plus K over to log in.",
            "So for large samples you see that if you look at the same K. You penalize a lot more with Bics then with AIC.",
            "Right, because the first term in this minus lock plus penalty usually grows linearly in N, the second term in the BICS type grows logarithmically.",
            "So for fixed K it will be a lot larger at some point with BICS then with AIC, where it doesn't grow with N at all.",
            "So you might expect by and large this is what happens, at least for large samples that be.",
            "Icy tends to select simpler models with less parameters and AIC, and this is indeed what happens."
        ],
        [
            "And now in machine learning there this discussion has never been so strong.",
            "But if you look at applied statistics an at Sciences which use a lot of statistics like biology or experimental psychology, you see that there's been an ongoing discussion of whether you should use AIC or be icy.",
            "And it has far from being resolved.",
            "Now, of course, in practice, both ACM."
        ],
        [
            "Yes, you are very crude.",
            "And in fact they can be thought of as summations to more sophisticated procedures, which are a lot more well known in the machine learning community.",
            "AIC.",
            "Is behaves very much like leave one out cross validation and BSE has been actually been derived as an approximation to base factor model selection which is based in models.",
            "And if you look at the essence behavior of these two methods, I already indicated that they are different.",
            "But essentially, for most model selection methods that are used in practice as synthetically, they fall in either one of these two categories, maybe for small samples they are much better than both AC MBC.",
            "But for large samples they either behave just like AIC or just like bye see.",
            "Cross Validation is a bit like a. I see an base factor.",
            "Model selection is more or less like BICS.",
            "So what's the diff?"
        ],
        [
            "From one point of view, the BSE type methods are.",
            "Very mild conditions in the models.",
            "They are consistent.",
            "So what does it mean?",
            "It means that if your data is actually sampled from a distribution in one of your models.",
            "Then if you use, be icy or base.",
            "Given enough data, you will actually identify that model and you will keep selecting that model no matter how much more data you get.",
            "So you identify the right model, which is the smallest model in your set of models containing the true distribution.",
            "AIC does not have that property, neither does leave one out cross validation.",
            "It may, with positive probability, keep selecting an overly complex model even in the limit of infinite data.",
            "So statisticians say it's inconsistent.",
            "So that's from one point of view, but you can also look at the behavior of model selection methods in another way."
        ],
        [
            "Namely, you can look at how well they behave if you use them to predict future data from the same source.",
            "So what you do then?",
            "It's a two stage process.",
            "First you use your model selection criterion to select the model.",
            "Then within the model you select it.",
            "You use some kind of estimator, or maybe an average over the distributions in your model, like in base to come up with a prediction.",
            "And then the question, how good are these predictions?",
            "Well, if you measure performance in that way, it turns out that under mild conditions on the models, AIC methods are for large samples at least better than BICS type methods, so their predictions converge at the optimal rate.",
            "So this means that if you compare the quality of the predictions to the predictions that somebody can make who knows the true underlying distributions.",
            "Clearly your predictions will be worse because you don't know the true underlying distributions.",
            "But as you get more and more data, your predictions will get better and better.",
            "And the rate at which they converge to optimal is.",
            "Better for AIC then for BICS.",
            "Essentially for AIC you get the optimal rates as syntactically no procedure can learn faster in terms of prediction.",
            "For Bics, you're often off by a log factor."
        ],
        [
            "So the question is there what methods to select?",
            "Should we do based on model selection or model averaging?",
            "On the one hand or leave one out cross validation ASP on the other hand?",
            "This is been an open question for a long time and what we're going to do in this talk I'm going to present a method which has both properties so it's both consistent and it's optimal in terms of predicted performance and what makes this interesting is that actually there have been several papers which suggests that such a method cannot exist, but we show that it does exist.",
            "So before I explain the method to you, I'll first explain with a bit more concrete detail what I mean by consistency and prediction."
        ],
        [
            "Convergence rate.",
            "And I use histograms as an example.",
            "So suppose there is some distribution.",
            "We don't know what it is and data ID from the distribution and all data points fall on the unit interval there between zero and one.",
            "Now we want.",
            "Using histograms of some with K, so we assume that all bins have the same with.",
            "We try to determine the optimal number of bins K based on the data.",
            "So this is like a model selection problem where now the key term complexity is in bins.",
            "So the way to think of this.",
            "Is that you get more and more data from some density and here we made the data from a very smooth density on 01, which looks like this.",
            "So the probability of getting data near the boundaries here and one is much larger than the probability of getting something in the middle and you get more and more data, and then you model this data first.",
            "Let's do it with some fixed."
        ],
        [
            "Order histogram let's say a second order histogram.",
            "If we have the eight points here, then with the 2nd order histogram, your model of the data your fitted distribution will be something like this.",
            "You have two bins of equal size and the size of each bin.",
            "He put the frequency of observed points which fall in that bin.",
            "So if you use two bins here, you get a very bad approximation of the underlying distribution.",
            "If you use three bins, it's already somewhat better.",
            "And of course, if you use more and more bins, you get more and more data than you hope.",
            "That you will get a good approximation of this actual density, so you should again think of this as a probability density.",
            "So the height indicates how how dense the measure is.",
            "At that point.",
            "Now note that here.",
            "There are no points and still the value is not zero of this program.",
            "So why is that?",
            "Well?",
            "This is because when we."
        ],
        [
            "Fit.",
            "Gram and also uses predict future data.",
            "We use something what is common.",
            "We don't just put the bin size equal to the frequencies, but rather we use some smooth frequencies.",
            "And what we do is in each bin we put the number of points that fall in that bin plus one divided by the total number of sample points plus the number of bins.",
            "So you can think of this as Teleplus estimator, which is a smooth at maximum likelihood estimator.",
            "Anne.",
            "So the maximum likelihood estimator within the class of histograms with three bins would actually put all the probabilities equal to the frequencies.",
            "Smooth them a little bit.",
            "Another way to think of this is a basin estimator.",
            "If you put a uniform prior on all possible three bin histograms and then you calculate the basin predicted.",
            "Given the data, then you also get exactly this.",
            "Distribution is smooth at maximum likely distribution.",
            "So if we've learned a histogram from a data and we want to use it to predict future data, then we will use this distribution rather than the plain frequencies."
        ],
        [
            "So now what happens if we do model selection with histograms?",
            "If the data come from this smooth density, so we just did a simulation experiment where the data came from the density we got more and more data.",
            "Then you see that leaf went up cross validations.",
            "It's consistently more bins than Basin maximum posteriori, so the base model selection criterion here is you put some prior.",
            "It doesn't really matter which one on the number of bins, and then you pick.",
            "The number of bins which has met their probability given the date, and this is an average over 200,000 runs.",
            "That's why the curve looks relatively smooth and you see that.",
            "30 runs two, yeah, not 200,200 runs samples.",
            "The maximum sample size is 200,000.",
            "I was confused.",
            "So you see, for example, at sample size 100,000, that base selects about 50 bins and leave one out selects about 90 bins.",
            "So for both methods the number of been selected goes up with the sample size, which is what you would like because you cannot model our density, which looks like this with the number of bins because it's smooth, so it's a good thing that you select more and more, but you see that the rate at which more selected is different, very different from Leaf to base.",
            "And then the question is which method is better if you use it for prediction.",
            "But before I stayed at first, I should note that AIC in this example does almost the same as base.",
            "You see that the curves overlap if you use BICS, which is an approximation of a few select slightly less been some base, but the slope of the curve is exactly the same As for base."
        ],
        [
            "So now if you look at prediction.",
            "What we do is at each point in time, we first select a model using either base or leave for, not cross validation.",
            "Within the model we use this Laplace approximator to predict the next point and we record how good our predictions are.",
            "An re record it by the log loss.",
            "So if you don't know what the lock losses, I'll explain it in more detail later.",
            "Just think of it as a measure of how good the predictions are measured by how large the probability is that you assigned to the outcome, which actually happens.",
            "Then you see that leaf or not, cross validation is actually better.",
            "So know that this is the accumulated prediction error.",
            "So I always add the prediction error on the next point.",
            "That's why the curves increase the individual increase per point actually goes to zero as N increases.",
            "That's why the slope is why it's a concave function.",
            "So, but you see that if you add the errors, the total errors made by base.",
            "Are larger than the total errors made by leave one out cross validation and a difference actually gets larger and larger as you get a larger sample.",
            "So this illustrates that for prediction purposes, cross validation leave one out cross validation or AIC."
        ],
        [
            "Maybe better than base.",
            "And this is a general pattern.",
            "If the data are sampled from a distribution in one of your models, so the data doesn't come from the finite order his.",
            "But it comes from something in the closure.",
            "The boundary of your models.",
            "So this density, like any smooth density, is not a histogram, but you can approximate arbitrarily well by getting a sequence of histograms with more and more bits.",
            "So if the data comes from the boundary of your model space in that sense you can approximate it arbitrarily well, but it's not in your model space.",
            "Then typically leave one out cross validation, AIC little bit.",
            "Estimates of the underlying distributions, because they are probability distributions.",
            "So you can use them as estimate.",
            "If you look at the quality of the estimates, you also see that they converge to the true distribution at a faster rate than for base.",
            "Basically, let's less bins for a given sample size, and apparently it is not greedy enough.",
            "It is in a way too slow.",
            "It under fits and therefore you get less predictive performance.",
            "So does this mean leave one out cross validation is better in problems like this?"
        ],
        [
            "So that's not clear.",
            "Now we look at another problem.",
            "Where again we sampled from some other electrocution, but now it's a very simple distribution.",
            "It's a uniform distribution.",
            "So the uniform distribution actually is a histogram.",
            "It's a one bin histogram.",
            "The simplest histogram there is.",
            "Now if we get more and more data and we do Bayesian model selection."
        ],
        [
            "Only for not cross validation after I think 100.",
            "Is the sites that there's just one bin the maximum posteriori probability goes to the histograms with one bin and it stays there forever basis consistent, it is identified.",
            "However, leave for not cross validation.",
            "Account.",
            "It's an average of about two or two and a half, and if you look at individual runs you see that sometimes it gets it right, and sometimes it's even much higher than two.",
            "And even at sample size 200,000, it hasn't found out that there's just one bin.",
            "Solely for not cross validation is inconsistent here.",
            "The truth is in your model and it doesn't seem to find out now.",
            "Some people say that's irrelevant.",
            "We should only care about prediction and not about consistency.",
            "That may be true for histogram density estimation, but if you think of regression then consistency.",
            "Sometimes it's really important.",
            "For example, if you model Y as a function of all kinds of features X one X2X3, and often the question of interest is really like is Y dependent on X4 or not.",
            "And in General, leaf one out cross validation will not give you the correct answer to that question.",
            "Sometimes it may really be independent.",
            "You will not find out.",
            "So one thing I should add here.",
            "Is that all the graphs I've given?",
            "You are actually not for base model station but for basic model averaging, right?",
            "So it doesn't help if you do as you should do as a basic model, averaging just then selection with model selection.",
            "Things even get worse.",
            "Not much doesn't make."
        ],
        [
            "So what we do here is we do analysis of why based converges slower when.",
            "For prediction or estimation.",
            "It's well known why this happens.",
            "There's been a lot of research on that in the statistics community, but we look at it from a different angle.",
            "Which is this catch up phenomenon.",
            "This graph that will come up in a moment, which I showed you on the 1st slide.",
            "Then with."
        ],
        [
            "This new analysis we can define a modification of base.",
            "We changed the Bayesian approach a little bit so that we get something which is both consistent.",
            "It will select the one bin.",
            "Gram example, if that's the true distribution and it also converges optimal in terms of prediction and estimation."
        ],
        [
            "So Interestingly, there are some papers by philosophers who say that this is this may be impossible, and there's also a theoretical result which indicates that in some cases it may not be possible.",
            "Unfortunately, there's no time to go white.",
            "That result can coexist with ours, but it's really interesting.",
            "Computer scientist or mathematician?",
            "Young is a very good mathematician.",
            "These are lots of person.",
            "I'm not saying anything about their butts, so Young's result is definitely, but it's it's very subtle because he makes slightly different assumptions as we do and then you get something different.",
            "Anne.",
            "So and what's also nice is that actually our method can often be used in practice, so we can actually experiment with it and find out it.",
            "Also, in practice it performs well."
        ],
        [
            "So what I'm going to do in the remainder of this talk?",
            "First explain in more detail how Bayesian model selection works based factor model selection and I'm going to give it a predictive interpretation which will be important for understanding its predictive behavior.",
            "Then I'll discuss this catch up phenomenon why it's sometimes converges too slowly and this will lead to this modification of base which solves the CBSE question."
        ],
        [
            "So based sector model selection, how does it work?",
            "Well again you have to set of parametric models.",
            "An parameterized by some theater, which is a subset of the reals.",
            "And.",
            "What you do is you simply pick the model, forget data which maximizes the posterior probability of the model given the.",
            "So by Bayes rule, that's the probability of the data given the model times to prior divided by something which does not depend on the data.",
            "So the Pi is the prior on the model index.",
            "So now I'll introduce shorthand notation for this.",
            "Which will make things a lot easier to state.",
            "So by the Speedbar sub Kate I simply mean the probability of the data given the model.",
            "And in Bayesian inference, that is defined as the average probability of the data, averaged according to the prior.",
            "So these W sub K is the prior of Theta inside the Model M sub K. So this is the standard definition of Bayesian.",
            "Marginal probability of data given model.",
            "And what you want to do is you select the K which maximizes this, or equivalently maximizes this this product.",
            "So something went wrong here.",
            "I don't know what this is, but.",
            "This.",
            "Amounts to picking the K which minimizes the minus logarithm.",
            "Of course, maximizing this is minimizing the minus logarithm of the product, which is the same as minus logarithm of the probability of the data given the model minus logarithm of the prior.",
            "And typically in the applications were interested in the prior month, next doesn't really play any role.",
            "We usually looking at cases where for sample size and you only consider about 10 different models, let's say polynomials from degree one to N. And then this prior on Model N will be of size, let's say 1 / N ^2.",
            "So you get a two log N there and so the penalty in the model index induced by that is completely negligible compared to the penalty on high complexity models which are already implicit.",
            "By taking this average overall distributions in your model.",
            "So this base and model selection effectively amounts to picking the model which maximizes the marginal probability of your data, or minimizes the minus log marginal probability data."
        ],
        [
            "So here's the picture.",
            "What you did here is another experiment with very artificial.",
            "We took the picture of Dorian Gray by Oscar Wilde.",
            "And we presented consecutive symbols of that ASCII symbols to our learning algorithm.",
            "And then we get the base factor.",
            "So no base selects the model.",
            "If you ignore the priors, which we can do here such that the probability of the data according to the model is maximum.",
            "So this means that if the sample size.",
            "So, for example, sympathized.",
            "100,000 means that you've seen the first 100,000 outcomes of the non novel.",
            "The log of the probability ratio between the two models is about 20,000, so this means that.",
            "The the 1st order model the probability one model gives probability two to the minus 20,000 times.",
            "2 to 20,000 times as large as the 2nd order model, so the models were using here are first order Markov models and 2nd order Markov models.",
            "So P1 is the base and average for the 1st order Markov model.",
            "This means that the probability of symbol can depend only on the previous symbols.",
            "So essentially you have 256 squared parameters there.",
            "The 2nd order model.",
            "The probability of a symbol can depend on the previous two symbols, so then you have more than 56 to the cube parameters.",
            "Sorry.",
            "The one corresponds to the 1st order Markov model and P2 should correspond to the 2nd order marketing.",
            "Then the graph is actually for the log of the base, there's yes, yes, you're completely right.",
            "So thanks for telling me so.",
            "The P1 and P2 should be flipped here.",
            "On the next slide it will be OK.",
            "So what what you see here?",
            "So you can now it's OK.",
            "So what you see here is that so this should be P1.",
            "The probability of the 1st order that the 1st order Markov model assigns to data is much much larger two to the 20,000 times larger than the 2nd order Markov model.",
            "But then as you get more and more data it goes they become approximately equal here and then the 2nd order model wins and it keeps winning and winning and winning.",
            "This is what you would intuitively expect, because the 2nd order model has so many free parameters that you need a lot of data before you can approximate them well at all.",
            "In the beginning you have no idea what their values should be and then clearly the simpler model with less parameters will lead to better predictions because you already have enough data.",
            "To estimate these parameters reasonably well, but in the end, as you get more and more data, the 2nd order model.",
            "Extra cast capture a lot more of the structure in the data so it will start predicting better and that's why at some point it starts catching up an from 160,000 onwards it's overtakes the 1st order model, so if you do based on model selection you will select the 1st order model until 160,000 and then you will start selecting the 2nd order model.",
            "So from now on it will be useful not to write a fraction, but rather as the difference of two logarithms, which is of course the same.",
            "So then you can think of this curve as the minus logarithm of the probability according to second order minus the minus logarithm of probability according to first order."
        ],
        [
            "So come on in model selection here very common.",
            "We have a simple model in a more complex model.",
            "The simple model predicts better for small sample sizes.",
            "The complex model predicts better for large sample sizes, so we would actually hope that base start switching from the simple to the complex model at the point where the complex false starts predicting better.",
            "Is this the pointer based switches?",
            "Right?"
        ],
        [
            "Sing the base, which is at 70, seven, 60,000.",
            "But is this where we really want to switch?",
            "If you're interested in prediction and then we will see the answer is no, not at all.",
            "We have to switch somewhere else and in a moment you will see where we have to switch."
        ],
        [
            "And to explain that, I have to say."
        ],
        [
            "Something about."
        ],
        [
            "Basin prediction so.",
            "Note that if I do basing prediction, I have some parametric model that defines a probability of my data, which is the average overall distributions in the model.",
            "I can use that probability for the data to define predictions for the next.",
            "In the past just by using the rule of conditional probability.",
            "This is the probability of the next point given the past where these probabilities are defined like this.",
            "And an easy exercise shows that you can rewrite this as the probability of the next point given the past, according to Theatre, which is a distribution in your model average not by the prior but by the posterior.",
            "So you now take the posterior of the thetas given the data, which will.",
            "But at values of theater, which give a good fit to the past data, you average over the posterior.",
            "This gives your next prediction."
        ],
        [
            "No.",
            "Armed with this knowledge that this is what we do if we use base for prediction.",
            "You can look at.",
            "How well are these predictions?",
            "If you look at them in a sequential way?",
            "So if you measure prediction quality by log loss.",
            "Which is very convenient.",
            "It has a lot to do with them.",
            "Then you can see that the following happens, so load with log loss.",
            "The loss you get if you predict.",
            "Are you by issuing a probability distribution of all possible wife values?",
            "Now.",
            "Now if the value you assign to the actual outcome as you assign probability one outcome, then your loss is 0.",
            "If you assign probability 0 to the actual outcome, your loss is infinite and usually it will neither be 0 nor infinite will be something in between.",
            "The higher the probability assigned to the actual outcome, the smaller your loss.",
            "So this is kind of an intuitive loss function in this sense.",
            "Now with this loss function, if you look at what is the accumulative loss you make if you predict using base first, the first point and then you first point, you predict the second point, get the first point, then you start point given the first 2 points and so on.",
            "Then the sum of the loss you make.",
            "So that's the sum of these minus log of the probability of the next outcome given the past, because the sum of a logarithm is a log of a product, this is the minus log of the product of these probabilities.",
            "Now, using the rule of conditional probability that's minus log of this product.",
            "Now if you write out this product, you get N factors.",
            "An everything in these factors cancels because you can always cancel the denominator numerator with the I -- 1 denominator and in the end there's only one factor which doesn't cancel, which is the last one, so this will be equal to this the sum of the loss you make in sequential prediction is equal to the minus log probability you assign to the whole sample.",
            "This holds for every probability distribution you might use for prediction based on or not.",
            "It's a general rule if you use a distribution for prediction.",
            "Likelihood minus log likelihood you guess get for a sample is equal to the accumulated lock lock sample.",
            "This is."
        ],
        [
            "Something.",
            "So remember now if you please.",
            "See that with base and model selection we picked the model minimizing.",
            "We minimize the minus log probability of the data and we minimize over OK.",
            "So this means that we minimize.",
            "The total accumulated loss if we use the model for sequential prediction.",
            "So if we select use base based model selection to select between two parametric models, what we're essentially doing is we're looking at how model how well these models predict data.",
            "If we use them to predict sequentially predict the first point, then the second point given the first point, Third Point given the first 2 points and then we select the model such that the total loss we make when we Add all the losses is minimal.",
            "That's a predictive interpretation of base and model selection, which goes back to Phil David's paper on potential statistics in 1984 and written as predicted Amazon 1984 as well.",
            "And so if you think of it this way, basis actually rather similar to leave one out cross validation.",
            "The crucial difference is that in leave one out cross validation, if you predict the point you use all other sample points to come up with a fascinator to predict it, and you do that for all points and you add the losses.",
            "With base you always only predict the future given the past, and you don't use points further out in the future to come up with your estimator, but apart from that they are very."
        ],
        [
            "So now it is predicted interpretation space."
        ],
        [
            "We can explain this catch up phenomenon.",
            "So.",
            "Look at this graph again.",
            "This is the difference between the minus log probability according to the 2nd order model and the minus log probability according to the 1st order model."
        ],
        [
            "So with our new interpretation."
        ],
        [
            "This is the difference between the total loss we make.",
            "If we predict the data sequentially using base with the 2nd order Markov and the total loss we make.",
            "If we predict sequentially using base with the 1st order Markov model.",
            "Right, so this is a difference between two accumulated losses, and therefore we can measure it in units of log loss, which if you use binary logarithm, you can think of as bits if you don't know anything about data compression and you can forget it, just think of it as last units, but you can think of it as a difference between 2, some pluses."
        ],
        [
            "So if you think of it is the difference between these two losses.",
            "Then you realize that at this point where if you get a larger sample base starts to select the complex model.",
            "They have until now they have made the same total loss on the sample, right?",
            "If you have added all their prediction errors till sample size on 60 thousands the difference is 0 between their prediction errors.",
            "But if you look at the maximum of the curve, you see that there the 1st order model.",
            "Until then, has outperformed by 20,000 bits, so it has performed much better in prediction.",
            "So as you move as you get more data, you move from this point to this point.",
            "See that here the simple model.",
            "Is 20,000 bits better?",
            "In total.",
            "And here it's equally good.",
            "So the only way in this is in which this is possible is if in the meantime bass the complex model has outperformed a simple model by 20,000 bits right?",
            "First the 23rd, the simple model has gained a head start of 20,000.",
            "It was 20,000 loss units better.",
            "At some point they are equally good, so in the meantime, because we add these losses.",
            "The 2nd order must have been better by 20,000 units, otherwise you cannot get back to 0 again.",
            "So if we are interested in predicting as well as possible, we should realize that this is the point where the 2nd order model starts to break better if you use it for prediction of the future and not at this point.",
            "So base is too slow, it has to catch up first.",
            "The simple model gains a head start and then the complex model has to catch up with it head start before based based arts."
        ],
        [
            "In other words, base has kind of inertia.",
            "It switches to the complex model when it makes better predictions, but it does so too late."
        ],
        [
            "So now you might say, well, maybe if you don't select model averaging problem will be overcome, But the picture is it won't.",
            "It doesn't really make any difference.",
            "So the blue line here is the difference between predictions you get by basin model averaging put a uniform prior on the 1st order and 2nd order models.",
            "And you compared it again to the performance of the model, which is always taken to be the baseline.",
            "Then you see that in the beginning the base model average behaves exactly like the 1st order model.",
            "That's why this curve is 0 all the time, because it just does the same as the 1st order model, which is the baseline.",
            "And then at this point here it starts behaving very rapidly, exactly like the 2nd order model.",
            "So it hardly makes a difference, and the reason why it make hardly makes a difference.",
            "Whether you do selection or averaging is that for almost all sample points except those very close to here.",
            "If you look at the posterior probability of the 1st order and 2nd order model, their ratio is exponentially large.",
            "So therefore in the mixture, one of the two models plays no role whatsoever.",
            "You can simply throw it away.",
            "So the question is, maybe we can modify based somehow such that we do better and let it behaves like the black curve, so the black curve is what you would get if you would switch exactly at the right point."
        ],
        [
            "And the answer is that you can actually do that, or actually almost do that.",
            "You can be almost with the black curve.",
            "Which can be achieved by somebody who knows who has already seen the data and post.",
            "Are you actually want to?"
        ],
        [
            "So.",
            "We achieved this by changing base in African way.",
            "Modification of base distribution.",
            "So how does it work?",
            "Well, first we assume that we have some.",
            "Oracle tells us where we should switch, and later we abstract away from it.",
            "So suppose we want to switch at sample size S. Then the total prediction error we make is the prediction error we make by using Model 1 until sample size S and then from S + 1 to N, we use Model 2.",
            "So that is if you write out.",
            "Whoa.",
            "Something goes wrong.",
            "Sorry about that."
        ],
        [
            "Yes.",
            "So if we switch at this point S, we somehow know where it is.",
            "Then this is the error we make.",
            "These are the losses and we can rewrite this as the minus log probability we give using the 1st order model to the first as outcomes and then minus log probability we give according to the 2nd order model for the rest of the data.",
            "Now if we define a new distribution on sequences of length N just by taking the product of these, it's easy to check that if you sum this overall outcomes, you get one.",
            "So this defines a probability distribution.",
            "Then with this distribution our total prediction error will be.",
            "This minus logarithm of this, which is just this.",
            "So with.",
            "If we use this distribution all the time, we predict optimally we switch at the optimal point.",
            "I think of this new distribution both as a prediction strategy used for sequential prediction, but also simply as a distribution of sequences of length N. It's again by switching back and forth between prediction strategies looking at accumulated loss and distributions."
        ],
        [
            "So no, of course we know this point S where we should switch.",
            "Let me know it afterwards.",
            "So how can we do about as well as if we would know the point?",
            "Without really knowing it well, we do this innovation way.",
            "We adopt Sebacean solution to Bashan, problem, so we want some distribution which we can use as a prediction strategy, just such that no matter what data we observe, no matter where the optimal switchpoint is, we perform about as well as if we would do it in advance.",
            "So.",
            "We can do that.",
            "By thinking of this as a parameter and putting appr."
        ],
        [
            "Fire on it.",
            "And then integrating it out.",
            "So what we'll do?",
            "To put a flat prior on the point where to switch.",
            "And then we define the switch distribution as the average of the switch distribution, which you get if you switch it point S, which would be optimal if S would be the optimal point to switch.",
            "Averaged over all possible switch points.",
            "And now you get to the crucial inside of this talk.",
            "If you do this.",
            "If you look at the total prediction error remake, because as we know this is the total prediction error we make if we use this distribution for prediction, it's minus log of this sum by definition.",
            "So sum is larger or equal in each of its terms.",
            "So minus log of the sum is smaller equal in each of its terms in, particularly, is smaller or equal and minus log of the.",
            "Error we make if we switch up the optimal point plus some overhead.",
            "If we use a flat prior like this then the overhead is about so this is about 1 / S squared, so this will be about 2 log S. So this distribution performs as well as the distribution which which is the optimal point plus an overhead which is logarithmic.",
            "In the sample size where you should switch optimally.",
            "So."
        ],
        [
            "What happens if you use this?",
            "Um, for the Markov chain example.",
            "As we know, if we would switch at the optimal point we could gain 20,000 bits over base and predictive performance.",
            "Because the size of this maximum is 20,000.",
            "So this new distribution, which averages overall switch points.",
            "We use it for prediction.",
            "It will be as good as this optimal point, which gains 20,000 plus an overhead which will be about 32, because the optimal switchpoint is at sample size, about 50,000.",
            "So the overhead you get.",
            "Compared to knowing the point in advance is almost nil."
        ],
        [
            "Gible and if you draw the two pictures for knowing the overhead in advance and using the switch distribution, which averages you see no difference, so now we predict as well as the black curve compared to the 1st order model, and we do much better than base."
        ],
        [
            "So no, I've told this to you.",
            "I can use this to solve the AI CBSE dilemma."
        ],
        [
            "And to do that, I first need to extend this not to two models, but to more than two models.",
            "Because notify, use two models that no matter how much data I get the gain I can make over base remains finite."
        ],
        [
            "But if I have more than two models, then the gain over base may increase every time I switch.",
            "If I switch earlier each time I switch, and in cases like the histogram examples where if I get more and more data I want to switch more and more often.",
            "In the limit infinitely often I may gain an infinite amount over base and we will see that that is actually what happens."
        ],
        [
            "So I know to find a multiswitch disk.",
            "Which works as follows.",
            "You put the prior now not on one switch point, but on a vector of switch points of arbitrary length.",
            "So first again, I assume that you know the points where you want to switch, so this is a vector of points he won the first time you switch to two.",
            "The second time you switch Anna Vector of model indices you want to switch."
        ],
        [
            "And now.",
            "Once you know the switching scenario, you can define a distribution which amounts to prediction strategy.",
            "Let's follow.",
            "This distribution is defined by until the first switchpoint you behave like model K0.",
            "That's what you use before the 1st."
        ],
        [
            "Then after that for switchpoint, you behave like K1.",
            "So the conditional probability of the next outcome given the past is given by this case."
        ],
        [
            "1.",
            "After the second switch point, you behave like K3, etc and now your new distribution for the whole sequence of data is defined as the product of these distributions.",
            "And you know, by this correspondence between accumulated loss and minus log likelihood that if you use this distribution for prediction, you will predict exactly as well as if you would have switched at this particular vector.",
            "Of course, in reality we don't know this vector."
        ],
        [
            "So again, we put a prior on it."
        ],
        [
            "And we can do this in various ways.",
            "Basically what we choose is a prior where we first put pressure on the number of points you switch, which goes down exponentially in the sample size.",
            "This is useful for computation.",
            "And then given this number of times we switch, we put a very flat prior.",
            "On the switch points and all the points you switch to.",
            "And we we get the final prior by multiplying all these individual priors.",
            "So this gives you a prior on all finite vectors of switching strategies.",
            "Between a finite number of models and define.",
            "The switch distribution for arbitrarily many models as the average probability of the data according to this prior over."
        ],
        [
            "Sing strategies.",
            "And now you can use basic theorem to get a posterior switching strategy given the data.",
            "And the posterior switching strategy.",
            "Can be used to come up with the maximum posterior model, so this is now the model which if you sum over given a sample size N if you some overall strategies.",
            "That's A at sample size and you should use case star.",
            "The probability of that particular strategy which says use case, start sample size N, then you get this probability and now you define a switching method for model selection as picking.",
            "For a given data thing which maximizes this, so this is not the most probable model given the data, but the most probable model to use for prediction at your given sample size given that."
        ],
        [
            "And now we get the first theorem, and there's no time to explain what it is.",
            "But The upshot is simply.",
            "Whenever it is consistent, then the switching distribution is consistent as well.",
            "They're very strong theorems going back to dupe 1949 saying that basis consistent on their wide variety circumstances.",
            "So for example, if data comes from this uniform distribution, one bin histogram, then the switch distribution will decide it's a one bin histogram.",
            "So that is consistency, so switching retains the nice property."
        ],
        [
            "The ICM base is consistent.",
            "And it also converges.",
            "That's the next result, so.",
            "If you want to do prediction or estimation based on model selection, you first have to do model selection.",
            "So for example with AIC and then within a multi select it you have to do some kind of estimation to come up with a prediction on the next point.",
            "An you can do that with AI."
        ],
        [
            "The maximum likelihood, for example.",
            "Or you can do it with Basin model averaging, where you first take the posterior over almost giving your data and then.",
            "You pick the base predictive distribution over all these models again and again.",
            "You get a prediction for the."
        ],
        [
            "Outcome or you can use the switch distribution right?",
            "Just by taking the conditional distribution of the next point given the past using the disk."
        ],
        [
            "Solution we just defined.",
            "Now if you look at the statistical risk of the switch distribution.",
            "Which is the expected distance between the true distribution which you don't know, which generates the data.",
            "And.",
            "Your estimate or prediction for the next outcome.",
            "We measured it here using."
        ],
        [
            "The older versions.",
            "Then we see that switching in general under mild conditions on the model achieves the minimax optimal rates, just like AIC, and not like BICS.",
            "So in a sense.",
            "It's optimal, so for example with histograms.",
            "If you take yours, your set of models, distributions which have a smooth density and a bounded first derivative so they can be arbitrarily well approximated by histograms, then the fastest risk you can achieve with any method at all overall distributions in that class is 1 / N to the one third.",
            "So that's how fast your risk goes to 0.",
            "And the risk of the switch distribution will go to zero equally fast.",
            "Where is the risk of base?",
            "Doesn't it's in general off by a factor of."
        ],
        [
            "Again.",
            "And I cheated error little, you should actually look at the sum of the risk.",
            "Another individual risks that's.",
            "That kind of day."
        ],
        [
            "Still.",
            "So the switch distribution is as fast as any other method at all, in particular as fast as leave one out, CrossFit."
        ],
        [
            "Nation.",
            "So we resolved KSEB.",
            "I see the lemma theorem says we do theory, but."
        ],
        [
            "Turns out we also do this in practice.",
            "Yes, in many cases we can actually do this.",
            "Compute this in practice and the reason we can is that, of course, if you think of this prior, it looks incredibly complicated.",
            "It's a prior over sequences of arbitrary length.",
            "But you can think of the model to use at each time.",
            "In fact, as a kind of expert you want to use for prediction and the expert is not observed.",
            "So you can think of it as a state in a hidden Markov model, and in fact our switch distribution.",
            "If it's a hidden Markov model and then you can use the forward algorithm to compute all predictions.",
            "So if you're interested in hidden Markov models and their extensions, and there have been several papers that I smell about that, then I'm going to make a little advertisement here.",
            "You should go to Walter: stop tomorrow, where he explains how you can do the implement.",
            "Things like this using hidden Markov models and the resulting algorithm is very similar to the tracking.",
            "The best expert algorithm by Herb Sandwich which was presented is called 10 years ago.",
            "Indeed, we are also doing something like tracking the best model.",
            "Edit Sample size each model is an expert.",
            "So."
        ],
        [
            "We are working on applying this to nonparametric density estimation, but of course you could also do regression or time series prediction and I hope to challenge some of you into trying this out."
        ],
        [
            "For for example, regression.",
            "Final remark, the question is, is this basin or not?",
            "So for me it is.",
            "We use a basic algorithm.",
            "But if you from a subjective based in POV.",
            "There is something 10 years about the basin interpretation because the prior seems to indicate that we believe that the true model changes overtime, but we don't believe that.",
            "Actually, we believe that the data is governed by a fixed law, which changes the same all the time, but still, it's a good idea to change your predictions overtime.",
            "So the base and interpretation, let's say the filler."
        ],
        [
            "Civilization interpretation."
        ],
        [
            "Is tenuous.",
            "You can think of it as MDL though, because this is a clear data compression interpretation.",
            "However, nobody in MDF are sort of doing this, so that may be too much honor.",
            "For me as well, but what I would like to stress here.",
            "Is that I really feel this is a prick wenczel method, so the prick wenczel idea is this basic idea of thinking about probabilities as prediction strategies and log likelihoods as some of prediction error.",
            "Now if you take that idea to its limits, you arrive at the switch distribution and this idea goes back to 1984.",
            "But I think it still has a lot of unexplored potential and I hope to explore that first."
        ],
        [
            "In the future.",
            "So thank you very much.",
            "Sometimes it's subjective value.",
            "Not say what you've done is subjective.",
            "So you know, I think it's really good, and I think it's OK.",
            "But I can show you exactly where you claim, which shows as well the slide where you said that the true model is in the limit, right?",
            "So let me."
        ],
        [
            "Just so I have two basic objections here and one I don't like and the other I like.",
            "So this is a better base, an objection which actually says that if you think that rulers in the limit, you should use some parametric prior because you put prior probability 0 on that.",
            "So that is actually true.",
            "But there was no time to state this in detail, but actually so I do think it actually has a base and interpretation as well.",
            "What we have here is a kind of nonparametric prior.",
            "But it's just very different from the nonparametric priors that people have been using.",
            "And it's nice if you're frequentist as well, because I can give frequentist guarantees to how well this prior will work for prediction.",
            "But yes, I think you can think of this as nonparametric base.",
            "Yes, definitely.",
            "Coming back to your initial example of Instagram.",
            "The prior that you chose there had account run on each business essentially, and now if you have more more bins, you're actually putting more and more prior mass that would overcome the amount of data essentially, and I'm wondering whether the phenomena would be identical or slightly different if you use supplier that had some number.",
            "That was spread out evenly over K so that as he took the limit of.",
            "Police would converge something like.",
            "Processor.",
            "I it's a good.",
            "It's a good question, so my guess would be that that it gets better, but it doesn't disappear because you still put prior mass 0.",
            "On the distribution being out being not a finite histogram, so I think it wouldn't disappear and also the basically the theorems we have indicate that as soon as you use, let's say classical base vector prior.",
            "This just happens.",
            "You cannot get rid of it.",
            "On the other hand, it's clear that this effect would be alleviated if you would do something like this, so it might be worth trying it out actually.",
            "Yeah.",
            "Oh no, that's if I can immediately answer that.",
            "We multiply everything by N. So then in the structural risk minimization, you would multiply by square root of N rather than divide, so it's actually increases even faster than log, which was what we had here.",
            "Is it possible to make?",
            "There are the similar thing with their square loss.",
            "Yes, although it is nice, probably wouldn't look more haggard, but you would.",
            "I'm sure, for example, if you do this with regression then they are the same the logarithm.",
            "Get this cleared loss if you use fixed variance, so so one is the other times to fix variance, so then it would look exactly the same so.",
            "It may depend on the model, but for some models like regression models, you could definitely do it with the square files as well.",
            "Just buy some.",
            "Yeah.",
            "Well, you can use base independent of the loss function you use of course, but this.",
            "Think of the log likelihood as the sum of the prediction error that is unique to logarithmic loss, yes.",
            "But then yeah.",
            "So it looks like.",
            "Your picture want to find the stationary point of the function, which relates to losses or in general case you have a medical diagnosis losses.",
            "So the interesting question is you could have done a different way.",
            "You could look for their place where the deal with changes aside.",
            "That's how that would correspond to your switching distribution.",
            "I wonder, so I think actually that you can think of leave one out cross validation.",
            "You can recast it in those terms is trying to trying to estimate where this derivative is 0.",
            "So then basically, if you would do that, what would happen is you would get the optimal convergence rates, but you would not get consistency because for this basically the consistency is caused by very different effect which has something to do if you use base you.",
            "Well, it would be too long to discuss, but you would lose the consistency if you would do just that.",
            "That's cross validation is inconsistent, it it keeps selecting an overly.",
            "An complex model in if the true distribution is in there.",
            "Definitely is not equivalent to finding their optimal.",
            "No, it's not the same thing now."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, I would like to thank the organizers of Fuying for inviting me here.",
                    "label": 0
                },
                {
                    "sent": "It's really an honor to be here.",
                    "label": 0
                },
                {
                    "sent": "So this is joint work with my students Tim Stephen and voucher or also in this room.",
                    "label": 0
                },
                {
                    "sent": "And this is 1 talk where there is a picture which says at all.",
                    "label": 0
                },
                {
                    "sent": "So I'm not referring to the ketchup bottle.",
                    "label": 0
                },
                {
                    "sent": "That's just to remember the title of this talk, but graph here.",
                    "label": 0
                },
                {
                    "sent": "So if at some point you don't follow anymore, you fall asleep or whatever when this graph comes up, wake up, because if you understand this graph then you understood the essence of this talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk about model selection, so I guess we're all familiar with the setting.",
                    "label": 0
                },
                {
                    "sent": "You have some data, for example points in a plane.",
                    "label": 0
                },
                {
                    "sent": "You want to find some function which relates the X data to the Y data here.",
                    "label": 0
                },
                {
                    "sent": "Very simple approach is to do least squares with straight lines.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then you would get a line like this, but maybe you want to be more ambitious, because if you look at this line it might catch some of the trend in the data, but perhaps not all of the trends.",
                    "label": 0
                },
                {
                    "sent": "So maybe you want to learn a function from a larger space.",
                    "label": 0
                },
                {
                    "sent": "Let's say the space of polynomials of arbitrary degree, but then you run into the problem of overfitting, because if you have a polynomial of.",
                    "label": 0
                },
                {
                    "sent": "If you have N data points, there's always a polynomial of degree N which goes exactly through these points in which has squared error zero.",
                    "label": 0
                },
                {
                    "sent": "So if you just pick the polynomial which best fits the data.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Longest of all polynomials you will pick something like this, which may work very well on your training set, but will probably generalize very badly if you use it to predict future data.",
                    "label": 0
                },
                {
                    "sent": "Probably probably the predictions will be very bad, so in model selection problems you are.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Usually interested in some kind of tradeoff between goodness of fit and complexity.",
                    "label": 0
                },
                {
                    "sent": "So in this example want something like this a third degree polynomial which doesn't go exactly through all the points, but which is reasonably close and which is also reasonably smooth.",
                    "label": 0
                },
                {
                    "sent": "So somehow you want to trade off smoothness, perhaps degree of the polynomial, and how well it fits the data.",
                    "label": 0
                },
                {
                    "sent": "That's the general setting, but of course you can apply this not only to pollen.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Almost, but to me.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Any other settings as well.",
                    "label": 0
                },
                {
                    "sent": "And in general, suppose just that data sequence Y12Y N. And we want to know.",
                    "label": 1
                },
                {
                    "sent": "Playing a set of candidate models best fits our data best, explains our data, not best fits our data.",
                    "label": 1
                },
                {
                    "sent": "So in this talk I look at several examples of this.",
                    "label": 0
                },
                {
                    "sent": "And invariably for simplicity, I'll assume that all the models are parametric.",
                    "label": 0
                },
                {
                    "sent": "So each sub model can be described as a set family of probability distributions paralyzed, parametrised by some Theta in Euclidean space.",
                    "label": 0
                },
                {
                    "sent": "OK. OK. Um so, and I also assume that all these models are probability sets of probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So to get the polynomials into that framework, I'll have to make some probabilistic additional assumptions.",
                    "label": 0
                },
                {
                    "sent": "The standard assumption is of course that you assume that errors are normally distributed, then a set of K degree polynomials becomes a set of.",
                    "label": 0
                },
                {
                    "sent": "Conditional distributions for Y given X with K parameters.",
                    "label": 0
                },
                {
                    "sent": "But you could also do model section for example to learn not just the parameters of a Gaussian mixture, but the number of components of the mixture.",
                    "label": 0
                },
                {
                    "sent": "Or if your data is for example text, you might want to learn some Markov chain to predict future text, and you might want to do model selection to find the order of the.",
                    "label": 0
                },
                {
                    "sent": "Best Markov chain.",
                    "label": 1
                },
                {
                    "sent": "Or you might want to learn the number of bins in a histogram.",
                    "label": 0
                },
                {
                    "sent": "For your data and of course there are many other examples as well.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in general model selection method.",
                    "label": 0
                },
                {
                    "sent": "Is defined here simply as a function from data sequences to models or other indices of models?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'll always denote model selection methods by K. Hat so K head is a function to data of arbitrary length and K head of white to the NY 12.",
                    "label": 1
                },
                {
                    "sent": "N is simply the model chosen.",
                    "label": 0
                },
                {
                    "sent": "Your method for the particular data I.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "In statistics, there is a long going discussion about various methods for model selection.",
                    "label": 0
                },
                {
                    "sent": "Of course there are many, many methods for doing model selection, which is called the AIC Bics dilemma.",
                    "label": 0
                },
                {
                    "sent": "And to explain what it is, our first talk only about AIC MBC.",
                    "label": 0
                },
                {
                    "sent": "Two particular model selection methods.",
                    "label": 1
                },
                {
                    "sent": "And then I'll generalize to other methods.",
                    "label": 0
                },
                {
                    "sent": "So AIC is one of the oldest model selection methods still in use.",
                    "label": 0
                },
                {
                    "sent": "The Akaike information criterion.",
                    "label": 0
                },
                {
                    "sent": "And it simply works by picking the model for the given data.",
                    "label": 0
                },
                {
                    "sent": "Such that.",
                    "label": 0
                },
                {
                    "sent": "The minus log of the probability of the data according to the maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "The best fitting distribution within the model.",
                    "label": 0
                },
                {
                    "sent": "Plus, a complexity penalty is minimized, so you don't just pick the best fitting model that would be without the K term, which you add a term which depends on the number of parameters, and it's a very simple term.",
                    "label": 0
                },
                {
                    "sent": "It's just the number of parameters key.",
                    "label": 0
                },
                {
                    "sent": "So this is what AIC does and clearly.",
                    "label": 0
                },
                {
                    "sent": "If a model gets more complex, it will usually fit the data better.",
                    "label": 0
                },
                {
                    "sent": "But maybe you will select still not very complex model because of this penalty K right?",
                    "label": 0
                },
                {
                    "sent": "So the first term gets smaller if K gets larger because.",
                    "label": 0
                },
                {
                    "sent": "The probability of the data according to maximum likelihood gets larger and the second term gets larger as you get more.",
                    "label": 0
                },
                {
                    "sent": "As you increase the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "Now another method is the so-called BICS type method.",
                    "label": 0
                },
                {
                    "sent": "The basic information criterion and this tells you to select the model which minimizes the minus log probability of the data according to the best fitting distribution in the model plus K over to log in.",
                    "label": 0
                },
                {
                    "sent": "So for large samples you see that if you look at the same K. You penalize a lot more with Bics then with AIC.",
                    "label": 0
                },
                {
                    "sent": "Right, because the first term in this minus lock plus penalty usually grows linearly in N, the second term in the BICS type grows logarithmically.",
                    "label": 0
                },
                {
                    "sent": "So for fixed K it will be a lot larger at some point with BICS then with AIC, where it doesn't grow with N at all.",
                    "label": 0
                },
                {
                    "sent": "So you might expect by and large this is what happens, at least for large samples that be.",
                    "label": 0
                },
                {
                    "sent": "Icy tends to select simpler models with less parameters and AIC, and this is indeed what happens.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now in machine learning there this discussion has never been so strong.",
                    "label": 0
                },
                {
                    "sent": "But if you look at applied statistics an at Sciences which use a lot of statistics like biology or experimental psychology, you see that there's been an ongoing discussion of whether you should use AIC or be icy.",
                    "label": 0
                },
                {
                    "sent": "And it has far from being resolved.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, in practice, both ACM.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, you are very crude.",
                    "label": 0
                },
                {
                    "sent": "And in fact they can be thought of as summations to more sophisticated procedures, which are a lot more well known in the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "AIC.",
                    "label": 0
                },
                {
                    "sent": "Is behaves very much like leave one out cross validation and BSE has been actually been derived as an approximation to base factor model selection which is based in models.",
                    "label": 1
                },
                {
                    "sent": "And if you look at the essence behavior of these two methods, I already indicated that they are different.",
                    "label": 0
                },
                {
                    "sent": "But essentially, for most model selection methods that are used in practice as synthetically, they fall in either one of these two categories, maybe for small samples they are much better than both AC MBC.",
                    "label": 0
                },
                {
                    "sent": "But for large samples they either behave just like AIC or just like bye see.",
                    "label": 0
                },
                {
                    "sent": "Cross Validation is a bit like a. I see an base factor.",
                    "label": 1
                },
                {
                    "sent": "Model selection is more or less like BICS.",
                    "label": 0
                },
                {
                    "sent": "So what's the diff?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From one point of view, the BSE type methods are.",
                    "label": 0
                },
                {
                    "sent": "Very mild conditions in the models.",
                    "label": 0
                },
                {
                    "sent": "They are consistent.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "It means that if your data is actually sampled from a distribution in one of your models.",
                    "label": 0
                },
                {
                    "sent": "Then if you use, be icy or base.",
                    "label": 0
                },
                {
                    "sent": "Given enough data, you will actually identify that model and you will keep selecting that model no matter how much more data you get.",
                    "label": 0
                },
                {
                    "sent": "So you identify the right model, which is the smallest model in your set of models containing the true distribution.",
                    "label": 0
                },
                {
                    "sent": "AIC does not have that property, neither does leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "It may, with positive probability, keep selecting an overly complex model even in the limit of infinite data.",
                    "label": 0
                },
                {
                    "sent": "So statisticians say it's inconsistent.",
                    "label": 0
                },
                {
                    "sent": "So that's from one point of view, but you can also look at the behavior of model selection methods in another way.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Namely, you can look at how well they behave if you use them to predict future data from the same source.",
                    "label": 0
                },
                {
                    "sent": "So what you do then?",
                    "label": 0
                },
                {
                    "sent": "It's a two stage process.",
                    "label": 0
                },
                {
                    "sent": "First you use your model selection criterion to select the model.",
                    "label": 0
                },
                {
                    "sent": "Then within the model you select it.",
                    "label": 0
                },
                {
                    "sent": "You use some kind of estimator, or maybe an average over the distributions in your model, like in base to come up with a prediction.",
                    "label": 0
                },
                {
                    "sent": "And then the question, how good are these predictions?",
                    "label": 0
                },
                {
                    "sent": "Well, if you measure performance in that way, it turns out that under mild conditions on the models, AIC methods are for large samples at least better than BICS type methods, so their predictions converge at the optimal rate.",
                    "label": 0
                },
                {
                    "sent": "So this means that if you compare the quality of the predictions to the predictions that somebody can make who knows the true underlying distributions.",
                    "label": 0
                },
                {
                    "sent": "Clearly your predictions will be worse because you don't know the true underlying distributions.",
                    "label": 0
                },
                {
                    "sent": "But as you get more and more data, your predictions will get better and better.",
                    "label": 0
                },
                {
                    "sent": "And the rate at which they converge to optimal is.",
                    "label": 0
                },
                {
                    "sent": "Better for AIC then for BICS.",
                    "label": 0
                },
                {
                    "sent": "Essentially for AIC you get the optimal rates as syntactically no procedure can learn faster in terms of prediction.",
                    "label": 0
                },
                {
                    "sent": "For Bics, you're often off by a log factor.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question is there what methods to select?",
                    "label": 0
                },
                {
                    "sent": "Should we do based on model selection or model averaging?",
                    "label": 1
                },
                {
                    "sent": "On the one hand or leave one out cross validation ASP on the other hand?",
                    "label": 0
                },
                {
                    "sent": "This is been an open question for a long time and what we're going to do in this talk I'm going to present a method which has both properties so it's both consistent and it's optimal in terms of predicted performance and what makes this interesting is that actually there have been several papers which suggests that such a method cannot exist, but we show that it does exist.",
                    "label": 1
                },
                {
                    "sent": "So before I explain the method to you, I'll first explain with a bit more concrete detail what I mean by consistency and prediction.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convergence rate.",
                    "label": 0
                },
                {
                    "sent": "And I use histograms as an example.",
                    "label": 0
                },
                {
                    "sent": "So suppose there is some distribution.",
                    "label": 0
                },
                {
                    "sent": "We don't know what it is and data ID from the distribution and all data points fall on the unit interval there between zero and one.",
                    "label": 0
                },
                {
                    "sent": "Now we want.",
                    "label": 0
                },
                {
                    "sent": "Using histograms of some with K, so we assume that all bins have the same with.",
                    "label": 0
                },
                {
                    "sent": "We try to determine the optimal number of bins K based on the data.",
                    "label": 1
                },
                {
                    "sent": "So this is like a model selection problem where now the key term complexity is in bins.",
                    "label": 0
                },
                {
                    "sent": "So the way to think of this.",
                    "label": 0
                },
                {
                    "sent": "Is that you get more and more data from some density and here we made the data from a very smooth density on 01, which looks like this.",
                    "label": 0
                },
                {
                    "sent": "So the probability of getting data near the boundaries here and one is much larger than the probability of getting something in the middle and you get more and more data, and then you model this data first.",
                    "label": 0
                },
                {
                    "sent": "Let's do it with some fixed.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Order histogram let's say a second order histogram.",
                    "label": 0
                },
                {
                    "sent": "If we have the eight points here, then with the 2nd order histogram, your model of the data your fitted distribution will be something like this.",
                    "label": 0
                },
                {
                    "sent": "You have two bins of equal size and the size of each bin.",
                    "label": 0
                },
                {
                    "sent": "He put the frequency of observed points which fall in that bin.",
                    "label": 0
                },
                {
                    "sent": "So if you use two bins here, you get a very bad approximation of the underlying distribution.",
                    "label": 0
                },
                {
                    "sent": "If you use three bins, it's already somewhat better.",
                    "label": 0
                },
                {
                    "sent": "And of course, if you use more and more bins, you get more and more data than you hope.",
                    "label": 0
                },
                {
                    "sent": "That you will get a good approximation of this actual density, so you should again think of this as a probability density.",
                    "label": 0
                },
                {
                    "sent": "So the height indicates how how dense the measure is.",
                    "label": 0
                },
                {
                    "sent": "At that point.",
                    "label": 0
                },
                {
                    "sent": "Now note that here.",
                    "label": 0
                },
                {
                    "sent": "There are no points and still the value is not zero of this program.",
                    "label": 0
                },
                {
                    "sent": "So why is that?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "This is because when we.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fit.",
                    "label": 0
                },
                {
                    "sent": "Gram and also uses predict future data.",
                    "label": 0
                },
                {
                    "sent": "We use something what is common.",
                    "label": 0
                },
                {
                    "sent": "We don't just put the bin size equal to the frequencies, but rather we use some smooth frequencies.",
                    "label": 0
                },
                {
                    "sent": "And what we do is in each bin we put the number of points that fall in that bin plus one divided by the total number of sample points plus the number of bins.",
                    "label": 0
                },
                {
                    "sent": "So you can think of this as Teleplus estimator, which is a smooth at maximum likelihood estimator.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So the maximum likelihood estimator within the class of histograms with three bins would actually put all the probabilities equal to the frequencies.",
                    "label": 0
                },
                {
                    "sent": "Smooth them a little bit.",
                    "label": 0
                },
                {
                    "sent": "Another way to think of this is a basin estimator.",
                    "label": 0
                },
                {
                    "sent": "If you put a uniform prior on all possible three bin histograms and then you calculate the basin predicted.",
                    "label": 0
                },
                {
                    "sent": "Given the data, then you also get exactly this.",
                    "label": 0
                },
                {
                    "sent": "Distribution is smooth at maximum likely distribution.",
                    "label": 0
                },
                {
                    "sent": "So if we've learned a histogram from a data and we want to use it to predict future data, then we will use this distribution rather than the plain frequencies.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now what happens if we do model selection with histograms?",
                    "label": 0
                },
                {
                    "sent": "If the data come from this smooth density, so we just did a simulation experiment where the data came from the density we got more and more data.",
                    "label": 0
                },
                {
                    "sent": "Then you see that leaf went up cross validations.",
                    "label": 0
                },
                {
                    "sent": "It's consistently more bins than Basin maximum posteriori, so the base model selection criterion here is you put some prior.",
                    "label": 1
                },
                {
                    "sent": "It doesn't really matter which one on the number of bins, and then you pick.",
                    "label": 0
                },
                {
                    "sent": "The number of bins which has met their probability given the date, and this is an average over 200,000 runs.",
                    "label": 0
                },
                {
                    "sent": "That's why the curve looks relatively smooth and you see that.",
                    "label": 0
                },
                {
                    "sent": "30 runs two, yeah, not 200,200 runs samples.",
                    "label": 1
                },
                {
                    "sent": "The maximum sample size is 200,000.",
                    "label": 0
                },
                {
                    "sent": "I was confused.",
                    "label": 0
                },
                {
                    "sent": "So you see, for example, at sample size 100,000, that base selects about 50 bins and leave one out selects about 90 bins.",
                    "label": 0
                },
                {
                    "sent": "So for both methods the number of been selected goes up with the sample size, which is what you would like because you cannot model our density, which looks like this with the number of bins because it's smooth, so it's a good thing that you select more and more, but you see that the rate at which more selected is different, very different from Leaf to base.",
                    "label": 0
                },
                {
                    "sent": "And then the question is which method is better if you use it for prediction.",
                    "label": 0
                },
                {
                    "sent": "But before I stayed at first, I should note that AIC in this example does almost the same as base.",
                    "label": 0
                },
                {
                    "sent": "You see that the curves overlap if you use BICS, which is an approximation of a few select slightly less been some base, but the slope of the curve is exactly the same As for base.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now if you look at prediction.",
                    "label": 0
                },
                {
                    "sent": "What we do is at each point in time, we first select a model using either base or leave for, not cross validation.",
                    "label": 0
                },
                {
                    "sent": "Within the model we use this Laplace approximator to predict the next point and we record how good our predictions are.",
                    "label": 0
                },
                {
                    "sent": "An re record it by the log loss.",
                    "label": 0
                },
                {
                    "sent": "So if you don't know what the lock losses, I'll explain it in more detail later.",
                    "label": 0
                },
                {
                    "sent": "Just think of it as a measure of how good the predictions are measured by how large the probability is that you assigned to the outcome, which actually happens.",
                    "label": 0
                },
                {
                    "sent": "Then you see that leaf or not, cross validation is actually better.",
                    "label": 0
                },
                {
                    "sent": "So know that this is the accumulated prediction error.",
                    "label": 1
                },
                {
                    "sent": "So I always add the prediction error on the next point.",
                    "label": 0
                },
                {
                    "sent": "That's why the curves increase the individual increase per point actually goes to zero as N increases.",
                    "label": 0
                },
                {
                    "sent": "That's why the slope is why it's a concave function.",
                    "label": 0
                },
                {
                    "sent": "So, but you see that if you add the errors, the total errors made by base.",
                    "label": 0
                },
                {
                    "sent": "Are larger than the total errors made by leave one out cross validation and a difference actually gets larger and larger as you get a larger sample.",
                    "label": 0
                },
                {
                    "sent": "So this illustrates that for prediction purposes, cross validation leave one out cross validation or AIC.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe better than base.",
                    "label": 0
                },
                {
                    "sent": "And this is a general pattern.",
                    "label": 0
                },
                {
                    "sent": "If the data are sampled from a distribution in one of your models, so the data doesn't come from the finite order his.",
                    "label": 0
                },
                {
                    "sent": "But it comes from something in the closure.",
                    "label": 0
                },
                {
                    "sent": "The boundary of your models.",
                    "label": 0
                },
                {
                    "sent": "So this density, like any smooth density, is not a histogram, but you can approximate arbitrarily well by getting a sequence of histograms with more and more bits.",
                    "label": 0
                },
                {
                    "sent": "So if the data comes from the boundary of your model space in that sense you can approximate it arbitrarily well, but it's not in your model space.",
                    "label": 0
                },
                {
                    "sent": "Then typically leave one out cross validation, AIC little bit.",
                    "label": 0
                },
                {
                    "sent": "Estimates of the underlying distributions, because they are probability distributions.",
                    "label": 0
                },
                {
                    "sent": "So you can use them as estimate.",
                    "label": 0
                },
                {
                    "sent": "If you look at the quality of the estimates, you also see that they converge to the true distribution at a faster rate than for base.",
                    "label": 0
                },
                {
                    "sent": "Basically, let's less bins for a given sample size, and apparently it is not greedy enough.",
                    "label": 1
                },
                {
                    "sent": "It is in a way too slow.",
                    "label": 0
                },
                {
                    "sent": "It under fits and therefore you get less predictive performance.",
                    "label": 0
                },
                {
                    "sent": "So does this mean leave one out cross validation is better in problems like this?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's not clear.",
                    "label": 0
                },
                {
                    "sent": "Now we look at another problem.",
                    "label": 0
                },
                {
                    "sent": "Where again we sampled from some other electrocution, but now it's a very simple distribution.",
                    "label": 0
                },
                {
                    "sent": "It's a uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "So the uniform distribution actually is a histogram.",
                    "label": 1
                },
                {
                    "sent": "It's a one bin histogram.",
                    "label": 0
                },
                {
                    "sent": "The simplest histogram there is.",
                    "label": 0
                },
                {
                    "sent": "Now if we get more and more data and we do Bayesian model selection.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only for not cross validation after I think 100.",
                    "label": 0
                },
                {
                    "sent": "Is the sites that there's just one bin the maximum posteriori probability goes to the histograms with one bin and it stays there forever basis consistent, it is identified.",
                    "label": 0
                },
                {
                    "sent": "However, leave for not cross validation.",
                    "label": 0
                },
                {
                    "sent": "Account.",
                    "label": 0
                },
                {
                    "sent": "It's an average of about two or two and a half, and if you look at individual runs you see that sometimes it gets it right, and sometimes it's even much higher than two.",
                    "label": 0
                },
                {
                    "sent": "And even at sample size 200,000, it hasn't found out that there's just one bin.",
                    "label": 1
                },
                {
                    "sent": "Solely for not cross validation is inconsistent here.",
                    "label": 1
                },
                {
                    "sent": "The truth is in your model and it doesn't seem to find out now.",
                    "label": 0
                },
                {
                    "sent": "Some people say that's irrelevant.",
                    "label": 0
                },
                {
                    "sent": "We should only care about prediction and not about consistency.",
                    "label": 0
                },
                {
                    "sent": "That may be true for histogram density estimation, but if you think of regression then consistency.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's really important.",
                    "label": 0
                },
                {
                    "sent": "For example, if you model Y as a function of all kinds of features X one X2X3, and often the question of interest is really like is Y dependent on X4 or not.",
                    "label": 0
                },
                {
                    "sent": "And in General, leaf one out cross validation will not give you the correct answer to that question.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it may really be independent.",
                    "label": 0
                },
                {
                    "sent": "You will not find out.",
                    "label": 0
                },
                {
                    "sent": "So one thing I should add here.",
                    "label": 0
                },
                {
                    "sent": "Is that all the graphs I've given?",
                    "label": 0
                },
                {
                    "sent": "You are actually not for base model station but for basic model averaging, right?",
                    "label": 0
                },
                {
                    "sent": "So it doesn't help if you do as you should do as a basic model, averaging just then selection with model selection.",
                    "label": 0
                },
                {
                    "sent": "Things even get worse.",
                    "label": 0
                },
                {
                    "sent": "Not much doesn't make.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we do here is we do analysis of why based converges slower when.",
                    "label": 1
                },
                {
                    "sent": "For prediction or estimation.",
                    "label": 0
                },
                {
                    "sent": "It's well known why this happens.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of research on that in the statistics community, but we look at it from a different angle.",
                    "label": 0
                },
                {
                    "sent": "Which is this catch up phenomenon.",
                    "label": 0
                },
                {
                    "sent": "This graph that will come up in a moment, which I showed you on the 1st slide.",
                    "label": 0
                },
                {
                    "sent": "Then with.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This new analysis we can define a modification of base.",
                    "label": 0
                },
                {
                    "sent": "We changed the Bayesian approach a little bit so that we get something which is both consistent.",
                    "label": 0
                },
                {
                    "sent": "It will select the one bin.",
                    "label": 0
                },
                {
                    "sent": "Gram example, if that's the true distribution and it also converges optimal in terms of prediction and estimation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Interestingly, there are some papers by philosophers who say that this is this may be impossible, and there's also a theoretical result which indicates that in some cases it may not be possible.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there's no time to go white.",
                    "label": 0
                },
                {
                    "sent": "That result can coexist with ours, but it's really interesting.",
                    "label": 0
                },
                {
                    "sent": "Computer scientist or mathematician?",
                    "label": 0
                },
                {
                    "sent": "Young is a very good mathematician.",
                    "label": 0
                },
                {
                    "sent": "These are lots of person.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying anything about their butts, so Young's result is definitely, but it's it's very subtle because he makes slightly different assumptions as we do and then you get something different.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So and what's also nice is that actually our method can often be used in practice, so we can actually experiment with it and find out it.",
                    "label": 0
                },
                {
                    "sent": "Also, in practice it performs well.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'm going to do in the remainder of this talk?",
                    "label": 0
                },
                {
                    "sent": "First explain in more detail how Bayesian model selection works based factor model selection and I'm going to give it a predictive interpretation which will be important for understanding its predictive behavior.",
                    "label": 1
                },
                {
                    "sent": "Then I'll discuss this catch up phenomenon why it's sometimes converges too slowly and this will lead to this modification of base which solves the CBSE question.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So based sector model selection, how does it work?",
                    "label": 1
                },
                {
                    "sent": "Well again you have to set of parametric models.",
                    "label": 0
                },
                {
                    "sent": "An parameterized by some theater, which is a subset of the reals.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What you do is you simply pick the model, forget data which maximizes the posterior probability of the model given the.",
                    "label": 0
                },
                {
                    "sent": "So by Bayes rule, that's the probability of the data given the model times to prior divided by something which does not depend on the data.",
                    "label": 0
                },
                {
                    "sent": "So the Pi is the prior on the model index.",
                    "label": 0
                },
                {
                    "sent": "So now I'll introduce shorthand notation for this.",
                    "label": 0
                },
                {
                    "sent": "Which will make things a lot easier to state.",
                    "label": 0
                },
                {
                    "sent": "So by the Speedbar sub Kate I simply mean the probability of the data given the model.",
                    "label": 0
                },
                {
                    "sent": "And in Bayesian inference, that is defined as the average probability of the data, averaged according to the prior.",
                    "label": 0
                },
                {
                    "sent": "So these W sub K is the prior of Theta inside the Model M sub K. So this is the standard definition of Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Marginal probability of data given model.",
                    "label": 0
                },
                {
                    "sent": "And what you want to do is you select the K which maximizes this, or equivalently maximizes this this product.",
                    "label": 0
                },
                {
                    "sent": "So something went wrong here.",
                    "label": 0
                },
                {
                    "sent": "I don't know what this is, but.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Amounts to picking the K which minimizes the minus logarithm.",
                    "label": 0
                },
                {
                    "sent": "Of course, maximizing this is minimizing the minus logarithm of the product, which is the same as minus logarithm of the probability of the data given the model minus logarithm of the prior.",
                    "label": 0
                },
                {
                    "sent": "And typically in the applications were interested in the prior month, next doesn't really play any role.",
                    "label": 0
                },
                {
                    "sent": "We usually looking at cases where for sample size and you only consider about 10 different models, let's say polynomials from degree one to N. And then this prior on Model N will be of size, let's say 1 / N ^2.",
                    "label": 0
                },
                {
                    "sent": "So you get a two log N there and so the penalty in the model index induced by that is completely negligible compared to the penalty on high complexity models which are already implicit.",
                    "label": 0
                },
                {
                    "sent": "By taking this average overall distributions in your model.",
                    "label": 0
                },
                {
                    "sent": "So this base and model selection effectively amounts to picking the model which maximizes the marginal probability of your data, or minimizes the minus log marginal probability data.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the picture.",
                    "label": 0
                },
                {
                    "sent": "What you did here is another experiment with very artificial.",
                    "label": 0
                },
                {
                    "sent": "We took the picture of Dorian Gray by Oscar Wilde.",
                    "label": 1
                },
                {
                    "sent": "And we presented consecutive symbols of that ASCII symbols to our learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then we get the base factor.",
                    "label": 0
                },
                {
                    "sent": "So no base selects the model.",
                    "label": 0
                },
                {
                    "sent": "If you ignore the priors, which we can do here such that the probability of the data according to the model is maximum.",
                    "label": 0
                },
                {
                    "sent": "So this means that if the sample size.",
                    "label": 0
                },
                {
                    "sent": "So, for example, sympathized.",
                    "label": 0
                },
                {
                    "sent": "100,000 means that you've seen the first 100,000 outcomes of the non novel.",
                    "label": 0
                },
                {
                    "sent": "The log of the probability ratio between the two models is about 20,000, so this means that.",
                    "label": 0
                },
                {
                    "sent": "The the 1st order model the probability one model gives probability two to the minus 20,000 times.",
                    "label": 0
                },
                {
                    "sent": "2 to 20,000 times as large as the 2nd order model, so the models were using here are first order Markov models and 2nd order Markov models.",
                    "label": 0
                },
                {
                    "sent": "So P1 is the base and average for the 1st order Markov model.",
                    "label": 0
                },
                {
                    "sent": "This means that the probability of symbol can depend only on the previous symbols.",
                    "label": 0
                },
                {
                    "sent": "So essentially you have 256 squared parameters there.",
                    "label": 0
                },
                {
                    "sent": "The 2nd order model.",
                    "label": 0
                },
                {
                    "sent": "The probability of a symbol can depend on the previous two symbols, so then you have more than 56 to the cube parameters.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "The one corresponds to the 1st order Markov model and P2 should correspond to the 2nd order marketing.",
                    "label": 0
                },
                {
                    "sent": "Then the graph is actually for the log of the base, there's yes, yes, you're completely right.",
                    "label": 0
                },
                {
                    "sent": "So thanks for telling me so.",
                    "label": 0
                },
                {
                    "sent": "The P1 and P2 should be flipped here.",
                    "label": 0
                },
                {
                    "sent": "On the next slide it will be OK.",
                    "label": 0
                },
                {
                    "sent": "So what what you see here?",
                    "label": 0
                },
                {
                    "sent": "So you can now it's OK.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is that so this should be P1.",
                    "label": 0
                },
                {
                    "sent": "The probability of the 1st order that the 1st order Markov model assigns to data is much much larger two to the 20,000 times larger than the 2nd order Markov model.",
                    "label": 0
                },
                {
                    "sent": "But then as you get more and more data it goes they become approximately equal here and then the 2nd order model wins and it keeps winning and winning and winning.",
                    "label": 0
                },
                {
                    "sent": "This is what you would intuitively expect, because the 2nd order model has so many free parameters that you need a lot of data before you can approximate them well at all.",
                    "label": 0
                },
                {
                    "sent": "In the beginning you have no idea what their values should be and then clearly the simpler model with less parameters will lead to better predictions because you already have enough data.",
                    "label": 0
                },
                {
                    "sent": "To estimate these parameters reasonably well, but in the end, as you get more and more data, the 2nd order model.",
                    "label": 0
                },
                {
                    "sent": "Extra cast capture a lot more of the structure in the data so it will start predicting better and that's why at some point it starts catching up an from 160,000 onwards it's overtakes the 1st order model, so if you do based on model selection you will select the 1st order model until 160,000 and then you will start selecting the 2nd order model.",
                    "label": 0
                },
                {
                    "sent": "So from now on it will be useful not to write a fraction, but rather as the difference of two logarithms, which is of course the same.",
                    "label": 0
                },
                {
                    "sent": "So then you can think of this curve as the minus logarithm of the probability according to second order minus the minus logarithm of probability according to first order.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So come on in model selection here very common.",
                    "label": 0
                },
                {
                    "sent": "We have a simple model in a more complex model.",
                    "label": 1
                },
                {
                    "sent": "The simple model predicts better for small sample sizes.",
                    "label": 1
                },
                {
                    "sent": "The complex model predicts better for large sample sizes, so we would actually hope that base start switching from the simple to the complex model at the point where the complex false starts predicting better.",
                    "label": 1
                },
                {
                    "sent": "Is this the pointer based switches?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sing the base, which is at 70, seven, 60,000.",
                    "label": 0
                },
                {
                    "sent": "But is this where we really want to switch?",
                    "label": 0
                },
                {
                    "sent": "If you're interested in prediction and then we will see the answer is no, not at all.",
                    "label": 0
                },
                {
                    "sent": "We have to switch somewhere else and in a moment you will see where we have to switch.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to explain that, I have to say.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something about.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basin prediction so.",
                    "label": 0
                },
                {
                    "sent": "Note that if I do basing prediction, I have some parametric model that defines a probability of my data, which is the average overall distributions in the model.",
                    "label": 0
                },
                {
                    "sent": "I can use that probability for the data to define predictions for the next.",
                    "label": 0
                },
                {
                    "sent": "In the past just by using the rule of conditional probability.",
                    "label": 0
                },
                {
                    "sent": "This is the probability of the next point given the past where these probabilities are defined like this.",
                    "label": 0
                },
                {
                    "sent": "And an easy exercise shows that you can rewrite this as the probability of the next point given the past, according to Theatre, which is a distribution in your model average not by the prior but by the posterior.",
                    "label": 0
                },
                {
                    "sent": "So you now take the posterior of the thetas given the data, which will.",
                    "label": 0
                },
                {
                    "sent": "But at values of theater, which give a good fit to the past data, you average over the posterior.",
                    "label": 0
                },
                {
                    "sent": "This gives your next prediction.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Armed with this knowledge that this is what we do if we use base for prediction.",
                    "label": 0
                },
                {
                    "sent": "You can look at.",
                    "label": 0
                },
                {
                    "sent": "How well are these predictions?",
                    "label": 0
                },
                {
                    "sent": "If you look at them in a sequential way?",
                    "label": 0
                },
                {
                    "sent": "So if you measure prediction quality by log loss.",
                    "label": 1
                },
                {
                    "sent": "Which is very convenient.",
                    "label": 0
                },
                {
                    "sent": "It has a lot to do with them.",
                    "label": 0
                },
                {
                    "sent": "Then you can see that the following happens, so load with log loss.",
                    "label": 0
                },
                {
                    "sent": "The loss you get if you predict.",
                    "label": 0
                },
                {
                    "sent": "Are you by issuing a probability distribution of all possible wife values?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Now if the value you assign to the actual outcome as you assign probability one outcome, then your loss is 0.",
                    "label": 0
                },
                {
                    "sent": "If you assign probability 0 to the actual outcome, your loss is infinite and usually it will neither be 0 nor infinite will be something in between.",
                    "label": 0
                },
                {
                    "sent": "The higher the probability assigned to the actual outcome, the smaller your loss.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of an intuitive loss function in this sense.",
                    "label": 0
                },
                {
                    "sent": "Now with this loss function, if you look at what is the accumulative loss you make if you predict using base first, the first point and then you first point, you predict the second point, get the first point, then you start point given the first 2 points and so on.",
                    "label": 0
                },
                {
                    "sent": "Then the sum of the loss you make.",
                    "label": 0
                },
                {
                    "sent": "So that's the sum of these minus log of the probability of the next outcome given the past, because the sum of a logarithm is a log of a product, this is the minus log of the product of these probabilities.",
                    "label": 0
                },
                {
                    "sent": "Now, using the rule of conditional probability that's minus log of this product.",
                    "label": 0
                },
                {
                    "sent": "Now if you write out this product, you get N factors.",
                    "label": 0
                },
                {
                    "sent": "An everything in these factors cancels because you can always cancel the denominator numerator with the I -- 1 denominator and in the end there's only one factor which doesn't cancel, which is the last one, so this will be equal to this the sum of the loss you make in sequential prediction is equal to the minus log probability you assign to the whole sample.",
                    "label": 0
                },
                {
                    "sent": "This holds for every probability distribution you might use for prediction based on or not.",
                    "label": 0
                },
                {
                    "sent": "It's a general rule if you use a distribution for prediction.",
                    "label": 0
                },
                {
                    "sent": "Likelihood minus log likelihood you guess get for a sample is equal to the accumulated lock lock sample.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something.",
                    "label": 0
                },
                {
                    "sent": "So remember now if you please.",
                    "label": 0
                },
                {
                    "sent": "See that with base and model selection we picked the model minimizing.",
                    "label": 0
                },
                {
                    "sent": "We minimize the minus log probability of the data and we minimize over OK.",
                    "label": 0
                },
                {
                    "sent": "So this means that we minimize.",
                    "label": 0
                },
                {
                    "sent": "The total accumulated loss if we use the model for sequential prediction.",
                    "label": 1
                },
                {
                    "sent": "So if we select use base based model selection to select between two parametric models, what we're essentially doing is we're looking at how model how well these models predict data.",
                    "label": 0
                },
                {
                    "sent": "If we use them to predict sequentially predict the first point, then the second point given the first point, Third Point given the first 2 points and then we select the model such that the total loss we make when we Add all the losses is minimal.",
                    "label": 1
                },
                {
                    "sent": "That's a predictive interpretation of base and model selection, which goes back to Phil David's paper on potential statistics in 1984 and written as predicted Amazon 1984 as well.",
                    "label": 0
                },
                {
                    "sent": "And so if you think of it this way, basis actually rather similar to leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "The crucial difference is that in leave one out cross validation, if you predict the point you use all other sample points to come up with a fascinator to predict it, and you do that for all points and you add the losses.",
                    "label": 0
                },
                {
                    "sent": "With base you always only predict the future given the past, and you don't use points further out in the future to come up with your estimator, but apart from that they are very.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now it is predicted interpretation space.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can explain this catch up phenomenon.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Look at this graph again.",
                    "label": 0
                },
                {
                    "sent": "This is the difference between the minus log probability according to the 2nd order model and the minus log probability according to the 1st order model.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with our new interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the difference between the total loss we make.",
                    "label": 0
                },
                {
                    "sent": "If we predict the data sequentially using base with the 2nd order Markov and the total loss we make.",
                    "label": 0
                },
                {
                    "sent": "If we predict sequentially using base with the 1st order Markov model.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is a difference between two accumulated losses, and therefore we can measure it in units of log loss, which if you use binary logarithm, you can think of as bits if you don't know anything about data compression and you can forget it, just think of it as last units, but you can think of it as a difference between 2, some pluses.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you think of it is the difference between these two losses.",
                    "label": 0
                },
                {
                    "sent": "Then you realize that at this point where if you get a larger sample base starts to select the complex model.",
                    "label": 1
                },
                {
                    "sent": "They have until now they have made the same total loss on the sample, right?",
                    "label": 0
                },
                {
                    "sent": "If you have added all their prediction errors till sample size on 60 thousands the difference is 0 between their prediction errors.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the maximum of the curve, you see that there the 1st order model.",
                    "label": 0
                },
                {
                    "sent": "Until then, has outperformed by 20,000 bits, so it has performed much better in prediction.",
                    "label": 0
                },
                {
                    "sent": "So as you move as you get more data, you move from this point to this point.",
                    "label": 0
                },
                {
                    "sent": "See that here the simple model.",
                    "label": 0
                },
                {
                    "sent": "Is 20,000 bits better?",
                    "label": 0
                },
                {
                    "sent": "In total.",
                    "label": 0
                },
                {
                    "sent": "And here it's equally good.",
                    "label": 0
                },
                {
                    "sent": "So the only way in this is in which this is possible is if in the meantime bass the complex model has outperformed a simple model by 20,000 bits right?",
                    "label": 0
                },
                {
                    "sent": "First the 23rd, the simple model has gained a head start of 20,000.",
                    "label": 0
                },
                {
                    "sent": "It was 20,000 loss units better.",
                    "label": 0
                },
                {
                    "sent": "At some point they are equally good, so in the meantime, because we add these losses.",
                    "label": 0
                },
                {
                    "sent": "The 2nd order must have been better by 20,000 units, otherwise you cannot get back to 0 again.",
                    "label": 0
                },
                {
                    "sent": "So if we are interested in predicting as well as possible, we should realize that this is the point where the 2nd order model starts to break better if you use it for prediction of the future and not at this point.",
                    "label": 0
                },
                {
                    "sent": "So base is too slow, it has to catch up first.",
                    "label": 0
                },
                {
                    "sent": "The simple model gains a head start and then the complex model has to catch up with it head start before based based arts.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In other words, base has kind of inertia.",
                    "label": 0
                },
                {
                    "sent": "It switches to the complex model when it makes better predictions, but it does so too late.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now you might say, well, maybe if you don't select model averaging problem will be overcome, But the picture is it won't.",
                    "label": 1
                },
                {
                    "sent": "It doesn't really make any difference.",
                    "label": 0
                },
                {
                    "sent": "So the blue line here is the difference between predictions you get by basin model averaging put a uniform prior on the 1st order and 2nd order models.",
                    "label": 0
                },
                {
                    "sent": "And you compared it again to the performance of the model, which is always taken to be the baseline.",
                    "label": 0
                },
                {
                    "sent": "Then you see that in the beginning the base model average behaves exactly like the 1st order model.",
                    "label": 0
                },
                {
                    "sent": "That's why this curve is 0 all the time, because it just does the same as the 1st order model, which is the baseline.",
                    "label": 0
                },
                {
                    "sent": "And then at this point here it starts behaving very rapidly, exactly like the 2nd order model.",
                    "label": 0
                },
                {
                    "sent": "So it hardly makes a difference, and the reason why it make hardly makes a difference.",
                    "label": 0
                },
                {
                    "sent": "Whether you do selection or averaging is that for almost all sample points except those very close to here.",
                    "label": 0
                },
                {
                    "sent": "If you look at the posterior probability of the 1st order and 2nd order model, their ratio is exponentially large.",
                    "label": 0
                },
                {
                    "sent": "So therefore in the mixture, one of the two models plays no role whatsoever.",
                    "label": 0
                },
                {
                    "sent": "You can simply throw it away.",
                    "label": 0
                },
                {
                    "sent": "So the question is, maybe we can modify based somehow such that we do better and let it behaves like the black curve, so the black curve is what you would get if you would switch exactly at the right point.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the answer is that you can actually do that, or actually almost do that.",
                    "label": 0
                },
                {
                    "sent": "You can be almost with the black curve.",
                    "label": 1
                },
                {
                    "sent": "Which can be achieved by somebody who knows who has already seen the data and post.",
                    "label": 0
                },
                {
                    "sent": "Are you actually want to?",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We achieved this by changing base in African way.",
                    "label": 0
                },
                {
                    "sent": "Modification of base distribution.",
                    "label": 0
                },
                {
                    "sent": "So how does it work?",
                    "label": 0
                },
                {
                    "sent": "Well, first we assume that we have some.",
                    "label": 0
                },
                {
                    "sent": "Oracle tells us where we should switch, and later we abstract away from it.",
                    "label": 0
                },
                {
                    "sent": "So suppose we want to switch at sample size S. Then the total prediction error we make is the prediction error we make by using Model 1 until sample size S and then from S + 1 to N, we use Model 2.",
                    "label": 1
                },
                {
                    "sent": "So that is if you write out.",
                    "label": 0
                },
                {
                    "sent": "Whoa.",
                    "label": 0
                },
                {
                    "sent": "Something goes wrong.",
                    "label": 0
                },
                {
                    "sent": "Sorry about that.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So if we switch at this point S, we somehow know where it is.",
                    "label": 1
                },
                {
                    "sent": "Then this is the error we make.",
                    "label": 0
                },
                {
                    "sent": "These are the losses and we can rewrite this as the minus log probability we give using the 1st order model to the first as outcomes and then minus log probability we give according to the 2nd order model for the rest of the data.",
                    "label": 0
                },
                {
                    "sent": "Now if we define a new distribution on sequences of length N just by taking the product of these, it's easy to check that if you sum this overall outcomes, you get one.",
                    "label": 0
                },
                {
                    "sent": "So this defines a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Then with this distribution our total prediction error will be.",
                    "label": 1
                },
                {
                    "sent": "This minus logarithm of this, which is just this.",
                    "label": 0
                },
                {
                    "sent": "So with.",
                    "label": 0
                },
                {
                    "sent": "If we use this distribution all the time, we predict optimally we switch at the optimal point.",
                    "label": 0
                },
                {
                    "sent": "I think of this new distribution both as a prediction strategy used for sequential prediction, but also simply as a distribution of sequences of length N. It's again by switching back and forth between prediction strategies looking at accumulated loss and distributions.",
                    "label": 1
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So no, of course we know this point S where we should switch.",
                    "label": 0
                },
                {
                    "sent": "Let me know it afterwards.",
                    "label": 0
                },
                {
                    "sent": "So how can we do about as well as if we would know the point?",
                    "label": 0
                },
                {
                    "sent": "Without really knowing it well, we do this innovation way.",
                    "label": 0
                },
                {
                    "sent": "We adopt Sebacean solution to Bashan, problem, so we want some distribution which we can use as a prediction strategy, just such that no matter what data we observe, no matter where the optimal switchpoint is, we perform about as well as if we would do it in advance.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can do that.",
                    "label": 1
                },
                {
                    "sent": "By thinking of this as a parameter and putting appr.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fire on it.",
                    "label": 0
                },
                {
                    "sent": "And then integrating it out.",
                    "label": 0
                },
                {
                    "sent": "So what we'll do?",
                    "label": 0
                },
                {
                    "sent": "To put a flat prior on the point where to switch.",
                    "label": 1
                },
                {
                    "sent": "And then we define the switch distribution as the average of the switch distribution, which you get if you switch it point S, which would be optimal if S would be the optimal point to switch.",
                    "label": 0
                },
                {
                    "sent": "Averaged over all possible switch points.",
                    "label": 0
                },
                {
                    "sent": "And now you get to the crucial inside of this talk.",
                    "label": 0
                },
                {
                    "sent": "If you do this.",
                    "label": 0
                },
                {
                    "sent": "If you look at the total prediction error remake, because as we know this is the total prediction error we make if we use this distribution for prediction, it's minus log of this sum by definition.",
                    "label": 0
                },
                {
                    "sent": "So sum is larger or equal in each of its terms.",
                    "label": 0
                },
                {
                    "sent": "So minus log of the sum is smaller equal in each of its terms in, particularly, is smaller or equal and minus log of the.",
                    "label": 0
                },
                {
                    "sent": "Error we make if we switch up the optimal point plus some overhead.",
                    "label": 0
                },
                {
                    "sent": "If we use a flat prior like this then the overhead is about so this is about 1 / S squared, so this will be about 2 log S. So this distribution performs as well as the distribution which which is the optimal point plus an overhead which is logarithmic.",
                    "label": 0
                },
                {
                    "sent": "In the sample size where you should switch optimally.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What happens if you use this?",
                    "label": 0
                },
                {
                    "sent": "Um, for the Markov chain example.",
                    "label": 0
                },
                {
                    "sent": "As we know, if we would switch at the optimal point we could gain 20,000 bits over base and predictive performance.",
                    "label": 1
                },
                {
                    "sent": "Because the size of this maximum is 20,000.",
                    "label": 0
                },
                {
                    "sent": "So this new distribution, which averages overall switch points.",
                    "label": 0
                },
                {
                    "sent": "We use it for prediction.",
                    "label": 0
                },
                {
                    "sent": "It will be as good as this optimal point, which gains 20,000 plus an overhead which will be about 32, because the optimal switchpoint is at sample size, about 50,000.",
                    "label": 0
                },
                {
                    "sent": "So the overhead you get.",
                    "label": 0
                },
                {
                    "sent": "Compared to knowing the point in advance is almost nil.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gible and if you draw the two pictures for knowing the overhead in advance and using the switch distribution, which averages you see no difference, so now we predict as well as the black curve compared to the 1st order model, and we do much better than base.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So no, I've told this to you.",
                    "label": 0
                },
                {
                    "sent": "I can use this to solve the AI CBSE dilemma.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to do that, I first need to extend this not to two models, but to more than two models.",
                    "label": 0
                },
                {
                    "sent": "Because notify, use two models that no matter how much data I get the gain I can make over base remains finite.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But if I have more than two models, then the gain over base may increase every time I switch.",
                    "label": 1
                },
                {
                    "sent": "If I switch earlier each time I switch, and in cases like the histogram examples where if I get more and more data I want to switch more and more often.",
                    "label": 1
                },
                {
                    "sent": "In the limit infinitely often I may gain an infinite amount over base and we will see that that is actually what happens.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I know to find a multiswitch disk.",
                    "label": 0
                },
                {
                    "sent": "Which works as follows.",
                    "label": 0
                },
                {
                    "sent": "You put the prior now not on one switch point, but on a vector of switch points of arbitrary length.",
                    "label": 1
                },
                {
                    "sent": "So first again, I assume that you know the points where you want to switch, so this is a vector of points he won the first time you switch to two.",
                    "label": 1
                },
                {
                    "sent": "The second time you switch Anna Vector of model indices you want to switch.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now.",
                    "label": 0
                },
                {
                    "sent": "Once you know the switching scenario, you can define a distribution which amounts to prediction strategy.",
                    "label": 0
                },
                {
                    "sent": "Let's follow.",
                    "label": 0
                },
                {
                    "sent": "This distribution is defined by until the first switchpoint you behave like model K0.",
                    "label": 0
                },
                {
                    "sent": "That's what you use before the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then after that for switchpoint, you behave like K1.",
                    "label": 0
                },
                {
                    "sent": "So the conditional probability of the next outcome given the past is given by this case.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "After the second switch point, you behave like K3, etc and now your new distribution for the whole sequence of data is defined as the product of these distributions.",
                    "label": 0
                },
                {
                    "sent": "And you know, by this correspondence between accumulated loss and minus log likelihood that if you use this distribution for prediction, you will predict exactly as well as if you would have switched at this particular vector.",
                    "label": 0
                },
                {
                    "sent": "Of course, in reality we don't know this vector.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, we put a prior on it.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we can do this in various ways.",
                    "label": 0
                },
                {
                    "sent": "Basically what we choose is a prior where we first put pressure on the number of points you switch, which goes down exponentially in the sample size.",
                    "label": 0
                },
                {
                    "sent": "This is useful for computation.",
                    "label": 0
                },
                {
                    "sent": "And then given this number of times we switch, we put a very flat prior.",
                    "label": 0
                },
                {
                    "sent": "On the switch points and all the points you switch to.",
                    "label": 0
                },
                {
                    "sent": "And we we get the final prior by multiplying all these individual priors.",
                    "label": 0
                },
                {
                    "sent": "So this gives you a prior on all finite vectors of switching strategies.",
                    "label": 1
                },
                {
                    "sent": "Between a finite number of models and define.",
                    "label": 0
                },
                {
                    "sent": "The switch distribution for arbitrarily many models as the average probability of the data according to this prior over.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sing strategies.",
                    "label": 0
                },
                {
                    "sent": "And now you can use basic theorem to get a posterior switching strategy given the data.",
                    "label": 0
                },
                {
                    "sent": "And the posterior switching strategy.",
                    "label": 0
                },
                {
                    "sent": "Can be used to come up with the maximum posterior model, so this is now the model which if you sum over given a sample size N if you some overall strategies.",
                    "label": 0
                },
                {
                    "sent": "That's A at sample size and you should use case star.",
                    "label": 0
                },
                {
                    "sent": "The probability of that particular strategy which says use case, start sample size N, then you get this probability and now you define a switching method for model selection as picking.",
                    "label": 1
                },
                {
                    "sent": "For a given data thing which maximizes this, so this is not the most probable model given the data, but the most probable model to use for prediction at your given sample size given that.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now we get the first theorem, and there's no time to explain what it is.",
                    "label": 0
                },
                {
                    "sent": "But The upshot is simply.",
                    "label": 0
                },
                {
                    "sent": "Whenever it is consistent, then the switching distribution is consistent as well.",
                    "label": 0
                },
                {
                    "sent": "They're very strong theorems going back to dupe 1949 saying that basis consistent on their wide variety circumstances.",
                    "label": 0
                },
                {
                    "sent": "So for example, if data comes from this uniform distribution, one bin histogram, then the switch distribution will decide it's a one bin histogram.",
                    "label": 0
                },
                {
                    "sent": "So that is consistency, so switching retains the nice property.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The ICM base is consistent.",
                    "label": 0
                },
                {
                    "sent": "And it also converges.",
                    "label": 0
                },
                {
                    "sent": "That's the next result, so.",
                    "label": 0
                },
                {
                    "sent": "If you want to do prediction or estimation based on model selection, you first have to do model selection.",
                    "label": 0
                },
                {
                    "sent": "So for example with AIC and then within a multi select it you have to do some kind of estimation to come up with a prediction on the next point.",
                    "label": 0
                },
                {
                    "sent": "An you can do that with AI.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The maximum likelihood, for example.",
                    "label": 1
                },
                {
                    "sent": "Or you can do it with Basin model averaging, where you first take the posterior over almost giving your data and then.",
                    "label": 0
                },
                {
                    "sent": "You pick the base predictive distribution over all these models again and again.",
                    "label": 0
                },
                {
                    "sent": "You get a prediction for the.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Outcome or you can use the switch distribution right?",
                    "label": 0
                },
                {
                    "sent": "Just by taking the conditional distribution of the next point given the past using the disk.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solution we just defined.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at the statistical risk of the switch distribution.",
                    "label": 0
                },
                {
                    "sent": "Which is the expected distance between the true distribution which you don't know, which generates the data.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Your estimate or prediction for the next outcome.",
                    "label": 0
                },
                {
                    "sent": "We measured it here using.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The older versions.",
                    "label": 0
                },
                {
                    "sent": "Then we see that switching in general under mild conditions on the model achieves the minimax optimal rates, just like AIC, and not like BICS.",
                    "label": 0
                },
                {
                    "sent": "So in a sense.",
                    "label": 0
                },
                {
                    "sent": "It's optimal, so for example with histograms.",
                    "label": 0
                },
                {
                    "sent": "If you take yours, your set of models, distributions which have a smooth density and a bounded first derivative so they can be arbitrarily well approximated by histograms, then the fastest risk you can achieve with any method at all overall distributions in that class is 1 / N to the one third.",
                    "label": 0
                },
                {
                    "sent": "So that's how fast your risk goes to 0.",
                    "label": 0
                },
                {
                    "sent": "And the risk of the switch distribution will go to zero equally fast.",
                    "label": 0
                },
                {
                    "sent": "Where is the risk of base?",
                    "label": 0
                },
                {
                    "sent": "Doesn't it's in general off by a factor of.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "And I cheated error little, you should actually look at the sum of the risk.",
                    "label": 0
                },
                {
                    "sent": "Another individual risks that's.",
                    "label": 0
                },
                {
                    "sent": "That kind of day.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still.",
                    "label": 0
                },
                {
                    "sent": "So the switch distribution is as fast as any other method at all, in particular as fast as leave one out, CrossFit.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation.",
                    "label": 0
                },
                {
                    "sent": "So we resolved KSEB.",
                    "label": 0
                },
                {
                    "sent": "I see the lemma theorem says we do theory, but.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turns out we also do this in practice.",
                    "label": 0
                },
                {
                    "sent": "Yes, in many cases we can actually do this.",
                    "label": 0
                },
                {
                    "sent": "Compute this in practice and the reason we can is that, of course, if you think of this prior, it looks incredibly complicated.",
                    "label": 0
                },
                {
                    "sent": "It's a prior over sequences of arbitrary length.",
                    "label": 0
                },
                {
                    "sent": "But you can think of the model to use at each time.",
                    "label": 0
                },
                {
                    "sent": "In fact, as a kind of expert you want to use for prediction and the expert is not observed.",
                    "label": 0
                },
                {
                    "sent": "So you can think of it as a state in a hidden Markov model, and in fact our switch distribution.",
                    "label": 1
                },
                {
                    "sent": "If it's a hidden Markov model and then you can use the forward algorithm to compute all predictions.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in hidden Markov models and their extensions, and there have been several papers that I smell about that, then I'm going to make a little advertisement here.",
                    "label": 0
                },
                {
                    "sent": "You should go to Walter: stop tomorrow, where he explains how you can do the implement.",
                    "label": 0
                },
                {
                    "sent": "Things like this using hidden Markov models and the resulting algorithm is very similar to the tracking.",
                    "label": 0
                },
                {
                    "sent": "The best expert algorithm by Herb Sandwich which was presented is called 10 years ago.",
                    "label": 0
                },
                {
                    "sent": "Indeed, we are also doing something like tracking the best model.",
                    "label": 0
                },
                {
                    "sent": "Edit Sample size each model is an expert.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are working on applying this to nonparametric density estimation, but of course you could also do regression or time series prediction and I hope to challenge some of you into trying this out.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For for example, regression.",
                    "label": 0
                },
                {
                    "sent": "Final remark, the question is, is this basin or not?",
                    "label": 0
                },
                {
                    "sent": "So for me it is.",
                    "label": 0
                },
                {
                    "sent": "We use a basic algorithm.",
                    "label": 0
                },
                {
                    "sent": "But if you from a subjective based in POV.",
                    "label": 0
                },
                {
                    "sent": "There is something 10 years about the basin interpretation because the prior seems to indicate that we believe that the true model changes overtime, but we don't believe that.",
                    "label": 1
                },
                {
                    "sent": "Actually, we believe that the data is governed by a fixed law, which changes the same all the time, but still, it's a good idea to change your predictions overtime.",
                    "label": 0
                },
                {
                    "sent": "So the base and interpretation, let's say the filler.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Civilization interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is tenuous.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as MDL though, because this is a clear data compression interpretation.",
                    "label": 0
                },
                {
                    "sent": "However, nobody in MDF are sort of doing this, so that may be too much honor.",
                    "label": 0
                },
                {
                    "sent": "For me as well, but what I would like to stress here.",
                    "label": 0
                },
                {
                    "sent": "Is that I really feel this is a prick wenczel method, so the prick wenczel idea is this basic idea of thinking about probabilities as prediction strategies and log likelihoods as some of prediction error.",
                    "label": 0
                },
                {
                    "sent": "Now if you take that idea to its limits, you arrive at the switch distribution and this idea goes back to 1984.",
                    "label": 0
                },
                {
                    "sent": "But I think it still has a lot of unexplored potential and I hope to explore that first.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the future.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's subjective value.",
                    "label": 0
                },
                {
                    "sent": "Not say what you've done is subjective.",
                    "label": 0
                },
                {
                    "sent": "So you know, I think it's really good, and I think it's OK.",
                    "label": 0
                },
                {
                    "sent": "But I can show you exactly where you claim, which shows as well the slide where you said that the true model is in the limit, right?",
                    "label": 0
                },
                {
                    "sent": "So let me.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just so I have two basic objections here and one I don't like and the other I like.",
                    "label": 0
                },
                {
                    "sent": "So this is a better base, an objection which actually says that if you think that rulers in the limit, you should use some parametric prior because you put prior probability 0 on that.",
                    "label": 1
                },
                {
                    "sent": "So that is actually true.",
                    "label": 0
                },
                {
                    "sent": "But there was no time to state this in detail, but actually so I do think it actually has a base and interpretation as well.",
                    "label": 1
                },
                {
                    "sent": "What we have here is a kind of nonparametric prior.",
                    "label": 0
                },
                {
                    "sent": "But it's just very different from the nonparametric priors that people have been using.",
                    "label": 1
                },
                {
                    "sent": "And it's nice if you're frequentist as well, because I can give frequentist guarantees to how well this prior will work for prediction.",
                    "label": 0
                },
                {
                    "sent": "But yes, I think you can think of this as nonparametric base.",
                    "label": 0
                },
                {
                    "sent": "Yes, definitely.",
                    "label": 0
                },
                {
                    "sent": "Coming back to your initial example of Instagram.",
                    "label": 0
                },
                {
                    "sent": "The prior that you chose there had account run on each business essentially, and now if you have more more bins, you're actually putting more and more prior mass that would overcome the amount of data essentially, and I'm wondering whether the phenomena would be identical or slightly different if you use supplier that had some number.",
                    "label": 0
                },
                {
                    "sent": "That was spread out evenly over K so that as he took the limit of.",
                    "label": 0
                },
                {
                    "sent": "Police would converge something like.",
                    "label": 0
                },
                {
                    "sent": "Processor.",
                    "label": 0
                },
                {
                    "sent": "I it's a good.",
                    "label": 0
                },
                {
                    "sent": "It's a good question, so my guess would be that that it gets better, but it doesn't disappear because you still put prior mass 0.",
                    "label": 0
                },
                {
                    "sent": "On the distribution being out being not a finite histogram, so I think it wouldn't disappear and also the basically the theorems we have indicate that as soon as you use, let's say classical base vector prior.",
                    "label": 0
                },
                {
                    "sent": "This just happens.",
                    "label": 0
                },
                {
                    "sent": "You cannot get rid of it.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it's clear that this effect would be alleviated if you would do something like this, so it might be worth trying it out actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh no, that's if I can immediately answer that.",
                    "label": 0
                },
                {
                    "sent": "We multiply everything by N. So then in the structural risk minimization, you would multiply by square root of N rather than divide, so it's actually increases even faster than log, which was what we had here.",
                    "label": 0
                },
                {
                    "sent": "Is it possible to make?",
                    "label": 0
                },
                {
                    "sent": "There are the similar thing with their square loss.",
                    "label": 0
                },
                {
                    "sent": "Yes, although it is nice, probably wouldn't look more haggard, but you would.",
                    "label": 0
                },
                {
                    "sent": "I'm sure, for example, if you do this with regression then they are the same the logarithm.",
                    "label": 0
                },
                {
                    "sent": "Get this cleared loss if you use fixed variance, so so one is the other times to fix variance, so then it would look exactly the same so.",
                    "label": 0
                },
                {
                    "sent": "It may depend on the model, but for some models like regression models, you could definitely do it with the square files as well.",
                    "label": 0
                },
                {
                    "sent": "Just buy some.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, you can use base independent of the loss function you use of course, but this.",
                    "label": 1
                },
                {
                    "sent": "Think of the log likelihood as the sum of the prediction error that is unique to logarithmic loss, yes.",
                    "label": 0
                },
                {
                    "sent": "But then yeah.",
                    "label": 0
                },
                {
                    "sent": "So it looks like.",
                    "label": 0
                },
                {
                    "sent": "Your picture want to find the stationary point of the function, which relates to losses or in general case you have a medical diagnosis losses.",
                    "label": 0
                },
                {
                    "sent": "So the interesting question is you could have done a different way.",
                    "label": 0
                },
                {
                    "sent": "You could look for their place where the deal with changes aside.",
                    "label": 0
                },
                {
                    "sent": "That's how that would correspond to your switching distribution.",
                    "label": 0
                },
                {
                    "sent": "I wonder, so I think actually that you can think of leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "You can recast it in those terms is trying to trying to estimate where this derivative is 0.",
                    "label": 0
                },
                {
                    "sent": "So then basically, if you would do that, what would happen is you would get the optimal convergence rates, but you would not get consistency because for this basically the consistency is caused by very different effect which has something to do if you use base you.",
                    "label": 1
                },
                {
                    "sent": "Well, it would be too long to discuss, but you would lose the consistency if you would do just that.",
                    "label": 0
                },
                {
                    "sent": "That's cross validation is inconsistent, it it keeps selecting an overly.",
                    "label": 0
                },
                {
                    "sent": "An complex model in if the true distribution is in there.",
                    "label": 0
                },
                {
                    "sent": "Definitely is not equivalent to finding their optimal.",
                    "label": 0
                },
                {
                    "sent": "No, it's not the same thing now.",
                    "label": 0
                }
            ]
        }
    }
}