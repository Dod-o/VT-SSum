{
    "id": "2wa5liulbwukkjr6qalqaqcs7jr7tmjw",
    "title": "Semantic Concept Discovery Over Event Databases",
    "info": {
        "author": [
            "Oktie Hassanzadeh, IBM Thomas J. Watson Research Center"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_hassanzadeh_event_databases/",
    "segmentation": [
        [
            "Hello everyone and thanks for being here in this nice weather.",
            "Close to the beast so I'm from IBM research AI.",
            "This is joint work with my colleagues Sherry Trevenen Alfie Oglio."
        ],
        [
            "So, so I'm going to talk about a component of a larger project with the high level goal of assisting analysts primarily risk analysts in their daily activities, and the particular task that we focus on for this work is when the analyst is tasked with creating a comprehensive and accurate report on a given topic or a given high level question.",
            "So that question of course could be broken down into a set of topics and entities.",
            "I have an example here.",
            "Real question here is what are the consequences of Brexit on London's financial markets, right?",
            "So in order to prepare a report on this topic, the analyst needs to discover the key concepts and entities related to this.",
            "To this question here it could be financial markets economy Brexit.",
            "Some of them could be directly on the question, some of them, like for example Brexit, divorce bill is something that a domain expert needs to be familiar with with the event and then the key people and organizations.",
            "For example the European Union and the decision makers in the European Union that the analyst needs to study to know about the progress.",
            "And then of course all the related events that it could be negotiation meetings.",
            "It could be parliamentary elections that could affect the outcome.",
            "And."
        ],
        [
            "And all that, right?",
            "So what is the current solution?",
            "The classic solution that the analysts do nowadays?",
            "They start with the search.",
            "And and the search is often assisted.",
            "There are commercial solutions out there, or they can go up publicly on the web.",
            "Search news, articles.",
            "Social media.",
            "Look at past reports on similar topics by previous analysts and then out of those articles and reports an mostly unstructured data.",
            "They find they need to find out these key concepts and entities and then later on use it in their analysis task, right?",
            "So there are two major problems with this approach.",
            "One is that this process, I mean, there could be a vast amount of information about that topic, and it's not really possible for a human being to go through all the all the text, all the available data and identify those concepts.",
            "So there might be missing concepts and information and the other major problem is that it could be very biased, right?",
            "The analyst, these analysts are usually experts in the domain.",
            "They already know a lot.",
            "About the topic, they may have studied before they may have written similar reports, and they may be very biased by there, and they may have had successes on that, right?",
            "So they may be very biased in terms of the sources of information they look at and what they already believe in.",
            "So there is really a need for a solution to to make sure there is an unbiased and complete.",
            "The set of concepts found and then the other problem.",
            "The other major problem is that usually this search process is done in isolation from the end analysis tasks and I have two particular examples.",
            "Example use cases.",
            "One is when the high level question has some forecast nature.",
            "For example, you want to know if there will be a change in inflation rate or a change in employment, and that's something that the analysts usually turn into a machine learning model right there.",
            "They start building models from the past events to be able to.",
            "Predict or come up with the probability of certain kinds of events and basically the concepts that you discover in your first phase become features for your machine learning model, right?",
            "So basically this common concept search becomes feature certain feature construction effort and and if you do that in isolation you may not have the data to build those features right?",
            "And it's second case is related to scenario planning.",
            "We have a project at IBM Research AI called Scenario Planning Advisor we have.",
            "A paper on the AAAI 2018 and the demo paper coming in each guide.",
            "2018.",
            "The high level goal is basically preparing for future scenarios.",
            "This is scenario planning, and for this purpose also.",
            "Basically, the process is that you have a model of the walls and the events that could happen, and the consequences of the events and different conditions, and you really need to be able to align where you are by looking at the news and doing this discovery task.",
            "To be able to see where you are in the model of events and drivers and conditions.",
            "So these are the partic."
        ],
        [
            "Other use cases that can benefit from such a solution.",
            "So before going into the details of the solution, I will briefly introduce the sources of data we use.",
            "So instead of relying on classic texts.",
            "A text corpus or news articles.",
            "Here we decided to use the so called event databases, so I'm listing three event databases that we used here.",
            "This is of course not a complete, hence if list and you'll hear more even in this session on an event extraction, this is a well studied topic in in the NLP community, but these are three relatively widely used and open publicly available event databases we have used."
        ],
        [
            "The first 2G Dalton Iqs are the so called political event databases for these.",
            "An event has a very specific definition so it's a political science definition that it has an action and up to two actors and these actions and actors are coded according to some dictionary.",
            "For example, some government makes the statement or the two actors get into a conflict, so there's these are basically codes that define certain kinds of actions and actors.",
            "And then there is event registry which is a generic event database and event registry.",
            "The notion of an event is just a collection of documents talking about the same topic or the same event.",
            "And this is a work from the semantic web community.",
            "So it comes with semantic annotations with Wikipedia concepts."
        ],
        [
            "And you can see these have different characteristics.",
            "There could be millions of records fields.",
            "These are mostly semi structured according to the database community definition.",
            "So these are Jason documents or tabular data with some columns that are multivalued."
        ],
        [
            "So."
        ],
        [
            "So our solution, and in particular for this work being an induced track paper, I want to highlight the two uses of semantic technology for our solution in concept discovery.",
            "So one is this unified semantic index that we built on top of this data using a lightweight mapping and link discovery method that I will talk more.",
            "But basically this enables going from a question or a set of concepts.",
            "To querying different kinds of different sources right here, we have three different event databases that we can query with a unified input, and then the second aspect that I want to talk about is this semantic embedding engine.",
            "So this enables semantic similarity queries.",
            "So given an input query or set of concepts, we are able to retrieve and rank a set of similar concepts.",
            "So I'll talk more."
        ],
        [
            "About these and I will use screenshots of prototype UI we have built.",
            "This is a very simple UI we built using the API's that we have developed as part of this work to showcase the application of this technology.",
            "Basically these.",
            "Semantic technologies in use right so?"
        ],
        [
            "The input to the system could be a question like the example I had, or a set of concepts that are extracted from the question."
        ],
        [
            "And then the very first thing that you get when you.",
            "Run your query on on top.",
            "On that box you get what we are referring to as global context, so this is basically mapping the concepts in your question or your input to our background knowledge graph and if you click."
        ],
        [
            "And here you Get the facts that we have here for this prototype.",
            "These are coming from wiki data, DB Pedia and YAGO right.",
            "But the main thing about this is."
        ],
        [
            "Is that you can then.",
            "Yeah, you can then use these concepts that are extracted to query different sources, assuming that each source is also annotated with the same objects that you have in your background knowledge graph.",
            "So in this case I'm showing you an example.",
            "This is basically our baseline for concept discovery, so the 3 three queries this was, by the way an example on impeachment of Dilma Rousseff in Brazil, right?",
            "So the global context we identified.",
            "Dilma Rousseff, impeachment in Brazil and four events registry.",
            "This is a box on querying event registry.",
            "These turn into what we call the local context or the event registry context.",
            "This is basically querying event registry for all the events that are annotated with these three objects.",
            "With these three concepts right, Dilma Rousseff impeachment in Brazil, and in this case it turned out that we have these concepts in event registry.",
            "It could be that depending on the data source, some of them are missing, so the query or the local context could be different.",
            "And then for the concept discovery part, the baseline we have implemented, we refer to it in the paper as the Co occurrence method.",
            "This is a very simple approach that you retrieve all the events that are annotated with these concepts and then among the results you just count the frequency of the other kinds of concepts and entities that are found right.",
            "For example here you have of course the query items are appearing 100% of the results and all the results, but you have for example.",
            "Government mentioned in 92% of the results, or Michel Temer appearing in 20 something percent of the results.",
            "So this is our baseline simple approach.",
            "We call it."
        ],
        [
            "Occurrence in this paper and the second approach for concept discovery, which is the second part of use of semantic techniques in this work, is is the idea of using semantic embeddings, and most of you are probably already familiar with the idea of work toward embeddings in in NLP basically assigns a vector to each word in a document in a corpus that captures the semantic context of that word.",
            "So if 2 words are similar in terms of being in a similar context, those vectors are highly similar according to similarity like cosine similarity, and then in the classic work to work work there are two different models that Skip gram and and see Bao continuous bag of Ward.",
            "One of them tries to predict the context given award.",
            "The other one tries to predict the award given the context.",
            "So what we do?"
        ],
        [
            "Here is that we apply the same technique to structured or semi structured data coming from these event databases.",
            "So the first step is turning each record or each row in the database into one sentence or context and we do that by adding a prefix which is the name of the field or the name of the column in the structured data with the value you find in that column, right?",
            "And then that gives us a document or a corpus of documents that we can use in exist."
        ],
        [
            "Sing more to back models.",
            "One thing that is different here is that in documents we wear the distance between the words.",
            "Show how related they are, but in a in a database 1st and 2nd column are as related as the first and last column, so there is no notion of.",
            "Sliding window here anymore.",
            "The second aspect we have done in this system is what we are referring to as this embedding management system, which is a super fast in memory index for nearest neighbor search.",
            "This is based on the open source and our library and our team has worked on on this micrograph sitting here has been working on this and then the other part that we did for this system is the query engine.",
            "So instead of retrieving just simply wards we can.",
            "We basically have an index for each field.",
            "Or basically each prefix in the words and you are able to query for, for example only persons or locations."
        ],
        [
            "Kinds of concepts.",
            "Here we have an example for GL GCG and you can see again the local context is similar.",
            "The three terms have been found and the three boxes you see here are basically query results over three different indexes, one on key people, which is basically persons.",
            "The other is organization, the other is theme which in G Delta is basically means a topic and one thing about this is that this is super fast, so this runs in milliseconds.",
            "Second times I can show you.",
            "Live demo afterwards if you're interested."
        ],
        [
            "Yeah, and you can see in the screenshot of the API.",
            "So basically you can specify the Target Field or you can just do a star query and retrieve in all the related fields."
        ],
        [
            "So briefly, about the evaluation methodology, what we did here given our goal of helping the analysts to prepare reports, we take existing reports written by human experts, and then we use the title of those documents as the input as if they were the question or the topic, and we try to find out if we if our system can discover all the entities and concept mentioned in the text.",
            "So we do that primarily on Human Rights Watch organizations, so these are PDF documents publicly available with some title, an subtitle that we use as the query and then we manually.",
            "Or one of our datasets manually, and for another one automatically find out all the entities mentioned in those articles and then we run it into our engine and try to see if our concepts, concepts retrieved and ranked properly retrieve those entities so."
        ],
        [
            "Briefly about the results.",
            "So overall we got very promising results, especially for the semantic embeddings engine.",
            "You can see the accuracy numbers are relatively low.",
            "This is in part of problem in our in the evaluation methods.",
            "So given that we are relying only on a single document for a particular topic, that document may not really contain all the entities that one can retrieve, and there is also this notion of this problem with the time period that our corpus had we.",
            "The corpus we used for example for G Delton event registry covers around three years.",
            "There are some of these reports are older and refer to other entities, but in general what we found is that a combination approach works best.",
            "So we do the context method or the deep similarity method and refine it based on frequency, method or the other way around.",
            "And this usually we were able to achieve statistically significant results that.",
            "This approach is better in most cases and one."
        ],
        [
            "I think about the context method or the deep similarity method is that although the.",
            "The accuracy numbers are not much higher.",
            "By manual evaluation we observe that all the hits we get, for example, in this example right, which is from one of the Human Rights Watch results.",
            "All of the hits are actually relevant if you look into them.",
            "So these are very relevant.",
            "People mention related to the input question, but for the Co occurrence method the other hits that were not in our benchmarking are usually these popular entities like Barack Obama or Donald Trump.",
            "These appear in most articles and there are not really.",
            "Relevant to that question.",
            "So in."
        ],
        [
            "Summary what I showed in terms of use of semantic technologies has been two components, one on this lightweight semantic integration approach.",
            "Being able to query various structured and semi structured sources in a unified way and and what I showed you is fairly generic, so you can really put other structured or semi structured sources as well and the other part was about this semantic embeddings approach that showed very promising results.",
            "So what we have a lot to do.",
            "In the future, and there are also components that I didn't show.",
            "For example, the latitude in Lanja tude in G dealt also turn in to get their own vectors, so you can do semantic similarity for locations.",
            "So using the exact same API we were able to build this visualization on a map.",
            "So you put just a question or a topic and you get all the related locations and the users of the system were really impressed on how accurate these locations where under relevant these locations where.",
            "So we have more work on the event extraction engine, so we had this issue of missing certain kinds of events in the existing event databases.",
            "And finally one thing that we want to work on and we have started working on is focusing on the different kinds of relations, not just general semantic similarity and one particular one is the causal relation.",
            "So if certain kinds of events happening can indicate that another kind of event is more likely to happen, so this is.",
            "Something that is also part of this project.",
            "And that's it.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everyone and thanks for being here in this nice weather.",
                    "label": 0
                },
                {
                    "sent": "Close to the beast so I'm from IBM research AI.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with my colleagues Sherry Trevenen Alfie Oglio.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so I'm going to talk about a component of a larger project with the high level goal of assisting analysts primarily risk analysts in their daily activities, and the particular task that we focus on for this work is when the analyst is tasked with creating a comprehensive and accurate report on a given topic or a given high level question.",
                    "label": 0
                },
                {
                    "sent": "So that question of course could be broken down into a set of topics and entities.",
                    "label": 0
                },
                {
                    "sent": "I have an example here.",
                    "label": 0
                },
                {
                    "sent": "Real question here is what are the consequences of Brexit on London's financial markets, right?",
                    "label": 1
                },
                {
                    "sent": "So in order to prepare a report on this topic, the analyst needs to discover the key concepts and entities related to this.",
                    "label": 0
                },
                {
                    "sent": "To this question here it could be financial markets economy Brexit.",
                    "label": 0
                },
                {
                    "sent": "Some of them could be directly on the question, some of them, like for example Brexit, divorce bill is something that a domain expert needs to be familiar with with the event and then the key people and organizations.",
                    "label": 0
                },
                {
                    "sent": "For example the European Union and the decision makers in the European Union that the analyst needs to study to know about the progress.",
                    "label": 0
                },
                {
                    "sent": "And then of course all the related events that it could be negotiation meetings.",
                    "label": 0
                },
                {
                    "sent": "It could be parliamentary elections that could affect the outcome.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And all that, right?",
                    "label": 0
                },
                {
                    "sent": "So what is the current solution?",
                    "label": 0
                },
                {
                    "sent": "The classic solution that the analysts do nowadays?",
                    "label": 1
                },
                {
                    "sent": "They start with the search.",
                    "label": 0
                },
                {
                    "sent": "And and the search is often assisted.",
                    "label": 1
                },
                {
                    "sent": "There are commercial solutions out there, or they can go up publicly on the web.",
                    "label": 0
                },
                {
                    "sent": "Search news, articles.",
                    "label": 0
                },
                {
                    "sent": "Social media.",
                    "label": 0
                },
                {
                    "sent": "Look at past reports on similar topics by previous analysts and then out of those articles and reports an mostly unstructured data.",
                    "label": 0
                },
                {
                    "sent": "They find they need to find out these key concepts and entities and then later on use it in their analysis task, right?",
                    "label": 0
                },
                {
                    "sent": "So there are two major problems with this approach.",
                    "label": 0
                },
                {
                    "sent": "One is that this process, I mean, there could be a vast amount of information about that topic, and it's not really possible for a human being to go through all the all the text, all the available data and identify those concepts.",
                    "label": 1
                },
                {
                    "sent": "So there might be missing concepts and information and the other major problem is that it could be very biased, right?",
                    "label": 0
                },
                {
                    "sent": "The analyst, these analysts are usually experts in the domain.",
                    "label": 0
                },
                {
                    "sent": "They already know a lot.",
                    "label": 0
                },
                {
                    "sent": "About the topic, they may have studied before they may have written similar reports, and they may be very biased by there, and they may have had successes on that, right?",
                    "label": 0
                },
                {
                    "sent": "So they may be very biased in terms of the sources of information they look at and what they already believe in.",
                    "label": 0
                },
                {
                    "sent": "So there is really a need for a solution to to make sure there is an unbiased and complete.",
                    "label": 0
                },
                {
                    "sent": "The set of concepts found and then the other problem.",
                    "label": 0
                },
                {
                    "sent": "The other major problem is that usually this search process is done in isolation from the end analysis tasks and I have two particular examples.",
                    "label": 0
                },
                {
                    "sent": "Example use cases.",
                    "label": 0
                },
                {
                    "sent": "One is when the high level question has some forecast nature.",
                    "label": 0
                },
                {
                    "sent": "For example, you want to know if there will be a change in inflation rate or a change in employment, and that's something that the analysts usually turn into a machine learning model right there.",
                    "label": 0
                },
                {
                    "sent": "They start building models from the past events to be able to.",
                    "label": 0
                },
                {
                    "sent": "Predict or come up with the probability of certain kinds of events and basically the concepts that you discover in your first phase become features for your machine learning model, right?",
                    "label": 1
                },
                {
                    "sent": "So basically this common concept search becomes feature certain feature construction effort and and if you do that in isolation you may not have the data to build those features right?",
                    "label": 0
                },
                {
                    "sent": "And it's second case is related to scenario planning.",
                    "label": 0
                },
                {
                    "sent": "We have a project at IBM Research AI called Scenario Planning Advisor we have.",
                    "label": 0
                },
                {
                    "sent": "A paper on the AAAI 2018 and the demo paper coming in each guide.",
                    "label": 0
                },
                {
                    "sent": "2018.",
                    "label": 0
                },
                {
                    "sent": "The high level goal is basically preparing for future scenarios.",
                    "label": 0
                },
                {
                    "sent": "This is scenario planning, and for this purpose also.",
                    "label": 0
                },
                {
                    "sent": "Basically, the process is that you have a model of the walls and the events that could happen, and the consequences of the events and different conditions, and you really need to be able to align where you are by looking at the news and doing this discovery task.",
                    "label": 0
                },
                {
                    "sent": "To be able to see where you are in the model of events and drivers and conditions.",
                    "label": 0
                },
                {
                    "sent": "So these are the partic.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other use cases that can benefit from such a solution.",
                    "label": 0
                },
                {
                    "sent": "So before going into the details of the solution, I will briefly introduce the sources of data we use.",
                    "label": 0
                },
                {
                    "sent": "So instead of relying on classic texts.",
                    "label": 0
                },
                {
                    "sent": "A text corpus or news articles.",
                    "label": 0
                },
                {
                    "sent": "Here we decided to use the so called event databases, so I'm listing three event databases that we used here.",
                    "label": 1
                },
                {
                    "sent": "This is of course not a complete, hence if list and you'll hear more even in this session on an event extraction, this is a well studied topic in in the NLP community, but these are three relatively widely used and open publicly available event databases we have used.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first 2G Dalton Iqs are the so called political event databases for these.",
                    "label": 1
                },
                {
                    "sent": "An event has a very specific definition so it's a political science definition that it has an action and up to two actors and these actions and actors are coded according to some dictionary.",
                    "label": 0
                },
                {
                    "sent": "For example, some government makes the statement or the two actors get into a conflict, so there's these are basically codes that define certain kinds of actions and actors.",
                    "label": 0
                },
                {
                    "sent": "And then there is event registry which is a generic event database and event registry.",
                    "label": 1
                },
                {
                    "sent": "The notion of an event is just a collection of documents talking about the same topic or the same event.",
                    "label": 1
                },
                {
                    "sent": "And this is a work from the semantic web community.",
                    "label": 0
                },
                {
                    "sent": "So it comes with semantic annotations with Wikipedia concepts.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see these have different characteristics.",
                    "label": 0
                },
                {
                    "sent": "There could be millions of records fields.",
                    "label": 0
                },
                {
                    "sent": "These are mostly semi structured according to the database community definition.",
                    "label": 0
                },
                {
                    "sent": "So these are Jason documents or tabular data with some columns that are multivalued.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our solution, and in particular for this work being an induced track paper, I want to highlight the two uses of semantic technology for our solution in concept discovery.",
                    "label": 1
                },
                {
                    "sent": "So one is this unified semantic index that we built on top of this data using a lightweight mapping and link discovery method that I will talk more.",
                    "label": 1
                },
                {
                    "sent": "But basically this enables going from a question or a set of concepts.",
                    "label": 0
                },
                {
                    "sent": "To querying different kinds of different sources right here, we have three different event databases that we can query with a unified input, and then the second aspect that I want to talk about is this semantic embedding engine.",
                    "label": 0
                },
                {
                    "sent": "So this enables semantic similarity queries.",
                    "label": 0
                },
                {
                    "sent": "So given an input query or set of concepts, we are able to retrieve and rank a set of similar concepts.",
                    "label": 0
                },
                {
                    "sent": "So I'll talk more.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About these and I will use screenshots of prototype UI we have built.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple UI we built using the API's that we have developed as part of this work to showcase the application of this technology.",
                    "label": 0
                },
                {
                    "sent": "Basically these.",
                    "label": 0
                },
                {
                    "sent": "Semantic technologies in use right so?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The input to the system could be a question like the example I had, or a set of concepts that are extracted from the question.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then the very first thing that you get when you.",
                    "label": 0
                },
                {
                    "sent": "Run your query on on top.",
                    "label": 0
                },
                {
                    "sent": "On that box you get what we are referring to as global context, so this is basically mapping the concepts in your question or your input to our background knowledge graph and if you click.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here you Get the facts that we have here for this prototype.",
                    "label": 0
                },
                {
                    "sent": "These are coming from wiki data, DB Pedia and YAGO right.",
                    "label": 0
                },
                {
                    "sent": "But the main thing about this is.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that you can then.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can then use these concepts that are extracted to query different sources, assuming that each source is also annotated with the same objects that you have in your background knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So in this case I'm showing you an example.",
                    "label": 0
                },
                {
                    "sent": "This is basically our baseline for concept discovery, so the 3 three queries this was, by the way an example on impeachment of Dilma Rousseff in Brazil, right?",
                    "label": 0
                },
                {
                    "sent": "So the global context we identified.",
                    "label": 0
                },
                {
                    "sent": "Dilma Rousseff, impeachment in Brazil and four events registry.",
                    "label": 0
                },
                {
                    "sent": "This is a box on querying event registry.",
                    "label": 0
                },
                {
                    "sent": "These turn into what we call the local context or the event registry context.",
                    "label": 0
                },
                {
                    "sent": "This is basically querying event registry for all the events that are annotated with these three objects.",
                    "label": 0
                },
                {
                    "sent": "With these three concepts right, Dilma Rousseff impeachment in Brazil, and in this case it turned out that we have these concepts in event registry.",
                    "label": 0
                },
                {
                    "sent": "It could be that depending on the data source, some of them are missing, so the query or the local context could be different.",
                    "label": 0
                },
                {
                    "sent": "And then for the concept discovery part, the baseline we have implemented, we refer to it in the paper as the Co occurrence method.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple approach that you retrieve all the events that are annotated with these concepts and then among the results you just count the frequency of the other kinds of concepts and entities that are found right.",
                    "label": 0
                },
                {
                    "sent": "For example here you have of course the query items are appearing 100% of the results and all the results, but you have for example.",
                    "label": 0
                },
                {
                    "sent": "Government mentioned in 92% of the results, or Michel Temer appearing in 20 something percent of the results.",
                    "label": 0
                },
                {
                    "sent": "So this is our baseline simple approach.",
                    "label": 0
                },
                {
                    "sent": "We call it.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Occurrence in this paper and the second approach for concept discovery, which is the second part of use of semantic techniques in this work, is is the idea of using semantic embeddings, and most of you are probably already familiar with the idea of work toward embeddings in in NLP basically assigns a vector to each word in a document in a corpus that captures the semantic context of that word.",
                    "label": 1
                },
                {
                    "sent": "So if 2 words are similar in terms of being in a similar context, those vectors are highly similar according to similarity like cosine similarity, and then in the classic work to work work there are two different models that Skip gram and and see Bao continuous bag of Ward.",
                    "label": 0
                },
                {
                    "sent": "One of them tries to predict the context given award.",
                    "label": 1
                },
                {
                    "sent": "The other one tries to predict the award given the context.",
                    "label": 0
                },
                {
                    "sent": "So what we do?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is that we apply the same technique to structured or semi structured data coming from these event databases.",
                    "label": 0
                },
                {
                    "sent": "So the first step is turning each record or each row in the database into one sentence or context and we do that by adding a prefix which is the name of the field or the name of the column in the structured data with the value you find in that column, right?",
                    "label": 0
                },
                {
                    "sent": "And then that gives us a document or a corpus of documents that we can use in exist.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sing more to back models.",
                    "label": 0
                },
                {
                    "sent": "One thing that is different here is that in documents we wear the distance between the words.",
                    "label": 0
                },
                {
                    "sent": "Show how related they are, but in a in a database 1st and 2nd column are as related as the first and last column, so there is no notion of.",
                    "label": 0
                },
                {
                    "sent": "Sliding window here anymore.",
                    "label": 0
                },
                {
                    "sent": "The second aspect we have done in this system is what we are referring to as this embedding management system, which is a super fast in memory index for nearest neighbor search.",
                    "label": 1
                },
                {
                    "sent": "This is based on the open source and our library and our team has worked on on this micrograph sitting here has been working on this and then the other part that we did for this system is the query engine.",
                    "label": 0
                },
                {
                    "sent": "So instead of retrieving just simply wards we can.",
                    "label": 0
                },
                {
                    "sent": "We basically have an index for each field.",
                    "label": 1
                },
                {
                    "sent": "Or basically each prefix in the words and you are able to query for, for example only persons or locations.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kinds of concepts.",
                    "label": 0
                },
                {
                    "sent": "Here we have an example for GL GCG and you can see again the local context is similar.",
                    "label": 0
                },
                {
                    "sent": "The three terms have been found and the three boxes you see here are basically query results over three different indexes, one on key people, which is basically persons.",
                    "label": 0
                },
                {
                    "sent": "The other is organization, the other is theme which in G Delta is basically means a topic and one thing about this is that this is super fast, so this runs in milliseconds.",
                    "label": 0
                },
                {
                    "sent": "Second times I can show you.",
                    "label": 0
                },
                {
                    "sent": "Live demo afterwards if you're interested.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, and you can see in the screenshot of the API.",
                    "label": 0
                },
                {
                    "sent": "So basically you can specify the Target Field or you can just do a star query and retrieve in all the related fields.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So briefly, about the evaluation methodology, what we did here given our goal of helping the analysts to prepare reports, we take existing reports written by human experts, and then we use the title of those documents as the input as if they were the question or the topic, and we try to find out if we if our system can discover all the entities and concept mentioned in the text.",
                    "label": 1
                },
                {
                    "sent": "So we do that primarily on Human Rights Watch organizations, so these are PDF documents publicly available with some title, an subtitle that we use as the query and then we manually.",
                    "label": 0
                },
                {
                    "sent": "Or one of our datasets manually, and for another one automatically find out all the entities mentioned in those articles and then we run it into our engine and try to see if our concepts, concepts retrieved and ranked properly retrieve those entities so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Briefly about the results.",
                    "label": 0
                },
                {
                    "sent": "So overall we got very promising results, especially for the semantic embeddings engine.",
                    "label": 1
                },
                {
                    "sent": "You can see the accuracy numbers are relatively low.",
                    "label": 0
                },
                {
                    "sent": "This is in part of problem in our in the evaluation methods.",
                    "label": 0
                },
                {
                    "sent": "So given that we are relying only on a single document for a particular topic, that document may not really contain all the entities that one can retrieve, and there is also this notion of this problem with the time period that our corpus had we.",
                    "label": 0
                },
                {
                    "sent": "The corpus we used for example for G Delton event registry covers around three years.",
                    "label": 0
                },
                {
                    "sent": "There are some of these reports are older and refer to other entities, but in general what we found is that a combination approach works best.",
                    "label": 1
                },
                {
                    "sent": "So we do the context method or the deep similarity method and refine it based on frequency, method or the other way around.",
                    "label": 1
                },
                {
                    "sent": "And this usually we were able to achieve statistically significant results that.",
                    "label": 0
                },
                {
                    "sent": "This approach is better in most cases and one.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think about the context method or the deep similarity method is that although the.",
                    "label": 0
                },
                {
                    "sent": "The accuracy numbers are not much higher.",
                    "label": 0
                },
                {
                    "sent": "By manual evaluation we observe that all the hits we get, for example, in this example right, which is from one of the Human Rights Watch results.",
                    "label": 0
                },
                {
                    "sent": "All of the hits are actually relevant if you look into them.",
                    "label": 0
                },
                {
                    "sent": "So these are very relevant.",
                    "label": 0
                },
                {
                    "sent": "People mention related to the input question, but for the Co occurrence method the other hits that were not in our benchmarking are usually these popular entities like Barack Obama or Donald Trump.",
                    "label": 0
                },
                {
                    "sent": "These appear in most articles and there are not really.",
                    "label": 0
                },
                {
                    "sent": "Relevant to that question.",
                    "label": 0
                },
                {
                    "sent": "So in.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summary what I showed in terms of use of semantic technologies has been two components, one on this lightweight semantic integration approach.",
                    "label": 0
                },
                {
                    "sent": "Being able to query various structured and semi structured sources in a unified way and and what I showed you is fairly generic, so you can really put other structured or semi structured sources as well and the other part was about this semantic embeddings approach that showed very promising results.",
                    "label": 1
                },
                {
                    "sent": "So what we have a lot to do.",
                    "label": 0
                },
                {
                    "sent": "In the future, and there are also components that I didn't show.",
                    "label": 0
                },
                {
                    "sent": "For example, the latitude in Lanja tude in G dealt also turn in to get their own vectors, so you can do semantic similarity for locations.",
                    "label": 0
                },
                {
                    "sent": "So using the exact same API we were able to build this visualization on a map.",
                    "label": 0
                },
                {
                    "sent": "So you put just a question or a topic and you get all the related locations and the users of the system were really impressed on how accurate these locations where under relevant these locations where.",
                    "label": 1
                },
                {
                    "sent": "So we have more work on the event extraction engine, so we had this issue of missing certain kinds of events in the existing event databases.",
                    "label": 0
                },
                {
                    "sent": "And finally one thing that we want to work on and we have started working on is focusing on the different kinds of relations, not just general semantic similarity and one particular one is the causal relation.",
                    "label": 0
                },
                {
                    "sent": "So if certain kinds of events happening can indicate that another kind of event is more likely to happen, so this is.",
                    "label": 0
                },
                {
                    "sent": "Something that is also part of this project.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}