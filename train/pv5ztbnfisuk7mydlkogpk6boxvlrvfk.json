{
    "id": "pv5ztbnfisuk7mydlkogpk6boxvlrvfk",
    "title": "Challenges of source selection in the WoD",
    "info": {
        "author": [
            "Tobias Grubenmann, Department of Informatics, University of Zurich"
        ],
        "published": "Nov. 28, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2017_grubenmann_WoD/",
    "segmentation": [
        [
            "So good afternoon.",
            "Welcome to my presentation.",
            "Changes of source selection in the web of data.",
            "I wrote this paper together with Abraham Bernstein, Image Timothy Moore and since I can we are all from the Department of Informatics at University of Zurich."
        ],
        [
            "So what is the motivation of my work?",
            "Well, think about your favorite Spartan query and imagine that there is one single sparkle endpoint that holds all the data that you need for your query.",
            "Well, things are."
        ],
        [
            "Nice and simple.",
            "You just create endpoint, you get all your data.",
            "However."
        ],
        [
            "What happens if there's more than one single sparkle endpoint that is relevant for your specific query?",
            "Well, what you can do is."
        ],
        [
            "You just create them all in a Federated fashion and you get a lot of solutions and everything is fine.",
            "However, what you could also do is maybe you could."
        ],
        [
            "Exclude one of the sources and still get a reasonable number of solutions.",
            "How?"
        ],
        [
            "However, if you exclude exclude too many sources, you might end up with an empty.",
            "Result set."
        ],
        [
            "But what happens if there is not only free sources that are relevant for a query, but there are hundreds or even thousands?"
        ],
        [
            "Problem is it will just take too long to query all this relevant sources in a Federated fashion.",
            "So you have to somehow select a subset of the sources to run your query on it.",
            "And so the question is which one?",
            "So the idea is, well, we should somehow be able to approximate how many solutions we will get when we select a specific set of sources."
        ],
        [
            "So my question is, which combination of endpoints approximately would lead?",
            "How many solutions?"
        ],
        [
            "So for example, you could approximate what happens if you run the query just on the middle sparkling point, and you would realize OK, just only maybe a handful of solutions.",
            "Running"
        ],
        [
            "Your approximation on a different subset you would realize that there's much more estimated solutions that you would get intense.",
            "You would decide for the latter option.",
            "We can use Bloom filters, histograms, wavelets and many other techniques to do such an approximation.",
            "But there's one big problem with this.",
            "It turns out sometimes these approximations are really poor.",
            "There really bad and not very useful for selecting sources.",
            "And even worse than that is some types take awfully long to execute.",
            "In fact, sometimes they need even longer for the approximation to execute.",
            "Then you would need time to run the actual query on the actual data, and this is something that is completely against what we actually wanted initially.",
            "To have a fast approximation of the result.",
            "So how are we approximating queries well?"
        ],
        [
            "Let me show you by an example using Bloom filters.",
            "Bloom filters basically just a bit vector.",
            "Initially all bits are set to 0.",
            "However, if you want to add."
        ],
        [
            "I meant to the Bloom filter.",
            "You apply hash functions to this element.",
            "And you set accordingly some bits from zero to 1.",
            "You can add more than one element you apply again the hash functions to this element, and you set different bits from zero to 1.",
            "Monster created you Bloom filter.",
            "You can test any element whether it is part of this Bloom filter or not.",
            "So for example, if you test the X against the Bloom filter we're played, I apply the same hash functions again and we see that all bits are one.",
            "So we conclude yes, this X must be in the Bloom filter, and actually it is in the Bloom filter, so this is a true positive match.",
            "However, what can also happen is that.",
            "You apply the hash functions to different element.",
            "You again see that all bits are flipped from zero to one, but it's actually a false positive match because the element was never part of the Bloom filter.",
            "Now, this second case can happen with a certain probability, which is a parameter of the bloom filter, and we call this probability the false positive probability.",
            "Finally, but also can happen, is that you have a true negative match.",
            "So if you apply the hash function to an element and one of the bit is not one, you can conclude that the element was never part of the Bloom filter.",
            "So note that there is no possibility that you have a false negative match, so in the Bloom filter you only have two false positive, but you never have false negative.",
            "To make this notation of a Bloom filter a little bit simpler, I."
        ],
        [
            "Write this approximation sign and X&Y to indicate that there's a Bloom filter containing the two elements X&Y."
        ],
        [
            "OK, let's have a look at a simple query.",
            "You see free triple patterns and I'll illustrate with the service clause that the three different triple patterns can be sent to the three different endpoints to get the result.",
            "On the right side you have a lot of sparkle endpoints, and now you can choose how we assign this triples to different sparkle endpoints.",
            "OK, let's make an example.",
            "Assume that the."
        ],
        [
            "Stripper pattern is to assign to the Blue Sparkle endpoint to second one to the red and defer to the green one.",
            "Now, one possible way of April running this query is that you join first the first triple pattern with the second one via the variable A.",
            "And then the result you join via variable B with the green and point and finally get the result."
        ],
        [
            "And now let's have a closer look at how we would approximate such a query."
        ],
        [
            "So first of all, each endpoint gets its assigned triple pattern."
        ],
        [
            "And I indicate with this tables which are the bindings for each of these triple pattern.",
            "Now the first thing that will happen is that the first endpoint will approximate it by its bindings.",
            "And will create.",
            "In our case, a Bloom filter out of this bindings.",
            "This Bloom filter is transmitted to the right endpoint.",
            "And to join happens.",
            "The result of the joint is then added to another Bloom filter which is transmitted to the green endpoint.",
            "Since the green endpoint is the last one in the sequence of joints, you can do now I'm cardinality estimation and count how many joints there should be approximately.",
            "And this is the result of the approximation.",
            "OK, let's have a little bit closer look at what can happen and how we can, how errors can be introduced in this whole process.",
            "Services first the first Bloom filter contains the element ABC and D. No, but the second endpoint, the red one, is doing.",
            "He tries to match his findings against this Bloom filter.",
            "Assuming there's a false positive probability of 25%.",
            "This means that in addition to the two true positives, matches A&B.",
            "We have one false positive match, the X.",
            "So if one out of four elements are classified wrongly, being part of the Bloom filter, even though it's actually not the case because the CX is not part of the Bloom filter.",
            "Now the next step what is happening is that the red end point is creating a new Bloom filter with the bindings of the variable B.",
            "In this case it's 1, two and four.",
            "And note that red is including four into the new Bloom filter because it thinks that X was a positive match and the red endpoint cannot distinguish between false and true positive matches.",
            "Now assume that we have again the same false positive probability of 25%.",
            "We again have an you false positive match.",
            "In this case the five.",
            "It's again one out of four possibilities, 154 and six, and one of them is wrongly classified as being part of the Bloom filter.",
            "We also have again a true positive match, the Von Becausw as you see, the one is part of the Bloom filter, the red one.",
            "However, there's also something very interesting happening.",
            "You also see that the four is classified as a positive match.",
            "Because you see the forest part of Bloom filter.",
            "However, it's the result of a previous false positive match, so I call it a true positive of a false positive.",
            "And so now if we count how many solutions we will get running this query, our estimation is free, although the actual result is only one.",
            "So what we see we have a relative error of 200%.",
            "Even though we only have a false positive probability of 25."
        ],
        [
            "Now this is not nothing new so far, you only this it all studied nature of this propagation of errors, and this is happening in the database world all day.",
            "And the influence of this propagated error is worse when we have more number of joints.",
            "So the more joins they have, the more the false positives will create more and more error with propagate and will accumulate.",
            "So what are the experiment?"
        ],
        [
            "Cause that we got when we use bloomfields for approximation.",
            "You see Ivan example.",
            "In this case it's the Creality 10 from the Fed Bench benchmark.",
            "So what you see here is the relative error, which is basically the actual count of the query minus the estimate count and then.",
            "Yeah, the relative error.",
            "So relative to the actual count, what you see is that the error is quite high, so 540 means that estimated count was roughly 1600, but actually count is only free.",
            "So what type in swift execution time you see here?",
            "The dotted line indicates one.",
            "That means means that approximation was as fast as running the query on the actual data.",
            "However, our approximation is 17 times slower than running decree in the actual data.",
            "If you have a false positive probability of 10%, and if it decreases false positive property if you make the approximation more accurate.",
            "It's actually also faster.",
            "Any 15th this numbers are bad.",
            "Well they can also be."
        ],
        [
            "Much worse you see here, the relative errors up to 13,000 and the execution time is never below 18.",
            "Some."
        ],
        [
            "Observations well, first of all, the false positive probability have to be very small to get some reasonable small error.",
            "And somehow the execution time.",
            "It seems that we have more accurate synopsis with less compression of the data we actually perform faster, which is somehow strange.",
            "And eventually the approximation always runs somehow slower than running and query on the actual data."
        ],
        [
            "So how can we explain this behavior?",
            "So."
        ],
        [
            "I did some analysis and 1st I want to discuss the error."
        ],
        [
            "On the left side you see an example where have a high chance selectivity.",
            "So each nine of the 10 elements are joining actually, and we have two positive matches.",
            "However, there is a 10th element, the ex, which is not a true positive match, but the false positive match.",
            "So what happens?",
            "We have 9 through positive and one false positive match.",
            "And this leads to a relative error.",
            "Zero Point 1 one.",
            "So note that with a false positive probability of 10%, we get a relative error of around 11%, which is quite close to each other.",
            "However, if the transfer activity is very low, then something interesting is happening with the same false positive probability of 10%.",
            "You suddenly have a relative error of 1.",
            "Why cause the false positives are not changing but the true positives?",
            "Are suddenly very, very low and tense.",
            "The influence of the false positives is much more pronounced.",
            "So."
        ],
        [
            "We see that low low chance activities amplify the bad influence of false positives."
        ],
        [
            "And we put this into formula and so that if you have a very low chance selectivity then also your false positive has to be very low."
        ],
        [
            "Now let's have a look at execution time.",
            "If you have no approximation at all, you just run your query on your actual data."
        ],
        [
            "If you have a smaller false positive probability in addition to the two positives, you also have the false positives and these false positives are larger.",
            "If you have a large false positive probability.",
            "If you run the query and actual date, you have no compression at all.",
            "If you use some bloom filters, for example, you have some space efficient way of compressed data.",
            "And larger the false positive probability the height is compression is.",
            "However it can happen.",
            "That is, compression is not able to compensate increased number of false positives that you introduce in your approximation.",
            "And this is the reason why it can happen that your approximation runs actually slower than the actual critics a quetion."
        ],
        [
            "OK, what are the limitations and conclusions of my work?"
        ],
        [
            "So for the limitations we exclude that creates having unions options and filters because we didn't support him with our simple approximation mechanism.",
            "And we also assume that there is no bias for the propagation rate of false positives and true positives.",
            "For the conclusion."
        ],
        [
            "Since.",
            "Well, if you look at my examples, you might think that approximation methods with false projects are doomed to fail.",
            "This is not necessarily the case, but you have to consider a few points.",
            "First of all, if the chance selectivity is very low, you false positive probability has also to be very low, otherwise the error explodes.",
            "Second of all, the compression that you have using a data synopsis might not always be able to compensate the increasing false positives.",
            "And first of all, we assume some propagation.",
            "We assume that there's no propagation bias for false positive and true positives.",
            "If this is the case, then well, your error might not be so bad, because the false positives don't propagate.",
            "So if this I'm on, thanks."
        ],
        [
            "For a time and I'm happy to answer your questions, thank you.",
            "I was wondering how realistic these numbers are.",
            "There false positive error rate for a realistic size of the synopsis for Snooks is that it's actually synoptic, so of course it depends on the kinds of values and you're hashing and the hash function.",
            "But let's say that.",
            "You know, under normal assumptions and with your choice of a hash function, what's what's a reasonable relationship between the error rate and the size of the hash.",
            "OK, so if I send you correctly, so the question is what?",
            "What is a reasonable choice for the false positive rate and then also for the number of hash functions and so on.",
            "So maybe first of all I want to mention that I didn't implement the Bloom filters.",
            "I used an existing implementation and the point is the only parameter that you specify is the false positive probability given the false positive probability.",
            "Then you get the Bloom filter with a certain length and certain number of hash functions, so you don't choose the hash functions yourself.",
            "The standard way of using bloom filters if you don't specify false positive rate, it will use 3%, so this is somehow the well known standard of.",
            "It's a good compromise between being accurate and introducing error.",
            "Now the problem is that it really depends on the the join selectivity.",
            "What is a good choice for your false positive probability?",
            "So for some queries you might have a chance activity where only one out of a million is chosen with Eric Chan, so your false positive probability has to be quite much lower than one out of a million, otherwise your error explodes.",
            "This, but I was just wondering, you know if you aim for an error rate of say one out of 1000.",
            "Yeah, you know how big is the synopsis for OK OK assumptions, so I think I'm not sure about the length of the point that I think the role of fan base unit.",
            "The.",
            "Something like 7 bits for each element.",
            "If you have a false positive probability of 1%, you have something like that in mind.",
            "The point is that there's a formal tells you the length in number of bits in relation to the false positive probability, but I don't know this out of my head, but I think after going lower than 10 to minus 8 at some point doesn't make sense to call the approximation anymore because the lower your false positive probabilities, the larger bloom filter grows.",
            "And of course at some points.",
            "It's as speakers to actual data, but I can't give you an exact number, but there's a formal I think it grows with the logarithm of P. The length of the bloom filter, and basically an is the number of bits you need.",
            "So number pits grows in think logarithmically with none of the probability or inverse logarithm.",
            "IK There's a formula, but I don't know by heart I'm afraid.",
            "Could you go back to slide 4040?",
            "Yes, of course.",
            "Yeah.",
            "I'm looking just at properties P&Q so you are looking for resources that have both P&Q, but it seems that you are considering only explicit triples.",
            "Or what if there isn't any explicit resource that has both P&Q but there exists a resource with which has Q through inference because through the chain of reasoning, so is it possible to apply your off the shelf bloom filters to account for implicit triples, which are the real semantics of G and.",
            "And can this be done efficiently?",
            "So I think if you don't have actually if you have to influence which endpoint is responsible certain 3 point.",
            "I think this is this is a step before the approximation.",
            "So first of all you entered it, identify which endpoints are relevant for several triple pattern.",
            "Either you actually have PQ inside this endpoint or through inference you can say OK, there's something that is related to this and then.",
            "Once you have given candidate set of end points that you could assign to certain triple pattern, you then as next step has to have to choose which combination would yield how many results and I think this second step is then independent of whether you do this by inference or whether you have actual triple patterns that match end point and points, because it's basically the next step.",
            "Once you already realized which endpoints are relevant for triple pattern.",
            "Did I answer your questions such as family?",
            "Kind of maybe we have to discuss this in more depth afterwards here, but to be honest, I didn't go much in this direction, so I think this is something to think about.",
            "Yes, thank you.",
            "I think we will have more question, more time for questions.",
            "OK, thank you very much.",
            "Thank you very much for your time.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good afternoon.",
                    "label": 0
                },
                {
                    "sent": "Welcome to my presentation.",
                    "label": 0
                },
                {
                    "sent": "Changes of source selection in the web of data.",
                    "label": 1
                },
                {
                    "sent": "I wrote this paper together with Abraham Bernstein, Image Timothy Moore and since I can we are all from the Department of Informatics at University of Zurich.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is the motivation of my work?",
                    "label": 0
                },
                {
                    "sent": "Well, think about your favorite Spartan query and imagine that there is one single sparkle endpoint that holds all the data that you need for your query.",
                    "label": 0
                },
                {
                    "sent": "Well, things are.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice and simple.",
                    "label": 0
                },
                {
                    "sent": "You just create endpoint, you get all your data.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens if there's more than one single sparkle endpoint that is relevant for your specific query?",
                    "label": 0
                },
                {
                    "sent": "Well, what you can do is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You just create them all in a Federated fashion and you get a lot of solutions and everything is fine.",
                    "label": 0
                },
                {
                    "sent": "However, what you could also do is maybe you could.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exclude one of the sources and still get a reasonable number of solutions.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, if you exclude exclude too many sources, you might end up with an empty.",
                    "label": 0
                },
                {
                    "sent": "Result set.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what happens if there is not only free sources that are relevant for a query, but there are hundreds or even thousands?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem is it will just take too long to query all this relevant sources in a Federated fashion.",
                    "label": 0
                },
                {
                    "sent": "So you have to somehow select a subset of the sources to run your query on it.",
                    "label": 0
                },
                {
                    "sent": "And so the question is which one?",
                    "label": 0
                },
                {
                    "sent": "So the idea is, well, we should somehow be able to approximate how many solutions we will get when we select a specific set of sources.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my question is, which combination of endpoints approximately would lead?",
                    "label": 0
                },
                {
                    "sent": "How many solutions?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, you could approximate what happens if you run the query just on the middle sparkling point, and you would realize OK, just only maybe a handful of solutions.",
                    "label": 0
                },
                {
                    "sent": "Running",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your approximation on a different subset you would realize that there's much more estimated solutions that you would get intense.",
                    "label": 0
                },
                {
                    "sent": "You would decide for the latter option.",
                    "label": 0
                },
                {
                    "sent": "We can use Bloom filters, histograms, wavelets and many other techniques to do such an approximation.",
                    "label": 0
                },
                {
                    "sent": "But there's one big problem with this.",
                    "label": 0
                },
                {
                    "sent": "It turns out sometimes these approximations are really poor.",
                    "label": 0
                },
                {
                    "sent": "There really bad and not very useful for selecting sources.",
                    "label": 0
                },
                {
                    "sent": "And even worse than that is some types take awfully long to execute.",
                    "label": 0
                },
                {
                    "sent": "In fact, sometimes they need even longer for the approximation to execute.",
                    "label": 0
                },
                {
                    "sent": "Then you would need time to run the actual query on the actual data, and this is something that is completely against what we actually wanted initially.",
                    "label": 0
                },
                {
                    "sent": "To have a fast approximation of the result.",
                    "label": 0
                },
                {
                    "sent": "So how are we approximating queries well?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me show you by an example using Bloom filters.",
                    "label": 0
                },
                {
                    "sent": "Bloom filters basically just a bit vector.",
                    "label": 1
                },
                {
                    "sent": "Initially all bits are set to 0.",
                    "label": 0
                },
                {
                    "sent": "However, if you want to add.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I meant to the Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "You apply hash functions to this element.",
                    "label": 0
                },
                {
                    "sent": "And you set accordingly some bits from zero to 1.",
                    "label": 0
                },
                {
                    "sent": "You can add more than one element you apply again the hash functions to this element, and you set different bits from zero to 1.",
                    "label": 0
                },
                {
                    "sent": "Monster created you Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "You can test any element whether it is part of this Bloom filter or not.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you test the X against the Bloom filter we're played, I apply the same hash functions again and we see that all bits are one.",
                    "label": 0
                },
                {
                    "sent": "So we conclude yes, this X must be in the Bloom filter, and actually it is in the Bloom filter, so this is a true positive match.",
                    "label": 1
                },
                {
                    "sent": "However, what can also happen is that.",
                    "label": 0
                },
                {
                    "sent": "You apply the hash functions to different element.",
                    "label": 1
                },
                {
                    "sent": "You again see that all bits are flipped from zero to one, but it's actually a false positive match because the element was never part of the Bloom filter.",
                    "label": 1
                },
                {
                    "sent": "Now, this second case can happen with a certain probability, which is a parameter of the bloom filter, and we call this probability the false positive probability.",
                    "label": 1
                },
                {
                    "sent": "Finally, but also can happen, is that you have a true negative match.",
                    "label": 0
                },
                {
                    "sent": "So if you apply the hash function to an element and one of the bit is not one, you can conclude that the element was never part of the Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "So note that there is no possibility that you have a false negative match, so in the Bloom filter you only have two false positive, but you never have false negative.",
                    "label": 0
                },
                {
                    "sent": "To make this notation of a Bloom filter a little bit simpler, I.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write this approximation sign and X&Y to indicate that there's a Bloom filter containing the two elements X&Y.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's have a look at a simple query.",
                    "label": 0
                },
                {
                    "sent": "You see free triple patterns and I'll illustrate with the service clause that the three different triple patterns can be sent to the three different endpoints to get the result.",
                    "label": 0
                },
                {
                    "sent": "On the right side you have a lot of sparkle endpoints, and now you can choose how we assign this triples to different sparkle endpoints.",
                    "label": 0
                },
                {
                    "sent": "OK, let's make an example.",
                    "label": 0
                },
                {
                    "sent": "Assume that the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stripper pattern is to assign to the Blue Sparkle endpoint to second one to the red and defer to the green one.",
                    "label": 0
                },
                {
                    "sent": "Now, one possible way of April running this query is that you join first the first triple pattern with the second one via the variable A.",
                    "label": 0
                },
                {
                    "sent": "And then the result you join via variable B with the green and point and finally get the result.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now let's have a closer look at how we would approximate such a query.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, each endpoint gets its assigned triple pattern.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I indicate with this tables which are the bindings for each of these triple pattern.",
                    "label": 0
                },
                {
                    "sent": "Now the first thing that will happen is that the first endpoint will approximate it by its bindings.",
                    "label": 0
                },
                {
                    "sent": "And will create.",
                    "label": 0
                },
                {
                    "sent": "In our case, a Bloom filter out of this bindings.",
                    "label": 0
                },
                {
                    "sent": "This Bloom filter is transmitted to the right endpoint.",
                    "label": 0
                },
                {
                    "sent": "And to join happens.",
                    "label": 0
                },
                {
                    "sent": "The result of the joint is then added to another Bloom filter which is transmitted to the green endpoint.",
                    "label": 0
                },
                {
                    "sent": "Since the green endpoint is the last one in the sequence of joints, you can do now I'm cardinality estimation and count how many joints there should be approximately.",
                    "label": 0
                },
                {
                    "sent": "And this is the result of the approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, let's have a little bit closer look at what can happen and how we can, how errors can be introduced in this whole process.",
                    "label": 0
                },
                {
                    "sent": "Services first the first Bloom filter contains the element ABC and D. No, but the second endpoint, the red one, is doing.",
                    "label": 0
                },
                {
                    "sent": "He tries to match his findings against this Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "Assuming there's a false positive probability of 25%.",
                    "label": 0
                },
                {
                    "sent": "This means that in addition to the two true positives, matches A&B.",
                    "label": 0
                },
                {
                    "sent": "We have one false positive match, the X.",
                    "label": 0
                },
                {
                    "sent": "So if one out of four elements are classified wrongly, being part of the Bloom filter, even though it's actually not the case because the CX is not part of the Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "Now the next step what is happening is that the red end point is creating a new Bloom filter with the bindings of the variable B.",
                    "label": 0
                },
                {
                    "sent": "In this case it's 1, two and four.",
                    "label": 0
                },
                {
                    "sent": "And note that red is including four into the new Bloom filter because it thinks that X was a positive match and the red endpoint cannot distinguish between false and true positive matches.",
                    "label": 0
                },
                {
                    "sent": "Now assume that we have again the same false positive probability of 25%.",
                    "label": 0
                },
                {
                    "sent": "We again have an you false positive match.",
                    "label": 0
                },
                {
                    "sent": "In this case the five.",
                    "label": 0
                },
                {
                    "sent": "It's again one out of four possibilities, 154 and six, and one of them is wrongly classified as being part of the Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "We also have again a true positive match, the Von Becausw as you see, the one is part of the Bloom filter, the red one.",
                    "label": 0
                },
                {
                    "sent": "However, there's also something very interesting happening.",
                    "label": 0
                },
                {
                    "sent": "You also see that the four is classified as a positive match.",
                    "label": 0
                },
                {
                    "sent": "Because you see the forest part of Bloom filter.",
                    "label": 0
                },
                {
                    "sent": "However, it's the result of a previous false positive match, so I call it a true positive of a false positive.",
                    "label": 0
                },
                {
                    "sent": "And so now if we count how many solutions we will get running this query, our estimation is free, although the actual result is only one.",
                    "label": 0
                },
                {
                    "sent": "So what we see we have a relative error of 200%.",
                    "label": 0
                },
                {
                    "sent": "Even though we only have a false positive probability of 25.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this is not nothing new so far, you only this it all studied nature of this propagation of errors, and this is happening in the database world all day.",
                    "label": 0
                },
                {
                    "sent": "And the influence of this propagated error is worse when we have more number of joints.",
                    "label": 1
                },
                {
                    "sent": "So the more joins they have, the more the false positives will create more and more error with propagate and will accumulate.",
                    "label": 0
                },
                {
                    "sent": "So what are the experiment?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cause that we got when we use bloomfields for approximation.",
                    "label": 0
                },
                {
                    "sent": "You see Ivan example.",
                    "label": 0
                },
                {
                    "sent": "In this case it's the Creality 10 from the Fed Bench benchmark.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is the relative error, which is basically the actual count of the query minus the estimate count and then.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the relative error.",
                    "label": 0
                },
                {
                    "sent": "So relative to the actual count, what you see is that the error is quite high, so 540 means that estimated count was roughly 1600, but actually count is only free.",
                    "label": 0
                },
                {
                    "sent": "So what type in swift execution time you see here?",
                    "label": 0
                },
                {
                    "sent": "The dotted line indicates one.",
                    "label": 0
                },
                {
                    "sent": "That means means that approximation was as fast as running the query on the actual data.",
                    "label": 0
                },
                {
                    "sent": "However, our approximation is 17 times slower than running decree in the actual data.",
                    "label": 0
                },
                {
                    "sent": "If you have a false positive probability of 10%, and if it decreases false positive property if you make the approximation more accurate.",
                    "label": 0
                },
                {
                    "sent": "It's actually also faster.",
                    "label": 0
                },
                {
                    "sent": "Any 15th this numbers are bad.",
                    "label": 0
                },
                {
                    "sent": "Well they can also be.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much worse you see here, the relative errors up to 13,000 and the execution time is never below 18.",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Observations well, first of all, the false positive probability have to be very small to get some reasonable small error.",
                    "label": 1
                },
                {
                    "sent": "And somehow the execution time.",
                    "label": 1
                },
                {
                    "sent": "It seems that we have more accurate synopsis with less compression of the data we actually perform faster, which is somehow strange.",
                    "label": 1
                },
                {
                    "sent": "And eventually the approximation always runs somehow slower than running and query on the actual data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how can we explain this behavior?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I did some analysis and 1st I want to discuss the error.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the left side you see an example where have a high chance selectivity.",
                    "label": 0
                },
                {
                    "sent": "So each nine of the 10 elements are joining actually, and we have two positive matches.",
                    "label": 0
                },
                {
                    "sent": "However, there is a 10th element, the ex, which is not a true positive match, but the false positive match.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                },
                {
                    "sent": "We have 9 through positive and one false positive match.",
                    "label": 0
                },
                {
                    "sent": "And this leads to a relative error.",
                    "label": 0
                },
                {
                    "sent": "Zero Point 1 one.",
                    "label": 0
                },
                {
                    "sent": "So note that with a false positive probability of 10%, we get a relative error of around 11%, which is quite close to each other.",
                    "label": 0
                },
                {
                    "sent": "However, if the transfer activity is very low, then something interesting is happening with the same false positive probability of 10%.",
                    "label": 0
                },
                {
                    "sent": "You suddenly have a relative error of 1.",
                    "label": 0
                },
                {
                    "sent": "Why cause the false positives are not changing but the true positives?",
                    "label": 0
                },
                {
                    "sent": "Are suddenly very, very low and tense.",
                    "label": 0
                },
                {
                    "sent": "The influence of the false positives is much more pronounced.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We see that low low chance activities amplify the bad influence of false positives.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we put this into formula and so that if you have a very low chance selectivity then also your false positive has to be very low.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's have a look at execution time.",
                    "label": 0
                },
                {
                    "sent": "If you have no approximation at all, you just run your query on your actual data.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have a smaller false positive probability in addition to the two positives, you also have the false positives and these false positives are larger.",
                    "label": 0
                },
                {
                    "sent": "If you have a large false positive probability.",
                    "label": 0
                },
                {
                    "sent": "If you run the query and actual date, you have no compression at all.",
                    "label": 0
                },
                {
                    "sent": "If you use some bloom filters, for example, you have some space efficient way of compressed data.",
                    "label": 0
                },
                {
                    "sent": "And larger the false positive probability the height is compression is.",
                    "label": 0
                },
                {
                    "sent": "However it can happen.",
                    "label": 0
                },
                {
                    "sent": "That is, compression is not able to compensate increased number of false positives that you introduce in your approximation.",
                    "label": 0
                },
                {
                    "sent": "And this is the reason why it can happen that your approximation runs actually slower than the actual critics a quetion.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, what are the limitations and conclusions of my work?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the limitations we exclude that creates having unions options and filters because we didn't support him with our simple approximation mechanism.",
                    "label": 0
                },
                {
                    "sent": "And we also assume that there is no bias for the propagation rate of false positives and true positives.",
                    "label": 1
                },
                {
                    "sent": "For the conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Since.",
                    "label": 0
                },
                {
                    "sent": "Well, if you look at my examples, you might think that approximation methods with false projects are doomed to fail.",
                    "label": 0
                },
                {
                    "sent": "This is not necessarily the case, but you have to consider a few points.",
                    "label": 0
                },
                {
                    "sent": "First of all, if the chance selectivity is very low, you false positive probability has also to be very low, otherwise the error explodes.",
                    "label": 0
                },
                {
                    "sent": "Second of all, the compression that you have using a data synopsis might not always be able to compensate the increasing false positives.",
                    "label": 1
                },
                {
                    "sent": "And first of all, we assume some propagation.",
                    "label": 0
                },
                {
                    "sent": "We assume that there's no propagation bias for false positive and true positives.",
                    "label": 1
                },
                {
                    "sent": "If this is the case, then well, your error might not be so bad, because the false positives don't propagate.",
                    "label": 0
                },
                {
                    "sent": "So if this I'm on, thanks.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For a time and I'm happy to answer your questions, thank you.",
                    "label": 1
                },
                {
                    "sent": "I was wondering how realistic these numbers are.",
                    "label": 0
                },
                {
                    "sent": "There false positive error rate for a realistic size of the synopsis for Snooks is that it's actually synoptic, so of course it depends on the kinds of values and you're hashing and the hash function.",
                    "label": 0
                },
                {
                    "sent": "But let's say that.",
                    "label": 0
                },
                {
                    "sent": "You know, under normal assumptions and with your choice of a hash function, what's what's a reasonable relationship between the error rate and the size of the hash.",
                    "label": 0
                },
                {
                    "sent": "OK, so if I send you correctly, so the question is what?",
                    "label": 0
                },
                {
                    "sent": "What is a reasonable choice for the false positive rate and then also for the number of hash functions and so on.",
                    "label": 0
                },
                {
                    "sent": "So maybe first of all I want to mention that I didn't implement the Bloom filters.",
                    "label": 0
                },
                {
                    "sent": "I used an existing implementation and the point is the only parameter that you specify is the false positive probability given the false positive probability.",
                    "label": 0
                },
                {
                    "sent": "Then you get the Bloom filter with a certain length and certain number of hash functions, so you don't choose the hash functions yourself.",
                    "label": 0
                },
                {
                    "sent": "The standard way of using bloom filters if you don't specify false positive rate, it will use 3%, so this is somehow the well known standard of.",
                    "label": 0
                },
                {
                    "sent": "It's a good compromise between being accurate and introducing error.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is that it really depends on the the join selectivity.",
                    "label": 0
                },
                {
                    "sent": "What is a good choice for your false positive probability?",
                    "label": 0
                },
                {
                    "sent": "So for some queries you might have a chance activity where only one out of a million is chosen with Eric Chan, so your false positive probability has to be quite much lower than one out of a million, otherwise your error explodes.",
                    "label": 0
                },
                {
                    "sent": "This, but I was just wondering, you know if you aim for an error rate of say one out of 1000.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you know how big is the synopsis for OK OK assumptions, so I think I'm not sure about the length of the point that I think the role of fan base unit.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Something like 7 bits for each element.",
                    "label": 0
                },
                {
                    "sent": "If you have a false positive probability of 1%, you have something like that in mind.",
                    "label": 0
                },
                {
                    "sent": "The point is that there's a formal tells you the length in number of bits in relation to the false positive probability, but I don't know this out of my head, but I think after going lower than 10 to minus 8 at some point doesn't make sense to call the approximation anymore because the lower your false positive probabilities, the larger bloom filter grows.",
                    "label": 0
                },
                {
                    "sent": "And of course at some points.",
                    "label": 0
                },
                {
                    "sent": "It's as speakers to actual data, but I can't give you an exact number, but there's a formal I think it grows with the logarithm of P. The length of the bloom filter, and basically an is the number of bits you need.",
                    "label": 0
                },
                {
                    "sent": "So number pits grows in think logarithmically with none of the probability or inverse logarithm.",
                    "label": 0
                },
                {
                    "sent": "IK There's a formula, but I don't know by heart I'm afraid.",
                    "label": 0
                },
                {
                    "sent": "Could you go back to slide 4040?",
                    "label": 0
                },
                {
                    "sent": "Yes, of course.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I'm looking just at properties P&Q so you are looking for resources that have both P&Q, but it seems that you are considering only explicit triples.",
                    "label": 0
                },
                {
                    "sent": "Or what if there isn't any explicit resource that has both P&Q but there exists a resource with which has Q through inference because through the chain of reasoning, so is it possible to apply your off the shelf bloom filters to account for implicit triples, which are the real semantics of G and.",
                    "label": 0
                },
                {
                    "sent": "And can this be done efficiently?",
                    "label": 0
                },
                {
                    "sent": "So I think if you don't have actually if you have to influence which endpoint is responsible certain 3 point.",
                    "label": 0
                },
                {
                    "sent": "I think this is this is a step before the approximation.",
                    "label": 0
                },
                {
                    "sent": "So first of all you entered it, identify which endpoints are relevant for several triple pattern.",
                    "label": 0
                },
                {
                    "sent": "Either you actually have PQ inside this endpoint or through inference you can say OK, there's something that is related to this and then.",
                    "label": 0
                },
                {
                    "sent": "Once you have given candidate set of end points that you could assign to certain triple pattern, you then as next step has to have to choose which combination would yield how many results and I think this second step is then independent of whether you do this by inference or whether you have actual triple patterns that match end point and points, because it's basically the next step.",
                    "label": 0
                },
                {
                    "sent": "Once you already realized which endpoints are relevant for triple pattern.",
                    "label": 0
                },
                {
                    "sent": "Did I answer your questions such as family?",
                    "label": 0
                },
                {
                    "sent": "Kind of maybe we have to discuss this in more depth afterwards here, but to be honest, I didn't go much in this direction, so I think this is something to think about.",
                    "label": 0
                },
                {
                    "sent": "Yes, thank you.",
                    "label": 0
                },
                {
                    "sent": "I think we will have more question, more time for questions.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your time.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}