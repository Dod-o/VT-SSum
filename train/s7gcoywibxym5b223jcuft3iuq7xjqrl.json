{
    "id": "s7gcoywibxym5b223jcuft3iuq7xjqrl",
    "title": "Incremental Light Bundle Adjustment",
    "info": {
        "author": [
            "Vadim Indelman, Georgia Institute of Technology"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Color, Texture, Illumination & Reflectance"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_indelman_bundle_adjustment/",
    "segmentation": [
        [
            "But I'm going to talk about incremental like bundle adjustment and this is joint work with Richard Roberts, Chris Bill and Frank Dirt.",
            "So in bundle adjustment we are given a sequence of images."
        ],
        [
            "And the goal is to actually to reconstruct the camera poses and the structure that is observed from these images.",
            "And this kind of problems are relevant in a variety of applications such as structure from motion, augmented reality and also in robotics in particular, for full simultaneous localization and mapping and for distributed smoothing and mapping.",
            "So essentially we have a large optimization problem where we would like to minimize the overall sum of the reprojection errors."
        ],
        [
            "And indeed, several efficient solvers exists that exploit the sparsity of the typical structure from motion problems.",
            "So we have these sparse bundle adjustment and the sparse sparse bundle adjustment that exploits the secondary sparsity structure, and more recently we have been robotics community method process induced that is called incremental smoothing and mapping that in addition to exploiting the sparsity, also allows reform.",
            "Efficient, incremental inference and this work is going to use this solver as well, but at the end of the day, the problem is that we are given an cameras and that observe M3 points and optimization is going to be over 6 and plus 3M variables.",
            "So the question is, can we somehow reduce the number of variables in the optimization?",
            "Cindy did interfere in the last."
        ],
        [
            "Two or three years, several methods have been proposed for that are called here as Structureless bundle adjustment, where the optimization is made only over the camera poses and does not include any three points in the invitation.",
            "So for that the three points are algebraically illuminated from the optimization and the cost function is formulated using the multiview constraints and this of course leads to significantly less.",
            "Number of variables to optimize?",
            "Of course, that if indeed this structure is actually required, we can always perform structural construction using the software optimized camera poses.",
            "One thing to note is that all the methods that were proposed so far perform a batch optimization, which is quite expensive.",
            "So in this work."
        ],
        [
            "We combine the following two ideas.",
            "We're going to use structure as bundle adjustment, and in particular we're going to use three view constraints to allow inconsistent motion estimate on.",
            "Also, when the camera centers are collinear.",
            "And the second ingredient will be incremental inference over graphical models that essentially will allow us to selectively optimize only part of the camera poses without compromising the accuracy at all.",
            "So let me start with the first part.",
            "So one possible approach."
        ],
        [
            "For for the cost function in structure is bundle adjustment is to approximate the reprojection errors by the difference between the measured and the correct visual observations where the correction is made by satisfying the overall multiview constraints.",
            "Here H denotes all the applicable multi constraints where each.",
            "Such constraint is a function of several camera poses in the given sequence of images.",
            "Now, as you can see, this cost function is actually a function of camera poses and also of the corrected visual observations and therefore the number of the actual variables that need to be optimized.",
            "Here is quite larger than bundle adjustment that so that that is not precisely what we want.",
            "So to address this issue, we're going to make another approximation."
        ],
        [
            "And adopt the observation made by Drygas last year, so that we will not correct the visual observations and we therefore can reformulate the cost function as follows.",
            "As you can see, this cost function is only a function of the camera poses and therefore the number of the variables in the optimization is only 6 and as opposed to 6 N plus 3M in conventional bundle adjustment.",
            "We also extend the formulation of Rodriguez by incorporating Mahalanobis norm, where in theory this norm should be calculated using the equipment Co variance.",
            "That is different for each legalization of this nonlinear function.",
            "But in practice, as we will see in the results section, we can only calculate these this term only once without sacrificing the accuracy at all."
        ],
        [
            "So let me talk about the actual constraints that are used in LBA.",
            "We're going to use three constraints that can be derived by algebraically eliminating some 3 point that are that is observed by any 3 views KL&M.",
            "And see here.",
            "These are the actual constraints where Qi is just in the calibrated pixel transfer to some global frame.",
            "So the first 2 equations are the well known, two view geometry constraints, or the people are constraints between views.",
            "K&L in between views, L&M.",
            "The third equation, however, allows us to maintain a consistent scale between the given views and what is interesting is that these three equations allowed to maintain consistency.",
            "Also, when the camera configuration are collinear, which is not possible if we only rely on people geometry constraints.",
            "So now I'm going to talk about the second part, the incremental."
        ],
        [
            "Prince like bundle adjustment.",
            "So all previous approaches perform batch optimization, which means that we are solving for all the variables, which in this case our camera poses each time a new image is added and this is regardless to the optimized cost function.",
            "However, there are two distinct cases that are that we would like to note when we have shorter features.",
            "These features encode only available information for the most recent few images and will not influence any other images in the past.",
            "On the other case, if we have observed the same feature, such as loop closures or we observe the same feature many, many times, then of course many more camera poses will be actually updated in the optimization.",
            "So in order to encode this into our framework, we propose the following.",
            "Each time."
        ],
        [
            "A new image is received.",
            "We adaptively identify what camera frames should be actually updated and update only these cameras while reusing calculations from the previous step and the whole thing is going to be based on the Isom to approach the incremental inference, and for that we are going now to formulate the problem using a factor graph which is strongly related to a random and mark of random field and then to convert the factor graph.",
            "2IN base net and also to a direct junction tree.",
            "So consider the maximum posterior estimates that we have.",
            "Here we have the joint probability function of all."
        ],
        [
            "Variables X, given all the measurements so far, we can always factorize this joint PDF by stating the individual measurement and process models in our problem.",
            "For example, here we have some prior factor term, some process models and some measurement model terms.",
            "We can consider each such term as a single factor in this factorization so that each factor, if I depends on a subset of variables.",
            "In the overall set of variables that we have.",
            "So in our case the variables are just the camera."
        ],
        [
            "Poses and the factors will be the two and three view constraints that we have seen in the previous slides, so this is a graphical representation of these factorization with, for example, 4 camera poses and several two view in three view factors.",
            "OK, so we have a factor graph.",
            "What is a good for?",
            "So let us consider once again the nonlinear optimization that we're trying to solve in factor graph language.",
            "We're just trying to."
        ],
        [
            "Perform inference over this nonlinear function.",
            "And this and this optimization, since it is nonlinear, involves repeated linearisation of the function regional function, so we have a linear equation that we are solving for Delta and then updating the unionization point and hence force.",
            "So the issue here is that since a the Jacobian matrix tends to be sparse large Jacobian matrix, we usually perform factorization of these metrics using techniques such as you are.",
            "This key factorization and the idea."
        ],
        [
            "Is that we?",
            "Actually when we add a new camera pose, we actually can reuse calculations.",
            "In particular, we don't have to recalculate the factorization of a from scratch each time we're going to update this factorization from the factorization from the previous step.",
            "Another idea is to.",
            "Form regionalization and to solve for only part of the variables in the large vector that we have as well as we'll see in a few moments.",
            "So for that for these two issues, we're going to convert the factor graph into a Bayes net.",
            "So to illustrate."
        ],
        [
            "These let us consider a very basic example with three camera poses that are related by only two view constraints.",
            "We have two constraints here and three constraints between the 2nd and the 3rd frame, so the underlying nonlinear problem can be linearized and we will obtain the following Jacobian matrix and a factorization of these metrics will give us the following upper triangular matrix R. So the equivalent process to these two steps is actually go back go direct."
        ],
        [
            "From the factor graph to the base net by first linearizing and then eliminating each node in the factor graph using a chosen elimination order.",
            "So that each node here presents the conditional condition of the previous nodes."
        ],
        [
            "Well OK, we have the best net what what's next?",
            "The idea is to get when we add new measurements or or new camera poses.",
            "The best net can be updated only into relevant parts and not be entirely recalculated each time.",
            "So let us see the this.",
            "In this example we have the blue lines present.",
            "The old information we added here in new camera pose and two factors until you factor in the three refactor now.",
            "Using matrices, the update will involve unionization.",
            "With these two new rows being added and the factorization with with only this area being the modified area.",
            "While these two elements in this case are going to be exactly the same as in the previous step, before we actually added this new information.",
            "Well, in the in terms of a base net, if we have the previous base net, we can go directly and update this base net to the following formulation where only this part is changing and this node remains the same, so that the conditional of X1 given X2 is not changing.",
            "Because of this new information.",
            "Of course this is just basic example, but in practice we tend to have very large factor graphs and quite a few.",
            "Nodes very few nodes are going to be actually changed in the base net each time.",
            "So OK, so one question that could be asked is how to actually identify which parts in the base net in the base net should be updated."
        ],
        [
            "So for that we are going to convert the base net into a directed junction tree, also known as a base tree, and Additionally additional data can be found in this paper.",
            "So let me just say the big picture of the overall algorithm we have the non linear cost function that we would like to optimize over.",
            "We have the linear, we have a very efficient method to factor the Jacobian matrix A and now that we.",
            "No, the Jacobian we can instead of calculating the Delta vector for all the variables, we can actually perform back substitution only on the part of the variables that are going to actually change, and the other issue is that instead of performing realization each step for the whole variables, we're going to perform linearizations only on part of the variables and only when required and not each time as usual.",
            "So let me show you some results.",
            "It hurts.",
            "I'm going to show results for these.",
            "Typically small datasets should stay there."
        ],
        [
            "At this point, we rely on that the image correspondences an camera calibrations are given, and in this example, in this result we first ran Bander to get these two inputs.",
            "So in the results I'm going to."
        ],
        [
            "Compare between these four different methods.",
            "We have the light bundle adjustment method.",
            "We have a variation of that where the covariance Sigma I is recalculated each time as I mentioned before, and we're going to compare it also to the structure as bundle adjustment and to the conventional bundle adjustment cost function."
        ],
        [
            "So here you can see a typical graph for one of the data sets that compares between the computational time and the average projection error.",
            "You can see for each method in arrow that goes from incremental batch through incremental smoothing.",
            "So in the overall we can see that switching to incremental smoothing allows us to greatly save computational time without compromising at all the accuracy of the projection error.",
            "While compare between bundle adjustment and light, bundle adjustment reveals that we have, we have pretty much the same accuracy bit deteriorate in the case of LBA, but the computational time is much shorter than bundle adjustment.",
            "For example, in this case, around 17 seconds as opposed to 100 seconds.",
            "Here are some more results for just for the incremental smoothing approach.",
            "Compare between bundle adjustment and the rest."
        ],
        [
            "The bundle adjustment.",
            "I'll be in the rest of the methods we can see here.",
            "Reprojection errors and computational cost.",
            "So the main part to see here is that the accuracy is a bit deteriorated in LBA as opposed to bundle adjustment.",
            "But the computational cost is much much more attractive.",
            "And finally, I would like to present some."
        ],
        [
            "Results of some larger data sets, so this is a data set for 150 images.",
            "You can see the computational time in the current implementation of LBA.",
            "And you can see that only a few cameras are moved each time a new image is actually added."
        ],
        [
            "And here is another data set.",
            "This is in outdoor data set with about 300 images and about 74,000 three points.",
            "You can see that.",
            "Once again, only a few cameras are actually moved, unless we have a loop closure, so we will have a look close around here and then the entire route here.",
            "The entire path here will be updated accordingly.",
            "So you can see now and of course at each time and we can actually reconstruct the three points as it's now based on the LB optimized camera poses.",
            "So to conclude this talk I present."
        ],
        [
            "Other incremental light bundle adjustment method.",
            "This method allowed to reduce the number of variables by algebraically eliminating the three points from the optimization.",
            "And another significant computational gain was obtained by applying incremental inference, where in practice only on the relevant part of the camera poses were updated each time."
        ],
        [
            "You"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I'm going to talk about incremental like bundle adjustment and this is joint work with Richard Roberts, Chris Bill and Frank Dirt.",
                    "label": 0
                },
                {
                    "sent": "So in bundle adjustment we are given a sequence of images.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the goal is to actually to reconstruct the camera poses and the structure that is observed from these images.",
                    "label": 1
                },
                {
                    "sent": "And this kind of problems are relevant in a variety of applications such as structure from motion, augmented reality and also in robotics in particular, for full simultaneous localization and mapping and for distributed smoothing and mapping.",
                    "label": 1
                },
                {
                    "sent": "So essentially we have a large optimization problem where we would like to minimize the overall sum of the reprojection errors.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And indeed, several efficient solvers exists that exploit the sparsity of the typical structure from motion problems.",
                    "label": 1
                },
                {
                    "sent": "So we have these sparse bundle adjustment and the sparse sparse bundle adjustment that exploits the secondary sparsity structure, and more recently we have been robotics community method process induced that is called incremental smoothing and mapping that in addition to exploiting the sparsity, also allows reform.",
                    "label": 0
                },
                {
                    "sent": "Efficient, incremental inference and this work is going to use this solver as well, but at the end of the day, the problem is that we are given an cameras and that observe M3 points and optimization is going to be over 6 and plus 3M variables.",
                    "label": 1
                },
                {
                    "sent": "So the question is, can we somehow reduce the number of variables in the optimization?",
                    "label": 0
                },
                {
                    "sent": "Cindy did interfere in the last.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two or three years, several methods have been proposed for that are called here as Structureless bundle adjustment, where the optimization is made only over the camera poses and does not include any three points in the invitation.",
                    "label": 1
                },
                {
                    "sent": "So for that the three points are algebraically illuminated from the optimization and the cost function is formulated using the multiview constraints and this of course leads to significantly less.",
                    "label": 1
                },
                {
                    "sent": "Number of variables to optimize?",
                    "label": 0
                },
                {
                    "sent": "Of course, that if indeed this structure is actually required, we can always perform structural construction using the software optimized camera poses.",
                    "label": 0
                },
                {
                    "sent": "One thing to note is that all the methods that were proposed so far perform a batch optimization, which is quite expensive.",
                    "label": 0
                },
                {
                    "sent": "So in this work.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We combine the following two ideas.",
                    "label": 0
                },
                {
                    "sent": "We're going to use structure as bundle adjustment, and in particular we're going to use three view constraints to allow inconsistent motion estimate on.",
                    "label": 0
                },
                {
                    "sent": "Also, when the camera centers are collinear.",
                    "label": 1
                },
                {
                    "sent": "And the second ingredient will be incremental inference over graphical models that essentially will allow us to selectively optimize only part of the camera poses without compromising the accuracy at all.",
                    "label": 1
                },
                {
                    "sent": "So let me start with the first part.",
                    "label": 0
                },
                {
                    "sent": "So one possible approach.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For for the cost function in structure is bundle adjustment is to approximate the reprojection errors by the difference between the measured and the correct visual observations where the correction is made by satisfying the overall multiview constraints.",
                    "label": 1
                },
                {
                    "sent": "Here H denotes all the applicable multi constraints where each.",
                    "label": 1
                },
                {
                    "sent": "Such constraint is a function of several camera poses in the given sequence of images.",
                    "label": 0
                },
                {
                    "sent": "Now, as you can see, this cost function is actually a function of camera poses and also of the corrected visual observations and therefore the number of the actual variables that need to be optimized.",
                    "label": 0
                },
                {
                    "sent": "Here is quite larger than bundle adjustment that so that that is not precisely what we want.",
                    "label": 0
                },
                {
                    "sent": "So to address this issue, we're going to make another approximation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And adopt the observation made by Drygas last year, so that we will not correct the visual observations and we therefore can reformulate the cost function as follows.",
                    "label": 0
                },
                {
                    "sent": "As you can see, this cost function is only a function of the camera poses and therefore the number of the variables in the optimization is only 6 and as opposed to 6 N plus 3M in conventional bundle adjustment.",
                    "label": 1
                },
                {
                    "sent": "We also extend the formulation of Rodriguez by incorporating Mahalanobis norm, where in theory this norm should be calculated using the equipment Co variance.",
                    "label": 0
                },
                {
                    "sent": "That is different for each legalization of this nonlinear function.",
                    "label": 1
                },
                {
                    "sent": "But in practice, as we will see in the results section, we can only calculate these this term only once without sacrificing the accuracy at all.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me talk about the actual constraints that are used in LBA.",
                    "label": 0
                },
                {
                    "sent": "We're going to use three constraints that can be derived by algebraically eliminating some 3 point that are that is observed by any 3 views KL&M.",
                    "label": 1
                },
                {
                    "sent": "And see here.",
                    "label": 0
                },
                {
                    "sent": "These are the actual constraints where Qi is just in the calibrated pixel transfer to some global frame.",
                    "label": 0
                },
                {
                    "sent": "So the first 2 equations are the well known, two view geometry constraints, or the people are constraints between views.",
                    "label": 0
                },
                {
                    "sent": "K&L in between views, L&M.",
                    "label": 0
                },
                {
                    "sent": "The third equation, however, allows us to maintain a consistent scale between the given views and what is interesting is that these three equations allowed to maintain consistency.",
                    "label": 1
                },
                {
                    "sent": "Also, when the camera configuration are collinear, which is not possible if we only rely on people geometry constraints.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to talk about the second part, the incremental.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prince like bundle adjustment.",
                    "label": 0
                },
                {
                    "sent": "So all previous approaches perform batch optimization, which means that we are solving for all the variables, which in this case our camera poses each time a new image is added and this is regardless to the optimized cost function.",
                    "label": 1
                },
                {
                    "sent": "However, there are two distinct cases that are that we would like to note when we have shorter features.",
                    "label": 1
                },
                {
                    "sent": "These features encode only available information for the most recent few images and will not influence any other images in the past.",
                    "label": 0
                },
                {
                    "sent": "On the other case, if we have observed the same feature, such as loop closures or we observe the same feature many, many times, then of course many more camera poses will be actually updated in the optimization.",
                    "label": 0
                },
                {
                    "sent": "So in order to encode this into our framework, we propose the following.",
                    "label": 0
                },
                {
                    "sent": "Each time.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A new image is received.",
                    "label": 1
                },
                {
                    "sent": "We adaptively identify what camera frames should be actually updated and update only these cameras while reusing calculations from the previous step and the whole thing is going to be based on the Isom to approach the incremental inference, and for that we are going now to formulate the problem using a factor graph which is strongly related to a random and mark of random field and then to convert the factor graph.",
                    "label": 1
                },
                {
                    "sent": "2IN base net and also to a direct junction tree.",
                    "label": 0
                },
                {
                    "sent": "So consider the maximum posterior estimates that we have.",
                    "label": 0
                },
                {
                    "sent": "Here we have the joint probability function of all.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Variables X, given all the measurements so far, we can always factorize this joint PDF by stating the individual measurement and process models in our problem.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have some prior factor term, some process models and some measurement model terms.",
                    "label": 0
                },
                {
                    "sent": "We can consider each such term as a single factor in this factorization so that each factor, if I depends on a subset of variables.",
                    "label": 1
                },
                {
                    "sent": "In the overall set of variables that we have.",
                    "label": 0
                },
                {
                    "sent": "So in our case the variables are just the camera.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Poses and the factors will be the two and three view constraints that we have seen in the previous slides, so this is a graphical representation of these factorization with, for example, 4 camera poses and several two view in three view factors.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have a factor graph.",
                    "label": 0
                },
                {
                    "sent": "What is a good for?",
                    "label": 0
                },
                {
                    "sent": "So let us consider once again the nonlinear optimization that we're trying to solve in factor graph language.",
                    "label": 0
                },
                {
                    "sent": "We're just trying to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Perform inference over this nonlinear function.",
                    "label": 0
                },
                {
                    "sent": "And this and this optimization, since it is nonlinear, involves repeated linearisation of the function regional function, so we have a linear equation that we are solving for Delta and then updating the unionization point and hence force.",
                    "label": 0
                },
                {
                    "sent": "So the issue here is that since a the Jacobian matrix tends to be sparse large Jacobian matrix, we usually perform factorization of these metrics using techniques such as you are.",
                    "label": 1
                },
                {
                    "sent": "This key factorization and the idea.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that we?",
                    "label": 0
                },
                {
                    "sent": "Actually when we add a new camera pose, we actually can reuse calculations.",
                    "label": 1
                },
                {
                    "sent": "In particular, we don't have to recalculate the factorization of a from scratch each time we're going to update this factorization from the factorization from the previous step.",
                    "label": 0
                },
                {
                    "sent": "Another idea is to.",
                    "label": 1
                },
                {
                    "sent": "Form regionalization and to solve for only part of the variables in the large vector that we have as well as we'll see in a few moments.",
                    "label": 0
                },
                {
                    "sent": "So for that for these two issues, we're going to convert the factor graph into a Bayes net.",
                    "label": 1
                },
                {
                    "sent": "So to illustrate.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These let us consider a very basic example with three camera poses that are related by only two view constraints.",
                    "label": 0
                },
                {
                    "sent": "We have two constraints here and three constraints between the 2nd and the 3rd frame, so the underlying nonlinear problem can be linearized and we will obtain the following Jacobian matrix and a factorization of these metrics will give us the following upper triangular matrix R. So the equivalent process to these two steps is actually go back go direct.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the factor graph to the base net by first linearizing and then eliminating each node in the factor graph using a chosen elimination order.",
                    "label": 0
                },
                {
                    "sent": "So that each node here presents the conditional condition of the previous nodes.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well OK, we have the best net what what's next?",
                    "label": 0
                },
                {
                    "sent": "The idea is to get when we add new measurements or or new camera poses.",
                    "label": 1
                },
                {
                    "sent": "The best net can be updated only into relevant parts and not be entirely recalculated each time.",
                    "label": 0
                },
                {
                    "sent": "So let us see the this.",
                    "label": 0
                },
                {
                    "sent": "In this example we have the blue lines present.",
                    "label": 0
                },
                {
                    "sent": "The old information we added here in new camera pose and two factors until you factor in the three refactor now.",
                    "label": 1
                },
                {
                    "sent": "Using matrices, the update will involve unionization.",
                    "label": 0
                },
                {
                    "sent": "With these two new rows being added and the factorization with with only this area being the modified area.",
                    "label": 0
                },
                {
                    "sent": "While these two elements in this case are going to be exactly the same as in the previous step, before we actually added this new information.",
                    "label": 0
                },
                {
                    "sent": "Well, in the in terms of a base net, if we have the previous base net, we can go directly and update this base net to the following formulation where only this part is changing and this node remains the same, so that the conditional of X1 given X2 is not changing.",
                    "label": 0
                },
                {
                    "sent": "Because of this new information.",
                    "label": 0
                },
                {
                    "sent": "Of course this is just basic example, but in practice we tend to have very large factor graphs and quite a few.",
                    "label": 0
                },
                {
                    "sent": "Nodes very few nodes are going to be actually changed in the base net each time.",
                    "label": 0
                },
                {
                    "sent": "So OK, so one question that could be asked is how to actually identify which parts in the base net in the base net should be updated.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for that we are going to convert the base net into a directed junction tree, also known as a base tree, and Additionally additional data can be found in this paper.",
                    "label": 1
                },
                {
                    "sent": "So let me just say the big picture of the overall algorithm we have the non linear cost function that we would like to optimize over.",
                    "label": 0
                },
                {
                    "sent": "We have the linear, we have a very efficient method to factor the Jacobian matrix A and now that we.",
                    "label": 0
                },
                {
                    "sent": "No, the Jacobian we can instead of calculating the Delta vector for all the variables, we can actually perform back substitution only on the part of the variables that are going to actually change, and the other issue is that instead of performing realization each step for the whole variables, we're going to perform linearizations only on part of the variables and only when required and not each time as usual.",
                    "label": 1
                },
                {
                    "sent": "So let me show you some results.",
                    "label": 0
                },
                {
                    "sent": "It hurts.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show results for these.",
                    "label": 0
                },
                {
                    "sent": "Typically small datasets should stay there.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At this point, we rely on that the image correspondences an camera calibrations are given, and in this example, in this result we first ran Bander to get these two inputs.",
                    "label": 0
                },
                {
                    "sent": "So in the results I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Compare between these four different methods.",
                    "label": 0
                },
                {
                    "sent": "We have the light bundle adjustment method.",
                    "label": 1
                },
                {
                    "sent": "We have a variation of that where the covariance Sigma I is recalculated each time as I mentioned before, and we're going to compare it also to the structure as bundle adjustment and to the conventional bundle adjustment cost function.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here you can see a typical graph for one of the data sets that compares between the computational time and the average projection error.",
                    "label": 0
                },
                {
                    "sent": "You can see for each method in arrow that goes from incremental batch through incremental smoothing.",
                    "label": 0
                },
                {
                    "sent": "So in the overall we can see that switching to incremental smoothing allows us to greatly save computational time without compromising at all the accuracy of the projection error.",
                    "label": 0
                },
                {
                    "sent": "While compare between bundle adjustment and light, bundle adjustment reveals that we have, we have pretty much the same accuracy bit deteriorate in the case of LBA, but the computational time is much shorter than bundle adjustment.",
                    "label": 1
                },
                {
                    "sent": "For example, in this case, around 17 seconds as opposed to 100 seconds.",
                    "label": 0
                },
                {
                    "sent": "Here are some more results for just for the incremental smoothing approach.",
                    "label": 0
                },
                {
                    "sent": "Compare between bundle adjustment and the rest.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The bundle adjustment.",
                    "label": 0
                },
                {
                    "sent": "I'll be in the rest of the methods we can see here.",
                    "label": 0
                },
                {
                    "sent": "Reprojection errors and computational cost.",
                    "label": 1
                },
                {
                    "sent": "So the main part to see here is that the accuracy is a bit deteriorated in LBA as opposed to bundle adjustment.",
                    "label": 0
                },
                {
                    "sent": "But the computational cost is much much more attractive.",
                    "label": 0
                },
                {
                    "sent": "And finally, I would like to present some.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results of some larger data sets, so this is a data set for 150 images.",
                    "label": 0
                },
                {
                    "sent": "You can see the computational time in the current implementation of LBA.",
                    "label": 0
                },
                {
                    "sent": "And you can see that only a few cameras are moved each time a new image is actually added.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is another data set.",
                    "label": 0
                },
                {
                    "sent": "This is in outdoor data set with about 300 images and about 74,000 three points.",
                    "label": 0
                },
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "Once again, only a few cameras are actually moved, unless we have a loop closure, so we will have a look close around here and then the entire route here.",
                    "label": 0
                },
                {
                    "sent": "The entire path here will be updated accordingly.",
                    "label": 0
                },
                {
                    "sent": "So you can see now and of course at each time and we can actually reconstruct the three points as it's now based on the LB optimized camera poses.",
                    "label": 0
                },
                {
                    "sent": "So to conclude this talk I present.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other incremental light bundle adjustment method.",
                    "label": 1
                },
                {
                    "sent": "This method allowed to reduce the number of variables by algebraically eliminating the three points from the optimization.",
                    "label": 0
                },
                {
                    "sent": "And another significant computational gain was obtained by applying incremental inference, where in practice only on the relevant part of the camera poses were updated each time.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You",
                    "label": 0
                }
            ]
        }
    }
}