{
    "id": "djf5qzfzxk46ylud3sqlqq63w7tmjoc3",
    "title": "A boosting approach to multiview classification with cooperation",
    "info": {
        "author": [
            "Sokol Ko\u00e7o, Laboratoire d\u2019Informatique Fondamentale de Marseille"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Classification",
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Boosting"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_koco_boosting/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "My name is Tucker Carlson from the University of Ex.",
            "Marseille and today I will present the work joint work with Cecil Co on boosting approach to the multiview classification with Corporation."
        ],
        [
            "So I will start with introducing the multiview setting, then the multiclass the boosting setting we used for our approach.",
            "Then I'll present the proposed approach.",
            "I followed by some results we had on synthetic data and then the conclusion and."
        ],
        [
            "Futureworks"
        ],
        [
            "So the multi view learning as start with an example of the multiview learning on further image classification desk.",
            "So we have some data.",
            "In this case the images and the goal is to.",
            "Associate a class or level to the data.",
            "To do so, we use some feature extraction methods, so we get the RGB histogram and other features we call this.",
            "This features views so the RPG histogram in this case is called the view the age OG is called another view, etc.",
            "Then we take these views these features.",
            "We pass them to a learning algorithm and then we get a classifier which we used to classify new examples."
        ],
        [
            "For example, in this case we classify the image as a plane as the image of the plane.",
            "This."
        ],
        [
            "For the Multi View framework, generally we use the most general methods are Fusion based methods and which are divided into cases.",
            "Early Fusion.",
            "An late Fusion in the first case we we fuse the different several views we have on the data and then we learn a classifier on the resulting view and in the second in the second case.",
            "The later Fusion we learn a classifier preview and then we fuse this.",
            "We combine the resulting classifiers on final one.",
            "These are good method methods have good results."
        ],
        [
            "Nevertheless, we believe that there are some drawbacks to this Fusion based methods.",
            "For example, the learn classifiers do not communicate their failures among each others, or marginally they do not communicate among each other, which can be seen as.",
            "Is the lack of.",
            "It's a lack of good generalization result.",
            "Another drawback is that the views must be independent to learn.",
            "Known to have good classification classification results.",
            "Uh, so that the land classifiers are not the same classifiers and the last one is that the Fusion based methods are not effective with weak views.",
            "So as as a possible improvement, what we what we proposed in this paper is to have some sort of cooperation among 'cause of use.",
            "So the idea is to have a classifier.",
            "That is learned on review too.",
            "To communicate its failures to the other and its results to the other classifiers to the other.",
            "Viewed this one.",
            "Should not should be limited so that so.",
            "Yeah, so that we don't have to many problems with the classifiers and by doing this we hope to have its example but be processed by the most appropriate to view."
        ],
        [
            "So Experts week week views that we use the term week week views we used in this paper.",
            "We could view is to consider that week if the best classifier that we can learn on this view is weak classifier in the back bays sense."
        ],
        [
            "Now, As for the multiclass boosting framework that we use, there are generally two different approaches for the multiclass are problem.",
            "The first one is the to divide the problem in several one versus 1.",
            "Problems, smaller problems and the second approach is to divide the multiclass problem in several one versus all problems."
        ],
        [
            "Nevertheless, the problem inconvenient with these two approaches is that there is no formal definition of weak learning condition.",
            "Further boosting cases we have in the binary classification case.",
            "So last year."
        ],
        [
            "There was a framework proposed at NIPS.",
            "The main idea of this framework was to replace the idea of weight of an example of an example with the cost of classification of this example and using this idea we can define the week learning condition, which is the one guy given there.",
            "The idea is that a classifier is is better than random if it's cost on the cost metrics versus the cost metrics is.",
            "Lower than the cost of given basis."
        ],
        [
            "So now I'll pass to the second."
        ],
        [
            "The part.",
            "And I'll present the proposed method.",
            "So our proposed method is a multi view method, so there are different view.",
            "There are several views of different strength defined on the data and for each iteration we maintain N + 1 cost matrices.",
            "In the other post case, for example, we have only one cost metrics or one wait.",
            "For example, in this case we have as many cost metrics is as there are views plus one that is a global cost metrics.",
            "And at each iteration we will the classifiers, communicate their failures to the other, and for each view the cost metrics.",
            "With we had updated using the result of the learn classifier further view and the results of the other classifier.",
            "The idea of this method is given by this schema, where the distribution cost metrics depends on the custom metrics, aren't you?",
            "And that the other cost matrix is."
        ],
        [
            "So As for the algorithm itself, this is the same as the algorithm.",
            "It is an iterative, iterative algorithms.",
            "So at each iteration we learn as many weak classifiers as their views, and for each classifier we can we compute the parimeter Alpha.",
            "Then we update the cost metrics is for the views of we select.",
            "Weak classifier from the M from the EMUI classifiers that we learned that before and then we select the compute another parameter Alpha for this for the chosen classifier.",
            "And then we update the global cost.",
            "Metrics are not the cost metrics for the views.",
            "Then the final hypothesis it's.",
            "It's a classical hypothesis for the multiple multiclass problems where the the label that we associated to an example is the one that has the greatest car."
        ],
        [
            "Now, As for the Matrix update formula, there are.",
            "There are two, uh, two magic update formulas that we use in the algorithm, so the formula is is the same for the best cases.",
            "But what changes is the.",
            "The F function.",
            "The function is roughly the F of INL is roughly the number of times that we we associated the label L to the example.",
            "I further metrics for the metrics of the views we define.",
            "F is given in the formula and we used a second function D which allows us to update or not the function F. A function F during an iteration.",
            "And for the global custom metrics, there is no function D 'cause we don't have multiple views.",
            "There is only one classifier that we have at the time."
        ],
        [
            "Um?",
            "So now I will present the results of theoretical results we had on the cycle and carry them.",
            "First we have we proved that we can bound the error of the learn classifiers purview.",
            "So this roughly means that we can the classifiers that we.",
            "Now that's the algorithm."
        ],
        [
            "Allows us to choose a good classifier at each iteration.",
            "So the proof of the bound of this Mount just I'll give you just the Shima.",
            "So first we used edge condition at the weak learning condition on the.",
            "And the week classifier, and we obtained the 1st in equation.",
            "Then we compute the 3 three quantities in different quantities which correspond to the change on the on the cost metrics is of the.",
            "The examples that are correctly classified by the view, the second one, the Delta minus, correspond to the.",
            "So they do the change of the weights of the classifier examples that time is classified by the by all the views and the last one.",
            "The change of the weight of the weights of the of the examples that I crashed misclassified by the view but are correctly classified by at least another of the other views.",
            "So we compute the dropping loss and using the last result we have there, we obtain the results shown in the other theorem in the bound."
        ],
        [
            "The second bound is the general generalization error bound.",
            "To solve this we we use formula given by Sophie.",
            "It's a classic formula.",
            "We have the generalization error which is bounded by the.",
            "Yeah, empirical error pressed constant.",
            "So to prove that the generalization error of our method decreases with the number of iterations it's we need to show that the first term decreases with the number of iterations and the formula is given."
        ],
        [
            "The lemma, so to prove this we use the margin of an example which is defined as shown.",
            "Then using this margin we calculate the probability that the margin of an example is a lower than than a threshold Theta, and then we generalize this result, which is the second one to 12 the sample and we have the.",
            "The result for the for the bound."
        ],
        [
            "Now is present some results we had on the synthetic data.",
            "We generated data using a Gaussian distribution and a uniform distribution so that user generated reviews so that for some examples all of the attributes the features are generated using a Gaussian distribution and for some others the features are generated using a Gaussian distribution in some use and uniform distribution in in another.",
            "Then we compared our methods with.",
            "Three other methods.",
            "The three other Fusion based methods.",
            "The first one is the early Fusion.",
            "A method combined with an SM, so we learned a lesson on the on the fused views.",
            "Then we learned on SM per view and then refused the resulting classifiers and the last method.",
            "We refused the views and we learned that Nando Boost algorithm on.",
            "On the on the data.",
            "And there is.",
            "There is also that our method is indeed better than than the other Fusion based methods."
        ],
        [
            "Uh, so."
        ],
        [
            "It's a conclusion.",
            "I will be in in the paper we present the boosting like algorithm for multi view setting which promotes the cooperation between the different views.",
            "The views that we consider are of different strengths and the cost update formula allows the views to focus on on examples that are hard to classify for the other views.",
            "So we have the.",
            "The the cooperation between other different views and then we I showed the bound for the dinner.",
            "I proved the bound for the generalization error and the empirical empirical error and the result that we had on this synthetic data confirm that.",
            "The theoretical properties some of the future works.",
            "Um?",
            "Some of the future works that we can modify the degree of cooperation between the different views we we can find.",
            "Hopefully tighter bounds for the different errors and to test the algorithm on."
        ],
        [
            "Other data, so thank you for your attention and if you have any questions.",
            "We could take a couple of questions.",
            "Our questions.",
            "OK, let's thank our speaker.",
            "The top 10 for giving us some extra minutes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Tucker Carlson from the University of Ex.",
                    "label": 0
                },
                {
                    "sent": "Marseille and today I will present the work joint work with Cecil Co on boosting approach to the multiview classification with Corporation.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will start with introducing the multiview setting, then the multiclass the boosting setting we used for our approach.",
                    "label": 0
                },
                {
                    "sent": "Then I'll present the proposed approach.",
                    "label": 0
                },
                {
                    "sent": "I followed by some results we had on synthetic data and then the conclusion and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Futureworks",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the multi view learning as start with an example of the multiview learning on further image classification desk.",
                    "label": 1
                },
                {
                    "sent": "So we have some data.",
                    "label": 0
                },
                {
                    "sent": "In this case the images and the goal is to.",
                    "label": 0
                },
                {
                    "sent": "Associate a class or level to the data.",
                    "label": 0
                },
                {
                    "sent": "To do so, we use some feature extraction methods, so we get the RGB histogram and other features we call this.",
                    "label": 0
                },
                {
                    "sent": "This features views so the RPG histogram in this case is called the view the age OG is called another view, etc.",
                    "label": 0
                },
                {
                    "sent": "Then we take these views these features.",
                    "label": 0
                },
                {
                    "sent": "We pass them to a learning algorithm and then we get a classifier which we used to classify new examples.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, in this case we classify the image as a plane as the image of the plane.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the Multi View framework, generally we use the most general methods are Fusion based methods and which are divided into cases.",
                    "label": 0
                },
                {
                    "sent": "Early Fusion.",
                    "label": 0
                },
                {
                    "sent": "An late Fusion in the first case we we fuse the different several views we have on the data and then we learn a classifier on the resulting view and in the second in the second case.",
                    "label": 0
                },
                {
                    "sent": "The later Fusion we learn a classifier preview and then we fuse this.",
                    "label": 0
                },
                {
                    "sent": "We combine the resulting classifiers on final one.",
                    "label": 0
                },
                {
                    "sent": "These are good method methods have good results.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nevertheless, we believe that there are some drawbacks to this Fusion based methods.",
                    "label": 1
                },
                {
                    "sent": "For example, the learn classifiers do not communicate their failures among each others, or marginally they do not communicate among each other, which can be seen as.",
                    "label": 1
                },
                {
                    "sent": "Is the lack of.",
                    "label": 0
                },
                {
                    "sent": "It's a lack of good generalization result.",
                    "label": 1
                },
                {
                    "sent": "Another drawback is that the views must be independent to learn.",
                    "label": 0
                },
                {
                    "sent": "Known to have good classification classification results.",
                    "label": 0
                },
                {
                    "sent": "Uh, so that the land classifiers are not the same classifiers and the last one is that the Fusion based methods are not effective with weak views.",
                    "label": 1
                },
                {
                    "sent": "So as as a possible improvement, what we what we proposed in this paper is to have some sort of cooperation among 'cause of use.",
                    "label": 1
                },
                {
                    "sent": "So the idea is to have a classifier.",
                    "label": 0
                },
                {
                    "sent": "That is learned on review too.",
                    "label": 1
                },
                {
                    "sent": "To communicate its failures to the other and its results to the other classifiers to the other.",
                    "label": 0
                },
                {
                    "sent": "Viewed this one.",
                    "label": 0
                },
                {
                    "sent": "Should not should be limited so that so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that we don't have to many problems with the classifiers and by doing this we hope to have its example but be processed by the most appropriate to view.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Experts week week views that we use the term week week views we used in this paper.",
                    "label": 0
                },
                {
                    "sent": "We could view is to consider that week if the best classifier that we can learn on this view is weak classifier in the back bays sense.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, As for the multiclass boosting framework that we use, there are generally two different approaches for the multiclass are problem.",
                    "label": 1
                },
                {
                    "sent": "The first one is the to divide the problem in several one versus 1.",
                    "label": 0
                },
                {
                    "sent": "Problems, smaller problems and the second approach is to divide the multiclass problem in several one versus all problems.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nevertheless, the problem inconvenient with these two approaches is that there is no formal definition of weak learning condition.",
                    "label": 1
                },
                {
                    "sent": "Further boosting cases we have in the binary classification case.",
                    "label": 0
                },
                {
                    "sent": "So last year.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There was a framework proposed at NIPS.",
                    "label": 0
                },
                {
                    "sent": "The main idea of this framework was to replace the idea of weight of an example of an example with the cost of classification of this example and using this idea we can define the week learning condition, which is the one guy given there.",
                    "label": 1
                },
                {
                    "sent": "The idea is that a classifier is is better than random if it's cost on the cost metrics versus the cost metrics is.",
                    "label": 0
                },
                {
                    "sent": "Lower than the cost of given basis.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'll pass to the second.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The part.",
                    "label": 0
                },
                {
                    "sent": "And I'll present the proposed method.",
                    "label": 0
                },
                {
                    "sent": "So our proposed method is a multi view method, so there are different view.",
                    "label": 0
                },
                {
                    "sent": "There are several views of different strength defined on the data and for each iteration we maintain N + 1 cost matrices.",
                    "label": 1
                },
                {
                    "sent": "In the other post case, for example, we have only one cost metrics or one wait.",
                    "label": 0
                },
                {
                    "sent": "For example, in this case we have as many cost metrics is as there are views plus one that is a global cost metrics.",
                    "label": 1
                },
                {
                    "sent": "And at each iteration we will the classifiers, communicate their failures to the other, and for each view the cost metrics.",
                    "label": 1
                },
                {
                    "sent": "With we had updated using the result of the learn classifier further view and the results of the other classifier.",
                    "label": 0
                },
                {
                    "sent": "The idea of this method is given by this schema, where the distribution cost metrics depends on the custom metrics, aren't you?",
                    "label": 0
                },
                {
                    "sent": "And that the other cost matrix is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So As for the algorithm itself, this is the same as the algorithm.",
                    "label": 1
                },
                {
                    "sent": "It is an iterative, iterative algorithms.",
                    "label": 1
                },
                {
                    "sent": "So at each iteration we learn as many weak classifiers as their views, and for each classifier we can we compute the parimeter Alpha.",
                    "label": 0
                },
                {
                    "sent": "Then we update the cost metrics is for the views of we select.",
                    "label": 0
                },
                {
                    "sent": "Weak classifier from the M from the EMUI classifiers that we learned that before and then we select the compute another parameter Alpha for this for the chosen classifier.",
                    "label": 0
                },
                {
                    "sent": "And then we update the global cost.",
                    "label": 1
                },
                {
                    "sent": "Metrics are not the cost metrics for the views.",
                    "label": 0
                },
                {
                    "sent": "Then the final hypothesis it's.",
                    "label": 0
                },
                {
                    "sent": "It's a classical hypothesis for the multiple multiclass problems where the the label that we associated to an example is the one that has the greatest car.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, As for the Matrix update formula, there are.",
                    "label": 0
                },
                {
                    "sent": "There are two, uh, two magic update formulas that we use in the algorithm, so the formula is is the same for the best cases.",
                    "label": 0
                },
                {
                    "sent": "But what changes is the.",
                    "label": 0
                },
                {
                    "sent": "The F function.",
                    "label": 0
                },
                {
                    "sent": "The function is roughly the F of INL is roughly the number of times that we we associated the label L to the example.",
                    "label": 0
                },
                {
                    "sent": "I further metrics for the metrics of the views we define.",
                    "label": 0
                },
                {
                    "sent": "F is given in the formula and we used a second function D which allows us to update or not the function F. A function F during an iteration.",
                    "label": 0
                },
                {
                    "sent": "And for the global custom metrics, there is no function D 'cause we don't have multiple views.",
                    "label": 0
                },
                {
                    "sent": "There is only one classifier that we have at the time.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So now I will present the results of theoretical results we had on the cycle and carry them.",
                    "label": 0
                },
                {
                    "sent": "First we have we proved that we can bound the error of the learn classifiers purview.",
                    "label": 0
                },
                {
                    "sent": "So this roughly means that we can the classifiers that we.",
                    "label": 0
                },
                {
                    "sent": "Now that's the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Allows us to choose a good classifier at each iteration.",
                    "label": 0
                },
                {
                    "sent": "So the proof of the bound of this Mount just I'll give you just the Shima.",
                    "label": 1
                },
                {
                    "sent": "So first we used edge condition at the weak learning condition on the.",
                    "label": 1
                },
                {
                    "sent": "And the week classifier, and we obtained the 1st in equation.",
                    "label": 0
                },
                {
                    "sent": "Then we compute the 3 three quantities in different quantities which correspond to the change on the on the cost metrics is of the.",
                    "label": 0
                },
                {
                    "sent": "The examples that are correctly classified by the view, the second one, the Delta minus, correspond to the.",
                    "label": 0
                },
                {
                    "sent": "So they do the change of the weights of the classifier examples that time is classified by the by all the views and the last one.",
                    "label": 0
                },
                {
                    "sent": "The change of the weight of the weights of the of the examples that I crashed misclassified by the view but are correctly classified by at least another of the other views.",
                    "label": 0
                },
                {
                    "sent": "So we compute the dropping loss and using the last result we have there, we obtain the results shown in the other theorem in the bound.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second bound is the general generalization error bound.",
                    "label": 1
                },
                {
                    "sent": "To solve this we we use formula given by Sophie.",
                    "label": 0
                },
                {
                    "sent": "It's a classic formula.",
                    "label": 1
                },
                {
                    "sent": "We have the generalization error which is bounded by the.",
                    "label": 1
                },
                {
                    "sent": "Yeah, empirical error pressed constant.",
                    "label": 0
                },
                {
                    "sent": "So to prove that the generalization error of our method decreases with the number of iterations it's we need to show that the first term decreases with the number of iterations and the formula is given.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The lemma, so to prove this we use the margin of an example which is defined as shown.",
                    "label": 1
                },
                {
                    "sent": "Then using this margin we calculate the probability that the margin of an example is a lower than than a threshold Theta, and then we generalize this result, which is the second one to 12 the sample and we have the.",
                    "label": 1
                },
                {
                    "sent": "The result for the for the bound.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now is present some results we had on the synthetic data.",
                    "label": 0
                },
                {
                    "sent": "We generated data using a Gaussian distribution and a uniform distribution so that user generated reviews so that for some examples all of the attributes the features are generated using a Gaussian distribution and for some others the features are generated using a Gaussian distribution in some use and uniform distribution in in another.",
                    "label": 0
                },
                {
                    "sent": "Then we compared our methods with.",
                    "label": 0
                },
                {
                    "sent": "Three other methods.",
                    "label": 0
                },
                {
                    "sent": "The three other Fusion based methods.",
                    "label": 0
                },
                {
                    "sent": "The first one is the early Fusion.",
                    "label": 0
                },
                {
                    "sent": "A method combined with an SM, so we learned a lesson on the on the fused views.",
                    "label": 0
                },
                {
                    "sent": "Then we learned on SM per view and then refused the resulting classifiers and the last method.",
                    "label": 0
                },
                {
                    "sent": "We refused the views and we learned that Nando Boost algorithm on.",
                    "label": 0
                },
                {
                    "sent": "On the on the data.",
                    "label": 0
                },
                {
                    "sent": "And there is.",
                    "label": 0
                },
                {
                    "sent": "There is also that our method is indeed better than than the other Fusion based methods.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uh, so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a conclusion.",
                    "label": 0
                },
                {
                    "sent": "I will be in in the paper we present the boosting like algorithm for multi view setting which promotes the cooperation between the different views.",
                    "label": 1
                },
                {
                    "sent": "The views that we consider are of different strengths and the cost update formula allows the views to focus on on examples that are hard to classify for the other views.",
                    "label": 1
                },
                {
                    "sent": "So we have the.",
                    "label": 1
                },
                {
                    "sent": "The the cooperation between other different views and then we I showed the bound for the dinner.",
                    "label": 1
                },
                {
                    "sent": "I proved the bound for the generalization error and the empirical empirical error and the result that we had on this synthetic data confirm that.",
                    "label": 0
                },
                {
                    "sent": "The theoretical properties some of the future works.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Some of the future works that we can modify the degree of cooperation between the different views we we can find.",
                    "label": 0
                },
                {
                    "sent": "Hopefully tighter bounds for the different errors and to test the algorithm on.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other data, so thank you for your attention and if you have any questions.",
                    "label": 0
                },
                {
                    "sent": "We could take a couple of questions.",
                    "label": 0
                },
                {
                    "sent": "Our questions.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank our speaker.",
                    "label": 0
                },
                {
                    "sent": "The top 10 for giving us some extra minutes.",
                    "label": 0
                }
            ]
        }
    }
}